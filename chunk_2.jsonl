{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding elements given a By strategy and locator.", "response": "def find_elements(self, by=By.ID, value=None):\n        \"\"\"\n        Find elements given a By strategy and locator. Prefer the find_elements_by_* methods when\n        possible.\n\n        :Usage:\n            ::\n\n                elements = driver.find_elements(By.CLASS_NAME, 'foo')\n\n        :rtype: list of WebElement\n        \"\"\"\n        if self.w3c:\n            if by == By.ID:\n                by = By.CSS_SELECTOR\n                value = '[id=\"%s\"]' % value\n            elif by == By.TAG_NAME:\n                by = By.CSS_SELECTOR\n            elif by == By.CLASS_NAME:\n                by = By.CSS_SELECTOR\n                value = \".%s\" % value\n            elif by == By.NAME:\n                by = By.CSS_SELECTOR\n                value = '[name=\"%s\"]' % value\n\n        # Return empty list if driver returns null\n        # See https://github.com/SeleniumHQ/selenium/issues/4555\n        return self.execute(Command.FIND_ELEMENTS, {\n            'using': by,\n            'value': value})['value'] or []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_screenshot_as_file(self, filename):\n        if not filename.lower().endswith('.png'):\n            warnings.warn(\"name used for saved screenshot does not match file \"\n                          \"type. It should end with a `.png` extension\", UserWarning)\n        png = self.get_screenshot_as_png()\n        try:\n            with open(filename, 'wb') as f:\n                f.write(png)\n        except IOError:\n            return False\n        finally:\n            del png\n        return True", "response": "Saves a screenshot of the current window to a PNG image file. Returns False if there is any IOError else returns True."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_window_size(self, width, height, windowHandle='current'):\n        if self.w3c:\n            if windowHandle != 'current':\n                warnings.warn(\"Only 'current' window is supported for W3C compatibile browsers.\")\n            self.set_window_rect(width=int(width), height=int(height))\n        else:\n            self.execute(Command.SET_WINDOW_SIZE, {\n                'width': int(width),\n                'height': int(height),\n                'windowHandle': windowHandle})", "response": "Sets the width and height of the current window."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_window_size(self, windowHandle='current'):\n        command = Command.GET_WINDOW_SIZE\n        if self.w3c:\n            if windowHandle != 'current':\n                warnings.warn(\"Only 'current' window is supported for W3C compatibile browsers.\")\n            size = self.get_window_rect()\n        else:\n            size = self.execute(command, {'windowHandle': windowHandle})\n\n        if size.get('value', None) is not None:\n            size = size['value']\n\n        return {k: size[k] for k in ('width', 'height')}", "response": "Gets the width and height of the current window."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_window_position(self, x, y, windowHandle='current'):\n        if self.w3c:\n            if windowHandle != 'current':\n                warnings.warn(\"Only 'current' window is supported for W3C compatibile browsers.\")\n            return self.set_window_rect(x=int(x), y=int(y))\n        else:\n            self.execute(Command.SET_WINDOW_POSITION,\n                         {\n                             'x': int(x),\n                             'y': int(y),\n                             'windowHandle': windowHandle\n                         })", "response": "Sets the x y position of the current window."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the x y position of the current window.", "response": "def get_window_position(self, windowHandle='current'):\n        \"\"\"\n        Gets the x,y position of the current window.\n\n        :Usage:\n            ::\n\n                driver.get_window_position()\n        \"\"\"\n        if self.w3c:\n            if windowHandle != 'current':\n                warnings.warn(\"Only 'current' window is supported for W3C compatibile browsers.\")\n            position = self.get_window_rect()\n        else:\n            position = self.execute(Command.GET_WINDOW_POSITION,\n                                    {'windowHandle': windowHandle})['value']\n\n        return {k: position[k] for k in ('x', 'y')}"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the x y coordinates of the current window as well as height and width of the current window.", "response": "def set_window_rect(self, x=None, y=None, width=None, height=None):\n        \"\"\"\n        Sets the x, y coordinates of the window as well as height and width of\n        the current window. This method is only supported for W3C compatible\n        browsers; other browsers should use `set_window_position` and\n        `set_window_size`.\n\n        :Usage:\n            ::\n\n                driver.set_window_rect(x=10, y=10)\n                driver.set_window_rect(width=100, height=200)\n                driver.set_window_rect(x=10, y=10, width=100, height=200)\n        \"\"\"\n        if not self.w3c:\n            raise UnknownMethodException(\"set_window_rect is only supported for W3C compatible browsers\")\n\n        if (x is None and y is None) and (height is None and width is None):\n            raise InvalidArgumentException(\"x and y or height and width need values\")\n\n        return self.execute(Command.SET_WINDOW_RECT, {\"x\": x, \"y\": y,\n                                                      \"width\": width,\n                                                      \"height\": height})['value']"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the file detector that will be used when sending keyboard input.", "response": "def file_detector(self, detector):\n        \"\"\"\n        Set the file detector to be used when sending keyboard input.\n        By default, this is set to a file detector that does nothing.\n\n        see FileDetector\n        see LocalFileDetector\n        see UselessFileDetector\n\n        :Args:\n         - detector: The detector to use. Must not be None.\n        \"\"\"\n        if detector is None:\n            raise WebDriverException(\"You may not set a file detector that is null\")\n        if not isinstance(detector, FileDetector):\n            raise WebDriverException(\"Detector has to be instance of FileDetector\")\n        self._file_detector = detector"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the current orientation of the device.", "response": "def orientation(self, value):\n        \"\"\"\n        Sets the current orientation of the device\n\n        :Args:\n         - value: orientation to set it to.\n\n        :Usage:\n            ::\n\n                driver.orientation = 'landscape'\n        \"\"\"\n        allowed_values = ['LANDSCAPE', 'PORTRAIT']\n        if value.upper() in allowed_values:\n            self.execute(Command.SET_SCREEN_ORIENTATION, {'orientation': value})\n        else:\n            raise WebDriverException(\"You can only set the orientation to 'LANDSCAPE' and 'PORTRAIT'\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_response(self, response):\n        status = response.get('status', None)\n        if status is None or status == ErrorCode.SUCCESS:\n            return\n        value = None\n        message = response.get(\"message\", \"\")\n        screen = response.get(\"screen\", \"\")\n        stacktrace = None\n        if isinstance(status, int):\n            value_json = response.get('value', None)\n            if value_json and isinstance(value_json, basestring):\n                import json\n                try:\n                    value = json.loads(value_json)\n                    if len(value.keys()) == 1:\n                        value = value['value']\n                    status = value.get('error', None)\n                    if status is None:\n                        status = value[\"status\"]\n                        message = value[\"value\"]\n                        if not isinstance(message, basestring):\n                            value = message\n                            message = message.get('message')\n                    else:\n                        message = value.get('message', None)\n                except ValueError:\n                    pass\n\n        if status in ErrorCode.NO_SUCH_ELEMENT:\n            exception_class = NoSuchElementException\n        elif status in ErrorCode.NO_SUCH_FRAME:\n            exception_class = NoSuchFrameException\n        elif status in ErrorCode.NO_SUCH_WINDOW:\n            exception_class = NoSuchWindowException\n        elif status in ErrorCode.STALE_ELEMENT_REFERENCE:\n            exception_class = StaleElementReferenceException\n        elif status in ErrorCode.ELEMENT_NOT_VISIBLE:\n            exception_class = ElementNotVisibleException\n        elif status in ErrorCode.INVALID_ELEMENT_STATE:\n            exception_class = InvalidElementStateException\n        elif status in ErrorCode.INVALID_SELECTOR \\\n                or status in ErrorCode.INVALID_XPATH_SELECTOR \\\n                or status in ErrorCode.INVALID_XPATH_SELECTOR_RETURN_TYPER:\n            exception_class = InvalidSelectorException\n        elif status in ErrorCode.ELEMENT_IS_NOT_SELECTABLE:\n            exception_class = ElementNotSelectableException\n        elif status in ErrorCode.ELEMENT_NOT_INTERACTABLE:\n            exception_class = ElementNotInteractableException\n        elif status in ErrorCode.INVALID_COOKIE_DOMAIN:\n            exception_class = InvalidCookieDomainException\n        elif status in ErrorCode.UNABLE_TO_SET_COOKIE:\n            exception_class = UnableToSetCookieException\n        elif status in ErrorCode.TIMEOUT:\n            exception_class = TimeoutException\n        elif status in ErrorCode.SCRIPT_TIMEOUT:\n            exception_class = TimeoutException\n        elif status in ErrorCode.UNKNOWN_ERROR:\n            exception_class = WebDriverException\n        elif status in ErrorCode.UNEXPECTED_ALERT_OPEN:\n            exception_class = UnexpectedAlertPresentException\n        elif status in ErrorCode.NO_ALERT_OPEN:\n            exception_class = NoAlertPresentException\n        elif status in ErrorCode.IME_NOT_AVAILABLE:\n            exception_class = ImeNotAvailableException\n        elif status in ErrorCode.IME_ENGINE_ACTIVATION_FAILED:\n            exception_class = ImeActivationFailedException\n        elif status in ErrorCode.MOVE_TARGET_OUT_OF_BOUNDS:\n            exception_class = MoveTargetOutOfBoundsException\n        elif status in ErrorCode.JAVASCRIPT_ERROR:\n            exception_class = JavascriptException\n        elif status in ErrorCode.SESSION_NOT_CREATED:\n            exception_class = SessionNotCreatedException\n        elif status in ErrorCode.INVALID_ARGUMENT:\n            exception_class = InvalidArgumentException\n        elif status in ErrorCode.NO_SUCH_COOKIE:\n            exception_class = NoSuchCookieException\n        elif status in ErrorCode.UNABLE_TO_CAPTURE_SCREEN:\n            exception_class = ScreenshotException\n        elif status in ErrorCode.ELEMENT_CLICK_INTERCEPTED:\n            exception_class = ElementClickInterceptedException\n        elif status in ErrorCode.INSECURE_CERTIFICATE:\n            exception_class = InsecureCertificateException\n        elif status in ErrorCode.INVALID_COORDINATES:\n            exception_class = InvalidCoordinatesException\n        elif status in ErrorCode.INVALID_SESSION_ID:\n            exception_class = InvalidSessionIdException\n        elif status in ErrorCode.UNKNOWN_METHOD:\n            exception_class = UnknownMethodException\n        else:\n            exception_class = WebDriverException\n        if value == '' or value is None:\n            value = response['value']\n        if isinstance(value, basestring):\n            raise exception_class(value)\n        if message == \"\" and 'message' in value:\n            message = value['message']\n\n        screen = None\n        if 'screen' in value:\n            screen = value['screen']\n\n        stacktrace = None\n        if 'stackTrace' in value and value['stackTrace']:\n            stacktrace = []\n            try:\n                for frame in value['stackTrace']:\n                    line = self._value_or_default(frame, 'lineNumber', '')\n                    file = self._value_or_default(frame, 'fileName', '<anonymous>')\n                    if line:\n                        file = \"%s:%s\" % (file, line)\n                    meth = self._value_or_default(frame, 'methodName', '<anonymous>')\n                    if 'className' in frame:\n                        meth = \"%s.%s\" % (frame['className'], meth)\n                    msg = \"    at %s (%s)\"\n                    msg = msg % (meth, file)\n                    stacktrace.append(msg)\n            except TypeError:\n                pass\n        if exception_class == UnexpectedAlertPresentException:\n            alert_text = None\n            if 'data' in value:\n                alert_text = value['data'].get('text')\n            elif 'alert' in value:\n                alert_text = value['alert'].get('text')\n            raise exception_class(message, screen, stacktrace, alert_text)\n        raise exception_class(message, screen, stacktrace)", "response": "Checks that a JSON response from the WebDriver server has an error."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef until(self, method, message=''):\n        screen = None\n        stacktrace = None\n\n        end_time = time.time() + self._timeout\n        while True:\n            try:\n                value = method(self._driver)\n                if value:\n                    return value\n            except self._ignored_exceptions as exc:\n                screen = getattr(exc, 'screen', None)\n                stacktrace = getattr(exc, 'stacktrace', None)\n            time.sleep(self._poll)\n            if time.time() > end_time:\n                break\n        raise TimeoutException(message, screen, stacktrace)", "response": "Calls the method provided with the driver as an argument until the return value does not evaluate to False."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef until_not(self, method, message=''):\n        end_time = time.time() + self._timeout\n        while True:\n            try:\n                value = method(self._driver)\n                if not value:\n                    return value\n            except self._ignored_exceptions:\n                return True\n            time.sleep(self._poll)\n            if time.time() > end_time:\n                break\n        raise TimeoutException(message)", "response": "Calls the method provided with the driver as an argument until the return value evaluates to False."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nquitting the driver and close every associated window.", "response": "def quit(self):\n        \"\"\"Quits the driver and close every associated window.\"\"\"\n        try:\n            RemoteWebDriver.quit(self)\n        except Exception:\n            # We don't care about the message because something probably has gone wrong\n            pass\n\n        if self.w3c:\n            self.service.stop()\n        else:\n            self.binary.kill()\n\n        if self.profile is not None:\n            try:\n                shutil.rmtree(self.profile.path)\n                if self.profile.tempfolder is not None:\n                    shutil.rmtree(self.profile.tempfolder)\n            except Exception as e:\n                print(str(e))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef context(self, context):\n        initial_context = self.execute('GET_CONTEXT').pop('value')\n        self.set_context(context)\n        try:\n            yield\n        finally:\n            self.set_context(initial_context)", "response": "Sets the context that Selenium commands are running in using\n        a with statement."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef install_addon(self, path, temporary=None):\n        payload = {\"path\": path}\n        if temporary is not None:\n            payload[\"temporary\"] = temporary\n        return self.execute(\"INSTALL_ADDON\", payload)[\"value\"]", "response": "Installs Firefox addon.\n\n        Returns identifier of installed addon. This identifier can later\n        be used to uninstall addon.\n\n        :param path: Absolute path to the addon that will be installed.\n\n        :Usage:\n            ::\n\n                driver.install_addon('/path/to/firebug.xpi')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef binary(self, new_binary):\n        if not isinstance(new_binary, FirefoxBinary):\n            new_binary = FirefoxBinary(new_binary)\n        self._binary = new_binary", "response": "Sets the location of the browser binary."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the location of the browser profile to use either by string or FirefoxProfile.", "response": "def profile(self, new_profile):\n        \"\"\"Sets location of the browser profile to use, either by string\n        or ``FirefoxProfile``.\n\n        \"\"\"\n        if not isinstance(new_profile, FirefoxProfile):\n            new_profile = FirefoxProfile(new_profile)\n        self._profile = new_profile"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef headless(self, value):\n        if value is True:\n            self._arguments.append('-headless')\n        elif '-headless' in self._arguments:\n            self._arguments.remove('-headless')", "response": "Sets the headless argument"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmarshals the Firefox options to a moz. firefoxOptions object.", "response": "def to_capabilities(self):\n        \"\"\"Marshals the Firefox options to a `moz:firefoxOptions`\n        object.\n        \"\"\"\n        # This intentionally looks at the internal properties\n        # so if a binary or profile has _not_ been set,\n        # it will defer to geckodriver to find the system Firefox\n        # and generate a fresh profile.\n        caps = self._caps\n        opts = {}\n\n        if self._binary is not None:\n            opts[\"binary\"] = self._binary._start_cmd\n        if len(self._preferences) > 0:\n            opts[\"prefs\"] = self._preferences\n        if self._proxy is not None:\n            self._proxy.add_to_capabilities(opts)\n        if self._profile is not None:\n            opts[\"profile\"] = self._profile.encoded\n        if len(self._arguments) > 0:\n            opts[\"args\"] = self._arguments\n\n        opts.update(self.log.to_capabilities())\n\n        if len(opts) > 0:\n            caps[Options.KEY] = opts\n\n        return caps"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_network_connection(self, network):\n        mode = network.mask if isinstance(network, self.ConnectionType) else network\n        return self.ConnectionType(self._driver.execute(\n            Command.SET_NETWORK_CONNECTION, {\n                'name': 'network_connection',\n                'parameters': {'type': mode}})['value'])", "response": "Sets the network connection for the remote device."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nunzips a zip file into a temporary directory.", "response": "def unzip_to_temp_dir(zip_file_name):\n    \"\"\"Unzip zipfile to a temporary directory.\n\n    The directory of the unzipped files is returned if success,\n    otherwise None is returned. \"\"\"\n    if not zip_file_name or not os.path.exists(zip_file_name):\n        return None\n\n    zf = zipfile.ZipFile(zip_file_name)\n\n    if zf.testzip() is not None:\n        return None\n\n    # Unzip the files into a temporary directory\n    LOGGER.info(\"Extracting zipped file: %s\" % zip_file_name)\n    tempdir = tempfile.mkdtemp()\n\n    try:\n        # Create directories that don't exist\n        for zip_name in zf.namelist():\n            # We have no knowledge on the os where the zipped file was\n            # created, so we restrict to zip files with paths without\n            # charactor \"\\\" and \"/\".\n            name = (zip_name.replace(\"\\\\\", os.path.sep).\n                    replace(\"/\", os.path.sep))\n            dest = os.path.join(tempdir, name)\n            if (name.endswith(os.path.sep) and not os.path.exists(dest)):\n                os.mkdir(dest)\n                LOGGER.debug(\"Directory %s created.\" % dest)\n\n        # Copy files\n        for zip_name in zf.namelist():\n            # We have no knowledge on the os where the zipped file was\n            # created, so we restrict to zip files with paths without\n            # charactor \"\\\" and \"/\".\n            name = (zip_name.replace(\"\\\\\", os.path.sep).\n                    replace(\"/\", os.path.sep))\n            dest = os.path.join(tempdir, name)\n            if not (name.endswith(os.path.sep)):\n                LOGGER.debug(\"Copying file %s......\" % dest)\n                outfile = open(dest, 'wb')\n                outfile.write(zf.read(zip_name))\n                outfile.close()\n                LOGGER.debug(\"File %s copied.\" % dest)\n\n        LOGGER.info(\"Unzipped file can be found at %s\" % tempdir)\n        return tempdir\n\n    except IOError as err:\n        LOGGER.error(\"Error in extracting webdriver.xpi: %s\" % err)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tap(self, on_element):\n        self._actions.append(lambda: self._driver.execute(\n            Command.SINGLE_TAP, {'element': on_element.id}))\n        return self", "response": "Taps on a given element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef double_tap(self, on_element):\n        self._actions.append(lambda: self._driver.execute(\n            Command.DOUBLE_TAP, {'element': on_element.id}))\n        return self", "response": "Double taps on an element."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tap_and_hold(self, xcoord, ycoord):\n        self._actions.append(lambda: self._driver.execute(\n            Command.TOUCH_DOWN, {\n                'x': int(xcoord),\n                'y': int(ycoord)}))\n        return self", "response": "Touch down at given coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmoving held tap to specified location.", "response": "def move(self, xcoord, ycoord):\n        \"\"\"\n        Move held tap to specified location.\n\n        :Args:\n         - xcoord: X Coordinate to move.\n         - ycoord: Y Coordinate to move.\n        \"\"\"\n        self._actions.append(lambda: self._driver.execute(\n            Command.TOUCH_MOVE, {\n                'x': int(xcoord),\n                'y': int(ycoord)}))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef release(self, xcoord, ycoord):\n        self._actions.append(lambda: self._driver.execute(\n            Command.TOUCH_UP, {\n                'x': int(xcoord),\n                'y': int(ycoord)}))\n        return self", "response": "Release previously issued tap and hold command at specified location."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntouch and scroll moving by xoffset and yoffset.", "response": "def scroll(self, xoffset, yoffset):\n        \"\"\"\n        Touch and scroll, moving by xoffset and yoffset.\n\n        :Args:\n         - xoffset: X offset to scroll to.\n         - yoffset: Y offset to scroll to.\n        \"\"\"\n        self._actions.append(lambda: self._driver.execute(\n            Command.TOUCH_SCROLL, {\n                'xoffset': int(xoffset),\n                'yoffset': int(yoffset)}))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntouches and scroll starting at on_element moving by xoffset and yoffset.", "response": "def scroll_from_element(self, on_element, xoffset, yoffset):\n        \"\"\"\n        Touch and scroll starting at on_element, moving by xoffset and yoffset.\n\n        :Args:\n         - on_element: The element where scroll starts.\n         - xoffset: X offset to scroll to.\n         - yoffset: Y offset to scroll to.\n        \"\"\"\n        self._actions.append(lambda: self._driver.execute(\n            Command.TOUCH_SCROLL, {\n                'element': on_element.id,\n                'xoffset': int(xoffset),\n                'yoffset': int(yoffset)}))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef long_press(self, on_element):\n        self._actions.append(lambda: self._driver.execute(\n            Command.LONG_PRESS, {'element': on_element.id}))\n        return self", "response": "Long press on an element."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nflicks the current page.", "response": "def flick(self, xspeed, yspeed):\n        \"\"\"\n        Flicks, starting anywhere on the screen.\n\n        :Args:\n         - xspeed: The X speed in pixels per second.\n         - yspeed: The Y speed in pixels per second.\n        \"\"\"\n        self._actions.append(lambda: self._driver.execute(\n            Command.FLICK, {\n                'xspeed': int(xspeed),\n                'yspeed': int(yspeed)}))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef flick_element(self, on_element, xoffset, yoffset, speed):\n        self._actions.append(lambda: self._driver.execute(\n            Command.FLICK, {\n                'element': on_element.id,\n                'xoffset': int(xoffset),\n                'yoffset': int(yoffset),\n                'speed': int(speed)}))\n        return self", "response": "Flick an element in the hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a dictionary with all the options that have been set and returns a dictionary with all the options that have been set and returns a dictionary with everything", "response": "def to_capabilities(self):\n        \"\"\"\n        Creates a capabilities with all the options that have been set and\n        returns a dictionary with everything\n        \"\"\"\n        caps = self._caps\n\n        browser_options = {}\n        if self.binary_location:\n            browser_options[\"binary\"] = self.binary_location\n        if self.arguments:\n            browser_options[\"args\"] = self.arguments\n        browser_options[\"useOverlayScrollbars\"] = self.overlay_scrollbars_enabled\n\n        caps[Options.KEY] = browser_options\n\n        return caps"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the element with focus or BODY if nothing has focus.", "response": "def active_element(self):\n        \"\"\"\n        Returns the element with focus, or BODY if nothing has focus.\n\n        :Usage:\n            ::\n\n                element = driver.switch_to.active_element\n        \"\"\"\n        if self._driver.w3c:\n            return self._driver.execute(Command.W3C_GET_ACTIVE_ELEMENT)['value']\n        else:\n            return self._driver.execute(Command.GET_ACTIVE_ELEMENT)['value']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef frame(self, frame_reference):\n        if isinstance(frame_reference, basestring) and self._driver.w3c:\n            try:\n                frame_reference = self._driver.find_element(By.ID, frame_reference)\n            except NoSuchElementException:\n                try:\n                    frame_reference = self._driver.find_element(By.NAME, frame_reference)\n                except NoSuchElementException:\n                    raise NoSuchFrameException(frame_reference)\n\n        self._driver.execute(Command.SWITCH_TO_FRAME, {'id': frame_reference})", "response": "Switches focus to the specified frame."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nswitching to a new top - level browsing context.", "response": "def new_window(self, type_hint=None):\n        \"\"\"Switches to a new top-level browsing context.\n\n        The type hint can be one of \"tab\" or \"window\". If not specified the\n        browser will automatically select it.\n\n        :Usage:\n            ::\n\n                driver.switch_to.new_window('tab')\n        \"\"\"\n        value = self._driver.execute(Command.NEW_WINDOW, {'type': type_hint})['value']\n        self._w3c_window(value['handle'])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef window(self, window_name):\n        if self._driver.w3c:\n            self._w3c_window(window_name)\n            return\n        data = {'name': window_name}\n        self._driver.execute(Command.SWITCH_TO_WINDOW, data)", "response": "Switches focus to the specified window."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef perform(self):\n        if self._driver.w3c:\n            self.w3c_actions.perform()\n        else:\n            for action in self._actions:\n                action()", "response": "Perform all stored actions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reset_actions(self):\n        if self._driver.w3c:\n            self.w3c_actions.clear_actions()\n        self._actions = []", "response": "Clears actions that are already stored locally and on the remote end."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclick the left mouse button on an element.", "response": "def click_and_hold(self, on_element=None):\n        \"\"\"\n        Holds down the left mouse button on an element.\n\n        :Args:\n         - on_element: The element to mouse down.\n           If None, clicks on current mouse position.\n        \"\"\"\n        if on_element:\n            self.move_to_element(on_element)\n        if self._driver.w3c:\n            self.w3c_actions.pointer_action.click_and_hold()\n            self.w3c_actions.key_action.pause()\n        else:\n            self._actions.append(lambda: self._driver.execute(\n                                 Command.MOUSE_DOWN, {}))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform a context - click on an element.", "response": "def context_click(self, on_element=None):\n        \"\"\"\n        Performs a context-click (right click) on an element.\n\n        :Args:\n         - on_element: The element to context-click.\n           If None, clicks on current mouse position.\n        \"\"\"\n        if on_element:\n            self.move_to_element(on_element)\n        if self._driver.w3c:\n            self.w3c_actions.pointer_action.context_click()\n            self.w3c_actions.key_action.pause()\n            self.w3c_actions.key_action.pause()\n        else:\n            self._actions.append(lambda: self._driver.execute(\n                                 Command.CLICK, {'button': 2}))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef double_click(self, on_element=None):\n        if on_element:\n            self.move_to_element(on_element)\n        if self._driver.w3c:\n            self.w3c_actions.pointer_action.double_click()\n            for _ in range(4):\n                self.w3c_actions.key_action.pause()\n        else:\n            self._actions.append(lambda: self._driver.execute(\n                                 Command.DOUBLE_CLICK, {}))\n        return self", "response": "Double - clicks an element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmoving the mouse button on the source element and releases the mouse button on the target element.", "response": "def drag_and_drop(self, source, target):\n        \"\"\"\n        Holds down the left mouse button on the source element,\n           then moves to the target element and releases the mouse button.\n\n        :Args:\n         - source: The element to mouse down.\n         - target: The element to mouse up.\n        \"\"\"\n        self.click_and_hold(source)\n        self.release(target)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef drag_and_drop_by_offset(self, source, xoffset, yoffset):\n        self.click_and_hold(source)\n        self.move_by_offset(xoffset, yoffset)\n        self.release()\n        return self", "response": "Moves the element to the target offset and releases the mouse button."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a key down to the specified element.", "response": "def key_down(self, value, element=None):\n        \"\"\"\n        Sends a key press only, without releasing it.\n           Should only be used with modifier keys (Control, Alt and Shift).\n\n        :Args:\n         - value: The modifier key to send. Values are defined in `Keys` class.\n         - element: The element to send keys.\n           If None, sends a key to current focused element.\n\n        Example, pressing ctrl+c::\n\n            ActionChains(driver).key_down(Keys.CONTROL).send_keys('c').key_up(Keys.CONTROL).perform()\n\n        \"\"\"\n        if element:\n            self.click(element)\n        if self._driver.w3c:\n            self.w3c_actions.key_action.key_down(value)\n            self.w3c_actions.pointer_action.pause()\n        else:\n            self._actions.append(lambda: self._driver.execute(\n                Command.SEND_KEYS_TO_ACTIVE_ELEMENT,\n                {\"value\": keys_to_typing(value)}))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef move_by_offset(self, xoffset, yoffset):\n        if self._driver.w3c:\n            self.w3c_actions.pointer_action.move_by(xoffset, yoffset)\n            self.w3c_actions.key_action.pause()\n        else:\n            self._actions.append(lambda: self._driver.execute(\n                Command.MOVE_TO, {\n                    'xoffset': int(xoffset),\n                    'yoffset': int(yoffset)}))\n        return self", "response": "Moves the mouse to an offset from current mouse position."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmoving the mouse to the middle of an element.", "response": "def move_to_element(self, to_element):\n        \"\"\"\n        Moving the mouse to the middle of an element.\n\n        :Args:\n         - to_element: The WebElement to move to.\n        \"\"\"\n        if self._driver.w3c:\n            self.w3c_actions.pointer_action.move_to(to_element)\n            self.w3c_actions.key_action.pause()\n        else:\n            self._actions.append(lambda: self._driver.execute(\n                                 Command.MOVE_TO, {'element': to_element.id}))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmove the mouse to the specified element.", "response": "def move_to_element_with_offset(self, to_element, xoffset, yoffset):\n        \"\"\"\n        Move the mouse by an offset of the specified element.\n           Offsets are relative to the top-left corner of the element.\n\n        :Args:\n         - to_element: The WebElement to move to.\n         - xoffset: X offset to move to.\n         - yoffset: Y offset to move to.\n        \"\"\"\n        if self._driver.w3c:\n            self.w3c_actions.pointer_action.move_to(to_element, xoffset, yoffset)\n            self.w3c_actions.key_action.pause()\n        else:\n            self._actions.append(\n                lambda: self._driver.execute(Command.MOVE_TO, {\n                    'element': to_element.id,\n                    'xoffset': int(xoffset),\n                    'yoffset': int(yoffset)}))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npauses all inputs for the specified duration in seconds", "response": "def pause(self, seconds):\n        \"\"\" Pause all inputs for the specified duration in seconds \"\"\"\n        if self._driver.w3c:\n            self.w3c_actions.pointer_action.pause(seconds)\n            self.w3c_actions.key_action.pause(seconds)\n        else:\n            self._actions.append(lambda: time.sleep(seconds))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmove a held mouse button on an element.", "response": "def release(self, on_element=None):\n        \"\"\"\n        Releasing a held mouse button on an element.\n\n        :Args:\n         - on_element: The element to mouse up.\n           If None, releases on current mouse position.\n        \"\"\"\n        if on_element:\n            self.move_to_element(on_element)\n        if self._driver.w3c:\n            self.w3c_actions.pointer_action.release()\n            self.w3c_actions.key_action.pause()\n        else:\n            self._actions.append(lambda: self._driver.execute(Command.MOUSE_UP, {}))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_keys(self, *keys_to_send):\n        typing = keys_to_typing(keys_to_send)\n        if self._driver.w3c:\n            for key in typing:\n                self.key_down(key)\n                self.key_up(key)\n        else:\n            self._actions.append(lambda: self._driver.execute(\n                Command.SEND_KEYS_TO_ACTIVE_ELEMENT, {'value': typing}))\n        return self", "response": "Sends the specified keys to the currently focused element."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_keys_to_element(self, element, *keys_to_send):\n        self.click(element)\n        self.send_keys(*keys_to_send)\n        return self", "response": "Clicks the element and sends the specified keys to the specified elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the Browser Attach Timeout value", "response": "def browser_attach_timeout(self, value):\n        \"\"\"\n        Sets the options Browser Attach Timeout\n\n        :Args:\n         - value: Timeout in milliseconds\n\n        \"\"\"\n        if not isinstance(value, int):\n            raise ValueError('Browser Attach Timeout must be an integer.')\n        self._options[self.BROWSER_ATTACH_TIMEOUT] = value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef element_scroll_behavior(self, value):\n        if value not in [ElementScrollBehavior.TOP, ElementScrollBehavior.BOTTOM]:\n            raise ValueError('Element Scroll Behavior out of range.')\n        self._options[self.ELEMENT_SCROLL_BEHAVIOR] = value", "response": "Sets the options Element Scroll Behavior"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef file_upload_dialog_timeout(self, value):\n        if not isinstance(value, int):\n            raise ValueError('File Upload Dialog Timeout must be an integer.')\n        self._options[self.FILE_UPLOAD_DIALOG_TIMEOUT] = value", "response": "Sets the options File Upload Dialog Timeout value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_capabilities(self):\n        caps = self._caps\n\n        opts = self._options.copy()\n        if len(self._arguments) > 0:\n            opts[self.SWITCHES] = ' '.join(self._arguments)\n\n        if len(self._additional) > 0:\n            opts.update(self._additional)\n\n        if len(opts) > 0:\n            caps[Options.KEY] = opts\n        return caps", "response": "Marshals the IE options to the correct object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extensions(self):\n        encoded_extensions = []\n        for ext in self._extension_files:\n            file_ = open(ext, 'rb')\n            # Should not use base64.encodestring() which inserts newlines every\n            # 76 characters (per RFC 1521).  Chromedriver has to remove those\n            # unnecessary newlines before decoding, causing performance hit.\n            encoded_extensions.append(base64.b64encode(file_.read()).decode('UTF-8'))\n\n            file_.close()\n        return encoded_extensions + self._extensions", "response": "Returns a list of encoded extensions that will be loaded into chrome\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_extension(self, extension):\n        if extension:\n            extension_to_add = os.path.abspath(os.path.expanduser(extension))\n            if os.path.exists(extension_to_add):\n                self._extension_files.append(extension_to_add)\n            else:\n                raise IOError(\"Path to the extension doesn't exist\")\n        else:\n            raise ValueError(\"argument can not be null\")", "response": "Adds the path to the extension to the list that will be used to extract it\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the headless argument", "response": "def headless(self, value):\n        \"\"\"\n        Sets the headless argument\n\n        :Args:\n          value: boolean value indicating to set the headless option\n        \"\"\"\n        args = {'--headless'}\n        if value is True:\n            self._arguments.extend(args)\n        else:\n            self._arguments = list(set(self._arguments) - args)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a dictionary with all the options that have been set in the chrome environment.", "response": "def to_capabilities(self):\n        \"\"\"\n        Creates a capabilities with all the options that have been set\n\n        :Returns: A dictionary with everything\n        \"\"\"\n        caps = self._caps\n        chrome_options = self.experimental_options.copy()\n        chrome_options[\"extensions\"] = self.extensions\n        if self.binary_location:\n            chrome_options[\"binary\"] = self.binary_location\n        chrome_options[\"args\"] = self.arguments\n        if self.debugger_address:\n            chrome_options[\"debuggerAddress\"] = self.debugger_address\n\n        caps[self.KEY] = chrome_options\n\n        return caps"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlooks up an element. Logs and re - raises WebDriverException.", "response": "def _find_element(driver, by):\n    \"\"\"Looks up an element. Logs and re-raises ``WebDriverException``\n    if thrown.\"\"\"\n    try:\n        return driver.find_element(*by)\n    except NoSuchElementException as e:\n        raise e\n    except WebDriverException as e:\n        raise e"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef text(self):\n        if self.driver.w3c:\n            return self.driver.execute(Command.W3C_GET_ALERT_TEXT)[\"value\"]\n        else:\n            return self.driver.execute(Command.GET_ALERT_TEXT)[\"value\"]", "response": "Gets the text of the Alert."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dismiss(self):\n        if self.driver.w3c:\n            self.driver.execute(Command.W3C_DISMISS_ALERT)\n        else:\n            self.driver.execute(Command.DISMISS_ALERT)", "response": "Dismisses the alert available."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef accept(self):\n        if self.driver.w3c:\n            self.driver.execute(Command.W3C_ACCEPT_ALERT)\n        else:\n            self.driver.execute(Command.ACCEPT_ALERT)", "response": "Accept the alert available."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_keys(self, keysToSend):\n        if self.driver.w3c:\n            self.driver.execute(Command.W3C_SET_ALERT_VALUE, {'value': keys_to_typing(keysToSend),\n                                                              'text': keysToSend})\n        else:\n            self.driver.execute(Command.SET_ALERT_VALUE, {'text': keysToSend})", "response": "Send Keys to the Alert."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the port that WebDriver will be running on", "response": "def port(self, port):\n        \"\"\"\n        Sets the port that WebDriver will be running on\n        \"\"\"\n        if not isinstance(port, int):\n            raise WebDriverException(\"Port needs to be an integer\")\n        try:\n            port = int(port)\n            if port < 1 or port > 65535:\n                raise WebDriverException(\"Port number must be in the range 1..65535\")\n        except (ValueError, TypeError):\n            raise WebDriverException(\"Port needs to be an integer\")\n        self._port = port\n        self.set_preference(\"webdriver_firefox_port\", self._port)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting the user prefs dictionary to disk", "response": "def _write_user_prefs(self, user_prefs):\n        \"\"\"\n        writes the current user prefs dictionary to disk\n        \"\"\"\n        with open(self.userPrefs, \"w\") as f:\n            for key, value in user_prefs.items():\n                f.write('user_pref(\"%s\", %s);\\n' % (key, json.dumps(value)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninstalling an extension from a file or directory of addons in the profile.", "response": "def _install_extension(self, addon, unpack=True):\n        \"\"\"\n            Installs addon from a filepath, url\n            or directory of addons in the profile.\n            - path: url, absolute path to .xpi, or directory of addons\n            - unpack: whether to unpack unless specified otherwise in the install.rdf\n        \"\"\"\n        if addon == WEBDRIVER_EXT:\n            addon = os.path.join(os.path.dirname(__file__), WEBDRIVER_EXT)\n\n        tmpdir = None\n        xpifile = None\n        if addon.endswith('.xpi'):\n            tmpdir = tempfile.mkdtemp(suffix='.' + os.path.split(addon)[-1])\n            compressed_file = zipfile.ZipFile(addon, 'r')\n            for name in compressed_file.namelist():\n                if name.endswith('/'):\n                    if not os.path.isdir(os.path.join(tmpdir, name)):\n                        os.makedirs(os.path.join(tmpdir, name))\n                else:\n                    if not os.path.isdir(os.path.dirname(os.path.join(tmpdir, name))):\n                        os.makedirs(os.path.dirname(os.path.join(tmpdir, name)))\n                    data = compressed_file.read(name)\n                    with open(os.path.join(tmpdir, name), 'wb') as f:\n                        f.write(data)\n            xpifile = addon\n            addon = tmpdir\n\n        # determine the addon id\n        addon_details = self._addon_details(addon)\n        addon_id = addon_details.get('id')\n        assert addon_id, 'The addon id could not be found: %s' % addon\n\n        # copy the addon to the profile\n        addon_path = os.path.join(self.extensionsDir, addon_id)\n        if not unpack and not addon_details['unpack'] and xpifile:\n            if not os.path.exists(self.extensionsDir):\n                os.makedirs(self.extensionsDir)\n                os.chmod(self.extensionsDir, 0o755)\n            shutil.copy(xpifile, addon_path + '.xpi')\n        else:\n            if not os.path.exists(addon_path):\n                shutil.copytree(addon, addon_path, symlinks=True)\n\n        # remove the temporary directory, if any\n        if tmpdir:\n            shutil.rmtree(tmpdir)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dictionary of details about the addon.", "response": "def _addon_details(self, addon_path):\n        \"\"\"\n        Returns a dictionary of details about the addon.\n\n        :param addon_path: path to the add-on directory or XPI\n\n        Returns::\n\n            {'id':      u'rainbow@colors.org', # id of the addon\n             'version': u'1.4',                # version of the addon\n             'name':    u'Rainbow',            # name of the addon\n             'unpack':  False }                # whether to unpack the addon\n        \"\"\"\n\n        details = {\n            'id': None,\n            'unpack': False,\n            'name': None,\n            'version': None\n        }\n\n        def get_namespace_id(doc, url):\n            attributes = doc.documentElement.attributes\n            namespace = \"\"\n            for i in range(attributes.length):\n                if attributes.item(i).value == url:\n                    if \":\" in attributes.item(i).name:\n                        # If the namespace is not the default one remove 'xlmns:'\n                        namespace = attributes.item(i).name.split(':')[1] + \":\"\n                        break\n            return namespace\n\n        def get_text(element):\n            \"\"\"Retrieve the text value of a given node\"\"\"\n            rc = []\n            for node in element.childNodes:\n                if node.nodeType == node.TEXT_NODE:\n                    rc.append(node.data)\n            return ''.join(rc).strip()\n\n        def parse_manifest_json(content):\n            \"\"\"Extracts the details from the contents of a WebExtensions `manifest.json` file.\"\"\"\n            manifest = json.loads(content)\n            try:\n                id = manifest['applications']['gecko']['id']\n            except KeyError:\n                id = manifest['name'].replace(\" \", \"\") + \"@\" + manifest['version']\n            return {\n                'id': id,\n                'version': manifest['version'],\n                'name': manifest['version'],\n                'unpack': False,\n            }\n\n        if not os.path.exists(addon_path):\n            raise IOError('Add-on path does not exist: %s' % addon_path)\n\n        try:\n            if zipfile.is_zipfile(addon_path):\n                # Bug 944361 - We cannot use 'with' together with zipFile because\n                # it will cause an exception thrown in Python 2.6.\n                try:\n                    compressed_file = zipfile.ZipFile(addon_path, 'r')\n                    if 'manifest.json' in compressed_file.namelist():\n                        return parse_manifest_json(compressed_file.read('manifest.json'))\n\n                    manifest = compressed_file.read('install.rdf')\n                finally:\n                    compressed_file.close()\n            elif os.path.isdir(addon_path):\n                manifest_json_filename = os.path.join(addon_path, 'manifest.json')\n                if os.path.exists(manifest_json_filename):\n                    with open(manifest_json_filename, 'r') as f:\n                        return parse_manifest_json(f.read())\n\n                with open(os.path.join(addon_path, 'install.rdf'), 'r') as f:\n                    manifest = f.read()\n            else:\n                raise IOError('Add-on path is neither an XPI nor a directory: %s' % addon_path)\n        except (IOError, KeyError) as e:\n            raise AddonFormatError(str(e), sys.exc_info()[2])\n\n        try:\n            doc = minidom.parseString(manifest)\n\n            # Get the namespaces abbreviations\n            em = get_namespace_id(doc, 'http://www.mozilla.org/2004/em-rdf#')\n            rdf = get_namespace_id(doc, 'http://www.w3.org/1999/02/22-rdf-syntax-ns#')\n\n            description = doc.getElementsByTagName(rdf + 'Description').item(0)\n            if description is None:\n                description = doc.getElementsByTagName('Description').item(0)\n            for node in description.childNodes:\n                # Remove the namespace prefix from the tag for comparison\n                entry = node.nodeName.replace(em, \"\")\n                if entry in details.keys():\n                    details.update({entry: get_text(node)})\n            if details.get('id') is None:\n                for i in range(description.attributes.length):\n                    attribute = description.attributes.item(i)\n                    if attribute.name == em + 'id':\n                        details.update({'id': attribute.value})\n        except Exception as e:\n            raise AddonFormatError(str(e), sys.exc_info()[2])\n\n        # turn unpack into a true/false value\n        if isinstance(details['unpack'], str):\n            details['unpack'] = details['unpack'].lower() == 'true'\n\n        # If no ID is set, the add-on is invalid\n        if details.get('id') is None:\n            raise AddonFormatError('Add-on id could not be found.')\n\n        return details"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the given property of the element.", "response": "def get_property(self, name):\n        \"\"\"\n        Gets the given property of the element.\n\n        :Args:\n            - name - Name of the property to retrieve.\n\n        :Usage:\n            ::\n\n                text_length = target_element.get_property(\"text_length\")\n        \"\"\"\n        try:\n            return self._execute(Command.GET_ELEMENT_PROPERTY, {\"name\": name})[\"value\"]\n        except WebDriverException:\n            # if we hit an end point that doesnt understand getElementProperty lets fake it\n            return self.parent.execute_script('return arguments[0][arguments[1]]', self, name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the given attribute or property of the element.", "response": "def get_attribute(self, name):\n        \"\"\"Gets the given attribute or property of the element.\n\n        This method will first try to return the value of a property with the\n        given name. If a property with that name doesn't exist, it returns the\n        value of the attribute with the same name. If there's no attribute with\n        that name, ``None`` is returned.\n\n        Values which are considered truthy, that is equals \"true\" or \"false\",\n        are returned as booleans.  All other non-``None`` values are returned\n        as strings.  For attributes or properties which do not exist, ``None``\n        is returned.\n\n        :Args:\n            - name - Name of the attribute/property to retrieve.\n\n        Example::\n\n            # Check if the \"active\" CSS class is applied to an element.\n            is_active = \"active\" in target_element.get_attribute(\"class\")\n\n        \"\"\"\n\n        attributeValue = ''\n        if self._w3c:\n            attributeValue = self.parent.execute_script(\n                \"return (%s).apply(null, arguments);\" % getAttribute_js,\n                self, name)\n        else:\n            resp = self._execute(Command.GET_ELEMENT_ATTRIBUTE, {'name': name})\n            attributeValue = resp.get('value')\n            if attributeValue is not None:\n                if name != 'value' and attributeValue.lower() in ('true', 'false'):\n                    attributeValue = attributeValue.lower()\n        return attributeValue"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_keys(self, *value):\n        # transfer file to another machine only if remote driver is used\n        # the same behaviour as for java binding\n        if self.parent._is_remote:\n            local_file = self.parent.file_detector.is_local_file(*value)\n            if local_file is not None:\n                value = self._upload(local_file)\n\n        self._execute(Command.SEND_KEYS_TO_ELEMENT,\n                      {'text': \"\".join(keys_to_typing(value)),\n                       'value': keys_to_typing(value)})", "response": "Simulates typing into the element."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_displayed(self):\n        # Only go into this conditional for browsers that don't use the atom themselves\n        if self._w3c:\n            return self.parent.execute_script(\n                \"return (%s).apply(null, arguments);\" % isDisplayed_js,\n                self)\n        else:\n            return self._execute(Command.IS_ELEMENT_DISPLAYED)['value']", "response": "Whether the element is visible to a user."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef location_once_scrolled_into_view(self):\n        if self._w3c:\n            old_loc = self._execute(Command.W3C_EXECUTE_SCRIPT, {\n                'script': \"arguments[0].scrollIntoView(true); return arguments[0].getBoundingClientRect()\",\n                'args': [self]})['value']\n            return {\"x\": round(old_loc['x']),\n                    \"y\": round(old_loc['y'])}\n        else:\n            return self._execute(Command.GET_ELEMENT_LOCATION_ONCE_SCROLLED_INTO_VIEW)['value']", "response": "This method returns the location of the element once scrolled into view."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving a screenshot of the current element to a PNG image file. Returns False if there is any IOError else returns True.", "response": "def screenshot(self, filename):\n        \"\"\"\n        Saves a screenshot of the current element to a PNG image file. Returns\n           False if there is any IOError, else returns True. Use full paths in\n           your filename.\n\n        :Args:\n         - filename: The full path you wish to save your screenshot to. This\n           should end with a `.png` extension.\n\n        :Usage:\n            ::\n\n                element.screenshot('/Screenshots/foo.png')\n        \"\"\"\n        if not filename.lower().endswith('.png'):\n            warnings.warn(\"name used for saved screenshot does not match file \"\n                          \"type. It should end with a `.png` extension\", UserWarning)\n        png = self.screenshot_as_png\n        try:\n            with open(filename, 'wb') as f:\n                f.write(png)\n        except IOError:\n            return False\n        finally:\n            del png\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _execute(self, command, params=None):\n        if not params:\n            params = {}\n        params['id'] = self._id\n        return self._parent.execute(command, params)", "response": "Executes a command against the underlying HTML element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind an element given a By strategy and locator.", "response": "def find_element(self, by=By.ID, value=None):\n        \"\"\"\n        Find an element given a By strategy and locator. Prefer the find_element_by_* methods when\n        possible.\n\n        :Usage:\n            ::\n\n                element = element.find_element(By.ID, 'foo')\n\n        :rtype: WebElement\n        \"\"\"\n        if self._w3c:\n            if by == By.ID:\n                by = By.CSS_SELECTOR\n                value = '[id=\"%s\"]' % value\n            elif by == By.TAG_NAME:\n                by = By.CSS_SELECTOR\n            elif by == By.CLASS_NAME:\n                by = By.CSS_SELECTOR\n                value = \".%s\" % value\n            elif by == By.NAME:\n                by = By.CSS_SELECTOR\n                value = '[name=\"%s\"]' % value\n\n        return self._execute(Command.FIND_CHILD_ELEMENT,\n                             {\"using\": by, \"value\": value})['value']"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds elements given a By strategy and locator.", "response": "def find_elements(self, by=By.ID, value=None):\n        \"\"\"\n        Find elements given a By strategy and locator. Prefer the find_elements_by_* methods when\n        possible.\n\n        :Usage:\n            ::\n\n                element = element.find_elements(By.CLASS_NAME, 'foo')\n\n        :rtype: list of WebElement\n        \"\"\"\n        if self._w3c:\n            if by == By.ID:\n                by = By.CSS_SELECTOR\n                value = '[id=\"%s\"]' % value\n            elif by == By.TAG_NAME:\n                by = By.CSS_SELECTOR\n            elif by == By.CLASS_NAME:\n                by = By.CSS_SELECTOR\n                value = \".%s\" % value\n            elif by == By.NAME:\n                by = By.CSS_SELECTOR\n                value = '[name=\"%s\"]' % value\n\n        return self._execute(Command.FIND_CHILD_ELEMENTS,\n                             {\"using\": by, \"value\": value})['value']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef quit(self):\n        try:\n            RemoteWebDriver.quit(self)\n        except http_client.BadStatusLine:\n            pass\n        finally:\n            self.service.stop()", "response": "Closes the browser and shuts down the WebKitGTKDriver executable\n        that is started when starting the WebKitGTKDriver executable\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start(self):\n        try:\n            cmd = [self.path]\n            cmd.extend(self.command_line_args())\n            self.process = subprocess.Popen(cmd, env=self.env,\n                                            close_fds=platform.system() != 'Windows',\n                                            stdout=self.log_file,\n                                            stderr=self.log_file,\n                                            stdin=PIPE)\n        except TypeError:\n            raise\n        except OSError as err:\n            if err.errno == errno.ENOENT:\n                raise WebDriverException(\n                    \"'%s' executable needs to be in PATH. %s\" % (\n                        os.path.basename(self.path), self.start_error_message)\n                )\n            elif err.errno == errno.EACCES:\n                raise WebDriverException(\n                    \"'%s' executable may have wrong permissions. %s\" % (\n                        os.path.basename(self.path), self.start_error_message)\n                )\n            else:\n                raise\n        except Exception as e:\n            raise WebDriverException(\n                \"The executable %s needs to be available in the path. %s\\n%s\" %\n                (os.path.basename(self.path), self.start_error_message, str(e)))\n        count = 0\n        while True:\n            self.assert_process_still_running()\n            if self.is_connectable():\n                break\n            count += 1\n            time.sleep(1)\n            if count == 30:\n                raise WebDriverException(\"Can not connect to the Service %s\" % self.path)", "response": "Starts the Service.\n\n        :Exceptions:\n         - WebDriverException : Raised either when it can't start the service\n           or when it can't connect to the service"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlaunch the browser for the given profile.", "response": "def launch_browser(self, profile, timeout=30):\n        \"\"\"Launches the browser for the given profile name.\n        It is assumed the profile already exists.\n        \"\"\"\n        self.profile = profile\n\n        self._start_from_profile_path(self.profile.path)\n        self._wait_until_connectable(timeout=timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nkill the browser. This is useful when the browser is stuck.", "response": "def kill(self):\n        \"\"\"Kill the browser.\n\n        This is useful when the browser is stuck.\n        \"\"\"\n        if self.process:\n            self.process.kill()\n            self.process.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _wait_until_connectable(self, timeout=30):\n        count = 0\n        while not utils.is_connectable(self.profile.port):\n            if self.process.poll() is not None:\n                # Browser has exited\n                raise WebDriverException(\n                    \"The browser appears to have exited \"\n                    \"before we could connect. If you specified a log_file in \"\n                    \"the FirefoxBinary constructor, check it for details.\")\n            if count >= timeout:\n                self.kill()\n                raise WebDriverException(\n                    \"Can't load the profile. Possible firefox version mismatch. \"\n                    \"You must use GeckoDriver instead for Firefox 48+. Profile \"\n                    \"Dir: %s If you specified a log_file in the \"\n                    \"FirefoxBinary constructor, check it for details.\"\n                    % (self.profile.path))\n            count += 1\n            time.sleep(1)\n        return True", "response": "Blocks until the extension is connectable in the Firefox."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the command to start firefox.", "response": "def _get_firefox_start_cmd(self):\n        \"\"\"Return the command to start firefox.\"\"\"\n        start_cmd = \"\"\n        if platform.system() == \"Darwin\":\n            start_cmd = \"/Applications/Firefox.app/Contents/MacOS/firefox-bin\"\n            # fallback to homebrew installation for mac users\n            if not os.path.exists(start_cmd):\n                start_cmd = os.path.expanduser(\"~\") + start_cmd\n        elif platform.system() == \"Windows\":\n            start_cmd = (self._find_exe_in_registry() or self._default_windows_location())\n        elif platform.system() == 'Java' and os._name == 'nt':\n            start_cmd = self._default_windows_location()\n        else:\n            for ffname in [\"firefox\", \"iceweasel\"]:\n                start_cmd = self.which(ffname)\n                if start_cmd is not None:\n                    break\n            else:\n                # couldn't find firefox on the system path\n                raise RuntimeError(\n                    \"Could not find firefox in your system PATH.\" +\n                    \" Please specify the firefox binary location or install firefox\")\n        return start_cmd"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the fully qualified path by searching Path of the given fname", "response": "def which(self, fname):\n        \"\"\"Returns the fully qualified path by searching Path of the given\n        name\"\"\"\n        for pe in os.environ['PATH'].split(os.pathsep):\n            checkname = os.path.join(pe, fname)\n            if os.access(checkname, os.X_OK) and not os.path.isdir(checkname):\n                return checkname\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_remote_connection_headers(cls, parsed_url, keep_alive=False):\n\n        system = platform.system().lower()\n        if system == \"darwin\":\n            system = \"mac\"\n\n        headers = {\n            'Accept': 'application/json',\n            'Content-Type': 'application/json;charset=UTF-8',\n            'User-Agent': 'selenium/{} (python {})'.format(__version__, system)\n        }\n\n        if parsed_url.username:\n            base64string = base64.b64encode('{0.username}:{0.password}'.format(parsed_url).encode())\n            headers.update({\n                'Authorization': 'Basic {}'.format(base64string.decode())\n            })\n\n        if keep_alive:\n            headers.update({\n                'Connection': 'keep-alive'\n            })\n\n        return headers", "response": "Returns the headers for a remote connection."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute(self, command, params):\n        command_info = self._commands[command]\n        assert command_info is not None, 'Unrecognised command %s' % command\n        path = string.Template(command_info[1]).substitute(params)\n        if hasattr(self, 'w3c') and self.w3c and isinstance(params, dict) and 'sessionId' in params:\n            del params['sessionId']\n        data = utils.dump_json(params)\n        url = '%s%s' % (self._url, path)\n        return self._request(command_info[0], url, body=data)", "response": "Send a command to the remote server."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _request(self, method, url, body=None):\n        LOGGER.debug('%s %s %s' % (method, url, body))\n\n        parsed_url = parse.urlparse(url)\n        headers = self.get_remote_connection_headers(parsed_url, self.keep_alive)\n        resp = None\n        if body and method != 'POST' and method != 'PUT':\n            body = None\n\n        if self.keep_alive:\n            resp = self._conn.request(method, url, body=body, headers=headers)\n\n            statuscode = resp.status\n        else:\n            http = urllib3.PoolManager(timeout=self._timeout)\n            resp = http.request(method, url, body=body, headers=headers)\n\n            statuscode = resp.status\n            if not hasattr(resp, 'getheader'):\n                if hasattr(resp.headers, 'getheader'):\n                    resp.getheader = lambda x: resp.headers.getheader(x)\n                elif hasattr(resp.headers, 'get'):\n                    resp.getheader = lambda x: resp.headers.get(x)\n\n        data = resp.data.decode('UTF-8')\n        try:\n            if 300 <= statuscode < 304:\n                return self._request('GET', resp.getheader('location'))\n            if 399 < statuscode <= 500:\n                return {'status': statuscode, 'value': data}\n            content_type = []\n            if resp.getheader('Content-Type') is not None:\n                content_type = resp.getheader('Content-Type').split(';')\n            if not any([x.startswith('image/png') for x in content_type]):\n\n                try:\n                    data = utils.load_json(data.strip())\n                except ValueError:\n                    if 199 < statuscode < 300:\n                        status = ErrorCode.SUCCESS\n                    else:\n                        status = ErrorCode.UNKNOWN_ERROR\n                    return {'status': status, 'value': data.strip()}\n\n                # Some of the drivers incorrectly return a response\n                # with no 'value' field when they should return null.\n                if 'value' not in data:\n                    data['value'] = None\n                return data\n            else:\n                data = {'status': 0, 'value': data}\n                return data\n        finally:\n            LOGGER.debug(\"Finished Request\")\n            resp.close()", "response": "Send an HTTP request to the remote server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of all selected options belonging to this select tag", "response": "def all_selected_options(self):\n        \"\"\"Returns a list of all selected options belonging to this select tag\"\"\"\n        ret = []\n        for opt in self.options:\n            if opt.is_selected():\n                ret.append(opt)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nselecting all options that have a value matching the argument. That is when given bar the option is selected and the option is selected.", "response": "def select_by_value(self, value):\n        \"\"\"Select all options that have a value matching the argument. That is, when given \"foo\" this\n           would select an option like:\n\n           <option value=\"foo\">Bar</option>\n\n           :Args:\n            - value - The value to match against\n\n           throws NoSuchElementException If there is no option with specified value in SELECT\n           \"\"\"\n        css = \"option[value =%s]\" % self._escapeString(value)\n        opts = self._el.find_elements(By.CSS_SELECTOR, css)\n        matched = False\n        for opt in opts:\n            self._setSelected(opt)\n            if not self.is_multiple:\n                return\n            matched = True\n        if not matched:\n            raise NoSuchElementException(\"Cannot locate option with value: %s\" % value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef select_by_index(self, index):\n        match = str(index)\n        for opt in self.options:\n            if opt.get_attribute(\"index\") == match:\n                self._setSelected(opt)\n                return\n        raise NoSuchElementException(\"Could not locate element with index %d\" % index)", "response": "Select the option at the given index."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deselect_all(self):\n        if not self.is_multiple:\n            raise NotImplementedError(\"You may only deselect all options of a multi-select\")\n        for opt in self.options:\n            self._unsetSelected(opt)", "response": "Clear all selected entries."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a dictionary with all the options that have been set and returns a dictionary with all the options that have been set and returns a dictionary with everything else", "response": "def to_capabilities(self):\n        \"\"\"\n        Creates a capabilities with all the options that have been set and\n        returns a dictionary with everything\n        \"\"\"\n        capabilities = ChromeOptions.to_capabilities(self)\n        capabilities.update(self._caps)\n        opera_options = capabilities[self.KEY]\n\n        if self.android_package_name:\n            opera_options[\"androidPackage\"] = self.android_package_name\n        if self.android_device_socket:\n            opera_options[\"androidDeviceSocket\"] = self.android_device_socket\n        if self.android_command_line_file:\n            opera_options[\"androidCommandLineFile\"] = \\\n                self.android_command_line_file\n        return capabilities"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupload a file to Google Cloud Storage.", "response": "def _upload(auth_http, project_id, bucket_name, file_path, object_name, acl):\n    \"\"\"Uploads a file to Google Cloud Storage.\n\n    Args:\n        auth_http: An authorized httplib2.Http instance.\n        project_id: The project to upload to.\n        bucket_name: The bucket to upload to.\n        file_path: Path to the file to upload.\n        object_name: The name within the bucket to upload to.\n        acl: The ACL to assign to the uploaded file.\n    \"\"\"\n    with open(file_path, 'rb') as f:\n        data = f.read()\n    content_type, content_encoding = mimetypes.guess_type(file_path)\n\n    headers = {\n        'x-goog-project-id': project_id,\n        'x-goog-api-version': API_VERSION,\n        'x-goog-acl': acl,\n        'Content-Length': '%d' % len(data)\n    }\n    if content_type: headers['Content-Type'] = content_type\n    if content_type: headers['Content-Encoding'] = content_encoding\n\n    try:\n        response, content = auth_http.request(\n            'http://%s.storage.googleapis.com/%s' % (bucket_name, object_name),\n            method='PUT',\n            headers=headers,\n            body=data)\n    except httplib2.ServerNotFoundError, se:\n        raise Error(404, 'Server not found.')\n\n    if response.status >= 300:\n        raise Error(response.status, response.reason)\n\n    return content"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns the OAuth 2. 0 installed application flow.", "response": "def _authenticate(secrets_file):\n    \"\"\"Runs the OAuth 2.0 installed application flow.\n\n    Returns:\n      An authorized httplib2.Http instance.\n    \"\"\"\n    flow = oauthclient.flow_from_clientsecrets(\n        secrets_file,\n        scope=OAUTH_SCOPE,\n        message=('Failed to initialized OAuth 2.0 flow with secrets '\n                 'file: %s' % secrets_file))\n    storage = oauthfile.Storage(OAUTH_CREDENTIALS_FILE)\n    credentials = storage.get()\n    if credentials is None or credentials.invalid:\n        credentials = oauthtools.run_flow(flow, storage, oauthtools.argparser.parse_args(args=[]))\n    http = httplib2.Http()\n    return credentials.authorize(http)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef auto_detect(self, value):\n        if isinstance(value, bool):\n            if self.autodetect is not value:\n                self._verify_proxy_type_compatibility(ProxyType.AUTODETECT)\n                self.proxyType = ProxyType.AUTODETECT\n                self.autodetect = value\n        else:\n            raise ValueError(\"Autodetect proxy value needs to be a boolean\")", "response": "Sets the autodetect setting."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the ftp proxy setting.", "response": "def ftp_proxy(self, value):\n        \"\"\"\n        Sets ftp proxy setting.\n\n        :Args:\n         - value: The ftp proxy value.\n        \"\"\"\n        self._verify_proxy_type_compatibility(ProxyType.MANUAL)\n        self.proxyType = ProxyType.MANUAL\n        self.ftpProxy = value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the http proxy setting.", "response": "def http_proxy(self, value):\n        \"\"\"\n        Sets http proxy setting.\n\n        :Args:\n         - value: The http proxy value.\n        \"\"\"\n        self._verify_proxy_type_compatibility(ProxyType.MANUAL)\n        self.proxyType = ProxyType.MANUAL\n        self.httpProxy = value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the noproxy setting.", "response": "def no_proxy(self, value):\n        \"\"\"\n        Sets noproxy setting.\n\n        :Args:\n         - value: The noproxy value.\n        \"\"\"\n        self._verify_proxy_type_compatibility(ProxyType.MANUAL)\n        self.proxyType = ProxyType.MANUAL\n        self.noProxy = value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef proxy_autoconfig_url(self, value):\n        self._verify_proxy_type_compatibility(ProxyType.PAC)\n        self.proxyType = ProxyType.PAC\n        self.proxyAutoconfigUrl = value", "response": "Sets the proxy autoconfig url setting."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ssl_proxy(self, value):\n        self._verify_proxy_type_compatibility(ProxyType.MANUAL)\n        self.proxyType = ProxyType.MANUAL\n        self.sslProxy = value", "response": "Sets the ssl proxy setting."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting socks proxy setting.", "response": "def socks_proxy(self, value):\n        \"\"\"\n        Sets socks proxy setting.\n\n        :Args:\n         - value: The socks proxy value.\n        \"\"\"\n        self._verify_proxy_type_compatibility(ProxyType.MANUAL)\n        self.proxyType = ProxyType.MANUAL\n        self.socksProxy = value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset socks proxy username setting.", "response": "def socks_username(self, value):\n        \"\"\"\n        Sets socks proxy username setting.\n\n        :Args:\n         - value: The socks proxy username value.\n        \"\"\"\n        self._verify_proxy_type_compatibility(ProxyType.MANUAL)\n        self.proxyType = ProxyType.MANUAL\n        self.socksUsername = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef socks_password(self, value):\n        self._verify_proxy_type_compatibility(ProxyType.MANUAL)\n        self.proxyType = ProxyType.MANUAL\n        self.socksPassword = value", "response": "Sets socks proxy password setting."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd proxy information as capability in specified capabilities.", "response": "def add_to_capabilities(self, capabilities):\n        \"\"\"\n        Adds proxy information as capability in specified capabilities.\n\n        :Args:\n         - capabilities: The capabilities to which proxy will be added.\n        \"\"\"\n        proxy_caps = {}\n        proxy_caps['proxyType'] = self.proxyType['string']\n        if self.autodetect:\n            proxy_caps['autodetect'] = self.autodetect\n        if self.ftpProxy:\n            proxy_caps['ftpProxy'] = self.ftpProxy\n        if self.httpProxy:\n            proxy_caps['httpProxy'] = self.httpProxy\n        if self.proxyAutoconfigUrl:\n            proxy_caps['proxyAutoconfigUrl'] = self.proxyAutoconfigUrl\n        if self.sslProxy:\n            proxy_caps['sslProxy'] = self.sslProxy\n        if self.noProxy:\n            proxy_caps['noProxy'] = self.noProxy\n        if self.socksProxy:\n            proxy_caps['socksProxy'] = self.socksProxy\n        if self.socksUsername:\n            proxy_caps['socksUsername'] = self.socksUsername\n        if self.socksPassword:\n            proxy_caps['socksPassword'] = self.socksPassword\n        capabilities['proxy'] = proxy_caps"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_connectable_ip(host, port=None):\n    try:\n        addrinfos = socket.getaddrinfo(host, None)\n    except socket.gaierror:\n        return None\n\n    ip = None\n    for family, _, _, _, sockaddr in addrinfos:\n        connectable = True\n        if port:\n            connectable = is_connectable(port, sockaddr[0])\n\n        if connectable and family == socket.AF_INET:\n            return sockaddr[0]\n        if connectable and not ip and family == socket.AF_INET6:\n            ip = sockaddr[0]\n    return ip", "response": "Resolves a hostname to an IP and returns the IP address."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef join_host_port(host, port):\n    if ':' in host and not host.startswith('['):\n        return '[%s]:%d' % (host, port)\n    return '%s:%d' % (host, port)", "response": "Joins a hostname and port together."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if a server is connected to the specified port.", "response": "def is_connectable(port, host=\"localhost\"):\n    \"\"\"\n    Tries to connect to the server at port to see if it is running.\n\n    :Args:\n     - port - The port to connect.\n    \"\"\"\n    socket_ = None\n    try:\n        socket_ = socket.create_connection((host, port), 1)\n        result = True\n    except _is_connectable_exceptions:\n        result = False\n    finally:\n        if socket_:\n            socket_.close()\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_url_connectable(port):\n    try:\n        from urllib import request as url_request\n    except ImportError:\n        import urllib2 as url_request\n\n    try:\n        res = url_request.urlopen(\"http://127.0.0.1:%s/status\" % port)\n        if res.getcode() == 200:\n            return True\n        else:\n            return False\n    except Exception:\n        return False", "response": "Checks if the URL is connectable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess the values that will be typed in the element.", "response": "def keys_to_typing(value):\n    \"\"\"Processes the values that will be typed in the element.\"\"\"\n    typing = []\n    for val in value:\n        if isinstance(val, Keys):\n            typing.append(val)\n        elif isinstance(val, int):\n            val = str(val)\n            for i in range(len(val)):\n                typing.append(val[i])\n        else:\n            for i in range(len(val)):\n                typing.append(val[i])\n    return typing"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves the current state as a displaCy visualization.", "response": "def to_html(doc, output=\"/tmp\", style=\"dep\"):\n    \"\"\"Doc method extension for saving the current state as a displaCy\n    visualization.\n    \"\"\"\n    # generate filename from first six non-punct tokens\n    file_name = \"-\".join([w.text for w in doc[:6] if not w.is_punct]) + \".html\"\n    html = displacy.render(doc, style=style, page=True)  # render markup\n    if output is not None:\n        output_path = Path(output)\n        if not output_path.exists():\n            output_path.mkdir()\n        output_file = Path(output) / file_name\n        output_file.open(\"w\", encoding=\"utf-8\").write(html)  # save to file\n        print(\"Saved HTML to {}\".format(output_file))\n    else:\n        print(html)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef overlap_tokens(doc, other_doc):\n    overlap = []\n    other_tokens = [token.text for token in other_doc]\n    for token in doc:\n        if token.text in other_tokens:\n            overlap.append(token)\n    return overlap", "response": "Get the tokens from the original Doc that are also in the comparison Doc."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting IOB files into JSON format for use with train cli.", "response": "def iob2json(input_data, n_sents=10, *args, **kwargs):\n    \"\"\"\n    Convert IOB files into JSON format for use with train cli.\n    \"\"\"\n    docs = []\n    for group in minibatch(docs, n_sents):\n        group = list(group)\n        first = group.pop(0)\n        to_extend = first[\"paragraphs\"][0][\"sentences\"]\n        for sent in group[1:]:\n            to_extend.extend(sent[\"paragraphs\"][0][\"sentences\"])\n        docs.append(first)\n    return docs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render(\n    docs, style=\"dep\", page=False, minify=False, jupyter=None, options={}, manual=False\n):\n    \"\"\"Render displaCy visualisation.\n\n    docs (list or Doc): Document(s) to visualise.\n    style (unicode): Visualisation style, 'dep' or 'ent'.\n    page (bool): Render markup as full HTML page.\n    minify (bool): Minify HTML markup.\n    jupyter (bool): Override Jupyter auto-detection.\n    options (dict): Visualiser-specific options, e.g. colors.\n    manual (bool): Don't parse `Doc` and instead expect a dict/list of dicts.\n    RETURNS (unicode): Rendered HTML markup.\n\n    DOCS: https://spacy.io/api/top-level#displacy.render\n    USAGE: https://spacy.io/usage/visualizers\n    \"\"\"\n    factories = {\n        \"dep\": (DependencyRenderer, parse_deps),\n        \"ent\": (EntityRenderer, parse_ents),\n    }\n    if style not in factories:\n        raise ValueError(Errors.E087.format(style=style))\n    if isinstance(docs, (Doc, Span, dict)):\n        docs = [docs]\n    docs = [obj if not isinstance(obj, Span) else obj.as_doc() for obj in docs]\n    if not all(isinstance(obj, (Doc, Span, dict)) for obj in docs):\n        raise ValueError(Errors.E096)\n    renderer, converter = factories[style]\n    renderer = renderer(options=options)\n    parsed = [converter(doc, options) for doc in docs] if not manual else docs\n    _html[\"parsed\"] = renderer.render(parsed, page=page, minify=minify).strip()\n    html = _html[\"parsed\"]\n    if RENDER_WRAPPER is not None:\n        html = RENDER_WRAPPER(html)\n    if jupyter or (jupyter is None and is_in_jupyter()):\n        # return HTML rendered by IPython display()\n        from IPython.core.display import display, HTML\n\n        return display(HTML(html))\n    return html", "response": "Render displaCy visualisation.\n\n    docs (list or Doc): Document(s) to visualise.\n    style (unicode): Visualisation style, 'dep' or 'ent'.\n    page (bool): Render markup as full HTML page.\n    minify (bool): Minify HTML markup.\n    jupyter (bool): Override Jupyter auto-detection.\n    options (dict): Visualiser-specific options, e.g. colors.\n    manual (bool): Don't parse `Doc` and instead expect a dict/list of dicts.\n    RETURNS (unicode): Rendered HTML markup.\n\n    DOCS: https://spacy.io/api/top-level#displacy.render\n    USAGE: https://spacy.io/usage/visualizers"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef serve(\n    docs,\n    style=\"dep\",\n    page=True,\n    minify=False,\n    options={},\n    manual=False,\n    port=5000,\n    host=\"0.0.0.0\",\n):\n    \"\"\"Serve displaCy visualisation.\n\n    docs (list or Doc): Document(s) to visualise.\n    style (unicode): Visualisation style, 'dep' or 'ent'.\n    page (bool): Render markup as full HTML page.\n    minify (bool): Minify HTML markup.\n    options (dict): Visualiser-specific options, e.g. colors.\n    manual (bool): Don't parse `Doc` and instead expect a dict/list of dicts.\n    port (int): Port to serve visualisation.\n    host (unicode): Host to serve visualisation.\n\n    DOCS: https://spacy.io/api/top-level#displacy.serve\n    USAGE: https://spacy.io/usage/visualizers\n    \"\"\"\n    from wsgiref import simple_server\n\n    if is_in_jupyter():\n        user_warning(Warnings.W011)\n\n    render(docs, style=style, page=page, minify=minify, options=options, manual=manual)\n    httpd = simple_server.make_server(host, port, app)\n    print(\"\\nUsing the '{}' visualizer\".format(style))\n    print(\"Serving on http://{}:{} ...\\n\".format(host, port))\n    try:\n        httpd.serve_forever()\n    except KeyboardInterrupt:\n        print(\"Shutting down server on port {}.\".format(port))\n    finally:\n        httpd.server_close()", "response": "Serve a list of displaCy docstrings."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate dependency parse in dict format.", "response": "def parse_deps(orig_doc, options={}):\n    \"\"\"Generate dependency parse in {'words': [], 'arcs': []} format.\n\n    doc (Doc): Document do parse.\n    RETURNS (dict): Generated dependency parse keyed by words and arcs.\n    \"\"\"\n    doc = Doc(orig_doc.vocab).from_bytes(orig_doc.to_bytes())\n    if not doc.is_parsed:\n        user_warning(Warnings.W005)\n    if options.get(\"collapse_phrases\", False):\n        with doc.retokenize() as retokenizer:\n            for np in list(doc.noun_chunks):\n                attrs = {\n                    \"tag\": np.root.tag_,\n                    \"lemma\": np.root.lemma_,\n                    \"ent_type\": np.root.ent_type_,\n                }\n                retokenizer.merge(np, attrs=attrs)\n    if options.get(\"collapse_punct\", True):\n        spans = []\n        for word in doc[:-1]:\n            if word.is_punct or not word.nbor(1).is_punct:\n                continue\n            start = word.i\n            end = word.i + 1\n            while end < len(doc) and doc[end].is_punct:\n                end += 1\n            span = doc[start:end]\n            spans.append((span, word.tag_, word.lemma_, word.ent_type_))\n        with doc.retokenize() as retokenizer:\n            for span, tag, lemma, ent_type in spans:\n                attrs = {\"tag\": tag, \"lemma\": lemma, \"ent_type\": ent_type}\n                retokenizer.merge(span, attrs=attrs)\n    if options.get(\"fine_grained\"):\n        words = [{\"text\": w.text, \"tag\": w.tag_} for w in doc]\n    else:\n        words = [{\"text\": w.text, \"tag\": w.pos_} for w in doc]\n    arcs = []\n    for word in doc:\n        if word.i < word.head.i:\n            arcs.append(\n                {\"start\": word.i, \"end\": word.head.i, \"label\": word.dep_, \"dir\": \"left\"}\n            )\n        elif word.i > word.head.i:\n            arcs.append(\n                {\n                    \"start\": word.head.i,\n                    \"end\": word.i,\n                    \"label\": word.dep_,\n                    \"dir\": \"right\",\n                }\n            )\n    return {\"words\": words, \"arcs\": arcs, \"settings\": get_doc_settings(orig_doc)}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates named entities in a document.", "response": "def parse_ents(doc, options={}):\n    \"\"\"Generate named entities in [{start: i, end: i, label: 'label'}] format.\n\n    doc (Doc): Document do parse.\n    RETURNS (dict): Generated entities keyed by text (original text) and ents.\n    \"\"\"\n    ents = [\n        {\"start\": ent.start_char, \"end\": ent.end_char, \"label\": ent.label_}\n        for ent in doc.ents\n    ]\n    if not ents:\n        user_warning(Warnings.W006)\n    title = doc.user_data.get(\"title\", None) if hasattr(doc, \"user_data\") else None\n    settings = get_doc_settings(doc)\n    return {\"text\": doc.text, \"ents\": ents, \"title\": title, \"settings\": settings}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the function that is called around the generated HTML markup on displacy. render.", "response": "def set_render_wrapper(func):\n    \"\"\"Set an optional wrapper function that is called around the generated\n    HTML markup on displacy.render. This can be used to allow integration into\n    other platforms, similar to Jupyter Notebooks that require functions to be\n    called around the HTML. It can also be used to implement custom callbacks\n    on render, or to embed the visualization in a custom page.\n\n    func (callable): Function to call around markup before rendering it. Needs\n        to take one argument, the HTML markup, and should return the desired\n        output of displacy.render.\n    \"\"\"\n    global RENDER_WRAPPER\n    if not hasattr(func, \"__call__\"):\n        raise ValueError(Errors.E110.format(obj=type(func)))\n    RENDER_WRAPPER = func"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nevaluating a model. To render a sample of parses in a HTML file, set an output directory as the displacy_path argument.", "response": "def evaluate(\n    model,\n    data_path,\n    gpu_id=-1,\n    gold_preproc=False,\n    displacy_path=None,\n    displacy_limit=25,\n    return_scores=False,\n):\n    \"\"\"\n    Evaluate a model. To render a sample of parses in a HTML file, set an\n    output directory as the displacy_path argument.\n    \"\"\"\n    msg = Printer()\n    util.fix_random_seed()\n    if gpu_id >= 0:\n        util.use_gpu(gpu_id)\n    util.set_env_log(False)\n    data_path = util.ensure_path(data_path)\n    displacy_path = util.ensure_path(displacy_path)\n    if not data_path.exists():\n        msg.fail(\"Evaluation data not found\", data_path, exits=1)\n    if displacy_path and not displacy_path.exists():\n        msg.fail(\"Visualization output directory not found\", displacy_path, exits=1)\n    corpus = GoldCorpus(data_path, data_path)\n    nlp = util.load_model(model)\n    dev_docs = list(corpus.dev_docs(nlp, gold_preproc=gold_preproc))\n    begin = timer()\n    scorer = nlp.evaluate(dev_docs, verbose=False)\n    end = timer()\n    nwords = sum(len(doc_gold[0]) for doc_gold in dev_docs)\n    results = {\n        \"Time\": \"%.2f s\" % (end - begin),\n        \"Words\": nwords,\n        \"Words/s\": \"%.0f\" % (nwords / (end - begin)),\n        \"TOK\": \"%.2f\" % scorer.token_acc,\n        \"POS\": \"%.2f\" % scorer.tags_acc,\n        \"UAS\": \"%.2f\" % scorer.uas,\n        \"LAS\": \"%.2f\" % scorer.las,\n        \"NER P\": \"%.2f\" % scorer.ents_p,\n        \"NER R\": \"%.2f\" % scorer.ents_r,\n        \"NER F\": \"%.2f\" % scorer.ents_f,\n    }\n    msg.table(results, title=\"Results\")\n\n    if displacy_path:\n        docs, golds = zip(*dev_docs)\n        render_deps = \"parser\" in nlp.meta.get(\"pipeline\", [])\n        render_ents = \"ner\" in nlp.meta.get(\"pipeline\", [])\n        render_parses(\n            docs,\n            displacy_path,\n            model_name=model,\n            limit=displacy_limit,\n            deps=render_deps,\n            ents=render_ents,\n        )\n        msg.good(\"Generated {} parses as HTML\".format(displacy_limit), displacy_path)\n    if return_scores:\n        return scorer.scores"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a symlink for models within the spaCy data directory.", "response": "def link(origin, link_name, force=False, model_path=None):\n    \"\"\"\n    Create a symlink for models within the spacy/data directory. Accepts\n    either the name of a pip package, or the local path to the model data\n    directory. Linking models allows loading them via spacy.load(link_name).\n    \"\"\"\n    msg = Printer()\n    if util.is_package(origin):\n        model_path = util.get_package_path(origin)\n    else:\n        model_path = Path(origin) if model_path is None else Path(model_path)\n    if not model_path.exists():\n        msg.fail(\n            \"Can't locate model data\",\n            \"The data should be located in {}\".format(path2str(model_path)),\n            exits=1,\n        )\n    data_path = util.get_data_path()\n    if not data_path or not data_path.exists():\n        spacy_loc = Path(__file__).parent.parent\n        msg.fail(\n            \"Can't find the spaCy data path to create model symlink\",\n            \"Make sure a directory `/data` exists within your spaCy \"\n            \"installation and try again. The data directory should be located \"\n            \"here:\".format(path=spacy_loc),\n            exits=1,\n        )\n    link_path = util.get_data_path() / link_name\n    if link_path.is_symlink() and not force:\n        msg.fail(\n            \"Link '{}' already exists\".format(link_name),\n            \"To overwrite an existing link, use the --force flag\",\n            exits=1,\n        )\n    elif link_path.is_symlink():  # does a symlink exist?\n        # NB: It's important to check for is_symlink here and not for exists,\n        # because invalid/outdated symlinks would return False otherwise.\n        link_path.unlink()\n    elif link_path.exists():  # does it exist otherwise?\n        # NB: Check this last because valid symlinks also \"exist\".\n        msg.fail(\n            \"Can't overwrite symlink '{}'\".format(link_name),\n            \"This can happen if your data directory contains a directory or \"\n            \"file of the same name.\",\n            exits=1,\n        )\n    details = \"%s --> %s\" % (path2str(model_path), path2str(link_path))\n    try:\n        symlink_to(link_path, model_path)\n    except:  # noqa: E722\n        # This is quite dirty, but just making sure other errors are caught.\n        msg.fail(\n            \"Couldn't link model to '{}'\".format(link_name),\n            \"Creating a symlink in spacy/data failed. Make sure you have the \"\n            \"required permissions and try re-running the command as admin, or \"\n            \"use a virtualenv. You can still import the model as a module and \"\n            \"call its load() method, or create the symlink manually.\",\n        )\n        msg.text(details)\n        raise\n    msg.good(\"Linking successful\", details)\n    msg.text(\"You can now load the model via spacy.load('{}')\".format(link_name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate():\n    msg = Printer()\n    with msg.loading(\"Loading compatibility table...\"):\n        r = requests.get(about.__compatibility__)\n        if r.status_code != 200:\n            msg.fail(\n                \"Server error ({})\".format(r.status_code),\n                \"Couldn't fetch compatibility table.\",\n                exits=1,\n            )\n    msg.good(\"Loaded compatibility table\")\n    compat = r.json()[\"spacy\"]\n    version = about.__version__\n    version = version.rsplit(\".dev\", 1)[0]\n    current_compat = compat.get(version)\n    if not current_compat:\n        msg.fail(\n            \"Can't find spaCy v{} in compatibility table\".format(version),\n            about.__compatibility__,\n            exits=1,\n        )\n    all_models = set()\n    for spacy_v, models in dict(compat).items():\n        all_models.update(models.keys())\n        for model, model_vs in models.items():\n            compat[spacy_v][model] = [reformat_version(v) for v in model_vs]\n    model_links = get_model_links(current_compat)\n    model_pkgs = get_model_pkgs(current_compat, all_models)\n    incompat_links = {l for l, d in model_links.items() if not d[\"compat\"]}\n    incompat_models = {d[\"name\"] for _, d in model_pkgs.items() if not d[\"compat\"]}\n    incompat_models.update(\n        [d[\"name\"] for _, d in model_links.items() if not d[\"compat\"]]\n    )\n    na_models = [m for m in incompat_models if m not in current_compat]\n    update_models = [m for m in incompat_models if m in current_compat]\n    spacy_dir = Path(__file__).parent.parent\n\n    msg.divider(\"Installed models (spaCy v{})\".format(about.__version__))\n    msg.info(\"spaCy installation: {}\".format(path2str(spacy_dir)))\n\n    if model_links or model_pkgs:\n        header = (\"TYPE\", \"NAME\", \"MODEL\", \"VERSION\", \"\")\n        rows = []\n        for name, data in model_pkgs.items():\n            rows.append(get_model_row(current_compat, name, data, msg))\n        for name, data in model_links.items():\n            rows.append(get_model_row(current_compat, name, data, msg, \"link\"))\n        msg.table(rows, header=header)\n    else:\n        msg.text(\"No models found in your current environment.\", exits=0)\n    if update_models:\n        msg.divider(\"Install updates\")\n        msg.text(\"Use the following commands to update the model packages:\")\n        cmd = \"python -m spacy download {}\"\n        print(\"\\n\".join([cmd.format(pkg) for pkg in update_models]) + \"\\n\")\n    if na_models:\n        msg.text(\n            \"The following models are not available for spaCy \"\n            \"v{}: {}\".format(about.__version__, \", \".join(na_models))\n        )\n    if incompat_links:\n        msg.text(\n            \"You may also want to overwrite the incompatible links using the \"\n            \"`python -m spacy link` command with `--force`, or remove them \"\n            \"from the data directory. \"\n            \"Data path: {path}\".format(path=path2str(get_data_path()))\n        )\n    if incompat_models or incompat_links:\n        sys.exit(1)", "response": "Validate that the currently installed version of spaCy is compatible with the installed models."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprofile a spaCy pipeline to find out which functions take the most time.", "response": "def profile(model, inputs=None, n_texts=10000):\n    \"\"\"\n    Profile a spaCy pipeline, to find out which functions take the most time.\n    Input should be formatted as one JSON object per line with a key \"text\".\n    It can either be provided as a JSONL file, or be read from sys.sytdin.\n    If no input file is specified, the IMDB dataset is loaded via Thinc.\n    \"\"\"\n    msg = Printer()\n    if inputs is not None:\n        inputs = _read_inputs(inputs, msg)\n    if inputs is None:\n        n_inputs = 25000\n        with msg.loading(\"Loading IMDB dataset via Thinc...\"):\n            imdb_train, _ = thinc.extra.datasets.imdb()\n            inputs, _ = zip(*imdb_train)\n        msg.info(\"Loaded IMDB dataset and using {} examples\".format(n_inputs))\n        inputs = inputs[:n_inputs]\n    with msg.loading(\"Loading model '{}'...\".format(model)):\n        nlp = load_model(model)\n    msg.good(\"Loaded model '{}'\".format(model))\n    texts = list(itertools.islice(inputs, n_texts))\n    cProfile.runctx(\"parse_texts(nlp, texts)\", globals(), locals(), \"Profile.prof\")\n    s = pstats.Stats(\"Profile.prof\")\n    msg.divider(\"Profile stats\")\n    s.strip_dirs().sort_stats(\"time\").print_stats()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresolves POS tags for a given token.", "response": "def resolve_pos(token):\n    \"\"\"If necessary, add a field to the POS tag for UD mapping.\n    Under Universal Dependencies, sometimes the same Unidic POS tag can\n    be mapped differently depending on the literal token or its context\n    in the sentence. This function adds information to the POS tag to\n    resolve ambiguous mappings.\n    \"\"\"\n    # TODO: This is a first take. The rules here are crude approximations.\n    # For many of these, full dependencies are needed to properly resolve\n    # PoS mappings.\n    if token.pos == \"\u9023\u4f53\u8a5e,*,*,*\":\n        if re.match(r\"[\u3053\u305d\u3042\u3069\u6b64\u5176\u5f7c]\u306e\", token.surface):\n            return token.pos + \",DET\"\n        if re.match(r\"[\u3053\u305d\u3042\u3069\u6b64\u5176\u5f7c]\", token.surface):\n            return token.pos + \",PRON\"\n        return token.pos + \",ADJ\"\n    return token.pos"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nformatting Mecab output into a nice data structure based on Janome.", "response": "def detailed_tokens(tokenizer, text):\n    \"\"\"Format Mecab output into a nice data structure, based on Janome.\"\"\"\n    node = tokenizer.parseToNode(text)\n    node = node.next  # first node is beginning of sentence and empty, skip it\n    words = []\n    while node.posid != 0:\n        surface = node.surface\n        base = surface  # a default value. Updated if available later.\n        parts = node.feature.split(\",\")\n        pos = \",\".join(parts[0:4])\n        if len(parts) > 7:\n            # this information is only available for words in the tokenizer\n            # dictionary\n            base = parts[7]\n        words.append(ShortUnitWord(surface, base, pos))\n        node = node.next\n    return words"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef symlink_to(orig, dest):\n    if is_windows:\n        import subprocess\n\n        subprocess.check_call(\n            [\"mklink\", \"/d\", path2str(orig), path2str(dest)], shell=True\n        )\n    else:\n        orig.symlink_to(dest)", "response": "Create a symlink. Used for model shortcut links."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves a symlink. Used for model shortcut links.", "response": "def symlink_remove(link):\n    \"\"\"Remove a symlink. Used for model shortcut links.\n\n    link (unicode / Path): The path to the symlink.\n    \"\"\"\n    # https://stackoverflow.com/q/26554135/6400719\n    if os.path.isdir(path2str(link)) and is_windows:\n        # this should only be on Py2.7 and windows\n        os.rmdir(path2str(link))\n    else:\n        os.unlink(path2str(link))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_config(python2=None, python3=None, windows=None, linux=None, osx=None):\n    return (\n        python2 in (None, is_python2)\n        and python3 in (None, is_python3)\n        and windows in (None, is_windows)\n        and linux in (None, is_linux)\n        and osx in (None, is_osx)\n    )", "response": "Check if a specific configuration of Python version and operating system is configured."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef import_file(name, loc):\n    loc = path2str(loc)\n    if is_python_pre_3_5:\n        import imp\n\n        return imp.load_source(name, loc)\n    else:\n        import importlib.util\n\n        spec = importlib.util.spec_from_file_location(name, str(loc))\n        module = importlib.util.module_from_spec(spec)\n        spec.loader.exec_module(module)\n        return module", "response": "Import a module from a file. Used to load models from a directory."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nimporting and loads a Language class.", "response": "def get_lang_class(lang):\n    \"\"\"Import and load a Language class.\n\n    lang (unicode): Two-letter language code, e.g. 'en'.\n    RETURNS (Language): Language class.\n    \"\"\"\n    global LANGUAGES\n    # Check if an entry point is exposed for the language code\n    entry_point = get_entry_point(\"spacy_languages\", lang)\n    if entry_point is not None:\n        LANGUAGES[lang] = entry_point\n        return entry_point\n    if lang not in LANGUAGES:\n        try:\n            module = importlib.import_module(\".lang.%s\" % lang, \"spacy\")\n        except ImportError as err:\n            raise ImportError(Errors.E048.format(lang=lang, err=err))\n        LANGUAGES[lang] = getattr(module, module.__all__[0])\n    return LANGUAGES[lang]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_model(name, **overrides):\n    data_path = get_data_path()\n    if not data_path or not data_path.exists():\n        raise IOError(Errors.E049.format(path=path2str(data_path)))\n    if isinstance(name, basestring_):  # in data dir / shortcut\n        if name in set([d.name for d in data_path.iterdir()]):\n            return load_model_from_link(name, **overrides)\n        if is_package(name):  # installed as package\n            return load_model_from_package(name, **overrides)\n        if Path(name).exists():  # path to model data directory\n            return load_model_from_path(Path(name), **overrides)\n    elif hasattr(name, \"exists\"):  # Path or Path-like to model data\n        return load_model_from_path(name, **overrides)\n    raise IOError(Errors.E050.format(name=name))", "response": "Load a model from a shortcut link or a path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_model_from_link(name, **overrides):\n    path = get_data_path() / name / \"__init__.py\"\n    try:\n        cls = import_file(name, path)\n    except AttributeError:\n        raise IOError(Errors.E051.format(name=name))\n    return cls.load(**overrides)", "response": "Load a model from a shortcut link or directory in spaCy data path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading a model from an installed package.", "response": "def load_model_from_package(name, **overrides):\n    \"\"\"Load a model from an installed package.\"\"\"\n    cls = importlib.import_module(name)\n    return cls.load(**overrides)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a language model from a data directory path. Creates a Language class with pipeline from meta. json and then calls from_disk() with path.", "response": "def load_model_from_path(model_path, meta=False, **overrides):\n    \"\"\"Load a model from a data directory path. Creates Language class with\n    pipeline from meta.json and then calls from_disk() with path.\"\"\"\n    if not meta:\n        meta = get_model_meta(model_path)\n    cls = get_lang_class(meta[\"lang\"])\n    nlp = cls(meta=meta, **overrides)\n    pipeline = meta.get(\"pipeline\", [])\n    disable = overrides.get(\"disable\", [])\n    if pipeline is True:\n        pipeline = nlp.Defaults.pipe_names\n    elif pipeline in (False, None):\n        pipeline = []\n    for name in pipeline:\n        if name not in disable:\n            config = meta.get(\"pipeline_args\", {}).get(name, {})\n            component = nlp.create_pipe(name, config=config)\n            nlp.add_pipe(component, name=name)\n    return nlp.from_disk(model_path)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_model_meta(path):\n    model_path = ensure_path(path)\n    if not model_path.exists():\n        raise IOError(Errors.E052.format(path=path2str(model_path)))\n    meta_path = model_path / \"meta.json\"\n    if not meta_path.is_file():\n        raise IOError(Errors.E053.format(path=meta_path))\n    meta = srsly.read_json(meta_path)\n    for setting in [\"lang\", \"name\", \"version\"]:\n        if setting not in meta or not meta[setting]:\n            raise ValueError(Errors.E054.format(setting=setting))\n    return meta", "response": "Get model meta. json from a directory path and validate its contents."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_package_path(name):\n    name = name.lower()  # use lowercase version to be safe\n    # Here we're importing the module just to find it. This is worryingly\n    # indirect, but it's otherwise very difficult to find the package.\n    pkg = importlib.import_module(name)\n    return Path(pkg.__file__).parent", "response": "Get the path to an installed package."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting registered entry points from other packages for a given key e. g. catalyz_factories and return them as a dictionary keyed by name.", "response": "def get_entry_points(key):\n    \"\"\"Get registered entry points from other packages for a given key, e.g.\n    'spacy_factories' and return them as a dictionary, keyed by name.\n\n    key (unicode): Entry point name.\n    RETURNS (dict): Entry points, keyed by name.\n    \"\"\"\n    result = {}\n    for entry_point in pkg_resources.iter_entry_points(key):\n        result[entry_point.name] = entry_point.load()\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_entry_point(key, value):\n    for entry_point in pkg_resources.iter_entry_points(key):\n        if entry_point.name == value:\n            return entry_point.load()", "response": "Checks if a registered entry point is available for a given name and load it. If it is available return None. Otherwise return None."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_in_jupyter():\n    # https://stackoverflow.com/a/39662359/6400719\n    try:\n        shell = get_ipython().__class__.__name__\n        if shell == \"ZMQInteractiveShell\":\n            return True  # Jupyter notebook or qtconsole\n    except NameError:\n        return False  # Probably standard Python interpreter\n    return False", "response": "Check if user is running spaCy from a Jupyter notebook by detecting the\n    IPython kernel and then checking if it is in Jupyter or Qtconsole."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compile_suffix_regex(entries):\n    expression = \"|\".join([piece + \"$\" for piece in entries if piece.strip()])\n    return re.compile(expression)", "response": "Compile a sequence of suffix rules into a regex object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompile a sequence of infix rules into a regex object.", "response": "def compile_infix_regex(entries):\n    \"\"\"Compile a sequence of infix rules into a regex object.\n\n    entries (tuple): The infix rules, e.g. spacy.lang.punctuation.TOKENIZER_INFIXES.\n    RETURNS (regex object): The regex object. to be used for Tokenizer.infix_finditer.\n    \"\"\"\n    expression = \"|\".join([piece for piece in entries if piece.strip()])\n    return re.compile(expression)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_exc(base_exceptions, *addition_dicts):\n    exc = dict(base_exceptions)\n    for additions in addition_dicts:\n        for orth, token_attrs in additions.items():\n            if not all(isinstance(attr[ORTH], unicode_) for attr in token_attrs):\n                raise ValueError(Errors.E055.format(key=orth, orths=token_attrs))\n            described_orth = \"\".join(attr[ORTH] for attr in token_attrs)\n            if orth != described_orth:\n                raise ValueError(Errors.E056.format(key=orth, orths=described_orth))\n        exc.update(additions)\n    exc = expand_exc(exc, \"'\", \"\u2019\")\n    return exc", "response": "Update and validate tokenizer exceptions. Will overwrite exceptions."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexpands tokenizer exceptions with a string to find and replace string.", "response": "def expand_exc(excs, search, replace):\n    \"\"\"Find string in tokenizer exceptions, duplicate entry and replace string.\n    For example, to add additional versions with typographic apostrophes.\n\n    excs (dict): Tokenizer exceptions.\n    search (unicode): String to find and replace.\n    replace (unicode): Replacement.\n    RETURNS (dict): Combined tokenizer exceptions.\n    \"\"\"\n\n    def _fix_token(token, search, replace):\n        fixed = dict(token)\n        fixed[ORTH] = fixed[ORTH].replace(search, replace)\n        return fixed\n\n    new_excs = dict(excs)\n    for token_string, tokens in excs.items():\n        if search in token_string:\n            new_key = token_string.replace(search, replace)\n            new_value = [_fix_token(t, search, replace) for t in tokens]\n            new_excs[new_key] = new_value\n    return new_excs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef minibatch(items, size=8):\n    if isinstance(size, int):\n        size_ = itertools.repeat(size)\n    else:\n        size_ = size\n    items = iter(items)\n    while True:\n        batch_size = next(size_)\n        batch = list(itertools.islice(items, int(batch_size)))\n        if len(batch) == 0:\n            break\n        yield list(batch)", "response": "Iterate over batches of items. size may be an iterator and batch - size can vary on each step."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nyields an infinite series of compounding values. Each value is produced by multiplying the previous value by the compound rate.", "response": "def compounding(start, stop, compound):\n    \"\"\"Yield an infinite series of compounding values. Each time the\n    generator is called, a value is produced by multiplying the previous\n    value by the compound rate.\n\n    EXAMPLE:\n      >>> sizes = compounding(1., 10., 1.5)\n      >>> assert next(sizes) == 1.\n      >>> assert next(sizes) == 1 * 1.5\n      >>> assert next(sizes) == 1.5 * 1.5\n    \"\"\"\n\n    def clip(value):\n        return max(value, stop) if (start > stop) else min(value, stop)\n\n    curr = float(start)\n    while True:\n        yield clip(curr)\n        curr *= compound"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stepping(start, stop, steps):\n\n    def clip(value):\n        return max(value, stop) if (start > stop) else min(value, stop)\n\n    curr = float(start)\n    while True:\n        yield clip(curr)\n        curr += (stop - start) / steps", "response": "Yields an infinite series of values that step from a start value to a stop value over some number of steps."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef decaying(start, stop, decay):\n\n    curr = float(start)\n    while True:\n        yield max(curr, stop)\n        curr -= (decay)", "response": "Yields an infinite series of linearly decaying values."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef minibatch_by_words(items, size, tuples=True, count_words=len):\n    if isinstance(size, int):\n        size_ = itertools.repeat(size)\n    else:\n        size_ = size\n    items = iter(items)\n    while True:\n        batch_size = next(size_)\n        batch = []\n        while batch_size >= 0:\n            try:\n                if tuples:\n                    doc, gold = next(items)\n                else:\n                    doc = next(items)\n            except StopIteration:\n                if batch:\n                    yield batch\n                return\n            batch_size -= count_words(doc)\n            if tuples:\n                batch.append((doc, gold))\n            else:\n                batch.append(doc)\n        if batch:\n            yield batch", "response": "Create minibatches of a given number of words."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nshuffles an iterator. This works by holding `bufsize` items back and yielding them sometime later. Obviously, this is not unbiased \u2013 but should be good enough for batching. Larger bufsize means less bias. From https://gist.github.com/andres-erbsen/1307752 iterable (iterable): Iterator to shuffle. bufsize (int): Items to hold back. YIELDS (iterable): The shuffled iterator.", "response": "def itershuffle(iterable, bufsize=1000):\n    \"\"\"Shuffle an iterator. This works by holding `bufsize` items back\n    and yielding them sometime later. Obviously, this is not unbiased \u2013\n    but should be good enough for batching. Larger bufsize means less bias.\n    From https://gist.github.com/andres-erbsen/1307752\n\n    iterable (iterable): Iterator to shuffle.\n    bufsize (int): Items to hold back.\n    YIELDS (iterable): The shuffled iterator.\n    \"\"\"\n    iterable = iter(iterable)\n    buf = []\n    try:\n        while True:\n            for i in range(random.randint(1, bufsize - len(buf))):\n                buf.append(next(iterable))\n            random.shuffle(buf)\n            for i in range(random.randint(1, bufsize)):\n                if buf:\n                    yield buf.pop()\n                else:\n                    break\n    except StopIteration:\n        random.shuffle(buf)\n        while buf:\n            yield buf.pop()\n        raise StopIteration"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating data against a given JSON schema.", "response": "def validate_json(data, validator):\n    \"\"\"Validate data against a given JSON schema (see https://json-schema.org).\n\n    data: JSON-serializable data to validate.\n    validator (jsonschema.DraftXValidator): The validator.\n    RETURNS (list): A list of error messages, if available.\n    \"\"\"\n    errors = []\n    for err in sorted(validator.iter_errors(data), key=lambda e: e.path):\n        if err.path:\n            err_path = \"[{}]\".format(\" -> \".join([str(p) for p in err.path]))\n        else:\n            err_path = \"\"\n        msg = err.message + \" \" + err_path\n        if err.context:  # Error has suberrors, e.g. if schema uses anyOf\n            suberrs = [\"  - {}\".format(suberr.message) for suberr in err.context]\n            msg += \":\\n{}\".format(\"\".join(suberrs))\n        errors.append(msg)\n    return errors"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef labels(self):\n        all_labels = set(self.token_patterns.keys())\n        all_labels.update(self.phrase_patterns.keys())\n        return tuple(all_labels)", "response": "Returns a tuple of all labels present in the match patterns."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef patterns(self):\n        all_patterns = []\n        for label, patterns in self.token_patterns.items():\n            for pattern in patterns:\n                all_patterns.append({\"label\": label, \"pattern\": pattern})\n        for label, patterns in self.phrase_patterns.items():\n            for pattern in patterns:\n                all_patterns.append({\"label\": label, \"pattern\": pattern.text})\n        return all_patterns", "response": "Get all patterns that were added to the entity ruler."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_patterns(self, patterns):\n        for entry in patterns:\n            label = entry[\"label\"]\n            pattern = entry[\"pattern\"]\n            if isinstance(pattern, basestring_):\n                self.phrase_patterns[label].append(self.nlp(pattern))\n            elif isinstance(pattern, list):\n                self.token_patterns[label].append(pattern)\n            else:\n                raise ValueError(Errors.E097.format(pattern=pattern))\n        for label, patterns in self.token_patterns.items():\n            self.matcher.add(label, None, *patterns)\n        for label, patterns in self.phrase_patterns.items():\n            self.phrase_matcher.add(label, None, *patterns)", "response": "Add patterns to the entitiy ruler."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the entity ruler from a bytestring.", "response": "def from_bytes(self, patterns_bytes, **kwargs):\n        \"\"\"Load the entity ruler from a bytestring.\n\n        patterns_bytes (bytes): The bytestring to load.\n        **kwargs: Other config paramters, mostly for consistency.\n        RETURNS (EntityRuler): The loaded entity ruler.\n\n        DOCS: https://spacy.io/api/entityruler#from_bytes\n        \"\"\"\n        patterns = srsly.msgpack_loads(patterns_bytes)\n        self.add_patterns(patterns)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload the entity ruler from a JSONL file.", "response": "def from_disk(self, path, **kwargs):\n        \"\"\"Load the entity ruler from a file. Expects a file containing\n        newline-delimited JSON (JSONL) with one entry per line.\n\n        path (unicode / Path): The JSONL file to load.\n        **kwargs: Other config paramters, mostly for consistency.\n        RETURNS (EntityRuler): The loaded entity ruler.\n\n        DOCS: https://spacy.io/api/entityruler#from_disk\n        \"\"\"\n        path = ensure_path(path)\n        path = path.with_suffix(\".jsonl\")\n        patterns = srsly.read_jsonl(path)\n        self.add_patterns(patterns)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the entity ruler patterns to a JSONL file.", "response": "def to_disk(self, path, **kwargs):\n        \"\"\"Save the entity ruler patterns to a directory. The patterns will be\n        saved as newline-delimited JSON (JSONL).\n\n        path (unicode / Path): The JSONL file to load.\n        **kwargs: Other config paramters, mostly for consistency.\n        RETURNS (EntityRuler): The loaded entity ruler.\n\n        DOCS: https://spacy.io/api/entityruler#to_disk\n        \"\"\"\n        path = ensure_path(path)\n        path = path.with_suffix(\".jsonl\")\n        srsly.write_jsonl(path, self.patterns)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_data(\n    nlp,\n    conllu_file,\n    text_file,\n    raw_text=True,\n    oracle_segments=False,\n    max_doc_length=None,\n    limit=None,\n):\n    \"\"\"Read the CONLLU format into (Doc, GoldParse) tuples. If raw_text=True,\n    include Doc objects created using nlp.make_doc and then aligned against\n    the gold-standard sequences. If oracle_segments=True, include Doc objects\n    created from the gold-standard segments. At least one must be True.\"\"\"\n    if not raw_text and not oracle_segments:\n        raise ValueError(\"At least one of raw_text or oracle_segments must be True\")\n    paragraphs = split_text(text_file.read())\n    conllu = read_conllu(conllu_file)\n    # sd is spacy doc; cd is conllu doc\n    # cs is conllu sent, ct is conllu token\n    docs = []\n    golds = []\n    for doc_id, (text, cd) in enumerate(zip(paragraphs, conllu)):\n        sent_annots = []\n        for cs in cd:\n            sent = defaultdict(list)\n            for id_, word, lemma, pos, tag, morph, head, dep, _, space_after in cs:\n                if \".\" in id_:\n                    continue\n                if \"-\" in id_:\n                    continue\n                id_ = int(id_) - 1\n                head = int(head) - 1 if head != \"0\" else id_\n                sent[\"words\"].append(word)\n                sent[\"tags\"].append(tag)\n                sent[\"heads\"].append(head)\n                sent[\"deps\"].append(\"ROOT\" if dep == \"root\" else dep)\n                sent[\"spaces\"].append(space_after == \"_\")\n            sent[\"entities\"] = [\"-\"] * len(sent[\"words\"])\n            sent[\"heads\"], sent[\"deps\"] = projectivize(sent[\"heads\"], sent[\"deps\"])\n            if oracle_segments:\n                docs.append(Doc(nlp.vocab, words=sent[\"words\"], spaces=sent[\"spaces\"]))\n                golds.append(GoldParse(docs[-1], **sent))\n\n            sent_annots.append(sent)\n            if raw_text and max_doc_length and len(sent_annots) >= max_doc_length:\n                doc, gold = _make_gold(nlp, None, sent_annots)\n                sent_annots = []\n                docs.append(doc)\n                golds.append(gold)\n                if limit and len(docs) >= limit:\n                    return docs, golds\n\n        if raw_text and sent_annots:\n            doc, gold = _make_gold(nlp, None, sent_annots)\n            docs.append(doc)\n            golds.append(gold)\n        if limit and len(docs) >= limit:\n            return docs, golds\n    return docs, golds", "response": "Read the CONLLU format into a list of Doc objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget out the annoying tuples format used by begin_training given the GoldParse objects.", "response": "def golds_to_gold_tuples(docs, golds):\n    \"\"\"Get out the annoying 'tuples' format used by begin_training, given the\n    GoldParse objects.\"\"\"\n    tuples = []\n    for doc, gold in zip(docs, golds):\n        text = doc.text\n        ids, words, tags, heads, labels, iob = zip(*gold.orig_annot)\n        sents = [((ids, words, tags, heads, labels, iob), [])]\n        tuples.append((text, sents))\n    return tuples"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if text resembles a number", "response": "def like_num(text):\n    \"\"\"\n    check if text resembles a number\n    \"\"\"\n    text = (\n        text.replace(\",\", \"\")\n        .replace(\".\", \"\")\n        .replace(\"\u060c\", \"\")\n        .replace(\"\u066b\", \"\")\n        .replace(\"/\", \"\")\n    )\n    if text.isdigit():\n        return True\n    if text in _num_words:\n        return True\n    if text in _ordinal_words:\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconcatenating multiple serialized binders into one byte string.", "response": "def merge_bytes(binder_strings):\n    \"\"\"Concatenate multiple serialized binders into one byte string.\"\"\"\n    output = None\n    for byte_string in binder_strings:\n        binder = Binder().from_bytes(byte_string)\n        if output is None:\n            output = binder\n        else:\n            output.merge(binder)\n    return output.to_bytes()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add(self, doc):\n        array = doc.to_array(self.attrs)\n        if len(array.shape) == 1:\n            array = array.reshape((array.shape[0], 1))\n        self.tokens.append(array)\n        spaces = doc.to_array(SPACY)\n        assert array.shape[0] == spaces.shape[0]\n        spaces = spaces.reshape((spaces.shape[0], 1))\n        self.spaces.append(numpy.asarray(spaces, dtype=bool))\n        self.strings.update(w.text for w in doc)", "response": "Add a doc s annotations to the binder for serialization."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrecover Doc objects from the annotations using the given vocab.", "response": "def get_docs(self, vocab):\n        \"\"\"Recover Doc objects from the annotations, using the given vocab.\"\"\"\n        for string in self.strings:\n            vocab[string]\n        orth_col = self.attrs.index(ORTH)\n        for tokens, spaces in zip(self.tokens, self.spaces):\n            words = [vocab.strings[orth] for orth in tokens[:, orth_col]]\n            doc = Doc(vocab, words=words, spaces=spaces)\n            doc = doc.from_array(self.attrs, tokens)\n            yield doc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextend the annotations of this binder with the annotations from another.", "response": "def merge(self, other):\n        \"\"\"Extend the annotations of this binder with the annotations from another.\"\"\"\n        assert self.attrs == other.attrs\n        self.tokens.extend(other.tokens)\n        self.spaces.extend(other.spaces)\n        self.strings.update(other.strings)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nserializing the binder s annotations into a byte string.", "response": "def to_bytes(self):\n        \"\"\"Serialize the binder's annotations into a byte string.\"\"\"\n        for tokens in self.tokens:\n            assert len(tokens.shape) == 2, tokens.shape\n        lengths = [len(tokens) for tokens in self.tokens]\n        msg = {\n            \"attrs\": self.attrs,\n            \"tokens\": numpy.vstack(self.tokens).tobytes(\"C\"),\n            \"spaces\": numpy.vstack(self.spaces).tobytes(\"C\"),\n            \"lengths\": numpy.asarray(lengths, dtype=\"int32\").tobytes(\"C\"),\n            \"strings\": list(self.strings),\n        }\n        return gzip.compress(srsly.msgpack_dumps(msg))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_bytes(self, string):\n        msg = srsly.msgpack_loads(gzip.decompress(string))\n        self.attrs = msg[\"attrs\"]\n        self.strings = set(msg[\"strings\"])\n        lengths = numpy.fromstring(msg[\"lengths\"], dtype=\"int32\")\n        flat_spaces = numpy.fromstring(msg[\"spaces\"], dtype=bool)\n        flat_tokens = numpy.fromstring(msg[\"tokens\"], dtype=\"uint64\")\n        shape = (flat_tokens.size // len(self.attrs), len(self.attrs))\n        flat_tokens = flat_tokens.reshape(shape)\n        flat_spaces = flat_spaces.reshape((flat_spaces.size, 1))\n        self.tokens = NumpyOps().unflatten(flat_tokens, lengths)\n        self.spaces = NumpyOps().unflatten(flat_spaces, lengths)\n        for tokens in self.tokens:\n            assert len(tokens.shape) == 2, tokens.shape\n        return self", "response": "Deserialize the binder s annotations from a byte string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_data(limit=0, split=0.8):\n    # Partition off part of the train data for evaluation\n    train_data, _ = thinc.extra.datasets.imdb()\n    random.shuffle(train_data)\n    train_data = train_data[-limit:]\n    texts, labels = zip(*train_data)\n    cats = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)} for y in labels]\n    split = int(len(train_data) * split)\n    return (texts[:split], cats[:split]), (texts[split:], cats[split:])", "response": "Load data from the IMDB dataset."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef package(input_dir, output_dir, meta_path=None, create_meta=False, force=False):\n    msg = Printer()\n    input_path = util.ensure_path(input_dir)\n    output_path = util.ensure_path(output_dir)\n    meta_path = util.ensure_path(meta_path)\n    if not input_path or not input_path.exists():\n        msg.fail(\"Can't locate model data\", input_path, exits=1)\n    if not output_path or not output_path.exists():\n        msg.fail(\"Output directory not found\", output_path, exits=1)\n    if meta_path and not meta_path.exists():\n        msg.fail(\"Can't find model meta.json\", meta_path, exits=1)\n\n    meta_path = meta_path or input_path / \"meta.json\"\n    if meta_path.is_file():\n        meta = srsly.read_json(meta_path)\n        if not create_meta:  # only print if user doesn't want to overwrite\n            msg.good(\"Loaded meta.json from file\", meta_path)\n        else:\n            meta = generate_meta(input_dir, meta, msg)\n    for key in (\"lang\", \"name\", \"version\"):\n        if key not in meta or meta[key] == \"\":\n            msg.fail(\n                \"No '{}' setting found in meta.json\".format(key),\n                \"This setting is required to build your package.\",\n                exits=1,\n            )\n    model_name = meta[\"lang\"] + \"_\" + meta[\"name\"]\n    model_name_v = model_name + \"-\" + meta[\"version\"]\n    main_path = output_path / model_name_v\n    package_path = main_path / model_name\n\n    if package_path.exists():\n        if force:\n            shutil.rmtree(path2str(package_path))\n        else:\n            msg.fail(\n                \"Package directory already exists\",\n                \"Please delete the directory and try again, or use the \"\n                \"`--force` flag to overwrite existing \"\n                \"directories.\".format(path=path2str(package_path)),\n                exits=1,\n            )\n    Path.mkdir(package_path, parents=True)\n    shutil.copytree(path2str(input_path), path2str(package_path / model_name_v))\n    create_file(main_path / \"meta.json\", srsly.json_dumps(meta, indent=2))\n    create_file(main_path / \"setup.py\", TEMPLATE_SETUP)\n    create_file(main_path / \"MANIFEST.in\", TEMPLATE_MANIFEST)\n    create_file(package_path / \"__init__.py\", TEMPLATE_INIT)\n    msg.good(\"Successfully created package '{}'\".format(model_name_v), main_path)\n    msg.text(\"To build the package, run `python setup.py sdist` in this directory.\")", "response": "Generate a Python package for the specified input directory and output directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_base_form(self, univ_pos, morphology=None):\n        morphology = {} if morphology is None else morphology\n        others = [key for key in morphology\n                  if key not in (POS, 'Number', 'POS', 'VerbForm', 'Tense')]\n        if univ_pos == 'noun' and morphology.get('Number') == 'sing':\n            return True\n        elif univ_pos == 'verb' and morphology.get('VerbForm') == 'inf':\n            return True\n        # This maps 'VBP' to base form -- probably just need 'IS_BASE'\n        # morphology\n        elif univ_pos == 'verb' and (morphology.get('VerbForm') == 'fin' and\n                                     morphology.get('Tense') == 'pres' and\n                                     morphology.get('Number') is None and\n                                     not others):\n            return True\n        elif univ_pos == 'adj' and morphology.get('Degree') == 'pos':\n            return True\n        elif VerbForm_inf in morphology:\n            return True\n        elif VerbForm_none in morphology:\n            return True\n        elif Number_sing in morphology:\n            return True\n        elif Degree_pos in morphology:\n            return True\n        else:\n            return False", "response": "Check whether we re dealing with a base form."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main(model=None, new_model_name=\"animal\", output_dir=None, n_iter=30):\n    random.seed(0)\n    if model is not None:\n        nlp = spacy.load(model)  # load existing spaCy model\n        print(\"Loaded model '%s'\" % model)\n    else:\n        nlp = spacy.blank(\"en\")  # create blank Language class\n        print(\"Created blank 'en' model\")\n    # Add entity recognizer to model if it's not in the pipeline\n    # nlp.create_pipe works for built-ins that are registered with spaCy\n    if \"ner\" not in nlp.pipe_names:\n        ner = nlp.create_pipe(\"ner\")\n        nlp.add_pipe(ner)\n    # otherwise, get it, so we can add labels to it\n    else:\n        ner = nlp.get_pipe(\"ner\")\n\n    ner.add_label(LABEL)  # add new entity label to entity recognizer\n    # Adding extraneous labels shouldn't mess anything up\n    ner.add_label(\"VEGETABLE\")\n    if model is None:\n        optimizer = nlp.begin_training()\n    else:\n        optimizer = nlp.resume_training()\n    move_names = list(ner.move_names)\n    # get names of other pipes to disable them during training\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n    with nlp.disable_pipes(*other_pipes):  # only train NER\n        sizes = compounding(1.0, 4.0, 1.001)\n        # batch up the examples using spaCy's minibatch\n        for itn in range(n_iter):\n            random.shuffle(TRAIN_DATA)\n            batches = minibatch(TRAIN_DATA, size=sizes)\n            losses = {}\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n            print(\"Losses\", losses)\n\n    # test the trained model\n    test_text = \"Do you like horses?\"\n    doc = nlp(test_text)\n    print(\"Entities in '%s'\" % test_text)\n    for ent in doc.ents:\n        print(ent.label_, ent.text)\n\n    # save model to output directory\n    if output_dir is not None:\n        output_dir = Path(output_dir)\n        if not output_dir.exists():\n            output_dir.mkdir()\n        nlp.meta[\"name\"] = new_model_name  # rename model\n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)\n\n        # test the saved model\n        print(\"Loading from\", output_dir)\n        nlp2 = spacy.load(output_dir)\n        # Check the classes have loaded back consistently\n        assert nlp2.get_pipe(\"ner\").move_names == move_names\n        doc2 = nlp2(test_text)\n        for ent in doc2.ents:\n            print(ent.label_, ent.text)", "response": "Train the pipeline and entity recognizer and train the new entity."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert CoNLL - 2003 NER format into JSON format for use with CoNLL - 2003 train cli.", "response": "def conll_ner2json(input_data, **kwargs):\n    \"\"\"\n    Convert files in the CoNLL-2003 NER format into JSON format for use with\n    train cli.\n    \"\"\"\n    delimit_docs = \"-DOCSTART- -X- O O\"\n    output_docs = []\n    for doc in input_data.strip().split(delimit_docs):\n        doc = doc.strip()\n        if not doc:\n            continue\n        output_doc = []\n        for sent in doc.split(\"\\n\\n\"):\n            sent = sent.strip()\n            if not sent:\n                continue\n            lines = [line.strip() for line in sent.split(\"\\n\") if line.strip()]\n            words, tags, chunks, iob_ents = zip(*[line.split() for line in lines])\n            biluo_ents = iob_to_biluo(iob_ents)\n            output_doc.append(\n                {\n                    \"tokens\": [\n                        {\"orth\": w, \"tag\": tag, \"ner\": ent}\n                        for (w, tag, ent) in zip(words, tags, biluo_ents)\n                    ]\n                }\n            )\n        output_docs.append(\n            {\"id\": len(output_docs), \"paragraphs\": [{\"sentences\": output_doc}]}\n        )\n        output_doc = []\n    return output_docs"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new language to train the tagger and save the model to output_dir", "response": "def main(lang=\"en\", output_dir=None, n_iter=25):\n    \"\"\"Create a new model, set up the pipeline and train the tagger. In order to\n    train the tagger with a custom tag map, we're creating a new Language\n    instance with a custom vocab.\n    \"\"\"\n    nlp = spacy.blank(lang)\n    # add the tagger to the pipeline\n    # nlp.create_pipe works for built-ins that are registered with spaCy\n    tagger = nlp.create_pipe(\"tagger\")\n    # Add the tags. This needs to be done before you start training.\n    for tag, values in TAG_MAP.items():\n        tagger.add_label(tag, values)\n    nlp.add_pipe(tagger)\n\n    optimizer = nlp.begin_training()\n    for i in range(n_iter):\n        random.shuffle(TRAIN_DATA)\n        losses = {}\n        # batch up the examples using spaCy's minibatch\n        batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n        for batch in batches:\n            texts, annotations = zip(*batch)\n            nlp.update(texts, annotations, sgd=optimizer, losses=losses)\n        print(\"Losses\", losses)\n\n    # test the trained model\n    test_text = \"I like blue eggs\"\n    doc = nlp(test_text)\n    print(\"Tags\", [(t.text, t.tag_, t.pos_) for t in doc])\n\n    # save model to output directory\n    if output_dir is not None:\n        output_dir = Path(output_dir)\n        if not output_dir.exists():\n            output_dir.mkdir()\n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)\n\n        # test the save model\n        print(\"Loading from\", output_dir)\n        nlp2 = spacy.load(output_dir)\n        doc = nlp2(test_text)\n        print(\"Tags\", [(t.text, t.tag_, t.pos_) for t in doc])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading data from the IMDB dataset.", "response": "def load_textcat_data(limit=0):\n    \"\"\"Load data from the IMDB dataset.\"\"\"\n    # Partition off part of the train data for evaluation\n    train_data, eval_data = thinc.extra.datasets.imdb()\n    random.shuffle(train_data)\n    train_data = train_data[-limit:]\n    texts, labels = zip(*train_data)\n    eval_texts, eval_labels = zip(*eval_data)\n    cats = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)} for y in labels]\n    eval_cats = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)} for y in eval_labels]\n    return (texts, cats), (eval_texts, eval_cats)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize a new language - specific model.", "response": "def init_model(\n    lang,\n    output_dir,\n    freqs_loc=None,\n    clusters_loc=None,\n    jsonl_loc=None,\n    vectors_loc=None,\n    prune_vectors=-1,\n):\n    \"\"\"\n    Create a new model from raw data, like word frequencies, Brown clusters\n    and word vectors. If vectors are provided in Word2Vec format, they can\n    be either a .txt or zipped as a .zip or .tar.gz.\n    \"\"\"\n    if jsonl_loc is not None:\n        if freqs_loc is not None or clusters_loc is not None:\n            settings = [\"-j\"]\n            if freqs_loc:\n                settings.append(\"-f\")\n            if clusters_loc:\n                settings.append(\"-c\")\n            msg.warn(\n                \"Incompatible arguments\",\n                \"The -f and -c arguments are deprecated, and not compatible \"\n                \"with the -j argument, which should specify the same \"\n                \"information. Either merge the frequencies and clusters data \"\n                \"into the JSONL-formatted file (recommended), or use only the \"\n                \"-f and -c files, without the other lexical attributes.\",\n            )\n        jsonl_loc = ensure_path(jsonl_loc)\n        lex_attrs = srsly.read_jsonl(jsonl_loc)\n    else:\n        clusters_loc = ensure_path(clusters_loc)\n        freqs_loc = ensure_path(freqs_loc)\n        if freqs_loc is not None and not freqs_loc.exists():\n            msg.fail(\"Can't find words frequencies file\", freqs_loc, exits=1)\n        lex_attrs = read_attrs_from_deprecated(freqs_loc, clusters_loc)\n\n    with msg.loading(\"Creating model...\"):\n        nlp = create_model(lang, lex_attrs)\n    msg.good(\"Successfully created model\")\n    if vectors_loc is not None:\n        add_vectors(nlp, vectors_loc, prune_vectors)\n    vec_added = len(nlp.vocab.vectors)\n    lex_added = len(nlp.vocab)\n    msg.good(\n        \"Sucessfully compiled vocab\",\n        \"{} entries, {} vectors\".format(lex_added, vec_added),\n    )\n    if not output_dir.exists():\n        output_dir.mkdir()\n    nlp.to_disk(output_dir)\n    return nlp"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling gz tar. gz or unzipped files", "response": "def open_file(loc):\n    \"\"\"Handle .gz, .tar.gz or unzipped files\"\"\"\n    loc = ensure_path(loc)\n    if tarfile.is_tarfile(str(loc)):\n        return tarfile.open(str(loc), \"r:gz\")\n    elif loc.parts[-1].endswith(\"gz\"):\n        return (line.decode(\"utf8\") for line in gzip.open(str(loc), \"r\"))\n    elif loc.parts[-1].endswith(\"zip\"):\n        zip_file = zipfile.ZipFile(str(loc))\n        names = zip_file.namelist()\n        file_ = zip_file.open(names[0])\n        return (line.decode(\"utf8\") for line in file_)\n    else:\n        return loc.open(\"r\", encoding=\"utf8\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads the model set up the pipeline and train the entity recognizer.", "response": "def main(model=None, output_dir=None, n_iter=100):\n    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n    if model is not None:\n        nlp = spacy.load(model)  # load existing spaCy model\n        print(\"Loaded model '%s'\" % model)\n    else:\n        nlp = spacy.blank(\"en\")  # create blank Language class\n        print(\"Created blank 'en' model\")\n\n    # create the built-in pipeline components and add them to the pipeline\n    # nlp.create_pipe works for built-ins that are registered with spaCy\n    if \"ner\" not in nlp.pipe_names:\n        ner = nlp.create_pipe(\"ner\")\n        nlp.add_pipe(ner, last=True)\n    # otherwise, get it so we can add labels\n    else:\n        ner = nlp.get_pipe(\"ner\")\n\n    # add labels\n    for _, annotations in TRAIN_DATA:\n        for ent in annotations.get(\"entities\"):\n            ner.add_label(ent[2])\n\n    # get names of other pipes to disable them during training\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n    with nlp.disable_pipes(*other_pipes):  # only train NER\n        # reset and initialize the weights randomly \u2013 but only if we're\n        # training a new model\n        if model is None:\n            nlp.begin_training()\n        for itn in range(n_iter):\n            random.shuffle(TRAIN_DATA)\n            losses = {}\n            # batch up the examples using spaCy's minibatch\n            batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(\n                    texts,  # batch of texts\n                    annotations,  # batch of annotations\n                    drop=0.5,  # dropout - make it harder to memorise data\n                    losses=losses,\n                )\n            print(\"Losses\", losses)\n\n    # test the trained model\n    for text, _ in TRAIN_DATA:\n        doc = nlp(text)\n        print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n        print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])\n\n    # save model to output directory\n    if output_dir is not None:\n        output_dir = Path(output_dir)\n        if not output_dir.exists():\n            output_dir.mkdir()\n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)\n\n        # test the saved model\n        print(\"Loading from\", output_dir)\n        nlp2 = spacy.load(output_dir)\n        for text, _ in TRAIN_DATA:\n            doc = nlp2(text)\n            print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n            print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pretrain(\n    texts_loc,\n    vectors_model,\n    output_dir,\n    width=96,\n    depth=4,\n    embed_rows=2000,\n    loss_func=\"cosine\",\n    use_vectors=False,\n    dropout=0.2,\n    n_iter=1000,\n    batch_size=3000,\n    max_length=500,\n    min_length=5,\n    seed=0,\n    n_save_every=None,\n):\n    \"\"\"\n    Pre-train the 'token-to-vector' (tok2vec) layer of pipeline components,\n    using an approximate language-modelling objective. Specifically, we load\n    pre-trained vectors, and train a component like a CNN, BiLSTM, etc to predict\n    vectors which match the pre-trained ones. The weights are saved to a directory\n    after each epoch. You can then pass a path to one of these pre-trained weights\n    files to the 'spacy train' command.\n\n    This technique may be especially helpful if you have little labelled data.\n    However, it's still quite experimental, so your mileage may vary.\n\n    To load the weights back in during 'spacy train', you need to ensure\n    all settings are the same between pretraining and training. The API and\n    errors around this need some improvement.\n    \"\"\"\n    config = dict(locals())\n    msg = Printer()\n    util.fix_random_seed(seed)\n\n    has_gpu = prefer_gpu()\n    msg.info(\"Using GPU\" if has_gpu else \"Not using GPU\")\n\n    output_dir = Path(output_dir)\n    if not output_dir.exists():\n        output_dir.mkdir()\n        msg.good(\"Created output directory\")\n    srsly.write_json(output_dir / \"config.json\", config)\n    msg.good(\"Saved settings to config.json\")\n\n    # Load texts from file or stdin\n    if texts_loc != \"-\":  # reading from a file\n        texts_loc = Path(texts_loc)\n        if not texts_loc.exists():\n            msg.fail(\"Input text file doesn't exist\", texts_loc, exits=1)\n        with msg.loading(\"Loading input texts...\"):\n            texts = list(srsly.read_jsonl(texts_loc))\n        msg.good(\"Loaded input texts\")\n        random.shuffle(texts)\n    else:  # reading from stdin\n        msg.text(\"Reading input text from stdin...\")\n        texts = srsly.read_jsonl(\"-\")\n\n    with msg.loading(\"Loading model '{}'...\".format(vectors_model)):\n        nlp = util.load_model(vectors_model)\n    msg.good(\"Loaded model '{}'\".format(vectors_model))\n    pretrained_vectors = None if not use_vectors else nlp.vocab.vectors.name\n    model = create_pretraining_model(\n        nlp,\n        Tok2Vec(\n            width,\n            embed_rows,\n            conv_depth=depth,\n            pretrained_vectors=pretrained_vectors,\n            bilstm_depth=0,  # Requires PyTorch. Experimental.\n            cnn_maxout_pieces=3,  # You can try setting this higher\n            subword_features=True,  # Set to False for Chinese etc\n        ),\n    )\n    optimizer = create_default_optimizer(model.ops)\n    tracker = ProgressTracker(frequency=10000)\n    msg.divider(\"Pre-training tok2vec layer\")\n    row_settings = {\"widths\": (3, 10, 10, 6, 4), \"aligns\": (\"r\", \"r\", \"r\", \"r\", \"r\")}\n    msg.row((\"#\", \"# Words\", \"Total Loss\", \"Loss\", \"w/s\"), **row_settings)\n\n    def _save_model(epoch, is_temp=False):\n        is_temp_str = \".temp\" if is_temp else \"\"\n        with model.use_params(optimizer.averages):\n            with (output_dir / (\"model%d%s.bin\" % (epoch, is_temp_str))).open(\n                \"wb\"\n            ) as file_:\n                file_.write(model.tok2vec.to_bytes())\n            log = {\n                \"nr_word\": tracker.nr_word,\n                \"loss\": tracker.loss,\n                \"epoch_loss\": tracker.epoch_loss,\n                \"epoch\": epoch,\n            }\n            with (output_dir / \"log.jsonl\").open(\"a\") as file_:\n                file_.write(srsly.json_dumps(log) + \"\\n\")\n\n    for epoch in range(n_iter):\n        for batch_id, batch in enumerate(\n            util.minibatch_by_words(((text, None) for text in texts), size=batch_size)\n        ):\n            docs = make_docs(\n                nlp,\n                [text for (text, _) in batch],\n                max_length=max_length,\n                min_length=min_length,\n            )\n            loss = make_update(\n                model, docs, optimizer, objective=loss_func, drop=dropout\n            )\n            progress = tracker.update(epoch, loss, docs)\n            if progress:\n                msg.row(progress, **row_settings)\n                if texts_loc == \"-\" and tracker.words_per_epoch[epoch] >= 10 ** 7:\n                    break\n            if n_save_every and (batch_id % n_save_every == 0):\n                _save_model(epoch, is_temp=True)\n        _save_model(epoch)\n        tracker.epoch_loss = 0.0\n        if texts_loc != \"-\":\n            # Reshuffle the texts if texts were loaded from a file\n            random.shuffle(texts)", "response": "Pre - train a node - level token - to - vector layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_update(model, docs, optimizer, drop=0.0, objective=\"L2\"):\n    predictions, backprop = model.begin_update(docs, drop=drop)\n    loss, gradients = get_vectors_loss(model.ops, docs, predictions, objective)\n    backprop(gradients, sgd=optimizer)\n    # Don't want to return a cupy object here\n    # The gradients are modified in-place by the BERT MLM,\n    # so we get an accurate loss\n    return float(loss)", "response": "Perform an update over a single batch of documents."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute a mean squared error loss between the documents vectors and the prediction.", "response": "def get_vectors_loss(ops, docs, prediction, objective=\"L2\"):\n    \"\"\"Compute a mean-squared error loss between the documents' vectors and\n    the prediction.\n\n    Note that this is ripe for customization! We could compute the vectors\n    in some other word, e.g. with an LSTM language model, or use some other\n    type of objective.\n    \"\"\"\n    # The simplest way to implement this would be to vstack the\n    # token.vector values, but that's a bit inefficient, especially on GPU.\n    # Instead we fetch the index into the vectors table for each of our tokens,\n    # and look them up all at once. This prevents data copying.\n    ids = ops.flatten([doc.to_array(ID).ravel() for doc in docs])\n    target = docs[0].vocab.vectors.data[ids]\n    if objective == \"L2\":\n        d_target = prediction - target\n        loss = (d_target ** 2).sum()\n    elif objective == \"cosine\":\n        loss, d_target = get_cossim_loss(prediction, target)\n    return loss, d_target"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a pretraining network for the CNA - style pretraining.", "response": "def create_pretraining_model(nlp, tok2vec):\n    \"\"\"Define a network for the pretraining. We simply add an output layer onto\n    the tok2vec input model. The tok2vec input model needs to be a model that\n    takes a batch of Doc objects (as a list), and returns a list of arrays.\n    Each array in the output needs to have one row per token in the doc.\n    \"\"\"\n    output_size = nlp.vocab.vectors.data.shape[1]\n    output_layer = chain(\n        LN(Maxout(300, pieces=3)), Affine(output_size, drop_factor=0.0)\n    )\n    # This is annoying, but the parser etc have the flatten step after\n    # the tok2vec. To load the weights in cleanly, we need to match\n    # the shape of the models' components exactly. So what we cann\n    # \"tok2vec\" has to be the same set of processes as what the components do.\n    tok2vec = chain(tok2vec, flatten)\n    model = chain(tok2vec, output_layer)\n    model = masked_language_model(nlp.vocab, model)\n    model.tok2vec = tok2vec\n    model.output_layer = output_layer\n    model.begin_training([nlp.make_doc(\"Give it a doc to infer shapes\")])\n    return model"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _smart_round(figure, width=10, max_decimal=4):\n    n_digits = len(str(int(figure)))\n    n_decimal = width - (n_digits + 1)\n    if n_decimal <= 1:\n        return str(int(figure))\n    else:\n        n_decimal = min(n_decimal, max_decimal)\n        format_str = \"%.\" + str(n_decimal) + \"f\"\n        return format_str % figure", "response": "Round large numbers as integers smaller numbers as decimals."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetecting base noun phrases.", "response": "def noun_chunks(obj):\n    \"\"\"\n    Detect base noun phrases. Works on both Doc and Span.\n    \"\"\"\n    # It follows the logic of the noun chunks finder of English language,\n    # adjusted to some Greek language special characteristics.\n    # obj tag corrects some DEP tagger mistakes.\n    # Further improvement of the models will eliminate the need for this tag.\n    labels = [\"nsubj\", \"obj\", \"iobj\", \"appos\", \"ROOT\", \"obl\"]\n    doc = obj.doc  # Ensure works on both Doc and Span.\n    np_deps = [doc.vocab.strings.add(label) for label in labels]\n    conj = doc.vocab.strings.add(\"conj\")\n    nmod = doc.vocab.strings.add(\"nmod\")\n    np_label = doc.vocab.strings.add(\"NP\")\n    seen = set()\n    for i, word in enumerate(obj):\n        if word.pos not in (NOUN, PROPN, PRON):\n            continue\n        # Prevent nested chunks from being produced\n        if word.i in seen:\n            continue\n        if word.dep in np_deps:\n            if any(w.i in seen for w in word.subtree):\n                continue\n            flag = False\n            if word.pos == NOUN:\n                #  check for patterns such as \u03b3\u03c1\u03b1\u03bc\u03bc\u03ae \u03c0\u03b1\u03c1\u03b1\u03b3\u03c9\u03b3\u03ae\u03c2\n                for potential_nmod in word.rights:\n                    if potential_nmod.dep == nmod:\n                        seen.update(\n                            j for j in range(word.left_edge.i, potential_nmod.i + 1)\n                        )\n                        yield word.left_edge.i, potential_nmod.i + 1, np_label\n                        flag = True\n                        break\n            if flag is False:\n                seen.update(j for j in range(word.left_edge.i, word.i + 1))\n                yield word.left_edge.i, word.i + 1, np_label\n        elif word.dep == conj:\n            # covers the case: \u03ad\u03c7\u03b5\u03b9 \u03cc\u03bc\u03bf\u03c1\u03c6\u03b1 \u03ba\u03b1\u03b9 \u03ad\u03be\u03c5\u03c0\u03bd\u03b1 \u03c0\u03b1\u03b9\u03b4\u03b9\u03ac\n            head = word.head\n            while head.dep == conj and head.head.i < head.i:\n                head = head.head\n            # If the head is an NP, and we're coordinated to it, we're an NP\n            if head.dep in np_deps:\n                if any(w.i in seen for w in word.subtree):\n                    continue\n                seen.update(j for j in range(word.left_edge.i, word.i + 1))\n                yield word.left_edge.i, word.i + 1, np_label"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_ext_args(**kwargs):\n    default = kwargs.get(\"default\")\n    getter = kwargs.get(\"getter\")\n    setter = kwargs.get(\"setter\")\n    method = kwargs.get(\"method\")\n    if getter is None and setter is not None:\n        raise ValueError(Errors.E089)\n    valid_opts = (\"default\" in kwargs, method is not None, getter is not None)\n    nr_defined = sum(t is True for t in valid_opts)\n    if nr_defined != 1:\n        raise ValueError(Errors.E083.format(nr_defined=nr_defined))\n    if setter is not None and not hasattr(setter, \"__call__\"):\n        raise ValueError(Errors.E091.format(name=\"setter\", value=repr(setter)))\n    if getter is not None and not hasattr(getter, \"__call__\"):\n        raise ValueError(Errors.E091.format(name=\"getter\", value=repr(getter)))\n    if method is not None and not hasattr(method, \"__call__\"):\n        raise ValueError(Errors.E091.format(name=\"method\", value=repr(method)))\n    return (default, method, getter, setter)", "response": "Validate and convert arguments. Reused in Doc Token and Span."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if an extension attribute is writable.", "response": "def is_writable_attr(ext):\n    \"\"\"Check if an extension attribute is writable.\n    ext (tuple): The (default, getter, setter, method) tuple available  via\n        {Doc,Span,Token}.get_extension.\n    RETURNS (bool): Whether the attribute is writable.\n    \"\"\"\n    default, method, getter, setter = ext\n    # Extension is writable if it has a setter (getter + setter), if it has a\n    # default value (or, if its default value is none, none of the other values\n    # should be set).\n    if setter is not None or default is not None or all(e is None for e in ext):\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_new_osx():\n    name = distutils.util.get_platform()\n    if sys.platform != \"darwin\":\n        return False\n    elif name.startswith(\"macosx-10\"):\n        minor_version = int(name.split(\"-\")[1].split(\".\")[1])\n        if minor_version >= 7:\n            return True\n        else:\n            return False\n    else:\n        return False", "response": "Check whether we re on OSX 10. 10."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn labels indicating the position of the word in the document.", "response": "def get_position_label(i, words, tags, heads, labels, ents):\n    \"\"\"Return labels indicating the position of the word in the document.\n    \"\"\"\n    if len(words) < 20:\n        return \"short-doc\"\n    elif i == 0:\n        return \"first-word\"\n    elif i < 10:\n        return \"early-word\"\n    elif i < 20:\n        return \"mid-word\"\n    elif i == len(words) - 1:\n        return \"last-word\"\n    else:\n        return \"late-word\""}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef download(model, direct=False, *pip_args):\n    dl_tpl = \"{m}-{v}/{m}-{v}.tar.gz#egg={m}=={v}\"\n    if direct:\n        components = model.split(\"-\")\n        model_name = \"\".join(components[:-1])\n        version = components[-1]\n        dl = download_model(dl_tpl.format(m=model_name, v=version), pip_args)\n    else:\n        shortcuts = get_json(about.__shortcuts__, \"available shortcuts\")\n        model_name = shortcuts.get(model, model)\n        compatibility = get_compatibility()\n        version = get_version(model_name, compatibility)\n        dl = download_model(dl_tpl.format(m=model_name, v=version), pip_args)\n        if dl != 0:  # if download subprocess doesn't return 0, exit\n            sys.exit(dl)\n        msg.good(\n            \"Download and installation successful\",\n            \"You can now load the model via spacy.load('{}')\".format(model_name),\n        )\n        # Only create symlink if the model is installed via a shortcut like 'en'.\n        # There's no real advantage over an additional symlink for en_core_web_sm\n        # and if anything, it's more error prone and causes more confusion.\n        if model in shortcuts:\n            try:\n                # Get package path here because link uses\n                # pip.get_installed_distributions() to check if model is a\n                # package, which fails if model was just installed via\n                # subprocess\n                package_path = get_package_path(model_name)\n                link(model_name, model, force=True, model_path=package_path)\n            except:  # noqa: E722\n                # Dirty, but since spacy.download and the auto-linking is\n                # mostly a convenience wrapper, it's best to show a success\n                # message and loading instructions, even if linking fails.\n                msg.warn(\n                    \"Download successful but linking failed\",\n                    \"Creating a shortcut link for '{}' didn't work (maybe you \"\n                    \"don't have admin permissions?), but you can still load \"\n                    \"the model via its full package name: \"\n                    \"nlp = spacy.load('{}')\".format(model, model_name),\n                )", "response": "Download compatible model from default download path using pip."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a single file into a JSON file.", "response": "def convert(\n    input_file,\n    output_dir=\"-\",\n    file_type=\"json\",\n    n_sents=1,\n    morphology=False,\n    converter=\"auto\",\n    lang=None,\n):\n    \"\"\"\n    Convert files into JSON format for use with train command and other\n    experiment management functions. If no output_dir is specified, the data\n    is written to stdout, so you can pipe them forward to a JSON file:\n    $ spacy convert some_file.conllu > some_file.json\n    \"\"\"\n    msg = Printer()\n    input_path = Path(input_file)\n    if file_type not in FILE_TYPES:\n        msg.fail(\n            \"Unknown file type: '{}'\".format(file_type),\n            \"Supported file types: '{}'\".format(\", \".join(FILE_TYPES)),\n            exits=1,\n        )\n    if file_type not in FILE_TYPES_STDOUT and output_dir == \"-\":\n        # TODO: support msgpack via stdout in srsly?\n        msg.fail(\n            \"Can't write .{} data to stdout.\".format(file_type),\n            \"Please specify an output directory.\",\n            exits=1,\n        )\n    if not input_path.exists():\n        msg.fail(\"Input file not found\", input_path, exits=1)\n    if output_dir != \"-\" and not Path(output_dir).exists():\n        msg.fail(\"Output directory not found\", output_dir, exits=1)\n    if converter == \"auto\":\n        converter = input_path.suffix[1:]\n    if converter not in CONVERTERS:\n        msg.fail(\"Can't find converter for {}\".format(converter), exits=1)\n    # Use converter function to convert data\n    func = CONVERTERS[converter]\n    input_data = input_path.open(\"r\", encoding=\"utf-8\").read()\n    data = func(input_data, n_sents=n_sents, use_morphology=morphology, lang=lang)\n    if output_dir != \"-\":\n        # Export data to a file\n        suffix = \".{}\".format(file_type)\n        output_file = Path(output_dir) / Path(input_path.parts[-1]).with_suffix(suffix)\n        if file_type == \"json\":\n            srsly.write_json(output_file, data)\n        elif file_type == \"jsonl\":\n            srsly.write_jsonl(output_file, data)\n        elif file_type == \"msg\":\n            srsly.write_msgpack(output_file, data)\n        msg.good(\"Generated output file ({} documents)\".format(len(data)), output_file)\n    else:\n        # Print to stdout\n        if file_type == \"json\":\n            srsly.write_json(\"-\", data)\n        elif file_type == \"jsonl\":\n            srsly.write_jsonl(\"-\", data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads a specific spaCy model", "response": "def load_model(modelname, add_sentencizer=False):\n    \"\"\" Load a specific spaCy model \"\"\"\n    loading_start = time.time()\n    nlp = spacy.load(modelname)\n    if add_sentencizer:\n        nlp.add_pipe(nlp.create_pipe('sentencizer'))\n    loading_end = time.time()\n    loading_time = loading_end - loading_start\n    if add_sentencizer:\n        return nlp, loading_time, modelname + '_sentencizer'\n    return nlp, loading_time, modelname"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_default_model_sentencizer(lang):\n    loading_start = time.time()\n    lang_class = get_lang_class(lang)\n    nlp = lang_class()\n    nlp.add_pipe(nlp.create_pipe('sentencizer'))\n    loading_end = time.time()\n    loading_time = loading_end - loading_start\n    return nlp, loading_time, lang + \"_default_\" + 'sentencizer'", "response": "Load a generic spaCy model and add the sentencizer for sentence tokenization"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nturning a list of errors into frequency - sorted tuples thresholded by a certain total number", "response": "def get_freq_tuples(my_list, print_total_threshold):\n    \"\"\" Turn a list of errors into frequency-sorted tuples thresholded by a certain total number \"\"\"\n    d = {}\n    for token in my_list:\n        d.setdefault(token, 0)\n        d[token] += 1\n    return sorted(d.items(), key=operator.itemgetter(1), reverse=True)[:print_total_threshold]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _contains_blinded_text(stats_xml):\n    tree = ET.parse(stats_xml)\n    root = tree.getroot()\n    total_tokens = int(root.find('size/total/tokens').text)\n    unique_lemmas = int(root.find('lemmas').get('unique'))\n\n    # assume the corpus is largely blinded when there are less than 1% unique tokens\n    return (unique_lemmas / total_tokens) < 0.01", "response": "Heuristic to determine whether the treebank contains blinded texts"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch_all_treebanks(ud_dir, languages, corpus, best_per_language):\n    all_treebanks = dict()\n    treebank_size = dict()\n    for l in languages:\n        all_treebanks[l] = []\n        treebank_size[l] = 0\n\n    for treebank_dir in ud_dir.iterdir():\n        if treebank_dir.is_dir():\n            for txt_path in treebank_dir.iterdir():\n                if txt_path.name.endswith('-ud-' + corpus + '.txt'):\n                    file_lang = txt_path.name.split('_')[0]\n                    if file_lang in languages:\n                        gold_path = treebank_dir / txt_path.name.replace('.txt', '.conllu')\n                        stats_xml = treebank_dir / \"stats.xml\"\n                        # ignore treebanks where the texts are not publicly available\n                        if not _contains_blinded_text(stats_xml):\n                            if not best_per_language:\n                                all_treebanks[file_lang].append(txt_path)\n                            # check the tokens in the gold annotation to keep only the biggest treebank per language\n                            else:\n                                with gold_path.open(mode='r', encoding='utf-8') as gold_file:\n                                    gold_ud = conll17_ud_eval.load_conllu(gold_file)\n                                    gold_tokens = len(gold_ud.tokens)\n                                if treebank_size[file_lang] < gold_tokens:\n                                    all_treebanks[file_lang] = [txt_path]\n                                    treebank_size[file_lang] = gold_tokens\n\n    return all_treebanks", "response": "Fetch the txt files for all treebanks for a given set of languages"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning an evaluation of a model nlp on a certain treebank.", "response": "def run_single_eval(nlp, loading_time, print_name, text_path, gold_ud, tmp_output_path, out_file, print_header,\n                    check_parse, print_freq_tasks):\n    \"\"\"\" Run an evaluation of a model nlp on a certain specified treebank \"\"\"\n    with text_path.open(mode='r', encoding='utf-8') as f:\n        flat_text = f.read()\n\n    # STEP 1: tokenize text\n    tokenization_start = time.time()\n    texts = split_text(flat_text)\n    docs = list(nlp.pipe(texts))\n    tokenization_end = time.time()\n    tokenization_time = tokenization_end - tokenization_start\n\n    # STEP 2: record stats and timings\n    tokens_per_s = int(len(gold_ud.tokens) / tokenization_time)\n\n    print_header_1 = ['date', 'text_path', 'gold_tokens', 'model', 'loading_time', 'tokenization_time', 'tokens_per_s']\n    print_string_1 = [str(datetime.date.today()), text_path.name, len(gold_ud.tokens),\n                      print_name, \"%.2f\" % loading_time, \"%.2f\" % tokenization_time, tokens_per_s]\n\n    # STEP 3: evaluate predicted tokens and features\n    with tmp_output_path.open(mode=\"w\", encoding=\"utf8\") as tmp_out_file:\n        write_conllu(docs, tmp_out_file)\n    with tmp_output_path.open(mode=\"r\", encoding=\"utf8\") as sys_file:\n        sys_ud = conll17_ud_eval.load_conllu(sys_file, check_parse=check_parse)\n    tmp_output_path.unlink()\n    scores = conll17_ud_eval.evaluate(gold_ud, sys_ud, check_parse=check_parse)\n\n    # STEP 4: format the scoring results\n    eval_headers = EVAL_PARSE\n    if not check_parse:\n        eval_headers = EVAL_NO_PARSE\n\n    for score_name in eval_headers:\n        score = scores[score_name]\n        print_string_1.extend([\"%.2f\" % score.precision,\n                               \"%.2f\" % score.recall,\n                               \"%.2f\" % score.f1])\n        print_string_1.append(\"-\" if score.aligned_accuracy is None else \"%.2f\" % score.aligned_accuracy)\n        print_string_1.append(\"-\" if score.undersegmented is None else \"%.4f\" % score.under_perc)\n        print_string_1.append(\"-\" if score.oversegmented is None else \"%.4f\" % score.over_perc)\n\n        print_header_1.extend([score_name + '_p', score_name + '_r', score_name + '_F', score_name + '_acc',\n                               score_name + '_under', score_name + '_over'])\n\n        if score_name in print_freq_tasks:\n            print_header_1.extend([score_name + '_word_under_ex', score_name + '_shape_under_ex',\n                                   score_name + '_word_over_ex', score_name + '_shape_over_ex'])\n\n            d_under_words = get_freq_tuples(score.undersegmented, PRINT_TOTAL)\n            d_under_shapes = get_freq_tuples([word_shape(x) for x in score.undersegmented], PRINT_TOTAL)\n            d_over_words = get_freq_tuples(score.oversegmented, PRINT_TOTAL)\n            d_over_shapes = get_freq_tuples([word_shape(x) for x in score.oversegmented], PRINT_TOTAL)\n\n            # saving to CSV with ; seperator so blinding ; in the example output\n            print_string_1.append(\n                str({k: v for k, v in d_under_words if v > PRINT_FREQ}).replace(\";\", \"*SEMICOLON*\"))\n            print_string_1.append(\n                str({k: v for k, v in d_under_shapes if v > PRINT_FREQ}).replace(\";\", \"*SEMICOLON*\"))\n            print_string_1.append(\n                str({k: v for k, v in d_over_words if v > PRINT_FREQ}).replace(\";\", \"*SEMICOLON*\"))\n            print_string_1.append(\n                str({k: v for k, v in d_over_shapes if v > PRINT_FREQ}).replace(\";\", \"*SEMICOLON*\"))\n\n    # STEP 5: print the formatted results to CSV\n    if print_header:\n        out_file.write(';'.join(map(str, print_header_1)) + '\\n')\n    out_file.write(';'.join(map(str, print_string_1)) + '\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_all_evals(models, treebanks, out_file, check_parse, print_freq_tasks):\n    print_header = True\n\n    for tb_lang, treebank_list in treebanks.items():\n        print()\n        print(\"Language\", tb_lang)\n        for text_path in treebank_list:\n            print(\" Evaluating on\", text_path)\n\n            gold_path = text_path.parent / (text_path.stem + '.conllu')\n            print(\"  Gold data from \", gold_path)\n\n            # nested try blocks to ensure the code can continue with the next iteration after a failure\n            try:\n                with gold_path.open(mode='r', encoding='utf-8') as gold_file:\n                    gold_ud = conll17_ud_eval.load_conllu(gold_file)\n\n                for nlp, nlp_loading_time, nlp_name in models[tb_lang]:\n                    try:\n                        print(\"   Benchmarking\", nlp_name)\n                        tmp_output_path = text_path.parent / str('tmp_' + nlp_name + '.conllu')\n                        run_single_eval(nlp, nlp_loading_time, nlp_name, text_path, gold_ud, tmp_output_path, out_file,\n                                        print_header, check_parse, print_freq_tasks)\n                        print_header = False\n                    except Exception as e:\n                        print(\"    Ran into trouble: \", str(e))\n            except Exception as e:\n                print(\"   Ran into trouble: \", str(e))", "response": "Run an evaluation for each language with its specified models and treebanks."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main(out_path, ud_dir, check_parse=False, langs=ALL_LANGUAGES, exclude_trained_models=False, exclude_multi=False,\n         hide_freq=False, corpus='train', best_per_language=False):\n    \"\"\"\"\n    Assemble all treebanks and models to run evaluations with.\n    When setting check_parse to True, the default models will not be evaluated as they don't have parsing functionality\n    \"\"\"\n    languages = [lang.strip() for lang in langs.split(\",\")]\n\n    print_freq_tasks = []\n    if not hide_freq:\n        print_freq_tasks = ['Tokens']\n\n    # fetching all relevant treebank from the directory\n    treebanks = fetch_all_treebanks(ud_dir, languages, corpus, best_per_language)\n\n    print()\n    print(\"Loading all relevant models for\", languages)\n    models = dict()\n\n    # multi-lang model\n    multi = None\n    if not exclude_multi and not check_parse:\n        multi = load_model('xx_ent_wiki_sm', add_sentencizer=True)\n\n    # initialize all models with the multi-lang model\n    for lang in languages:\n        models[lang] = [multi] if multi else []\n        # add default models if we don't want to evaluate parsing info\n        if not check_parse:\n            # Norwegian is 'nb' in spaCy but 'no' in the UD corpora\n            if lang == 'no':\n                models['no'].append(load_default_model_sentencizer('nb'))\n            else:\n                models[lang].append(load_default_model_sentencizer(lang))\n\n    # language-specific trained models\n    if not exclude_trained_models:\n        if 'de' in models:\n            models['de'].append(load_model('de_core_news_sm'))\n        if 'es' in models:\n            models['es'].append(load_model('es_core_news_sm'))\n            models['es'].append(load_model('es_core_news_md'))\n        if 'pt' in models:\n            models['pt'].append(load_model('pt_core_news_sm'))\n        if 'it' in models:\n            models['it'].append(load_model('it_core_news_sm'))\n        if 'nl' in models:\n            models['nl'].append(load_model('nl_core_news_sm'))\n        if 'en' in models:\n            models['en'].append(load_model('en_core_web_sm'))\n            models['en'].append(load_model('en_core_web_md'))\n            models['en'].append(load_model('en_core_web_lg'))\n        if 'fr' in models:\n            models['fr'].append(load_model('fr_core_news_sm'))\n            models['fr'].append(load_model('fr_core_news_md'))\n\n    with out_path.open(mode='w', encoding='utf-8') as out_file:\n        run_all_evals(models, treebanks, out_file, check_parse, print_freq_tasks)", "response": "Assemble all treebanks and models to run evaluations with."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetects base noun phrases from a dependency parse. Works on both Doc and Span.", "response": "def noun_chunks(obj):\n    \"\"\"\n    Detect base noun phrases from a dependency parse. Works on both Doc and Span.\n    \"\"\"\n    # this iterator extracts spans headed by NOUNs starting from the left-most\n    # syntactic dependent until the NOUN itself for close apposition and\n    # measurement construction, the span is sometimes extended to the right of\n    # the NOUN. Example: \"eine Tasse Tee\" (a cup (of) tea) returns \"eine Tasse Tee\"\n    # and not just \"eine Tasse\", same for \"das Thema Familie\".\n    labels = [\n        \"sb\",\n        \"oa\",\n        \"da\",\n        \"nk\",\n        \"mo\",\n        \"ag\",\n        \"ROOT\",\n        \"root\",\n        \"cj\",\n        \"pd\",\n        \"og\",\n        \"app\",\n    ]\n    doc = obj.doc  # Ensure works on both Doc and Span.\n    np_label = doc.vocab.strings.add(\"NP\")\n    np_deps = set(doc.vocab.strings.add(label) for label in labels)\n    close_app = doc.vocab.strings.add(\"nk\")\n\n    rbracket = 0\n    for i, word in enumerate(obj):\n        if i < rbracket:\n            continue\n        if word.pos in (NOUN, PROPN, PRON) and word.dep in np_deps:\n            rbracket = word.i + 1\n            # try to extend the span to the right\n            # to capture close apposition/measurement constructions\n            for rdep in doc[word.i].rights:\n                if rdep.pos in (NOUN, PROPN) and rdep.dep == close_app:\n                    rbracket = rdep.i + 1\n            yield word.left_edge.i, rbracket, np_label"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap a model that should run on CPU transferring inputs and outputs as necessary.", "response": "def with_cpu(ops, model):\n    \"\"\"Wrap a model that should run on CPU, transferring inputs and outputs\n    as necessary.\"\"\"\n    model.to_cpu()\n\n    def with_cpu_forward(inputs, drop=0.0):\n        cpu_outputs, backprop = model.begin_update(_to_cpu(inputs), drop=drop)\n        gpu_outputs = _to_device(ops, cpu_outputs)\n\n        def with_cpu_backprop(d_outputs, sgd=None):\n            cpu_d_outputs = _to_cpu(d_outputs)\n            return backprop(cpu_d_outputs, sgd=sgd)\n\n        return gpu_outputs, with_cpu_backprop\n\n    return wrap(with_cpu_forward, model)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a simple CNN text classifier given a token - to - vector model as inputs.", "response": "def build_simple_cnn_text_classifier(tok2vec, nr_class, exclusive_classes=False, **cfg):\n    \"\"\"\n    Build a simple CNN text classifier, given a token-to-vector model as inputs.\n    If exclusive_classes=True, a softmax non-linearity is applied, so that the\n    outputs sum to 1. If exclusive_classes=False, a logistic non-linearity\n    is applied instead, so that outputs are in the range [0, 1].\n    \"\"\"\n    with Model.define_operators({\">>\": chain}):\n        if exclusive_classes:\n            output_layer = Softmax(nr_class, tok2vec.nO)\n        else:\n            output_layer = (\n                zero_init(Affine(nr_class, tok2vec.nO, drop_factor=0.0)) >> logistic\n            )\n        model = tok2vec >> flatten_add_lengths >> Pooling(mean_pool) >> output_layer\n    model.tok2vec = chain(tok2vec, flatten)\n    model.nO = nr_class\n    return model"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef concatenate_lists(*layers, **kwargs):  # pragma: no cover\n    if not layers:\n        return noop()\n    drop_factor = kwargs.get(\"drop_factor\", 1.0)\n    ops = layers[0].ops\n    layers = [chain(layer, flatten) for layer in layers]\n    concat = concatenate(*layers)\n\n    def concatenate_lists_fwd(Xs, drop=0.0):\n        drop *= drop_factor\n        lengths = ops.asarray([len(X) for X in Xs], dtype=\"i\")\n        flat_y, bp_flat_y = concat.begin_update(Xs, drop=drop)\n        ys = ops.unflatten(flat_y, lengths)\n\n        def concatenate_lists_bwd(d_ys, sgd=None):\n            return bp_flat_y(ops.flatten(d_ys), sgd=sgd)\n\n        return ys, concatenate_lists_bwd\n\n    model = wrap(concatenate_lists_fwd, concat)\n    return model", "response": "Compose two or more models f g etc. such that their outputs are concatenated i. e. f g x computes hstack ( f g x ) computes hstack ( f g x ) computes hstack ( f g x ) computes hstack ( f g x ) computes hstack ( f g x ) computes hstack ( f g x ) computes hstack ( f g x ) computes hstack ( f g x ) computes hstack ( f g x ) computes hstack ( x g x"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef masked_language_model(vocab, model, mask_prob=0.15):\n\n    random_words = _RandomWords(vocab)\n\n    def mlm_forward(docs, drop=0.0):\n        mask, docs = _apply_mask(docs, random_words, mask_prob=mask_prob)\n        mask = model.ops.asarray(mask).reshape((mask.shape[0], 1))\n        output, backprop = model.begin_update(docs, drop=drop)\n\n        def mlm_backward(d_output, sgd=None):\n            d_output *= 1 - mask\n            return backprop(d_output, sgd=sgd)\n\n        return output, mlm_backward\n\n    return wrap(mlm_forward, model)", "response": "Convert a model into a BERT - style masked language model"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef begin_training(self, _=tuple(), pipeline=None, sgd=None, **kwargs):\n        if self.model is True:\n            self.model = self.Model(pipeline[0].model.nO)\n            link_vectors_to_models(self.vocab)\n        if sgd is None:\n            sgd = self.create_optimizer()\n        return sgd", "response": "Allocate model using width from tensorizer in pipeline."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render(self, parsed, page=False, minify=False):\n        # Create a random ID prefix to make sure parses don't receive the\n        # same ID, even if they're identical\n        id_prefix = uuid.uuid4().hex\n        rendered = []\n        for i, p in enumerate(parsed):\n            if i == 0:\n                settings = p.get(\"settings\", {})\n                self.direction = settings.get(\"direction\", DEFAULT_DIR)\n                self.lang = settings.get(\"lang\", DEFAULT_LANG)\n            render_id = \"{}-{}\".format(id_prefix, i)\n            svg = self.render_svg(render_id, p[\"words\"], p[\"arcs\"])\n            rendered.append(svg)\n        if page:\n            content = \"\".join([TPL_FIGURE.format(content=svg) for svg in rendered])\n            markup = TPL_PAGE.format(\n                content=content, lang=self.lang, dir=self.direction\n            )\n        else:\n            markup = \"\".join(rendered)\n        if minify:\n            return minify_html(markup)\n        return markup", "response": "Render complete markup.\n\n        parsed (list): Dependency parses to render.\n        page (bool): Render parses wrapped as full HTML page.\n        minify (bool): Minify HTML markup.\n        RETURNS (unicode): Rendered SVG or HTML markup."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrendering SVG. render_id (int): Unique ID, typically index of document. words (list): Individual words and their tags. arcs (list): Individual arcs and their start, end, direction and label. RETURNS (unicode): Rendered SVG markup.", "response": "def render_svg(self, render_id, words, arcs):\n        \"\"\"Render SVG.\n\n        render_id (int): Unique ID, typically index of document.\n        words (list): Individual words and their tags.\n        arcs (list): Individual arcs and their start, end, direction and label.\n        RETURNS (unicode): Rendered SVG markup.\n        \"\"\"\n        self.levels = self.get_levels(arcs)\n        self.highest_level = len(self.levels)\n        self.offset_y = self.distance / 2 * self.highest_level + self.arrow_stroke\n        self.width = self.offset_x + len(words) * self.distance\n        self.height = self.offset_y + 3 * self.word_spacing\n        self.id = render_id\n        words = [self.render_word(w[\"text\"], w[\"tag\"], i) for i, w in enumerate(words)]\n        arcs = [\n            self.render_arrow(a[\"label\"], a[\"start\"], a[\"end\"], a[\"dir\"], i)\n            for i, a in enumerate(arcs)\n        ]\n        content = \"\".join(words) + \"\".join(arcs)\n        return TPL_DEP_SVG.format(\n            id=self.id,\n            width=self.width,\n            height=self.height,\n            color=self.color,\n            bg=self.bg,\n            font=self.font,\n            content=content,\n            dir=self.direction,\n            lang=self.lang,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render_word(self, text, tag, i):\n        y = self.offset_y + self.word_spacing\n        x = self.offset_x + i * self.distance\n        if self.direction == \"rtl\":\n            x = self.width - x\n        html_text = escape_html(text)\n        return TPL_DEP_WORDS.format(text=html_text, tag=tag, x=x, y=y)", "response": "Render individual word.\n\n        text (unicode): Word text.\n        tag (unicode): Part-of-speech tag.\n        i (int): Unique ID, typically word index.\n        RETURNS (unicode): Rendered SVG markup."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render_arrow(self, label, start, end, direction, i):\n        level = self.levels.index(end - start) + 1\n        x_start = self.offset_x + start * self.distance + self.arrow_spacing\n        if self.direction == \"rtl\":\n            x_start = self.width - x_start\n        y = self.offset_y\n        x_end = (\n            self.offset_x\n            + (end - start) * self.distance\n            + start * self.distance\n            - self.arrow_spacing * (self.highest_level - level) / 4\n        )\n        if self.direction == \"rtl\":\n            x_end = self.width - x_end\n        y_curve = self.offset_y - level * self.distance / 2\n        if self.compact:\n            y_curve = self.offset_y - level * self.distance / 6\n        if y_curve == 0 and len(self.levels) > 5:\n            y_curve = -self.distance\n        arrowhead = self.get_arrowhead(direction, x_start, y, x_end)\n        arc = self.get_arc(x_start, y, y_curve, x_end)\n        label_side = \"right\" if self.direction == \"rtl\" else \"left\"\n        return TPL_DEP_ARCS.format(\n            id=self.id,\n            i=i,\n            stroke=self.arrow_stroke,\n            head=arrowhead,\n            label=label,\n            label_side=label_side,\n            arc=arc,\n        )", "response": "Render individual arrow.\n\n        label (unicode): Dependency label.\n        start (int): Index of start word.\n        end (int): Index of end word.\n        direction (unicode): Arrow direction, 'left' or 'right'.\n        i (int): Unique ID, typically arrow index.\n        RETURNS (unicode): Rendered SVG markup."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrendering individual arc. x_start (int): X-coordinate of arrow start point. y (int): Y-coordinate of arrow start and end point. y_curve (int): Y-corrdinate of Cubic B\u00e9zier y_curve point. x_end (int): X-coordinate of arrow end point. RETURNS (unicode): Definition of the arc path ('d' attribute).", "response": "def get_arc(self, x_start, y, y_curve, x_end):\n        \"\"\"Render individual arc.\n\n        x_start (int): X-coordinate of arrow start point.\n        y (int): Y-coordinate of arrow start and end point.\n        y_curve (int): Y-corrdinate of Cubic B\u00e9zier y_curve point.\n        x_end (int): X-coordinate of arrow end point.\n        RETURNS (unicode): Definition of the arc path ('d' attribute).\n        \"\"\"\n        template = \"M{x},{y} C{x},{c} {e},{c} {e},{y}\"\n        if self.compact:\n            template = \"M{x},{y} {x},{c} {e},{c} {e},{y}\"\n        return template.format(x=x_start, y=y, c=y_curve, e=x_end)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrender individual arrow head.", "response": "def get_arrowhead(self, direction, x, y, end):\n        \"\"\"Render individual arrow head.\n\n        direction (unicode): Arrow direction, 'left' or 'right'.\n        x (int): X-coordinate of arrow start point.\n        y (int): Y-coordinate of arrow start and end point.\n        end (int): X-coordinate of arrow end point.\n        RETURNS (unicode): Definition of the arrow head path ('d' attribute).\n        \"\"\"\n        if direction == \"left\":\n            pos1, pos2, pos3 = (x, x - self.arrow_width + 2, x + self.arrow_width - 2)\n        else:\n            pos1, pos2, pos3 = (\n                end,\n                end + self.arrow_width - 2,\n                end - self.arrow_width + 2,\n            )\n        arrowhead = (\n            pos1,\n            y + 2,\n            pos2,\n            y - self.arrow_width,\n            pos3,\n            y - self.arrow_width,\n        )\n        return \"M{},{} L{},{} {},{}\".format(*arrowhead)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_levels(self, arcs):\n        levels = set(map(lambda arc: arc[\"end\"] - arc[\"start\"], arcs))\n        return sorted(list(levels))", "response": "Calculate available arc height levels."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render(self, parsed, page=False, minify=False):\n        rendered = []\n        for i, p in enumerate(parsed):\n            if i == 0:\n                settings = p.get(\"settings\", {})\n                self.direction = settings.get(\"direction\", DEFAULT_DIR)\n                self.lang = settings.get(\"lang\", DEFAULT_LANG)\n            rendered.append(self.render_ents(p[\"text\"], p[\"ents\"], p.get(\"title\")))\n        if page:\n            docs = \"\".join([TPL_FIGURE.format(content=doc) for doc in rendered])\n            markup = TPL_PAGE.format(content=docs, lang=self.lang, dir=self.direction)\n        else:\n            markup = \"\".join(rendered)\n        if minify:\n            return minify_html(markup)\n        return markup", "response": "Render complete markup.\n\n        parsed (list): Dependency parses to render.\n        page (bool): Render parses wrapped as full HTML page.\n        minify (bool): Minify HTML markup.\n        RETURNS (unicode): Rendered HTML markup."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrenders entities in text.", "response": "def render_ents(self, text, spans, title):\n        \"\"\"Render entities in text.\n\n        text (unicode): Original text.\n        spans (list): Individual entity spans and their start, end and label.\n        title (unicode or None): Document title set in Doc.user_data['title'].\n        \"\"\"\n        markup = \"\"\n        offset = 0\n        for span in spans:\n            label = span[\"label\"]\n            start = span[\"start\"]\n            end = span[\"end\"]\n            entity = escape_html(text[start:end])\n            fragments = text[offset:start].split(\"\\n\")\n            for i, fragment in enumerate(fragments):\n                markup += escape_html(fragment)\n                if len(fragments) > 1 and i != len(fragments) - 1:\n                    markup += \"</br>\"\n            if self.ents is None or label.upper() in self.ents:\n                color = self.colors.get(label.upper(), self.default_color)\n                ent_settings = {\"label\": label, \"text\": entity, \"bg\": color}\n                if self.direction == \"rtl\":\n                    markup += TPL_ENT_RTL.format(**ent_settings)\n                else:\n                    markup += TPL_ENT.format(**ent_settings)\n            else:\n                markup += entity\n            offset = end\n        markup += escape_html(text[offset:])\n        markup = TPL_ENTS.format(content=markup, dir=self.direction)\n        if title:\n            markup = TPL_TITLE.format(title=title) + markup\n        return markup"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef merge_noun_chunks(doc):\n    if not doc.is_parsed:\n        return doc\n    with doc.retokenize() as retokenizer:\n        for np in doc.noun_chunks:\n            attrs = {\"tag\": np.root.tag, \"dep\": np.root.dep}\n            retokenizer.merge(np, attrs=attrs)\n    return doc", "response": "Merge noun chunks into a single token."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merge_entities(doc):\n    with doc.retokenize() as retokenizer:\n        for ent in doc.ents:\n            attrs = {\"tag\": ent.root.tag, \"dep\": ent.root.dep, \"ent_type\": ent.label}\n            retokenizer.merge(ent, attrs=attrs)\n    return doc", "response": "Merge entities into a single token."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef merge_subtokens(doc, label=\"subtok\"):\n    merger = Matcher(doc.vocab)\n    merger.add(\"SUBTOK\", None, [{\"DEP\": label, \"op\": \"+\"}])\n    matches = merger(doc)\n    spans = [doc[start : end + 1] for _, start, end in matches]\n    with doc.retokenize() as retokenizer:\n        for span in spans:\n            retokenizer.merge(span)\n    return doc", "response": "Merge subtokens into a single token."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntrain a spaCy model.", "response": "def train(\n    lang,\n    output_path,\n    train_path,\n    dev_path,\n    raw_text=None,\n    base_model=None,\n    pipeline=\"tagger,parser,ner\",\n    vectors=None,\n    n_iter=30,\n    n_early_stopping=None,\n    n_examples=0,\n    use_gpu=-1,\n    version=\"0.0.0\",\n    meta_path=None,\n    init_tok2vec=None,\n    parser_multitasks=\"\",\n    entity_multitasks=\"\",\n    noise_level=0.0,\n    eval_beam_widths=\"\",\n    gold_preproc=False,\n    learn_tokens=False,\n    verbose=False,\n    debug=False,\n):\n    \"\"\"\n    Train or update a spaCy model. Requires data to be formatted in spaCy's\n    JSON format. To convert data from other formats, use the `spacy convert`\n    command.\n    \"\"\"\n    msg = Printer()\n    util.fix_random_seed()\n    util.set_env_log(verbose)\n\n    # Make sure all files and paths exists if they are needed\n    train_path = util.ensure_path(train_path)\n    dev_path = util.ensure_path(dev_path)\n    meta_path = util.ensure_path(meta_path)\n    output_path = util.ensure_path(output_path)\n    if raw_text is not None:\n        raw_text = list(srsly.read_jsonl(raw_text))\n    if not train_path or not train_path.exists():\n        msg.fail(\"Training data not found\", train_path, exits=1)\n    if not dev_path or not dev_path.exists():\n        msg.fail(\"Development data not found\", dev_path, exits=1)\n    if meta_path is not None and not meta_path.exists():\n        msg.fail(\"Can't find model meta.json\", meta_path, exits=1)\n    meta = srsly.read_json(meta_path) if meta_path else {}\n    if output_path.exists() and [p for p in output_path.iterdir() if p.is_dir()]:\n        msg.warn(\n            \"Output directory is not empty\",\n            \"This can lead to unintended side effects when saving the model. \"\n            \"Please use an empty directory or a different path instead. If \"\n            \"the specified output path doesn't exist, the directory will be \"\n            \"created for you.\",\n        )\n    if not output_path.exists():\n        output_path.mkdir()\n\n    # Take dropout and batch size as generators of values -- dropout\n    # starts high and decays sharply, to force the optimizer to explore.\n    # Batch size starts at 1 and grows, so that we make updates quickly\n    # at the beginning of training.\n    dropout_rates = util.decaying(\n        util.env_opt(\"dropout_from\", 0.2),\n        util.env_opt(\"dropout_to\", 0.2),\n        util.env_opt(\"dropout_decay\", 0.0),\n    )\n    batch_sizes = util.compounding(\n        util.env_opt(\"batch_from\", 100.0),\n        util.env_opt(\"batch_to\", 1000.0),\n        util.env_opt(\"batch_compound\", 1.001),\n    )\n\n    if not eval_beam_widths:\n        eval_beam_widths = [1]\n    else:\n        eval_beam_widths = [int(bw) for bw in eval_beam_widths.split(\",\")]\n        if 1 not in eval_beam_widths:\n            eval_beam_widths.append(1)\n        eval_beam_widths.sort()\n    has_beam_widths = eval_beam_widths != [1]\n\n    # Set up the base model and pipeline. If a base model is specified, load\n    # the model and make sure the pipeline matches the pipeline setting. If\n    # training starts from a blank model, intitalize the language class.\n    pipeline = [p.strip() for p in pipeline.split(\",\")]\n    msg.text(\"Training pipeline: {}\".format(pipeline))\n    if base_model:\n        msg.text(\"Starting with base model '{}'\".format(base_model))\n        nlp = util.load_model(base_model)\n        if nlp.lang != lang:\n            msg.fail(\n                \"Model language ('{}') doesn't match language specified as \"\n                \"`lang` argument ('{}') \".format(nlp.lang, lang),\n                exits=1,\n            )\n        other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipeline]\n        nlp.disable_pipes(*other_pipes)\n        for pipe in pipeline:\n            if pipe not in nlp.pipe_names:\n                nlp.add_pipe(nlp.create_pipe(pipe))\n    else:\n        msg.text(\"Starting with blank model '{}'\".format(lang))\n        lang_cls = util.get_lang_class(lang)\n        nlp = lang_cls()\n        for pipe in pipeline:\n            nlp.add_pipe(nlp.create_pipe(pipe))\n\n    if learn_tokens:\n        nlp.add_pipe(nlp.create_pipe(\"merge_subtokens\"))\n\n    if vectors:\n        msg.text(\"Loading vector from model '{}'\".format(vectors))\n        _load_vectors(nlp, vectors)\n\n    # Multitask objectives\n    multitask_options = [(\"parser\", parser_multitasks), (\"ner\", entity_multitasks)]\n    for pipe_name, multitasks in multitask_options:\n        if multitasks:\n            if pipe_name not in pipeline:\n                msg.fail(\n                    \"Can't use multitask objective without '{}' in the \"\n                    \"pipeline\".format(pipe_name)\n                )\n            pipe = nlp.get_pipe(pipe_name)\n            for objective in multitasks.split(\",\"):\n                pipe.add_multitask_objective(objective)\n\n    # Prepare training corpus\n    msg.text(\"Counting training words (limit={})\".format(n_examples))\n    corpus = GoldCorpus(train_path, dev_path, limit=n_examples)\n    n_train_words = corpus.count_train()\n\n    if base_model:\n        # Start with an existing model, use default optimizer\n        optimizer = create_default_optimizer(Model.ops)\n    else:\n        # Start with a blank model, call begin_training\n        optimizer = nlp.begin_training(lambda: corpus.train_tuples, device=use_gpu)\n\n    nlp._optimizer = None\n\n    # Load in pre-trained weights\n    if init_tok2vec is not None:\n        components = _load_pretrained_tok2vec(nlp, init_tok2vec)\n        msg.text(\"Loaded pretrained tok2vec for: {}\".format(components))\n\n    # fmt: off\n    row_head = [\"Itn\", \"Dep Loss\", \"NER Loss\", \"UAS\", \"NER P\", \"NER R\", \"NER F\", \"Tag %\", \"Token %\", \"CPU WPS\", \"GPU WPS\"]\n    row_widths = [3, 10, 10, 7, 7, 7, 7, 7, 7, 7, 7]\n    if has_beam_widths:\n        row_head.insert(1, \"Beam W.\")\n        row_widths.insert(1, 7)\n    row_settings = {\"widths\": row_widths, \"aligns\": tuple([\"r\" for i in row_head]), \"spacing\": 2}\n    # fmt: on\n    print(\"\")\n    msg.row(row_head, **row_settings)\n    msg.row([\"-\" * width for width in row_settings[\"widths\"]], **row_settings)\n    try:\n        iter_since_best = 0\n        best_score = 0.0\n        for i in range(n_iter):\n            train_docs = corpus.train_docs(\n                nlp, noise_level=noise_level, gold_preproc=gold_preproc, max_length=0\n            )\n            if raw_text:\n                random.shuffle(raw_text)\n                raw_batches = util.minibatch(\n                    (nlp.make_doc(rt[\"text\"]) for rt in raw_text), size=8\n                )\n            words_seen = 0\n            with tqdm.tqdm(total=n_train_words, leave=False) as pbar:\n                losses = {}\n                for batch in util.minibatch_by_words(train_docs, size=batch_sizes):\n                    if not batch:\n                        continue\n                    docs, golds = zip(*batch)\n                    nlp.update(\n                        docs,\n                        golds,\n                        sgd=optimizer,\n                        drop=next(dropout_rates),\n                        losses=losses,\n                    )\n                    if raw_text:\n                        # If raw text is available, perform 'rehearsal' updates,\n                        # which use unlabelled data to reduce overfitting.\n                        raw_batch = list(next(raw_batches))\n                        nlp.rehearse(raw_batch, sgd=optimizer, losses=losses)\n                    if not int(os.environ.get(\"LOG_FRIENDLY\", 0)):\n                        pbar.update(sum(len(doc) for doc in docs))\n                    words_seen += sum(len(doc) for doc in docs)\n            with nlp.use_params(optimizer.averages):\n                util.set_env_log(False)\n                epoch_model_path = output_path / (\"model%d\" % i)\n                nlp.to_disk(epoch_model_path)\n                nlp_loaded = util.load_model_from_path(epoch_model_path)\n                for beam_width in eval_beam_widths:\n                    for name, component in nlp_loaded.pipeline:\n                        if hasattr(component, \"cfg\"):\n                            component.cfg[\"beam_width\"] = beam_width\n                    dev_docs = list(\n                        corpus.dev_docs(nlp_loaded, gold_preproc=gold_preproc)\n                    )\n                    nwords = sum(len(doc_gold[0]) for doc_gold in dev_docs)\n                    start_time = timer()\n                    scorer = nlp_loaded.evaluate(dev_docs, debug)\n                    end_time = timer()\n                    if use_gpu < 0:\n                        gpu_wps = None\n                        cpu_wps = nwords / (end_time - start_time)\n                    else:\n                        gpu_wps = nwords / (end_time - start_time)\n                        with Model.use_device(\"cpu\"):\n                            nlp_loaded = util.load_model_from_path(epoch_model_path)\n                            for name, component in nlp_loaded.pipeline:\n                                if hasattr(component, \"cfg\"):\n                                    component.cfg[\"beam_width\"] = beam_width\n                            dev_docs = list(\n                                corpus.dev_docs(nlp_loaded, gold_preproc=gold_preproc)\n                            )\n                            start_time = timer()\n                            scorer = nlp_loaded.evaluate(dev_docs)\n                            end_time = timer()\n                            cpu_wps = nwords / (end_time - start_time)\n                    acc_loc = output_path / (\"model%d\" % i) / \"accuracy.json\"\n                    srsly.write_json(acc_loc, scorer.scores)\n\n                    # Update model meta.json\n                    meta[\"lang\"] = nlp.lang\n                    meta[\"pipeline\"] = nlp.pipe_names\n                    meta[\"spacy_version\"] = \">=%s\" % about.__version__\n                    if beam_width == 1:\n                        meta[\"speed\"] = {\n                            \"nwords\": nwords,\n                            \"cpu\": cpu_wps,\n                            \"gpu\": gpu_wps,\n                        }\n                        meta[\"accuracy\"] = scorer.scores\n                    else:\n                        meta.setdefault(\"beam_accuracy\", {})\n                        meta.setdefault(\"beam_speed\", {})\n                        meta[\"beam_accuracy\"][beam_width] = scorer.scores\n                        meta[\"beam_speed\"][beam_width] = {\n                            \"nwords\": nwords,\n                            \"cpu\": cpu_wps,\n                            \"gpu\": gpu_wps,\n                        }\n                    meta[\"vectors\"] = {\n                        \"width\": nlp.vocab.vectors_length,\n                        \"vectors\": len(nlp.vocab.vectors),\n                        \"keys\": nlp.vocab.vectors.n_keys,\n                        \"name\": nlp.vocab.vectors.name,\n                    }\n                    meta.setdefault(\"name\", \"model%d\" % i)\n                    meta.setdefault(\"version\", version)\n                    meta_loc = output_path / (\"model%d\" % i) / \"meta.json\"\n                    srsly.write_json(meta_loc, meta)\n                    util.set_env_log(verbose)\n\n                    progress = _get_progress(\n                        i,\n                        losses,\n                        scorer.scores,\n                        beam_width=beam_width if has_beam_widths else None,\n                        cpu_wps=cpu_wps,\n                        gpu_wps=gpu_wps,\n                    )\n                    msg.row(progress, **row_settings)\n                # Early stopping\n                if n_early_stopping is not None:\n                    current_score = _score_for_model(meta)\n                    if current_score < best_score:\n                        iter_since_best += 1\n                    else:\n                        iter_since_best = 0\n                        best_score = current_score\n                    if iter_since_best >= n_early_stopping:\n                        msg.text(\n                            \"Early stopping, best iteration \"\n                            \"is: {}\".format(i - iter_since_best)\n                        )\n                        msg.text(\n                            \"Best score = {}; Final iteration \"\n                            \"score = {}\".format(best_score, current_score)\n                        )\n                        break\n    finally:\n        with nlp.use_params(optimizer.averages):\n            final_model_path = output_path / \"model-final\"\n            nlp.to_disk(final_model_path)\n        msg.good(\"Saved model to output directory\", final_model_path)\n        with msg.loading(\"Creating best model...\"):\n            best_model_path = _collate_best_model(meta, output_path, nlp.pipe_names)\n        msg.good(\"Created best model\", best_model_path)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the mean score between tasks in pipeline that can be used for early stopping.", "response": "def _score_for_model(meta):\n    \"\"\" Returns mean score between tasks in pipeline that can be used for early stopping. \"\"\"\n    mean_acc = list()\n    pipes = meta[\"pipeline\"]\n    acc = meta[\"accuracy\"]\n    if \"tagger\" in pipes:\n        mean_acc.append(acc[\"tags_acc\"])\n    if \"parser\" in pipes:\n        mean_acc.append((acc[\"uas\"] + acc[\"las\"]) / 2)\n    if \"ner\" in pipes:\n        mean_acc.append((acc[\"ents_p\"] + acc[\"ents_r\"] + acc[\"ents_f\"]) / 3)\n    return sum(mean_acc) / len(mean_acc)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload pre - trained token - to - vector weights for the component articles.", "response": "def _load_pretrained_tok2vec(nlp, loc):\n    \"\"\"Load pre-trained weights for the 'token-to-vector' part of the component\n    models, which is typically a CNN. See 'spacy pretrain'. Experimental.\n    \"\"\"\n    with loc.open(\"rb\") as file_:\n        weights_data = file_.read()\n    loaded = []\n    for name, component in nlp.pipeline:\n        if hasattr(component, \"model\") and hasattr(component.model, \"tok2vec\"):\n            component.tok2vec.from_bytes(weights_data)\n            loaded.append(name)\n    return loaded"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef conllu2json(input_data, n_sents=10, use_morphology=False, lang=None):\n    # by @dvsrepo, via #11 explosion/spacy-dev-resources\n    # by @katarkor\n    docs = []\n    sentences = []\n    conll_tuples = read_conllx(input_data, use_morphology=use_morphology)\n    checked_for_ner = False\n    has_ner_tags = False\n    for i, (raw_text, tokens) in enumerate(conll_tuples):\n        sentence, brackets = tokens[0]\n        if not checked_for_ner:\n            has_ner_tags = is_ner(sentence[5][0])\n            checked_for_ner = True\n        sentences.append(generate_sentence(sentence, has_ner_tags))\n        # Real-sized documents could be extracted using the comments on the\n        # conluu document\n        if len(sentences) % n_sents == 0:\n            doc = create_doc(sentences, i)\n            docs.append(doc)\n            sentences = []\n    return docs", "response": "Convert conllu files into JSON format."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the file contains NER tags", "response": "def is_ner(tag):\n    \"\"\"\n    Check the 10th column of the first token to determine if the file contains\n    NER tags\n    \"\"\"\n    tag_match = re.match(\"([A-Z_]+)-([A-Z_]+)\", tag)\n    if tag_match:\n        return True\n    elif tag == \"O\":\n        return True\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsimplifying tags obtained from the dataset in order to follow Wikipedia scheme.", "response": "def simplify_tags(iob):\n    \"\"\"\n    Simplify tags obtained from the dataset in order to follow Wikipedia\n    scheme (PER, LOC, ORG, MISC). 'PER', 'LOC' and 'ORG' keep their tags, while\n    'GPE_LOC' is simplified to 'LOC', 'GPE_ORG' to 'ORG' and all remaining tags to\n    'MISC'.\n    \"\"\"\n    new_iob = []\n    for tag in iob:\n        tag_match = re.match(\"([A-Z_]+)-([A-Z_]+)\", tag)\n        if tag_match:\n            prefix = tag_match.group(1)\n            suffix = tag_match.group(2)\n            if suffix == \"GPE_LOC\":\n                suffix = \"LOC\"\n            elif suffix == \"GPE_ORG\":\n                suffix = \"ORG\"\n            elif suffix != \"PER\" and suffix != \"LOC\" and suffix != \"ORG\":\n                suffix = \"MISC\"\n            tag = prefix + \"-\" + suffix\n        new_iob.append(tag)\n    return new_iob"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef info(model=None, markdown=False, silent=False):\n    msg = Printer()\n    if model:\n        if util.is_package(model):\n            model_path = util.get_package_path(model)\n        else:\n            model_path = util.get_data_path() / model\n        meta_path = model_path / \"meta.json\"\n        if not meta_path.is_file():\n            msg.fail(\"Can't find model meta.json\", meta_path, exits=1)\n        meta = srsly.read_json(meta_path)\n        if model_path.resolve() != model_path:\n            meta[\"link\"] = path2str(model_path)\n            meta[\"source\"] = path2str(model_path.resolve())\n        else:\n            meta[\"source\"] = path2str(model_path)\n        if not silent:\n            title = \"Info about model '{}'\".format(model)\n            model_meta = {\n                k: v for k, v in meta.items() if k not in (\"accuracy\", \"speed\")\n            }\n            if markdown:\n                print_markdown(model_meta, title=title)\n            else:\n                msg.table(model_meta, title=title)\n        return meta\n    data = {\n        \"spaCy version\": about.__version__,\n        \"Location\": path2str(Path(__file__).parent.parent),\n        \"Platform\": platform.platform(),\n        \"Python version\": platform.python_version(),\n        \"Models\": list_models(),\n    }\n    if not silent:\n        title = \"Info about spaCy\"\n        if markdown:\n            print_markdown(data, title=title)\n        else:\n            msg.table(data, title=title)\n    return data", "response": "Print info about the current spaCy installation."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints data in GitHub - flavoured Markdown format for issues etc.", "response": "def print_markdown(data, title=None):\n    \"\"\"Print data in GitHub-flavoured Markdown format for issues etc.\n\n    data (dict or list of tuples): Label/value pairs.\n    title (unicode or None): Title, will be rendered as headline 2.\n    \"\"\"\n    markdown = []\n    for key, value in data.items():\n        if isinstance(value, basestring_) and Path(value).exists():\n            continue\n        markdown.append(\"* **{}:** {}\".format(key, unicode_(value)))\n    if title:\n        print(\"\\n## {}\".format(title))\n    print(\"\\n{}\\n\".format(\"\\n\".join(markdown)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main(model=None, output_dir=None, n_iter=15):\n    if model is not None:\n        nlp = spacy.load(model)  # load existing spaCy model\n        print(\"Loaded model '%s'\" % model)\n    else:\n        nlp = spacy.blank(\"en\")  # create blank Language class\n        print(\"Created blank 'en' model\")\n\n    # We'll use the built-in dependency parser class, but we want to create a\n    # fresh instance \u2013 just in case.\n    if \"parser\" in nlp.pipe_names:\n        nlp.remove_pipe(\"parser\")\n    parser = nlp.create_pipe(\"parser\")\n    nlp.add_pipe(parser, first=True)\n\n    for text, annotations in TRAIN_DATA:\n        for dep in annotations.get(\"deps\", []):\n            parser.add_label(dep)\n\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"parser\"]\n    with nlp.disable_pipes(*other_pipes):  # only train parser\n        optimizer = nlp.begin_training()\n        for itn in range(n_iter):\n            random.shuffle(TRAIN_DATA)\n            losses = {}\n            # batch up the examples using spaCy's minibatch\n            batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(texts, annotations, sgd=optimizer, losses=losses)\n            print(\"Losses\", losses)\n\n    # test the trained model\n    test_model(nlp)\n\n    # save model to output directory\n    if output_dir is not None:\n        output_dir = Path(output_dir)\n        if not output_dir.exists():\n            output_dir.mkdir()\n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)\n\n        # test the saved model\n        print(\"Loading from\", output_dir)\n        nlp2 = spacy.load(output_dir)\n        test_model(nlp2)", "response": "Load the model set up the pipeline and train the parser and save the model to output_dir"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_pipe(self, name):\n        for pipe_name, component in self.pipeline:\n            if pipe_name == name:\n                return component\n        raise KeyError(Errors.E001.format(name=name, opts=self.pipe_names))", "response": "Get a pipeline component for a given component name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_pipe(self, name, config=dict()):\n        if name not in self.factories:\n            if name == \"sbd\":\n                raise KeyError(Errors.E108.format(name=name))\n            else:\n                raise KeyError(Errors.E002.format(name=name))\n        factory = self.factories[name]\n        return factory(self, **config)", "response": "Create a pipeline component from a factory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_pipe(\n        self, component, name=None, before=None, after=None, first=None, last=None\n    ):\n        \"\"\"Add a component to the processing pipeline. Valid components are\n        callables that take a `Doc` object, modify it and return it. Only one\n        of before/after/first/last can be set. Default behaviour is \"last\".\n\n        component (callable): The pipeline component.\n        name (unicode): Name of pipeline component. Overwrites existing\n            component.name attribute if available. If no name is set and\n            the component exposes no name attribute, component.__name__ is\n            used. An error is raised if a name already exists in the pipeline.\n        before (unicode): Component name to insert component directly before.\n        after (unicode): Component name to insert component directly after.\n        first (bool): Insert component first / not first in the pipeline.\n        last (bool): Insert component last / not last in the pipeline.\n\n        DOCS: https://spacy.io/api/language#add_pipe\n        \"\"\"\n        if not hasattr(component, \"__call__\"):\n            msg = Errors.E003.format(component=repr(component), name=name)\n            if isinstance(component, basestring_) and component in self.factories:\n                msg += Errors.E004.format(component=component)\n            raise ValueError(msg)\n        if name is None:\n            if hasattr(component, \"name\"):\n                name = component.name\n            elif hasattr(component, \"__name__\"):\n                name = component.__name__\n            elif hasattr(component, \"__class__\") and hasattr(\n                component.__class__, \"__name__\"\n            ):\n                name = component.__class__.__name__\n            else:\n                name = repr(component)\n        if name in self.pipe_names:\n            raise ValueError(Errors.E007.format(name=name, opts=self.pipe_names))\n        if sum([bool(before), bool(after), bool(first), bool(last)]) >= 2:\n            raise ValueError(Errors.E006)\n        pipe = (name, component)\n        if last or not any([first, before, after]):\n            self.pipeline.append(pipe)\n        elif first:\n            self.pipeline.insert(0, pipe)\n        elif before and before in self.pipe_names:\n            self.pipeline.insert(self.pipe_names.index(before), pipe)\n        elif after and after in self.pipe_names:\n            self.pipeline.insert(self.pipe_names.index(after) + 1, pipe)\n        else:\n            raise ValueError(\n                Errors.E001.format(name=before or after, opts=self.pipe_names)\n            )", "response": "Add a component to the processing pipeline."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreplaces a component in the pipeline.", "response": "def replace_pipe(self, name, component):\n        \"\"\"Replace a component in the pipeline.\n\n        name (unicode): Name of the component to replace.\n        component (callable): Pipeline component.\n\n        DOCS: https://spacy.io/api/language#replace_pipe\n        \"\"\"\n        if name not in self.pipe_names:\n            raise ValueError(Errors.E001.format(name=name, opts=self.pipe_names))\n        self.pipeline[self.pipe_names.index(name)] = (name, component)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrenaming a pipeline component.", "response": "def rename_pipe(self, old_name, new_name):\n        \"\"\"Rename a pipeline component.\n\n        old_name (unicode): Name of the component to rename.\n        new_name (unicode): New name of the component.\n\n        DOCS: https://spacy.io/api/language#rename_pipe\n        \"\"\"\n        if old_name not in self.pipe_names:\n            raise ValueError(Errors.E001.format(name=old_name, opts=self.pipe_names))\n        if new_name in self.pipe_names:\n            raise ValueError(Errors.E007.format(name=new_name, opts=self.pipe_names))\n        i = self.pipe_names.index(old_name)\n        self.pipeline[i] = (new_name, self.pipeline[i][1])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a component from the pipeline.", "response": "def remove_pipe(self, name):\n        \"\"\"Remove a component from the pipeline.\n\n        name (unicode): Name of the component to remove.\n        RETURNS (tuple): A `(name, component)` tuple of the removed component.\n\n        DOCS: https://spacy.io/api/language#remove_pipe\n        \"\"\"\n        if name not in self.pipe_names:\n            raise ValueError(Errors.E001.format(name=name, opts=self.pipe_names))\n        return self.pipeline.pop(self.pipe_names.index(name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the models in the pipeline.", "response": "def update(self, docs, golds, drop=0.0, sgd=None, losses=None, component_cfg=None):\n        \"\"\"Update the models in the pipeline.\n\n        docs (iterable): A batch of `Doc` objects.\n        golds (iterable): A batch of `GoldParse` objects.\n        drop (float): The droput rate.\n        sgd (callable): An optimizer.\n        RETURNS (dict): Results from the update.\n\n        DOCS: https://spacy.io/api/language#update\n        \"\"\"\n        if len(docs) != len(golds):\n            raise IndexError(Errors.E009.format(n_docs=len(docs), n_golds=len(golds)))\n        if len(docs) == 0:\n            return\n        if sgd is None:\n            if self._optimizer is None:\n                self._optimizer = create_default_optimizer(Model.ops)\n            sgd = self._optimizer\n        # Allow dict of args to GoldParse, instead of GoldParse objects.\n        gold_objs = []\n        doc_objs = []\n        for doc, gold in zip(docs, golds):\n            if isinstance(doc, basestring_):\n                doc = self.make_doc(doc)\n            if not isinstance(gold, GoldParse):\n                gold = GoldParse(doc, **gold)\n            doc_objs.append(doc)\n            gold_objs.append(gold)\n        golds = gold_objs\n        docs = doc_objs\n        grads = {}\n\n        def get_grads(W, dW, key=None):\n            grads[key] = (W, dW)\n\n        get_grads.alpha = sgd.alpha\n        get_grads.b1 = sgd.b1\n        get_grads.b2 = sgd.b2\n        pipes = list(self.pipeline)\n        random.shuffle(pipes)\n        if component_cfg is None:\n            component_cfg = {}\n        for name, proc in pipes:\n            if not hasattr(proc, \"update\"):\n                continue\n            grads = {}\n            kwargs = component_cfg.get(name, {})\n            kwargs.setdefault(\"drop\", drop)\n            proc.update(docs, golds, sgd=get_grads, losses=losses, **kwargs)\n            for key, (W, dW) in grads.items():\n                sgd(W, dW, key=key)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmake a \"rehearsal\" update to the models in the pipeline, to prevent forgetting. Rehearsal updates run an initial copy of the model over some data, and update the model so its current predictions are more like the initial ones. This is useful for keeping a pre-trained model on-track, even if you're updating it with a smaller set of examples. docs (iterable): A batch of `Doc` objects. drop (float): The droput rate. sgd (callable): An optimizer. RETURNS (dict): Results from the update. EXAMPLE: >>> raw_text_batches = minibatch(raw_texts) >>> for labelled_batch in minibatch(zip(train_docs, train_golds)): >>> docs, golds = zip(*train_docs) >>> nlp.update(docs, golds) >>> raw_batch = [nlp.make_doc(text) for text in next(raw_text_batches)] >>> nlp.rehearse(raw_batch)", "response": "def rehearse(self, docs, sgd=None, losses=None, config=None):\n        \"\"\"Make a \"rehearsal\" update to the models in the pipeline, to prevent\n        forgetting. Rehearsal updates run an initial copy of the model over some\n        data, and update the model so its current predictions are more like the\n        initial ones. This is useful for keeping a pre-trained model on-track,\n        even if you're updating it with a smaller set of examples.\n\n        docs (iterable): A batch of `Doc` objects.\n        drop (float): The droput rate.\n        sgd (callable): An optimizer.\n        RETURNS (dict): Results from the update.\n\n        EXAMPLE:\n            >>> raw_text_batches = minibatch(raw_texts)\n            >>> for labelled_batch in minibatch(zip(train_docs, train_golds)):\n            >>>     docs, golds = zip(*train_docs)\n            >>>     nlp.update(docs, golds)\n            >>>     raw_batch = [nlp.make_doc(text) for text in next(raw_text_batches)]\n            >>>     nlp.rehearse(raw_batch)\n        \"\"\"\n        # TODO: document\n        if len(docs) == 0:\n            return\n        if sgd is None:\n            if self._optimizer is None:\n                self._optimizer = create_default_optimizer(Model.ops)\n            sgd = self._optimizer\n        docs = list(docs)\n        for i, doc in enumerate(docs):\n            if isinstance(doc, basestring_):\n                docs[i] = self.make_doc(doc)\n        pipes = list(self.pipeline)\n        random.shuffle(pipes)\n        if config is None:\n            config = {}\n        grads = {}\n\n        def get_grads(W, dW, key=None):\n            grads[key] = (W, dW)\n\n        get_grads.alpha = sgd.alpha\n        get_grads.b1 = sgd.b1\n        get_grads.b2 = sgd.b2\n        for name, proc in pipes:\n            if not hasattr(proc, \"rehearse\"):\n                continue\n            grads = {}\n            proc.rehearse(docs, sgd=get_grads, losses=losses, **config.get(name, {}))\n            for key, (W, dW) in grads.items():\n                sgd(W, dW, key=key)\n        return losses"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef begin_training(self, get_gold_tuples=None, sgd=None, component_cfg=None, **cfg):\n        if get_gold_tuples is None:\n            get_gold_tuples = lambda: []\n        # Populate vocab\n        else:\n            for _, annots_brackets in get_gold_tuples():\n                for annots, _ in annots_brackets:\n                    for word in annots[1]:\n                        _ = self.vocab[word]  # noqa: F841\n        if cfg.get(\"device\", -1) >= 0:\n            util.use_gpu(cfg[\"device\"])\n            if self.vocab.vectors.data.shape[1] >= 1:\n                self.vocab.vectors.data = Model.ops.asarray(self.vocab.vectors.data)\n        link_vectors_to_models(self.vocab)\n        if self.vocab.vectors.data.shape[1]:\n            cfg[\"pretrained_vectors\"] = self.vocab.vectors.name\n        if sgd is None:\n            sgd = create_default_optimizer(Model.ops)\n        self._optimizer = sgd\n        if component_cfg is None:\n            component_cfg = {}\n        for name, proc in self.pipeline:\n            if hasattr(proc, \"begin_training\"):\n                kwargs = component_cfg.get(name, {})\n                kwargs.update(cfg)\n                proc.begin_training(\n                    get_gold_tuples,\n                    pipeline=self.pipeline,\n                    sgd=self._optimizer,\n                    **kwargs\n                )\n        return self._optimizer", "response": "Allocate models pre - process training data and acquire a trainer and an optimizer. Used as a contextmanager."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resume_training(self, sgd=None, **cfg):\n        if cfg.get(\"device\", -1) >= 0:\n            util.use_gpu(cfg[\"device\"])\n            if self.vocab.vectors.data.shape[1] >= 1:\n                self.vocab.vectors.data = Model.ops.asarray(self.vocab.vectors.data)\n        link_vectors_to_models(self.vocab)\n        if self.vocab.vectors.data.shape[1]:\n            cfg[\"pretrained_vectors\"] = self.vocab.vectors.name\n        if sgd is None:\n            sgd = create_default_optimizer(Model.ops)\n        self._optimizer = sgd\n        for name, proc in self.pipeline:\n            if hasattr(proc, \"_rehearsal_model\"):\n                proc._rehearsal_model = deepcopy(proc.model)\n        return self._optimizer", "response": "Continue training a pre - trained model."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef use_params(self, params, **cfg):\n        contexts = [\n            pipe.use_params(params)\n            for name, pipe in self.pipeline\n            if hasattr(pipe, \"use_params\")\n        ]\n        # TODO: Having trouble with contextlib\n        # Workaround: these aren't actually context managers atm.\n        for context in contexts:\n            try:\n                next(context)\n            except StopIteration:\n                pass\n        yield\n        for context in contexts:\n            try:\n                next(context)\n            except StopIteration:\n                pass", "response": "Replace weights of models in the pipeline with those provided in the params dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pipe(\n        self,\n        texts,\n        as_tuples=False,\n        n_threads=-1,\n        batch_size=1000,\n        disable=[],\n        cleanup=False,\n        component_cfg=None,\n    ):\n        \"\"\"Process texts as a stream, and yield `Doc` objects in order.\n\n        texts (iterator): A sequence of texts to process.\n        as_tuples (bool): If set to True, inputs should be a sequence of\n            (text, context) tuples. Output will then be a sequence of\n            (doc, context) tuples. Defaults to False.\n        batch_size (int): The number of texts to buffer.\n        disable (list): Names of the pipeline components to disable.\n        cleanup (bool): If True, unneeded strings are freed to control memory\n            use. Experimental.\n        component_cfg (dict): An optional dictionary with extra keyword\n            arguments for specific components.\n        YIELDS (Doc): Documents in the order of the original text.\n\n        DOCS: https://spacy.io/api/language#pipe\n        \"\"\"\n        if n_threads != -1:\n            deprecation_warning(Warnings.W016)\n        if as_tuples:\n            text_context1, text_context2 = itertools.tee(texts)\n            texts = (tc[0] for tc in text_context1)\n            contexts = (tc[1] for tc in text_context2)\n            docs = self.pipe(\n                texts,\n                batch_size=batch_size,\n                disable=disable,\n                component_cfg=component_cfg,\n            )\n            for doc, context in izip(docs, contexts):\n                yield (doc, context)\n            return\n        docs = (self.make_doc(text) for text in texts)\n        if component_cfg is None:\n            component_cfg = {}\n        for name, proc in self.pipeline:\n            if name in disable:\n                continue\n            kwargs = component_cfg.get(name, {})\n            # Allow component_cfg to overwrite the top-level kwargs.\n            kwargs.setdefault(\"batch_size\", batch_size)\n            if hasattr(proc, \"pipe\"):\n                docs = proc.pipe(docs, **kwargs)\n            else:\n                # Apply the function, but yield the doc\n                docs = _pipe(proc, docs, kwargs)\n        # Track weakrefs of \"recent\" documents, so that we can see when they\n        # expire from memory. When they do, we know we don't need old strings.\n        # This way, we avoid maintaining an unbounded growth in string entries\n        # in the string store.\n        recent_refs = weakref.WeakSet()\n        old_refs = weakref.WeakSet()\n        # Keep track of the original string data, so that if we flush old strings,\n        # we can recover the original ones. However, we only want to do this if we're\n        # really adding strings, to save up-front costs.\n        original_strings_data = None\n        nr_seen = 0\n        for doc in docs:\n            yield doc\n            if cleanup:\n                recent_refs.add(doc)\n                if nr_seen < 10000:\n                    old_refs.add(doc)\n                    nr_seen += 1\n                elif len(old_refs) == 0:\n                    old_refs, recent_refs = recent_refs, old_refs\n                    if original_strings_data is None:\n                        original_strings_data = list(self.vocab.strings)\n                    else:\n                        keys, strings = self.vocab.strings._cleanup_stale_strings(\n                            original_strings_data\n                        )\n                        self.vocab._reset_cache(keys, strings)\n                        self.tokenizer._reset_cache(keys)\n                    nr_seen = 0", "response": "Process texts as a stream and yield Doc objects in order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving the current state of the current instance to disk.", "response": "def to_disk(self, path, exclude=tuple(), disable=None):\n        \"\"\"Save the current state to a directory.  If a model is loaded, this\n        will include the model.\n\n        path (unicode or Path): Path to a directory, which will be created if\n            it doesn't exist.\n        exclude (list): Names of components or serialization fields to exclude.\n\n        DOCS: https://spacy.io/api/language#to_disk\n        \"\"\"\n        if disable is not None:\n            deprecation_warning(Warnings.W014)\n            exclude = disable\n        path = util.ensure_path(path)\n        serializers = OrderedDict()\n        serializers[\"tokenizer\"] = lambda p: self.tokenizer.to_disk(p, exclude=[\"vocab\"])\n        serializers[\"meta.json\"] = lambda p: p.open(\"w\").write(srsly.json_dumps(self.meta))\n        for name, proc in self.pipeline:\n            if not hasattr(proc, \"name\"):\n                continue\n            if name in exclude:\n                continue\n            if not hasattr(proc, \"to_disk\"):\n                continue\n            serializers[name] = lambda p, proc=proc: proc.to_disk(p, exclude=[\"vocab\"])\n        serializers[\"vocab\"] = lambda p: self.vocab.to_disk(p)\n        util.to_disk(path, serializers, exclude)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_disk(self, path, exclude=tuple(), disable=None):\n        if disable is not None:\n            deprecation_warning(Warnings.W014)\n            exclude = disable\n        path = util.ensure_path(path)\n        deserializers = OrderedDict()\n        deserializers[\"meta.json\"] = lambda p: self.meta.update(srsly.read_json(p))\n        deserializers[\"vocab\"] = lambda p: self.vocab.from_disk(p) and _fix_pretrained_vectors_name(self)\n        deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(p, exclude=[\"vocab\"])\n        for name, proc in self.pipeline:\n            if name in exclude:\n                continue\n            if not hasattr(proc, \"from_disk\"):\n                continue\n            deserializers[name] = lambda p, proc=proc: proc.from_disk(p, exclude=[\"vocab\"])\n        if not (path / \"vocab\").exists() and \"vocab\" not in exclude:\n            # Convert to list here in case exclude is (default) tuple\n            exclude = list(exclude) + [\"vocab\"]\n        util.from_disk(path, deserializers, exclude)\n        self._path = path\n        return self", "response": "Loads the state from a directory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_bytes(self, exclude=tuple(), disable=None, **kwargs):\n        if disable is not None:\n            deprecation_warning(Warnings.W014)\n            exclude = disable\n        serializers = OrderedDict()\n        serializers[\"vocab\"] = lambda: self.vocab.to_bytes()\n        serializers[\"tokenizer\"] = lambda: self.tokenizer.to_bytes(exclude=[\"vocab\"])\n        serializers[\"meta.json\"] = lambda: srsly.json_dumps(self.meta)\n        for name, proc in self.pipeline:\n            if name in exclude:\n                continue\n            if not hasattr(proc, \"to_bytes\"):\n                continue\n            serializers[name] = lambda proc=proc: proc.to_bytes(exclude=[\"vocab\"])\n        exclude = util.get_serialization_exclude(serializers, exclude, kwargs)\n        return util.to_bytes(serializers, exclude)", "response": "Serialize the current state to a binary string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_bytes(self, bytes_data, exclude=tuple(), disable=None, **kwargs):\n        if disable is not None:\n            deprecation_warning(Warnings.W014)\n            exclude = disable\n        deserializers = OrderedDict()\n        deserializers[\"meta.json\"] = lambda b: self.meta.update(srsly.json_loads(b))\n        deserializers[\"vocab\"] = lambda b: self.vocab.from_bytes(b) and _fix_pretrained_vectors_name(self)\n        deserializers[\"tokenizer\"] = lambda b: self.tokenizer.from_bytes(b, exclude=[\"vocab\"])\n        for name, proc in self.pipeline:\n            if name in exclude:\n                continue\n            if not hasattr(proc, \"from_bytes\"):\n                continue\n            deserializers[name] = lambda b, proc=proc: proc.from_bytes(b, exclude=[\"vocab\"])\n        exclude = util.get_serialization_exclude(deserializers, exclude, kwargs)\n        util.from_bytes(bytes_data, deserializers, exclude)\n        return self", "response": "Load state from a binary string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef restore(self):\n        current, self.nlp.pipeline = self.nlp.pipeline, self.original_pipeline\n        unexpected = [name for name, pipe in current if not self.nlp.has_pipe(name)]\n        if unexpected:\n            # Don't change the pipeline if we're raising an error.\n            self.nlp.pipeline = current\n            raise ValueError(Errors.E008.format(names=unexpected))\n        self[:] = []", "response": "Restore the pipeline to its state when DisabledPipes was created."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_loaded_rules(rules_paths):\n    for path in rules_paths:\n        if path.name != '__init__.py':\n            rule = Rule.from_path(path)\n            if rule.is_enabled:\n                yield rule", "response": "Yields all available rules."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_rules_import_paths():\n    # Bundled rules:\n    yield Path(__file__).parent.joinpath('rules')\n    # Rules defined by user:\n    yield settings.user_dir.joinpath('rules')\n    # Packages with third-party rules:\n    for path in sys.path:\n        for contrib_module in Path(path).glob('thefuck_contrib_*'):\n            contrib_rules = contrib_module.joinpath('rules')\n            if contrib_rules.is_dir():\n                yield contrib_rules", "response": "Yields all rules import paths."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn all enabled rules.", "response": "def get_rules():\n    \"\"\"Returns all enabled rules.\n\n    :rtype: [Rule]\n\n    \"\"\"\n    paths = [rule_path for path in get_rules_import_paths()\n             for rule_path in sorted(path.glob('*.py'))]\n    return sorted(get_loaded_rules(paths),\n                  key=lambda rule: rule.priority)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef organize_commands(corrected_commands):\n    try:\n        first_command = next(corrected_commands)\n        yield first_command\n    except StopIteration:\n        return\n\n    without_duplicates = {\n        command for command in sorted(\n            corrected_commands, key=lambda command: command.priority)\n        if command != first_command}\n\n    sorted_commands = sorted(\n        without_duplicates,\n        key=lambda corrected_command: corrected_command.priority)\n\n    logs.debug('Corrected commands: '.format(\n        ', '.join(u'{}'.format(cmd) for cmd in [first_command] + sorted_commands)))\n\n    for command in sorted_commands:\n        yield command", "response": "Yields sorted commands without duplicates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning generator with sorted and unique corrected commands.", "response": "def get_corrected_commands(command):\n    \"\"\"Returns generator with sorted and unique corrected commands.\n\n    :type command: thefuck.types.Command\n    :rtype: Iterable[thefuck.types.CorrectedCommand]\n\n    \"\"\"\n    corrected_commands = (\n        corrected for rule in get_rules()\n        if rule.is_match(command)\n        for corrected in rule.get_corrected_commands(command))\n    return organize_commands(corrected_commands)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfix previous command. Used when thefuck called without arguments.", "response": "def fix_command(known_args):\n    \"\"\"Fixes previous command. Used when `thefuck` called without arguments.\"\"\"\n    settings.init(known_args)\n    with logs.debug_time('Total'):\n        logs.debug(u'Run with settings: {}'.format(pformat(settings)))\n        raw_command = _get_raw_command(known_args)\n\n        try:\n            command = types.Command.from_raw_script(raw_command)\n        except EmptyCommand:\n            logs.debug('Empty command, nothing to do')\n            return\n\n        corrected_commands = get_corrected_commands(command)\n        selected_command = select_command(corrected_commands)\n\n        if selected_command:\n            selected_command.run(command)\n        else:\n            sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_output(script):\n    with logs.debug_time(u'Read output from external shell logger'):\n        commands = _get_last_n(const.SHELL_LOGGER_LIMIT)\n        for command in commands:\n            if command['command'] == script:\n                lines = _get_output_lines(command['output'])\n                output = '\\n'.join(lines).strip()\n                return output\n            else:\n                logs.warn(\"Output isn't available in shell logger\")\n                return None", "response": "Gets command output from external shell logger."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns list of history entries.", "response": "def _get_history_lines(self):\n        \"\"\"Returns list of history entries.\"\"\"\n        history_file_name = self._get_history_file_name()\n        if os.path.isfile(history_file_name):\n            with io.open(history_file_name, 'r',\n                         encoding='utf-8', errors='ignore') as history_file:\n\n                lines = history_file.readlines()\n                if settings.history_limit:\n                    lines = lines[-settings.history_limit:]\n\n                for line in lines:\n                    prepared = self._script_from_history(line) \\\n                        .strip()\n                    if prepared:\n                        yield prepared"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef split_command(self, command):\n        encoded = self.encode_utf8(command)\n\n        try:\n            splitted = [s.replace(\"??\", \"\\\\ \") for s in shlex.split(encoded.replace('\\\\ ', '??'))]\n        except ValueError:\n            splitted = encoded.split(' ')\n\n        return self.decode_utf8(splitted)", "response": "Split the command using shell - like syntax."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a shell - escaped version of the string s.", "response": "def quote(self, s):\n        \"\"\"Return a shell-escaped version of the string s.\"\"\"\n\n        if six.PY2:\n            from pipes import quote\n        else:\n            from shlex import quote\n\n        return quote(s)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the name and version of the current shell", "response": "def info(self):\n        \"\"\"Returns the name and version of the current shell\"\"\"\n        proc = Popen(['fish', '--version'],\n                     stdout=PIPE, stderr=DEVNULL)\n        version = proc.stdout.read().decode('utf-8').split()[-1]\n        return u'Fish Shell {}'.format(version)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _put_to_history(self, command_script):\n        history_file_name = self._get_history_file_name()\n        if os.path.isfile(history_file_name):\n            with open(history_file_name, 'a') as history:\n                entry = self._get_history_line(command_script)\n                if six.PY2:\n                    history.write(entry.encode('utf-8'))\n                else:\n                    history.write(entry)", "response": "Puts command script to shell history."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_brew_tap_specific_commands(brew_path_prefix):\n    commands = []\n    brew_taps_path = brew_path_prefix + TAP_PATH\n\n    for user in _get_directory_names_only(brew_taps_path):\n        taps = _get_directory_names_only(brew_taps_path + '/%s' % user)\n\n        # Brew Taps's naming rule\n        # https://github.com/Homebrew/homebrew/blob/master/share/doc/homebrew/brew-tap.md#naming-conventions-and-limitations\n        taps = (tap for tap in taps if tap.startswith('homebrew-'))\n        for tap in taps:\n            tap_cmd_path = brew_taps_path + TAP_CMD_PATH % (user, tap)\n\n            if os.path.isdir(tap_cmd_path):\n                commands += (name.replace('brew-', '').replace('.rb', '')\n                             for name in os.listdir(tap_cmd_path)\n                             if _is_brew_tap_cmd_naming(name))\n\n    return commands", "response": "To get tap s specific commands available in Brew TAPs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef info(self):\n        proc = Popen(['zsh', '-c', 'echo $ZSH_VERSION'],\n                     stdout=PIPE, stderr=DEVNULL)\n        version = proc.stdout.read().decode('utf-8').strip()\n        return u'ZSH {}'.format(version)", "response": "Returns the name and version of the current shell"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nresolving git aliases and supports testing for both git and hub.", "response": "def git_support(fn, command):\n    \"\"\"Resolves git aliases and supports testing for both git and hub.\"\"\"\n    # supports GitHub's `hub` command\n    # which is recommended to be used with `alias git=hub`\n    # but at this point, shell aliases have already been resolved\n    if not is_app(command, 'git', 'hub'):\n        return False\n\n    # perform git aliases expansion\n    if 'trace: alias expansion:' in command.output:\n        search = re.search(\"trace: alias expansion: ([^ ]*) => ([^\\n]*)\",\n                           command.output)\n        alias = search.group(1)\n\n        # by default git quotes everything, for example:\n        #     'commit' '--amend'\n        # which is surprising and does not allow to easily test for\n        # eg. 'git commit'\n        expansion = ' '.join(shell.quote(part)\n                             for part in shell.split_command(search.group(2)))\n        new_script = command.script.replace(alias, expansion)\n\n        command = command.update(script=new_script)\n\n    return fn(command)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nyield the actions for pressed keys.", "response": "def read_actions():\n    \"\"\"Yields actions for pressed keys.\"\"\"\n    while True:\n        key = get_key()\n\n        # Handle arrows, j/k (qwerty), and n/e (colemak)\n        if key in (const.KEY_UP, const.KEY_CTRL_N, 'k', 'e'):\n            yield const.ACTION_PREVIOUS\n        elif key in (const.KEY_DOWN, const.KEY_CTRL_P, 'j', 'n'):\n            yield const.ACTION_NEXT\n        elif key in (const.KEY_CTRL_C, 'q'):\n            yield const.ACTION_ABORT\n        elif key in ('\\n', '\\r'):\n            yield const.ACTION_SELECT"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nselecting a command from the list of corrected commands.", "response": "def select_command(corrected_commands):\n    \"\"\"Returns:\n\n     - the first command when confirmation disabled;\n     - None when ctrl+c pressed;\n     - selected command.\n\n    :type corrected_commands: Iterable[thefuck.types.CorrectedCommand]\n    :rtype: thefuck.types.CorrectedCommand | None\n\n    \"\"\"\n    try:\n        selector = CommandSelector(corrected_commands)\n    except NoRuleMatched:\n        logs.failed('No fucks given' if get_alias() == 'fuck'\n                    else 'Nothing found')\n        return\n\n    if not settings.require_confirmation:\n        logs.show_corrected_command(selector.value)\n        return selector.value\n\n    logs.confirm_text(selector.value)\n\n    for action in read_actions():\n        if action == const.ACTION_SELECT:\n            sys.stderr.write('\\n')\n            return selector.value\n        elif action == const.ACTION_ABORT:\n            logs.failed('\\nAborted')\n            return\n        elif action == const.ACTION_PREVIOUS:\n            selector.previous()\n            logs.confirm_text(selector.value)\n        elif action == const.ACTION_NEXT:\n            selector.next()\n            logs.confirm_text(selector.value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _spawn(shell, master_read):\n    pid, master_fd = pty.fork()\n\n    if pid == pty.CHILD:\n        os.execlp(shell, shell)\n\n    try:\n        mode = tty.tcgetattr(pty.STDIN_FILENO)\n        tty.setraw(pty.STDIN_FILENO)\n        restore = True\n    except tty.error:    # This is the same as termios.error\n        restore = False\n\n    _set_pty_size(master_fd)\n    signal.signal(signal.SIGWINCH, lambda *_: _set_pty_size(master_fd))\n\n    try:\n        pty._copy(master_fd, master_read, pty._read)\n    except OSError:\n        if restore:\n            tty.tcsetattr(pty.STDIN_FILENO, tty.TCSAFLUSH, mode)\n\n    os.close(master_fd)\n    return os.waitpid(pid, 0)[1]", "response": "Create a new process."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlog shell output to the output.", "response": "def shell_logger(output):\n    \"\"\"Logs shell output to the `output`.\n\n    Works like unix script command with `-f` flag.\n\n    \"\"\"\n    if not os.environ.get('SHELL'):\n        logs.warn(\"Shell logger doesn't support your platform.\")\n        sys.exit(1)\n\n    fd = os.open(output, os.O_CREAT | os.O_TRUNC | os.O_RDWR)\n    os.write(fd, b'\\x00' * const.LOG_SIZE_IN_BYTES)\n    buffer = mmap.mmap(fd, const.LOG_SIZE_IN_BYTES, mmap.MAP_SHARED, mmap.PROT_WRITE)\n    return_code = _spawn(os.environ['SHELL'], partial(_read, buffer))\n\n    sys.exit(return_code)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets output of the console script.", "response": "def get_output(script, expanded):\n    \"\"\"Get output of the script.\n\n    :param script: Console script.\n    :type script: str\n    :param expanded: Console script with expanded aliases.\n    :type expanded: str\n    :rtype: str\n\n    \"\"\"\n    if shell_logger.is_available():\n        return shell_logger.get_output(script)\n    if settings.instant_mode:\n        return read_log.get_output(script)\n    else:\n        return rerun.get_output(script, expanded)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd command line arguments to the parser.", "response": "def _add_arguments(self):\n        \"\"\"Adds arguments to parser.\"\"\"\n        self._parser.add_argument(\n            '-v', '--version',\n            action='store_true',\n            help=\"show program's version number and exit\")\n        self._parser.add_argument(\n            '-a', '--alias',\n            nargs='?',\n            const=get_alias(),\n            help='[custom-alias-name] prints alias for current shell')\n        self._parser.add_argument(\n            '-l', '--shell-logger',\n            action='store',\n            help='log shell output to the file')\n        self._parser.add_argument(\n            '--enable-experimental-instant-mode',\n            action='store_true',\n            help='enable experimental instant mode, use on your own risk')\n        self._parser.add_argument(\n            '-h', '--help',\n            action='store_true',\n            help='show this help message and exit')\n        self._add_conflicting_arguments()\n        self._parser.add_argument(\n            '-d', '--debug',\n            action='store_true',\n            help='enable debug output')\n        self._parser.add_argument(\n            '--force-command',\n            action='store',\n            help=SUPPRESS)\n        self._parser.add_argument(\n            'command',\n            nargs='*',\n            help='command that should be fixed')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_conflicting_arguments(self):\n        group = self._parser.add_mutually_exclusive_group()\n        group.add_argument(\n            '-y', '--yes', '--yeah',\n            action='store_true',\n            help='execute fixed command without confirmation')\n        group.add_argument(\n            '-r', '--repeat',\n            action='store_true',\n            help='repeat on failure')", "response": "It s too dangerous to use - y and - r together."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _prepare_arguments(self, argv):\n        if ARGUMENT_PLACEHOLDER in argv:\n            index = argv.index(ARGUMENT_PLACEHOLDER)\n            return argv[index + 1:] + ['--'] + argv[:index]\n        elif argv and not argv[0].startswith('-') and argv[0] != '--':\n            return ['--'] + argv\n        else:\n            return argv", "response": "Prepares the arguments by removing placeholders and moving arguments after it to beginning and adding the command name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget custom npm scripts.", "response": "def get_scripts():\n    \"\"\"Get custom npm scripts.\"\"\"\n    proc = Popen(['npm', 'run-script'], stdout=PIPE)\n    should_yeild = False\n    for line in proc.stdout.readlines():\n        line = line.decode()\n        if 'available via `npm run-script`:' in line:\n            should_yeild = True\n            continue\n\n        if should_yeild and re.match(r'^  [^ ]+', line):\n            yield line.strip().split(' ')[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef init(self, args=None):\n        from .logs import exception\n\n        self._setup_user_dir()\n        self._init_settings_file()\n\n        try:\n            self.update(self._settings_from_file())\n        except Exception:\n            exception(\"Can't load settings from file\", sys.exc_info())\n\n        try:\n            self.update(self._settings_from_env())\n        except Exception:\n            exception(\"Can't load settings from env\", sys.exc_info())\n\n        self.update(self._settings_from_args(args))", "response": "Fills settings with values from settings. py and env."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_user_dir_path(self):\n        xdg_config_home = os.environ.get('XDG_CONFIG_HOME', '~/.config')\n        user_dir = Path(xdg_config_home, 'thefuck').expanduser()\n        legacy_user_dir = Path('~', '.thefuck').expanduser()\n\n        # For backward compatibility use legacy '~/.thefuck' if it exists:\n        if legacy_user_dir.is_dir():\n            warn(u'Config path {} is deprecated. Please move to {}'.format(\n                legacy_user_dir, user_dir))\n            return legacy_user_dir\n        else:\n            return user_dir", "response": "Returns the path object representing the user config resource"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _setup_user_dir(self):\n        user_dir = self._get_user_dir_path()\n\n        rules_dir = user_dir.joinpath('rules')\n        if not rules_dir.is_dir():\n            rules_dir.mkdir(parents=True)\n        self.user_dir = user_dir", "response": "Returns user config dir create it when it doesn t exist."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading settings from file.", "response": "def _settings_from_file(self):\n        \"\"\"Loads settings from file.\"\"\"\n        settings = load_source(\n            'settings', text_type(self.user_dir.joinpath('settings.py')))\n        return {key: getattr(settings, key)\n                for key in const.DEFAULT_SETTINGS.keys()\n                if hasattr(settings, key)}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntransform rules list from env - string to python.", "response": "def _rules_from_env(self, val):\n        \"\"\"Transforms rules list from env-string to python.\"\"\"\n        val = val.split(':')\n        if 'DEFAULT_RULES' in val:\n            val = const.DEFAULT_RULES + [rule for rule in val if rule != 'DEFAULT_RULES']\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _priority_from_env(self, val):\n        for part in val.split(':'):\n            try:\n                rule, priority = part.split('=')\n                yield rule, int(priority)\n            except ValueError:\n                continue", "response": "Gets priority pairs from env."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntransform env - strings to python.", "response": "def _val_from_env(self, env, attr):\n        \"\"\"Transforms env-strings to python.\"\"\"\n        val = os.environ[env]\n        if attr in ('rules', 'exclude_rules'):\n            return self._rules_from_env(val)\n        elif attr == 'priority':\n            return dict(self._priority_from_env(val))\n        elif attr in ('wait_command', 'history_limit', 'wait_slow_command',\n                      'num_close_matches'):\n            return int(val)\n        elif attr in ('require_confirmation', 'no_colors', 'debug',\n                      'alter_history', 'instant_mode'):\n            return val.lower() == 'true'\n        elif attr == 'slow_commands':\n            return val.split(':')\n        else:\n            return val"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _settings_from_env(self):\n        return {attr: self._val_from_env(env, attr)\n                for env, attr in const.ENV_TO_ATTR.items()\n                if env in os.environ}", "response": "Loads settings from env."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload settings from args.", "response": "def _settings_from_args(self, args):\n        \"\"\"Loads settings from args.\"\"\"\n        if not args:\n            return {}\n\n        from_args = {}\n        if args.yes:\n            from_args['require_confirmation'] = not args.yes\n        if args.debug:\n            from_args['debug'] = args.debug\n        if args.repeat:\n            from_args['repeat'] = args.repeat\n        return from_args"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_destination(script_parts):\n    for part in script_parts:\n        if part not in {'ln', '-s', '--symbolic'} and os.path.exists(part):\n            return part", "response": "Returns the destination of the script."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sudo_support(fn, command):\n    if not command.script.startswith('sudo '):\n        return fn(command)\n\n    result = fn(command.update(script=command.script[5:]))\n\n    if result and isinstance(result, six.string_types):\n        return u'sudo {}'.format(result)\n    elif isinstance(result, list):\n        return [u'sudo {}'.format(x) for x in result]\n    else:\n        return result", "response": "Removes sudo before calling fn and adds it after."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _kill_process(proc):\n    try:\n        proc.kill()\n    except AccessDenied:\n        logs.debug(u'Rerun: process PID {} ({}) could not be terminated'.format(\n            proc.pid, proc.exe()))", "response": "Tries to kill the process if it can t be terminated just logs a debug message"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if we can get output of the command in the settings. wait_command time.", "response": "def _wait_output(popen, is_slow):\n    \"\"\"Returns `True` if we can get output of the command in the\n    `settings.wait_command` time.\n\n    Command will be killed if it wasn't finished in the time.\n\n    :type popen: Popen\n    :rtype: bool\n\n    \"\"\"\n    proc = Process(popen.pid)\n    try:\n        proc.wait(settings.wait_slow_command if is_slow\n                  else settings.wait_command)\n        return True\n    except TimeoutExpired:\n        for child in proc.children(recursive=True):\n            _kill_process(child)\n        _kill_process(proc)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_output(script, expanded):\n    env = dict(os.environ)\n    env.update(settings.env)\n\n    is_slow = shlex.split(expanded) in settings.slow_commands\n    with logs.debug_time(u'Call: {}; with env: {}; is slow: '.format(\n            script, env, is_slow)):\n        result = Popen(expanded, shell=True, stdin=PIPE,\n                       stdout=PIPE, stderr=STDOUT, env=env)\n        if _wait_output(result, is_slow):\n            output = result.stdout.read().decode('utf-8')\n            logs.debug(u'Received output: {}'.format(output))\n            return output\n        else:\n            logs.debug(u'Execution timed out!')\n            return None", "response": "Runs the script and obtains stdout and stderr."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread script output from log and returns it as string.", "response": "def get_output(script):\n    \"\"\"Reads script output from log.\n\n    :type script: str\n    :rtype: str | None\n\n    \"\"\"\n    if six.PY2:\n        logs.warn('Experimental instant mode is Python 3+ only')\n        return None\n\n    if 'THEFUCK_OUTPUT_LOG' not in os.environ:\n        logs.warn(\"Output log isn't specified\")\n        return None\n\n    if const.USER_COMMAND_MARK not in os.environ.get('PS1', ''):\n        logs.warn(\n            \"PS1 doesn't contain user command mark, please ensure \"\n            \"that PS1 is not changed after The Fuck alias initialization\")\n        return None\n\n    try:\n        with logs.debug_time(u'Read output from log'):\n            fd = os.open(os.environ['THEFUCK_OUTPUT_LOG'], os.O_RDONLY)\n            buffer = mmap.mmap(fd, const.LOG_SIZE_IN_BYTES, mmap.MAP_SHARED, mmap.PROT_READ)\n            _skip_old_lines(buffer)\n            lines = _get_output_lines(script, buffer)\n            output = '\\n'.join(lines).strip()\n            logs.debug(u'Received output: {}'.format(output))\n            return output\n    except OSError:\n        logs.warn(\"Can't read output log\")\n        return None\n    except ScriptNotInLog:\n        logs.warn(\"Script not found in output log\")\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the packages that provide the given command using pkgfile.", "response": "def get_pkgfile(command):\n    \"\"\" Gets the packages that provide the given command using `pkgfile`.\n\n    If the command is of the form `sudo foo`, searches for the `foo` command\n    instead.\n    \"\"\"\n    try:\n        command = command.strip()\n\n        if command.startswith('sudo '):\n            command = command[5:]\n\n        command = command.split(\" \")[0]\n\n        packages = subprocess.check_output(\n            ['pkgfile', '-b', '-v', command],\n            universal_newlines=True, stderr=utils.DEVNULL\n        ).splitlines()\n\n        return [package.split()[0] for package in packages]\n    except subprocess.CalledProcessError as err:\n        if err.returncode == 1 and err.output == \"\":\n            return []\n        else:\n            raise err"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_sub_dirs(parent):\n    return [child for child in os.listdir(parent) if os.path.isdir(os.path.join(parent, child))]", "response": "Returns a list of the child directories of the given parent directory"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_new_command(command):\n    dest = command.script_parts[1].split(os.sep)\n    if dest[-1] == '':\n        dest = dest[:-1]\n\n    if dest[0] == '':\n        cwd = os.sep\n        dest = dest[1:]\n    elif six.PY2:\n        cwd = os.getcwdu()\n    else:\n        cwd = os.getcwd()\n    for directory in dest:\n        if directory == \".\":\n            continue\n        elif directory == \"..\":\n            cwd = os.path.split(cwd)[0]\n            continue\n        best_matches = get_close_matches(directory, _get_sub_dirs(cwd), cutoff=MAX_ALLOWED_DIFF)\n        if best_matches:\n            cwd = os.path.join(cwd, best_matches[0])\n        else:\n            return cd_mkdir.get_new_command(command)\n    return u'cd \"{0}\"'.format(cwd)", "response": "Returns a new command that can be used to rebuild the path string by spellchecking the directories."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, **kwargs):\n        kwargs.setdefault('script', self.script)\n        kwargs.setdefault('output', self.output)\n        return Command(**kwargs)", "response": "Returns new command with replaced fields."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_raw_script(cls, raw_script):\n        script = format_raw_script(raw_script)\n        if not script:\n            raise EmptyCommand\n\n        expanded = shell.from_shell(script)\n        output = get_output(script, expanded)\n        return cls(expanded, output)", "response": "Creates a Command instance from a list of script parts."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_path(cls, path):\n        name = path.name[:-3]\n        with logs.debug_time(u'Importing rule: {};'.format(name)):\n            rule_module = load_source(name, str(path))\n            priority = getattr(rule_module, 'priority', DEFAULT_PRIORITY)\n        return cls(name, rule_module.match,\n                   rule_module.get_new_command,\n                   getattr(rule_module, 'enabled_by_default', True),\n                   getattr(rule_module, 'side_effect', None),\n                   settings.priority.get(name, priority),\n                   getattr(rule_module, 'requires_output', True))", "response": "Creates a new rule instance from a path."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True when rule enabled.", "response": "def is_enabled(self):\n        \"\"\"Returns `True` when rule enabled.\n\n        :rtype: bool\n\n        \"\"\"\n        if self.name in settings.exclude_rules:\n            return False\n        elif self.name in settings.rules:\n            return True\n        elif self.enabled_by_default and ALL_ENABLED in settings.rules:\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_match(self, command):\n        if command.output is None and self.requires_output:\n            return False\n\n        try:\n            with logs.debug_time(u'Trying rule: {};'.format(self.name)):\n                if self.match(command):\n                    return True\n        except Exception:\n            logs.rule_failed(self, sys.exc_info())", "response": "Returns True if rule matches the command."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns generator with corrected commands.", "response": "def get_corrected_commands(self, command):\n        \"\"\"Returns generator with corrected commands.\n\n        :type command: Command\n        :rtype: Iterable[CorrectedCommand]\n\n        \"\"\"\n        new_commands = self.get_new_command(command)\n        if not isinstance(new_commands, list):\n            new_commands = (new_commands,)\n        for n, new_command in enumerate(new_commands):\n            yield CorrectedCommand(script=new_command,\n                                   side_effect=self.side_effect,\n                                   priority=(n + 1) * self.priority)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn fixed commands script.", "response": "def _get_script(self):\n        \"\"\"Returns fixed commands script.\n\n        If `settings.repeat` is `True`, appends command with second attempt\n        of running fuck in case fixed command fails again.\n\n        \"\"\"\n        if settings.repeat:\n            repeat_fuck = '{} --repeat {}--force-command {}'.format(\n                get_alias(),\n                '--debug ' if settings.debug else '',\n                shell.quote(self.script))\n            return shell.or_(self.script, repeat_fuck)\n        else:\n            return self.script"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(self, old_cmd):\n        if self.side_effect:\n            self.side_effect(old_cmd, self.script)\n        if settings.alter_history:\n            shell.put_to_history(self.script)\n        # This depends on correct setting of PYTHONIOENCODING by the alias:\n        logs.debug(u'PYTHONIOENCODING: {}'.format(\n            os.environ.get('PYTHONIOENCODING', '!!not-set!!')))\n\n        print(self._get_script())", "response": "Runs command from rule for passed command."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_shell_pid():\n    proc = Process(os.getpid())\n\n    try:\n        return proc.parent().pid\n    except TypeError:\n        return proc.parent.pid", "response": "Returns parent process pid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _record_first_run():\n    info = {'pid': _get_shell_pid(),\n            'time': time.time()}\n\n    mode = 'wb' if six.PY2 else 'w'\n    with _get_not_configured_usage_tracker_path().open(mode) as tracker:\n        json.dump(info, tracker)", "response": "Records shell pid to tracker file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _is_second_run():\n    tracker_path = _get_not_configured_usage_tracker_path()\n    if not tracker_path.exists():\n        return False\n\n    current_pid = _get_shell_pid()\n    with tracker_path.open('r') as tracker:\n        try:\n            info = json.load(tracker)\n        except ValueError:\n            return False\n\n    if not (isinstance(info, dict) and info.get('pid') == current_pid):\n        return False\n\n    return (_get_previous_command() == 'fuck' or\n            time.time() - info.get('time', 0) < const.CONFIGURATION_TIMEOUT)", "response": "Returns True when we know that fuck called second time."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _is_already_configured(configuration_details):\n    path = Path(configuration_details.path).expanduser()\n    with path.open('r') as shell_config:\n        return configuration_details.content in shell_config.read()", "response": "Returns True when alias already in shell config."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _configure(configuration_details):\n    path = Path(configuration_details.path).expanduser()\n    with path.open('a') as shell_config:\n        shell_config.write(u'\\n')\n        shell_config.write(configuration_details.content)\n        shell_config.write(u'\\n')", "response": "Adds alias to shell config."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main():\n    settings.init()\n    configuration_details = shell.how_to_configure()\n    if (\n        configuration_details and\n        configuration_details.can_configure_automatically\n    ):\n        if _is_already_configured(configuration_details):\n            logs.already_configured(configuration_details)\n            return\n        elif _is_second_run():\n            _configure(configuration_details)\n            logs.configured_successfully(configuration_details)\n            return\n        else:\n            _record_first_run()\n\n    logs.how_to_configure_alias(configuration_details)", "response": "Shows useful information about how - to configure alias on a first run\n    and configure automatically on a second run\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncaches previous calls to the function.", "response": "def memoize(fn):\n    \"\"\"Caches previous calls to the function.\"\"\"\n    memo = {}\n\n    @wraps(fn)\n    def wrapper(*args, **kwargs):\n        if not memoize.disabled:\n            key = pickle.dumps((args, kwargs))\n            if key not in memo:\n                memo[key] = fn(*args, **kwargs)\n            value = memo[key]\n        else:\n            # Memoize is disabled, call the function\n            value = fn(*args, **kwargs)\n\n        return value\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding default values to settings if it not presented. Usage: @default_settings({'apt': '/usr/bin/apt'}) def match(command): print(settings.apt)", "response": "def default_settings(params):\n    \"\"\"Adds default values to settings if it not presented.\n\n    Usage:\n\n        @default_settings({'apt': '/usr/bin/apt'})\n        def match(command):\n            print(settings.apt)\n\n    \"\"\"\n    def _default_settings(fn, command):\n        for k, w in params.items():\n            settings.setdefault(k, w)\n        return fn(command)\n    return decorator(_default_settings)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn closest match or just first from possibilities.", "response": "def get_closest(word, possibilities, cutoff=0.6, fallback_to_first=True):\n    \"\"\"Returns closest match or just first from possibilities.\"\"\"\n    possibilities = list(possibilities)\n    try:\n        return difflib_get_close_matches(word, possibilities, 1, cutoff)[0]\n    except IndexError:\n        if fallback_to_first:\n            return possibilities[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_close_matches(word, possibilities, n=None, cutoff=0.6):\n    if n is None:\n        n = settings.num_close_matches\n    return difflib_get_close_matches(word, possibilities, n, cutoff)", "response": "Overrides difflib. get_close_match to controle argument n."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef replace_argument(script, from_, to):\n    replaced_in_the_end = re.sub(u' {}$'.format(re.escape(from_)), u' {}'.format(to),\n                                 script, count=1)\n    if replaced_in_the_end != script:\n        return replaced_in_the_end\n    else:\n        return script.replace(\n            u' {} '.format(from_), u' {} '.format(to), 1)", "response": "Replaces command line argument from_ to to."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if command is called to one of passed app names.", "response": "def is_app(command, *app_names, **kwargs):\n    \"\"\"Returns `True` if command is call to one of passed app names.\"\"\"\n\n    at_least = kwargs.pop('at_least', 0)\n    if kwargs:\n        raise TypeError(\"got an unexpected keyword argument '{}'\".format(kwargs.keys()))\n\n    if len(command.script_parts) > at_least:\n        return command.script_parts[0] in app_names\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef for_app(*app_names, **kwargs):\n    def _for_app(fn, command):\n        if is_app(command, *app_names, **kwargs):\n            return fn(command)\n        else:\n            return False\n\n    return decorator(_for_app)", "response": "Specifies that matching script is for on of app names."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncaches function result in temporary file. Cache will be expired when modification date of files from `depends_on` will be changed. Only functions should be wrapped in `cache`, not methods.", "response": "def cache(*depends_on):\n    \"\"\"Caches function result in temporary file.\n\n    Cache will be expired when modification date of files from `depends_on`\n    will be changed.\n\n    Only functions should be wrapped in `cache`, not methods.\n\n    \"\"\"\n    def cache_decorator(fn):\n        @memoize\n        @wraps(fn)\n        def wrapper(*args, **kwargs):\n            if cache.disabled:\n                return fn(*args, **kwargs)\n            else:\n                return _cache.get_value(fn, depends_on, args, kwargs)\n\n        return wrapper\n\n    return cache_decorator"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef format_raw_script(raw_script):\n    if six.PY2:\n        script = ' '.join(arg.decode('utf-8') for arg in raw_script)\n    else:\n        script = ' '.join(raw_script)\n\n    return script.strip()", "response": "Formats a list of script parts into a single script."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_action(self, brain_info: BrainInfo) -> ActionInfo:\n        if len(brain_info.agents) == 0:\n            return ActionInfo([], [], [], None, None)\n\n        run_out = self.evaluate(brain_info)\n        return ActionInfo(\n            action=run_out.get('action'),\n            memory=run_out.get('memory_out'),\n            text=None,\n            value=run_out.get('value'),\n            outputs=run_out\n        )", "response": "Decides actions given observations information and takes them in environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _execute_model(self, feed_dict, out_dict):\n        network_out = self.sess.run(list(out_dict.values()), feed_dict=feed_dict)\n        run_out = dict(zip(list(out_dict.keys()), network_out))\n        return run_out", "response": "Executes model.\n        :param feed_dict: Input dictionary mapping nodes to input data.\n        :param out_dict: Output dictionary mapping names to nodes.\n        :return: Dictionary mapping names to input data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_current_step(self):\n        step = self.sess.run(self.model.global_step)\n        return step", "response": "Gets current model step."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_model(self, steps):\n        with self.graph.as_default():\n            last_checkpoint = self.model_path + '/model-' + str(steps) + '.cptk'\n            self.saver.save(self.sess, last_checkpoint)\n            tf.train.write_graph(self.graph, self.model_path,\n                                 'raw_graph_def.pb', as_text=False)", "response": "Saves the model to disk."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexport the latest saved model to. nn format for Unity embedding.", "response": "def export_model(self):\n        \"\"\"\n        Exports latest saved model to .nn format for Unity embedding.\n        \"\"\"\n\n        with self.graph.as_default():\n            target_nodes = ','.join(self._process_graph())\n            ckpt = tf.train.get_checkpoint_state(self.model_path)\n            freeze_graph.freeze_graph(\n                input_graph=self.model_path + '/raw_graph_def.pb',\n                input_binary=True,\n                input_checkpoint=ckpt.model_checkpoint_path,\n                output_node_names=target_nodes,\n                output_graph=(self.model_path + '/frozen_graph_def.pb'),\n                clear_devices=True, initializer_nodes='', input_saver='',\n                restore_op_name='save/restore_all',\n                filename_tensor_name='save/Const:0')\n\n        tf2bc.convert(self.model_path + '/frozen_graph_def.pb', self.model_path + '.nn')\n        logger.info('Exported ' + self.model_path + '.nn file')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the list of output nodes present in the graph for inference", "response": "def _process_graph(self):\n        \"\"\"\n        Gets the list of the output nodes present in the graph for inference\n        :return: list of node names\n        \"\"\"\n        all_nodes = [x.name for x in self.graph.as_graph_def().node]\n        nodes = [x for x in all_nodes if x in self.possible_output_nodes]\n        logger.info('List of nodes to export for brain :' + self.brain.brain_name)\n        for n in nodes:\n            logger.info('\\t' + n)\n        return nodes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reset_local_buffers(self):\n        agent_ids = list(self.keys())\n        for k in agent_ids:\n            self[k].reset_agent()", "response": "Resets all the local buffers that are not yet in use."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef append_update_buffer(self, agent_id, key_list=None, batch_size=None, training_length=None):\n        if key_list is None:\n            key_list = self[agent_id].keys()\n        if not self[agent_id].check_length(key_list):\n            raise BufferException(\"The length of the fields {0} for agent {1} where not of same length\"\n                                  .format(key_list, agent_id))\n        for field_key in key_list:\n            self.update_buffer[field_key].extend(\n                self[agent_id][field_key].get_batch(batch_size=batch_size, training_length=training_length)\n            )", "response": "Append the buffer of the data for the given agent to the update buffer."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef append_all_agent_batch_to_update_buffer(self, key_list=None, batch_size=None, training_length=None):\n        for agent_id in self.keys():\n            self.append_update_buffer(agent_id, key_list, batch_size, training_length)", "response": "Appends the buffer of all agents to the update buffer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlaunch training session. :param process_queue: Queue used to send signal back to main. :param sub_id: Unique id for training session. :param run_seed: Random seed used for training. :param run_options: Command line arguments for training.", "response": "def run_training(sub_id: int, run_seed: int, run_options, process_queue):\n    \"\"\"\n    Launches training session.\n    :param process_queue: Queue used to send signal back to main.\n    :param sub_id: Unique id for training session.\n    :param run_seed: Random seed used for training.\n    :param run_options: Command line arguments for training.\n    \"\"\"\n    # Docker Parameters\n    docker_target_name = (run_options['--docker-target-name']\n                          if run_options['--docker-target-name'] != 'None' else None)\n\n    # General parameters\n    env_path = (run_options['--env']\n                if run_options['--env'] != 'None' else None)\n    run_id = run_options['--run-id']\n    load_model = run_options['--load']\n    train_model = run_options['--train']\n    save_freq = int(run_options['--save-freq'])\n    keep_checkpoints = int(run_options['--keep-checkpoints'])\n    base_port = int(run_options['--base-port'])\n    num_envs = int(run_options['--num-envs'])\n    curriculum_folder = (run_options['--curriculum']\n                         if run_options['--curriculum'] != 'None' else None)\n    lesson = int(run_options['--lesson'])\n    fast_simulation = not bool(run_options['--slow'])\n    no_graphics = run_options['--no-graphics']\n    trainer_config_path = run_options['<trainer-config-path>']\n    # Recognize and use docker volume if one is passed as an argument\n    if not docker_target_name:\n        model_path = './models/{run_id}-{sub_id}'.format(run_id=run_id, sub_id=sub_id)\n        summaries_dir = './summaries'\n    else:\n        trainer_config_path = \\\n            '/{docker_target_name}/{trainer_config_path}'.format(\n                docker_target_name=docker_target_name,\n                trainer_config_path=trainer_config_path)\n        if curriculum_folder is not None:\n            curriculum_folder = \\\n                '/{docker_target_name}/{curriculum_folder}'.format(\n                    docker_target_name=docker_target_name,\n                    curriculum_folder=curriculum_folder)\n        model_path = '/{docker_target_name}/models/{run_id}-{sub_id}'.format(\n            docker_target_name=docker_target_name,\n            run_id=run_id,\n            sub_id=sub_id)\n        summaries_dir = '/{docker_target_name}/summaries'.format(\n            docker_target_name=docker_target_name)\n\n    trainer_config = load_config(trainer_config_path)\n    env_factory = create_environment_factory(\n        env_path,\n        docker_target_name,\n        no_graphics,\n        run_seed,\n        base_port + (sub_id * num_envs)\n    )\n    env = SubprocessUnityEnvironment(env_factory, num_envs)\n    maybe_meta_curriculum = try_create_meta_curriculum(curriculum_folder, env)\n\n    # Create controller and begin training.\n    tc = TrainerController(model_path, summaries_dir, run_id + '-' + str(sub_id),\n                           save_freq, maybe_meta_curriculum,\n                           load_model, train_model,\n                           keep_checkpoints, lesson, env.external_brains,\n                           run_seed, fast_simulation)\n\n    # Signal that environment has been launched.\n    process_queue.put(True)\n\n    # Begin training\n    tc.start_learning(env, trainer_config)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_action(self, curr_info: BrainInfo) -> ActionInfo:\n        self.trainer_metrics.start_experience_collection_timer()\n        action = self.policy.get_action(curr_info)\n        self.trainer_metrics.end_experience_collection_timer()\n        return action", "response": "Get an action from the policy given by the current BrainInfo."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites training statistics to Tensorboard.", "response": "def write_summary(self, global_step, delta_train_start, lesson_num=0):\n        \"\"\"\n        Saves training statistics to Tensorboard.\n        :param delta_train_start:  Time elapsed since training started.\n        :param lesson_num: Current lesson number in curriculum.\n        :param global_step: The number of steps the simulation has been going for\n        \"\"\"\n        if global_step % self.trainer_parameters['summary_freq'] == 0 and global_step != 0:\n            is_training = \"Training.\" if self.is_training and self.get_step <= self.get_max_steps else \"Not Training.\"\n            if len(self.stats['Environment/Cumulative Reward']) > 0:\n                mean_reward = np.mean(\n                    self.stats['Environment/Cumulative Reward'])\n                LOGGER.info(\" {}: {}: Step: {}. \"\n                            \"Time Elapsed: {:0.3f} s \"\n                            \"Mean \"\n                            \"Reward: {\"\n                            \":0.3f}. Std of Reward: {:0.3f}. {}\"\n                            .format(self.run_id, self.brain_name,\n                                    min(self.get_step, self.get_max_steps),\n                                    delta_train_start,\n                                    mean_reward, np.std(\n                                        self.stats['Environment/Cumulative Reward']),\n                                    is_training))\n            else:\n                LOGGER.info(\" {}: {}: Step: {}. No episode was completed since last summary. {}\"\n                            .format(self.run_id, self.brain_name, self.get_step, is_training))\n            summary = tf.Summary()\n            for key in self.stats:\n                if len(self.stats[key]) > 0:\n                    stat_mean = float(np.mean(self.stats[key]))\n                    summary.value.add(tag='{}'.format(\n                        key), simple_value=stat_mean)\n                    self.stats[key] = []\n            summary.value.add(tag='Environment/Lesson', simple_value=lesson_num)\n            self.summary_writer.add_summary(summary, self.get_step)\n            self.summary_writer.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_tensorboard_text(self, key, input_dict):\n        try:\n            with tf.Session() as sess:\n                s_op = tf.summary.text(key, tf.convert_to_tensor(\n                    ([[str(x), str(input_dict[x])] for x in input_dict])))\n                s = sess.run(s_op)\n                self.summary_writer.add_summary(s, self.get_step)\n        except:\n            LOGGER.info(\n                \"Cannot write text summary for Tensorboard. Tensorflow version must be r1.2 or above.\")\n            pass", "response": "Saves text to Tensorboard."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nattempting to increment all the lessons of all the curriculums in this MetaCurriculum. If the measure threshold is reached the curriculum will not increment. If the minimum number of episodes in the curriculum is reached the curriculum will not increment. If the minimum number of episodes in the curriculum will not increment.", "response": "def increment_lessons(self, measure_vals, reward_buff_sizes=None):\n        \"\"\"Attempts to increments all the lessons of all the curriculums in this\n        MetaCurriculum. Note that calling this method does not guarantee the\n        lesson of a curriculum will increment. The lesson of a curriculum will\n        only increment if the specified measure threshold defined in the\n        curriculum has been reached and the minimum number of episodes in the\n        lesson have been completed.\n\n        Args:\n            measure_vals (dict): A dict of brain name to measure value.\n            reward_buff_sizes (dict): A dict of brain names to the size of their\n                corresponding reward buffers.\n\n        Returns:\n            A dict from brain name to whether that brain's lesson number was\n            incremented.\n        \"\"\"\n        ret = {}\n        if reward_buff_sizes:\n            for brain_name, buff_size in reward_buff_sizes.items():\n                if self._lesson_ready_to_increment(brain_name, buff_size):\n                    measure_val = measure_vals[brain_name]\n                    ret[brain_name] = (self.brains_to_curriculums[brain_name]\n                                           .increment_lesson(measure_val))\n        else:\n            for brain_name, measure_val in measure_vals.items():\n                ret[brain_name] = (self.brains_to_curriculums[brain_name]\n                                       .increment_lesson(measure_val))\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets all the curriculums in this meta curriculum to a specified lesson number.", "response": "def set_all_curriculums_to_lesson_num(self, lesson_num):\n        \"\"\"Sets all the curriculums in this meta curriculum to a specified\n        lesson number.\n\n        Args:\n            lesson_num (int): The lesson number which all the curriculums will\n                be set to.\n        \"\"\"\n        for _, curriculum in self.brains_to_curriculums.items():\n            curriculum.lesson_num = lesson_num"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_config(self):\n        config = {}\n\n        for _, curriculum in self.brains_to_curriculums.items():\n            curr_config = curriculum.get_config()\n            config.update(curr_config)\n\n        return config", "response": "Get the combined configuration of all curriculums in this MetaCurriculum."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreset the unity environment.", "response": "def reset(self, config=None, train_mode=True, custom_reset_parameters=None) -> AllBrainInfo:\n        \"\"\"\n        Sends a signal to reset the unity environment.\n        :return: AllBrainInfo  : A data structure corresponding to the initial reset state of the environment.\n        \"\"\"\n        if config is None:\n            config = self._resetParameters\n        elif config:\n            logger.info(\"Academy reset with parameters: {0}\"\n                        .format(', '.join([str(x) + ' -> ' + str(config[x]) for x in config])))\n        for k in config:\n            if (k in self._resetParameters) and (isinstance(config[k], (int, float))):\n                self._resetParameters[k] = config[k]\n            elif not isinstance(config[k], (int, float)):\n                raise UnityEnvironmentException(\n                    \"The value for parameter '{0}'' must be an Integer or a Float.\".format(k))\n            else:\n                raise UnityEnvironmentException(\n                    \"The parameter '{0}' is not a valid parameter.\".format(k))\n\n        if self._loaded:\n            outputs = self.communicator.exchange(\n                self._generate_reset_input(train_mode, config, custom_reset_parameters)\n            )\n            if outputs is None:\n                raise KeyboardInterrupt\n            rl_output = outputs.rl_output\n            s = self._get_state(rl_output)\n            self._global_done = s[1]\n            for _b in self._external_brain_names:\n                self._n_agents[_b] = len(s[0][_b].agents)\n            return s[0]\n        else:\n            raise UnityEnvironmentException(\"No Unity environment is loaded.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef step(self, vector_action=None, memory=None, text_action=None, value=None, custom_action=None) -> AllBrainInfo:\n        vector_action = {} if vector_action is None else vector_action\n        memory = {} if memory is None else memory\n        text_action = {} if text_action is None else text_action\n        value = {} if value is None else value\n        custom_action = {} if custom_action is None else custom_action\n\n        # Check that environment is loaded, and episode is currently running.\n        if self._loaded and not self._global_done and self._global_done is not None:\n            if isinstance(vector_action, self.SINGLE_BRAIN_ACTION_TYPES):\n                if self._num_external_brains == 1:\n                    vector_action = {self._external_brain_names[0]: vector_action}\n                elif self._num_external_brains > 1:\n                    raise UnityActionException(\n                        \"You have {0} brains, you need to feed a dictionary of brain names a keys, \"\n                        \"and vector_actions as values\".format(self._num_brains))\n                else:\n                    raise UnityActionException(\n                        \"There are no external brains in the environment, \"\n                        \"step cannot take a vector_action input\")\n\n            if isinstance(memory, self.SINGLE_BRAIN_ACTION_TYPES):\n                if self._num_external_brains == 1:\n                    memory = {self._external_brain_names[0]: memory}\n                elif self._num_external_brains > 1:\n                    raise UnityActionException(\n                        \"You have {0} brains, you need to feed a dictionary of brain names as keys \"\n                        \"and memories as values\".format(self._num_brains))\n                else:\n                    raise UnityActionException(\n                        \"There are no external brains in the environment, \"\n                        \"step cannot take a memory input\")\n\n            if isinstance(text_action, self.SINGLE_BRAIN_TEXT_TYPES):\n                if self._num_external_brains == 1:\n                    text_action = {self._external_brain_names[0]: text_action}\n                elif self._num_external_brains > 1:\n                    raise UnityActionException(\n                        \"You have {0} brains, you need to feed a dictionary of brain names as keys \"\n                        \"and text_actions as values\".format(self._num_brains))\n                else:\n                    raise UnityActionException(\n                        \"There are no external brains in the environment, \"\n                        \"step cannot take a value input\")\n\n            if isinstance(value, self.SINGLE_BRAIN_ACTION_TYPES):\n                if self._num_external_brains == 1:\n                    value = {self._external_brain_names[0]: value}\n                elif self._num_external_brains > 1:\n                    raise UnityActionException(\n                        \"You have {0} brains, you need to feed a dictionary of brain names as keys \"\n                        \"and state/action value estimates as values\".format(self._num_brains))\n                else:\n                    raise UnityActionException(\n                        \"There are no external brains in the environment, \"\n                        \"step cannot take a value input\")\n\n            if isinstance(custom_action, CustomAction):\n                if self._num_external_brains == 1:\n                    custom_action = {self._external_brain_names[0]: custom_action}\n                elif self._num_external_brains > 1:\n                    raise UnityActionException(\n                        \"You have {0} brains, you need to feed a dictionary of brain names as keys \"\n                        \"and CustomAction instances as values\".format(self._num_brains))\n                else:\n                    raise UnityActionException(\n                        \"There are no external brains in the environment, \"\n                        \"step cannot take a custom_action input\")\n\n            for brain_name in list(vector_action.keys()) + list(memory.keys()) + list(\n                    text_action.keys()):\n                if brain_name not in self._external_brain_names:\n                    raise UnityActionException(\n                        \"The name {0} does not correspond to an external brain \"\n                        \"in the environment\".format(brain_name))\n\n            for brain_name in self._external_brain_names:\n                n_agent = self._n_agents[brain_name]\n                if brain_name not in vector_action:\n                    if self._brains[brain_name].vector_action_space_type == \"discrete\":\n                        vector_action[brain_name] = [0.0] * n_agent * len(\n                            self._brains[brain_name].vector_action_space_size)\n                    else:\n                        vector_action[brain_name] = [0.0] * n_agent * \\\n                                                    self._brains[\n                                                        brain_name].vector_action_space_size[0]\n                else:\n                    vector_action[brain_name] = self._flatten(vector_action[brain_name])\n                if brain_name not in memory:\n                    memory[brain_name] = []\n                else:\n                    if memory[brain_name] is None:\n                        memory[brain_name] = []\n                    else:\n                        memory[brain_name] = self._flatten(memory[brain_name])\n                if brain_name not in text_action:\n                    text_action[brain_name] = [\"\"] * n_agent\n                else:\n                    if text_action[brain_name] is None:\n                        text_action[brain_name] = [\"\"] * n_agent\n                    if isinstance(text_action[brain_name], str):\n                        text_action[brain_name] = [text_action[brain_name]] * n_agent\n                if brain_name not in custom_action:\n                    custom_action[brain_name] = [None] * n_agent\n                else:\n                    if custom_action[brain_name] is None:\n                        custom_action[brain_name] = [None] * n_agent\n                    if isinstance(custom_action[brain_name], CustomAction):\n                        custom_action[brain_name] = [custom_action[brain_name]] * n_agent\n\n                number_text_actions = len(text_action[brain_name])\n                if not ((number_text_actions == n_agent) or number_text_actions == 0):\n                    raise UnityActionException(\n                        \"There was a mismatch between the provided text_action and \"\n                        \"the environment's expectation: \"\n                        \"The brain {0} expected {1} text_action but was given {2}\".format(\n                            brain_name, n_agent, number_text_actions))\n\n                discrete_check = self._brains[brain_name].vector_action_space_type == \"discrete\"\n\n                expected_discrete_size = n_agent * len(\n                    self._brains[brain_name].vector_action_space_size)\n\n                continuous_check = self._brains[brain_name].vector_action_space_type == \"continuous\"\n\n                expected_continuous_size = self._brains[brain_name].vector_action_space_size[\n                                               0] * n_agent\n\n                if not ((discrete_check and len(\n                        vector_action[brain_name]) == expected_discrete_size) or\n                        (continuous_check and len(\n                            vector_action[brain_name]) == expected_continuous_size)):\n                    raise UnityActionException(\n                        \"There was a mismatch between the provided action and \"\n                        \"the environment's expectation: \"\n                        \"The brain {0} expected {1} {2} action(s), but was provided: {3}\"\n                            .format(brain_name, str(expected_discrete_size)\n                        if discrete_check\n                        else str(expected_continuous_size),\n                                    self._brains[brain_name].vector_action_space_type,\n                                    str(vector_action[brain_name])))\n\n            outputs = self.communicator.exchange(\n                self._generate_step_input(vector_action, memory, text_action, value, custom_action))\n            if outputs is None:\n                raise KeyboardInterrupt\n            rl_output = outputs.rl_output\n            state = self._get_state(rl_output)\n            self._global_done = state[1]\n            for _b in self._external_brain_names:\n                self._n_agents[_b] = len(state[0][_b].agents)\n            return state[0]\n        elif not self._loaded:\n            raise UnityEnvironmentException(\"No Unity environment is loaded.\")\n        elif self._global_done:\n            raise UnityActionException(\n                \"The episode is completed. Reset the environment with 'reset()'\")\n        elif self.global_done is None:\n            raise UnityActionException(\n                \"You cannot conduct step without first calling reset. \"\n                \"Reset the environment with 'reset()'\")", "response": "This method is used to perform a single step of the environment dynamics."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _flatten(cls, arr) -> List[float]:\n        if isinstance(arr, cls.SCALAR_ACTION_TYPES):\n            arr = [float(arr)]\n        if isinstance(arr, np.ndarray):\n            arr = arr.tolist()\n        if len(arr) == 0:\n            return arr\n        if isinstance(arr[0], np.ndarray):\n            arr = [item for sublist in arr for item in sublist.tolist()]\n        if isinstance(arr[0], list):\n            arr = [item for sublist in arr for item in sublist]\n        arr = [float(x) for x in arr]\n        return arr", "response": "Converts arrays to list.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_state(self, output: UnityRLOutput) -> (AllBrainInfo, bool):\n        _data = {}\n        global_done = output.global_done\n        for brain_name in output.agentInfos:\n            agent_info_list = output.agentInfos[brain_name].value\n            _data[brain_name] = BrainInfo.from_agent_proto(agent_info_list,\n                                                           self.brains[brain_name])\n        return _data, global_done", "response": "Collect experience information from all external brains in environment at current step."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nend the experience collection timer.", "response": "def end_experience_collection_timer(self):\n        \"\"\"\n        Inform Metrics class that experience collection is done.\n        \"\"\"\n        if self.time_start_experience_collection:\n            curr_delta = time() - self.time_start_experience_collection\n            if self.delta_last_experience_collection is None:\n                self.delta_last_experience_collection = curr_delta\n            else:\n                self.delta_last_experience_collection += curr_delta\n        self.time_start_experience_collection = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_delta_step(self, delta: float):\n        if self.delta_last_experience_collection:\n            self.delta_last_experience_collection += delta\n        else:\n            self.delta_last_experience_collection = delta", "response": "Add delta to the last experience collection of the current time step in environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts the timer that is called when the policy update has started.", "response": "def start_policy_update_timer(self, number_experiences: int, mean_return: float):\n        \"\"\"\n        Inform Metrics class that policy update has started.\n        :int number_experiences: Number of experiences in Buffer at this point.\n        :float mean_return: Return averaged across all cumulative returns since last policy update\n        \"\"\"\n        self.last_buffer_length = number_experiences\n        self.last_mean_return = mean_return\n        self.time_policy_update_start = time()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nends of Policy Update Training Metrics class that policy update has started.", "response": "def end_policy_update(self):\n        \"\"\"\n        Inform Metrics class that policy update has started.\n        \"\"\"\n        if self.time_policy_update_start:\n            self.delta_policy_update = time() - self.time_policy_update_start\n        else:\n            self.delta_policy_update = 0\n        delta_train_start = time() - self.time_training_start\n        LOGGER.debug(\" Policy Update Training Metrics for {}: \"\n                     \"\\n\\t\\tTime to update Policy: {:0.3f} s \\n\"\n                     \"\\t\\tTime elapsed since training: {:0.3f} s \\n\"\n                     \"\\t\\tTime for experience collection: {:0.3f} s \\n\"\n                     \"\\t\\tBuffer Length: {} \\n\"\n                     \"\\t\\tReturns : {:0.3f}\\n\"\n                     .format(self.brain_name, self.delta_policy_update,\n                             delta_train_start, self.delta_last_experience_collection,\n                             self.last_buffer_length, self.last_mean_return))\n        self._add_row(delta_train_start)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_training_metrics(self):\n        with open(self.path, 'w') as file:\n            writer = csv.writer(file)\n            writer.writerow(FIELD_NAMES)\n            for row in self.rows:\n                writer.writerow(row)", "response": "Writes Training Metrics to CSV file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_reward_encoder():\n        last_reward = tf.Variable(0, name=\"last_reward\", trainable=False, dtype=tf.float32)\n        new_reward = tf.placeholder(shape=[], dtype=tf.float32, name='new_reward')\n        update_reward = tf.assign(last_reward, new_reward)\n        return last_reward, new_reward, update_reward", "response": "Creates TF ops to track and increment recent average cumulative reward."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_curiosity_encoders(self):\n        encoded_state_list = []\n        encoded_next_state_list = []\n\n        if self.vis_obs_size > 0:\n            self.next_visual_in = []\n            visual_encoders = []\n            next_visual_encoders = []\n            for i in range(self.vis_obs_size):\n                # Create input ops for next (t+1) visual observations.\n                next_visual_input = self.create_visual_input(self.brain.camera_resolutions[i],\n                                                             name=\"next_visual_observation_\" + str(i))\n                self.next_visual_in.append(next_visual_input)\n\n                # Create the encoder ops for current and next visual input. Not that these encoders are siamese.\n                encoded_visual = self.create_visual_observation_encoder(self.visual_in[i], self.curiosity_enc_size,\n                                                                        self.swish, 1, \"stream_{}_visual_obs_encoder\"\n                                                                        .format(i), False)\n\n                encoded_next_visual = self.create_visual_observation_encoder(self.next_visual_in[i],\n                                                                             self.curiosity_enc_size,\n                                                                             self.swish, 1,\n                                                                             \"stream_{}_visual_obs_encoder\".format(i),\n                                                                             True)\n                visual_encoders.append(encoded_visual)\n                next_visual_encoders.append(encoded_next_visual)\n\n            hidden_visual = tf.concat(visual_encoders, axis=1)\n            hidden_next_visual = tf.concat(next_visual_encoders, axis=1)\n            encoded_state_list.append(hidden_visual)\n            encoded_next_state_list.append(hidden_next_visual)\n\n        if self.vec_obs_size > 0:\n            # Create the encoder ops for current and next vector input. Not that these encoders are siamese.\n            # Create input op for next (t+1) vector observation.\n            self.next_vector_in = tf.placeholder(shape=[None, self.vec_obs_size], dtype=tf.float32,\n                                                 name='next_vector_observation')\n\n            encoded_vector_obs = self.create_vector_observation_encoder(self.vector_in,\n                                                                        self.curiosity_enc_size,\n                                                                        self.swish, 2, \"vector_obs_encoder\",\n                                                                        False)\n            encoded_next_vector_obs = self.create_vector_observation_encoder(self.next_vector_in,\n                                                                             self.curiosity_enc_size,\n                                                                             self.swish, 2,\n                                                                                 \"vector_obs_encoder\",\n                                                                             True)\n            encoded_state_list.append(encoded_vector_obs)\n            encoded_next_state_list.append(encoded_next_vector_obs)\n\n        encoded_state = tf.concat(encoded_state_list, axis=1)\n        encoded_next_state = tf.concat(encoded_next_state_list, axis=1)\n        return encoded_state, encoded_next_state", "response": "Creates state encoders for current and future observations."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate inverse model TensorFlow ops for Curiosity module.", "response": "def create_inverse_model(self, encoded_state, encoded_next_state):\n        \"\"\"\n        Creates inverse model TensorFlow ops for Curiosity module.\n        Predicts action taken given current and future encoded states.\n        :param encoded_state: Tensor corresponding to encoded current state.\n        :param encoded_next_state: Tensor corresponding to encoded next state.\n        \"\"\"\n        combined_input = tf.concat([encoded_state, encoded_next_state], axis=1)\n        hidden = tf.layers.dense(combined_input, 256, activation=self.swish)\n        if self.brain.vector_action_space_type == \"continuous\":\n            pred_action = tf.layers.dense(hidden, self.act_size[0], activation=None)\n            squared_difference = tf.reduce_sum(tf.squared_difference(pred_action, self.selected_actions), axis=1)\n            self.inverse_loss = tf.reduce_mean(tf.dynamic_partition(squared_difference, self.mask, 2)[1])\n        else:\n            pred_action = tf.concat(\n                [tf.layers.dense(hidden, self.act_size[i], activation=tf.nn.softmax)\n                 for i in range(len(self.act_size))], axis=1)\n            cross_entropy = tf.reduce_sum(-tf.log(pred_action + 1e-10) * self.selected_actions, axis=1)\n            self.inverse_loss = tf.reduce_mean(tf.dynamic_partition(cross_entropy, self.mask, 2)[1])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a forward model for Curiosity module.", "response": "def create_forward_model(self, encoded_state, encoded_next_state):\n        \"\"\"\n        Creates forward model TensorFlow ops for Curiosity module.\n        Predicts encoded future state based on encoded current state and given action.\n        :param encoded_state: Tensor corresponding to encoded current state.\n        :param encoded_next_state: Tensor corresponding to encoded next state.\n        \"\"\"\n        combined_input = tf.concat([encoded_state, self.selected_actions], axis=1)\n        hidden = tf.layers.dense(combined_input, 256, activation=self.swish)\n        # We compare against the concatenation of all observation streams, hence `self.vis_obs_size + int(self.vec_obs_size > 0)`.\n        pred_next_state = tf.layers.dense(hidden, self.curiosity_enc_size * (self.vis_obs_size + int(self.vec_obs_size > 0)),\n                                          activation=None)\n\n        squared_difference = 0.5 * tf.reduce_sum(tf.squared_difference(pred_next_state, encoded_next_state), axis=1)\n        self.intrinsic_reward = tf.clip_by_value(self.curiosity_strength * squared_difference, 0, 1)\n        self.forward_loss = tf.reduce_mean(tf.dynamic_partition(squared_difference, self.mask, 2)[1])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_ppo_optimizer(self, probs, old_probs, value, entropy, beta, epsilon, lr, max_step):\n        self.returns_holder = tf.placeholder(shape=[None], dtype=tf.float32, name='discounted_rewards')\n        self.advantage = tf.placeholder(shape=[None, 1], dtype=tf.float32, name='advantages')\n        self.learning_rate = tf.train.polynomial_decay(lr, self.global_step, max_step, 1e-10, power=1.0)\n\n        self.old_value = tf.placeholder(shape=[None], dtype=tf.float32, name='old_value_estimates')\n\n        decay_epsilon = tf.train.polynomial_decay(epsilon, self.global_step, max_step, 0.1, power=1.0)\n        decay_beta = tf.train.polynomial_decay(beta, self.global_step, max_step, 1e-5, power=1.0)\n        optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n\n        clipped_value_estimate = self.old_value + tf.clip_by_value(tf.reduce_sum(value, axis=1) - self.old_value,\n                                                                   - decay_epsilon, decay_epsilon)\n\n        v_opt_a = tf.squared_difference(self.returns_holder, tf.reduce_sum(value, axis=1))\n        v_opt_b = tf.squared_difference(self.returns_holder, clipped_value_estimate)\n        self.value_loss = tf.reduce_mean(tf.dynamic_partition(tf.maximum(v_opt_a, v_opt_b), self.mask, 2)[1])\n\n        # Here we calculate PPO policy loss. In continuous control this is done independently for each action gaussian\n        # and then averaged together. This provides significantly better performance than treating the probability\n        # as an average of probabilities, or as a joint probability.\n        r_theta = tf.exp(probs - old_probs)\n        p_opt_a = r_theta * self.advantage\n        p_opt_b = tf.clip_by_value(r_theta, 1.0 - decay_epsilon, 1.0 + decay_epsilon) * self.advantage\n        self.policy_loss = -tf.reduce_mean(tf.dynamic_partition(tf.minimum(p_opt_a, p_opt_b), self.mask, 2)[1])\n\n        self.loss = self.policy_loss + 0.5 * self.value_loss - decay_beta * tf.reduce_mean(\n            tf.dynamic_partition(entropy, self.mask, 2)[1])\n\n        if self.use_curiosity:\n            self.loss += 10 * (0.2 * self.forward_loss + 0.8 * self.inverse_loss)\n        self.update_batch = optimizer.minimize(self.loss)", "response": "Creates training - specific Tensorflow ops for PPO models."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef evaluate(self, brain_info):\n        feed_dict = {self.model.batch_size: len(brain_info.vector_observations),\n                     self.model.sequence_length: 1}\n        epsilon = None\n        if self.use_recurrent:\n            if not self.use_continuous_act:\n                feed_dict[self.model.prev_action] = brain_info.previous_vector_actions.reshape(\n                    [-1, len(self.model.act_size)])\n            if brain_info.memories.shape[1] == 0:\n                brain_info.memories = self.make_empty_memory(len(brain_info.agents))\n            feed_dict[self.model.memory_in] = brain_info.memories\n        if self.use_continuous_act:\n            epsilon = np.random.normal(\n                size=(len(brain_info.vector_observations), self.model.act_size[0]))\n            feed_dict[self.model.epsilon] = epsilon\n        feed_dict = self._fill_eval_dict(feed_dict, brain_info)\n        run_out = self._execute_model(feed_dict, self.inference_dict)\n        if self.use_continuous_act:\n            run_out['random_normal_epsilon'] = epsilon\n        return run_out", "response": "Evaluates policy for the agent experiences provided."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the model using the given mini_batch.", "response": "def update(self, mini_batch, num_sequences):\n        \"\"\"\n        Updates model using buffer.\n        :param num_sequences: Number of trajectories in batch.\n        :param mini_batch: Experience batch.\n        :return: Output from update process.\n        \"\"\"\n        feed_dict = {self.model.batch_size: num_sequences,\n                     self.model.sequence_length: self.sequence_length,\n                     self.model.mask_input: mini_batch['masks'].flatten(),\n                     self.model.returns_holder: mini_batch['discounted_returns'].flatten(),\n                     self.model.old_value: mini_batch['value_estimates'].flatten(),\n                     self.model.advantage: mini_batch['advantages'].reshape([-1, 1]),\n                     self.model.all_old_log_probs: mini_batch['action_probs'].reshape(\n                         [-1, sum(self.model.act_size)])}\n        if self.use_continuous_act:\n            feed_dict[self.model.output_pre] = mini_batch['actions_pre'].reshape(\n                [-1, self.model.act_size[0]])\n            feed_dict[self.model.epsilon] = mini_batch['random_normal_epsilon'].reshape(\n                [-1, self.model.act_size[0]])\n        else:\n            feed_dict[self.model.action_holder] = mini_batch['actions'].reshape(\n                [-1, len(self.model.act_size)])\n            if self.use_recurrent:\n                feed_dict[self.model.prev_action] = mini_batch['prev_action'].reshape(\n                    [-1, len(self.model.act_size)])\n            feed_dict[self.model.action_masks] = mini_batch['action_mask'].reshape(\n                [-1, sum(self.brain.vector_action_space_size)])\n        if self.use_vec_obs:\n            feed_dict[self.model.vector_in] = mini_batch['vector_obs'].reshape(\n                [-1, self.vec_obs_size])\n            if self.use_curiosity:\n                feed_dict[self.model.next_vector_in] = mini_batch['next_vector_in'].reshape(\n                    [-1, self.vec_obs_size])\n        if self.model.vis_obs_size > 0:\n            for i, _ in enumerate(self.model.visual_in):\n                _obs = mini_batch['visual_obs%d' % i]\n                if self.sequence_length > 1 and self.use_recurrent:\n                    (_batch, _seq, _w, _h, _c) = _obs.shape\n                    feed_dict[self.model.visual_in[i]] = _obs.reshape([-1, _w, _h, _c])\n                else:\n                    feed_dict[self.model.visual_in[i]] = _obs\n            if self.use_curiosity:\n                for i, _ in enumerate(self.model.visual_in):\n                    _obs = mini_batch['next_visual_obs%d' % i]\n                    if self.sequence_length > 1 and self.use_recurrent:\n                        (_batch, _seq, _w, _h, _c) = _obs.shape\n                        feed_dict[self.model.next_visual_in[i]] = _obs.reshape([-1, _w, _h, _c])\n                    else:\n                        feed_dict[self.model.next_visual_in[i]] = _obs\n        if self.use_recurrent:\n            mem_in = mini_batch['memory'][:, 0, :]\n            feed_dict[self.model.memory_in] = mem_in\n        self.has_updated = True\n        run_out = self._execute_model(feed_dict, self.update_dict)\n        return run_out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating intrinsic rewards for all agents in the current BrainInfo.", "response": "def get_intrinsic_rewards(self, curr_info, next_info):\n        \"\"\"\n        Generates intrinsic reward used for Curiosity-based training.\n        :BrainInfo curr_info: Current BrainInfo.\n        :BrainInfo next_info: Next BrainInfo.\n        :return: Intrinsic rewards for all agents.\n        \"\"\"\n        if self.use_curiosity:\n            if len(curr_info.agents) == 0:\n                return []\n\n            feed_dict = {self.model.batch_size: len(next_info.vector_observations),\n                         self.model.sequence_length: 1}\n            if self.use_continuous_act:\n                feed_dict[self.model.selected_actions] = next_info.previous_vector_actions\n            else:\n                feed_dict[self.model.action_holder] = next_info.previous_vector_actions\n            for i in range(self.model.vis_obs_size):\n                feed_dict[self.model.visual_in[i]] = curr_info.visual_observations[i]\n                feed_dict[self.model.next_visual_in[i]] = next_info.visual_observations[i]\n            if self.use_vec_obs:\n                feed_dict[self.model.vector_in] = curr_info.vector_observations\n                feed_dict[self.model.next_vector_in] = next_info.vector_observations\n            if self.use_recurrent:\n                if curr_info.memories.shape[1] == 0:\n                    curr_info.memories = self.make_empty_memory(len(curr_info.agents))\n                feed_dict[self.model.memory_in] = curr_info.memories\n            intrinsic_rewards = self.sess.run(self.model.intrinsic_reward,\n                                              feed_dict=feed_dict) * float(self.has_updated)\n            return intrinsic_rewards\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates value estimates for bootstrapping.", "response": "def get_value_estimate(self, brain_info, idx):\n        \"\"\"\n        Generates value estimates for bootstrapping.\n        :param brain_info: BrainInfo to be used for bootstrapping.\n        :param idx: Index in BrainInfo of agent.\n        :return: Value estimate.\n        \"\"\"\n        feed_dict = {self.model.batch_size: 1, self.model.sequence_length: 1}\n        for i in range(len(brain_info.visual_observations)):\n            feed_dict[self.model.visual_in[i]] = [brain_info.visual_observations[i][idx]]\n        if self.use_vec_obs:\n            feed_dict[self.model.vector_in] = [brain_info.vector_observations[idx]]\n        if self.use_recurrent:\n            if brain_info.memories.shape[1] == 0:\n                brain_info.memories = self.make_empty_memory(len(brain_info.agents))\n            feed_dict[self.model.memory_in] = [brain_info.memories[idx]]\n        if not self.use_continuous_act and self.use_recurrent:\n            feed_dict[self.model.prev_action] = brain_info.previous_vector_actions[idx].reshape(\n                [-1, len(self.model.act_size)])\n        value_estimate = self.sess.run(self.model.value, feed_dict)\n        return value_estimate"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the current reward value for the current policy.", "response": "def update_reward(self, new_reward):\n        \"\"\"\n        Updates reward value for policy.\n        :param new_reward: New reward to save.\n        \"\"\"\n        self.sess.run(self.model.update_reward,\n                      feed_dict={self.model.new_reward: new_reward})"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd experiences to each agent s experience history.", "response": "def add_experiences(self, curr_info: AllBrainInfo, next_info: AllBrainInfo,\n                        take_action_outputs):\n        \"\"\"\n        Adds experiences to each agent's experience history.\n        :param curr_info: Current AllBrainInfo (Dictionary of all current brains and corresponding BrainInfo).\n        :param next_info: Next AllBrainInfo (Dictionary of all current brains and corresponding BrainInfo).\n        :param take_action_outputs: The outputs of the take action method.\n        \"\"\"\n\n        # Used to collect information about student performance.\n        info_student = curr_info[self.brain_name]\n        next_info_student = next_info[self.brain_name]\n        for agent_id in info_student.agents:\n            self.evaluation_buffer[agent_id].last_brain_info = info_student\n\n        for agent_id in next_info_student.agents:\n            stored_info_student = self.evaluation_buffer[agent_id].last_brain_info\n            if stored_info_student is None:\n                continue\n            else:\n                next_idx = next_info_student.agents.index(agent_id)\n                if agent_id not in self.cumulative_rewards:\n                    self.cumulative_rewards[agent_id] = 0\n                self.cumulative_rewards[agent_id] += next_info_student.rewards[next_idx]\n                if not next_info_student.local_done[next_idx]:\n                    if agent_id not in self.episode_steps:\n                        self.episode_steps[agent_id] = 0\n                    self.episode_steps[agent_id] += 1"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_experiences(self, current_info: AllBrainInfo, next_info: AllBrainInfo):\n        info_student = next_info[self.brain_name]\n        for l in range(len(info_student.agents)):\n            if info_student.local_done[l]:\n                agent_id = info_student.agents[l]\n                self.stats['Environment/Cumulative Reward'].append(\n                    self.cumulative_rewards.get(agent_id, 0))\n                self.stats['Environment/Episode Length'].append(\n                    self.episode_steps.get(agent_id, 0))\n                self.cumulative_rewards[agent_id] = 0\n                self.episode_steps[agent_id] = 0", "response": "Processes the experiments in the current and next AllBrainInfo."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef end_episode(self):\n        self.evaluation_buffer.reset_local_buffers()\n        for agent_id in self.cumulative_rewards:\n            self.cumulative_rewards[agent_id] = 0\n        for agent_id in self.episode_steps:\n            self.episode_steps[agent_id] = 0", "response": "A signal that the Episode has ended. The buffer must be reset.\n        Get only called when the academy resets."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_global_steps():\n        global_step = tf.Variable(0, name=\"global_step\", trainable=False, dtype=tf.int32)\n        increment_step = tf.assign(global_step, tf.add(global_step, 1))\n        return global_step, increment_step", "response": "Creates TF ops to track and increment global training step."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate image input op.", "response": "def create_visual_input(camera_parameters, name):\n        \"\"\"\n        Creates image input op.\n        :param camera_parameters: Parameters for visual observation from BrainInfo.\n        :param name: Desired name of input op.\n        :return: input op.\n        \"\"\"\n        o_size_h = camera_parameters['height']\n        o_size_w = camera_parameters['width']\n        bw = camera_parameters['blackAndWhite']\n\n        if bw:\n            c_channels = 1\n        else:\n            c_channels = 3\n\n        visual_in = tf.placeholder(shape=[None, o_size_h, o_size_w, c_channels], dtype=tf.float32,\n                                   name=name)\n        return visual_in"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_vector_input(self, name='vector_observation'):\n        self.vector_in = tf.placeholder(shape=[None, self.vec_obs_size], dtype=tf.float32,\n                                        name=name)\n        if self.normalize:\n            self.running_mean = tf.get_variable(\"running_mean\", [self.vec_obs_size],\n                                                trainable=False, dtype=tf.float32,\n                                                initializer=tf.zeros_initializer())\n            self.running_variance = tf.get_variable(\"running_variance\", [self.vec_obs_size],\n                                                    trainable=False,\n                                                    dtype=tf.float32,\n                                                    initializer=tf.ones_initializer())\n            self.update_mean, self.update_variance = self.create_normalizer_update(self.vector_in)\n\n            self.normalized_state = tf.clip_by_value((self.vector_in - self.running_mean) / tf.sqrt(\n                self.running_variance / (tf.cast(self.global_step, tf.float32) + 1)), -5, 5,\n                                                     name=\"normalized_state\")\n            return self.normalized_state\n        else:\n            return self.vector_in", "response": "Creates the vector input."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a set of hidden state encoders for a vector observation.", "response": "def create_vector_observation_encoder(observation_input, h_size, activation, num_layers, scope,\n                                          reuse):\n        \"\"\"\n        Builds a set of hidden state encoders.\n        :param reuse: Whether to re-use the weights within the same scope.\n        :param scope: Graph scope for the encoder ops.\n        :param observation_input: Input vector.\n        :param h_size: Hidden layer size.\n        :param activation: What type of activation function to use for layers.\n        :param num_layers: number of hidden layers to create.\n        :return: List of hidden layer tensors.\n        \"\"\"\n        with tf.variable_scope(scope):\n            hidden = observation_input\n            for i in range(num_layers):\n                hidden = tf.layers.dense(hidden, h_size, activation=activation, reuse=reuse,\n                                         name=\"hidden_{}\".format(i),\n                                         kernel_initializer=c_layers.variance_scaling_initializer(\n                                             1.0))\n        return hidden"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a set of visual encoder tensors.", "response": "def create_visual_observation_encoder(self, image_input, h_size, activation, num_layers, scope,\n                                          reuse):\n        \"\"\"\n        Builds a set of visual (CNN) encoders.\n        :param reuse: Whether to re-use the weights within the same scope.\n        :param scope: The scope of the graph within which to create the ops.\n        :param image_input: The placeholder for the image input to use.\n        :param h_size: Hidden layer size.\n        :param activation: What type of activation function to use for layers.\n        :param num_layers: number of hidden layers to create.\n        :return: List of hidden layer tensors.\n        \"\"\"\n        with tf.variable_scope(scope):\n            conv1 = tf.layers.conv2d(image_input, 16, kernel_size=[8, 8], strides=[4, 4],\n                                     activation=tf.nn.elu, reuse=reuse, name=\"conv_1\")\n            conv2 = tf.layers.conv2d(conv1, 32, kernel_size=[4, 4], strides=[2, 2],\n                                     activation=tf.nn.elu, reuse=reuse, name=\"conv_2\")\n            hidden = c_layers.flatten(conv2)\n\n        with tf.variable_scope(scope + '/' + 'flat_encoding'):\n            hidden_flat = self.create_vector_observation_encoder(hidden, h_size, activation,\n                                                                 num_layers, scope, reuse)\n        return hidden_flat"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a discrete masking layer for the discrete actions.", "response": "def create_discrete_action_masking_layer(all_logits, action_masks, action_size):\n        \"\"\"\n        Creates a masking layer for the discrete actions\n        :param all_logits: The concatenated unnormalized action probabilities for all branches\n        :param action_masks: The mask for the logits. Must be of dimension [None x total_number_of_action]\n        :param action_size: A list containing the number of possible actions for each branch\n        :return: The action output dimension [batch_size, num_branches] and the concatenated normalized logits\n        \"\"\"\n        action_idx = [0] + list(np.cumsum(action_size))\n        branches_logits = [all_logits[:, action_idx[i]:action_idx[i + 1]] for i in range(len(action_size))]\n        branch_masks = [action_masks[:, action_idx[i]:action_idx[i + 1]] for i in range(len(action_size))]\n        raw_probs = [tf.multiply(tf.nn.softmax(branches_logits[k]) + 1.0e-10, branch_masks[k])\n                     for k in range(len(action_size))]\n        normalized_probs = [\n            tf.divide(raw_probs[k], tf.reduce_sum(raw_probs[k], axis=1, keepdims=True))\n            for k in range(len(action_size))]\n        output = tf.concat([tf.multinomial(tf.log(normalized_probs[k]), 1) for k in range(len(action_size))], axis=1)\n        return output, tf.concat([tf.log(normalized_probs[k] + 1.0e-10) for k in range(len(action_size))], axis=1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates encoding streams for observations.", "response": "def create_observation_streams(self, num_streams, h_size, num_layers):\n        \"\"\"\n        Creates encoding stream for observations.\n        :param num_streams: Number of streams to create.\n        :param h_size: Size of hidden linear layers in stream.\n        :param num_layers: Number of hidden linear layers in stream.\n        :return: List of encoded streams.\n        \"\"\"\n        brain = self.brain\n        activation_fn = self.swish\n\n        self.visual_in = []\n        for i in range(brain.number_visual_observations):\n            visual_input = self.create_visual_input(brain.camera_resolutions[i],\n                                                    name=\"visual_observation_\" + str(i))\n            self.visual_in.append(visual_input)\n        vector_observation_input = self.create_vector_input()\n\n        final_hiddens = []\n        for i in range(num_streams):\n            visual_encoders = []\n            hidden_state, hidden_visual = None, None\n            if self.vis_obs_size > 0:\n                for j in range(brain.number_visual_observations):\n                    encoded_visual = self.create_visual_observation_encoder(self.visual_in[j],\n                                                                            h_size,\n                                                                            activation_fn,\n                                                                            num_layers,\n                                                                            \"main_graph_{}_encoder{}\"\n                                                                            .format(i, j), False)\n                    visual_encoders.append(encoded_visual)\n                hidden_visual = tf.concat(visual_encoders, axis=1)\n            if brain.vector_observation_space_size > 0:\n                hidden_state = self.create_vector_observation_encoder(vector_observation_input,\n                                                                      h_size, activation_fn,\n                                                                      num_layers,\n                                                                      \"main_graph_{}\".format(i),\n                                                                      False)\n            if hidden_state is not None and hidden_visual is not None:\n                final_hidden = tf.concat([hidden_visual, hidden_state], axis=1)\n            elif hidden_state is None and hidden_visual is not None:\n                final_hidden = hidden_visual\n            elif hidden_state is not None and hidden_visual is None:\n                final_hidden = hidden_state\n            else:\n                raise Exception(\"No valid network configuration possible. \"\n                                \"There are no states or observations in this brain\")\n            final_hiddens.append(final_hidden)\n        return final_hiddens"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds a recurrent encoder for either state or observations of the LSTM cell.", "response": "def create_recurrent_encoder(input_state, memory_in, sequence_length, name='lstm'):\n        \"\"\"\n        Builds a recurrent encoder for either state or observations (LSTM).\n        :param sequence_length: Length of sequence to unroll.\n        :param input_state: The input tensor to the LSTM cell.\n        :param memory_in: The input memory to the LSTM cell.\n        :param name: The scope of the LSTM cell.\n        \"\"\"\n        s_size = input_state.get_shape().as_list()[1]\n        m_size = memory_in.get_shape().as_list()[1]\n        lstm_input_state = tf.reshape(input_state, shape=[-1, sequence_length, s_size])\n        memory_in = tf.reshape(memory_in[:, :], [-1, m_size])\n        _half_point = int(m_size / 2)\n        with tf.variable_scope(name):\n            rnn_cell = tf.contrib.rnn.BasicLSTMCell(_half_point)\n            lstm_vector_in = tf.contrib.rnn.LSTMStateTuple(memory_in[:, :_half_point],\n                                                           memory_in[:, _half_point:])\n            recurrent_output, lstm_state_out = tf.nn.dynamic_rnn(rnn_cell, lstm_input_state,\n                                                                 initial_state=lstm_vector_in)\n\n        recurrent_output = tf.reshape(recurrent_output, shape=[-1, _half_point])\n        return recurrent_output, tf.concat([lstm_state_out.c, lstm_state_out.h], axis=1)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_cc_actor_critic(self, h_size, num_layers):\n        hidden_streams = self.create_observation_streams(2, h_size, num_layers)\n\n        if self.use_recurrent:\n            self.memory_in = tf.placeholder(shape=[None, self.m_size], dtype=tf.float32,\n                                            name='recurrent_in')\n            _half_point = int(self.m_size / 2)\n            hidden_policy, memory_policy_out = self.create_recurrent_encoder(\n                hidden_streams[0], self.memory_in[:, :_half_point], self.sequence_length,\n                name='lstm_policy')\n\n            hidden_value, memory_value_out = self.create_recurrent_encoder(\n                hidden_streams[1], self.memory_in[:, _half_point:], self.sequence_length,\n                name='lstm_value')\n            self.memory_out = tf.concat([memory_policy_out, memory_value_out], axis=1,\n                                        name='recurrent_out')\n        else:\n            hidden_policy = hidden_streams[0]\n            hidden_value = hidden_streams[1]\n\n        mu = tf.layers.dense(hidden_policy, self.act_size[0], activation=None,\n                             kernel_initializer=c_layers.variance_scaling_initializer(factor=0.01))\n\n        log_sigma_sq = tf.get_variable(\"log_sigma_squared\", [self.act_size[0]], dtype=tf.float32,\n                                       initializer=tf.zeros_initializer())\n\n        sigma_sq = tf.exp(log_sigma_sq)\n\n        self.epsilon = tf.placeholder(shape=[None, self.act_size[0]], dtype=tf.float32, name='epsilon')\n        # Clip and scale output to ensure actions are always within [-1, 1] range.\n        self.output_pre = mu + tf.sqrt(sigma_sq) * self.epsilon\n        output_post = tf.clip_by_value(self.output_pre, -3, 3) / 3\n        self.output = tf.identity(output_post, name='action')\n        self.selected_actions = tf.stop_gradient(output_post)\n\n        # Compute probability of model output.\n        all_probs = - 0.5 * tf.square(tf.stop_gradient(self.output_pre) - mu) / sigma_sq \\\n                    - 0.5 * tf.log(2.0 * np.pi) - 0.5 * log_sigma_sq\n\n        self.all_log_probs = tf.identity(all_probs, name='action_probs')\n\n        self.entropy = 0.5 * tf.reduce_mean(tf.log(2 * np.pi * np.e) + log_sigma_sq)\n\n        value = tf.layers.dense(hidden_value, 1, activation=None)\n        self.value = tf.identity(value, name=\"value_estimate\")\n\n        self.all_old_log_probs = tf.placeholder(shape=[None, self.act_size[0]], dtype=tf.float32,\n                                                name='old_probabilities')\n\n        # We keep these tensors the same name, but use new nodes to keep code parallelism with discrete control.\n        self.log_probs = tf.reduce_sum((tf.identity(self.all_log_probs)), axis=1, keepdims=True)\n        self.old_log_probs = tf.reduce_sum((tf.identity(self.all_old_log_probs)), axis=1,\n                                           keepdims=True)", "response": "Creates Continuous control actor - critic model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating Discrete control actor - critic model.", "response": "def create_dc_actor_critic(self, h_size, num_layers):\n        \"\"\"\n        Creates Discrete control actor-critic model.\n        :param h_size: Size of hidden linear layers.\n        :param num_layers: Number of hidden linear layers.\n        \"\"\"\n        hidden_streams = self.create_observation_streams(1, h_size, num_layers)\n        hidden = hidden_streams[0]\n\n        if self.use_recurrent:\n            self.prev_action = tf.placeholder(shape=[None, len(self.act_size)], dtype=tf.int32,\n                                              name='prev_action')\n            prev_action_oh = tf.concat([\n                tf.one_hot(self.prev_action[:, i], self.act_size[i]) for i in\n                range(len(self.act_size))], axis=1)\n            hidden = tf.concat([hidden, prev_action_oh], axis=1)\n\n            self.memory_in = tf.placeholder(shape=[None, self.m_size], dtype=tf.float32,\n                                            name='recurrent_in')\n            hidden, memory_out = self.create_recurrent_encoder(hidden, self.memory_in,\n                                                               self.sequence_length)\n            self.memory_out = tf.identity(memory_out, name='recurrent_out')\n\n        policy_branches = []\n        for size in self.act_size:\n            policy_branches.append(tf.layers.dense(hidden, size, activation=None, use_bias=False,\n                                      kernel_initializer=c_layers.variance_scaling_initializer(factor=0.01)))\n\n        self.all_log_probs = tf.concat([branch for branch in policy_branches], axis=1, name=\"action_probs\")\n\n        self.action_masks = tf.placeholder(shape=[None, sum(self.act_size)], dtype=tf.float32, name=\"action_masks\")\n        output, normalized_logits = self.create_discrete_action_masking_layer(\n            self.all_log_probs, self.action_masks, self.act_size)\n\n        self.output = tf.identity(output)\n        self.normalized_logits = tf.identity(normalized_logits, name='action')\n\n        value = tf.layers.dense(hidden, 1, activation=None)\n        self.value = tf.identity(value, name=\"value_estimate\")\n\n        self.action_holder = tf.placeholder(\n            shape=[None, len(policy_branches)], dtype=tf.int32, name=\"action_holder\")\n        self.action_oh = tf.concat([\n            tf.one_hot(self.action_holder[:, i], self.act_size[i]) for i in range(len(self.act_size))], axis=1)\n        self.selected_actions = tf.stop_gradient(self.action_oh)\n\n        self.all_old_log_probs = tf.placeholder(\n            shape=[None, sum(self.act_size)], dtype=tf.float32, name='old_probabilities')\n        _, old_normalized_logits = self.create_discrete_action_masking_layer(\n            self.all_old_log_probs, self.action_masks, self.act_size)\n\n        action_idx = [0] + list(np.cumsum(self.act_size))\n\n        self.entropy = tf.reduce_sum((tf.stack([\n            tf.nn.softmax_cross_entropy_with_logits_v2(\n                labels=tf.nn.softmax(self.all_log_probs[:, action_idx[i]:action_idx[i + 1]]),\n                logits=self.all_log_probs[:, action_idx[i]:action_idx[i + 1]])\n            for i in range(len(self.act_size))], axis=1)), axis=1)\n\n        self.log_probs = tf.reduce_sum((tf.stack([\n            -tf.nn.softmax_cross_entropy_with_logits_v2(\n                labels=self.action_oh[:, action_idx[i]:action_idx[i + 1]],\n                logits=normalized_logits[:, action_idx[i]:action_idx[i + 1]]\n            )\n            for i in range(len(self.act_size))], axis=1)), axis=1, keepdims=True)\n        self.old_log_probs = tf.reduce_sum((tf.stack([\n            -tf.nn.softmax_cross_entropy_with_logits_v2(\n                labels=self.action_oh[:, action_idx[i]:action_idx[i + 1]],\n                logits=old_normalized_logits[:, action_idx[i]:action_idx[i + 1]]\n            )\n            for i in range(len(self.act_size))], axis=1)), axis=1, keepdims=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd experiences to each agent s experience history.", "response": "def add_experiences(self, curr_info: AllBrainInfo, next_info: AllBrainInfo,\n                        take_action_outputs):\n        \"\"\"\n        Adds experiences to each agent's experience history.\n        :param curr_info: Current AllBrainInfo (Dictionary of all current brains and corresponding BrainInfo).\n        :param next_info: Next AllBrainInfo (Dictionary of all current brains and corresponding BrainInfo).\n        :param take_action_outputs: The outputs of the take action method.\n        \"\"\"\n\n        # Used to collect teacher experience into training buffer\n        info_teacher = curr_info[self.brain_to_imitate]\n        next_info_teacher = next_info[self.brain_to_imitate]\n        for agent_id in info_teacher.agents:\n            self.demonstration_buffer[agent_id].last_brain_info = info_teacher\n\n        for agent_id in next_info_teacher.agents:\n            stored_info_teacher = self.demonstration_buffer[agent_id].last_brain_info\n            if stored_info_teacher is None:\n                continue\n            else:\n                idx = stored_info_teacher.agents.index(agent_id)\n                next_idx = next_info_teacher.agents.index(agent_id)\n                if stored_info_teacher.text_observations[idx] != \"\":\n                    info_teacher_record, info_teacher_reset = \\\n                        stored_info_teacher.text_observations[idx].lower().split(\",\")\n                    next_info_teacher_record, next_info_teacher_reset = \\\n                    next_info_teacher.text_observations[idx]. \\\n                        lower().split(\",\")\n                    if next_info_teacher_reset == \"true\":\n                        self.demonstration_buffer.reset_update_buffer()\n                else:\n                    info_teacher_record, next_info_teacher_record = \"true\", \"true\"\n                if info_teacher_record == \"true\" and next_info_teacher_record == \"true\":\n                    if not stored_info_teacher.local_done[idx]:\n                        for i in range(self.policy.vis_obs_size):\n                            self.demonstration_buffer[agent_id]['visual_obs%d' % i] \\\n                                .append(stored_info_teacher.visual_observations[i][idx])\n                        if self.policy.use_vec_obs:\n                            self.demonstration_buffer[agent_id]['vector_obs'] \\\n                                .append(stored_info_teacher.vector_observations[idx])\n                        if self.policy.use_recurrent:\n                            if stored_info_teacher.memories.shape[1] == 0:\n                                stored_info_teacher.memories = np.zeros(\n                                    (len(stored_info_teacher.agents),\n                                     self.policy.m_size))\n                            self.demonstration_buffer[agent_id]['memory'].append(\n                                stored_info_teacher.memories[idx])\n                        self.demonstration_buffer[agent_id]['actions'].append(\n                            next_info_teacher.previous_vector_actions[next_idx])\n\n        super(OnlineBCTrainer, self).add_experiences(curr_info, next_info, take_action_outputs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_experiences(self, current_info: AllBrainInfo, next_info: AllBrainInfo):\n        info_teacher = next_info[self.brain_to_imitate]\n        for l in range(len(info_teacher.agents)):\n            teacher_action_list = len(self.demonstration_buffer[info_teacher.agents[l]]['actions'])\n            horizon_reached = teacher_action_list > self.trainer_parameters['time_horizon']\n            teacher_filled = len(self.demonstration_buffer[info_teacher.agents[l]]['actions']) > 0\n            if (info_teacher.local_done[l] or horizon_reached) and teacher_filled:\n                agent_id = info_teacher.agents[l]\n                self.demonstration_buffer.append_update_buffer(\n                    agent_id, batch_size=None, training_length=self.policy.sequence_length)\n                self.demonstration_buffer[agent_id].reset_agent()\n\n        super(OnlineBCTrainer, self).process_experiences(current_info, next_info)", "response": "Process the experiments of the current and next trains."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nyields items from any nested iterable ; see REF.", "response": "def flatten(items,enter=lambda x:isinstance(x, list)):\n    # http://stackoverflow.com/a/40857703\n    # https://github.com/ctmakro/canton/blob/master/canton/misc.py\n    \"\"\"Yield items from any nested iterable; see REF.\"\"\"\n    for x in items:\n        if enter(x):\n            yield from flatten(x)\n        else:\n            yield x"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npreserves the order of elements in the list", "response": "def remove_duplicates_from_list(array):\n    \"Preserves the order of elements in the list\"\n    output = []\n    unique = set()\n    for a in array:\n        if a not in unique:\n            unique.add(a)\n            output.append(a)\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert from NHWC|NCHW to HW", "response": "def pool_to_HW(shape, data_frmt):\n    \"\"\" Convert from NHWC|NCHW => HW\n    \"\"\"\n    if len(shape) != 4:\n        return shape # Not NHWC|NCHW, return as is\n    if data_frmt == 'NCHW':\n        return [shape[2], shape[3]]\n    return [shape[1], shape[2]]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a TensorFlow model into a Barracuda model.", "response": "def convert(source_file, target_file, trim_unused_by_output=\"\", verbose=False, compress_f16=False):\n    \"\"\"\n    Converts a TensorFlow model into a Barracuda model.\n    :param source_file: The TensorFlow Model\n    :param target_file: The name of the file the converted model will be saved to\n    :param trim_unused_by_output: The regexp to match output nodes to remain in the model. All other uconnected nodes will be removed.\n    :param verbose: If True, will display debug messages\n    :param compress_f16: If true, the float values will be converted to f16\n    :return:\n    \"\"\"\n    if (type(verbose)==bool):\n        args = Struct()\n        args.verbose = verbose\n        args.print_layers = verbose\n        args.print_source_json = verbose\n        args.print_barracuda_json = verbose\n        args.print_layer_links = verbose\n        args.print_patterns = verbose\n        args.print_tensors = verbose\n    else:\n        args = verbose\n\n    # Load Tensorflow model\n    print(\"Converting %s to %s\" % (source_file, target_file))\n    f = open(source_file, 'rb')\n    i_model = tf.GraphDef()\n    i_model.ParseFromString(f.read())\n\n    if args.verbose:\n        print('OP_TYPES:', {layer.op for layer in i_model.node})\n\n    if args.print_source_json or args.verbose:\n        for layer in i_model.node:\n            if not layer.op == 'Const':\n                print('MODEL:', MessageToJson(layer) + \",\")\n\n    # Convert\n    o_model = barracuda.Model()\n    o_model.layers, o_input_shapes, o_model.tensors, o_model.memories = \\\n        process_model(i_model, args)\n\n    # Cleanup unconnected Identities (they might linger after processing complex node patterns like LSTM)\n    def cleanup_layers(layers):\n        all_layers = {l.name for l in layers}\n        all_inputs = {i for l in layers for i in l.inputs}\n\n        def is_unconnected_identity(layer):\n            if layer.class_name == 'Activation' and layer.activation == 0: # Identity\n                assert(len(layer.inputs) == 1)\n                if layer.inputs[0] not in all_layers and layer.name not in all_inputs:\n                    return True;\n            return False;\n\n        return [l for l in layers if not is_unconnected_identity(l)]\n    o_model.layers = cleanup_layers(o_model.layers)\n\n    all_inputs = {i for l in o_model.layers for i in l.inputs}\n    embedded_tensors = {t.name for l in o_model.layers for t in l.tensors}\n\n    # Find global tensors\n    def dims_to_barracuda_shape(dims):\n        shape = list(dims)\n        while len(shape) < 4:\n            shape = [1] + shape\n        return shape\n    o_model.globals = [t for t in o_model.tensors if t not in all_inputs and t not in embedded_tensors]\n    #for x in global_tensors:\n    #    shape = dims_to_barracuda_shape(get_tensor_dims(o_model.tensors[x]))    \n    #    o_globals += [Struct(\n    #        name = x,\n    #        shape = shape,\n    #        data = np.reshape(get_tensor_data(o_model.tensors[x]), shape).astype(np.float32))]\n\n    # Trim\n    if trim_unused_by_output:\n        o_model.layers = barracuda.trim(o_model.layers, trim_unused_by_output, args.verbose)\n\n    # Create load layers for constants\n    const_tensors = [i for i in all_inputs if i in o_model.tensors]\n    const_tensors += o_model.globals\n    for x in const_tensors:\n        shape = dims_to_barracuda_shape(get_tensor_dims(o_model.tensors[x]))\n\n        o_l = Struct(\n            type        = 255,  # Load\n            class_name  = \"Const\",\n            name        = x,\n            pads        = [0,0,0,0],\n            strides     = [],\n            pool_size   = [],\n            axis        = -1,\n            alpha       = 1,\n            beta        = 0,\n            activation  = 0,\n            inputs      = [],\n            tensors     = [Struct(\n                name = x,\n                shape = shape,\n                data = np.reshape(get_tensor_data(o_model.tensors[x]), shape).astype(np.float32))]\n        )\n        o_model.layers.insert(0, o_l)\n\n    # Find model inputs & outputs\n    all_layers = {l.name for l in o_model.layers}\n    # global inputs => are inputs that are NOT connected to any layer in the network\n    # global outputs => are outputs that are NOT feeding any layer in the network OR are coming from Identity layers\n    o_model.inputs = {i:o_input_shapes[i] for l in o_model.layers for i in l.inputs if i not in all_layers and i not in o_model.memories}\n\n    def is_output_layer(layer):\n        if layer.class_name == 'Const': # Constants never count as global output even when unconnected\n            return False;\n        if layer.name not in all_inputs: # this layer is not inputing to any other layer\n            return True\n        if layer.class_name == 'Activation' and layer.activation == 0: # Identity marks global output\n            return True\n        return False\n    o_model.outputs = [l.name for l in o_model.layers if is_output_layer(l)]\n\n    # Compress\n    if compress_f16:\n        o_model = barracuda.compress(o_model)\n\n    # Sort model so that layer inputs are always ready upfront\n    o_model.layers = barracuda.sort(o_model.layers, o_model.inputs, o_model.memories, args.verbose)\n\n    # Summary\n    barracuda.summary(o_model,\n        print_layer_links = args.print_layer_links or args.verbose,\n        print_barracuda_json = args.print_barracuda_json or args.verbose,\n        print_tensors = args.print_tensors or args.verbose)\n\n    # Write to file\n    barracuda.write(o_model, target_file)\n    print('DONE: wrote', target_file, 'file.')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload a demonstration file and uses it to fill training buffer.", "response": "def demo_to_buffer(file_path, sequence_length):\n    \"\"\"\n    Loads demonstration file and uses it to fill training buffer.\n    :param file_path: Location of demonstration file (.demo).\n    :param sequence_length: Length of trajectories to fill buffer.\n    :return:\n    \"\"\"\n    brain_params, brain_infos, _ = load_demonstration(file_path)\n    demo_buffer = make_demo_buffer(brain_infos, brain_params, sequence_length)\n    return brain_params, demo_buffer"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_demonstration(file_path):\n\n    # First 32 bytes of file dedicated to meta-data.\n    INITIAL_POS = 33\n\n    if not os.path.isfile(file_path):\n        raise FileNotFoundError(\"The demonstration file {} does not exist.\".format(file_path))\n    file_extension = pathlib.Path(file_path).suffix\n    if file_extension != '.demo':\n        raise ValueError(\"The file is not a '.demo' file. Please provide a file with the \"\n                         \"correct extension.\")\n\n    brain_params = None\n    brain_infos = []\n    data = open(file_path, \"rb\").read()\n    next_pos, pos, obs_decoded = 0, 0, 0\n    total_expected = 0\n    while pos < len(data):\n        next_pos, pos = _DecodeVarint32(data, pos)\n        if obs_decoded == 0:\n            meta_data_proto = DemonstrationMetaProto()\n            meta_data_proto.ParseFromString(data[pos:pos + next_pos])\n            total_expected = meta_data_proto.number_steps\n            pos = INITIAL_POS\n        if obs_decoded == 1:\n            brain_param_proto = BrainParametersProto()\n            brain_param_proto.ParseFromString(data[pos:pos + next_pos])\n            brain_params = BrainParameters.from_proto(brain_param_proto)\n            pos += next_pos\n        if obs_decoded > 1:\n            agent_info = AgentInfoProto()\n            agent_info.ParseFromString(data[pos:pos + next_pos])\n            brain_info = BrainInfo.from_agent_proto([agent_info], brain_params)\n            brain_infos.append(brain_info)\n            if len(brain_infos) == total_expected:\n                break\n            pos += next_pos\n        obs_decoded += 1\n    return brain_params, brain_infos, total_expected", "response": "Loads and parses a demonstration file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _save_model(self, steps=0):\n        for brain_name in self.trainers.keys():\n            self.trainers[brain_name].save_model()\n        self.logger.info('Saved Model')", "response": "Saves current model to checkpoint folder."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite all CSV metrics for all trains", "response": "def _write_training_metrics(self):\n        \"\"\"\n        Write all CSV metrics\n        :return:\n        \"\"\"\n        for brain_name in self.trainers.keys():\n            if brain_name in self.trainer_metrics:\n                self.trainers[brain_name].write_training_metrics()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexporting latest saved models to. nn format for Unity embedding.", "response": "def _export_graph(self):\n        \"\"\"\n        Exports latest saved models to .nn format for Unity embedding.\n        \"\"\"\n        for brain_name in self.trainers.keys():\n            self.trainers[brain_name].export_model()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef initialize_trainers(self, trainer_config: Dict[str, Dict[str, str]]):\n        trainer_parameters_dict = {}\n        for brain_name in self.external_brains:\n            trainer_parameters = trainer_config['default'].copy()\n            trainer_parameters['summary_path'] = '{basedir}/{name}'.format(\n                basedir=self.summaries_dir,\n                name=str(self.run_id) + '_' + brain_name)\n            trainer_parameters['model_path'] = '{basedir}/{name}'.format(\n                basedir=self.model_path,\n                name=brain_name)\n            trainer_parameters['keep_checkpoints'] = self.keep_checkpoints\n            if brain_name in trainer_config:\n                _brain_key = brain_name\n                while not isinstance(trainer_config[_brain_key], dict):\n                    _brain_key = trainer_config[_brain_key]\n                for k in trainer_config[_brain_key]:\n                    trainer_parameters[k] = trainer_config[_brain_key][k]\n            trainer_parameters_dict[brain_name] = trainer_parameters.copy()\n        for brain_name in self.external_brains:\n            if trainer_parameters_dict[brain_name]['trainer'] == 'offline_bc':\n                self.trainers[brain_name] = OfflineBCTrainer(\n                    self.external_brains[brain_name],\n                    trainer_parameters_dict[brain_name], self.train_model,\n                    self.load_model, self.seed, self.run_id)\n            elif trainer_parameters_dict[brain_name]['trainer'] == 'online_bc':\n                self.trainers[brain_name] = OnlineBCTrainer(\n                    self.external_brains[brain_name],\n                    trainer_parameters_dict[brain_name], self.train_model,\n                    self.load_model, self.seed, self.run_id)\n            elif trainer_parameters_dict[brain_name]['trainer'] == 'ppo':\n                self.trainers[brain_name] = PPOTrainer(\n                    self.external_brains[brain_name],\n                    self.meta_curriculum\n                        .brains_to_curriculums[brain_name]\n                        .min_lesson_length if self.meta_curriculum else 0,\n                    trainer_parameters_dict[brain_name],\n                    self.train_model, self.load_model, self.seed,\n                    self.run_id)\n                self.trainer_metrics[brain_name] = self.trainers[brain_name].trainer_metrics\n            else:\n                raise UnityEnvironmentException('The trainer config contains '\n                                                'an unknown trainer type for '\n                                                'brain {}'\n                                                .format(brain_name))", "response": "Initializes the trainers and store the model and summary files for the trainers."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresets the environment. Returns: A Data structure corresponding to the initial reset state of the environment.", "response": "def _reset_env(self, env: BaseUnityEnvironment):\n        \"\"\"Resets the environment.\n\n        Returns:\n            A Data structure corresponding to the initial reset state of the\n            environment.\n        \"\"\"\n        if self.meta_curriculum is not None:\n            return env.reset(train_mode=self.fast_simulation, config=self.meta_curriculum.get_config())\n        else:\n            return env.reset(train_mode=self.fast_simulation)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef close(self):\n        if self._socket is not None and self._conn is not None:\n            message_input = UnityMessage()\n            message_input.header.status = 400\n            self._communicator_send(message_input.SerializeToString())\n        if self._socket is not None:\n            self._socket.close()\n            self._socket = None\n        if self._socket is not None:\n            self._conn.close()\n            self._conn = None", "response": "Closes the unity environment and closes the socket connection."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fuse_batchnorm_weights(gamma, beta, mean, var, epsilon):\n    # https://github.com/Tencent/ncnn/blob/master/src/layer/batchnorm.cpp\n    \"\"\" float sqrt_var = sqrt(var_data[i]);\n        a_data[i] = bias_data[i] - slope_data[i] * mean_data[i] / sqrt_var;\n        b_data[i] = slope_data[i] / sqrt_var;\n        ...\n        ptr[i] = b * ptr[i] + a;\n    \"\"\"\n    scale = gamma / np.sqrt(var + epsilon)\n    bias = beta - gamma * mean / np.sqrt(var + epsilon)\n    return [scale, bias]", "response": "Fuse the batchnorm weights to compute the scale and bias of the current log - likelihood."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef gru(name, input, state, kernel_r, kernel_u, kernel_c, bias_r, bias_u, bias_c, new_state, number_of_gates = 2):\n    ''' - zt = f(Xt*Wz + Ht_1*Rz        + Wbz + Rbz)\n        - rt = f(Xt*Wr + Ht_1*Rr        + Wbr + Rbr)\n        - ht = g(Xt*Wh + (rt . Ht_1)*Rh + Rbh + Wbh)\n        - Ht = (1-zt).ht + zt.Ht_1\n    '''\n    nn = Build(name)\n    inputs = nn.concat(input, state)\n\n    u = nn.sigmoid(nn.mad(inputs, kernel_u, bias_u))\n    r = nn.sigmoid(nn.mad(inputs, kernel_r, bias_r))\n    r_state = nn.mul(r, state)\n\n    c = nn.tanh(nn.mad(kernel=kernel_c, bias=bias_c,\n        x=nn.concat(input, r_state)))\n\n    # new_h = u' * state + (1 - u') * c'\n    #       = u' * state + c' - u' * c'\n\n    # u' * state + c'\n    nn.add(nn.mul(u, state), c)\n    # - u' * c'\n    nn.sub(nn._, nn.mul(u, c),\n        out=new_state)\n\n    return nn.layers;", "response": "- zt = f(Xt*Wz + Ht_1*Rz        + Wbz + Rbz)\n        - rt = f(Xt*Wr + Ht_1*Rr        + Wbr + Rbr)\n        - ht = g(Xt*Wh + (rt . Ht_1)*Rh + Rbh + Wbh)\n        - Ht = (1-zt).ht + zt.Ht_1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lstm(name, input, state_c, state_h, kernel_i, kernel_j, kernel_f, kernel_o, bias_i, bias_j, bias_f, bias_o, new_state_c, new_state_h):\n    ''' Full:\n    - it = f(Xt*Wi + Ht_1*Ri + Pi . Ct_1 + Wbi + Rbi)\n    - ft = f(Xt*Wf + Ht_1*Rf + Pf . Ct_1 + Wbf + Rbf)\n    - ct = g(Xt*Wc + Ht_1*Rc + Wbc + Rbc)\n    - Ct =  ft . Ct_1  + it . ct\n    - ot = f(Xt*Wo + Ht_1*Ro + Po . Ct + Wbo + Rbo)\n    - Ht =  ot . h(Ct)\n    '''\n\n    ''' No peephole:\n    - it = f(Xt*Wi + Ht_1*Ri + Wbi + Rbi)\n    - ft = f(Xt*Wf + Ht_1*Rf + Wbf + Rbf)\n    - ct = g(Xt*Wc + Ht_1*Rc + Wbc + Rbc)\n    - Ct =   ft . Ct_  + it . ct\n    - ot = f(Xt*Wo + Ht_1*Ro + Wbo + Rbo)\n    - Ht =   ot . h(Ct)\n    '''\n\n    nn = Build(name)\n    inputs = nn.concat(input, state_h)\n\n    i = nn.sigmoid(nn.mad(x=inputs, kernel=kernel_i, bias=bias_i))\n    j =    nn.tanh(nn.mad(inputs, kernel_j, bias_j))\n    f = nn.sigmoid(nn.mad(inputs, kernel_f, bias_f))\n    o = nn.sigmoid(nn.mad(inputs, kernel_o, bias_o))\n\n    # new_c = state_c * f' + i' * j'\n    nn.add(\n        nn.mul(state_c, f), nn.mul(i, j),\n        out=new_state_c)\n\n    # new_h = \n    nn.mul(o, nn.tanh(new_state_c),\n        out=new_state_h)\n\n    return nn.layers", "response": "This function builds a list of states for the LSTM algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nevaluates policy for the agent experiences provided.", "response": "def evaluate(self, brain_info):\n        \"\"\"\n        Evaluates policy for the agent experiences provided.\n        :param brain_info: BrainInfo input to network.\n        :return: Results of evaluation.\n        \"\"\"\n        feed_dict = {self.model.dropout_rate: self.evaluate_rate,\n                     self.model.sequence_length: 1}\n\n        feed_dict = self._fill_eval_dict(feed_dict, brain_info)\n        if self.use_recurrent:\n            if brain_info.memories.shape[1] == 0:\n                brain_info.memories = self.make_empty_memory(len(brain_info.agents))\n            feed_dict[self.model.memory_in] = brain_info.memories\n        run_out = self._execute_model(feed_dict, self.inference_dict)\n        return run_out"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, mini_batch, num_sequences):\n\n        feed_dict = {self.model.dropout_rate: self.update_rate,\n                     self.model.batch_size: num_sequences,\n                     self.model.sequence_length: self.sequence_length}\n        if self.use_continuous_act:\n            feed_dict[self.model.true_action] = mini_batch['actions']. \\\n                reshape([-1, self.brain.vector_action_space_size[0]])\n        else:\n            feed_dict[self.model.true_action] = mini_batch['actions'].reshape(\n                [-1, len(self.brain.vector_action_space_size)])\n            feed_dict[self.model.action_masks] = np.ones(\n                (num_sequences, sum(self.brain.vector_action_space_size)))\n        if self.use_vec_obs:\n            apparent_obs_size = self.brain.vector_observation_space_size * \\\n                                self.brain.num_stacked_vector_observations\n            feed_dict[self.model.vector_in] = mini_batch['vector_obs'] \\\n                .reshape([-1,apparent_obs_size])\n        for i, _ in enumerate(self.model.visual_in):\n            visual_obs = mini_batch['visual_obs%d' % i]\n            feed_dict[self.model.visual_in[i]] = visual_obs\n        if self.use_recurrent:\n            feed_dict[self.model.memory_in] = np.zeros([num_sequences, self.m_size])\n        run_out = self._execute_model(feed_dict, self.update_dict)\n        return run_out", "response": "Updates the model with the given mini_batch."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nincrement the number of the lesson based on the given measure value.", "response": "def increment_lesson(self, measure_val):\n        \"\"\"\n        Increments the lesson number depending on the progress given.\n        :param measure_val: Measure of progress (either reward or percentage\n               steps completed).\n        :return Whether the lesson was incremented.\n        \"\"\"\n        if not self.data or not measure_val or math.isnan(measure_val):\n            return False\n        if self.data['signal_smoothing']:\n            measure_val = self.smoothing_value * 0.25 + 0.75 * measure_val\n            self.smoothing_value = measure_val\n        if self.lesson_num < self.max_lesson_num:\n            if measure_val > self.data['thresholds'][self.lesson_num]:\n                self.lesson_num += 1\n                config = {}\n                parameters = self.data['parameters']\n                for key in parameters:\n                    config[key] = parameters[key][self.lesson_num]\n                logger.info('{0} lesson changed. Now in lesson {1}: {2}'\n                            .format(self._brain_name,\n                                    self.lesson_num,\n                                    ', '.join([str(x) + ' -> ' + str(config[x])\n                                        for x in config])))\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_config(self, lesson=None):\n        if not self.data:\n            return {}\n        if lesson is None:\n            lesson = self.lesson_num\n        lesson = max(0, min(lesson, self.max_lesson_num))\n        config = {}\n        parameters = self.data['parameters']\n        for key in parameters:\n            config[key] = parameters[key][lesson]\n        return config", "response": "Returns the configuration of the reset parameters which correspond to the specified lesson."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the generalized advantage estimate for updating policy.", "response": "def get_gae(rewards, value_estimates, value_next=0.0, gamma=0.99, lambd=0.95):\n    \"\"\"\n    Computes generalized advantage estimate for use in updating policy.\n    :param rewards: list of rewards for time-steps t to T.\n    :param value_next: Value estimate for time-step T+1.\n    :param value_estimates: list of value estimates for time-steps t to T.\n    :param gamma: Discount factor.\n    :param lambd: GAE weighing factor.\n    :return: list of advantage estimates for time-steps t to T.\n    \"\"\"\n    value_estimates = np.asarray(value_estimates.tolist() + [value_next])\n    delta_t = rewards + gamma * value_estimates[1:] - value_estimates[:-1]\n    advantage = discount_rewards(r=delta_t, gamma=gamma * lambd)\n    return advantage"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef increment_step_and_update_last_reward(self):\n        if len(self.stats['Environment/Cumulative Reward']) > 0:\n            mean_reward = np.mean(self.stats['Environment/Cumulative Reward'])\n            self.policy.update_reward(mean_reward)\n        self.policy.increment_step()\n        self.step = self.policy.get_current_step()", "response": "Increment the step count of the trainer and updates the last reward"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef construct_curr_info(self, next_info: BrainInfo) -> BrainInfo:\n        visual_observations = [[]]\n        vector_observations = []\n        text_observations = []\n        memories = []\n        rewards = []\n        local_dones = []\n        max_reacheds = []\n        agents = []\n        prev_vector_actions = []\n        prev_text_actions = []\n        action_masks = []\n        for agent_id in next_info.agents:\n            agent_brain_info = self.training_buffer[agent_id].last_brain_info\n            if agent_brain_info is None:\n                agent_brain_info = next_info\n            agent_index = agent_brain_info.agents.index(agent_id)\n            for i in range(len(next_info.visual_observations)):\n                visual_observations[i].append(agent_brain_info.visual_observations[i][agent_index])\n            vector_observations.append(agent_brain_info.vector_observations[agent_index])\n            text_observations.append(agent_brain_info.text_observations[agent_index])\n            if self.policy.use_recurrent:\n                if len(agent_brain_info.memories) > 0:\n                    memories.append(agent_brain_info.memories[agent_index])\n                else:\n                    memories.append(self.policy.make_empty_memory(1))\n            rewards.append(agent_brain_info.rewards[agent_index])\n            local_dones.append(agent_brain_info.local_done[agent_index])\n            max_reacheds.append(agent_brain_info.max_reached[agent_index])\n            agents.append(agent_brain_info.agents[agent_index])\n            prev_vector_actions.append(agent_brain_info.previous_vector_actions[agent_index])\n            prev_text_actions.append(agent_brain_info.previous_text_actions[agent_index])\n            action_masks.append(agent_brain_info.action_masks[agent_index])\n        if self.policy.use_recurrent:\n            memories = np.vstack(memories)\n        curr_info = BrainInfo(visual_observations, vector_observations, text_observations,\n                              memories, rewards, agents, local_dones, prev_vector_actions,\n                              prev_text_actions, max_reacheds, action_masks)\n        return curr_info", "response": "Constructs a new BrainInfo which contains the most recent previous experiences for all agents in next_info."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_experiences(self, curr_all_info: AllBrainInfo, next_all_info: AllBrainInfo, take_action_outputs):\n        self.trainer_metrics.start_experience_collection_timer()\n        if take_action_outputs:\n            self.stats['Policy/Value Estimate'].append(take_action_outputs['value'].mean())\n            self.stats['Policy/Entropy'].append(take_action_outputs['entropy'].mean())\n            self.stats['Policy/Learning Rate'].append(take_action_outputs['learning_rate'])\n\n        curr_info = curr_all_info[self.brain_name]\n        next_info = next_all_info[self.brain_name]\n\n        for agent_id in curr_info.agents:\n            self.training_buffer[agent_id].last_brain_info = curr_info\n            self.training_buffer[agent_id].last_take_action_outputs = take_action_outputs\n\n        if curr_info.agents != next_info.agents:\n            curr_to_use = self.construct_curr_info(next_info)\n        else:\n            curr_to_use = curr_info\n\n        intrinsic_rewards = self.policy.get_intrinsic_rewards(curr_to_use, next_info)\n\n        for agent_id in next_info.agents:\n            stored_info = self.training_buffer[agent_id].last_brain_info\n            stored_take_action_outputs = self.training_buffer[agent_id].last_take_action_outputs\n            if stored_info is not None:\n                idx = stored_info.agents.index(agent_id)\n                next_idx = next_info.agents.index(agent_id)\n                if not stored_info.local_done[idx]:\n                    for i, _ in enumerate(stored_info.visual_observations):\n                        self.training_buffer[agent_id]['visual_obs%d' % i].append(\n                            stored_info.visual_observations[i][idx])\n                        self.training_buffer[agent_id]['next_visual_obs%d' % i].append(\n                            next_info.visual_observations[i][next_idx])\n                    if self.policy.use_vec_obs:\n                        self.training_buffer[agent_id]['vector_obs'].append(stored_info.vector_observations[idx])\n                        self.training_buffer[agent_id]['next_vector_in'].append(\n                            next_info.vector_observations[next_idx])\n                    if self.policy.use_recurrent:\n                        if stored_info.memories.shape[1] == 0:\n                            stored_info.memories = np.zeros((len(stored_info.agents), self.policy.m_size))\n                        self.training_buffer[agent_id]['memory'].append(stored_info.memories[idx])\n                    actions = stored_take_action_outputs['action']\n                    if self.policy.use_continuous_act:\n                        actions_pre = stored_take_action_outputs['pre_action']\n                        self.training_buffer[agent_id]['actions_pre'].append(actions_pre[idx])\n                        epsilons = stored_take_action_outputs['random_normal_epsilon']\n                        self.training_buffer[agent_id]['random_normal_epsilon'].append(\n                            epsilons[idx])\n                    else:\n                        self.training_buffer[agent_id]['action_mask'].append(\n                            stored_info.action_masks[idx], padding_value=1)\n                    a_dist = stored_take_action_outputs['log_probs']\n                    value = stored_take_action_outputs['value']\n                    self.training_buffer[agent_id]['actions'].append(actions[idx])\n                    self.training_buffer[agent_id]['prev_action'].append(stored_info.previous_vector_actions[idx])\n                    self.training_buffer[agent_id]['masks'].append(1.0)\n                    if self.use_curiosity:\n                        self.training_buffer[agent_id]['rewards'].append(next_info.rewards[next_idx] +\n                                                                         intrinsic_rewards[next_idx])\n                    else:\n                        self.training_buffer[agent_id]['rewards'].append(next_info.rewards[next_idx])\n                    self.training_buffer[agent_id]['action_probs'].append(a_dist[idx])\n                    self.training_buffer[agent_id]['value_estimates'].append(value[idx][0])\n                    if agent_id not in self.cumulative_rewards:\n                        self.cumulative_rewards[agent_id] = 0\n                    self.cumulative_rewards[agent_id] += next_info.rewards[next_idx]\n                    if self.use_curiosity:\n                        if agent_id not in self.intrinsic_rewards:\n                            self.intrinsic_rewards[agent_id] = 0\n                        self.intrinsic_rewards[agent_id] += intrinsic_rewards[next_idx]\n                if not next_info.local_done[next_idx]:\n                    if agent_id not in self.episode_steps:\n                        self.episode_steps[agent_id] = 0\n                    self.episode_steps[agent_id] += 1\n        self.trainer_metrics.end_experience_collection_timer()", "response": "Adds experiences to each agent s experience history."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess the experiments in the current_info and new_info dictionary.", "response": "def process_experiences(self, current_info: AllBrainInfo, new_info: AllBrainInfo):\n        \"\"\"\n        Checks agent histories for processing condition, and processes them as necessary.\n        Processing involves calculating value and advantage targets for model updating step.\n        :param current_info: Dictionary of all current brains and corresponding BrainInfo.\n        :param new_info: Dictionary of all next brains and corresponding BrainInfo.\n        \"\"\"\n        self.trainer_metrics.start_experience_collection_timer()\n        info = new_info[self.brain_name]\n        for l in range(len(info.agents)):\n            agent_actions = self.training_buffer[info.agents[l]]['actions']\n            if ((info.local_done[l] or len(agent_actions) > self.trainer_parameters['time_horizon'])\n                    and len(agent_actions) > 0):\n                agent_id = info.agents[l]\n                if info.local_done[l] and not info.max_reached[l]:\n                    value_next = 0.0\n                else:\n                    if info.max_reached[l]:\n                        bootstrapping_info = self.training_buffer[agent_id].last_brain_info\n                        idx = bootstrapping_info.agents.index(agent_id)\n                    else:\n                        bootstrapping_info = info\n                        idx = l\n                    value_next = self.policy.get_value_estimate(bootstrapping_info, idx)\n\n                self.training_buffer[agent_id]['advantages'].set(\n                    get_gae(\n                        rewards=self.training_buffer[agent_id]['rewards'].get_batch(),\n                        value_estimates=self.training_buffer[agent_id]['value_estimates'].get_batch(),\n                        value_next=value_next,\n                        gamma=self.trainer_parameters['gamma'],\n                        lambd=self.trainer_parameters['lambd']))\n                self.training_buffer[agent_id]['discounted_returns'].set(\n                    self.training_buffer[agent_id]['advantages'].get_batch()\n                    + self.training_buffer[agent_id]['value_estimates'].get_batch())\n\n                self.training_buffer.append_update_buffer(agent_id, batch_size=None,\n                                                          training_length=self.policy.sequence_length)\n\n                self.training_buffer[agent_id].reset_agent()\n                if info.local_done[l]:\n                    self.cumulative_returns_since_policy_update.append(self.\n                                                                       cumulative_rewards.get(agent_id, 0))\n                    self.stats['Environment/Cumulative Reward'].append(\n                        self.cumulative_rewards.get(agent_id, 0))\n                    self.reward_buffer.appendleft(self.cumulative_rewards.get(agent_id, 0))\n                    self.stats['Environment/Episode Length'].append(\n                        self.episode_steps.get(agent_id, 0))\n                    self.cumulative_rewards[agent_id] = 0\n                    self.episode_steps[agent_id] = 0\n                    if self.use_curiosity:\n                        self.stats['Policy/Curiosity Reward'].append(\n                            self.intrinsic_rewards.get(agent_id, 0))\n                        self.intrinsic_rewards[agent_id] = 0\n        self.trainer_metrics.end_experience_collection_timer()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef end_episode(self):\n        self.training_buffer.reset_local_buffers()\n        for agent_id in self.cumulative_rewards:\n            self.cumulative_rewards[agent_id] = 0\n        for agent_id in self.episode_steps:\n            self.episode_steps[agent_id] = 0\n        if self.use_curiosity:\n            for agent_id in self.intrinsic_rewards:\n                self.intrinsic_rewards[agent_id] = 0", "response": "A signal that the Episode has ended. The buffer must be reset.\n        Get only called when the academy resets."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn whether or not the trainer has enough elements to run update model", "response": "def is_ready_update(self):\n        \"\"\"\n        Returns whether or not the trainer has enough elements to run update model\n        :return: A boolean corresponding to whether or not update_model() can be run\n        \"\"\"\n        size_of_buffer = len(self.training_buffer.update_buffer['actions'])\n        return size_of_buffer > max(int(self.trainer_parameters['buffer_size'] / self.policy.sequence_length), 1)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the policy for all the classes in the current thread.", "response": "def update_policy(self):\n        \"\"\"\n        Uses demonstration_buffer to update the policy.\n        \"\"\"\n        self.trainer_metrics.start_policy_update_timer(\n            number_experiences=len(self.training_buffer.update_buffer['actions']),\n            mean_return=float(np.mean(self.cumulative_returns_since_policy_update)))\n        n_sequences = max(int(self.trainer_parameters['batch_size'] / self.policy.sequence_length), 1)\n        value_total, policy_total, forward_total, inverse_total = [], [], [], []\n        advantages = self.training_buffer.update_buffer['advantages'].get_batch()\n        self.training_buffer.update_buffer['advantages'].set(\n            (advantages - advantages.mean()) / (advantages.std() + 1e-10))\n        num_epoch = self.trainer_parameters['num_epoch']\n        for _ in range(num_epoch):\n            self.training_buffer.update_buffer.shuffle()\n            buffer = self.training_buffer.update_buffer\n            for l in range(len(self.training_buffer.update_buffer['actions']) // n_sequences):\n                start = l * n_sequences\n                end = (l + 1) * n_sequences\n                run_out = self.policy.update(buffer.make_mini_batch(start, end), n_sequences)\n                value_total.append(run_out['value_loss'])\n                policy_total.append(np.abs(run_out['policy_loss']))\n                if self.use_curiosity:\n                    inverse_total.append(run_out['inverse_loss'])\n                    forward_total.append(run_out['forward_loss'])\n        self.stats['Losses/Value Loss'].append(np.mean(value_total))\n        self.stats['Losses/Policy Loss'].append(np.mean(policy_total))\n        if self.use_curiosity:\n            self.stats['Losses/Forward Loss'].append(np.mean(forward_total))\n            self.stats['Losses/Inverse Loss'].append(np.mean(inverse_total))\n        self.training_buffer.reset_update_buffer()\n        self.trainer_metrics.end_policy_update()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reset(self):\n        info = self._env.reset()[self.brain_name]\n        n_agents = len(info.agents)\n        self._check_agents(n_agents)\n        self.game_over = False\n\n        if not self._multiagent:\n            obs, reward, done, info = self._single_step(info)\n        else:\n            obs, reward, done, info = self._multi_step(info)\n        return obs", "response": "Resets the state of the environment and returns an initial observation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun one timestep of the environment.", "response": "def step(self, action):\n        \"\"\"Run one timestep of the environment's dynamics. When end of\n        episode is reached, you are responsible for calling `reset()`\n        to reset this environment's state.\n        Accepts an action and returns a tuple (observation, reward, done, info).\n        In the case of multi-agent environments, these are lists.\n        Args:\n            action (object/list): an action provided by the environment\n        Returns:\n            observation (object/list): agent's observation of the current environment\n            reward (float/list) : amount of reward returned after previous action\n            done (boolean/list): whether the episode has ended.\n            info (dict): contains auxiliary diagnostic information, including BrainInfo.\n        \"\"\"\n\n        # Use random actions for all other agents in environment.\n        if self._multiagent:\n            if not isinstance(action, list):\n                raise UnityGymException(\"The environment was expecting `action` to be a list.\")\n            if len(action) != self._n_agents:\n                raise UnityGymException(\n                    \"The environment was expecting a list of {} actions.\".format(self._n_agents))\n            else:\n                if self._flattener is not None:\n                    # Action space is discrete and flattened - we expect a list of scalars\n                    action = [self._flattener.lookup_action(_act) for _act in action]\n                action = np.array(action)\n        else:\n            if self._flattener is not None:\n                # Translate action into list\n                action = self._flattener.lookup_action(action)\n\n        info = self._env.step(action)[self.brain_name]\n        n_agents = len(info.agents)\n        self._check_agents(n_agents)\n        self._current_state = info\n\n        if not self._multiagent:\n            obs, reward, done, info = self._single_step(info)\n            self.game_over = done\n        else:\n            obs, reward, done, info = self._multi_step(info)\n            self.game_over = all(done)\n        return obs, reward, done, info"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a lookup dict that maps discrete actions to branched actions.", "response": "def _create_lookup(self, branched_action_space):\n        \"\"\"\n        Creates a Dict that maps discrete actions (scalars) to branched actions (lists).\n        Each key in the Dict maps to one unique set of branched actions, and each value\n        contains the List of branched actions.\n        \"\"\"\n        possible_vals = [range(_num) for _num in branched_action_space]\n        all_actions = [list(_action) for _action in itertools.product(*possible_vals)]\n        # Dict should be faster than List for large action spaces\n        action_lookup = {_scalar: _action for (_scalar, _action) in enumerate(all_actions)}\n        return action_lookup"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate the GRPC server.", "response": "def create_server(self):\n        \"\"\"\n        Creates the GRPC server.\n        \"\"\"\n        self.check_port(self.port)\n\n        try:\n            # Establish communication grpc\n            self.server = grpc.server(ThreadPoolExecutor(max_workers=10))\n            self.unity_to_external = UnityToExternalServicerImplementation()\n            add_UnityToExternalServicer_to_server(self.unity_to_external, self.server)\n            # Using unspecified address, which means that grpc is communicating on all IPs\n            # This is so that the docker container can connect.\n            self.server.add_insecure_port('[::]:' + str(self.port))\n            self.server.start()\n            self.is_open = True\n        except:\n            raise UnityWorkerInUseException(self.worker_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the given communicator port is already in use.", "response": "def check_port(self, port):\n        \"\"\"\n        Attempts to bind to the requested communicator port, checking if it is already in use.\n        \"\"\"\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        try:\n            s.bind((\"localhost\", port))\n        except socket.error:\n            raise UnityWorkerInUseException(self.worker_id)\n        finally:\n            s.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclose the Unity server and closes the grpc connection.", "response": "def close(self):\n        \"\"\"\n        Sends a shutdown signal to the unity environment, and closes the grpc connection.\n        \"\"\"\n        if self.is_open:\n            message_input = UnityMessage()\n            message_input.header.status = 400\n            self.unity_to_external.parent_conn.send(message_input)\n            self.unity_to_external.parent_conn.close()\n            self.server.stop(False)\n            self.is_open = False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process_pixels(image_bytes, gray_scale):\n        s = bytearray(image_bytes)\n        image = Image.open(io.BytesIO(s))\n        s = np.array(image) / 255.0\n        if gray_scale:\n            s = np.mean(s, axis=2)\n            s = np.reshape(s, [s.shape[0], s.shape[1], 1])\n        return s", "response": "Converts byte array observation image into numpy array re - sizes it and optionally converts it to grey scale\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting list of agent infos to BrainInfo.", "response": "def from_agent_proto(agent_info_list, brain_params):\n        \"\"\"\n        Converts list of agent infos to BrainInfo.\n        \"\"\"\n        vis_obs = []\n        for i in range(brain_params.number_visual_observations):\n            obs = [BrainInfo.process_pixels(x.visual_observations[i],\n                                            brain_params.camera_resolutions[i]['blackAndWhite'])\n                   for x in agent_info_list]\n            vis_obs += [obs]\n        if len(agent_info_list) == 0:\n            memory_size = 0\n        else:\n            memory_size = max([len(x.memories) for x in agent_info_list])\n        if memory_size == 0:\n            memory = np.zeros((0, 0))\n        else:\n            [x.memories.extend([0] * (memory_size - len(x.memories))) for x in agent_info_list]\n            memory = np.array([list(x.memories) for x in agent_info_list])\n        total_num_actions = sum(brain_params.vector_action_space_size)\n        mask_actions = np.ones((len(agent_info_list), total_num_actions))\n        for agent_index, agent_info in enumerate(agent_info_list):\n            if agent_info.action_mask is not None:\n                if len(agent_info.action_mask) == total_num_actions:\n                    mask_actions[agent_index, :] = [\n                        0 if agent_info.action_mask[k] else 1 for k in range(total_num_actions)]\n        if any([np.isnan(x.reward) for x in agent_info_list]):\n            logger.warning(\"An agent had a NaN reward for brain \" + brain_params.brain_name)\n        if any([np.isnan(x.stacked_vector_observation).any() for x in agent_info_list]):\n            logger.warning(\"An agent had a NaN observation for brain \" + brain_params.brain_name)\n\n        if len(agent_info_list) == 0:\n            vector_obs = np.zeros(\n                (0, brain_params.vector_observation_space_size * brain_params.num_stacked_vector_observations)\n            )\n        else:\n            vector_obs = np.nan_to_num(\n                np.array([x.stacked_vector_observation for x in agent_info_list])\n            )\n        brain_info = BrainInfo(\n            visual_observation=vis_obs,\n            vector_observation=vector_obs,\n            text_observations=[x.text_observation for x in agent_info_list],\n            memory=memory,\n            reward=[x.reward if not np.isnan(x.reward) else 0 for x in agent_info_list],\n            agents=[x.id for x in agent_info_list],\n            local_done=[x.done for x in agent_info_list],\n            vector_action=np.array([x.stored_vector_actions for x in agent_info_list]),\n            text_action=[list(x.stored_text_actions) for x in agent_info_list],\n            max_reached=[x.max_step_reached for x in agent_info_list],\n            custom_observations=[x.custom_observation for x in agent_info_list],\n            action_mask=mask_actions\n        )\n        return brain_info"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_proto(brain_param_proto):\n        resolution = [{\n            \"height\": x.height,\n            \"width\": x.width,\n            \"blackAndWhite\": x.gray_scale\n        } for x in brain_param_proto.camera_resolutions]\n        brain_params = BrainParameters(brain_param_proto.brain_name,\n                                       brain_param_proto.vector_observation_size,\n                                       brain_param_proto.num_stacked_vector_observations,\n                                       resolution,\n                                       list(brain_param_proto.vector_action_size),\n                                       list(brain_param_proto.vector_action_descriptions),\n                                       brain_param_proto.vector_action_space_type)\n        return brain_params", "response": "Converts a protobuf BrainParameter object to a BrainParameter object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new blank dashboard and redirects to it in edit mode", "response": "def new(self):\n        \"\"\"Creates a new, blank dashboard and redirects to it in edit mode\"\"\"\n        new_dashboard = models.Dashboard(\n            dashboard_title='[ untitled dashboard ]',\n            owners=[g.user],\n        )\n        db.session.add(new_dashboard)\n        db.session.commit()\n        return redirect(f'/superset/dashboard/{new_dashboard.id}/?edit=true')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist all tags a given object has.", "response": "def get(self, object_type, object_id):\n        \"\"\"List all tags a given object has.\"\"\"\n        if object_id == 0:\n            return json_success(json.dumps([]))\n\n        query = db.session.query(TaggedObject).filter(and_(\n            TaggedObject.object_type == object_type,\n            TaggedObject.object_id == object_id))\n        tags = [{'id': obj.tag.id, 'name': obj.tag.name} for obj in query]\n        return json_success(json.dumps(tags))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef post(self, object_type, object_id):\n        if object_id == 0:\n            return Response(status=404)\n\n        tagged_objects = []\n        for name in request.get_json(force=True):\n            if ':' in name:\n                type_name = name.split(':', 1)[0]\n                type_ = TagTypes[type_name]\n            else:\n                type_ = TagTypes.custom\n\n            tag = db.session.query(Tag).filter_by(name=name, type=type_).first()\n            if not tag:\n                tag = Tag(name=name, type=type_)\n\n            tagged_objects.append(\n                TaggedObject(\n                    object_id=object_id,\n                    object_type=object_type,\n                    tag=tag,\n                ),\n            )\n\n        db.session.add_all(tagged_objects)\n        db.session.commit()\n\n        return Response(status=201)", "response": "Add new tags to an object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove tags from an object.", "response": "def delete(self, object_type, object_id):\n        \"\"\"Remove tags from an object.\"\"\"\n        tag_names = request.get_json(force=True)\n        if not tag_names:\n            return Response(status=403)\n\n        db.session.query(TaggedObject).filter(and_(\n            TaggedObject.object_type == object_type,\n            TaggedObject.object_id == object_id),\n            TaggedObject.tag.has(Tag.name.in_(tag_names)),\n        ).delete(synchronize_session=False)\n        db.session.commit()\n\n        return Response(status=204)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nimports the datasource from the object to the database.", "response": "def import_datasource(\n        session,\n        i_datasource,\n        lookup_database,\n        lookup_datasource,\n        import_time):\n    \"\"\"Imports the datasource from the object to the database.\n\n     Metrics and columns and datasource will be overrided if exists.\n     This function can be used to import/export dashboards between multiple\n     superset instances. Audit metadata isn't copies over.\n    \"\"\"\n    make_transient(i_datasource)\n    logging.info('Started import of the datasource: {}'.format(\n        i_datasource.to_json()))\n\n    i_datasource.id = None\n    i_datasource.database_id = lookup_database(i_datasource).id\n    i_datasource.alter_params(import_time=import_time)\n\n    # override the datasource\n    datasource = lookup_datasource(i_datasource)\n\n    if datasource:\n        datasource.override(i_datasource)\n        session.flush()\n    else:\n        datasource = i_datasource.copy()\n        session.add(datasource)\n        session.flush()\n\n    for m in i_datasource.metrics:\n        new_m = m.copy()\n        new_m.table_id = datasource.id\n        logging.info('Importing metric {} from the datasource: {}'.format(\n            new_m.to_json(), i_datasource.full_name))\n        imported_m = i_datasource.metric_class.import_obj(new_m)\n        if (imported_m.metric_name not in\n                [m.metric_name for m in datasource.metrics]):\n            datasource.metrics.append(imported_m)\n\n    for c in i_datasource.columns:\n        new_c = c.copy()\n        new_c.table_id = datasource.id\n        logging.info('Importing column {} from the datasource: {}'.format(\n            new_c.to_json(), i_datasource.full_name))\n        imported_c = i_datasource.column_class.import_obj(new_c)\n        if (imported_c.column_name not in\n                [c.column_name for c in datasource.columns]):\n            datasource.columns.append(imported_c)\n    session.flush()\n    return datasource.id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun migrations in online mode.", "response": "def run_migrations_online():\n    \"\"\"Run migrations in 'online' mode.\n\n    In this scenario we need to create an Engine\n    and associate a connection with the context.\n\n    \"\"\"\n\n    # this callback is used to prevent an auto-migration from being generated\n    # when there are no changes to the schema\n    # reference: https://alembic.sqlalchemy.org/en/latest/cookbook.html\n    def process_revision_directives(context, revision, directives):\n        if getattr(config.cmd_opts, 'autogenerate', False):\n            script = directives[0]\n            if script.upgrade_ops.is_empty():\n                directives[:] = []\n                logger.info('No changes in schema detected.')\n\n    engine = engine_from_config(config.get_section(config.config_ini_section),\n                                prefix='sqlalchemy.',\n                                poolclass=pool.NullPool)\n\n    connection = engine.connect()\n    kwargs = {}\n    if engine.name in ('sqlite', 'mysql'):\n        kwargs = {\n            'transaction_per_migration': True,\n            'transactional_ddl': True,\n        }\n    configure_args = current_app.extensions['migrate'].configure_args\n    if configure_args:\n        kwargs.update(configure_args)\n\n    context.configure(connection=connection,\n                      target_metadata=target_metadata,\n                      # compare_type=True,\n                      process_revision_directives=process_revision_directives,\n                      **kwargs)\n\n    try:\n        with context.begin_transaction():\n            context.run_migrations()\n    finally:\n        connection.close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_df(self, query_obj=None):\n        if not query_obj:\n            query_obj = self.query_obj()\n        if not query_obj:\n            return None\n\n        self.error_msg = ''\n\n        timestamp_format = None\n        if self.datasource.type == 'table':\n            dttm_col = self.datasource.get_col(query_obj['granularity'])\n            if dttm_col:\n                timestamp_format = dttm_col.python_date_format\n\n        # The datasource here can be different backend but the interface is common\n        self.results = self.datasource.query(query_obj)\n        self.query = self.results.query\n        self.status = self.results.status\n        self.error_message = self.results.error_message\n\n        df = self.results.df\n        # Transform the timestamp we received from database to pandas supported\n        # datetime format. If no python_date_format is specified, the pattern will\n        # be considered as the default ISO date format\n        # If the datetime format is unix, the parse will use the corresponding\n        # parsing logic.\n        if df is not None and not df.empty:\n            if DTTM_ALIAS in df.columns:\n                if timestamp_format in ('epoch_s', 'epoch_ms'):\n                    # Column has already been formatted as a timestamp.\n                    dttm_col = df[DTTM_ALIAS]\n                    one_ts_val = dttm_col[0]\n\n                    # convert time column to pandas Timestamp, but different\n                    # ways to convert depending on string or int types\n                    try:\n                        int(one_ts_val)\n                        is_integral = True\n                    except ValueError:\n                        is_integral = False\n                    if is_integral:\n                        unit = 's' if timestamp_format == 'epoch_s' else 'ms'\n                        df[DTTM_ALIAS] = pd.to_datetime(dttm_col, utc=False, unit=unit,\n                                                        origin='unix')\n                    else:\n                        df[DTTM_ALIAS] = dttm_col.apply(pd.Timestamp)\n                else:\n                    df[DTTM_ALIAS] = pd.to_datetime(\n                        df[DTTM_ALIAS], utc=False, format=timestamp_format)\n                if self.datasource.offset:\n                    df[DTTM_ALIAS] += timedelta(hours=self.datasource.offset)\n                df[DTTM_ALIAS] += self.time_shift\n\n            if self.enforce_numerical_metrics:\n                self.df_metrics_to_num(df)\n\n            df.replace([np.inf, -np.inf], np.nan, inplace=True)\n        return df", "response": "Returns a pandas dataframe based on the query object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding a query object from the form data.", "response": "def query_obj(self):\n        \"\"\"Building a query object\"\"\"\n        form_data = self.form_data\n        self.process_query_filters()\n        gb = form_data.get('groupby') or []\n        metrics = self.all_metrics or []\n        columns = form_data.get('columns') or []\n        groupby = []\n        for o in gb + columns:\n            if o not in groupby:\n                groupby.append(o)\n\n        is_timeseries = self.is_timeseries\n        if DTTM_ALIAS in groupby:\n            groupby.remove(DTTM_ALIAS)\n            is_timeseries = True\n\n        granularity = (\n            form_data.get('granularity') or\n            form_data.get('granularity_sqla')\n        )\n        limit = int(form_data.get('limit') or 0)\n        timeseries_limit_metric = form_data.get('timeseries_limit_metric')\n        row_limit = int(form_data.get('row_limit') or config.get('ROW_LIMIT'))\n\n        # default order direction\n        order_desc = form_data.get('order_desc', True)\n\n        since, until = utils.get_since_until(relative_end=relative_end,\n                                             time_range=form_data.get('time_range'),\n                                             since=form_data.get('since'),\n                                             until=form_data.get('until'))\n        time_shift = form_data.get('time_shift', '')\n        self.time_shift = utils.parse_human_timedelta(time_shift)\n        from_dttm = None if since is None else (since - self.time_shift)\n        to_dttm = None if until is None else (until - self.time_shift)\n        if from_dttm and to_dttm and from_dttm > to_dttm:\n            raise Exception(_('From date cannot be larger than to date'))\n\n        self.from_dttm = from_dttm\n        self.to_dttm = to_dttm\n\n        # extras are used to query elements specific to a datasource type\n        # for instance the extra where clause that applies only to Tables\n        extras = {\n            'where': form_data.get('where', ''),\n            'having': form_data.get('having', ''),\n            'having_druid': form_data.get('having_filters', []),\n            'time_grain_sqla': form_data.get('time_grain_sqla', ''),\n            'druid_time_origin': form_data.get('druid_time_origin', ''),\n        }\n\n        d = {\n            'granularity': granularity,\n            'from_dttm': from_dttm,\n            'to_dttm': to_dttm,\n            'is_timeseries': is_timeseries,\n            'groupby': groupby,\n            'metrics': metrics,\n            'row_limit': row_limit,\n            'filter': self.form_data.get('filters', []),\n            'timeseries_limit': limit,\n            'extras': extras,\n            'timeseries_limit_metric': timeseries_limit_metric,\n            'order_desc': order_desc,\n            'prequeries': [],\n            'is_prequery': False,\n        }\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cache_key(self, query_obj, **extra):\n        cache_dict = copy.copy(query_obj)\n        cache_dict.update(extra)\n\n        for k in ['from_dttm', 'to_dttm']:\n            del cache_dict[k]\n\n        cache_dict['time_range'] = self.form_data.get('time_range')\n        cache_dict['datasource'] = self.datasource.uid\n        json_data = self.json_dumps(cache_dict, sort_keys=True)\n        return hashlib.md5(json_data.encode('utf-8')).hexdigest()", "response": "Returns a cache key for the given query object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef data(self):\n        content = {\n            'form_data': self.form_data,\n            'token': self.token,\n            'viz_name': self.viz_type,\n            'filter_select_enabled': self.datasource.filter_select_enabled,\n        }\n        return content", "response": "This is the data object serialized to the js layer"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef query_obj(self):\n        d = super().query_obj()\n        d['row_limit'] = self.form_data.get(\n            'row_limit', int(config.get('VIZ_ROW_LIMIT')))\n        numeric_columns = self.form_data.get('all_columns_x')\n        if numeric_columns is None:\n            raise Exception(_('Must have at least one numeric column specified'))\n        self.columns = numeric_columns\n        d['columns'] = numeric_columns + self.groupby\n        # override groupby entry to avoid aggregation\n        d['groupby'] = []\n        return d", "response": "Returns the query object for this visualization"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the chart data", "response": "def get_data(self, df):\n        \"\"\"Returns the chart data\"\"\"\n        chart_data = []\n        if len(self.groupby) > 0:\n            groups = df.groupby(self.groupby)\n        else:\n            groups = [((), df)]\n        for keys, data in groups:\n            chart_data.extend([{\n                'key': self.labelify(keys, column),\n                'values': data[column].tolist()}\n                for column in self.columns])\n        return chart_data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the partition at each level from the dataframe.", "response": "def levels_for(self, time_op, groups, df):\n        \"\"\"\n        Compute the partition at each `level` from the dataframe.\n        \"\"\"\n        levels = {}\n        for i in range(0, len(groups) + 1):\n            agg_df = df.groupby(groups[:i]) if i else df\n            levels[i] = (\n                agg_df.mean() if time_op == 'agg_mean'\n                else agg_df.sum(numeric_only=True))\n        return levels"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nest_values(self, levels, level=0, metric=None, dims=()):\n        if not level:\n            return [{\n                'name': m,\n                'val': levels[0][m],\n                'children': self.nest_values(levels, 1, m),\n            } for m in levels[0].index]\n        if level == 1:\n            return [{\n                'name': i,\n                'val': levels[1][metric][i],\n                'children': self.nest_values(levels, 2, metric, (i,)),\n            } for i in levels[1][metric].index]\n        if level >= len(levels):\n            return []\n        return [{\n            'name': i,\n            'val': levels[level][metric][dims][i],\n            'children': self.nest_values(\n                levels, level + 1, metric, dims + (i,),\n            ),\n        } for i in levels[level][metric][dims].index]", "response": "Nest values at each level on the back - end with\n            access and setting instead of summing from the bottom."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dict representation of the datasource sent to the frontend", "response": "def short_data(self):\n        \"\"\"Data representation of the datasource sent to the frontend\"\"\"\n        return {\n            'edit_url': self.url,\n            'id': self.id,\n            'uid': self.uid,\n            'schema': self.schema,\n            'name': self.name,\n            'type': self.type,\n            'connection': self.connection,\n            'creator': str(self.created_by),\n        }"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dictionary representation of the datasource", "response": "def data(self):\n        \"\"\"Data representation of the datasource sent to the frontend\"\"\"\n        order_by_choices = []\n        # self.column_names return sorted column_names\n        for s in self.column_names:\n            s = str(s or '')\n            order_by_choices.append((json.dumps([s, True]), s + ' [asc]'))\n            order_by_choices.append((json.dumps([s, False]), s + ' [desc]'))\n\n        verbose_map = {'__timestamp': 'Time'}\n        verbose_map.update({\n            o.metric_name: o.verbose_name or o.metric_name\n            for o in self.metrics\n        })\n        verbose_map.update({\n            o.column_name: o.verbose_name or o.column_name\n            for o in self.columns\n        })\n        return {\n            # simple fields\n            'id': self.id,\n            'column_formats': self.column_formats,\n            'description': self.description,\n            'database': self.database.data,  # pylint: disable=no-member\n            'default_endpoint': self.default_endpoint,\n            'filter_select': self.filter_select_enabled,  # TODO deprecate\n            'filter_select_enabled': self.filter_select_enabled,\n            'name': self.name,\n            'datasource_name': self.datasource_name,\n            'type': self.type,\n            'schema': self.schema,\n            'offset': self.offset,\n            'cache_timeout': self.cache_timeout,\n            'params': self.params,\n            'perm': self.perm,\n            'edit_url': self.url,\n\n            # sqla-specific\n            'sql': self.sql,\n\n            # one to many\n            'columns': [o.data for o in self.columns],\n            'metrics': [o.data for o in self.metrics],\n\n            # TODO deprecate, move logic to JS\n            'order_by_choices': order_by_choices,\n            'owners': [owner.id for owner in self.owners],\n            'verbose_map': verbose_map,\n            'select_star': self.select_star,\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating ORM one - to - many list from object list", "response": "def get_fk_many_from_list(\n            self, object_list, fkmany, fkmany_class, key_attr):\n        \"\"\"Update ORM one-to-many list from object list\n\n        Used for syncing metrics and columns using the same code\"\"\"\n\n        object_dict = {o.get(key_attr): o for o in object_list}\n        object_keys = [o.get(key_attr) for o in object_list]\n\n        # delete fks that have been removed\n        fkmany = [o for o in fkmany if getattr(o, key_attr) in object_keys]\n\n        # sync existing fks\n        for fk in fkmany:\n            obj = object_dict.get(getattr(fk, key_attr))\n            for attr in fkmany_class.update_from_object_fields:\n                setattr(fk, attr, obj.get(attr))\n\n        # create new fks\n        new_fks = []\n        orm_keys = [getattr(o, key_attr) for o in fkmany]\n        for obj in object_list:\n            key = obj.get(key_attr)\n            if key not in orm_keys:\n                del obj['id']\n                orm_kwargs = {}\n                for k in obj:\n                    if (\n                        k in fkmany_class.update_from_object_fields and\n                        k in obj\n                    ):\n                        orm_kwargs[k] = obj[k]\n                new_obj = fkmany_class(**orm_kwargs)\n                new_fks.append(new_obj)\n        fkmany += new_fks\n        return fkmany"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the datasource from a data structure.", "response": "def update_from_object(self, obj):\n        \"\"\"Update datasource from a data structure\n\n        The UI's table editor crafts a complex data structure that\n        contains most of the datasource's properties as well as\n        an array of metrics and columns objects. This method\n        receives the object from the UI and syncs the datasource to\n        match it. Since the fields are different for the different\n        connectors, the implementation uses ``update_from_object_fields``\n        which can be defined for each connector and\n        defines which fields should be synced\"\"\"\n        for attr in self.update_from_object_fields:\n            setattr(self, attr, obj.get(attr))\n\n        self.owners = obj.get('owners', [])\n\n        # Syncing metrics\n        metrics = self.get_fk_many_from_list(\n            obj.get('metrics'), self.metrics, self.metric_class, 'metric_name')\n        self.metrics = metrics\n\n        # Syncing columns\n        self.columns = self.get_fk_many_from_list(\n            obj.get('columns'), self.columns, self.column_class, 'column_name')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_query_result(self, query_object):\n\n        # Here, we assume that all the queries will use the same datasource, which is\n        # is a valid assumption for current setting. In a long term, we may or maynot\n        # support multiple queries from different data source.\n\n        timestamp_format = None\n        if self.datasource.type == 'table':\n            dttm_col = self.datasource.get_col(query_object.granularity)\n            if dttm_col:\n                timestamp_format = dttm_col.python_date_format\n\n        # The datasource here can be different backend but the interface is common\n        result = self.datasource.query(query_object.to_dict())\n\n        df = result.df\n        # Transform the timestamp we received from database to pandas supported\n        # datetime format. If no python_date_format is specified, the pattern will\n        # be considered as the default ISO date format\n        # If the datetime format is unix, the parse will use the corresponding\n        # parsing logic\n        if df is not None and not df.empty:\n            if DTTM_ALIAS in df.columns:\n                if timestamp_format in ('epoch_s', 'epoch_ms'):\n                    # Column has already been formatted as a timestamp.\n                    df[DTTM_ALIAS] = df[DTTM_ALIAS].apply(pd.Timestamp)\n                else:\n                    df[DTTM_ALIAS] = pd.to_datetime(\n                        df[DTTM_ALIAS], utc=False, format=timestamp_format)\n                if self.datasource.offset:\n                    df[DTTM_ALIAS] += timedelta(hours=self.datasource.offset)\n                df[DTTM_ALIAS] += query_object.time_shift\n\n            if self.enforce_numerical_metrics:\n                self.df_metrics_to_num(df, query_object)\n\n            df.replace([np.inf, -np.inf], np.nan)\n        return {\n            'query': result.query,\n            'status': result.status,\n            'error_message': result.error_message,\n            'df': df,\n        }", "response": "Returns a pandas dataframe based on the query object"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef df_metrics_to_num(self, df, query_object):\n        metrics = [metric for metric in query_object.metrics]\n        for col, dtype in df.dtypes.items():\n            if dtype.type == np.object_ and col in metrics:\n                df[col] = pd.to_numeric(df[col], errors='coerce')", "response": "Convert metrics to numeric when pandas. read_sql cannot"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a payload of metadata and data", "response": "def get_single_payload(self, query_obj):\n        \"\"\"Returns a payload of metadata and data\"\"\"\n        payload = self.get_df_payload(query_obj)\n        df = payload.get('df')\n        status = payload.get('status')\n        if status != utils.QueryStatus.FAILED:\n            if df is not None and df.empty:\n                payload['error'] = 'No data'\n            else:\n                payload['data'] = self.get_data(df)\n        if 'df' in payload:\n            del payload['df']\n        return payload"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_df_payload(self, query_obj, **kwargs):\n        cache_key = query_obj.cache_key(\n            datasource=self.datasource.uid, **kwargs) if query_obj else None\n        logging.info('Cache key: {}'.format(cache_key))\n        is_loaded = False\n        stacktrace = None\n        df = None\n        cached_dttm = datetime.utcnow().isoformat().split('.')[0]\n        cache_value = None\n        status = None\n        query = ''\n        error_message = None\n        if cache_key and cache and not self.force:\n            cache_value = cache.get(cache_key)\n            if cache_value:\n                stats_logger.incr('loaded_from_cache')\n                try:\n                    cache_value = pkl.loads(cache_value)\n                    df = cache_value['df']\n                    query = cache_value['query']\n                    status = utils.QueryStatus.SUCCESS\n                    is_loaded = True\n                except Exception as e:\n                    logging.exception(e)\n                    logging.error('Error reading cache: ' +\n                                  utils.error_msg_from_exception(e))\n                logging.info('Serving from cache')\n\n        if query_obj and not is_loaded:\n            try:\n                query_result = self.get_query_result(query_obj)\n                status = query_result['status']\n                query = query_result['query']\n                error_message = query_result['error_message']\n                df = query_result['df']\n                if status != utils.QueryStatus.FAILED:\n                    stats_logger.incr('loaded_from_source')\n                    is_loaded = True\n            except Exception as e:\n                logging.exception(e)\n                if not error_message:\n                    error_message = '{}'.format(e)\n                status = utils.QueryStatus.FAILED\n                stacktrace = traceback.format_exc()\n\n            if (\n                    is_loaded and\n                    cache_key and\n                    cache and\n                    status != utils.QueryStatus.FAILED):\n                try:\n                    cache_value = dict(\n                        dttm=cached_dttm,\n                        df=df if df is not None else None,\n                        query=query,\n                    )\n                    cache_value = pkl.dumps(\n                        cache_value, protocol=pkl.HIGHEST_PROTOCOL)\n\n                    logging.info('Caching {} chars at key {}'.format(\n                        len(cache_value), cache_key))\n\n                    stats_logger.incr('set_cache_key')\n                    cache.set(\n                        cache_key,\n                        cache_value,\n                        timeout=self.cache_timeout)\n                except Exception as e:\n                    # cache.set call can fail if the backend is down or if\n                    # the key is too large or whatever other reasons\n                    logging.warning('Could not cache key {}'.format(cache_key))\n                    logging.exception(e)\n                    cache.delete(cache_key)\n        return {\n            'cache_key': cache_key,\n            'cached_dttm': cache_value['dttm'] if cache_value is not None else None,\n            'cache_timeout': self.cache_timeout,\n            'df': df,\n            'error': error_message,\n            'is_cached': cache_key is not None,\n            'query': query,\n            'status': status,\n            'stacktrace': stacktrace,\n            'rowcount': len(df.index) if df is not None else 0,\n        }", "response": "Get the payload of a df paylod retrieval"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef data(self):\n        d = {}\n        self.token = ''\n        try:\n            d = self.viz.data\n            self.token = d.get('token')\n        except Exception as e:\n            logging.exception(e)\n            d['error'] = str(e)\n        return {\n            'datasource': self.datasource_name,\n            'description': self.description,\n            'description_markeddown': self.description_markeddown,\n            'edit_url': self.edit_url,\n            'form_data': self.form_data,\n            'slice_id': self.id,\n            'slice_name': self.slice_name,\n            'slice_url': self.slice_url,\n            'modified': self.modified(),\n            'changed_on_humanized': self.changed_on_humanized,\n            'changed_on': self.changed_on.isoformat(),\n        }", "response": "Data used to render slice in templates"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_viz(self, force=False):\n        slice_params = json.loads(self.params)\n        slice_params['slice_id'] = self.id\n        slice_params['json'] = 'false'\n        slice_params['slice_name'] = self.slice_name\n        slice_params['viz_type'] = self.viz_type if self.viz_type else 'table'\n\n        return viz_types[slice_params.get('viz_type')](\n            self.datasource,\n            form_data=slice_params,\n            force=force,\n        )", "response": "Creates a Viz object from the url_params_multidict or self. params."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef import_obj(cls, slc_to_import, slc_to_override, import_time=None):\n        session = db.session\n        make_transient(slc_to_import)\n        slc_to_import.dashboards = []\n        slc_to_import.alter_params(\n            remote_id=slc_to_import.id, import_time=import_time)\n\n        slc_to_import = slc_to_import.copy()\n        params = slc_to_import.params_dict\n        slc_to_import.datasource_id = ConnectorRegistry.get_datasource_by_name(\n            session, slc_to_import.datasource_type, params['datasource_name'],\n            params['schema'], params['database_name']).id\n        if slc_to_override:\n            slc_to_override.override(slc_to_import)\n            session.flush()\n            return slc_to_override.id\n        session.add(slc_to_import)\n        logging.info('Final slice: {}'.format(slc_to_import.to_json()))\n        session.flush()\n        return slc_to_import.id", "response": "Imports a slice into the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef import_obj(cls, dashboard_to_import, import_time=None):\n        def alter_positions(dashboard, old_to_new_slc_id_dict):\n            \"\"\" Updates slice_ids in the position json.\n\n            Sample position_json data:\n            {\n                \"DASHBOARD_VERSION_KEY\": \"v2\",\n                \"DASHBOARD_ROOT_ID\": {\n                    \"type\": \"DASHBOARD_ROOT_TYPE\",\n                    \"id\": \"DASHBOARD_ROOT_ID\",\n                    \"children\": [\"DASHBOARD_GRID_ID\"]\n                },\n                \"DASHBOARD_GRID_ID\": {\n                    \"type\": \"DASHBOARD_GRID_TYPE\",\n                    \"id\": \"DASHBOARD_GRID_ID\",\n                    \"children\": [\"DASHBOARD_CHART_TYPE-2\"]\n                },\n                \"DASHBOARD_CHART_TYPE-2\": {\n                    \"type\": \"DASHBOARD_CHART_TYPE\",\n                    \"id\": \"DASHBOARD_CHART_TYPE-2\",\n                    \"children\": [],\n                    \"meta\": {\n                        \"width\": 4,\n                        \"height\": 50,\n                        \"chartId\": 118\n                    }\n                },\n            }\n            \"\"\"\n            position_data = json.loads(dashboard.position_json)\n            position_json = position_data.values()\n            for value in position_json:\n                if (isinstance(value, dict) and value.get('meta') and\n                        value.get('meta').get('chartId')):\n                    old_slice_id = value.get('meta').get('chartId')\n\n                    if old_slice_id in old_to_new_slc_id_dict:\n                        value['meta']['chartId'] = (\n                            old_to_new_slc_id_dict[old_slice_id]\n                        )\n            dashboard.position_json = json.dumps(position_data)\n\n        logging.info('Started import of the dashboard: {}'\n                     .format(dashboard_to_import.to_json()))\n        session = db.session\n        logging.info('Dashboard has {} slices'\n                     .format(len(dashboard_to_import.slices)))\n        # copy slices object as Slice.import_slice will mutate the slice\n        # and will remove the existing dashboard - slice association\n        slices = copy(dashboard_to_import.slices)\n        old_to_new_slc_id_dict = {}\n        new_filter_immune_slices = []\n        new_timed_refresh_immune_slices = []\n        new_expanded_slices = {}\n        i_params_dict = dashboard_to_import.params_dict\n        remote_id_slice_map = {\n            slc.params_dict['remote_id']: slc\n            for slc in session.query(Slice).all()\n            if 'remote_id' in slc.params_dict\n        }\n        for slc in slices:\n            logging.info('Importing slice {} from the dashboard: {}'.format(\n                slc.to_json(), dashboard_to_import.dashboard_title))\n            remote_slc = remote_id_slice_map.get(slc.id)\n            new_slc_id = Slice.import_obj(slc, remote_slc, import_time=import_time)\n            old_to_new_slc_id_dict[slc.id] = new_slc_id\n            # update json metadata that deals with slice ids\n            new_slc_id_str = '{}'.format(new_slc_id)\n            old_slc_id_str = '{}'.format(slc.id)\n            if ('filter_immune_slices' in i_params_dict and\n                    old_slc_id_str in i_params_dict['filter_immune_slices']):\n                new_filter_immune_slices.append(new_slc_id_str)\n            if ('timed_refresh_immune_slices' in i_params_dict and\n                    old_slc_id_str in\n                    i_params_dict['timed_refresh_immune_slices']):\n                new_timed_refresh_immune_slices.append(new_slc_id_str)\n            if ('expanded_slices' in i_params_dict and\n                    old_slc_id_str in i_params_dict['expanded_slices']):\n                new_expanded_slices[new_slc_id_str] = (\n                    i_params_dict['expanded_slices'][old_slc_id_str])\n\n        # override the dashboard\n        existing_dashboard = None\n        for dash in session.query(Dashboard).all():\n            if ('remote_id' in dash.params_dict and\n                    dash.params_dict['remote_id'] ==\n                    dashboard_to_import.id):\n                existing_dashboard = dash\n\n        dashboard_to_import.id = None\n        alter_positions(dashboard_to_import, old_to_new_slc_id_dict)\n        dashboard_to_import.alter_params(import_time=import_time)\n        if new_expanded_slices:\n            dashboard_to_import.alter_params(\n                expanded_slices=new_expanded_slices)\n        if new_filter_immune_slices:\n            dashboard_to_import.alter_params(\n                filter_immune_slices=new_filter_immune_slices)\n        if new_timed_refresh_immune_slices:\n            dashboard_to_import.alter_params(\n                timed_refresh_immune_slices=new_timed_refresh_immune_slices)\n\n        new_slices = session.query(Slice).filter(\n            Slice.id.in_(old_to_new_slc_id_dict.values())).all()\n\n        if existing_dashboard:\n            existing_dashboard.override(dashboard_to_import)\n            existing_dashboard.slices = new_slices\n            session.flush()\n            return existing_dashboard.id\n        else:\n            # session.add(dashboard_to_import) causes sqlachemy failures\n            # related to the attached users / slices. Creating new object\n            # allows to avoid conflicts in the sql alchemy state.\n            copied_dash = dashboard_to_import.copy()\n            copied_dash.slices = new_slices\n            session.add(copied_dash)\n            session.flush()\n            return copied_dash.id", "response": "Imports the dashboard from the object to the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_effective_user(self, url, user_name=None):\n        effective_username = None\n        if self.impersonate_user:\n            effective_username = url.username\n            if user_name:\n                effective_username = user_name\n            elif (\n                hasattr(g, 'user') and hasattr(g.user, 'username') and\n                g.user.username is not None\n            ):\n                effective_username = g.user.username\n        return effective_username", "response": "Get the effective user for the given URL."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a select * statement in the proper dialect", "response": "def select_star(\n            self, table_name, schema=None, limit=100, show_cols=False,\n            indent=True, latest_partition=False, cols=None):\n        \"\"\"Generates a ``select *`` statement in the proper dialect\"\"\"\n        eng = self.get_sqla_engine(\n            schema=schema, source=utils.sources.get('sql_lab', None))\n        return self.db_engine_spec.select_star(\n            self, table_name, schema=schema, engine=eng,\n            limit=limit, show_cols=show_cols,\n            indent=indent, latest_partition=latest_partition, cols=cols)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of table names in the database.", "response": "def all_table_names_in_database(self, cache=False,\n                                    cache_timeout=None, force=False):\n        \"\"\"Parameters need to be passed as keyword arguments.\"\"\"\n        if not self.allow_multi_schema_metadata_fetch:\n            return []\n        return self.db_engine_spec.fetch_result_sets(self, 'table')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef all_table_names_in_schema(self, schema, cache=False,\n                                  cache_timeout=None, force=False):\n        \"\"\"Parameters need to be passed as keyword arguments.\n\n        For unused parameters, they are referenced in\n        cache_util.memoized_func decorator.\n\n        :param schema: schema name\n        :type schema: str\n        :param cache: whether cache is enabled for the function\n        :type cache: bool\n        :param cache_timeout: timeout in seconds for the cache\n        :type cache_timeout: int\n        :param force: whether to force refresh the cache\n        :type force: bool\n        :return: table list\n        :rtype: list\n        \"\"\"\n        tables = []\n        try:\n            tables = self.db_engine_spec.get_table_names(\n                inspector=self.inspector, schema=schema)\n        except Exception as e:\n            logging.exception(e)\n        return tables", "response": "Get a list of all table names in a schema."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef all_view_names_in_schema(self, schema, cache=False,\n                                 cache_timeout=None, force=False):\n        \"\"\"Parameters need to be passed as keyword arguments.\n\n        For unused parameters, they are referenced in\n        cache_util.memoized_func decorator.\n\n        :param schema: schema name\n        :type schema: str\n        :param cache: whether cache is enabled for the function\n        :type cache: bool\n        :param cache_timeout: timeout in seconds for the cache\n        :type cache_timeout: int\n        :param force: whether to force refresh the cache\n        :type force: bool\n        :return: view list\n        :rtype: list\n        \"\"\"\n        views = []\n        try:\n            views = self.db_engine_spec.get_view_names(\n                inspector=self.inspector, schema=schema)\n        except Exception as e:\n            logging.exception(e)\n        return views", "response": "Get a list of all view names in a schema."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of schema names for all the keys in the cache", "response": "def all_schema_names(self, cache=False, cache_timeout=None, force=False):\n        \"\"\"Parameters need to be passed as keyword arguments.\n\n        For unused parameters, they are referenced in\n        cache_util.memoized_func decorator.\n\n        :param cache: whether cache is enabled for the function\n        :type cache: bool\n        :param cache_timeout: timeout in seconds for the cache\n        :type cache_timeout: int\n        :param force: whether to force refresh the cache\n        :type force: bool\n        :return: schema list\n        :rtype: list\n        \"\"\"\n        return self.db_engine_spec.get_schema_names(self.inspector)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef grains_dict(self):\n        d = {grain.duration: grain for grain in self.grains()}\n        d.update({grain.label: grain for grain in self.grains()})\n        return d", "response": "Returns a dictionary of grains for this object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_ownership(obj, raise_if_false=True):\n    if not obj:\n        return False\n\n    security_exception = SupersetSecurityException(\n        \"You don't have the rights to alter [{}]\".format(obj))\n\n    if g.user.is_anonymous:\n        if raise_if_false:\n            raise security_exception\n        return False\n    roles = [r.name for r in get_user_roles()]\n    if 'Admin' in roles:\n        return True\n    session = db.create_scoped_session()\n    orig_obj = session.query(obj.__class__).filter_by(id=obj.id).first()\n\n    # Making a list of owners that works across ORM models\n    owners = []\n    if hasattr(orig_obj, 'owners'):\n        owners += orig_obj.owners\n    if hasattr(orig_obj, 'owner'):\n        owners += [orig_obj.owner]\n    if hasattr(orig_obj, 'created_by'):\n        owners += [orig_obj.created_by]\n\n    owner_names = [o.username for o in owners if o]\n\n    if (\n            g.user and hasattr(g.user, 'username') and\n            g.user.username in owner_names):\n        return True\n    if raise_if_false:\n        raise security_exception\n    else:\n        return False", "response": "Check if the user has access to the User\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbinding the field to the given form.", "response": "def bind_field(\n        self,\n        form: DynamicForm,\n        unbound_field: UnboundField,\n        options: Dict[Any, Any],\n    ) -> Field:\n    \"\"\"\n    Customize how fields are bound by stripping all whitespace.\n\n    :param form: The form\n    :param unbound_field: The unbound field\n    :param options: The field options\n    :returns: The bound field\n    \"\"\"\n\n    filters = unbound_field.kwargs.get('filters', [])\n    filters.append(lambda x: x.strip() if isinstance(x, str) else x)\n    return unbound_field.bind(form=form, filters=filters, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _delete(self, pk):\n        item = self.datamodel.get(pk, self._base_filters)\n        if not item:\n            abort(404)\n        try:\n            self.pre_delete(item)\n        except Exception as e:\n            flash(str(e), 'danger')\n        else:\n            view_menu = security_manager.find_view_menu(item.get_perm())\n            pvs = security_manager.get_session.query(\n                security_manager.permissionview_model).filter_by(\n                view_menu=view_menu).all()\n\n            schema_view_menu = None\n            if hasattr(item, 'schema_perm'):\n                schema_view_menu = security_manager.find_view_menu(item.schema_perm)\n\n                pvs.extend(security_manager.get_session.query(\n                    security_manager.permissionview_model).filter_by(\n                    view_menu=schema_view_menu).all())\n\n            if self.datamodel.delete(item):\n                self.post_delete(item)\n\n                for pv in pvs:\n                    security_manager.get_session.delete(pv)\n\n                if view_menu:\n                    security_manager.get_session.delete(view_menu)\n\n                if schema_view_menu:\n                    security_manager.get_session.delete(schema_view_menu)\n\n                security_manager.get_session.commit()\n\n            flash(*self.datamodel.message)\n            self.update_redirect()", "response": "Delete function logic override to implement diferent logic\n            deletes the record with primary_key = pk"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_all_permissions(self):\n        perms = set()\n        for role in self.get_user_roles():\n            for perm_view in role.permissions:\n                t = (perm_view.permission.name, perm_view.view_menu.name)\n                perms.add(t)\n        return perms", "response": "Returns a set of tuples with the perm name and view menu name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the details of view_menus for a permission name", "response": "def get_view_menus(self, permission_name):\n        \"\"\"Returns the details of view_menus for a perm name\"\"\"\n        vm = set()\n        for perm_name, vm_name in self.get_all_permissions():\n            if perm_name == permission_name:\n                vm.add(vm_name)\n        return vm"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef deliver_dashboard(schedule):\n    dashboard = schedule.dashboard\n\n    dashboard_url = _get_url_path(\n        'Superset.dashboard',\n        dashboard_id=dashboard.id,\n    )\n\n    # Create a driver, fetch the page, wait for the page to render\n    driver = create_webdriver()\n    window = config.get('WEBDRIVER_WINDOW')['dashboard']\n    driver.set_window_size(*window)\n    driver.get(dashboard_url)\n    time.sleep(PAGE_RENDER_WAIT)\n\n    # Set up a function to retry once for the element.\n    # This is buggy in certain selenium versions with firefox driver\n    get_element = getattr(driver, 'find_element_by_class_name')\n    element = retry_call(\n        get_element,\n        fargs=['grid-container'],\n        tries=2,\n        delay=PAGE_RENDER_WAIT,\n    )\n\n    try:\n        screenshot = element.screenshot_as_png\n    except WebDriverException:\n        # Some webdrivers do not support screenshots for elements.\n        # In such cases, take a screenshot of the entire page.\n        screenshot = driver.screenshot()  # pylint: disable=no-member\n    finally:\n        destroy_webdriver(driver)\n\n    # Generate the email body and attachments\n    email = _generate_mail_content(\n        schedule,\n        screenshot,\n        dashboard.dashboard_title,\n        dashboard_url,\n    )\n\n    subject = __(\n        '%(prefix)s %(title)s',\n        prefix=config.get('EMAIL_REPORTS_SUBJECT_PREFIX'),\n        title=dashboard.dashboard_title,\n    )\n\n    _deliver_email(schedule, subject, email)", "response": "Given a schedule delivery the dashboard as an email report\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a schedule delivers the slice as an email report", "response": "def deliver_slice(schedule):\n    \"\"\"\n    Given a schedule, delivery the slice as an email report\n    \"\"\"\n    if schedule.email_format == SliceEmailReportFormat.data:\n        email = _get_slice_data(schedule)\n    elif schedule.email_format == SliceEmailReportFormat.visualization:\n        email = _get_slice_visualization(schedule)\n    else:\n        raise RuntimeError('Unknown email report format')\n\n    subject = __(\n        '%(prefix)s %(title)s',\n        prefix=config.get('EMAIL_REPORTS_SUBJECT_PREFIX'),\n        title=schedule.slice.slice_name,\n    )\n\n    _deliver_email(schedule, subject, email)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nscheduling celery tasks for a specific report type at a specific time.", "response": "def schedule_window(report_type, start_at, stop_at, resolution):\n    \"\"\"\n    Find all active schedules and schedule celery tasks for\n    each of them with a specific ETA (determined by parsing\n    the cron schedule for the schedule)\n    \"\"\"\n    model_cls = get_scheduler_model(report_type)\n    dbsession = db.create_scoped_session()\n    schedules = dbsession.query(model_cls).filter(model_cls.active.is_(True))\n\n    for schedule in schedules:\n        args = (\n            report_type,\n            schedule.id,\n        )\n\n        # Schedule the job for the specified time window\n        for eta in next_schedules(schedule.crontab,\n                                  start_at,\n                                  stop_at,\n                                  resolution=resolution):\n            schedule_email_report.apply_async(args, eta=eta)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef db_type(cls, dtype):\n        if isinstance(dtype, ExtensionDtype):\n            return cls.type_map.get(dtype.kind)\n        elif hasattr(dtype, 'char'):\n            return cls.type_map.get(dtype.char)", "response": "Given a numpy dtype returns a generic database type"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprovide metadata about columns for data visualization.", "response": "def columns(self):\n        \"\"\"Provides metadata about columns for data visualization.\n\n        :return: dict, with the fields name, type, is_date, is_dim and agg.\n        \"\"\"\n        if self.df.empty:\n            return None\n\n        columns = []\n        sample_size = min(INFER_COL_TYPES_SAMPLE_SIZE, len(self.df.index))\n        sample = self.df\n        if sample_size:\n            sample = self.df.sample(sample_size)\n        for col in self.df.dtypes.keys():\n            db_type_str = (\n                self._type_dict.get(col) or\n                self.db_type(self.df.dtypes[col])\n            )\n            column = {\n                'name': col,\n                'agg': self.agg_func(self.df.dtypes[col], col),\n                'type': db_type_str,\n                'is_date': self.is_date(self.df.dtypes[col], db_type_str),\n                'is_dim': self.is_dimension(self.df.dtypes[col], col),\n            }\n\n            if not db_type_str or db_type_str.upper() == 'OBJECT':\n                v = sample[col].iloc[0] if not sample[col].empty else None\n                if isinstance(v, str):\n                    column['type'] = 'STRING'\n                elif isinstance(v, int):\n                    column['type'] = 'INT'\n                elif isinstance(v, float):\n                    column['type'] = 'FLOAT'\n                elif isinstance(v, (datetime, date)):\n                    column['type'] = 'DATETIME'\n                    column['is_date'] = True\n                    column['is_dim'] = False\n                # check if encoded datetime\n                if (\n                        column['type'] == 'STRING' and\n                        self.datetime_conversion_rate(sample[col]) >\n                        INFER_COL_TYPES_THRESHOLD):\n                    column.update({\n                        'is_date': True,\n                        'is_dim': False,\n                        'agg': None,\n                    })\n            # 'agg' is optional attribute\n            if not column['agg']:\n                column.pop('agg', None)\n            columns.append(column)\n        return columns"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_timestamp_expression(self, time_grain):\n        label = utils.DTTM_ALIAS\n\n        db = self.table.database\n        pdf = self.python_date_format\n        is_epoch = pdf in ('epoch_s', 'epoch_ms')\n        if not self.expression and not time_grain and not is_epoch:\n            sqla_col = column(self.column_name, type_=DateTime)\n            return self.table.make_sqla_column_compatible(sqla_col, label)\n        grain = None\n        if time_grain:\n            grain = db.grains_dict().get(time_grain)\n            if not grain:\n                raise NotImplementedError(\n                    f'No grain spec for {time_grain} for database {db.database_name}')\n        col = db.db_engine_spec.get_timestamp_column(self.expression, self.column_name)\n        expr = db.db_engine_spec.get_time_expr(col, pdf, time_grain, grain)\n        sqla_col = literal_column(expr, type_=DateTime)\n        return self.table.make_sqla_column_compatible(sqla_col, label)", "response": "Gets the time component of the query"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting datetime object to a SQL literal string.", "response": "def dttm_sql_literal(self, dttm, is_epoch_in_utc):\n        \"\"\"Convert datetime object to a SQL expression string\n\n        If database_expression is empty, the internal dttm\n        will be parsed as the string with the pattern that\n        the user inputted (python_date_format)\n        If database_expression is not empty, the internal dttm\n        will be parsed as the sql sentence for the database to convert\n        \"\"\"\n        tf = self.python_date_format\n        if self.database_expression:\n            return self.database_expression.format(dttm.strftime('%Y-%m-%d %H:%M:%S'))\n        elif tf:\n            if is_epoch_in_utc:\n                seconds_since_epoch = dttm.timestamp()\n            else:\n                seconds_since_epoch = (dttm - datetime(1970, 1, 1)).total_seconds()\n            seconds_since_epoch = int(seconds_since_epoch)\n            if tf == 'epoch_s':\n                return str(seconds_since_epoch)\n            elif tf == 'epoch_ms':\n                return str(seconds_since_epoch * 1000)\n            return \"'{}'\".format(dttm.strftime(tf))\n        else:\n            s = self.table.database.db_engine_spec.convert_dttm(\n                self.type or '', dttm)\n            return s or \"'{}'\".format(dttm.strftime('%Y-%m-%d %H:%M:%S.%f'))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_sqla_column_compatible(self, sqla_col, label=None):\n        label_expected = label or sqla_col.name\n        db_engine_spec = self.database.db_engine_spec\n        if db_engine_spec.supports_column_aliases:\n            label = db_engine_spec.make_label_compatible(label_expected)\n            sqla_col = sqla_col.label(label)\n        sqla_col._df_label_expected = label_expected\n        return sqla_col", "response": "Takes a sqlalchemy column object and adds label info if supported by engine."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef values_for_column(self, column_name, limit=10000):\n        cols = {col.column_name: col for col in self.columns}\n        target_col = cols[column_name]\n        tp = self.get_template_processor()\n\n        qry = (\n            select([target_col.get_sqla_col()])\n            .select_from(self.get_from_clause(tp))\n            .distinct()\n        )\n        if limit:\n            qry = qry.limit(limit)\n\n        if self.fetch_values_predicate:\n            tp = self.get_template_processor()\n            qry = qry.where(tp.process_template(self.fetch_values_predicate))\n\n        engine = self.database.get_sqla_engine()\n        sql = '{}'.format(\n            qry.compile(engine, compile_kwargs={'literal_binds': True}),\n        )\n        sql = self.mutate_query_from_config(sql)\n\n        df = pd.read_sql_query(sql=sql, con=engine)\n        return [row[0] for row in df.to_records(index=False)]", "response": "Runs a query against sqla to retrieve someCOOKIE values for the given column."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\napply config s SQL_QUERY_MUTATOR Typically adds comments to the query with context", "response": "def mutate_query_from_config(self, sql):\n        \"\"\"Apply config's SQL_QUERY_MUTATOR\n\n        Typically adds comments to the query with context\"\"\"\n        SQL_QUERY_MUTATOR = config.get('SQL_QUERY_MUTATOR')\n        if SQL_QUERY_MUTATOR:\n            username = utils.get_username()\n            sql = SQL_QUERY_MUTATOR(sql, username, security_manager, self.database)\n        return sql"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef adhoc_metric_to_sqla(self, metric, cols):\n        expression_type = metric.get('expressionType')\n        label = utils.get_metric_name(metric)\n\n        if expression_type == utils.ADHOC_METRIC_EXPRESSION_TYPES['SIMPLE']:\n            column_name = metric.get('column').get('column_name')\n            table_column = cols.get(column_name)\n            if table_column:\n                sqla_column = table_column.get_sqla_col()\n            else:\n                sqla_column = column(column_name)\n            sqla_metric = self.sqla_aggregations[metric.get('aggregate')](sqla_column)\n        elif expression_type == utils.ADHOC_METRIC_EXPRESSION_TYPES['SQL']:\n            sqla_metric = literal_column(metric.get('sqlExpression'))\n        else:\n            return None\n\n        return self.make_sqla_column_compatible(sqla_metric, label)", "response": "Converts an adhoc metric definition into a sqlalchemy column."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_sqla_query(  # sqla\n            self,\n            groupby, metrics,\n            granularity,\n            from_dttm, to_dttm,\n            filter=None,  # noqa\n            is_timeseries=True,\n            timeseries_limit=15,\n            timeseries_limit_metric=None,\n            row_limit=None,\n            inner_from_dttm=None,\n            inner_to_dttm=None,\n            orderby=None,\n            extras=None,\n            columns=None,\n            order_desc=True,\n            prequeries=None,\n            is_prequery=False,\n    ):\n        \"\"\"Querying any sqla table from this common interface\"\"\"\n        template_kwargs = {\n            'from_dttm': from_dttm,\n            'groupby': groupby,\n            'metrics': metrics,\n            'row_limit': row_limit,\n            'to_dttm': to_dttm,\n            'filter': filter,\n            'columns': {col.column_name: col for col in self.columns},\n        }\n        template_kwargs.update(self.template_params_dict)\n        template_processor = self.get_template_processor(**template_kwargs)\n        db_engine_spec = self.database.db_engine_spec\n\n        orderby = orderby or []\n\n        # For backward compatibility\n        if granularity not in self.dttm_cols:\n            granularity = self.main_dttm_col\n\n        # Database spec supports join-free timeslot grouping\n        time_groupby_inline = db_engine_spec.time_groupby_inline\n\n        cols = {col.column_name: col for col in self.columns}\n        metrics_dict = {m.metric_name: m for m in self.metrics}\n\n        if not granularity and is_timeseries:\n            raise Exception(_(\n                'Datetime column not provided as part table configuration '\n                'and is required by this type of chart'))\n        if not groupby and not metrics and not columns:\n            raise Exception(_('Empty query?'))\n        metrics_exprs = []\n        for m in metrics:\n            if utils.is_adhoc_metric(m):\n                metrics_exprs.append(self.adhoc_metric_to_sqla(m, cols))\n            elif m in metrics_dict:\n                metrics_exprs.append(metrics_dict.get(m).get_sqla_col())\n            else:\n                raise Exception(_(\"Metric '{}' is not valid\".format(m)))\n        if metrics_exprs:\n            main_metric_expr = metrics_exprs[0]\n        else:\n            main_metric_expr, label = literal_column('COUNT(*)'), 'ccount'\n            main_metric_expr = self.make_sqla_column_compatible(main_metric_expr, label)\n\n        select_exprs = []\n        groupby_exprs_sans_timestamp = OrderedDict()\n\n        if groupby:\n            select_exprs = []\n            for s in groupby:\n                if s in cols:\n                    outer = cols[s].get_sqla_col()\n                else:\n                    outer = literal_column(f'({s})')\n                    outer = self.make_sqla_column_compatible(outer, s)\n\n                groupby_exprs_sans_timestamp[outer.name] = outer\n                select_exprs.append(outer)\n        elif columns:\n            for s in columns:\n                select_exprs.append(\n                    cols[s].get_sqla_col() if s in cols else\n                    self.make_sqla_column_compatible(literal_column(s)))\n            metrics_exprs = []\n\n        groupby_exprs_with_timestamp = OrderedDict(groupby_exprs_sans_timestamp.items())\n        if granularity:\n            dttm_col = cols[granularity]\n            time_grain = extras.get('time_grain_sqla')\n            time_filters = []\n\n            if is_timeseries:\n                timestamp = dttm_col.get_timestamp_expression(time_grain)\n                select_exprs += [timestamp]\n                groupby_exprs_with_timestamp[timestamp.name] = timestamp\n\n            # Use main dttm column to support index with secondary dttm columns\n            if db_engine_spec.time_secondary_columns and \\\n                    self.main_dttm_col in self.dttm_cols and \\\n                    self.main_dttm_col != dttm_col.column_name:\n                time_filters.append(cols[self.main_dttm_col].\n                                    get_time_filter(from_dttm, to_dttm))\n            time_filters.append(dttm_col.get_time_filter(from_dttm, to_dttm))\n\n        select_exprs += metrics_exprs\n\n        labels_expected = [c._df_label_expected for c in select_exprs]\n\n        select_exprs = db_engine_spec.make_select_compatible(\n            groupby_exprs_with_timestamp.values(),\n            select_exprs)\n        qry = sa.select(select_exprs)\n\n        tbl = self.get_from_clause(template_processor)\n\n        if not columns:\n            qry = qry.group_by(*groupby_exprs_with_timestamp.values())\n\n        where_clause_and = []\n        having_clause_and = []\n        for flt in filter:\n            if not all([flt.get(s) for s in ['col', 'op']]):\n                continue\n            col = flt['col']\n            op = flt['op']\n            col_obj = cols.get(col)\n            if col_obj:\n                is_list_target = op in ('in', 'not in')\n                eq = self.filter_values_handler(\n                    flt.get('val'),\n                    target_column_is_numeric=col_obj.is_num,\n                    is_list_target=is_list_target)\n                if op in ('in', 'not in'):\n                    cond = col_obj.get_sqla_col().in_(eq)\n                    if '<NULL>' in eq:\n                        cond = or_(cond, col_obj.get_sqla_col() == None)  # noqa\n                    if op == 'not in':\n                        cond = ~cond\n                    where_clause_and.append(cond)\n                else:\n                    if col_obj.is_num:\n                        eq = utils.string_to_num(flt['val'])\n                    if op == '==':\n                        where_clause_and.append(col_obj.get_sqla_col() == eq)\n                    elif op == '!=':\n                        where_clause_and.append(col_obj.get_sqla_col() != eq)\n                    elif op == '>':\n                        where_clause_and.append(col_obj.get_sqla_col() > eq)\n                    elif op == '<':\n                        where_clause_and.append(col_obj.get_sqla_col() < eq)\n                    elif op == '>=':\n                        where_clause_and.append(col_obj.get_sqla_col() >= eq)\n                    elif op == '<=':\n                        where_clause_and.append(col_obj.get_sqla_col() <= eq)\n                    elif op == 'LIKE':\n                        where_clause_and.append(col_obj.get_sqla_col().like(eq))\n                    elif op == 'IS NULL':\n                        where_clause_and.append(col_obj.get_sqla_col() == None)  # noqa\n                    elif op == 'IS NOT NULL':\n                        where_clause_and.append(\n                            col_obj.get_sqla_col() != None)  # noqa\n        if extras:\n            where = extras.get('where')\n            if where:\n                where = template_processor.process_template(where)\n                where_clause_and += [sa.text('({})'.format(where))]\n            having = extras.get('having')\n            if having:\n                having = template_processor.process_template(having)\n                having_clause_and += [sa.text('({})'.format(having))]\n        if granularity:\n            qry = qry.where(and_(*(time_filters + where_clause_and)))\n        else:\n            qry = qry.where(and_(*where_clause_and))\n        qry = qry.having(and_(*having_clause_and))\n\n        if not orderby and not columns:\n            orderby = [(main_metric_expr, not order_desc)]\n\n        for col, ascending in orderby:\n            direction = asc if ascending else desc\n            if utils.is_adhoc_metric(col):\n                col = self.adhoc_metric_to_sqla(col, cols)\n            qry = qry.order_by(direction(col))\n\n        if row_limit:\n            qry = qry.limit(row_limit)\n\n        if is_timeseries and \\\n                timeseries_limit and groupby and not time_groupby_inline:\n            if self.database.db_engine_spec.inner_joins:\n                # some sql dialects require for order by expressions\n                # to also be in the select clause -- others, e.g. vertica,\n                # require a unique inner alias\n                inner_main_metric_expr = self.make_sqla_column_compatible(\n                    main_metric_expr, 'mme_inner__')\n                inner_groupby_exprs = []\n                inner_select_exprs = []\n                for gby_name, gby_obj in groupby_exprs_sans_timestamp.items():\n                    inner = self.make_sqla_column_compatible(gby_obj, gby_name + '__')\n                    inner_groupby_exprs.append(inner)\n                    inner_select_exprs.append(inner)\n\n                inner_select_exprs += [inner_main_metric_expr]\n                subq = select(inner_select_exprs).select_from(tbl)\n                inner_time_filter = dttm_col.get_time_filter(\n                    inner_from_dttm or from_dttm,\n                    inner_to_dttm or to_dttm,\n                )\n                subq = subq.where(and_(*(where_clause_and + [inner_time_filter])))\n                subq = subq.group_by(*inner_groupby_exprs)\n\n                ob = inner_main_metric_expr\n                if timeseries_limit_metric:\n                    ob = self._get_timeseries_orderby(\n                        timeseries_limit_metric,\n                        metrics_dict,\n                        cols,\n                    )\n                direction = desc if order_desc else asc\n                subq = subq.order_by(direction(ob))\n                subq = subq.limit(timeseries_limit)\n\n                on_clause = []\n                for gby_name, gby_obj in groupby_exprs_sans_timestamp.items():\n                    # in this case the column name, not the alias, needs to be\n                    # conditionally mutated, as it refers to the column alias in\n                    # the inner query\n                    col_name = db_engine_spec.make_label_compatible(gby_name + '__')\n                    on_clause.append(gby_obj == column(col_name))\n\n                tbl = tbl.join(subq.alias(), and_(*on_clause))\n            else:\n                if timeseries_limit_metric:\n                    orderby = [(\n                        self._get_timeseries_orderby(\n                            timeseries_limit_metric,\n                            metrics_dict,\n                            cols,\n                        ),\n                        False,\n                    )]\n\n                # run subquery to get top groups\n                subquery_obj = {\n                    'prequeries': prequeries,\n                    'is_prequery': True,\n                    'is_timeseries': False,\n                    'row_limit': timeseries_limit,\n                    'groupby': groupby,\n                    'metrics': metrics,\n                    'granularity': granularity,\n                    'from_dttm': inner_from_dttm or from_dttm,\n                    'to_dttm': inner_to_dttm or to_dttm,\n                    'filter': filter,\n                    'orderby': orderby,\n                    'extras': extras,\n                    'columns': columns,\n                    'order_desc': True,\n                }\n                result = self.query(subquery_obj)\n                dimensions = [\n                    c for c in result.df.columns\n                    if c not in metrics and c in groupby_exprs_sans_timestamp\n                ]\n                top_groups = self._get_top_groups(result.df,\n                                                  dimensions,\n                                                  groupby_exprs_sans_timestamp)\n                qry = qry.where(top_groups)\n\n        return SqlaQuery(sqla_query=qry.select_from(tbl),\n                         labels_expected=labels_expected)", "response": "Returns a SQLA query for the common interface of the sqla table."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches the metadata for the table and merges it in", "response": "def fetch_metadata(self):\n        \"\"\"Fetches the metadata for the table and merges it in\"\"\"\n        try:\n            table = self.get_sqla_table_object()\n        except Exception as e:\n            logging.exception(e)\n            raise Exception(_(\n                \"Table [{}] doesn't seem to exist in the specified database, \"\n                \"couldn't fetch column information\").format(self.table_name))\n\n        M = SqlMetric  # noqa\n        metrics = []\n        any_date_col = None\n        db_engine_spec = self.database.db_engine_spec\n        db_dialect = self.database.get_dialect()\n        dbcols = (\n            db.session.query(TableColumn)\n            .filter(TableColumn.table == self)\n            .filter(or_(TableColumn.column_name == col.name\n                        for col in table.columns)))\n        dbcols = {dbcol.column_name: dbcol for dbcol in dbcols}\n\n        for col in table.columns:\n            try:\n                datatype = col.type.compile(dialect=db_dialect).upper()\n            except Exception as e:\n                datatype = 'UNKNOWN'\n                logging.error(\n                    'Unrecognized data type in {}.{}'.format(table, col.name))\n                logging.exception(e)\n            dbcol = dbcols.get(col.name, None)\n            if not dbcol:\n                dbcol = TableColumn(column_name=col.name, type=datatype)\n                dbcol.sum = dbcol.is_num\n                dbcol.avg = dbcol.is_num\n                dbcol.is_dttm = dbcol.is_time\n                db_engine_spec.alter_new_orm_column(dbcol)\n            else:\n                dbcol.type = datatype\n            dbcol.groupby = True\n            dbcol.filterable = True\n            self.columns.append(dbcol)\n            if not any_date_col and dbcol.is_time:\n                any_date_col = col.name\n\n        metrics.append(M(\n            metric_name='count',\n            verbose_name='COUNT(*)',\n            metric_type='count',\n            expression='COUNT(*)',\n        ))\n        if not self.main_dttm_col:\n            self.main_dttm_col = any_date_col\n        self.add_missing_metrics(metrics)\n        db.session.merge(self)\n        db.session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef import_obj(cls, i_datasource, import_time=None):\n        def lookup_sqlatable(table):\n            return db.session.query(SqlaTable).join(Database).filter(\n                SqlaTable.table_name == table.table_name,\n                SqlaTable.schema == table.schema,\n                Database.id == table.database_id,\n            ).first()\n\n        def lookup_database(table):\n            return db.session.query(Database).filter_by(\n                database_name=table.params_dict['database_name']).one()\n        return import_datasource.import_datasource(\n            db.session, i_datasource, lookup_database, lookup_sqlatable,\n            import_time)", "response": "Imports the datasource from the object to the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads long lat data from a csv file in the repo", "response": "def load_long_lat_data():\n    \"\"\"Loading lat/long data from a csv file in the repo\"\"\"\n    data = get_example_data('san_francisco.csv.gz', make_bytes=True)\n    pdf = pd.read_csv(data, encoding='utf-8')\n    start = datetime.datetime.now().replace(\n        hour=0, minute=0, second=0, microsecond=0)\n    pdf['datetime'] = [\n        start + datetime.timedelta(hours=i * 24 / (len(pdf) - 1))\n        for i in range(len(pdf))\n    ]\n    pdf['occupancy'] = [random.randint(1, 6) for _ in range(len(pdf))]\n    pdf['radius_miles'] = [random.uniform(1, 3) for _ in range(len(pdf))]\n    pdf['geohash'] = pdf[['LAT', 'LON']].apply(\n        lambda x: geohash.encode(*x), axis=1)\n    pdf['delimited'] = pdf['LAT'].map(str).str.cat(pdf['LON'].map(str), sep=',')\n    pdf.to_sql(  # pylint: disable=no-member\n        'long_lat',\n        db.engine,\n        if_exists='replace',\n        chunksize=500,\n        dtype={\n            'longitude': Float(),\n            'latitude': Float(),\n            'number': Float(),\n            'street': String(100),\n            'unit': String(10),\n            'city': String(50),\n            'district': String(50),\n            'region': String(50),\n            'postcode': Float(),\n            'id': String(100),\n            'datetime': DateTime(),\n            'occupancy': Float(),\n            'radius_miles': Float(),\n            'geohash': String(12),\n            'delimited': String(60),\n        },\n        index=False)\n    print('Done loading table!')\n    print('-' * 80)\n\n    print('Creating table reference')\n    obj = db.session.query(TBL).filter_by(table_name='long_lat').first()\n    if not obj:\n        obj = TBL(table_name='long_lat')\n    obj.main_dttm_col = 'datetime'\n    obj.database = utils.get_or_create_main_db()\n    db.session.merge(obj)\n    db.session.commit()\n    obj.fetch_metadata()\n    tbl = obj\n\n    slice_data = {\n        'granularity_sqla': 'day',\n        'since': '2014-01-01',\n        'until': 'now',\n        'where': '',\n        'viz_type': 'mapbox',\n        'all_columns_x': 'LON',\n        'all_columns_y': 'LAT',\n        'mapbox_style': 'mapbox://styles/mapbox/light-v9',\n        'all_columns': ['occupancy'],\n        'row_limit': 500000,\n    }\n\n    print('Creating a slice')\n    slc = Slice(\n        slice_name='Mapbox Long/Lat',\n        viz_type='mapbox',\n        datasource_type='table',\n        datasource_id=tbl.id,\n        params=get_slice_json(slice_data),\n    )\n    misc_dash_slices.add(slc.slice_name)\n    merge_slice(slc)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the external metadata from the source system", "response": "def external_metadata(self, datasource_type=None, datasource_id=None):\n        \"\"\"Gets column info from the source system\"\"\"\n        if datasource_type == 'druid':\n            datasource = ConnectorRegistry.get_datasource(\n                datasource_type, datasource_id, db.session)\n        elif datasource_type == 'table':\n            database = (\n                db.session\n                .query(Database)\n                .filter_by(id=request.args.get('db_id'))\n                .one()\n            )\n            Table = ConnectorRegistry.sources['table']\n            datasource = Table(\n                database=database,\n                table_name=request.args.get('table_name'),\n                schema=request.args.get('schema') or None,\n            )\n        external_metadata = datasource.external_metadata()\n        return self.json_response(external_metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of non empty values or None", "response": "def filter_not_empty_values(value):\n    \"\"\"Returns a list of non empty values or None\"\"\"\n    if not value:\n        return None\n    data = [x for x in value if x]\n    if not data:\n        return None\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the user can upload csv to any schema in the database.", "response": "def at_least_one_schema_is_allowed(database):\n        \"\"\"\n        If the user has access to the database or all datasource\n            1. if schemas_allowed_for_csv_upload is empty\n                a) if database does not support schema\n                    user is able to upload csv without specifying schema name\n                b) if database supports schema\n                    user is able to upload csv to any schema\n            2. if schemas_allowed_for_csv_upload is not empty\n                a) if database does not support schema\n                    This situation is impossible and upload will fail\n                b) if database supports schema\n                    user is able to upload to schema in schemas_allowed_for_csv_upload\n        elif the user does not access to the database or all datasource\n            1. if schemas_allowed_for_csv_upload is empty\n                a) if database does not support schema\n                    user is unable to upload csv\n                b) if database supports schema\n                    user is unable to upload csv\n            2. if schemas_allowed_for_csv_upload is not empty\n                a) if database does not support schema\n                    This situation is impossible and user is unable to upload csv\n                b) if database supports schema\n                    user is able to upload to schema in schemas_allowed_for_csv_upload\n        \"\"\"\n        if (security_manager.database_access(database) or\n                security_manager.all_datasource_access()):\n            return True\n        schemas = database.get_schema_access_for_csv_upload()\n        if (schemas and\n            security_manager.schemas_accessible_by_user(\n                database, schemas, False)):\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply a function to filter the query to only those owned by current user.", "response": "def apply(\n            self,\n            query: BaseQuery,\n            func: Callable) -> BaseQuery:\n        \"\"\"\n        Filter queries to only those owned by current user if\n        can_only_access_owned_queries permission is set.\n\n        :returns: query\n        \"\"\"\n        if security_manager.can_only_access_owned_queries():\n            query = (\n                query\n                .filter(Query.user_id == g.user.get_user_id())\n            )\n        return query"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a langugage pack for a given locale", "response": "def get_language_pack(locale):\n    \"\"\"Get/cache a language pack\n\n    Returns the langugage pack from cache if it exists, caches otherwise\n\n    >>> get_language_pack('fr')['Dashboards']\n    \"Tableaux de bords\"\n    \"\"\"\n    pack = ALL_LANGUAGE_PACKS.get(locale)\n    if not pack:\n        filename = DIR + '/{}/LC_MESSAGES/messages.json'.format(locale)\n        try:\n            with open(filename) as f:\n                pack = json.load(f)\n                ALL_LANGUAGE_PACKS[locale] = pack\n        except Exception:\n            # Assuming english, client side falls back on english\n            pass\n    return pack"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding the form_data for a chart GET request from a dashboard s default_filters.", "response": "def get_form_data(chart_id, dashboard=None):\n    \"\"\"\n    Build `form_data` for chart GET request from dashboard's `default_filters`.\n\n    When a dashboard has `default_filters` they need to be added  as extra\n    filters in the GET request for charts.\n\n    \"\"\"\n    form_data = {'slice_id': chart_id}\n\n    if dashboard is None or not dashboard.json_metadata:\n        return form_data\n\n    json_metadata = json.loads(dashboard.json_metadata)\n\n    # do not apply filters if chart is immune to them\n    if chart_id in json_metadata.get('filter_immune_slices', []):\n        return form_data\n\n    default_filters = json.loads(json_metadata.get('default_filters', 'null'))\n    if not default_filters:\n        return form_data\n\n    # are some of the fields in the chart immune to filters?\n    filter_immune_slice_fields = json_metadata.get('filter_immune_slice_fields', {})\n    immune_fields = filter_immune_slice_fields.get(str(chart_id), [])\n\n    extra_filters = []\n    for filters in default_filters.values():\n        for col, val in filters.items():\n            if col not in immune_fields:\n                extra_filters.append({'col': col, 'op': 'in', 'val': val})\n    if extra_filters:\n        form_data['extra_filters'] = extra_filters\n\n    return form_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns external URL for warming up a given chart or table cache.", "response": "def get_url(params):\n    \"\"\"Return external URL for warming up a given chart/table cache.\"\"\"\n    baseurl = 'http://{SUPERSET_WEBSERVER_ADDRESS}:{SUPERSET_WEBSERVER_PORT}/'.format(\n        **app.config)\n    with app.test_request_context():\n        return urllib.parse.urljoin(\n            baseurl,\n            url_for('Superset.explore_json', **params),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cache_warmup(strategy_name, *args, **kwargs):\n    logger.info('Loading strategy')\n    class_ = None\n    for class_ in strategies:\n        if class_.name == strategy_name:\n            break\n    else:\n        message = f'No strategy {strategy_name} found!'\n        logger.error(message)\n        return message\n\n    logger.info(f'Loading {class_.__name__}')\n    try:\n        strategy = class_(*args, **kwargs)\n        logger.info('Success!')\n    except TypeError:\n        message = 'Error loading strategy!'\n        logger.exception(message)\n        return message\n\n    results = {'success': [], 'errors': []}\n    for url in strategy.get_urls():\n        try:\n            logger.info(f'Fetching {url}')\n            requests.get(url)\n            results['success'].append(url)\n        except RequestException:\n            logger.exception('Error warming up cache!')\n            results['errors'].append(url)\n\n    return results", "response": "Warm up cache.\n\n    This task periodically hits charts to warm up the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetch_logs(self, max_rows=1024,\n               orientation=None):\n    \"\"\"Mocked. Retrieve the logs produced by the execution of the query.\n    Can be called multiple times to fetch the logs produced after\n    the previous call.\n    :returns: list<str>\n    :raises: ``ProgrammingError`` when no query has been started\n    .. note::\n        This is not a part of DB-API.\n    \"\"\"\n    from pyhive import hive\n    from TCLIService import ttypes\n    from thrift import Thrift\n    orientation = orientation or ttypes.TFetchOrientation.FETCH_NEXT\n    try:\n        req = ttypes.TGetLogReq(operationHandle=self._operationHandle)\n        logs = self._connection.client.GetLog(req).log\n        return logs\n    # raised if Hive is used\n    except (ttypes.TApplicationException,\n            Thrift.TApplicationException):\n        if self._state == self._STATE_NONE:\n            raise hive.ProgrammingError('No query yet')\n        logs = []\n        while True:\n            req = ttypes.TFetchResultsReq(\n                operationHandle=self._operationHandle,\n                orientation=ttypes.TFetchOrientation.FETCH_NEXT,\n                maxRows=self.arraysize,\n                fetchType=1,  # 0: results, 1: logs\n            )\n            response = self._connection.client.FetchResults(req)\n            hive._check_status(response)\n            assert not response.results.rows, \\\n                'expected data in columnar format'\n            assert len(response.results.columns) == 1, response.results.columns\n            new_logs = hive._unwrap_column(response.results.columns[0])\n            logs += new_logs\n            if not new_logs:\n                break\n        return '\\n'.join(logs)", "response": "Mocked. Retrieve the logs produced by the execution of the query."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef refresh_datasources(\n            self,\n            datasource_name=None,\n            merge_flag=True,\n            refreshAll=True):\n        \"\"\"Refresh metadata of all datasources in the cluster\n        If ``datasource_name`` is specified, only that datasource is updated\n        \"\"\"\n        ds_list = self.get_datasources()\n        blacklist = conf.get('DRUID_DATA_SOURCE_BLACKLIST', [])\n        ds_refresh = []\n        if not datasource_name:\n            ds_refresh = list(filter(lambda ds: ds not in blacklist, ds_list))\n        elif datasource_name not in blacklist and datasource_name in ds_list:\n            ds_refresh.append(datasource_name)\n        else:\n            return\n        self.refresh(ds_refresh, merge_flag, refreshAll)", "response": "Refresh metadata of all datasources in the cluster"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef refresh(self, datasource_names, merge_flag, refreshAll):\n        session = db.session\n        ds_list = (\n            session.query(DruidDatasource)\n            .filter(DruidDatasource.cluster_name == self.cluster_name)\n            .filter(DruidDatasource.datasource_name.in_(datasource_names))\n        )\n        ds_map = {ds.name: ds for ds in ds_list}\n        for ds_name in datasource_names:\n            datasource = ds_map.get(ds_name, None)\n            if not datasource:\n                datasource = DruidDatasource(datasource_name=ds_name)\n                with session.no_autoflush:\n                    session.add(datasource)\n                flasher(\n                    _('Adding new datasource [{}]').format(ds_name), 'success')\n                ds_map[ds_name] = datasource\n            elif refreshAll:\n                flasher(\n                    _('Refreshing datasource [{}]').format(ds_name), 'info')\n            else:\n                del ds_map[ds_name]\n                continue\n            datasource.cluster = self\n            datasource.merge_flag = merge_flag\n        session.flush()\n\n        # Prepare multithreaded executation\n        pool = ThreadPool()\n        ds_refresh = list(ds_map.values())\n        metadata = pool.map(_fetch_metadata_for, ds_refresh)\n        pool.close()\n        pool.join()\n\n        for i in range(0, len(ds_refresh)):\n            datasource = ds_refresh[i]\n            cols = metadata[i]\n            if cols:\n                col_objs_list = (\n                    session.query(DruidColumn)\n                    .filter(DruidColumn.datasource_id == datasource.id)\n                    .filter(DruidColumn.column_name.in_(cols.keys()))\n                )\n                col_objs = {col.column_name: col for col in col_objs_list}\n                for col in cols:\n                    if col == '__time':  # skip the time column\n                        continue\n                    col_obj = col_objs.get(col)\n                    if not col_obj:\n                        col_obj = DruidColumn(\n                            datasource_id=datasource.id,\n                            column_name=col)\n                        with session.no_autoflush:\n                            session.add(col_obj)\n                    col_obj.type = cols[col]['type']\n                    col_obj.datasource = datasource\n                    if col_obj.type == 'STRING':\n                        col_obj.groupby = True\n                        col_obj.filterable = True\n                datasource.refresh_metrics()\n        session.commit()", "response": "Refreshes the metadata for the specified datasources and merges them to the Superset database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef refresh_metrics(self):\n        metrics = self.get_metrics()\n        dbmetrics = (\n            db.session.query(DruidMetric)\n            .filter(DruidMetric.datasource_id == self.datasource_id)\n            .filter(DruidMetric.metric_name.in_(metrics.keys()))\n        )\n        dbmetrics = {metric.metric_name: metric for metric in dbmetrics}\n        for metric in metrics.values():\n            dbmetric = dbmetrics.get(metric.metric_name)\n            if dbmetric:\n                for attr in ['json', 'metric_type']:\n                    setattr(dbmetric, attr, getattr(metric, attr))\n            else:\n                with db.session.no_autoflush:\n                    metric.datasource_id = self.datasource_id\n                    db.session.add(metric)", "response": "Refresh the metrics based on the column metadata"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nimporting the datasource from the object to the database.", "response": "def import_obj(cls, i_datasource, import_time=None):\n        \"\"\"Imports the datasource from the object to the database.\n\n         Metrics and columns and datasource will be overridden if exists.\n         This function can be used to import/export dashboards between multiple\n         superset instances. Audit metadata isn't copies over.\n        \"\"\"\n        def lookup_datasource(d):\n            return db.session.query(DruidDatasource).filter(\n                DruidDatasource.datasource_name == d.datasource_name,\n                DruidCluster.cluster_name == d.cluster_name,\n            ).first()\n\n        def lookup_cluster(d):\n            return db.session.query(DruidCluster).filter_by(\n                cluster_name=d.cluster_name).one()\n        return import_datasource.import_datasource(\n            db.session, i_datasource, lookup_cluster, lookup_datasource,\n            import_time)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmerge the ds config from druid_config into one stored in the db.", "response": "def sync_to_db_from_config(\n            cls,\n            druid_config,\n            user,\n            cluster,\n            refresh=True):\n        \"\"\"Merges the ds config from druid_config into one stored in the db.\"\"\"\n        session = db.session\n        datasource = (\n            session.query(cls)\n            .filter_by(datasource_name=druid_config['name'])\n            .first()\n        )\n        # Create a new datasource.\n        if not datasource:\n            datasource = cls(\n                datasource_name=druid_config['name'],\n                cluster=cluster,\n                owners=[user],\n                changed_by_fk=user.id,\n                created_by_fk=user.id,\n            )\n            session.add(datasource)\n        elif not refresh:\n            return\n\n        dimensions = druid_config['dimensions']\n        col_objs = (\n            session.query(DruidColumn)\n            .filter(DruidColumn.datasource_id == datasource.id)\n            .filter(DruidColumn.column_name.in_(dimensions))\n        )\n        col_objs = {col.column_name: col for col in col_objs}\n        for dim in dimensions:\n            col_obj = col_objs.get(dim, None)\n            if not col_obj:\n                col_obj = DruidColumn(\n                    datasource_id=datasource.id,\n                    column_name=dim,\n                    groupby=True,\n                    filterable=True,\n                    # TODO: fetch type from Hive.\n                    type='STRING',\n                    datasource=datasource,\n                )\n                session.add(col_obj)\n        # Import Druid metrics\n        metric_objs = (\n            session.query(DruidMetric)\n            .filter(DruidMetric.datasource_id == datasource.id)\n            .filter(DruidMetric.metric_name.in_(\n                spec['name'] for spec in druid_config['metrics_spec']\n            ))\n        )\n        metric_objs = {metric.metric_name: metric for metric in metric_objs}\n        for metric_spec in druid_config['metrics_spec']:\n            metric_name = metric_spec['name']\n            metric_type = metric_spec['type']\n            metric_json = json.dumps(metric_spec)\n\n            if metric_type == 'count':\n                metric_type = 'longSum'\n                metric_json = json.dumps({\n                    'type': 'longSum',\n                    'name': metric_name,\n                    'fieldName': metric_name,\n                })\n\n            metric_obj = metric_objs.get(metric_name, None)\n            if not metric_obj:\n                metric_obj = DruidMetric(\n                    metric_name=metric_name,\n                    metric_type=metric_type,\n                    verbose_name='%s(%s)' % (metric_type, metric_name),\n                    datasource=datasource,\n                    json=metric_json,\n                    description=(\n                        'Imported from the airolap config dir for %s' %\n                        druid_config['name']),\n                )\n                session.add(metric_obj)\n        session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_post_agg(mconf):\n        if mconf.get('type') == 'javascript':\n            return JavascriptPostAggregator(\n                name=mconf.get('name', ''),\n                field_names=mconf.get('fieldNames', []),\n                function=mconf.get('function', ''))\n        elif mconf.get('type') == 'quantile':\n            return Quantile(\n                mconf.get('name', ''),\n                mconf.get('probability', ''),\n            )\n        elif mconf.get('type') == 'quantiles':\n            return Quantiles(\n                mconf.get('name', ''),\n                mconf.get('probabilities', ''),\n            )\n        elif mconf.get('type') == 'fieldAccess':\n            return Field(mconf.get('name'))\n        elif mconf.get('type') == 'constant':\n            return Const(\n                mconf.get('value'),\n                output_name=mconf.get('name', ''),\n            )\n        elif mconf.get('type') == 'hyperUniqueCardinality':\n            return HyperUniqueCardinality(\n                mconf.get('name'),\n            )\n        elif mconf.get('type') == 'arithmetic':\n            return Postaggregator(\n                mconf.get('fn', '/'),\n                mconf.get('fields', []),\n                mconf.get('name', ''))\n        else:\n            return CustomPostAggregator(\n                mconf.get('name', ''),\n                mconf)", "response": "Returns the kind of post aggregation for a metric specified as postagg."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of metrics that are post aggregations", "response": "def find_postaggs_for(postagg_names, metrics_dict):\n        \"\"\"Return a list of metrics that are post aggregations\"\"\"\n        postagg_metrics = [\n            metrics_dict[name] for name in postagg_names\n            if metrics_dict[name].metric_type == POST_AGG_TYPE\n        ]\n        # Remove post aggregations that were found\n        for postagg in postagg_metrics:\n            postagg_names.remove(postagg.metric_name)\n        return postagg_metrics"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving some values for the given column", "response": "def values_for_column(self,\n                          column_name,\n                          limit=10000):\n        \"\"\"Retrieve some values for the given column\"\"\"\n        logging.info(\n            'Getting values for columns [{}] limited to [{}]'\n            .format(column_name, limit))\n        # TODO: Use Lexicographic TopNMetricSpec once supported by PyDruid\n        if self.fetch_values_from:\n            from_dttm = utils.parse_human_datetime(self.fetch_values_from)\n        else:\n            from_dttm = datetime(1970, 1, 1)\n\n        qry = dict(\n            datasource=self.datasource_name,\n            granularity='all',\n            intervals=from_dttm.isoformat() + '/' + datetime.now().isoformat(),\n            aggregations=dict(count=count('count')),\n            dimension=column_name,\n            metric='count',\n            threshold=limit,\n        )\n\n        client = self.cluster.get_pydruid_client()\n        client.topn(**qry)\n        df = client.export_pandas()\n        return [row[column_name] for row in df.to_records(index=False)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary of aggregation metric names to aggregation json objects.", "response": "def get_aggregations(metrics_dict, saved_metrics, adhoc_metrics=[]):\n        \"\"\"\n            Returns a dictionary of aggregation metric names to aggregation json objects\n\n            :param metrics_dict: dictionary of all the metrics\n            :param saved_metrics: list of saved metric names\n            :param adhoc_metrics: list of adhoc metric names\n            :raise SupersetException: if one or more metric names are not aggregations\n        \"\"\"\n        aggregations = OrderedDict()\n        invalid_metric_names = []\n        for metric_name in saved_metrics:\n            if metric_name in metrics_dict:\n                metric = metrics_dict[metric_name]\n                if metric.metric_type == POST_AGG_TYPE:\n                    invalid_metric_names.append(metric_name)\n                else:\n                    aggregations[metric_name] = metric.json_obj\n            else:\n                invalid_metric_names.append(metric_name)\n        if len(invalid_metric_names) > 0:\n            raise SupersetException(\n                _('Metric(s) {} must be aggregations.').format(invalid_metric_names))\n        for adhoc_metric in adhoc_metrics:\n            aggregations[adhoc_metric['label']] = {\n                'fieldName': adhoc_metric['column']['column_name'],\n                'fieldNames': [adhoc_metric['column']['column_name']],\n                'type': DruidDatasource.druid_type_from_adhoc_metric(adhoc_metric),\n                'name': adhoc_metric['label'],\n            }\n        return aggregations"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a list of dimensions to a list of values.", "response": "def _dimensions_to_values(dimensions):\n        \"\"\"\n        Replace dimensions specs with their `dimension`\n        values, and ignore those without\n        \"\"\"\n        values = []\n        for dimension in dimensions:\n            if isinstance(dimension, dict):\n                if 'extractionFn' in dimension:\n                    values.append(dimension)\n                elif 'dimension' in dimension:\n                    values.append(dimension['dimension'])\n            else:\n                values.append(dimension)\n\n        return values"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning a query against Druid and returns a dataframe.", "response": "def run_query(  # noqa / druid\n            self,\n            groupby, metrics,\n            granularity,\n            from_dttm, to_dttm,\n            filter=None,  # noqa\n            is_timeseries=True,\n            timeseries_limit=None,\n            timeseries_limit_metric=None,\n            row_limit=None,\n            inner_from_dttm=None, inner_to_dttm=None,\n            orderby=None,\n            extras=None,  # noqa\n            columns=None, phase=2, client=None,\n            order_desc=True,\n            prequeries=None,\n            is_prequery=False,\n        ):\n        \"\"\"Runs a query against Druid and returns a dataframe.\n        \"\"\"\n        # TODO refactor into using a TBD Query object\n        client = client or self.cluster.get_pydruid_client()\n        row_limit = row_limit or conf.get('ROW_LIMIT')\n\n        if not is_timeseries:\n            granularity = 'all'\n\n        if granularity == 'all':\n            phase = 1\n        inner_from_dttm = inner_from_dttm or from_dttm\n        inner_to_dttm = inner_to_dttm or to_dttm\n\n        timezone = from_dttm.replace(tzinfo=DRUID_TZ).tzname() if from_dttm else None\n\n        query_str = ''\n        metrics_dict = {m.metric_name: m for m in self.metrics}\n        columns_dict = {c.column_name: c for c in self.columns}\n\n        if (\n            self.cluster and\n            LooseVersion(self.cluster.get_druid_version()) < LooseVersion('0.11.0')\n        ):\n            for metric in metrics:\n                self.sanitize_metric_object(metric)\n            self.sanitize_metric_object(timeseries_limit_metric)\n\n        aggregations, post_aggs = DruidDatasource.metrics_and_post_aggs(\n            metrics,\n            metrics_dict)\n\n        self.check_restricted_metrics(aggregations)\n\n        # the dimensions list with dimensionSpecs expanded\n        dimensions = self.get_dimensions(groupby, columns_dict)\n        extras = extras or {}\n        qry = dict(\n            datasource=self.datasource_name,\n            dimensions=dimensions,\n            aggregations=aggregations,\n            granularity=DruidDatasource.granularity(\n                granularity,\n                timezone=timezone,\n                origin=extras.get('druid_time_origin'),\n            ),\n            post_aggregations=post_aggs,\n            intervals=self.intervals_from_dttms(from_dttm, to_dttm),\n        )\n\n        filters = DruidDatasource.get_filters(filter, self.num_cols, columns_dict)\n        if filters:\n            qry['filter'] = filters\n\n        having_filters = self.get_having_filters(extras.get('having_druid'))\n        if having_filters:\n            qry['having'] = having_filters\n\n        order_direction = 'descending' if order_desc else 'ascending'\n\n        if columns:\n            columns.append('__time')\n            del qry['post_aggregations']\n            del qry['aggregations']\n            qry['dimensions'] = columns\n            qry['metrics'] = []\n            qry['granularity'] = 'all'\n            qry['limit'] = row_limit\n            client.scan(**qry)\n        elif len(groupby) == 0 and not having_filters:\n            logging.info('Running timeseries query for no groupby values')\n            del qry['dimensions']\n            client.timeseries(**qry)\n        elif (\n                not having_filters and\n                len(groupby) == 1 and\n                order_desc\n        ):\n            dim = list(qry.get('dimensions'))[0]\n            logging.info('Running two-phase topn query for dimension [{}]'.format(dim))\n            pre_qry = deepcopy(qry)\n            if timeseries_limit_metric:\n                order_by = utils.get_metric_name(timeseries_limit_metric)\n                aggs_dict, post_aggs_dict = DruidDatasource.metrics_and_post_aggs(\n                    [timeseries_limit_metric],\n                    metrics_dict)\n                if phase == 1:\n                    pre_qry['aggregations'].update(aggs_dict)\n                    pre_qry['post_aggregations'].update(post_aggs_dict)\n                else:\n                    pre_qry['aggregations'] = aggs_dict\n                    pre_qry['post_aggregations'] = post_aggs_dict\n            else:\n                agg_keys = qry['aggregations'].keys()\n                order_by = list(agg_keys)[0] if agg_keys else None\n\n            # Limit on the number of timeseries, doing a two-phases query\n            pre_qry['granularity'] = 'all'\n            pre_qry['threshold'] = min(row_limit,\n                                       timeseries_limit or row_limit)\n            pre_qry['metric'] = order_by\n            pre_qry['dimension'] = self._dimensions_to_values(qry.get('dimensions'))[0]\n            del pre_qry['dimensions']\n\n            client.topn(**pre_qry)\n            logging.info('Phase 1 Complete')\n            if phase == 2:\n                query_str += '// Two phase query\\n// Phase 1\\n'\n            query_str += json.dumps(\n                client.query_builder.last_query.query_dict, indent=2)\n            query_str += '\\n'\n            if phase == 1:\n                return query_str\n            query_str += (\n                \"// Phase 2 (built based on phase one's results)\\n\")\n            df = client.export_pandas()\n            qry['filter'] = self._add_filter_from_pre_query_data(\n                df,\n                [pre_qry['dimension']],\n                filters)\n            qry['threshold'] = timeseries_limit or 1000\n            if row_limit and granularity == 'all':\n                qry['threshold'] = row_limit\n            qry['dimension'] = dim\n            del qry['dimensions']\n            qry['metric'] = list(qry['aggregations'].keys())[0]\n            client.topn(**qry)\n            logging.info('Phase 2 Complete')\n        elif len(groupby) > 0 or having_filters:\n            # If grouping on multiple fields or using a having filter\n            # we have to force a groupby query\n            logging.info('Running groupby query for dimensions [{}]'.format(dimensions))\n            if timeseries_limit and is_timeseries:\n                logging.info('Running two-phase query for timeseries')\n\n                pre_qry = deepcopy(qry)\n                pre_qry_dims = self._dimensions_to_values(qry['dimensions'])\n\n                # Can't use set on an array with dicts\n                # Use set with non-dict items only\n                non_dict_dims = list(\n                    set([x for x in pre_qry_dims if not isinstance(x, dict)]),\n                )\n                dict_dims = [x for x in pre_qry_dims if isinstance(x, dict)]\n                pre_qry['dimensions'] = non_dict_dims + dict_dims\n\n                order_by = None\n                if metrics:\n                    order_by = utils.get_metric_name(metrics[0])\n                else:\n                    order_by = pre_qry_dims[0]\n\n                if timeseries_limit_metric:\n                    order_by = utils.get_metric_name(timeseries_limit_metric)\n                    aggs_dict, post_aggs_dict = DruidDatasource.metrics_and_post_aggs(\n                        [timeseries_limit_metric],\n                        metrics_dict)\n                    if phase == 1:\n                        pre_qry['aggregations'].update(aggs_dict)\n                        pre_qry['post_aggregations'].update(post_aggs_dict)\n                    else:\n                        pre_qry['aggregations'] = aggs_dict\n                        pre_qry['post_aggregations'] = post_aggs_dict\n\n                # Limit on the number of timeseries, doing a two-phases query\n                pre_qry['granularity'] = 'all'\n                pre_qry['limit_spec'] = {\n                    'type': 'default',\n                    'limit': min(timeseries_limit, row_limit),\n                    'intervals': self.intervals_from_dttms(\n                        inner_from_dttm, inner_to_dttm),\n                    'columns': [{\n                        'dimension': order_by,\n                        'direction': order_direction,\n                    }],\n                }\n                client.groupby(**pre_qry)\n                logging.info('Phase 1 Complete')\n                query_str += '// Two phase query\\n// Phase 1\\n'\n                query_str += json.dumps(\n                    client.query_builder.last_query.query_dict, indent=2)\n                query_str += '\\n'\n                if phase == 1:\n                    return query_str\n                query_str += (\n                    \"// Phase 2 (built based on phase one's results)\\n\")\n                df = client.export_pandas()\n                qry['filter'] = self._add_filter_from_pre_query_data(\n                    df,\n                    pre_qry['dimensions'],\n                    filters,\n                )\n                qry['limit_spec'] = None\n            if row_limit:\n                dimension_values = self._dimensions_to_values(dimensions)\n                qry['limit_spec'] = {\n                    'type': 'default',\n                    'limit': row_limit,\n                    'columns': [{\n                        'dimension': (\n                            utils.get_metric_name(\n                                metrics[0],\n                            ) if metrics else dimension_values[0]\n                        ),\n                        'direction': order_direction,\n                    }],\n                }\n            client.groupby(**qry)\n            logging.info('Query Complete')\n        query_str += json.dumps(\n            client.query_builder.last_query.query_dict, indent=2)\n        return query_str"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert all GROUPBY columns to strings", "response": "def homogenize_types(df, groupby_cols):\n        \"\"\"Converting all GROUPBY columns to strings\n\n        When grouping by a numeric (say FLOAT) column, pydruid returns\n        strings in the dataframe. This creates issues downstream related\n        to having mixed types in the dataframe\n\n        Here we replace None with <NULL> and make the whole series a\n        str instead of an object.\n        \"\"\"\n        for col in groupby_cols:\n            df[col] = df[col].fillna('<NULL>').astype('unicode')\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a list of Superset filter data structure returns a list of pydruid Filter objects.", "response": "def get_filters(cls, raw_filters, num_cols, columns_dict):  # noqa\n        \"\"\"Given Superset filter data structure, returns pydruid Filter(s)\"\"\"\n        filters = None\n        for flt in raw_filters:\n            col = flt.get('col')\n            op = flt.get('op')\n            eq = flt.get('val')\n            if (\n                    not col or\n                    not op or\n                    (eq is None and op not in ('IS NULL', 'IS NOT NULL'))):\n                continue\n\n            # Check if this dimension uses an extraction function\n            # If so, create the appropriate pydruid extraction object\n            column_def = columns_dict.get(col)\n            dim_spec = column_def.dimension_spec if column_def else None\n            extraction_fn = None\n            if dim_spec and 'extractionFn' in dim_spec:\n                (col, extraction_fn) = DruidDatasource._create_extraction_fn(dim_spec)\n\n            cond = None\n            is_numeric_col = col in num_cols\n            is_list_target = op in ('in', 'not in')\n            eq = cls.filter_values_handler(\n                eq, is_list_target=is_list_target,\n                target_column_is_numeric=is_numeric_col)\n\n            # For these two ops, could have used Dimension,\n            # but it doesn't support extraction functions\n            if op == '==':\n                cond = Filter(dimension=col, value=eq, extraction_function=extraction_fn)\n            elif op == '!=':\n                cond = ~Filter(dimension=col, value=eq, extraction_function=extraction_fn)\n            elif op in ('in', 'not in'):\n                fields = []\n                # ignore the filter if it has no value\n                if not len(eq):\n                    continue\n                # if it uses an extraction fn, use the \"in\" operator\n                # as Dimension isn't supported\n                elif extraction_fn is not None:\n                    cond = Filter(\n                        dimension=col,\n                        values=eq,\n                        type='in',\n                        extraction_function=extraction_fn,\n                    )\n                elif len(eq) == 1:\n                    cond = Dimension(col) == eq[0]\n                else:\n                    for s in eq:\n                        fields.append(Dimension(col) == s)\n                    cond = Filter(type='or', fields=fields)\n                if op == 'not in':\n                    cond = ~cond\n            elif op == 'regex':\n                cond = Filter(\n                    extraction_function=extraction_fn,\n                    type='regex',\n                    pattern=eq,\n                    dimension=col,\n                )\n\n            # For the ops below, could have used pydruid's Bound,\n            # but it doesn't support extraction functions\n            elif op == '>=':\n                cond = Filter(\n                    type='bound',\n                    extraction_function=extraction_fn,\n                    dimension=col,\n                    lowerStrict=False,\n                    upperStrict=False,\n                    lower=eq,\n                    upper=None,\n                    alphaNumeric=is_numeric_col,\n                )\n            elif op == '<=':\n                cond = Filter(\n                    type='bound',\n                    extraction_function=extraction_fn,\n                    dimension=col,\n                    lowerStrict=False,\n                    upperStrict=False,\n                    lower=None,\n                    upper=eq,\n                    alphaNumeric=is_numeric_col,\n                )\n            elif op == '>':\n                cond = Filter(\n                    type='bound',\n                    extraction_function=extraction_fn,\n                    lowerStrict=True,\n                    upperStrict=False,\n                    dimension=col,\n                    lower=eq,\n                    upper=None,\n                    alphaNumeric=is_numeric_col,\n                )\n            elif op == '<':\n                cond = Filter(\n                    type='bound',\n                    extraction_function=extraction_fn,\n                    upperStrict=True,\n                    lowerStrict=False,\n                    dimension=col,\n                    lower=None,\n                    upper=eq,\n                    alphaNumeric=is_numeric_col,\n                )\n            elif op == 'IS NULL':\n                cond = Dimension(col) == None  # NOQA\n            elif op == 'IS NOT NULL':\n                cond = Dimension(col) != None  # NOQA\n\n            if filters:\n                filters = Filter(type='and', fields=[\n                    cond,\n                    filters,\n                ])\n            else:\n                filters = cond\n\n        return filters"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_env_variable(var_name, default=None):\n    try:\n        return os.environ[var_name]\n    except KeyError:\n        if default is not None:\n            return default\n        else:\n            error_msg = 'The environment variable {} was missing, abort...'\\\n                        .format(var_name)\n            raise EnvironmentError(error_msg)", "response": "Get the environment variable or raise exception."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_eager_datasource(cls, session, datasource_type, datasource_id):\n        datasource_class = ConnectorRegistry.sources[datasource_type]\n        return (\n            session.query(datasource_class)\n            .options(\n                subqueryload(datasource_class.columns),\n                subqueryload(datasource_class.metrics),\n            )\n            .filter_by(id=datasource_id)\n            .one()\n        )", "response": "Returns datasource with columns and metrics."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_misc_dashboard():\n\n    print('Creating the dashboard')\n    db.session.expunge_all()\n    dash = db.session.query(Dash).filter_by(slug=DASH_SLUG).first()\n\n    if not dash:\n        dash = Dash()\n    js = textwrap.dedent(\"\"\"\\\n{\n    \"CHART-BkeVbh8ANQ\": {\n        \"children\": [],\n        \"id\": \"CHART-BkeVbh8ANQ\",\n        \"meta\": {\n            \"chartId\": 4004,\n            \"height\": 34,\n            \"sliceName\": \"Multi Line\",\n            \"width\": 8\n        },\n        \"type\": \"CHART\"\n    },\n    \"CHART-H1HYNzEANX\": {\n        \"children\": [],\n        \"id\": \"CHART-H1HYNzEANX\",\n        \"meta\": {\n            \"chartId\": 3940,\n            \"height\": 50,\n            \"sliceName\": \"Energy Sankey\",\n            \"width\": 6\n        },\n        \"type\": \"CHART\"\n    },\n    \"CHART-HJOYVMV0E7\": {\n        \"children\": [],\n        \"id\": \"CHART-HJOYVMV0E7\",\n        \"meta\": {\n            \"chartId\": 3969,\n            \"height\": 63,\n            \"sliceName\": \"Mapbox Long/Lat\",\n            \"width\": 6\n        },\n        \"type\": \"CHART\"\n    },\n    \"CHART-S1WYNz4AVX\": {\n        \"children\": [],\n        \"id\": \"CHART-S1WYNz4AVX\",\n        \"meta\": {\n            \"chartId\": 3989,\n            \"height\": 25,\n            \"sliceName\": \"Parallel Coordinates\",\n            \"width\": 4\n        },\n        \"type\": \"CHART\"\n    },\n    \"CHART-r19KVMNCE7\": {\n        \"children\": [],\n        \"id\": \"CHART-r19KVMNCE7\",\n        \"meta\": {\n            \"chartId\": 3971,\n            \"height\": 34,\n            \"sliceName\": \"Calendar Heatmap multiformat 0\",\n            \"width\": 4\n        },\n        \"type\": \"CHART\"\n    },\n    \"CHART-rJ4K4GV04Q\": {\n        \"children\": [],\n        \"id\": \"CHART-rJ4K4GV04Q\",\n        \"meta\": {\n            \"chartId\": 3941,\n            \"height\": 63,\n            \"sliceName\": \"Energy Force Layout\",\n            \"width\": 6\n        },\n        \"type\": \"CHART\"\n    },\n    \"CHART-rkgF4G4A4X\": {\n        \"children\": [],\n        \"id\": \"CHART-rkgF4G4A4X\",\n        \"meta\": {\n            \"chartId\": 3970,\n            \"height\": 25,\n            \"sliceName\": \"Birth in France by department in 2016\",\n            \"width\": 8\n        },\n        \"type\": \"CHART\"\n    },\n    \"CHART-rywK4GVR4X\": {\n        \"children\": [],\n        \"id\": \"CHART-rywK4GVR4X\",\n        \"meta\": {\n            \"chartId\": 3942,\n            \"height\": 50,\n            \"sliceName\": \"Heatmap\",\n            \"width\": 6\n        },\n        \"type\": \"CHART\"\n    },\n    \"COLUMN-ByUFVf40EQ\": {\n        \"children\": [\n            \"CHART-rywK4GVR4X\",\n            \"CHART-HJOYVMV0E7\"\n        ],\n        \"id\": \"COLUMN-ByUFVf40EQ\",\n        \"meta\": {\n            \"background\": \"BACKGROUND_TRANSPARENT\",\n            \"width\": 6\n        },\n        \"type\": \"COLUMN\"\n    },\n    \"COLUMN-rkmYVGN04Q\": {\n        \"children\": [\n            \"CHART-rJ4K4GV04Q\",\n            \"CHART-H1HYNzEANX\"\n        ],\n        \"id\": \"COLUMN-rkmYVGN04Q\",\n        \"meta\": {\n            \"background\": \"BACKGROUND_TRANSPARENT\",\n            \"width\": 6\n        },\n        \"type\": \"COLUMN\"\n    },\n    \"GRID_ID\": {\n        \"children\": [\n            \"ROW-SytNzNA4X\",\n            \"ROW-S1MK4M4A4X\",\n            \"ROW-HkFFEzVRVm\"\n        ],\n        \"id\": \"GRID_ID\",\n        \"type\": \"GRID\"\n    },\n    \"HEADER_ID\": {\n        \"id\": \"HEADER_ID\",\n        \"meta\": {\n            \"text\": \"Misc Charts\"\n        },\n        \"type\": \"HEADER\"\n    },\n    \"ROOT_ID\": {\n        \"children\": [\n            \"GRID_ID\"\n        ],\n        \"id\": \"ROOT_ID\",\n        \"type\": \"ROOT\"\n    },\n    \"ROW-HkFFEzVRVm\": {\n        \"children\": [\n            \"CHART-r19KVMNCE7\",\n            \"CHART-BkeVbh8ANQ\"\n        ],\n        \"id\": \"ROW-HkFFEzVRVm\",\n        \"meta\": {\n            \"background\": \"BACKGROUND_TRANSPARENT\"\n        },\n        \"type\": \"ROW\"\n    },\n    \"ROW-S1MK4M4A4X\": {\n        \"children\": [\n            \"COLUMN-rkmYVGN04Q\",\n            \"COLUMN-ByUFVf40EQ\"\n        ],\n        \"id\": \"ROW-S1MK4M4A4X\",\n        \"meta\": {\n            \"background\": \"BACKGROUND_TRANSPARENT\"\n        },\n        \"type\": \"ROW\"\n    },\n    \"ROW-SytNzNA4X\": {\n        \"children\": [\n            \"CHART-rkgF4G4A4X\",\n            \"CHART-S1WYNz4AVX\"\n        ],\n        \"id\": \"ROW-SytNzNA4X\",\n        \"meta\": {\n            \"background\": \"BACKGROUND_TRANSPARENT\"\n        },\n        \"type\": \"ROW\"\n    },\n    \"DASHBOARD_VERSION_KEY\": \"v2\"\n}\n    \"\"\")\n    pos = json.loads(js)\n    slices = (\n        db.session\n        .query(Slice)\n        .filter(Slice.slice_name.in_(misc_dash_slices))\n        .all()\n    )\n    slices = sorted(slices, key=lambda x: x.id)\n    update_slice_ids(pos, slices)\n    dash.dashboard_title = 'Misc Charts'\n    dash.position_json = json.dumps(pos, indent=4)\n    dash.slug = DASH_SLUG\n    dash.slices = slices\n    db.session.merge(dash)\n    db.session.commit()", "response": "Load a misc chart"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads the world bank health dataset slices and dashboard", "response": "def load_world_bank_health_n_pop():\n    \"\"\"Loads the world bank health dataset, slices and a dashboard\"\"\"\n    tbl_name = 'wb_health_population'\n    data = get_example_data('countries.json.gz')\n    pdf = pd.read_json(data)\n    pdf.columns = [col.replace('.', '_') for col in pdf.columns]\n    pdf.year = pd.to_datetime(pdf.year)\n    pdf.to_sql(\n        tbl_name,\n        db.engine,\n        if_exists='replace',\n        chunksize=50,\n        dtype={\n            'year': DateTime(),\n            'country_code': String(3),\n            'country_name': String(255),\n            'region': String(255),\n        },\n        index=False)\n\n    print('Creating table [wb_health_population] reference')\n    tbl = db.session.query(TBL).filter_by(table_name=tbl_name).first()\n    if not tbl:\n        tbl = TBL(table_name=tbl_name)\n    tbl.description = utils.readfile(os.path.join(DATA_FOLDER, 'countries.md'))\n    tbl.main_dttm_col = 'year'\n    tbl.database = utils.get_or_create_main_db()\n    tbl.filter_select_enabled = True\n\n    metrics = [\n        'sum__SP_POP_TOTL', 'sum__SH_DYN_AIDS', 'sum__SH_DYN_AIDS',\n        'sum__SP_RUR_TOTL_ZS', 'sum__SP_DYN_LE00_IN',\n    ]\n    for m in metrics:\n        if not any(col.metric_name == m for col in tbl.metrics):\n            tbl.metrics.append(SqlMetric(\n                metric_name=m,\n                expression=f'{m[:3]}({m[5:]})',\n            ))\n\n    db.session.merge(tbl)\n    db.session.commit()\n    tbl.fetch_metadata()\n\n    defaults = {\n        'compare_lag': '10',\n        'compare_suffix': 'o10Y',\n        'limit': '25',\n        'granularity_sqla': 'year',\n        'groupby': [],\n        'metric': 'sum__SP_POP_TOTL',\n        'metrics': ['sum__SP_POP_TOTL'],\n        'row_limit': config.get('ROW_LIMIT'),\n        'since': '2014-01-01',\n        'until': '2014-01-02',\n        'time_range': '2014-01-01 : 2014-01-02',\n        'where': '',\n        'markup_type': 'markdown',\n        'country_fieldtype': 'cca3',\n        'secondary_metric': 'sum__SP_POP_TOTL',\n        'entity': 'country_code',\n        'show_bubbles': True,\n    }\n\n    print('Creating slices')\n    slices = [\n        Slice(\n            slice_name='Region Filter',\n            viz_type='filter_box',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                viz_type='filter_box',\n                date_filter=False,\n                filter_configs=[\n                    {\n                        'asc': False,\n                        'clearable': True,\n                        'column': 'region',\n                        'key': '2s98dfu',\n                        'metric': 'sum__SP_POP_TOTL',\n                        'multiple': True,\n                    }, {\n                        'asc': False,\n                        'clearable': True,\n                        'key': 'li3j2lk',\n                        'column': 'country_name',\n                        'metric': 'sum__SP_POP_TOTL',\n                        'multiple': True,\n                    },\n                ])),\n        Slice(\n            slice_name=\"World's Population\",\n            viz_type='big_number',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                since='2000',\n                viz_type='big_number',\n                compare_lag='10',\n                metric='sum__SP_POP_TOTL',\n                compare_suffix='over 10Y')),\n        Slice(\n            slice_name='Most Populated Countries',\n            viz_type='table',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                viz_type='table',\n                metrics=['sum__SP_POP_TOTL'],\n                groupby=['country_name'])),\n        Slice(\n            slice_name='Growth Rate',\n            viz_type='line',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                viz_type='line',\n                since='1960-01-01',\n                metrics=['sum__SP_POP_TOTL'],\n                num_period_compare='10',\n                groupby=['country_name'])),\n        Slice(\n            slice_name='% Rural',\n            viz_type='world_map',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                viz_type='world_map',\n                metric='sum__SP_RUR_TOTL_ZS',\n                num_period_compare='10')),\n        Slice(\n            slice_name='Life Expectancy VS Rural %',\n            viz_type='bubble',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                viz_type='bubble',\n                since='2011-01-01',\n                until='2011-01-02',\n                series='region',\n                limit=0,\n                entity='country_name',\n                x='sum__SP_RUR_TOTL_ZS',\n                y='sum__SP_DYN_LE00_IN',\n                size='sum__SP_POP_TOTL',\n                max_bubble_size='50',\n                filters=[{\n                    'col': 'country_code',\n                    'val': [\n                        'TCA', 'MNP', 'DMA', 'MHL', 'MCO', 'SXM', 'CYM',\n                        'TUV', 'IMY', 'KNA', 'ASM', 'ADO', 'AMA', 'PLW',\n                    ],\n                    'op': 'not in'}],\n            )),\n        Slice(\n            slice_name='Rural Breakdown',\n            viz_type='sunburst',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                viz_type='sunburst',\n                groupby=['region', 'country_name'],\n                secondary_metric='sum__SP_RUR_TOTL',\n                since='2011-01-01',\n                until='2011-01-01')),\n        Slice(\n            slice_name=\"World's Pop Growth\",\n            viz_type='area',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                since='1960-01-01',\n                until='now',\n                viz_type='area',\n                groupby=['region'])),\n        Slice(\n            slice_name='Box plot',\n            viz_type='box_plot',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                since='1960-01-01',\n                until='now',\n                whisker_options='Min/max (no outliers)',\n                x_ticks_layout='staggered',\n                viz_type='box_plot',\n                groupby=['region'])),\n        Slice(\n            slice_name='Treemap',\n            viz_type='treemap',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                since='1960-01-01',\n                until='now',\n                viz_type='treemap',\n                metrics=['sum__SP_POP_TOTL'],\n                groupby=['region', 'country_code'])),\n        Slice(\n            slice_name='Parallel Coordinates',\n            viz_type='para',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                since='2011-01-01',\n                until='2011-01-01',\n                viz_type='para',\n                limit=100,\n                metrics=[\n                    'sum__SP_POP_TOTL',\n                    'sum__SP_RUR_TOTL_ZS',\n                    'sum__SH_DYN_AIDS'],\n                secondary_metric='sum__SP_POP_TOTL',\n                series='country_name')),\n    ]\n    misc_dash_slices.add(slices[-1].slice_name)\n    for slc in slices:\n        merge_slice(slc)\n\n    print(\"Creating a World's Health Bank dashboard\")\n    dash_name = \"World's Bank Data\"\n    slug = 'world_health'\n    dash = db.session.query(Dash).filter_by(slug=slug).first()\n\n    if not dash:\n        dash = Dash()\n    js = textwrap.dedent(\"\"\"\\\n{\n    \"CHART-36bfc934\": {\n        \"children\": [],\n        \"id\": \"CHART-36bfc934\",\n        \"meta\": {\n            \"chartId\": 40,\n            \"height\": 25,\n            \"sliceName\": \"Region Filter\",\n            \"width\": 2\n        },\n        \"type\": \"CHART\"\n    },\n    \"CHART-37982887\": {\n        \"children\": [],\n        \"id\": \"CHART-37982887\",\n        \"meta\": {\n            \"chartId\": 41,\n            \"height\": 25,\n            \"sliceName\": \"World's Population\",\n            \"width\": 2\n        },\n        \"type\": \"CHART\"\n    },\n    \"CHART-17e0f8d8\": {\n        \"children\": [],\n        \"id\": \"CHART-17e0f8d8\",\n        \"meta\": {\n            \"chartId\": 42,\n            \"height\": 92,\n            \"sliceName\": \"Most Populated Countries\",\n            \"width\": 3\n        },\n        \"type\": \"CHART\"\n    },\n    \"CHART-2ee52f30\": {\n        \"children\": [],\n        \"id\": \"CHART-2ee52f30\",\n        \"meta\": {\n            \"chartId\": 43,\n            \"height\": 38,\n            \"sliceName\": \"Growth Rate\",\n            \"width\": 6\n        },\n        \"type\": \"CHART\"\n    },\n    \"CHART-2d5b6871\": {\n        \"children\": [],\n        \"id\": \"CHART-2d5b6871\",\n        \"meta\": {\n            \"chartId\": 44,\n            \"height\": 52,\n            \"sliceName\": \"% Rural\",\n            \"width\": 7\n        },\n        \"type\": \"CHART\"\n    },\n    \"CHART-0fd0d252\": {\n        \"children\": [],\n        \"id\": \"CHART-0fd0d252\",\n        \"meta\": {\n            \"chartId\": 45,\n            \"height\": 50,\n            \"sliceName\": \"Life Expectancy VS Rural %\",\n            \"width\": 8\n        },\n        \"type\": \"CHART\"\n    },\n    \"CHART-97f4cb48\": {\n        \"children\": [],\n        \"id\": \"CHART-97f4cb48\",\n        \"meta\": {\n            \"chartId\": 46,\n            \"height\": 38,\n            \"sliceName\": \"Rural Breakdown\",\n            \"width\": 3\n        },\n        \"type\": \"CHART\"\n    },\n    \"CHART-b5e05d6f\": {\n        \"children\": [],\n        \"id\": \"CHART-b5e05d6f\",\n        \"meta\": {\n            \"chartId\": 47,\n            \"height\": 50,\n            \"sliceName\": \"World's Pop Growth\",\n            \"width\": 4\n        },\n        \"type\": \"CHART\"\n    },\n    \"CHART-e76e9f5f\": {\n        \"children\": [],\n        \"id\": \"CHART-e76e9f5f\",\n        \"meta\": {\n            \"chartId\": 48,\n            \"height\": 50,\n            \"sliceName\": \"Box plot\",\n            \"width\": 4\n        },\n        \"type\": \"CHART\"\n    },\n    \"CHART-a4808bba\": {\n        \"children\": [],\n        \"id\": \"CHART-a4808bba\",\n        \"meta\": {\n            \"chartId\": 49,\n            \"height\": 50,\n            \"sliceName\": \"Treemap\",\n            \"width\": 8\n        },\n        \"type\": \"CHART\"\n    },\n    \"COLUMN-071bbbad\": {\n        \"children\": [\n            \"ROW-1e064e3c\",\n            \"ROW-afdefba9\"\n        ],\n        \"id\": \"COLUMN-071bbbad\",\n        \"meta\": {\n            \"background\": \"BACKGROUND_TRANSPARENT\",\n            \"width\": 9\n        },\n        \"type\": \"COLUMN\"\n    },\n    \"COLUMN-fe3914b8\": {\n        \"children\": [\n            \"CHART-36bfc934\",\n            \"CHART-37982887\"\n        ],\n        \"id\": \"COLUMN-fe3914b8\",\n        \"meta\": {\n            \"background\": \"BACKGROUND_TRANSPARENT\",\n            \"width\": 2\n        },\n        \"type\": \"COLUMN\"\n    },\n    \"GRID_ID\": {\n        \"children\": [\n            \"ROW-46632bc2\",\n            \"ROW-3fa26c5d\",\n            \"ROW-812b3f13\"\n        ],\n        \"id\": \"GRID_ID\",\n        \"type\": \"GRID\"\n    },\n    \"HEADER_ID\": {\n        \"id\": \"HEADER_ID\",\n        \"meta\": {\n            \"text\": \"World's Bank Data\"\n        },\n        \"type\": \"HEADER\"\n    },\n    \"ROOT_ID\": {\n        \"children\": [\n            \"GRID_ID\"\n        ],\n        \"id\": \"ROOT_ID\",\n        \"type\": \"ROOT\"\n    },\n    \"ROW-1e064e3c\": {\n        \"children\": [\n            \"COLUMN-fe3914b8\",\n            \"CHART-2d5b6871\"\n        ],\n        \"id\": \"ROW-1e064e3c\",\n        \"meta\": {\n            \"background\": \"BACKGROUND_TRANSPARENT\"\n        },\n        \"type\": \"ROW\"\n    },\n    \"ROW-3fa26c5d\": {\n        \"children\": [\n            \"CHART-b5e05d6f\",\n            \"CHART-0fd0d252\"\n        ],\n        \"id\": \"ROW-3fa26c5d\",\n        \"meta\": {\n            \"background\": \"BACKGROUND_TRANSPARENT\"\n        },\n        \"type\": \"ROW\"\n    },\n    \"ROW-46632bc2\": {\n        \"children\": [\n            \"COLUMN-071bbbad\",\n            \"CHART-17e0f8d8\"\n        ],\n        \"id\": \"ROW-46632bc2\",\n        \"meta\": {\n            \"background\": \"BACKGROUND_TRANSPARENT\"\n        },\n        \"type\": \"ROW\"\n    },\n    \"ROW-812b3f13\": {\n        \"children\": [\n            \"CHART-a4808bba\",\n            \"CHART-e76e9f5f\"\n        ],\n        \"id\": \"ROW-812b3f13\",\n        \"meta\": {\n            \"background\": \"BACKGROUND_TRANSPARENT\"\n        },\n        \"type\": \"ROW\"\n    },\n    \"ROW-afdefba9\": {\n        \"children\": [\n            \"CHART-2ee52f30\",\n            \"CHART-97f4cb48\"\n        ],\n        \"id\": \"ROW-afdefba9\",\n        \"meta\": {\n            \"background\": \"BACKGROUND_TRANSPARENT\"\n        },\n        \"type\": \"ROW\"\n    },\n    \"DASHBOARD_VERSION_KEY\": \"v2\"\n}\n    \"\"\")\n    pos = json.loads(js)\n    update_slice_ids(pos, slices)\n\n    dash.dashboard_title = dash_name\n    dash.position_json = json.dumps(pos, indent=4)\n    dash.slug = slug\n\n    dash.slices = slices[:-1]\n    db.session.merge(dash)\n    db.session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_country_map_data():\n    csv_bytes = get_example_data(\n        'birth_france_data_for_country_map.csv', is_gzip=False, make_bytes=True)\n    data = pd.read_csv(csv_bytes, encoding='utf-8')\n    data['dttm'] = datetime.datetime.now().date()\n    data.to_sql(  # pylint: disable=no-member\n        'birth_france_by_region',\n        db.engine,\n        if_exists='replace',\n        chunksize=500,\n        dtype={\n            'DEPT_ID': String(10),\n            '2003': BigInteger,\n            '2004': BigInteger,\n            '2005': BigInteger,\n            '2006': BigInteger,\n            '2007': BigInteger,\n            '2008': BigInteger,\n            '2009': BigInteger,\n            '2010': BigInteger,\n            '2011': BigInteger,\n            '2012': BigInteger,\n            '2013': BigInteger,\n            '2014': BigInteger,\n            'dttm': Date(),\n        },\n        index=False)\n    print('Done loading table!')\n    print('-' * 80)\n    print('Creating table reference')\n    obj = db.session.query(TBL).filter_by(table_name='birth_france_by_region').first()\n    if not obj:\n        obj = TBL(table_name='birth_france_by_region')\n    obj.main_dttm_col = 'dttm'\n    obj.database = utils.get_or_create_main_db()\n    if not any(col.metric_name == 'avg__2004' for col in obj.metrics):\n        obj.metrics.append(SqlMetric(\n            metric_name='avg__2004',\n            expression='AVG(2004)',\n        ))\n    db.session.merge(obj)\n    db.session.commit()\n    obj.fetch_metadata()\n    tbl = obj\n\n    slice_data = {\n        'granularity_sqla': '',\n        'since': '',\n        'until': '',\n        'where': '',\n        'viz_type': 'country_map',\n        'entity': 'DEPT_ID',\n        'metric': {\n            'expressionType': 'SIMPLE',\n            'column': {\n                'type': 'INT',\n                'column_name': '2004',\n            },\n            'aggregate': 'AVG',\n            'label': 'Boys',\n            'optionName': 'metric_112342',\n        },\n        'row_limit': 500000,\n    }\n\n    print('Creating a slice')\n    slc = Slice(\n        slice_name='Birth in France by department in 2016',\n        viz_type='country_map',\n        datasource_type='table',\n        datasource_id=tbl.id,\n        params=get_slice_json(slice_data),\n    )\n    misc_dash_slices.add(slc.slice_name)\n    merge_slice(slc)", "response": "Load data for country map with country map"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_statements(self):\n        statements = []\n        for statement in self._parsed:\n            if statement:\n                sql = str(statement).strip(' \\n;\\t')\n                if sql:\n                    statements.append(sql)\n        return statements", "response": "Returns a list of SQL statements as strings stripped"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreformat the query into the create table as query.", "response": "def as_create_table(self, table_name, overwrite=False):\n        \"\"\"Reformats the query into the create table as query.\n\n        Works only for the single select SQL statements, in all other cases\n        the sql query is not modified.\n        :param superset_query: string, sql query that will be executed\n        :param table_name: string, will contain the results of the\n            query execution\n        :param overwrite, boolean, table table_name will be dropped if true\n        :return: string, create table as query\n        \"\"\"\n        exec_sql = ''\n        sql = self.stripped()\n        if overwrite:\n            exec_sql = f'DROP TABLE IF EXISTS {table_name};\\n'\n        exec_sql += f'CREATE TABLE {table_name} AS \\n{sql}'\n        return exec_sql"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the underlying query with the specified limit", "response": "def get_query_with_new_limit(self, new_limit):\n        \"\"\"returns the query with the specified limit\"\"\"\n        \"\"\"does not change the underlying query\"\"\"\n        if not self._limit:\n            return self.sql + ' LIMIT ' + str(new_limit)\n        limit_pos = None\n        tokens = self._parsed[0].tokens\n        # Add all items to before_str until there is a limit\n        for pos, item in enumerate(tokens):\n            if item.ttype in Keyword and item.value.lower() == 'limit':\n                limit_pos = pos\n                break\n        limit = tokens[limit_pos + 2]\n        if limit.ttype == sqlparse.tokens.Literal.Number.Integer:\n            tokens[limit_pos + 2].value = new_limit\n        elif limit.is_group:\n            tokens[limit_pos + 2].value = (\n                '{}, {}'.format(next(limit.get_identifiers()), new_limit)\n            )\n\n        str_res = ''\n        for i in tokens:\n            str_res += str(i.value)\n        return str_res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading a URL or POST parameter and use it in your SQL Lab query", "response": "def url_param(param, default=None):\n    \"\"\"Read a url or post parameter and use it in your SQL Lab query\n\n    When in SQL Lab, it's possible to add arbitrary URL \"query string\"\n    parameters, and use those in your SQL code. For instance you can\n    alter your url and add `?foo=bar`, as in\n    `{domain}/superset/sqllab?foo=bar`. Then if your query is something like\n    SELECT * FROM foo = '{{ url_param('foo') }}', it will be parsed at\n    runtime and replaced by the value in the URL.\n\n    As you create a visualization form this SQL Lab query, you can pass\n    parameters in the explore view as well as from the dashboard, and\n    it should carry through to your queries.\n\n    :param param: the parameter to lookup\n    :type param: str\n    :param default: the value to return in the absence of the parameter\n    :type default: str\n    \"\"\"\n    if request.args.get(param):\n        return request.args.get(param, default)\n    # Supporting POST as well as get\n    if request.form.get('form_data'):\n        form_data = json.loads(request.form.get('form_data'))\n        url_params = form_data.get('url_params') or {}\n        return url_params.get(param, default)\n    return default"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a list of values for a particular column", "response": "def filter_values(column, default=None):\n    \"\"\" Gets a values for a particular filter as a list\n\n    This is useful if:\n        - you want to use a filter box to filter a query where the name of filter box\n          column doesn't match the one in the select statement\n        - you want to have the ability for filter inside the main query for speed purposes\n\n    This searches for \"filters\" and \"extra_filters\" in form_data for a match\n\n    Usage example:\n        SELECT action, count(*) as times\n        FROM logs\n        WHERE action in ( {{ \"'\" + \"','\".join(filter_values('action_type')) + \"'\" }} )\n        GROUP BY 1\n\n    :param column: column/filter name to lookup\n    :type column: str\n    :param default: default value to return if there's no matching columns\n    :type default: str\n    :return: returns a list of filter values\n    :type: list\n    \"\"\"\n    form_data = json.loads(request.form.get('form_data', '{}'))\n    return_val = []\n    for filter_type in ['filters', 'extra_filters']:\n        if filter_type not in form_data:\n            continue\n\n        for f in form_data[filter_type]:\n            if f['col'] == column:\n                for v in f['val']:\n                    return_val.append(v)\n\n    if return_val:\n        return return_val\n\n    if default:\n        return [default]\n    else:\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_template(self, sql, **kwargs):\n        template = self.env.from_string(sql)\n        kwargs.update(self.context)\n        return template.render(kwargs)", "response": "Processes a sql template and returns the result as a string"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_datasource_info(datasource_id, datasource_type, form_data):\n    datasource = form_data.get('datasource', '')\n    if '__' in datasource:\n        datasource_id, datasource_type = datasource.split('__')\n        # The case where the datasource has been deleted\n        datasource_id = None if datasource_id == 'None' else datasource_id\n\n    if not datasource_id:\n        raise Exception(\n            'The datasource associated with this chart no longer exists')\n    datasource_id = int(datasource_id)\n    return datasource_id, datasource_type", "response": "Compatibility layer for handling of datasource info"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprotect from has_access failing from missing perms / view", "response": "def can_access(self, permission_name, view_name):\n        \"\"\"Protecting from has_access failing from missing perms/view\"\"\"\n        user = g.user\n        if user.is_anonymous:\n            return self.is_item_public(permission_name, view_name)\n        return self._has_view_access(user, permission_name, view_name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate missing perms for datasources schemas and metrics.", "response": "def create_missing_perms(self):\n        \"\"\"Creates missing perms for datasources, schemas and metrics\"\"\"\n        from superset import db\n        from superset.models import core as models\n\n        logging.info(\n            'Fetching a set of all perms to lookup which ones are missing')\n        all_pvs = set()\n        for pv in self.get_session.query(self.permissionview_model).all():\n            if pv.permission and pv.view_menu:\n                all_pvs.add((pv.permission.name, pv.view_menu.name))\n\n        def merge_pv(view_menu, perm):\n            \"\"\"Create permission view menu only if it doesn't exist\"\"\"\n            if view_menu and perm and (view_menu, perm) not in all_pvs:\n                self.merge_perm(view_menu, perm)\n\n        logging.info('Creating missing datasource permissions.')\n        datasources = ConnectorRegistry.get_all_datasources(db.session)\n        for datasource in datasources:\n            merge_pv('datasource_access', datasource.get_perm())\n            merge_pv('schema_access', datasource.schema_perm)\n\n        logging.info('Creating missing database permissions.')\n        databases = db.session.query(models.Database).all()\n        for database in databases:\n            merge_pv('database_access', database.perm)\n\n        logging.info('Creating missing metrics permissions')\n        metrics = []\n        for datasource_class in ConnectorRegistry.sources.values():\n            metrics += list(db.session.query(datasource_class.metric_class).all())\n\n        for metric in metrics:\n            if metric.is_restricted:\n                merge_pv('metric_access', metric.perm)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clean_perms(self):\n        logging.info('Cleaning faulty perms')\n        sesh = self.get_session\n        pvms = (\n            sesh.query(ab_models.PermissionView)\n            .filter(or_(\n                ab_models.PermissionView.permission == None,  # NOQA\n                ab_models.PermissionView.view_menu == None,  # NOQA\n            ))\n        )\n        deleted_count = pvms.delete()\n        sesh.commit()\n        if deleted_count:\n            logging.info('Deleted {} faulty permissions'.format(deleted_count))", "response": "Delete faulty permissions that need to be cleaned up"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sync_role_definitions(self):\n        from superset import conf\n        logging.info('Syncing role definition')\n\n        self.create_custom_permissions()\n\n        # Creating default roles\n        self.set_role('Admin', self.is_admin_pvm)\n        self.set_role('Alpha', self.is_alpha_pvm)\n        self.set_role('Gamma', self.is_gamma_pvm)\n        self.set_role('granter', self.is_granter_pvm)\n        self.set_role('sql_lab', self.is_sql_lab_pvm)\n\n        if conf.get('PUBLIC_ROLE_LIKE_GAMMA', False):\n            self.set_role('Public', self.is_gamma_pvm)\n\n        self.create_missing_perms()\n\n        # commit role and view menu updates\n        self.get_session.commit()\n        self.clean_perms()", "response": "Inits the Superset application with security roles and such"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexport the supported import / export schema to a dictionary", "response": "def export_schema_to_dict(back_references):\n    \"\"\"Exports the supported import/export schema to a dictionary\"\"\"\n    databases = [Database.export_schema(recursive=True,\n                 include_parent_ref=back_references)]\n    clusters = [DruidCluster.export_schema(recursive=True,\n                include_parent_ref=back_references)]\n    data = dict()\n    if databases:\n        data[DATABASES_KEY] = databases\n    if clusters:\n        data[DRUID_CLUSTERS_KEY] = clusters\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexports databases and druid clusters to a dictionary", "response": "def export_to_dict(session,\n                   recursive,\n                   back_references,\n                   include_defaults):\n    \"\"\"Exports databases and druid clusters to a dictionary\"\"\"\n    logging.info('Starting export')\n    dbs = session.query(Database)\n    databases = [database.export_to_dict(recursive=recursive,\n                 include_parent_ref=back_references,\n                 include_defaults=include_defaults) for database in dbs]\n    logging.info('Exported %d %s', len(databases), DATABASES_KEY)\n    cls = session.query(DruidCluster)\n    clusters = [cluster.export_to_dict(recursive=recursive,\n                include_parent_ref=back_references,\n                include_defaults=include_defaults) for cluster in cls]\n    logging.info('Exported %d %s', len(clusters), DRUID_CLUSTERS_KEY)\n    data = dict()\n    if databases:\n        data[DATABASES_KEY] = databases\n    if clusters:\n        data[DRUID_CLUSTERS_KEY] = clusters\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nimporting databases and druid clusters from dictionary", "response": "def import_from_dict(session, data, sync=[]):\n    \"\"\"Imports databases and druid clusters from dictionary\"\"\"\n    if isinstance(data, dict):\n        logging.info('Importing %d %s',\n                     len(data.get(DATABASES_KEY, [])),\n                     DATABASES_KEY)\n        for database in data.get(DATABASES_KEY, []):\n            Database.import_from_dict(session, database, sync=sync)\n\n        logging.info('Importing %d %s',\n                     len(data.get(DRUID_CLUSTERS_KEY, [])),\n                     DRUID_CLUSTERS_KEY)\n        for datasource in data.get(DRUID_CLUSTERS_KEY, []):\n            DruidCluster.import_from_dict(session, datasource, sync=sync)\n        session.commit()\n    else:\n        logging.info('Supplied object is not a dictionary.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef query(self):\n        query_context = QueryContext(**json.loads(request.form.get('query_context')))\n        security_manager.assert_datasource_permission(query_context.datasource)\n        payload_json = query_context.get_payload()\n        return json.dumps(\n            payload_json,\n            default=utils.json_int_dttm_ser,\n            ignore_nan=True,\n        )", "response": "Query the data for a given resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nquerying the formdata stored in the database for an existing slice.", "response": "def query_form_data(self):\n        \"\"\"\n        Get the formdata stored in the database for existing slice.\n        params: slice_id: integer\n        \"\"\"\n        form_data = {}\n        slice_id = request.args.get('slice_id')\n        if slice_id:\n            slc = db.session.query(models.Slice).filter_by(id=slice_id).one_or_none()\n            if slc:\n                form_data = slc.form_data.copy()\n\n        update_time_range(form_data)\n\n        return json.dumps(form_data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload 2 css templates to demonstrate the feature", "response": "def load_css_templates():\n    \"\"\"Loads 2 css templates to demonstrate the feature\"\"\"\n    print('Creating default CSS templates')\n\n    obj = db.session.query(CssTemplate).filter_by(template_name='Flat').first()\n    if not obj:\n        obj = CssTemplate(template_name='Flat')\n    css = textwrap.dedent(\"\"\"\\\n    .gridster div.widget {\n        transition: background-color 0.5s ease;\n        background-color: #FAFAFA;\n        border: 1px solid #CCC;\n        box-shadow: none;\n        border-radius: 0px;\n    }\n    .gridster div.widget:hover {\n        border: 1px solid #000;\n        background-color: #EAEAEA;\n    }\n    .navbar {\n        transition: opacity 0.5s ease;\n        opacity: 0.05;\n    }\n    .navbar:hover {\n        opacity: 1;\n    }\n    .chart-header .header{\n        font-weight: normal;\n        font-size: 12px;\n    }\n    /*\n    var bnbColors = [\n        //rausch    hackb      kazan      babu      lima        beach     tirol\n        '#ff5a5f', '#7b0051', '#007A87', '#00d1c1', '#8ce071', '#ffb400', '#b4a76c',\n        '#ff8083', '#cc0086', '#00a1b3', '#00ffeb', '#bbedab', '#ffd266', '#cbc29a',\n        '#ff3339', '#ff1ab1', '#005c66', '#00b3a5', '#55d12e', '#b37e00', '#988b4e',\n     ];\n    */\n    \"\"\")\n    obj.css = css\n    db.session.merge(obj)\n    db.session.commit()\n\n    obj = (\n        db.session.query(CssTemplate).filter_by(template_name='Courier Black').first())\n    if not obj:\n        obj = CssTemplate(template_name='Courier Black')\n    css = textwrap.dedent(\"\"\"\\\n    .gridster div.widget {\n        transition: background-color 0.5s ease;\n        background-color: #EEE;\n        border: 2px solid #444;\n        border-radius: 15px;\n        box-shadow: none;\n    }\n    h2 {\n        color: white;\n        font-size: 52px;\n    }\n    .navbar {\n        box-shadow: none;\n    }\n    .gridster div.widget:hover {\n        border: 2px solid #000;\n        background-color: #EAEAEA;\n    }\n    .navbar {\n        transition: opacity 0.5s ease;\n        opacity: 0.05;\n    }\n    .navbar:hover {\n        opacity: 1;\n    }\n    .chart-header .header{\n        font-weight: normal;\n        font-size: 12px;\n    }\n    .nvd3 text {\n        font-size: 12px;\n        font-family: inherit;\n    }\n    body{\n        background: #000;\n        font-family: Courier, Monaco, monospace;;\n    }\n    /*\n    var bnbColors = [\n        //rausch    hackb      kazan      babu      lima        beach     tirol\n        '#ff5a5f', '#7b0051', '#007A87', '#00d1c1', '#8ce071', '#ffb400', '#b4a76c',\n        '#ff8083', '#cc0086', '#00a1b3', '#00ffeb', '#bbedab', '#ffd266', '#cbc29a',\n        '#ff3339', '#ff1ab1', '#005c66', '#00b3a5', '#55d12e', '#b37e00', '#988b4e',\n     ];\n    */\n    \"\"\")\n    obj.css = css\n    db.session.merge(obj)\n    db.session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a mapping of foreign name to the local name of foreign keys", "response": "def _parent_foreign_key_mappings(cls):\n        \"\"\"Get a mapping of foreign name to the local name of foreign keys\"\"\"\n        parent_rel = cls.__mapper__.relationships.get(cls.export_parent)\n        if parent_rel:\n            return {l.name: r.name for (l, r) in parent_rel.local_remote_pairs}\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting all unique constraints", "response": "def _unique_constrains(cls):\n        \"\"\"Get all (single column and multi column) unique constraints\"\"\"\n        unique = [{c.name for c in u.columns} for u in cls.__table_args__\n                  if isinstance(u, UniqueConstraint)]\n        unique.extend({c.name} for c in cls.__table__.columns if c.unique)\n        return unique"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexporting schema as a dictionary", "response": "def export_schema(cls, recursive=True, include_parent_ref=False):\n        \"\"\"Export schema as a dictionary\"\"\"\n        parent_excludes = {}\n        if not include_parent_ref:\n            parent_ref = cls.__mapper__.relationships.get(cls.export_parent)\n            if parent_ref:\n                parent_excludes = {c.name for c in parent_ref.local_columns}\n\n        def formatter(c):\n            return ('{0} Default ({1})'.format(\n                str(c.type), c.default.arg) if c.default else str(c.type))\n\n        schema = {c.name: formatter(c) for c in cls.__table__.columns\n                  if (c.name in cls.export_fields and\n                  c.name not in parent_excludes)}\n        if recursive:\n            for c in cls.export_children:\n                child_class = cls.__mapper__.relationships[c].argument.class_\n                schema[c] = [child_class.export_schema(recursive=recursive,\n                             include_parent_ref=include_parent_ref)]\n        return schema"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nimporting obj from a dictionary", "response": "def import_from_dict(cls, session, dict_rep, parent=None,\n                         recursive=True, sync=[]):\n        \"\"\"Import obj from a dictionary\"\"\"\n        parent_refs = cls._parent_foreign_key_mappings()\n        export_fields = set(cls.export_fields) | set(parent_refs.keys())\n        new_children = {c: dict_rep.get(c) for c in cls.export_children\n                        if c in dict_rep}\n        unique_constrains = cls._unique_constrains()\n\n        filters = []  # Using these filters to check if obj already exists\n\n        # Remove fields that should not get imported\n        for k in list(dict_rep):\n            if k not in export_fields:\n                del dict_rep[k]\n\n        if not parent:\n            if cls.export_parent:\n                for p in parent_refs.keys():\n                    if p not in dict_rep:\n                        raise RuntimeError(\n                            '{0}: Missing field {1}'.format(cls.__name__, p))\n        else:\n            # Set foreign keys to parent obj\n            for k, v in parent_refs.items():\n                dict_rep[k] = getattr(parent, v)\n\n        # Add filter for parent obj\n        filters.extend([getattr(cls, k) == dict_rep.get(k)\n                        for k in parent_refs.keys()])\n\n        # Add filter for unique constraints\n        ucs = [and_(*[getattr(cls, k) == dict_rep.get(k)\n               for k in cs if dict_rep.get(k) is not None])\n               for cs in unique_constrains]\n        filters.append(or_(*ucs))\n\n        # Check if object already exists in DB, break if more than one is found\n        try:\n            obj_query = session.query(cls).filter(and_(*filters))\n            obj = obj_query.one_or_none()\n        except MultipleResultsFound as e:\n            logging.error('Error importing %s \\n %s \\n %s', cls.__name__,\n                          str(obj_query),\n                          yaml.safe_dump(dict_rep))\n            raise e\n\n        if not obj:\n            is_new_obj = True\n            # Create new DB object\n            obj = cls(**dict_rep)\n            logging.info('Importing new %s %s', obj.__tablename__, str(obj))\n            if cls.export_parent and parent:\n                setattr(obj, cls.export_parent, parent)\n            session.add(obj)\n        else:\n            is_new_obj = False\n            logging.info('Updating %s %s', obj.__tablename__, str(obj))\n            # Update columns\n            for k, v in dict_rep.items():\n                setattr(obj, k, v)\n\n        # Recursively create children\n        if recursive:\n            for c in cls.export_children:\n                child_class = cls.__mapper__.relationships[c].argument.class_\n                added = []\n                for c_obj in new_children.get(c, []):\n                    added.append(child_class.import_from_dict(session=session,\n                                                              dict_rep=c_obj,\n                                                              parent=obj,\n                                                              sync=sync))\n                # If children should get synced, delete the ones that did not\n                # get updated.\n                if c in sync and not is_new_obj:\n                    back_refs = child_class._parent_foreign_key_mappings()\n                    delete_filters = [getattr(child_class, k) ==\n                                      getattr(obj, back_refs.get(k))\n                                      for k in back_refs.keys()]\n                    to_delete = set(session.query(child_class).filter(\n                        and_(*delete_filters))).difference(set(added))\n                    for o in to_delete:\n                        logging.info('Deleting %s %s', c, str(obj))\n                        session.delete(o)\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexport obj to dictionary", "response": "def export_to_dict(self, recursive=True, include_parent_ref=False,\n                       include_defaults=False):\n        \"\"\"Export obj to dictionary\"\"\"\n        cls = self.__class__\n        parent_excludes = {}\n        if recursive and not include_parent_ref:\n            parent_ref = cls.__mapper__.relationships.get(cls.export_parent)\n            if parent_ref:\n                parent_excludes = {c.name for c in parent_ref.local_columns}\n        dict_rep = {c.name: getattr(self, c.name)\n                    for c in cls.__table__.columns\n                    if (c.name in self.export_fields and\n                        c.name not in parent_excludes and\n                        (include_defaults or (\n                            getattr(self, c.name) is not None and\n                            (not c.default or\n                                getattr(self, c.name) != c.default.arg))))\n                    }\n        if recursive:\n            for c in self.export_children:\n                # sorting to make lists of children stable\n                dict_rep[c] = sorted(\n                    [\n                        child.export_to_dict(\n                            recursive=recursive,\n                            include_parent_ref=include_parent_ref,\n                            include_defaults=include_defaults,\n                        ) for child in getattr(self, c)\n                    ],\n                    key=lambda k: sorted(k.items()))\n\n        return dict_rep"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef override(self, obj):\n        for field in obj.__class__.export_fields:\n            setattr(self, field, getattr(obj, field))", "response": "Overrides the plain fields of the dashboard."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmove since and until to time_range.", "response": "def update_time_range(form_data):\n    \"\"\"Move since and until to time_range.\"\"\"\n    if 'since' in form_data or 'until' in form_data:\n        form_data['time_range'] = '{} : {}'.format(\n            form_data.pop('since', '') or '',\n            form_data.pop('until', '') or '',\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef memoized_func(key=view_cache_key, attribute_in_key=None):\n    def wrap(f):\n        if tables_cache:\n            def wrapped_f(self, *args, **kwargs):\n                if not kwargs.get('cache', True):\n                    return f(self, *args, **kwargs)\n\n                if attribute_in_key:\n                    cache_key = key(*args, **kwargs).format(\n                        getattr(self, attribute_in_key))\n                else:\n                    cache_key = key(*args, **kwargs)\n                o = tables_cache.get(cache_key)\n                if not kwargs.get('force') and o is not None:\n                    return o\n                o = f(self, *args, **kwargs)\n                tables_cache.set(cache_key, o,\n                                 timeout=kwargs.get('cache_timeout'))\n                return o\n        else:\n            # noop\n            def wrapped_f(self, *args, **kwargs):\n                return f(self, *args, **kwargs)\n        return wrapped_f\n    return wrap", "response": "Decorator to cache functions that have predefined first arg."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nnaming property for the current table", "response": "def name(self):\n        \"\"\"Name property\"\"\"\n        ts = datetime.now().isoformat()\n        ts = ts.replace('-', '').replace(':', '').split('.')[0]\n        tab = (self.tab_name.replace(' ', '_').lower()\n               if self.tab_name else 'notab')\n        tab = re.sub(r'\\W+', '', tab)\n        return f'sqllab_{tab}_{ts}'"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if user can access a cached response from explore_json.", "response": "def check_datasource_perms(self, datasource_type=None, datasource_id=None):\n    \"\"\"\n    Check if user can access a cached response from explore_json.\n\n    This function takes `self` since it must have the same signature as the\n    the decorated method.\n\n    \"\"\"\n    form_data = get_form_data()[0]\n    datasource_id, datasource_type = get_datasource_info(\n        datasource_id, datasource_type, form_data)\n    viz_obj = get_viz(\n        datasource_type=datasource_type,\n        datasource_id=datasource_id,\n        form_data=form_data,\n        force=False,\n    )\n    security_manager.assert_datasource_permission(viz_obj.datasource)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if user can access a cached response from slice_json.", "response": "def check_slice_perms(self, slice_id):\n    \"\"\"\n    Check if user can access a cached response from slice_json.\n\n    This function takes `self` since it must have the same signature as the\n    the decorated method.\n\n    \"\"\"\n    form_data, slc = get_form_data(slice_id, use_slice_data=True)\n    datasource_type = slc.datasource.type\n    datasource_id = slc.datasource.id\n    viz_obj = get_viz(\n        datasource_type=datasource_type,\n        datasource_id=datasource_id,\n        form_data=form_data,\n        force=False,\n    )\n    security_manager.assert_datasource_permission(viz_obj.datasource)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef apply_caching(response):\n    for k, v in config.get('HTTP_HEADERS').items():\n        response.headers[k] = v\n    return response", "response": "Applies the configuration s http headers to all responses"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the role with the give datasource permissions.", "response": "def override_role_permissions(self):\n        \"\"\"Updates the role with the give datasource permissions.\n\n          Permissions not in the request will be revoked. This endpoint should\n          be available to admins only. Expects JSON in the format:\n           {\n            'role_name': '{role_name}',\n            'database': [{\n                'datasource_type': '{table|druid}',\n                'name': '{database_name}',\n                'schema': [{\n                    'name': '{schema_name}',\n                    'datasources': ['{datasource name}, {datasource name}']\n                }]\n            }]\n        }\n        \"\"\"\n        data = request.get_json(force=True)\n        role_name = data['role_name']\n        databases = data['database']\n\n        db_ds_names = set()\n        for dbs in databases:\n            for schema in dbs['schema']:\n                for ds_name in schema['datasources']:\n                    fullname = utils.get_datasource_full_name(\n                        dbs['name'], ds_name, schema=schema['name'])\n                    db_ds_names.add(fullname)\n\n        existing_datasources = ConnectorRegistry.get_all_datasources(db.session)\n        datasources = [\n            d for d in existing_datasources if d.full_name in db_ds_names]\n        role = security_manager.find_role(role_name)\n        # remove all permissions\n        role.permissions = []\n        # grant permissions to the list of datasources\n        granted_perms = []\n        for datasource in datasources:\n            view_menu_perm = security_manager.find_permission_view_menu(\n                view_menu_name=datasource.perm,\n                permission_name='datasource_access')\n            # prevent creating empty permissions\n            if view_menu_perm and view_menu_perm.view_menu:\n                role.permissions.append(view_menu_perm)\n                granted_perms.append(view_menu_perm.view_menu.name)\n        db.session.commit()\n        return self.json_response({\n            'granted': granted_perms,\n            'requested': list(db_ds_names),\n        }, status=201)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef import_dashboards(self):\n        f = request.files.get('file')\n        if request.method == 'POST' and f:\n            dashboard_import_export.import_dashboards(db.session, f.stream)\n            return redirect('/dashboard/list/')\n        return self.render_template('superset/import_dashboards.html')", "response": "Overrides the dashboards using json instances from the file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndeprecate endpoint here for backward compatibility of urls", "response": "def explorev2(self, datasource_type, datasource_id):\n        \"\"\"Deprecated endpoint, here for backward compatibility of urls\"\"\"\n        return redirect(url_for(\n            'Superset.explore',\n            datasource_type=datasource_type,\n            datasource_id=datasource_id,\n            **request.args))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_or_overwrite_slice(\n            self, args, slc, slice_add_perm, slice_overwrite_perm, slice_download_perm,\n            datasource_id, datasource_type, datasource_name):\n        \"\"\"Save or overwrite a slice\"\"\"\n        slice_name = args.get('slice_name')\n        action = args.get('action')\n        form_data = get_form_data()[0]\n\n        if action in ('saveas'):\n            if 'slice_id' in form_data:\n                form_data.pop('slice_id')  # don't save old slice_id\n            slc = models.Slice(owners=[g.user] if g.user else [])\n\n        slc.params = json.dumps(form_data, indent=2, sort_keys=True)\n        slc.datasource_name = datasource_name\n        slc.viz_type = form_data['viz_type']\n        slc.datasource_type = datasource_type\n        slc.datasource_id = datasource_id\n        slc.slice_name = slice_name\n\n        if action in ('saveas') and slice_add_perm:\n            self.save_slice(slc)\n        elif action == 'overwrite' and slice_overwrite_perm:\n            self.overwrite_slice(slc)\n\n        # Adding slice to a dashboard if requested\n        dash = None\n        if request.args.get('add_to_dash') == 'existing':\n            dash = (\n                db.session.query(models.Dashboard)\n                .filter_by(id=int(request.args.get('save_to_dashboard_id')))\n                .one()\n            )\n\n            # check edit dashboard permissions\n            dash_overwrite_perm = check_ownership(dash, raise_if_false=False)\n            if not dash_overwrite_perm:\n                return json_error_response(\n                    _('You don\\'t have the rights to ') + _('alter this ') +\n                    _('dashboard'),\n                    status=400)\n\n            flash(\n                _('Chart [{}] was added to dashboard [{}]').format(\n                    slc.slice_name,\n                    dash.dashboard_title),\n                'info')\n        elif request.args.get('add_to_dash') == 'new':\n            # check create dashboard permissions\n            dash_add_perm = security_manager.can_access('can_add', 'DashboardModelView')\n            if not dash_add_perm:\n                return json_error_response(\n                    _('You don\\'t have the rights to ') + _('create a ') + _('dashboard'),\n                    status=400)\n\n            dash = models.Dashboard(\n                dashboard_title=request.args.get('new_dashboard_name'),\n                owners=[g.user] if g.user else [])\n            flash(\n                _('Dashboard [{}] just got created and chart [{}] was added '\n                  'to it').format(\n                    dash.dashboard_title,\n                    slc.slice_name),\n                'info')\n\n        if dash and slc not in dash.slices:\n            dash.slices.append(slc)\n            db.session.commit()\n\n        response = {\n            'can_add': slice_add_perm,\n            'can_download': slice_download_perm,\n            'can_overwrite': is_owner(slc, g.user),\n            'form_data': slc.form_data,\n            'slice': slc.data,\n            'dashboard_id': dash.id if dash else None,\n        }\n\n        if request.args.get('goto_dash') == 'true':\n            response.update({'dashboard': dash.url})\n\n        return json_success(json.dumps(response))", "response": "Save or overwrite a slice"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tables(self, db_id, schema, substr, force_refresh='false'):\n        db_id = int(db_id)\n        force_refresh = force_refresh.lower() == 'true'\n        schema = utils.js_string_to_python(schema)\n        substr = utils.js_string_to_python(substr)\n        database = db.session.query(models.Database).filter_by(id=db_id).one()\n\n        if schema:\n            table_names = database.all_table_names_in_schema(\n                schema=schema, force=force_refresh,\n                cache=database.table_cache_enabled,\n                cache_timeout=database.table_cache_timeout)\n            view_names = database.all_view_names_in_schema(\n                schema=schema, force=force_refresh,\n                cache=database.table_cache_enabled,\n                cache_timeout=database.table_cache_timeout)\n        else:\n            table_names = database.all_table_names_in_database(\n                cache=True, force=False, cache_timeout=24 * 60 * 60)\n            view_names = database.all_view_names_in_database(\n                cache=True, force=False, cache_timeout=24 * 60 * 60)\n        table_names = security_manager.accessible_by_user(database, table_names, schema)\n        view_names = security_manager.accessible_by_user(database, view_names, schema)\n\n        if substr:\n            table_names = [tn for tn in table_names if substr in tn]\n            view_names = [vn for vn in view_names if substr in vn]\n\n        if not schema and database.default_schemas:\n            def get_schema(tbl_or_view_name):\n                return tbl_or_view_name.split('.')[0] if '.' in tbl_or_view_name else None\n\n            user_schema = g.user.email.split('@')[0]\n            valid_schemas = set(database.default_schemas + [user_schema])\n\n            table_names = [tn for tn in table_names if get_schema(tn) in valid_schemas]\n            view_names = [vn for vn in view_names if get_schema(vn) in valid_schemas]\n\n        max_items = config.get('MAX_TABLE_NAMES') or len(table_names)\n        total_items = len(table_names) + len(view_names)\n        max_tables = len(table_names)\n        max_views = len(view_names)\n        if total_items and substr:\n            max_tables = max_items * len(table_names) // total_items\n            max_views = max_items * len(view_names) // total_items\n\n        table_options = [{'value': tn, 'label': tn}\n                         for tn in table_names[:max_tables]]\n        table_options.extend([{'value': vn, 'label': '[view] {}'.format(vn)}\n                              for vn in view_names[:max_views]])\n        payload = {\n            'tableLength': len(table_names) + len(view_names),\n            'options': table_options,\n        }\n        return json_success(json.dumps(payload))", "response": "Endpoint to fetch the list of tables for given database and schema"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copy_dash(self, dashboard_id):\n        session = db.session()\n        data = json.loads(request.form.get('data'))\n        dash = models.Dashboard()\n        original_dash = (\n            session\n            .query(models.Dashboard)\n            .filter_by(id=dashboard_id).first())\n\n        dash.owners = [g.user] if g.user else []\n        dash.dashboard_title = data['dashboard_title']\n\n        if data['duplicate_slices']:\n            # Duplicating slices as well, mapping old ids to new ones\n            old_to_new_sliceids = {}\n            for slc in original_dash.slices:\n                new_slice = slc.clone()\n                new_slice.owners = [g.user] if g.user else []\n                session.add(new_slice)\n                session.flush()\n                new_slice.dashboards.append(dash)\n                old_to_new_sliceids['{}'.format(slc.id)] = \\\n                    '{}'.format(new_slice.id)\n\n            # update chartId of layout entities\n            # in v2_dash positions json data, chartId should be integer,\n            # while in older version slice_id is string type\n            for value in data['positions'].values():\n                if (\n                    isinstance(value, dict) and value.get('meta') and\n                    value.get('meta').get('chartId')\n                ):\n                    old_id = '{}'.format(value.get('meta').get('chartId'))\n                    new_id = int(old_to_new_sliceids[old_id])\n                    value['meta']['chartId'] = new_id\n        else:\n            dash.slices = original_dash.slices\n        dash.params = original_dash.params\n\n        self._set_dash_metadata(dash, data)\n        session.add(dash)\n        session.commit()\n        dash_json = json.dumps(dash.data)\n        session.close()\n        return json_success(dash_json)", "response": "Copy dashboard to new dashboard"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves a dashboard s metadata", "response": "def save_dash(self, dashboard_id):\n        \"\"\"Save a dashboard's metadata\"\"\"\n        session = db.session()\n        dash = (session\n                .query(models.Dashboard)\n                .filter_by(id=dashboard_id).first())\n        check_ownership(dash, raise_if_false=True)\n        data = json.loads(request.form.get('data'))\n        self._set_dash_metadata(dash, data)\n        session.merge(dash)\n        session.commit()\n        session.close()\n        return json_success(json.dumps({'status': 'SUCCESS'}))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_slices(self, dashboard_id):\n        data = json.loads(request.form.get('data'))\n        session = db.session()\n        Slice = models.Slice  # noqa\n        dash = (\n            session.query(models.Dashboard).filter_by(id=dashboard_id).first())\n        check_ownership(dash, raise_if_false=True)\n        new_slices = session.query(Slice).filter(\n            Slice.id.in_(data['slice_ids']))\n        dash.slices += new_slices\n        session.merge(dash)\n        session.commit()\n        session.close()\n        return 'SLICES ADDED'", "response": "Add and save slices to a dashboard"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of recent activity for a given user", "response": "def recent_activity(self, user_id):\n        \"\"\"Recent activity (actions) for a given user\"\"\"\n        M = models  # noqa\n\n        if request.args.get('limit'):\n            limit = int(request.args.get('limit'))\n        else:\n            limit = 1000\n\n        qry = (\n            db.session.query(M.Log, M.Dashboard, M.Slice)\n            .outerjoin(\n                M.Dashboard,\n                M.Dashboard.id == M.Log.dashboard_id,\n            )\n            .outerjoin(\n                M.Slice,\n                M.Slice.id == M.Log.slice_id,\n            )\n            .filter(\n                sqla.and_(\n                    ~M.Log.action.in_(('queries', 'shortner', 'sql_json')),\n                    M.Log.user_id == user_id,\n                ),\n            )\n            .order_by(M.Log.dttm.desc())\n            .limit(limit)\n        )\n        payload = []\n        for log in qry.all():\n            item_url = None\n            item_title = None\n            if log.Dashboard:\n                item_url = log.Dashboard.url\n                item_title = log.Dashboard.dashboard_title\n            elif log.Slice:\n                item_url = log.Slice.slice_url\n                item_title = log.Slice.slice_name\n\n            payload.append({\n                'action': log.Log.action,\n                'item_url': item_url,\n                'item_title': item_title,\n                'time': log.Log.dttm,\n            })\n        return json_success(\n            json.dumps(payload, default=utils.json_int_dttm_ser))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fave_dashboards_by_username(self, username):\n        user = security_manager.find_user(username=username)\n        return self.fave_dashboards(user.get_id())", "response": "This lets us use a user s username to pull favourite dashboards"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist of slices a user created or faved", "response": "def user_slices(self, user_id=None):\n        \"\"\"List of slices a user created, or faved\"\"\"\n        if not user_id:\n            user_id = g.user.id\n        Slice = models.Slice  # noqa\n        FavStar = models.FavStar # noqa\n        qry = (\n            db.session.query(Slice,\n                             FavStar.dttm).join(\n                models.FavStar,\n                sqla.and_(\n                    models.FavStar.user_id == int(user_id),\n                    models.FavStar.class_name == 'slice',\n                    models.Slice.id == models.FavStar.obj_id,\n                ),\n                isouter=True).filter(\n                sqla.or_(\n                    Slice.created_by_fk == user_id,\n                    Slice.changed_by_fk == user_id,\n                    FavStar.user_id == user_id,\n                ),\n            )\n            .order_by(Slice.slice_name.asc())\n        )\n        payload = [{\n            'id': o.Slice.id,\n            'title': o.Slice.slice_name,\n            'url': o.Slice.slice_url,\n            'data': o.Slice.form_data,\n            'dttm': o.dttm if o.dttm else o.Slice.changed_on,\n            'viz_type': o.Slice.viz_type,\n        } for o in qry.all()]\n        return json_success(\n            json.dumps(payload, default=utils.json_int_dttm_ser))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist of slices created by this user", "response": "def created_slices(self, user_id=None):\n        \"\"\"List of slices created by this user\"\"\"\n        if not user_id:\n            user_id = g.user.id\n        Slice = models.Slice  # noqa\n        qry = (\n            db.session.query(Slice)\n            .filter(\n                sqla.or_(\n                    Slice.created_by_fk == user_id,\n                    Slice.changed_by_fk == user_id,\n                ),\n            )\n            .order_by(Slice.changed_on.desc())\n        )\n        payload = [{\n            'id': o.id,\n            'title': o.slice_name,\n            'url': o.slice_url,\n            'dttm': o.changed_on,\n            'viz_type': o.viz_type,\n        } for o in qry.all()]\n        return json_success(\n            json.dumps(payload, default=utils.json_int_dttm_ser))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwarm up the cache for the slice or table.", "response": "def warm_up_cache(self):\n        \"\"\"Warms up the cache for the slice or table.\n\n        Note for slices a force refresh occurs.\n        \"\"\"\n        slices = None\n        session = db.session()\n        slice_id = request.args.get('slice_id')\n        table_name = request.args.get('table_name')\n        db_name = request.args.get('db_name')\n\n        if not slice_id and not (table_name and db_name):\n            return json_error_response(__(\n                'Malformed request. slice_id or table_name and db_name '\n                'arguments are expected'), status=400)\n        if slice_id:\n            slices = session.query(models.Slice).filter_by(id=slice_id).all()\n            if not slices:\n                return json_error_response(__(\n                    'Chart %(id)s not found', id=slice_id), status=404)\n        elif table_name and db_name:\n            SqlaTable = ConnectorRegistry.sources['table']\n            table = (\n                session.query(SqlaTable)\n                .join(models.Database)\n                .filter(\n                    models.Database.database_name == db_name or\n                    SqlaTable.table_name == table_name)\n            ).first()\n            if not table:\n                return json_error_response(__(\n                    \"Table %(t)s wasn't found in the database %(d)s\",\n                    t=table_name, s=db_name), status=404)\n            slices = session.query(models.Slice).filter_by(\n                datasource_id=table.id,\n                datasource_type=table.type).all()\n\n        for slc in slices:\n            try:\n                form_data = get_form_data(slc.id, use_slice_data=True)[0]\n                obj = get_viz(\n                    datasource_type=slc.datasource.type,\n                    datasource_id=slc.datasource.id,\n                    form_data=form_data,\n                    force=True,\n                )\n                obj.get_json()\n            except Exception as e:\n                return json_error_response(utils.error_msg_from_exception(e))\n        return json_success(json.dumps(\n            [{'slice_id': slc.id, 'slice_name': slc.slice_name}\n             for slc in slices]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntoggle favorite stars on Slices and Dashboard", "response": "def favstar(self, class_name, obj_id, action):\n        \"\"\"Toggle favorite stars on Slices and Dashboard\"\"\"\n        session = db.session()\n        FavStar = models.FavStar  # noqa\n        count = 0\n        favs = session.query(FavStar).filter_by(\n            class_name=class_name, obj_id=obj_id,\n            user_id=g.user.get_id()).all()\n        if action == 'select':\n            if not favs:\n                session.add(\n                    FavStar(\n                        class_name=class_name,\n                        obj_id=obj_id,\n                        user_id=g.user.get_id(),\n                        dttm=datetime.now(),\n                    ),\n                )\n            count = 1\n        elif action == 'unselect':\n            for fav in favs:\n                session.delete(fav)\n        else:\n            count = len(favs)\n        session.commit()\n        return json_success(json.dumps({'count': count}))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sync_druid_source(self):\n        payload = request.get_json(force=True)\n        druid_config = payload['config']\n        user_name = payload['user']\n        cluster_name = payload['cluster']\n\n        user = security_manager.find_user(username=user_name)\n        DruidDatasource = ConnectorRegistry.sources['druid']\n        DruidCluster = DruidDatasource.cluster_class\n        if not user:\n            err_msg = __(\"Can't find User '%(name)s', please ask your admin \"\n                         'to create one.', name=user_name)\n            logging.error(err_msg)\n            return json_error_response(err_msg)\n        cluster = db.session.query(DruidCluster).filter_by(\n            cluster_name=cluster_name).first()\n        if not cluster:\n            err_msg = __(\"Can't find DruidCluster with cluster_name = \"\n                         \"'%(name)s'\", name=cluster_name)\n            logging.error(err_msg)\n            return json_error_response(err_msg)\n        try:\n            DruidDatasource.sync_to_db_from_config(\n                druid_config, user, cluster)\n        except Exception as e:\n            logging.exception(utils.error_msg_from_exception(e))\n            return json_error_response(utils.error_msg_from_exception(e))\n        return Response(status=201)", "response": "Syncs the druid datasource in main db with the provided config."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cache_key_exist(self, key):\n        key_exist = True if cache.get(key) else False\n        status = 200 if key_exist else 404\n        return json_success(json.dumps({'key_exist': key_exist}),\n                            status=status)", "response": "Returns if a key from cache exist"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef results(self, key):\n        if not results_backend:\n            return json_error_response(\"Results backend isn't configured\")\n\n        read_from_results_backend_start = now_as_float()\n        blob = results_backend.get(key)\n        stats_logger.timing(\n            'sqllab.query.results_backend_read',\n            now_as_float() - read_from_results_backend_start,\n        )\n        if not blob:\n            return json_error_response(\n                'Data could not be retrieved. '\n                'You may want to re-run the query.',\n                status=410,\n            )\n\n        query = db.session.query(Query).filter_by(results_key=key).one()\n        rejected_tables = security_manager.rejected_datasources(\n            query.sql, query.database, query.schema)\n        if rejected_tables:\n            return json_error_response(security_manager.get_table_access_error_msg(\n                '{}'.format(rejected_tables)), status=403)\n\n        payload = utils.zlib_decompress_to_string(blob)\n        display_limit = app.config.get('DEFAULT_SQLLAB_LIMIT', None)\n        if display_limit:\n            payload_json = json.loads(payload)\n            payload_json['data'] = payload_json['data'][:display_limit]\n        return json_success(\n            json.dumps(\n                payload_json,\n                default=utils.json_iso_dttm_ser,\n                ignore_nan=True,\n            ),\n        )", "response": "Serves a key off of the results backend"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sql_json(self):\n        async_ = request.form.get('runAsync') == 'true'\n        sql = request.form.get('sql')\n        database_id = request.form.get('database_id')\n        schema = request.form.get('schema') or None\n        template_params = json.loads(\n            request.form.get('templateParams') or '{}')\n        limit = int(request.form.get('queryLimit', 0))\n        if limit < 0:\n            logging.warning(\n                'Invalid limit of {} specified. Defaulting to max limit.'.format(limit))\n            limit = 0\n        limit = limit or app.config.get('SQL_MAX_ROW')\n\n        session = db.session()\n        mydb = session.query(models.Database).filter_by(id=database_id).first()\n\n        if not mydb:\n            json_error_response(\n                'Database with id {} is missing.'.format(database_id))\n\n        rejected_tables = security_manager.rejected_datasources(sql, mydb, schema)\n        if rejected_tables:\n            return json_error_response(\n                security_manager.get_table_access_error_msg(rejected_tables),\n                link=security_manager.get_table_access_link(rejected_tables),\n                status=403)\n        session.commit()\n\n        select_as_cta = request.form.get('select_as_cta') == 'true'\n        tmp_table_name = request.form.get('tmp_table_name')\n        if select_as_cta and mydb.force_ctas_schema:\n            tmp_table_name = '{}.{}'.format(\n                mydb.force_ctas_schema,\n                tmp_table_name,\n            )\n\n        client_id = request.form.get('client_id') or utils.shortid()[:10]\n        query = Query(\n            database_id=int(database_id),\n            sql=sql,\n            schema=schema,\n            select_as_cta=select_as_cta,\n            start_time=now_as_float(),\n            tab_name=request.form.get('tab'),\n            status=QueryStatus.PENDING if async_ else QueryStatus.RUNNING,\n            sql_editor_id=request.form.get('sql_editor_id'),\n            tmp_table_name=tmp_table_name,\n            user_id=g.user.get_id() if g.user else None,\n            client_id=client_id,\n        )\n        session.add(query)\n        session.flush()\n        query_id = query.id\n        session.commit()  # shouldn't be necessary\n        if not query_id:\n            raise Exception(_('Query record was not created as expected.'))\n        logging.info('Triggering query_id: {}'.format(query_id))\n\n        try:\n            template_processor = get_template_processor(\n                database=query.database, query=query)\n            rendered_query = template_processor.process_template(\n                query.sql,\n                **template_params)\n        except Exception as e:\n            return json_error_response(\n                'Template rendering failed: {}'.format(utils.error_msg_from_exception(e)))\n\n        # set LIMIT after template processing\n        limits = [mydb.db_engine_spec.get_limit_from_sql(rendered_query), limit]\n        query.limit = min(lim for lim in limits if lim is not None)\n\n        # Async request.\n        if async_:\n            logging.info('Running query on a Celery worker')\n            # Ignore the celery future object and the request may time out.\n            try:\n                sql_lab.get_sql_results.delay(\n                    query_id,\n                    rendered_query,\n                    return_results=False,\n                    store_results=not query.select_as_cta,\n                    user_name=g.user.username if g.user else None,\n                    start_time=now_as_float())\n            except Exception as e:\n                logging.exception(e)\n                msg = _(\n                    'Failed to start remote query on a worker. '\n                    'Tell your administrator to verify the availability of '\n                    'the message queue.')\n                query.status = QueryStatus.FAILED\n                query.error_message = msg\n                session.commit()\n                return json_error_response('{}'.format(msg))\n\n            resp = json_success(json.dumps(\n                {'query': query.to_dict()}, default=utils.json_int_dttm_ser,\n                ignore_nan=True), status=202)\n            session.commit()\n            return resp\n\n        # Sync request.\n        try:\n            timeout = config.get('SQLLAB_TIMEOUT')\n            timeout_msg = (\n                f'The query exceeded the {timeout} seconds timeout.')\n            with utils.timeout(seconds=timeout,\n                               error_message=timeout_msg):\n                # pylint: disable=no-value-for-parameter\n                data = sql_lab.get_sql_results(\n                    query_id,\n                    rendered_query,\n                    return_results=True,\n                    user_name=g.user.username if g.user else None)\n            payload = json.dumps(\n                data,\n                default=utils.pessimistic_json_iso_dttm_ser,\n                ignore_nan=True,\n                encoding=None,\n            )\n        except Exception as e:\n            logging.exception(e)\n            return json_error_response('{}'.format(e))\n        if data.get('status') == QueryStatus.FAILED:\n            return json_error_response(payload=data)\n        return json_success(payload)", "response": "Runs arbitrary sql and returns and json"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads the query results as csv.", "response": "def csv(self, client_id):\n        \"\"\"Download the query results as csv.\"\"\"\n        logging.info('Exporting CSV file [{}]'.format(client_id))\n        query = (\n            db.session.query(Query)\n            .filter_by(client_id=client_id)\n            .one()\n        )\n\n        rejected_tables = security_manager.rejected_datasources(\n            query.sql, query.database, query.schema)\n        if rejected_tables:\n            flash(\n                security_manager.get_table_access_error_msg('{}'.format(rejected_tables)))\n            return redirect('/')\n        blob = None\n        if results_backend and query.results_key:\n            logging.info(\n                'Fetching CSV from results backend '\n                '[{}]'.format(query.results_key))\n            blob = results_backend.get(query.results_key)\n        if blob:\n            logging.info('Decompressing')\n            json_payload = utils.zlib_decompress_to_string(blob)\n            obj = json.loads(json_payload)\n            columns = [c['name'] for c in obj['columns']]\n            df = pd.DataFrame.from_records(obj['data'], columns=columns)\n            logging.info('Using pandas to convert to CSV')\n            csv = df.to_csv(index=False, **config.get('CSV_EXPORT'))\n        else:\n            logging.info('Running a query to turn into CSV')\n            sql = query.select_sql or query.executed_sql\n            df = query.database.get_df(sql, query.schema)\n            # TODO(bkyryliuk): add compression=gzip for big files.\n            csv = df.to_csv(index=False, **config.get('CSV_EXPORT'))\n        response = Response(csv, mimetype='text/csv')\n        response.headers['Content-Disposition'] = f'attachment; filename={query.name}.csv'\n        logging.info('Ready to return response')\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the updated queries.", "response": "def queries(self, last_updated_ms):\n        \"\"\"Get the updated queries.\"\"\"\n        stats_logger.incr('queries')\n        if not g.user.get_id():\n            return json_error_response(\n                'Please login to access the queries.', status=403)\n\n        # Unix time, milliseconds.\n        last_updated_ms_int = int(float(last_updated_ms)) if last_updated_ms else 0\n\n        # UTC date time, same that is stored in the DB.\n        last_updated_dt = utils.EPOCH + timedelta(seconds=last_updated_ms_int / 1000)\n\n        sql_queries = (\n            db.session.query(Query)\n            .filter(\n                Query.user_id == g.user.get_id(),\n                Query.changed_on >= last_updated_dt,\n            )\n            .all()\n        )\n        dict_queries = {q.client_id: q.to_dict() for q in sql_queries}\n\n        now = int(round(time.time() * 1000))\n\n        unfinished_states = [\n            QueryStatus.PENDING,\n            QueryStatus.RUNNING,\n        ]\n\n        queries_to_timeout = [\n            client_id for client_id, query_dict in dict_queries.items()\n            if (\n                query_dict['state'] in unfinished_states and (\n                    now - query_dict['startDttm'] >\n                    config.get('SQLLAB_ASYNC_TIME_LIMIT_SEC') * 1000\n                )\n            )\n        ]\n\n        if queries_to_timeout:\n            update(Query).where(\n                and_(\n                    Query.user_id == g.user.get_id(),\n                    Query.client_id in queries_to_timeout,\n                ),\n            ).values(state=QueryStatus.TIMED_OUT)\n\n            for client_id in queries_to_timeout:\n                dict_queries[client_id]['status'] = QueryStatus.TIMED_OUT\n\n        return json_success(\n            json.dumps(dict_queries, default=utils.json_int_dttm_ser))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsearch for previously run sqllab queries. Used for Sqllab Query Search page / superset / sqllab#search.", "response": "def search_queries(self) -> Response:\n        \"\"\"\n        Search for previously run sqllab queries. Used for Sqllab Query Search\n        page /superset/sqllab#search.\n\n        Custom permission can_only_search_queries_owned restricts queries\n        to only queries run by current user.\n\n        :returns: Response with list of sql query dicts\n        \"\"\"\n        query = db.session.query(Query)\n        if security_manager.can_only_access_owned_queries():\n            search_user_id = g.user.get_user_id()\n        else:\n            search_user_id = request.args.get('user_id')\n        database_id = request.args.get('database_id')\n        search_text = request.args.get('search_text')\n        status = request.args.get('status')\n        # From and To time stamp should be Epoch timestamp in seconds\n        from_time = request.args.get('from')\n        to_time = request.args.get('to')\n\n        if search_user_id:\n            # Filter on user_id\n            query = query.filter(Query.user_id == search_user_id)\n\n        if database_id:\n            # Filter on db Id\n            query = query.filter(Query.database_id == database_id)\n\n        if status:\n            # Filter on status\n            query = query.filter(Query.status == status)\n\n        if search_text:\n            # Filter on search text\n            query = query \\\n                .filter(Query.sql.like('%{}%'.format(search_text)))\n\n        if from_time:\n            query = query.filter(Query.start_time > int(from_time))\n\n        if to_time:\n            query = query.filter(Query.start_time < int(to_time))\n\n        query_limit = config.get('QUERY_SEARCH_LIMIT', 1000)\n        sql_queries = (\n            query.order_by(Query.start_time.asc())\n            .limit(query_limit)\n            .all()\n        )\n\n        dict_queries = [q.to_dict() for q in sql_queries]\n\n        return Response(\n            json.dumps(dict_queries, default=utils.json_int_dttm_ser),\n            status=200,\n            mimetype='application/json')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprovide a transactional scope around a series of operations.", "response": "def stats_timing(stats_key, stats_logger):\n    \"\"\"Provide a transactional scope around a series of operations.\"\"\"\n    start_ts = now_as_float()\n    try:\n        yield start_ts\n    except Exception as e:\n        raise e\n    finally:\n        stats_logger.timing(stats_key, now_as_float() - start_ts)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply_limit_to_sql(cls, sql, limit, database):\n        if cls.limit_method == LimitMethod.WRAP_SQL:\n            sql = sql.strip('\\t\\n ;')\n            qry = (\n                select('*')\n                .select_from(\n                    TextAsFrom(text(sql), ['*']).alias('inner_qry'),\n                )\n                .limit(limit)\n            )\n            return database.compile_sqla_query(qry)\n        elif LimitMethod.FORCE_LIMIT:\n            parsed_query = sql_parse.ParsedQuery(sql)\n            sql = parsed_query.get_query_with_new_limit(limit)\n        return sql", "response": "Alters the SQL statement to apply a LIMIT clause"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef modify_url_for_impersonation(cls, url, impersonate_user, username):\n        if impersonate_user is not None and username is not None:\n            url.username = username", "response": "Modify the SQL Alchemy URL object with the user to impersonate if applicable."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntruncates the label to the maximum length supported by the engine.", "response": "def truncate_label(cls, label):\n        \"\"\"\n        In the case that a label exceeds the max length supported by the engine,\n        this method is used to construct a deterministic and unique label based on\n        an md5 hash.\n        \"\"\"\n        label = hashlib.md5(label.encode('utf-8')).hexdigest()\n        # truncate hash if it exceeds max length\n        if cls.max_column_name_length and len(label) > cls.max_column_name_length:\n            label = label[:cls.max_column_name_length]\n        return label"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_table_names(cls, inspector, schema):\n        tables = inspector.get_table_names(schema)\n        tables.extend(inspector.get_foreign_table_names(schema))\n        return sorted(tables)", "response": "Get the names of tables that are used in the table table."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_timestamp_column(expression, column_name):\n        if expression:\n            return expression\n        elif column_name.lower() != column_name:\n            return f'\"{column_name}\"'\n        return column_name", "response": "Return the column name for the timestamp column."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extract_error_message(cls, e):\n        message = str(e)\n        try:\n            if isinstance(e.args, tuple) and len(e.args) > 1:\n                message = e.args[1]\n        except Exception:\n            pass\n        return message", "response": "Extract error message for queries"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of tables [ schema1. table1 schema2. table2... ]", "response": "def fetch_result_sets(cls, db, datasource_type):\n        \"\"\"Returns a list of tables [schema1.table1, schema2.table2, ...]\n\n        Datasource_type can be 'table' or 'view'.\n        Empty schema corresponds to the list of full names of the all\n        tables or views: <schema>.<result_set_name>.\n        \"\"\"\n        result_set_df = db.get_df(\n            \"\"\"SELECT table_schema, table_name FROM INFORMATION_SCHEMA.{}S\n               ORDER BY concat(table_schema, '.', table_name)\"\"\".format(\n                datasource_type.upper(),\n            ),\n            None)\n        result_sets = []\n        for unused, row in result_set_df.iterrows():\n            result_sets.append('{}.{}'.format(\n                row['table_schema'], row['table_name']))\n        return result_sets"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_cursor(cls, cursor, query, session):\n        logging.info('Polling the cursor for progress')\n        polled = cursor.poll()\n        # poll returns dict -- JSON status information or ``None``\n        # if the query is done\n        # https://github.com/dropbox/PyHive/blob/\n        # b34bdbf51378b3979eaf5eca9e956f06ddc36ca0/pyhive/presto.py#L178\n        while polled:\n            # Update the object and wait for the kill signal.\n            stats = polled.get('stats', {})\n\n            query = session.query(type(query)).filter_by(id=query.id).one()\n            if query.status in [QueryStatus.STOPPED, QueryStatus.TIMED_OUT]:\n                cursor.cancel()\n                break\n\n            if stats:\n                state = stats.get('state')\n\n                # if already finished, then stop polling\n                if state == 'FINISHED':\n                    break\n\n                completed_splits = float(stats.get('completedSplits'))\n                total_splits = float(stats.get('totalSplits'))\n                if total_splits and completed_splits:\n                    progress = 100 * (completed_splits / total_splits)\n                    logging.info(\n                        'Query progress: {} / {} '\n                        'splits'.format(completed_splits, total_splits))\n                    if progress > query.progress:\n                        query.progress = progress\n                    session.commit()\n            time.sleep(1)\n            logging.info('Polling the cursor for progress')\n            polled = cursor.poll()", "response": "Handles the cursor for the object and updates the progress information"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a query that returns a list of partitions from the specified table.", "response": "def _partition_query(\n            cls, table_name, limit=0, order_by=None, filters=None):\n        \"\"\"Returns a partition query\n\n        :param table_name: the name of the table to get partitions from\n        :type table_name: str\n        :param limit: the number of partitions to be returned\n        :type limit: int\n        :param order_by: a list of tuples of field name and a boolean\n            that determines if that field should be sorted in descending\n            order\n        :type order_by: list of (str, bool) tuples\n        :param filters: dict of field name and filter value combinations\n        \"\"\"\n        limit_clause = 'LIMIT {}'.format(limit) if limit else ''\n        order_by_clause = ''\n        if order_by:\n            l = []  # noqa: E741\n            for field, desc in order_by:\n                l.append(field + ' DESC' if desc else '')\n            order_by_clause = 'ORDER BY ' + ', '.join(l)\n\n        where_clause = ''\n        if filters:\n            l = []  # noqa: E741\n            for field, value in filters.items():\n                l.append(f\"{field} = '{value}'\")\n            where_clause = 'WHERE ' + ' AND '.join(l)\n\n        sql = textwrap.dedent(f\"\"\"\\\n            SELECT * FROM \"{table_name}$partitions\"\n\n            {where_clause}\n            {order_by_clause}\n            {limit_clause}\n        \"\"\")\n        return sql"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nuploads a csv file and creates a superset datasource in Hive.", "response": "def create_table_from_csv(form, table):\n        \"\"\"Uploads a csv file and creates a superset datasource in Hive.\"\"\"\n        def convert_to_hive_type(col_type):\n            \"\"\"maps tableschema's types to hive types\"\"\"\n            tableschema_to_hive_types = {\n                'boolean': 'BOOLEAN',\n                'integer': 'INT',\n                'number': 'DOUBLE',\n                'string': 'STRING',\n            }\n            return tableschema_to_hive_types.get(col_type, 'STRING')\n\n        bucket_path = config['CSV_TO_HIVE_UPLOAD_S3_BUCKET']\n\n        if not bucket_path:\n            logging.info('No upload bucket specified')\n            raise Exception(\n                'No upload bucket specified. You can specify one in the config file.')\n\n        table_name = form.name.data\n        schema_name = form.schema.data\n\n        if config.get('UPLOADED_CSV_HIVE_NAMESPACE'):\n            if '.' in table_name or schema_name:\n                raise Exception(\n                    \"You can't specify a namespace. \"\n                    'All tables will be uploaded to the `{}` namespace'.format(\n                        config.get('HIVE_NAMESPACE')))\n            full_table_name = '{}.{}'.format(\n                config.get('UPLOADED_CSV_HIVE_NAMESPACE'), table_name)\n        else:\n            if '.' in table_name and schema_name:\n                raise Exception(\n                    \"You can't specify a namespace both in the name of the table \"\n                    'and in the schema field. Please remove one')\n\n            full_table_name = '{}.{}'.format(\n                schema_name, table_name) if schema_name else table_name\n\n        filename = form.csv_file.data.filename\n\n        upload_prefix = config['CSV_TO_HIVE_UPLOAD_DIRECTORY']\n        upload_path = config['UPLOAD_FOLDER'] + \\\n            secure_filename(filename)\n\n        # Optional dependency\n        from tableschema import Table  # pylint: disable=import-error\n        hive_table_schema = Table(upload_path).infer()\n        column_name_and_type = []\n        for column_info in hive_table_schema['fields']:\n            column_name_and_type.append(\n                '`{}` {}'.format(\n                    column_info['name'],\n                    convert_to_hive_type(column_info['type'])))\n        schema_definition = ', '.join(column_name_and_type)\n\n        # Optional dependency\n        import boto3  # pylint: disable=import-error\n\n        s3 = boto3.client('s3')\n        location = os.path.join('s3a://', bucket_path, upload_prefix, table_name)\n        s3.upload_file(\n            upload_path, bucket_path,\n            os.path.join(upload_prefix, table_name, filename))\n        sql = f\"\"\"CREATE TABLE {full_table_name} ( {schema_definition} )\n            ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' STORED AS\n            TEXTFILE LOCATION '{location}'\n            tblproperties ('skip.header.line.count'='1')\"\"\"\n        logging.info(form.con.data)\n        engine = create_engine(form.con.data.sqlalchemy_uri_decrypted)\n        engine.execute(sql)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle_cursor(cls, cursor, query, session):\n        from pyhive import hive  # pylint: disable=no-name-in-module\n        unfinished_states = (\n            hive.ttypes.TOperationState.INITIALIZED_STATE,\n            hive.ttypes.TOperationState.RUNNING_STATE,\n        )\n        polled = cursor.poll()\n        last_log_line = 0\n        tracking_url = None\n        job_id = None\n        while polled.operationState in unfinished_states:\n            query = session.query(type(query)).filter_by(id=query.id).one()\n            if query.status == QueryStatus.STOPPED:\n                cursor.cancel()\n                break\n\n            log = cursor.fetch_logs() or ''\n            if log:\n                log_lines = log.splitlines()\n                progress = cls.progress(log_lines)\n                logging.info('Progress total: {}'.format(progress))\n                needs_commit = False\n                if progress > query.progress:\n                    query.progress = progress\n                    needs_commit = True\n                if not tracking_url:\n                    tracking_url = cls.get_tracking_url(log_lines)\n                    if tracking_url:\n                        job_id = tracking_url.split('/')[-2]\n                        logging.info(\n                            'Found the tracking url: {}'.format(tracking_url))\n                        tracking_url = tracking_url_trans(tracking_url)\n                        logging.info(\n                            'Transformation applied: {}'.format(tracking_url))\n                        query.tracking_url = tracking_url\n                        logging.info('Job id: {}'.format(job_id))\n                        needs_commit = True\n                if job_id and len(log_lines) > last_log_line:\n                    # Wait for job id before logging things out\n                    # this allows for prefixing all log lines and becoming\n                    # searchable in something like Kibana\n                    for l in log_lines[last_log_line:]:\n                        logging.info('[{}] {}'.format(job_id, l))\n                    last_log_line = len(log_lines)\n                if needs_commit:\n                    session.commit()\n            time.sleep(hive_poll_interval)\n            polled = cursor.poll()", "response": "Handles the cursor and updates the progress information"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_configuration_for_impersonation(cls, uri, impersonate_user, username):\n        configuration = {}\n        url = make_url(uri)\n        backend_name = url.get_backend_name()\n\n        # Must be Hive connection, enable impersonation, and set param auth=LDAP|KERBEROS\n        if (backend_name == 'hive' and 'auth' in url.query.keys() and\n                impersonate_user is True and username is not None):\n            configuration['hive.server2.proxy.user'] = username\n        return configuration", "response": "Returns a configuration dictionary that can be merged with other configs that can be set for impersonation"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_fields(cls, cols):\n        return [sqla.literal_column(c.get('name')).label(c.get('name').replace('.', '__'))\n                for c in cols]", "response": "Returns a list of SQLAlchemy fields for the given table."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_multiformat_time_series():\n    data = get_example_data('multiformat_time_series.json.gz')\n    pdf = pd.read_json(data)\n\n    pdf.ds = pd.to_datetime(pdf.ds, unit='s')\n    pdf.ds2 = pd.to_datetime(pdf.ds2, unit='s')\n    pdf.to_sql(\n        'multiformat_time_series',\n        db.engine,\n        if_exists='replace',\n        chunksize=500,\n        dtype={\n            'ds': Date,\n            'ds2': DateTime,\n            'epoch_s': BigInteger,\n            'epoch_ms': BigInteger,\n            'string0': String(100),\n            'string1': String(100),\n            'string2': String(100),\n            'string3': String(100),\n        },\n        index=False)\n    print('Done loading table!')\n    print('-' * 80)\n    print('Creating table [multiformat_time_series] reference')\n    obj = db.session.query(TBL).filter_by(table_name='multiformat_time_series').first()\n    if not obj:\n        obj = TBL(table_name='multiformat_time_series')\n    obj.main_dttm_col = 'ds'\n    obj.database = utils.get_or_create_main_db()\n    dttm_and_expr_dict = {\n        'ds': [None, None],\n        'ds2': [None, None],\n        'epoch_s': ['epoch_s', None],\n        'epoch_ms': ['epoch_ms', None],\n        'string2': ['%Y%m%d-%H%M%S', None],\n        'string1': ['%Y-%m-%d^%H:%M:%S', None],\n        'string0': ['%Y-%m-%d %H:%M:%S.%f', None],\n        'string3': ['%Y/%m/%d%H:%M:%S.%f', None],\n    }\n    for col in obj.columns:\n        dttm_and_expr = dttm_and_expr_dict[col.column_name]\n        col.python_date_format = dttm_and_expr[0]\n        col.dbatabase_expr = dttm_and_expr[1]\n        col.is_dttm = True\n    db.session.merge(obj)\n    db.session.commit()\n    obj.fetch_metadata()\n    tbl = obj\n\n    print('Creating Heatmap charts')\n    for i, col in enumerate(tbl.columns):\n        slice_data = {\n            'metrics': ['count'],\n            'granularity_sqla': col.column_name,\n            'row_limit': config.get('ROW_LIMIT'),\n            'since': '2015',\n            'until': '2016',\n            'where': '',\n            'viz_type': 'cal_heatmap',\n            'domain_granularity': 'month',\n            'subdomain_granularity': 'day',\n        }\n\n        slc = Slice(\n            slice_name=f'Calendar Heatmap multiformat {i}',\n            viz_type='cal_heatmap',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(slice_data),\n        )\n        merge_slice(slc)\n    misc_dash_slices.add('Calendar Heatmap multiformat 0')", "response": "Load the multiformat_time_series data from a zip file in the repo"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef import_dashboards(session, data_stream, import_time=None):\n    current_tt = int(time.time())\n    import_time = current_tt if import_time is None else import_time\n    data = json.loads(data_stream.read(), object_hook=decode_dashboards)\n    # TODO: import DRUID datasources\n    for table in data['datasources']:\n        type(table).import_obj(table, import_time=import_time)\n    session.commit()\n    for dashboard in data['dashboards']:\n        Dashboard.import_obj(\n            dashboard, import_time=import_time)\n    session.commit()", "response": "Imports dashboards from a stream to databases"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn all dashboards metadata as a json dump", "response": "def export_dashboards(session):\n    \"\"\"Returns all dashboards metadata as a json dump\"\"\"\n    logging.info('Starting export')\n    dashboards = session.query(Dashboard)\n    dashboard_ids = []\n    for dashboard in dashboards:\n        dashboard_ids.append(dashboard.id)\n    data = Dashboard.export_dashboards(dashboard_ids)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cache_key(self, **extra):\n        cache_dict = self.to_dict()\n        cache_dict.update(extra)\n\n        for k in ['from_dttm', 'to_dttm']:\n            del cache_dict[k]\n        if self.time_range:\n            cache_dict['time_range'] = self.time_range\n        json_data = self.json_dumps(cache_dict, sort_keys=True)\n        return hashlib.md5(json_data.encode('utf-8')).hexdigest()", "response": "Returns a cache key for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handle_query_error(msg, query, session, payload=None):\n    payload = payload or {}\n    troubleshooting_link = config['TROUBLESHOOTING_LINK']\n    query.error_message = msg\n    query.status = QueryStatus.FAILED\n    query.tmp_table_name = None\n    session.commit()\n    payload.update({\n        'status': query.status,\n        'error': msg,\n    })\n    if troubleshooting_link:\n        payload['link'] = troubleshooting_link\n    return payload", "response": "Local method handling error while processing the SQL"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_query(query_id, session, retry_count=5):\n    query = None\n    attempt = 0\n    while not query and attempt < retry_count:\n        try:\n            query = session.query(Query).filter_by(id=query_id).one()\n        except Exception:\n            attempt += 1\n            logging.error(\n                'Query with id `{}` could not be retrieved'.format(query_id))\n            stats_logger.incr('error_attempting_orm_query_' + str(attempt))\n            logging.error('Sleeping for a sec before retrying...')\n            sleep(1)\n    if not query:\n        stats_logger.incr('error_failed_at_getting_orm_query')\n        raise SqlLabException('Failed at getting query')\n    return query", "response": "Attempts to get the query and retry if it cannot"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprovides a transactional scope around a series of operations.", "response": "def session_scope(nullpool):\n    \"\"\"Provide a transactional scope around a series of operations.\"\"\"\n    if nullpool:\n        engine = sqlalchemy.create_engine(\n            app.config.get('SQLALCHEMY_DATABASE_URI'), poolclass=NullPool)\n        session_class = sessionmaker()\n        session_class.configure(bind=engine)\n        session = session_class()\n    else:\n        session = db.session()\n        session.commit()  # HACK\n\n    try:\n        yield session\n        session.commit()\n    except Exception as e:\n        session.rollback()\n        logging.exception(e)\n        raise\n    finally:\n        session.close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute the sql query returns the results.", "response": "def get_sql_results(\n    ctask, query_id, rendered_query, return_results=True, store_results=False,\n        user_name=None, start_time=None):\n    \"\"\"Executes the sql query returns the results.\"\"\"\n    with session_scope(not ctask.request.called_directly) as session:\n\n        try:\n            return execute_sql_statements(\n                ctask, query_id, rendered_query, return_results, store_results, user_name,\n                session=session, start_time=start_time)\n        except Exception as e:\n            logging.exception(e)\n            stats_logger.incr('error_sqllab_unhandled')\n            query = get_query(query_id, session)\n            return handle_query_error(str(e), query, session)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute a single SQL statement and returns the result.", "response": "def execute_sql_statement(sql_statement, query, user_name, session, cursor):\n    \"\"\"Executes a single SQL statement\"\"\"\n    database = query.database\n    db_engine_spec = database.db_engine_spec\n    parsed_query = ParsedQuery(sql_statement)\n    sql = parsed_query.stripped()\n    SQL_MAX_ROWS = app.config.get('SQL_MAX_ROW')\n\n    if not parsed_query.is_readonly() and not database.allow_dml:\n        raise SqlLabSecurityException(\n            _('Only `SELECT` statements are allowed against this database'))\n    if query.select_as_cta:\n        if not parsed_query.is_select():\n            raise SqlLabException(_(\n                'Only `SELECT` statements can be used with the CREATE TABLE '\n                'feature.'))\n        if not query.tmp_table_name:\n            start_dttm = datetime.fromtimestamp(query.start_time)\n            query.tmp_table_name = 'tmp_{}_table_{}'.format(\n                query.user_id, start_dttm.strftime('%Y_%m_%d_%H_%M_%S'))\n        sql = parsed_query.as_create_table(query.tmp_table_name)\n        query.select_as_cta_used = True\n    if parsed_query.is_select():\n        if SQL_MAX_ROWS and (not query.limit or query.limit > SQL_MAX_ROWS):\n            query.limit = SQL_MAX_ROWS\n        if query.limit:\n            sql = database.apply_limit_to_sql(sql, query.limit)\n\n    # Hook to allow environment-specific mutation (usually comments) to the SQL\n    SQL_QUERY_MUTATOR = config.get('SQL_QUERY_MUTATOR')\n    if SQL_QUERY_MUTATOR:\n        sql = SQL_QUERY_MUTATOR(sql, user_name, security_manager, database)\n\n    try:\n        if log_query:\n            log_query(\n                query.database.sqlalchemy_uri,\n                query.executed_sql,\n                query.schema,\n                user_name,\n                __name__,\n                security_manager,\n            )\n        query.executed_sql = sql\n        with stats_timing('sqllab.query.time_executing_query', stats_logger):\n            logging.info('Running query: \\n{}'.format(sql))\n            db_engine_spec.execute(cursor, sql, async_=True)\n            logging.info('Handling cursor')\n            db_engine_spec.handle_cursor(cursor, query, session)\n\n        with stats_timing('sqllab.query.time_fetching_results', stats_logger):\n            logging.debug('Fetching data for query object: {}'.format(query.to_dict()))\n            data = db_engine_spec.fetch_data(cursor, query.limit)\n\n    except SoftTimeLimitExceeded as e:\n        logging.exception(e)\n        raise SqlLabTimeoutException(\n            \"SQL Lab timeout. This environment's policy is to kill queries \"\n            'after {} seconds.'.format(SQLLAB_TIMEOUT))\n    except Exception as e:\n        logging.exception(e)\n        raise SqlLabException(db_engine_spec.extract_error_message(e))\n\n    logging.debug('Fetching cursor description')\n    cursor_description = cursor.description\n    return dataframe.SupersetDataFrame(data, cursor_description, db_engine_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute_sql_statements(\n    ctask, query_id, rendered_query, return_results=True, store_results=False,\n    user_name=None, session=None, start_time=None,\n):\n    \"\"\"Executes the sql query returns the results.\"\"\"\n    if store_results and start_time:\n        # only asynchronous queries\n        stats_logger.timing(\n            'sqllab.query.time_pending', now_as_float() - start_time)\n\n    query = get_query(query_id, session)\n    payload = dict(query_id=query_id)\n    database = query.database\n    db_engine_spec = database.db_engine_spec\n    db_engine_spec.patch()\n\n    if store_results and not results_backend:\n        raise SqlLabException(\"Results backend isn't configured.\")\n\n    # Breaking down into multiple statements\n    parsed_query = ParsedQuery(rendered_query)\n    statements = parsed_query.get_statements()\n    logging.info(f'Executing {len(statements)} statement(s)')\n\n    logging.info(\"Set query to 'running'\")\n    query.status = QueryStatus.RUNNING\n    query.start_running_time = now_as_float()\n\n    engine = database.get_sqla_engine(\n        schema=query.schema,\n        nullpool=True,\n        user_name=user_name,\n        source=sources.get('sql_lab', None),\n    )\n    # Sharing a single connection and cursor across the\n    # execution of all statements (if many)\n    with closing(engine.raw_connection()) as conn:\n        with closing(conn.cursor()) as cursor:\n            statement_count = len(statements)\n            for i, statement in enumerate(statements):\n                # TODO CHECK IF STOPPED\n                msg = f'Running statement {i+1} out of {statement_count}'\n                logging.info(msg)\n                query.set_extra_json_key('progress', msg)\n                session.commit()\n                try:\n                    cdf = execute_sql_statement(\n                        statement, query, user_name, session, cursor)\n                    msg = f'Running statement {i+1} out of {statement_count}'\n                except Exception as e:\n                    msg = str(e)\n                    if statement_count > 1:\n                        msg = f'[Statement {i+1} out of {statement_count}] ' + msg\n                    payload = handle_query_error(msg, query, session, payload)\n                    return payload\n\n    # Success, updating the query entry in database\n    query.rows = cdf.size\n    query.progress = 100\n    query.set_extra_json_key('progress', None)\n    query.status = QueryStatus.SUCCESS\n    if query.select_as_cta:\n        query.select_sql = database.select_star(\n            query.tmp_table_name,\n            limit=query.limit,\n            schema=database.force_ctas_schema,\n            show_cols=False,\n            latest_partition=False)\n    query.end_time = now_as_float()\n\n    payload.update({\n        'status': query.status,\n        'data': cdf.data if cdf.data else [],\n        'columns': cdf.columns if cdf.columns else [],\n        'query': query.to_dict(),\n    })\n\n    if store_results:\n        key = str(uuid.uuid4())\n        logging.info(f'Storing results in results backend, key: {key}')\n        with stats_timing('sqllab.query.results_backend_write', stats_logger):\n            json_payload = json.dumps(\n                payload, default=json_iso_dttm_ser, ignore_nan=True)\n            cache_timeout = database.cache_timeout\n            if cache_timeout is None:\n                cache_timeout = config.get('CACHE_DEFAULT_TIMEOUT', 0)\n            results_backend.set(key, zlib_compress(json_payload), cache_timeout)\n        query.results_key = key\n    session.commit()\n\n    if return_results:\n        return payload", "response": "Executes the sql query and returns the results."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nflasking s flash if available logging call if not", "response": "def flasher(msg, severity=None):\n    \"\"\"Flask's flash if available, logging call if not\"\"\"\n    try:\n        flash(msg, severity)\n    except RuntimeError:\n        if severity == 'danger':\n            logging.error(msg)\n        else:\n            logging.info(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a string to an int or float", "response": "def string_to_num(s: str):\n    \"\"\"Converts a string to an int/float\n\n    Returns ``None`` if it can't be converted\n\n    >>> string_to_num('5')\n    5\n    >>> string_to_num('5.2')\n    5.2\n    >>> string_to_num(10)\n    10\n    >>> string_to_num(10.1)\n    10.1\n    >>> string_to_num('this is not a string') is None\n    True\n    \"\"\"\n    if isinstance(s, (int, float)):\n        return s\n    if s.isdigit():\n        return int(s)\n    try:\n        return float(s)\n    except ValueError:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_minus(l: List, minus: List) -> List:\n    return [o for o in l if o not in minus]", "response": "Returns l without what is in minus"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a human readable datetime string into a datetime. datetime object.", "response": "def parse_human_datetime(s):\n    \"\"\"\n    Returns ``datetime.datetime`` from human readable strings\n\n    >>> from datetime import date, timedelta\n    >>> from dateutil.relativedelta import relativedelta\n    >>> parse_human_datetime('2015-04-03')\n    datetime.datetime(2015, 4, 3, 0, 0)\n    >>> parse_human_datetime('2/3/1969')\n    datetime.datetime(1969, 2, 3, 0, 0)\n    >>> parse_human_datetime('now') <= datetime.now()\n    True\n    >>> parse_human_datetime('yesterday') <= datetime.now()\n    True\n    >>> date.today() - timedelta(1) == parse_human_datetime('yesterday').date()\n    True\n    >>> year_ago_1 = parse_human_datetime('one year ago').date()\n    >>> year_ago_2 = (datetime.now() - relativedelta(years=1) ).date()\n    >>> year_ago_1 == year_ago_2\n    True\n    \"\"\"\n    if not s:\n        return None\n    try:\n        dttm = parse(s)\n    except Exception:\n        try:\n            cal = parsedatetime.Calendar()\n            parsed_dttm, parsed_flags = cal.parseDT(s)\n            # when time is not extracted, we 'reset to midnight'\n            if parsed_flags & 2 == 0:\n                parsed_dttm = parsed_dttm.replace(hour=0, minute=0, second=0)\n            dttm = dttm_from_timtuple(parsed_dttm.utctimetuple())\n        except Exception as e:\n            logging.exception(e)\n            raise ValueError(\"Couldn't parse date string [{}]\".format(s))\n    return dttm"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef decode_dashboards(o):\n    import superset.models.core as models\n    from superset.connectors.sqla.models import (\n        SqlaTable, SqlMetric, TableColumn,\n    )\n\n    if '__Dashboard__' in o:\n        d = models.Dashboard()\n        d.__dict__.update(o['__Dashboard__'])\n        return d\n    elif '__Slice__' in o:\n        d = models.Slice()\n        d.__dict__.update(o['__Slice__'])\n        return d\n    elif '__TableColumn__' in o:\n        d = TableColumn()\n        d.__dict__.update(o['__TableColumn__'])\n        return d\n    elif '__SqlaTable__' in o:\n        d = SqlaTable()\n        d.__dict__.update(o['__SqlaTable__'])\n        return d\n    elif '__SqlMetric__' in o:\n        d = SqlMetric()\n        d.__dict__.update(o['__SqlMetric__'])\n        return d\n    elif '__datetime__' in o:\n        return datetime.strptime(o['__datetime__'], '%Y-%m-%dT%H:%M:%S')\n    else:\n        return o", "response": "Decode a dashboard object into a series of dashboards."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning datetime. datetime from natural language time deltas", "response": "def parse_human_timedelta(s: str):\n    \"\"\"\n    Returns ``datetime.datetime`` from natural language time deltas\n\n    >>> parse_human_datetime('now') <= datetime.now()\n    True\n    \"\"\"\n    cal = parsedatetime.Calendar()\n    dttm = dttm_from_timtuple(datetime.now().timetuple())\n    d = cal.parse(s or '', dttm)[0]\n    d = datetime(d.tm_year, d.tm_mon, d.tm_mday, d.tm_hour, d.tm_min, d.tm_sec)\n    return d - dttm"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef datetime_f(dttm):\n    if dttm:\n        dttm = dttm.isoformat()\n        now_iso = datetime.now().isoformat()\n        if now_iso[:10] == dttm[:10]:\n            dttm = dttm[11:]\n        elif now_iso[:4] == dttm[:4]:\n            dttm = dttm[5:]\n    return '<nobr>{}</nobr>'.format(dttm)", "response": "Formats datetime to take less room when it is recent"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef json_iso_dttm_ser(obj, pessimistic: Optional[bool] = False):\n    val = base_json_conv(obj)\n    if val is not None:\n        return val\n    if isinstance(obj, (datetime, date, time, pd.Timestamp)):\n        obj = obj.isoformat()\n    else:\n        if pessimistic:\n            return 'Unserializable [{}]'.format(type(obj))\n        else:\n            raise TypeError(\n                'Unserializable object {} of type {}'.format(obj, type(obj)))\n    return obj", "response": "json serializer that deals with dates\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef json_int_dttm_ser(obj):\n    val = base_json_conv(obj)\n    if val is not None:\n        return val\n    if isinstance(obj, (datetime, pd.Timestamp)):\n        obj = datetime_to_epoch(obj)\n    elif isinstance(obj, date):\n        obj = (obj - EPOCH.date()).total_seconds() * 1000\n    else:\n        raise TypeError(\n            'Unserializable object {} of type {}'.format(obj, type(obj)))\n    return obj", "response": "json serializer that deals with dates"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntranslate exception into error message in the database.", "response": "def error_msg_from_exception(e):\n    \"\"\"Translate exception into error message\n\n    Database have different ways to handle exception. This function attempts\n    to make sense of the exception object and construct a human readable\n    sentence.\n\n    TODO(bkyryliuk): parse the Presto error message from the connection\n                     created via create_engine.\n    engine = create_engine('presto://localhost:3506/silver') -\n      gives an e.message as the str(dict)\n    presto.connect('localhost', port=3506, catalog='silver') - as a dict.\n    The latter version is parsed correctly by this function.\n    \"\"\"\n    msg = ''\n    if hasattr(e, 'message'):\n        if isinstance(e.message, dict):\n            msg = e.message.get('message')\n        elif e.message:\n            msg = '{}'.format(e.message)\n    return msg or '{}'.format(e)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generic_find_uq_constraint_name(table, columns, insp):\n\n    for uq in insp.get_unique_constraints(table):\n        if columns == set(uq['column_names']):\n            return uq['name']", "response": "Utility to find a unique constraint name in alembic migrations"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_email_smtp(to, subject, html_content, config,\n                    files=None, data=None, images=None, dryrun=False,\n                    cc=None, bcc=None, mime_subtype='mixed'):\n    \"\"\"\n    Send an email with html content, eg:\n    send_email_smtp(\n        'test@example.com', 'foo', '<b>Foo</b> bar',['/dev/null'], dryrun=True)\n    \"\"\"\n    smtp_mail_from = config.get('SMTP_MAIL_FROM')\n    to = get_email_address_list(to)\n\n    msg = MIMEMultipart(mime_subtype)\n    msg['Subject'] = subject\n    msg['From'] = smtp_mail_from\n    msg['To'] = ', '.join(to)\n    msg.preamble = 'This is a multi-part message in MIME format.'\n\n    recipients = to\n    if cc:\n        cc = get_email_address_list(cc)\n        msg['CC'] = ', '.join(cc)\n        recipients = recipients + cc\n\n    if bcc:\n        # don't add bcc in header\n        bcc = get_email_address_list(bcc)\n        recipients = recipients + bcc\n\n    msg['Date'] = formatdate(localtime=True)\n    mime_text = MIMEText(html_content, 'html')\n    msg.attach(mime_text)\n\n    # Attach files by reading them from disk\n    for fname in files or []:\n        basename = os.path.basename(fname)\n        with open(fname, 'rb') as f:\n            msg.attach(\n                MIMEApplication(\n                    f.read(),\n                    Content_Disposition=\"attachment; filename='%s'\" % basename,\n                    Name=basename))\n\n    # Attach any files passed directly\n    for name, body in (data or {}).items():\n        msg.attach(\n            MIMEApplication(\n                body,\n                Content_Disposition=\"attachment; filename='%s'\" % name,\n                Name=name,\n            ))\n\n    # Attach any inline images, which may be required for display in\n    # HTML content (inline)\n    for msgid, body in (images or {}).items():\n        image = MIMEImage(body)\n        image.add_header('Content-ID', '<%s>' % msgid)\n        image.add_header('Content-Disposition', 'inline')\n        msg.attach(image)\n\n    send_MIME_email(smtp_mail_from, recipients, msg, config, dryrun=dryrun)", "response": "Send an email with html content."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef zlib_compress(data):\n    if PY3K:\n        if isinstance(data, str):\n            return zlib.compress(bytes(data, 'utf-8'))\n        return zlib.compress(data)\n    return zlib.compress(data)", "response": "Compress things in a py2 or 3 safe fashion"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef zlib_decompress_to_string(blob):\n    if PY3K:\n        if isinstance(blob, bytes):\n            decompressed = zlib.decompress(blob)\n        else:\n            decompressed = zlib.decompress(bytes(blob, 'utf-8'))\n        return decompressed.decode('utf-8')\n    return zlib.decompress(blob)", "response": "Decompress things to a string in a py2 or 3 safe fashion."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef user_label(user: User) -> Optional[str]:\n    if user:\n        if user.first_name and user.last_name:\n            return user.first_name + ' ' + user.last_name\n        else:\n            return user.username\n\n    return None", "response": "Given a user ORM FAB object returns a label"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_since_until(time_range: Optional[str] = None,\n                    since: Optional[str] = None,\n                    until: Optional[str] = None,\n                    time_shift: Optional[str] = None,\n                    relative_end: Optional[str] = None) -> Tuple[datetime, datetime]:\n    \"\"\"Return `since` and `until` date time tuple from string representations of\n    time_range, since, until and time_shift.\n\n    This functiom supports both reading the keys separately (from `since` and\n    `until`), as well as the new `time_range` key. Valid formats are:\n\n        - ISO 8601\n        - X days/years/hours/day/year/weeks\n        - X days/years/hours/day/year/weeks ago\n        - X days/years/hours/day/year/weeks from now\n        - freeform\n\n    Additionally, for `time_range` (these specify both `since` and `until`):\n\n        - Last day\n        - Last week\n        - Last month\n        - Last quarter\n        - Last year\n        - No filter\n        - Last X seconds/minutes/hours/days/weeks/months/years\n        - Next X seconds/minutes/hours/days/weeks/months/years\n\n    \"\"\"\n    separator = ' : '\n    relative_end = parse_human_datetime(relative_end if relative_end else 'today')\n    common_time_frames = {\n        'Last day': (relative_end - relativedelta(days=1), relative_end),  # noqa: T400\n        'Last week': (relative_end - relativedelta(weeks=1), relative_end),  # noqa: T400\n        'Last month': (relative_end - relativedelta(months=1), relative_end),  # noqa: E501, T400\n        'Last quarter': (relative_end - relativedelta(months=3), relative_end),  # noqa: E501, T400\n        'Last year': (relative_end - relativedelta(years=1), relative_end),  # noqa: T400\n    }\n\n    if time_range:\n        if separator in time_range:\n            since, until = time_range.split(separator, 1)\n            if since and since not in common_time_frames:\n                since = add_ago_to_since(since)\n            since = parse_human_datetime(since)\n            until = parse_human_datetime(until)\n        elif time_range in common_time_frames:\n            since, until = common_time_frames[time_range]\n        elif time_range == 'No filter':\n            since = until = None\n        else:\n            rel, num, grain = time_range.split()\n            if rel == 'Last':\n                since = relative_end - relativedelta(**{grain: int(num)})  # noqa: T400\n                until = relative_end\n            else:  # rel == 'Next'\n                since = relative_end\n                until = relative_end + relativedelta(**{grain: int(num)})  # noqa: T400\n    else:\n        since = since or ''\n        if since:\n            since = add_ago_to_since(since)\n        since = parse_human_datetime(since)\n        until = parse_human_datetime(until) if until else relative_end\n\n    if time_shift:\n        time_shift = parse_human_timedelta(time_shift)\n        since = since if since is None else (since - time_shift)  # noqa: T400\n        until = until if until is None else (until - time_shift)  # noqa: T400\n\n    if since and until and since > until:\n        raise ValueError(_('From date cannot be larger than to date'))\n\n    return since, until", "response": "Return a tuple of date time tuple from string representations of time_range since and until."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd ago to the since if necessary.", "response": "def add_ago_to_since(since: str) -> str:\n    \"\"\"\n    Backwards compatibility hack. Without this slices with since: 7 days will\n    be treated as 7 days in the future.\n\n    :param str since:\n    :returns: Since with ago added if necessary\n    :rtype: str\n    \"\"\"\n    since_words = since.split(' ')\n    grains = ['days', 'years', 'hours', 'day', 'year', 'weeks']\n    if (len(since_words) == 2 and since_words[1] in grains):\n        since += ' ago'\n    return since"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef split_adhoc_filters_into_base_filters(fd):\n    adhoc_filters = fd.get('adhoc_filters')\n    if isinstance(adhoc_filters, list):\n        simple_where_filters = []\n        simple_having_filters = []\n        sql_where_filters = []\n        sql_having_filters = []\n        for adhoc_filter in adhoc_filters:\n            expression_type = adhoc_filter.get('expressionType')\n            clause = adhoc_filter.get('clause')\n            if expression_type == 'SIMPLE':\n                if clause == 'WHERE':\n                    simple_where_filters.append({\n                        'col': adhoc_filter.get('subject'),\n                        'op': adhoc_filter.get('operator'),\n                        'val': adhoc_filter.get('comparator'),\n                    })\n                elif clause == 'HAVING':\n                    simple_having_filters.append({\n                        'col': adhoc_filter.get('subject'),\n                        'op': adhoc_filter.get('operator'),\n                        'val': adhoc_filter.get('comparator'),\n                    })\n            elif expression_type == 'SQL':\n                if clause == 'WHERE':\n                    sql_where_filters.append(adhoc_filter.get('sqlExpression'))\n                elif clause == 'HAVING':\n                    sql_having_filters.append(adhoc_filter.get('sqlExpression'))\n        fd['where'] = ' AND '.join(['({})'.format(sql) for sql in sql_where_filters])\n        fd['having'] = ' AND '.join(['({})'.format(sql) for sql in sql_having_filters])\n        fd['having_filters'] = simple_having_filters\n        fd['filters'] = simple_where_filters", "response": "Splits the adhoc filters into base filters."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_energy():\n    tbl_name = 'energy_usage'\n    data = get_example_data('energy.json.gz')\n    pdf = pd.read_json(data)\n    pdf.to_sql(\n        tbl_name,\n        db.engine,\n        if_exists='replace',\n        chunksize=500,\n        dtype={\n            'source': String(255),\n            'target': String(255),\n            'value': Float(),\n        },\n        index=False)\n\n    print('Creating table [wb_health_population] reference')\n    tbl = db.session.query(TBL).filter_by(table_name=tbl_name).first()\n    if not tbl:\n        tbl = TBL(table_name=tbl_name)\n    tbl.description = 'Energy consumption'\n    tbl.database = utils.get_or_create_main_db()\n\n    if not any(col.metric_name == 'sum__value' for col in tbl.metrics):\n        tbl.metrics.append(SqlMetric(\n            metric_name='sum__value',\n            expression='SUM(value)',\n        ))\n\n    db.session.merge(tbl)\n    db.session.commit()\n    tbl.fetch_metadata()\n\n    slc = Slice(\n        slice_name='Energy Sankey',\n        viz_type='sankey',\n        datasource_type='table',\n        datasource_id=tbl.id,\n        params=textwrap.dedent(\"\"\"\\\n        {\n            \"collapsed_fieldsets\": \"\",\n            \"groupby\": [\n                \"source\",\n                \"target\"\n            ],\n            \"having\": \"\",\n            \"metric\": \"sum__value\",\n            \"row_limit\": \"5000\",\n            \"slice_name\": \"Energy Sankey\",\n            \"viz_type\": \"sankey\",\n            \"where\": \"\"\n        }\n        \"\"\"),\n    )\n    misc_dash_slices.add(slc.slice_name)\n    merge_slice(slc)\n\n    slc = Slice(\n        slice_name='Energy Force Layout',\n        viz_type='directed_force',\n        datasource_type='table',\n        datasource_id=tbl.id,\n        params=textwrap.dedent(\"\"\"\\\n        {\n            \"charge\": \"-500\",\n            \"collapsed_fieldsets\": \"\",\n            \"groupby\": [\n                \"source\",\n                \"target\"\n            ],\n            \"having\": \"\",\n            \"link_length\": \"200\",\n            \"metric\": \"sum__value\",\n            \"row_limit\": \"5000\",\n            \"slice_name\": \"Force\",\n            \"viz_type\": \"directed_force\",\n            \"where\": \"\"\n        }\n        \"\"\"),\n    )\n    misc_dash_slices.add(slc.slice_name)\n    merge_slice(slc)\n\n    slc = Slice(\n        slice_name='Heatmap',\n        viz_type='heatmap',\n        datasource_type='table',\n        datasource_id=tbl.id,\n        params=textwrap.dedent(\"\"\"\\\n        {\n            \"all_columns_x\": \"source\",\n            \"all_columns_y\": \"target\",\n            \"canvas_image_rendering\": \"pixelated\",\n            \"collapsed_fieldsets\": \"\",\n            \"having\": \"\",\n            \"linear_color_scheme\": \"blue_white_yellow\",\n            \"metric\": \"sum__value\",\n            \"normalize_across\": \"heatmap\",\n            \"slice_name\": \"Heatmap\",\n            \"viz_type\": \"heatmap\",\n            \"where\": \"\",\n            \"xscale_interval\": \"1\",\n            \"yscale_interval\": \"1\"\n        }\n        \"\"\"),\n    )\n    misc_dash_slices.add(slc.slice_name)\n    merge_slice(slc)", "response": "Loads an energy related dataset to use with sankey and graphs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_random_time_series_data():\n    data = get_example_data('random_time_series.json.gz')\n    pdf = pd.read_json(data)\n    pdf.ds = pd.to_datetime(pdf.ds, unit='s')\n    pdf.to_sql(\n        'random_time_series',\n        db.engine,\n        if_exists='replace',\n        chunksize=500,\n        dtype={\n            'ds': DateTime,\n        },\n        index=False)\n    print('Done loading table!')\n    print('-' * 80)\n\n    print('Creating table [random_time_series] reference')\n    obj = db.session.query(TBL).filter_by(table_name='random_time_series').first()\n    if not obj:\n        obj = TBL(table_name='random_time_series')\n    obj.main_dttm_col = 'ds'\n    obj.database = utils.get_or_create_main_db()\n    db.session.merge(obj)\n    db.session.commit()\n    obj.fetch_metadata()\n    tbl = obj\n\n    slice_data = {\n        'granularity_sqla': 'day',\n        'row_limit': config.get('ROW_LIMIT'),\n        'since': '1 year ago',\n        'until': 'now',\n        'metric': 'count',\n        'where': '',\n        'viz_type': 'cal_heatmap',\n        'domain_granularity': 'month',\n        'subdomain_granularity': 'day',\n    }\n\n    print('Creating a slice')\n    slc = Slice(\n        slice_name='Calendar Heatmap',\n        viz_type='cal_heatmap',\n        datasource_type='table',\n        datasource_id=tbl.id,\n        params=get_slice_json(slice_data),\n    )\n    merge_slice(slc)", "response": "Load random time series data from a zip file in the repo"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef runserver(debug, console_log, use_reloader, address, port, timeout, workers, socket):\n    debug = debug or config.get('DEBUG') or console_log\n    if debug:\n        print(Fore.BLUE + '-=' * 20)\n        print(\n            Fore.YELLOW + 'Starting Superset server in ' +\n            Fore.RED + 'DEBUG' +\n            Fore.YELLOW + ' mode')\n        print(Fore.BLUE + '-=' * 20)\n        print(Style.RESET_ALL)\n        if console_log:\n            console_log_run(app, port, use_reloader)\n        else:\n            debug_run(app, port, use_reloader)\n    else:\n        logging.info(\n            \"The Gunicorn 'superset runserver' command is deprecated. Please \"\n            \"use the 'gunicorn' command instead.\")\n        addr_str = f' unix:{socket} ' if socket else f' {address}:{port} '\n        cmd = (\n            'gunicorn '\n            f'-w {workers} '\n            f'--timeout {timeout} '\n            f'-b {addr_str} '\n            '--limit-request-line 0 '\n            '--limit-request-field_size 0 '\n            'superset:app'\n        )\n        print(Fore.GREEN + 'Starting server with command: ')\n        print(Fore.YELLOW + cmd)\n        print(Style.RESET_ALL)\n        Popen(cmd, shell=True).wait()", "response": "Starts a Superset web server."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef version(verbose):\n    print(Fore.BLUE + '-=' * 15)\n    print(Fore.YELLOW + 'Superset ' + Fore.CYAN + '{version}'.format(\n        version=config.get('VERSION_STRING')))\n    print(Fore.BLUE + '-=' * 15)\n    if verbose:\n        print('[DB] : ' + '{}'.format(db.engine))\n    print(Style.RESET_ALL)", "response": "Prints the current version number"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nimporting dashboards from JSON file", "response": "def import_dashboards(path, recursive):\n    \"\"\"Import dashboards from JSON\"\"\"\n    p = Path(path)\n    files = []\n    if p.is_file():\n        files.append(p)\n    elif p.exists() and not recursive:\n        files.extend(p.glob('*.json'))\n    elif p.exists() and recursive:\n        files.extend(p.rglob('*.json'))\n    for f in files:\n        logging.info('Importing dashboard from file %s', f)\n        try:\n            with f.open() as data_stream:\n                dashboard_import_export.import_dashboards(\n                    db.session, data_stream)\n        except Exception as e:\n            logging.error('Error when importing dashboard from file %s', f)\n            logging.error(e)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef export_dashboards(print_stdout, dashboard_file):\n    data = dashboard_import_export.export_dashboards(db.session)\n    if print_stdout or not dashboard_file:\n        print(data)\n    if dashboard_file:\n        logging.info('Exporting dashboards to %s', dashboard_file)\n        with open(dashboard_file, 'w') as data_stream:\n            data_stream.write(data)", "response": "Export dashboards to JSON"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef import_datasources(path, sync, recursive):\n    sync_array = sync.split(',')\n    p = Path(path)\n    files = []\n    if p.is_file():\n        files.append(p)\n    elif p.exists() and not recursive:\n        files.extend(p.glob('*.yaml'))\n        files.extend(p.glob('*.yml'))\n    elif p.exists() and recursive:\n        files.extend(p.rglob('*.yaml'))\n        files.extend(p.rglob('*.yml'))\n    for f in files:\n        logging.info('Importing datasources from file %s', f)\n        try:\n            with f.open() as data_stream:\n                dict_import_export.import_from_dict(\n                    db.session,\n                    yaml.safe_load(data_stream),\n                    sync=sync_array)\n        except Exception as e:\n            logging.error('Error when importing datasources from file %s', f)\n            logging.error(e)", "response": "Import datasources from YAML"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexporting datasources to YAML", "response": "def export_datasources(print_stdout, datasource_file,\n                       back_references, include_defaults):\n    \"\"\"Export datasources to YAML\"\"\"\n    data = dict_import_export.export_to_dict(\n        session=db.session,\n        recursive=True,\n        back_references=back_references,\n        include_defaults=include_defaults)\n    if print_stdout or not datasource_file:\n        yaml.safe_dump(data, stdout, default_flow_style=False)\n    if datasource_file:\n        logging.info('Exporting datasources to %s', datasource_file)\n        with open(datasource_file, 'w') as data_stream:\n            yaml.safe_dump(data, data_stream, default_flow_style=False)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef export_datasource_schema(back_references):\n    data = dict_import_export.export_schema_to_dict(\n        back_references=back_references)\n    yaml.safe_dump(data, stdout, default_flow_style=False)", "response": "Export datasource YAML schema to stdout"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrefreshes sqllab datasources cache", "response": "def update_datasources_cache():\n    \"\"\"Refresh sqllab datasources cache\"\"\"\n    from superset.models.core import Database\n    for database in db.session.query(Database).all():\n        if database.allow_multi_schema_metadata_fetch:\n            print('Fetching {} datasources ...'.format(database.name))\n            try:\n                database.all_table_names_in_database(\n                    force=True, cache=True, cache_timeout=24 * 60 * 60)\n                database.all_view_names_in_database(\n                    force=True, cache=True, cache_timeout=24 * 60 * 60)\n            except Exception as e:\n                print('{}'.format(str(e)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef worker(workers):\n    logging.info(\n        \"The 'superset worker' command is deprecated. Please use the 'celery \"\n        \"worker' command instead.\")\n    if workers:\n        celery_app.conf.update(CELERYD_CONCURRENCY=workers)\n    elif config.get('SUPERSET_CELERY_WORKERS'):\n        celery_app.conf.update(\n            CELERYD_CONCURRENCY=config.get('SUPERSET_CELERY_WORKERS'))\n\n    worker = celery_app.Worker(optimization='fair')\n    worker.start()", "response": "Starts a Superset worker for async SQL query execution."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef flower(port, address):\n    BROKER_URL = celery_app.conf.BROKER_URL\n    cmd = (\n        'celery flower '\n        f'--broker={BROKER_URL} '\n        f'--port={port} '\n        f'--address={address} '\n    )\n    logging.info(\n        \"The 'superset flower' command is deprecated. Please use the 'celery \"\n        \"flower' command instead.\")\n    print(Fore.GREEN + 'Starting a Celery Flower instance')\n    print(Fore.BLUE + '-=' * 40)\n    print(Fore.YELLOW + cmd)\n    print(Fore.BLUE + '-=' * 40)\n    Popen(cmd, shell=True).wait()", "response": "Runs a Celery Flower web server on a given broker"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_flights():\n    tbl_name = 'flights'\n    data = get_example_data('flight_data.csv.gz', make_bytes=True)\n    pdf = pd.read_csv(data, encoding='latin-1')\n\n    # Loading airports info to join and get lat/long\n    airports_bytes = get_example_data('airports.csv.gz', make_bytes=True)\n    airports = pd.read_csv(airports_bytes, encoding='latin-1')\n    airports = airports.set_index('IATA_CODE')\n\n    pdf['ds'] = pdf.YEAR.map(str) + '-0' + pdf.MONTH.map(str) + '-0' + pdf.DAY.map(str)\n    pdf.ds = pd.to_datetime(pdf.ds)\n    del pdf['YEAR']\n    del pdf['MONTH']\n    del pdf['DAY']\n\n    pdf = pdf.join(airports, on='ORIGIN_AIRPORT', rsuffix='_ORIG')\n    pdf = pdf.join(airports, on='DESTINATION_AIRPORT', rsuffix='_DEST')\n    pdf.to_sql(\n        tbl_name,\n        db.engine,\n        if_exists='replace',\n        chunksize=500,\n        dtype={\n            'ds': DateTime,\n        },\n        index=False)\n    tbl = db.session.query(TBL).filter_by(table_name=tbl_name).first()\n    if not tbl:\n        tbl = TBL(table_name=tbl_name)\n    tbl.description = 'Random set of flights in the US'\n    tbl.database = utils.get_or_create_main_db()\n    db.session.merge(tbl)\n    db.session.commit()\n    tbl.fetch_metadata()\n    print('Done loading table!')", "response": "Load random flights from a zip file in the repo"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload the birth name dataset from a zip file in the repo", "response": "def load_birth_names():\n    \"\"\"Loading birth name dataset from a zip file in the repo\"\"\"\n    data = get_example_data('birth_names.json.gz')\n    pdf = pd.read_json(data)\n    pdf.ds = pd.to_datetime(pdf.ds, unit='ms')\n    pdf.to_sql(\n        'birth_names',\n        db.engine,\n        if_exists='replace',\n        chunksize=500,\n        dtype={\n            'ds': DateTime,\n            'gender': String(16),\n            'state': String(10),\n            'name': String(255),\n        },\n        index=False)\n    print('Done loading table!')\n    print('-' * 80)\n\n    print('Creating table [birth_names] reference')\n    obj = db.session.query(TBL).filter_by(table_name='birth_names').first()\n    if not obj:\n        obj = TBL(table_name='birth_names')\n    obj.main_dttm_col = 'ds'\n    obj.database = get_or_create_main_db()\n    obj.filter_select_enabled = True\n\n    if not any(col.column_name == 'num_california' for col in obj.columns):\n        obj.columns.append(TableColumn(\n            column_name='num_california',\n            expression=\"CASE WHEN state = 'CA' THEN num ELSE 0 END\",\n        ))\n\n    if not any(col.metric_name == 'sum__num' for col in obj.metrics):\n        obj.metrics.append(SqlMetric(\n            metric_name='sum__num',\n            expression='SUM(num)',\n        ))\n\n    db.session.merge(obj)\n    db.session.commit()\n    obj.fetch_metadata()\n    tbl = obj\n\n    defaults = {\n        'compare_lag': '10',\n        'compare_suffix': 'o10Y',\n        'limit': '25',\n        'granularity_sqla': 'ds',\n        'groupby': [],\n        'metric': 'sum__num',\n        'metrics': ['sum__num'],\n        'row_limit': config.get('ROW_LIMIT'),\n        'since': '100 years ago',\n        'until': 'now',\n        'viz_type': 'table',\n        'where': '',\n        'markup_type': 'markdown',\n    }\n\n    admin = security_manager.find_user('admin')\n\n    print('Creating some slices')\n    slices = [\n        Slice(\n            slice_name='Girls',\n            viz_type='table',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                groupby=['name'],\n                filters=[{\n                    'col': 'gender',\n                    'op': 'in',\n                    'val': ['girl'],\n                }],\n                row_limit=50,\n                timeseries_limit_metric='sum__num')),\n        Slice(\n            slice_name='Boys',\n            viz_type='table',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                groupby=['name'],\n                filters=[{\n                    'col': 'gender',\n                    'op': 'in',\n                    'val': ['boy'],\n                }],\n                row_limit=50)),\n        Slice(\n            slice_name='Participants',\n            viz_type='big_number',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                viz_type='big_number', granularity_sqla='ds',\n                compare_lag='5', compare_suffix='over 5Y')),\n        Slice(\n            slice_name='Genders',\n            viz_type='pie',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                viz_type='pie', groupby=['gender'])),\n        Slice(\n            slice_name='Genders by State',\n            viz_type='dist_bar',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                adhoc_filters=[\n                    {\n                        'clause': 'WHERE',\n                        'expressionType': 'SIMPLE',\n                        'filterOptionName': '2745eae5',\n                        'comparator': ['other'],\n                        'operator': 'not in',\n                        'subject': 'state',\n                    },\n                ],\n                viz_type='dist_bar',\n                metrics=[\n                    {\n                        'expressionType': 'SIMPLE',\n                        'column': {\n                            'column_name': 'sum_boys',\n                            'type': 'BIGINT(20)',\n                        },\n                        'aggregate': 'SUM',\n                        'label': 'Boys',\n                        'optionName': 'metric_11',\n                    },\n                    {\n                        'expressionType': 'SIMPLE',\n                        'column': {\n                            'column_name': 'sum_girls',\n                            'type': 'BIGINT(20)',\n                        },\n                        'aggregate': 'SUM',\n                        'label': 'Girls',\n                        'optionName': 'metric_12',\n                    },\n                ],\n                groupby=['state'])),\n        Slice(\n            slice_name='Trends',\n            viz_type='line',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                viz_type='line', groupby=['name'],\n                granularity_sqla='ds', rich_tooltip=True, show_legend=True)),\n        Slice(\n            slice_name='Average and Sum Trends',\n            viz_type='dual_line',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                viz_type='dual_line',\n                metric={\n                    'expressionType': 'SIMPLE',\n                    'column': {\n                        'column_name': 'num',\n                        'type': 'BIGINT(20)',\n                    },\n                    'aggregate': 'AVG',\n                    'label': 'AVG(num)',\n                    'optionName': 'metric_vgops097wej_g8uff99zhk7',\n                },\n                metric_2='sum__num',\n                granularity_sqla='ds')),\n        Slice(\n            slice_name='Title',\n            viz_type='markup',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                viz_type='markup', markup_type='html',\n                code=\"\"\"\\\n    <div style='text-align:center'>\n        <h1>Birth Names Dashboard</h1>\n        <p>\n            The source dataset came from\n            <a href='https://github.com/hadley/babynames' target='_blank'>[here]</a>\n        </p>\n        <img src='/static/assets/images/babytux.jpg'>\n    </div>\n    \"\"\")),\n        Slice(\n            slice_name='Name Cloud',\n            viz_type='word_cloud',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                viz_type='word_cloud', size_from='10',\n                series='name', size_to='70', rotation='square',\n                limit='100')),\n        Slice(\n            slice_name='Pivot Table',\n            viz_type='pivot_table',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                viz_type='pivot_table', metrics=['sum__num'],\n                groupby=['name'], columns=['state'])),\n        Slice(\n            slice_name='Number of Girls',\n            viz_type='big_number_total',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                viz_type='big_number_total', granularity_sqla='ds',\n                filters=[{\n                    'col': 'gender',\n                    'op': 'in',\n                    'val': ['girl'],\n                }],\n                subheader='total female participants')),\n        Slice(\n            slice_name='Number of California Births',\n            viz_type='big_number_total',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                metric={\n                    'expressionType': 'SIMPLE',\n                    'column': {\n                        'column_name': 'num_california',\n                        'expression': \"CASE WHEN state = 'CA' THEN num ELSE 0 END\",\n                    },\n                    'aggregate': 'SUM',\n                    'label': 'SUM(num_california)',\n                },\n                viz_type='big_number_total',\n                granularity_sqla='ds')),\n        Slice(\n            slice_name='Top 10 California Names Timeseries',\n            viz_type='line',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                metrics=[{\n                    'expressionType': 'SIMPLE',\n                    'column': {\n                        'column_name': 'num_california',\n                        'expression': \"CASE WHEN state = 'CA' THEN num ELSE 0 END\",\n                    },\n                    'aggregate': 'SUM',\n                    'label': 'SUM(num_california)',\n                }],\n                viz_type='line',\n                granularity_sqla='ds',\n                groupby=['name'],\n                timeseries_limit_metric={\n                    'expressionType': 'SIMPLE',\n                    'column': {\n                        'column_name': 'num_california',\n                        'expression': \"CASE WHEN state = 'CA' THEN num ELSE 0 END\",\n                    },\n                    'aggregate': 'SUM',\n                    'label': 'SUM(num_california)',\n                },\n                limit='10')),\n        Slice(\n            slice_name='Names Sorted by Num in California',\n            viz_type='table',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                groupby=['name'],\n                row_limit=50,\n                timeseries_limit_metric={\n                    'expressionType': 'SIMPLE',\n                    'column': {\n                        'column_name': 'num_california',\n                        'expression': \"CASE WHEN state = 'CA' THEN num ELSE 0 END\",\n                    },\n                    'aggregate': 'SUM',\n                    'label': 'SUM(num_california)',\n                })),\n        Slice(\n            slice_name='Num Births Trend',\n            viz_type='line',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            params=get_slice_json(\n                defaults,\n                viz_type='line')),\n        Slice(\n            slice_name='Daily Totals',\n            viz_type='table',\n            datasource_type='table',\n            datasource_id=tbl.id,\n            created_by=admin,\n            params=get_slice_json(\n                defaults,\n                groupby=['ds'],\n                since='40 years ago',\n                until='now',\n                viz_type='table')),\n    ]\n    for slc in slices:\n        merge_slice(slc)\n\n    print('Creating a dashboard')\n    dash = db.session.query(Dash).filter_by(dashboard_title='Births').first()\n\n    if not dash:\n        dash = Dash()\n    js = textwrap.dedent(\"\"\"\\\n{\n    \"CHART-0dd270f0\": {\n        \"meta\": {\n            \"chartId\": 51,\n            \"width\": 2,\n            \"height\": 50\n        },\n        \"type\": \"CHART\",\n        \"id\": \"CHART-0dd270f0\",\n        \"children\": []\n    },\n    \"CHART-a3c21bcc\": {\n        \"meta\": {\n            \"chartId\": 52,\n            \"width\": 2,\n            \"height\": 50\n        },\n        \"type\": \"CHART\",\n        \"id\": \"CHART-a3c21bcc\",\n        \"children\": []\n    },\n    \"CHART-976960a5\": {\n        \"meta\": {\n            \"chartId\": 53,\n            \"width\": 2,\n            \"height\": 25\n        },\n        \"type\": \"CHART\",\n        \"id\": \"CHART-976960a5\",\n        \"children\": []\n    },\n    \"CHART-58575537\": {\n        \"meta\": {\n            \"chartId\": 54,\n            \"width\": 2,\n            \"height\": 25\n        },\n        \"type\": \"CHART\",\n        \"id\": \"CHART-58575537\",\n        \"children\": []\n    },\n    \"CHART-e9cd8f0b\": {\n        \"meta\": {\n            \"chartId\": 55,\n            \"width\": 8,\n            \"height\": 38\n        },\n        \"type\": \"CHART\",\n        \"id\": \"CHART-e9cd8f0b\",\n        \"children\": []\n    },\n    \"CHART-e440d205\": {\n        \"meta\": {\n            \"chartId\": 56,\n            \"width\": 8,\n            \"height\": 50\n        },\n        \"type\": \"CHART\",\n        \"id\": \"CHART-e440d205\",\n        \"children\": []\n    },\n    \"CHART-59444e0b\": {\n        \"meta\": {\n            \"chartId\": 57,\n            \"width\": 3,\n            \"height\": 38\n        },\n        \"type\": \"CHART\",\n        \"id\": \"CHART-59444e0b\",\n        \"children\": []\n    },\n    \"CHART-e2cb4997\": {\n        \"meta\": {\n            \"chartId\": 59,\n            \"width\": 4,\n            \"height\": 50\n        },\n        \"type\": \"CHART\",\n        \"id\": \"CHART-e2cb4997\",\n        \"children\": []\n    },\n    \"CHART-e8774b49\": {\n        \"meta\": {\n            \"chartId\": 60,\n            \"width\": 12,\n            \"height\": 50\n        },\n        \"type\": \"CHART\",\n        \"id\": \"CHART-e8774b49\",\n        \"children\": []\n    },\n    \"CHART-985bfd1e\": {\n        \"meta\": {\n            \"chartId\": 61,\n            \"width\": 4,\n            \"height\": 50\n        },\n        \"type\": \"CHART\",\n        \"id\": \"CHART-985bfd1e\",\n        \"children\": []\n    },\n    \"CHART-17f13246\": {\n        \"meta\": {\n            \"chartId\": 62,\n            \"width\": 4,\n            \"height\": 50\n        },\n        \"type\": \"CHART\",\n        \"id\": \"CHART-17f13246\",\n        \"children\": []\n    },\n    \"CHART-729324f6\": {\n        \"meta\": {\n            \"chartId\": 63,\n            \"width\": 4,\n            \"height\": 50\n        },\n        \"type\": \"CHART\",\n        \"id\": \"CHART-729324f6\",\n        \"children\": []\n    },\n    \"COLUMN-25a865d6\": {\n        \"meta\": {\n            \"width\": 4,\n            \"background\": \"BACKGROUND_TRANSPARENT\"\n        },\n        \"type\": \"COLUMN\",\n        \"id\": \"COLUMN-25a865d6\",\n        \"children\": [\n            \"ROW-cc97c6ac\",\n            \"CHART-e2cb4997\"\n        ]\n    },\n    \"COLUMN-4557b6ba\": {\n        \"meta\": {\n            \"width\": 8,\n            \"background\": \"BACKGROUND_TRANSPARENT\"\n        },\n        \"type\": \"COLUMN\",\n        \"id\": \"COLUMN-4557b6ba\",\n        \"children\": [\n            \"ROW-d2e78e59\",\n            \"CHART-e9cd8f0b\"\n        ]\n    },\n    \"GRID_ID\": {\n        \"type\": \"GRID\",\n        \"id\": \"GRID_ID\",\n        \"children\": [\n            \"ROW-8515ace3\",\n            \"ROW-1890385f\",\n            \"ROW-f0b64094\",\n            \"ROW-be9526b8\"\n        ]\n    },\n    \"HEADER_ID\": {\n        \"meta\": {\n            \"text\": \"Births\"\n        },\n        \"type\": \"HEADER\",\n        \"id\": \"HEADER_ID\"\n    },\n    \"MARKDOWN-00178c27\": {\n        \"meta\": {\n            \"width\": 5,\n            \"code\": \"<div style=\\\\\"text-align:center\\\\\">\\\\n <h1>Birth Names Dashboard</h1>\\\\n <p>\\\\n The source dataset came from\\\\n <a href=\\\\\"https://github.com/hadley/babynames\\\\\" target=\\\\\"_blank\\\\\">[here]</a>\\\\n </p>\\\\n <img src=\\\\\"/static/assets/images/babytux.jpg\\\\\">\\\\n</div>\\\\n\",\n            \"height\": 38\n        },\n        \"type\": \"MARKDOWN\",\n        \"id\": \"MARKDOWN-00178c27\",\n        \"children\": []\n    },\n    \"ROOT_ID\": {\n        \"type\": \"ROOT\",\n        \"id\": \"ROOT_ID\",\n        \"children\": [\n            \"GRID_ID\"\n        ]\n    },\n    \"ROW-1890385f\": {\n        \"meta\": {\n            \"background\": \"BACKGROUND_TRANSPARENT\"\n        },\n        \"type\": \"ROW\",\n        \"id\": \"ROW-1890385f\",\n        \"children\": [\n            \"CHART-e440d205\",\n            \"CHART-0dd270f0\",\n            \"CHART-a3c21bcc\"\n        ]\n    },\n    \"ROW-8515ace3\": {\n        \"meta\": {\n            \"background\": \"BACKGROUND_TRANSPARENT\"\n        },\n        \"type\": \"ROW\",\n        \"id\": \"ROW-8515ace3\",\n        \"children\": [\n            \"COLUMN-25a865d6\",\n            \"COLUMN-4557b6ba\"\n        ]\n    },\n    \"ROW-be9526b8\": {\n        \"meta\": {\n            \"background\": \"BACKGROUND_TRANSPARENT\"\n        },\n        \"type\": \"ROW\",\n        \"id\": \"ROW-be9526b8\",\n        \"children\": [\n            \"CHART-985bfd1e\",\n            \"CHART-17f13246\",\n            \"CHART-729324f6\"\n        ]\n    },\n    \"ROW-cc97c6ac\": {\n        \"meta\": {\n            \"background\": \"BACKGROUND_TRANSPARENT\"\n        },\n        \"type\": \"ROW\",\n        \"id\": \"ROW-cc97c6ac\",\n        \"children\": [\n            \"CHART-976960a5\",\n            \"CHART-58575537\"\n        ]\n    },\n    \"ROW-d2e78e59\": {\n        \"meta\": {\n            \"background\": \"BACKGROUND_TRANSPARENT\"\n        },\n        \"type\": \"ROW\",\n        \"id\": \"ROW-d2e78e59\",\n        \"children\": [\n            \"MARKDOWN-00178c27\",\n            \"CHART-59444e0b\"\n        ]\n    },\n    \"ROW-f0b64094\": {\n        \"meta\": {\n            \"background\": \"BACKGROUND_TRANSPARENT\"\n        },\n        \"type\": \"ROW\",\n        \"id\": \"ROW-f0b64094\",\n        \"children\": [\n            \"CHART-e8774b49\"\n        ]\n    },\n    \"DASHBOARD_VERSION_KEY\": \"v2\"\n}\n        \"\"\")\n    pos = json.loads(js)\n    # dashboard v2 doesn't allow add markup slice\n    dash.slices = [slc for slc in slices if slc.viz_type != 'markup']\n    update_slice_ids(pos, dash.slices)\n    dash.dashboard_title = 'Births'\n    dash.position_json = json.dumps(pos, indent=4)\n    dash.slug = 'births'\n    db.session.merge(dash)\n    db.session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef refresh_datasources(self, refreshAll=True):\n        session = db.session()\n        DruidCluster = ConnectorRegistry.sources['druid'].cluster_class\n        for cluster in session.query(DruidCluster).all():\n            cluster_name = cluster.cluster_name\n            valid_cluster = True\n            try:\n                cluster.refresh_datasources(refreshAll=refreshAll)\n            except Exception as e:\n                valid_cluster = False\n                flash(\n                    \"Error while processing cluster '{}'\\n{}\".format(\n                        cluster_name, utils.error_msg_from_exception(e)),\n                    'danger')\n                logging.exception(e)\n                pass\n            if valid_cluster:\n                cluster.metadata_last_refreshed = datetime.now()\n                flash(\n                    _('Refreshed metadata from cluster [{}]').format(\n                        cluster.cluster_name),\n                    'info')\n        session.commit()\n        return redirect('/druiddatasourcemodelview/list/')", "response": "endpoint that refreshes druid datasources metadata"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a positive integer into a reversed linked list.", "response": "def convert_to_list(number: int) -> Node:\n    \"\"\"\n        converts a positive integer into a (reversed) linked list.\n        for example: give 112\n        result 2 -> 1 -> 1\n    \"\"\"\n    if number >= 0:\n        head = Node(0)\n        current = head\n        remainder = number % 10\n        quotient = number // 10\n\n        while quotient != 0:\n            current.next = Node(remainder)\n            current = current.next\n            remainder = quotient % 10\n            quotient //= 10\n        current.next = Node(remainder)\n        return head.next\n    else:\n        print(\"number must be positive!\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting the non - negative number list into a string.", "response": "def convert_to_str(l: Node) -> str:\n    \"\"\"\n        converts the non-negative number list into a string.\n    \"\"\"\n    result = \"\"\n    while l:\n        result += str(l.val)\n        l = l.next\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the length of the longest consecutive node in the tree.", "response": "def longest_consecutive(root):\n    \"\"\"\n    :type root: TreeNode\n    :rtype: int\n    \"\"\"\n    if root is None:\n        return 0\n    max_len = 0\n    dfs(root, 0, root.val, max_len)\n    return max_len"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef three_sum(array):\n    res = set()\n    array.sort()\n    for i in range(len(array) - 2):\n        if i > 0 and array[i] == array[i - 1]:\n            continue\n        l, r = i + 1, len(array) - 1\n        while l < r:\n            s = array[i] + array[l] + array[r]\n            if s > 0:\n                r -= 1\n            elif s < 0:\n                l += 1\n            else:\n                # found three sum\n                res.add((array[i], array[l], array[r]))\n\n                # remove duplicates\n                while l < r and array[l] == array[l + 1]:\n                    l += 1\n\n                while l < r and array[r] == array[r - 1]:\n                    r -= 1\n\n                l += 1\n                r -= 1\n    return res", "response": "returns a set of tuples that are three summed in the list"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntops sort recursive function.", "response": "def top_sort_recursive(graph):\n    \"\"\" Time complexity is the same as DFS, which is O(V + E)\n        Space complexity: O(V)\n    \"\"\"\n    order, enter, state = [], set(graph), {}\n    \n    def dfs(node):\n        state[node] = GRAY\n        #print(node)\n        for k in graph.get(node, ()):\n            sk = state.get(k, None)\n            if sk == GRAY:\n                raise ValueError(\"cycle\")\n            if sk == BLACK:\n                continue\n            enter.discard(k)\n            dfs(k)\n        order.append(node)\n        state[node] = BLACK\n        \n    while enter: dfs(enter.pop())\n    return order"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef top_sort(graph):\n    order, enter, state = [], set(graph), {}\n    \n    def is_ready(node):\n        lst = graph.get(node, ())\n        if len(lst) == 0:\n            return True\n        for k in lst:\n            sk = state.get(k, None)\n            if sk == GRAY: \n                raise ValueError(\"cycle\")\n            if sk != BLACK:\n                return False\n        return True\n        \n    while enter:\n        node = enter.pop()\n        stack = []\n        while True:\n            state[node] = GRAY\n            stack.append(node)\n            for k in graph.get(node, ()):\n                sk = state.get(k, None)\n                if sk == GRAY: \n                    raise ValueError(\"cycle\")\n                if sk == BLACK: \n                    continue\n                enter.discard(k)\n                stack.append(k)\n            while stack and is_ready(stack[-1]):\n                node = stack.pop()\n                order.append(node)\n                state[node] = BLACK\n            if len(stack) == 0:\n                break\n            node = stack.pop()\n        \n    return order", "response": "Time complexity is the same as DFS, which is O(V + E)\n        Space complexity: O(V)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the maximum product of the two lists of log entries.", "response": "def max_product(nums):\n    \"\"\"\n    :type nums: List[int]\n    :rtype: int\n    \"\"\"\n    lmin = lmax = gmax = nums[0]\n    for i in range(len(nums)):\n        t1 = nums[i] * lmax\n        t2 = nums[i] * lmin\n        lmax = max(max(t1, t2), nums[i])\n        lmin = min(min(t1, t2), nums[i])\n        gmax = max(gmax, lmax)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef text_justification(words, max_width):\n    '''\n    :type words: list\n    :type max_width: int\n    :rtype: list\n    '''\n    ret = []  # return value\n    row_len = 0  # current length of strs in a row\n    row_words = []  # current words in a row\n    index = 0  # the index of current word in words\n    is_first_word = True  # is current word the first in a row\n    while index < len(words):\n        while row_len <= max_width and index < len(words):\n            if len(words[index]) > max_width:\n                raise ValueError(\"there exists word whose length is larger than max_width\")\n            tmp = row_len\n            row_words.append(words[index])\n            tmp += len(words[index])\n            if not is_first_word:\n                tmp += 1  # except for the first word, each word should have at least a ' ' before it.\n            if tmp > max_width:\n                row_words.pop()\n                break\n            row_len = tmp\n            index += 1\n            is_first_word = False\n        # here we have already got a row of str , then we should supplement enough ' ' to make sure the length is max_width.\n        row = \"\"\n        # if the row is the last\n        if index == len(words):\n            for word in row_words:\n                row += (word + ' ')\n            row = row[:-1]\n            row += ' ' * (max_width - len(row))\n        # not the last row and more than one word\n        elif len(row_words) != 1:\n            space_num = max_width - row_len\n            space_num_of_each_interval = space_num // (len(row_words) - 1)\n            space_num_rest = space_num - space_num_of_each_interval * (len(row_words) - 1)\n            for j in range(len(row_words)):\n                row += row_words[j]\n                if j != len(row_words) - 1:\n                    row += ' ' * (1 + space_num_of_each_interval)\n                if space_num_rest > 0:\n                    row += ' '\n                    space_num_rest -= 1\n        # row with only one word\n        else:\n            row += row_words[0]\n            row += ' ' * (max_width - len(row))\n        ret.append(row)\n        # after a row , reset those value\n        row_len = 0\n        row_words = []\n        is_first_word = True\n    return ret", "response": "This function will take a list of words and returns a list of all the words in the order they appear in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cycle_sort(arr):\n    len_arr = len(arr)\n    # Finding cycle to rotate.\n    for cur in range(len_arr - 1):\n        item = arr[cur]\n\n        # Finding an indx to put items in.\n        index = cur\n        for i in range(cur + 1, len_arr):\n            if arr[i] < item:\n                index += 1\n\n        # Case of there is not a cycle\n        if index == cur:\n            continue\n\n        # Putting the item immediately right after the duplicate item or on the right.\n        while item == arr[index]:\n            index += 1\n        arr[index], item = item, arr[index]\n\n        # Rotating the remaining cycle.\n        while index != cur:\n\n            # Finding where to put the item.\n            index = cur\n            for i in range(cur + 1, len_arr):\n                if arr[i] < item:\n                    index += 1\n\n            # After item is duplicated, put it in place or put it there.\n            while item == arr[index]:\n                index += 1\n            arr[index], item = item, arr[index]\n    return arr", "response": "This function sorts the array by cycle."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cocktail_shaker_sort(arr):\n\n    def swap(i, j):\n        arr[i], arr[j] = arr[j], arr[i]\n\n    n = len(arr)\n    swapped = True\n    while swapped:\n        swapped = False\n        for i in range(1, n):\n            if arr[i - 1] > arr[i]:\n                swap(i - 1, i)\n                swapped = True\n        if swapped == False:\n            return arr\n        swapped = False\n        for i in range(n-1,0,-1):\n            if arr[i - 1] > arr[i]:\n                swap(i - 1, i)\n                swapped = True\n    return arr", "response": "Cocktail_shaker_sort Sorting a given array of bubble sort\n    \n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reconstruct_queue(people):\n    queue = []\n    people.sort(key=lambda x: (-x[0], x[1]))\n    for h, k in people:\n        queue.insert(k, [h, k])\n    return queue", "response": "Reconstructs the queue of the given list of people."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef min_depth(self, root):\n    if root is None:\n        return 0\n    if root.left is not None or root.right is not None:\n        return max(self.minDepth(root.left), self.minDepth(root.right))+1\n    return min(self.minDepth(root.left), self.minDepth(root.right)) + 1", "response": "Returns the minimum depth of a node in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if a sequence of strings is one edit.", "response": "def is_one_edit(s, t):\n    \"\"\"\n    :type s: str\n    :type t: str\n    :rtype: bool\n    \"\"\"\n    if len(s) > len(t):\n        return is_one_edit(t, s)\n    if len(t) - len(s) > 1 or t == s:\n        return False\n    for i in range(len(s)):\n        if s[i] != t[i]:\n            return s[i+1:] == t[i+1:] or s[i:] == t[i+1:]\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nshells Sort WorkItem Complexity O ( n^2 )", "response": "def shell_sort(arr):\n    ''' Shell Sort\n        Complexity: O(n^2)\n    '''\n    n = len(arr)\n    # Initialize size of the gap\n    gap = n//2\n    \n    while gap > 0:\n        y_index = gap\n        while y_index < len(arr):\n            y = arr[y_index]\n            x_index = y_index - gap\n            while x_index >= 0 and y < arr[x_index]:\n                arr[x_index + gap] = arr[x_index]\n                x_index = x_index - gap\n            arr[x_index + gap] = y\n            y_index = y_index + 1\n        gap = gap//2\n        \n    return arr"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns prefix common of 2 strings", "response": "def common_prefix(s1, s2):\n    \"Return prefix common of 2 strings\"\n    if not s1 or not s2:\n        return \"\"\n    k = 0\n    while s1[k] == s2[k]:\n        k = k + 1\n        if k >= len(s1) or k >= len(s2):\n            return s1[0:k]\n    return s1[0:k]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef euler_totient(n):\n    result = n;\n    for i in range(2, int(n ** 0.5) + 1):\n        if n % i == 0:\n            while n % i == 0:\n                n //= i\n            result -= result // i\n    if n > 1:\n        result -= result // n;\n    return result;", "response": "Euler s totient function or Phi function. Time Complexity is O ( sqrt ( n )."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fib_list(n):\n\n    # precondition\n    assert n >= 0, 'n must be a positive integer'\n\n    list_results = [0, 1]\n    for i in range(2, n+1):\n        list_results.append(list_results[i-1] + list_results[i-2])\n    return list_results[n]", "response": "This function computes the n - th fibbonacci number\n    very quick. approximate O ( n )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef subsets(nums):\n    n = len(nums)\n    total = 1 << n\n    res = set()\n\n    for i in range(total):\n        subset = tuple(num for j, num in enumerate(nums) if i & 1 << j)\n        res.add(subset)\n\n    return res", "response": "Returns a set of subsets of the given list of integers."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lcs(s1, s2, i, j):\n    if i == 0 or j == 0:\n        return 0\n    elif s1[i - 1] == s2[j - 1]:\n        return 1 + lcs(s1, s2, i - 1, j - 1)\n    else:\n        return max(lcs(s1, s2, i - 1, j), lcs(s1, s2, i, j - 1))", "response": "Returns the length of longest common subsequence among the two given strings s1 and s2."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the root node of the tree that is a leaf node of the tree", "response": "def lca(root, p, q):\n    \"\"\"\n    :type root: TreeNode\n    :type p: TreeNode\n    :type q: TreeNode\n    :rtype: TreeNode\n    \"\"\"\n    if root is None or root is p or root is q:\n        return root\n    left = lca(root.left, p, q)\n    right = lca(root.right, p, q)\n    if left is not None and right is not None:\n        return root\n    return left if left else right"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the lowest common ancestor of two nodes.", "response": "def lowest_common_ancestor(root, p, q):\n    \"\"\"\n    :type root: Node\n    :type p: Node\n    :type q: Node\n    :rtype: Node\n    \"\"\"\n    while root:\n        if p.val > root.val < q.val:\n            root = root.right\n        elif p.val < root.val > q.val:\n            root = root.left\n        else:\n            return root"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef climb_stairs(n):\n    arr = [1, 1]\n    for _ in range(1, n):\n        arr.append(arr[-1] + arr[-2])\n    return arr[-1]", "response": "climb_stairs returns the n - th climb_stairs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_nth_digit(n):\n    length = 1\n    count = 9\n    start = 1\n    while n > length * count:\n        n -= length * count\n        length += 1\n        count *= 10\n        start *= 10\n    start += (n-1) / length\n    s = str(start)\n    return int(s[(n-1) % length])", "response": "find the nth digit of given number"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hailstone(n):\n\n  sequence = [n]\n  while n > 1:\n    if n%2 != 0:\n      n = 3*n + 1\n    else: \n      n = int(n/2)\n    sequence.append(n)\n  return sequence", "response": "Return the hailstone sequence from n to 1\n     n"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef word_break(s, word_dict):\n    dp = [False] * (len(s)+1)\n    dp[0] = True\n    for i in range(1, len(s)+1):\n        for j in range(0, i):\n            if dp[j] and s[j:i] in word_dict:\n                dp[i] = True\n                break\n    return dp[-1]", "response": "Returns True if s is a valid word - break."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prime_check(n):\n\n    if n <= 1:\n        return False\n    if n == 2 or n == 3:\n        return True\n    if n % 2 == 0 or n % 3 == 0:\n        return False\n    j = 5\n    while j * j <= n:\n        if n % j == 0 or n % (j + 2) == 0:\n            return False\n        j += 6\n    return True", "response": "Check if n is a prime number\n    Else return False."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds the length of the longest substring without repeating characters.", "response": "def longest_non_repeat_v1(string):\n    \"\"\"\n    Find the length of the longest substring\n    without repeating characters.\n    \"\"\"\n    if string is None:\n        return 0\n    dict = {}\n    max_length = 0\n    j = 0\n    for i in range(len(string)):\n        if string[i] in dict:\n            j = max(dict[string[i]], j)\n        dict[string[i]] = i + 1\n        max_length = max(max_length, i - j + 1)\n    return max_length"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds the length of the longest substring without repeating characters.", "response": "def longest_non_repeat_v2(string):\n    \"\"\"\n    Find the length of the longest substring\n    without repeating characters.\n    Uses alternative algorithm.\n    \"\"\"\n    if string is None:\n        return 0\n    start, max_len = 0, 0\n    used_char = {}\n    for index, char in enumerate(string):\n        if char in used_char and start <= used_char[char]:\n            start = used_char[char] + 1\n        else:\n            max_len = max(max_len, index - start + 1)\n        used_char[char] = index\n    return max_len"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding the length of the longest substring without repeating characters. Return max_len and the substring as a tuple", "response": "def get_longest_non_repeat_v1(string):\n    \"\"\"\n    Find the length of the longest substring\n    without repeating characters.\n    Return max_len and the substring as a tuple\n    \"\"\"\n    if string is None:\n        return 0, ''\n    sub_string = ''\n    dict = {}\n    max_length = 0\n    j = 0\n    for i in range(len(string)):\n        if string[i] in dict:\n            j = max(dict[string[i]], j)\n        dict[string[i]] = i + 1\n        if i - j + 1 > max_length:\n            max_length = i - j + 1\n            sub_string = string[j: i + 1]\n    return max_length, sub_string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the length of the longest substring without repeating characters.", "response": "def get_longest_non_repeat_v2(string):\n    \"\"\"\n    Find the length of the longest substring\n    without repeating characters.\n    Uses alternative algorithm.\n    Return max_len and the substring as a tuple\n    \"\"\"\n    if string is None:\n        return 0, ''\n    sub_string = ''\n    start, max_len = 0, 0\n    used_char = {}\n    for index, char in enumerate(string):\n        if char in used_char and start <= used_char[char]:\n            start = used_char[char] + 1\n        else:\n            if index - start + 1 > max_len:\n                max_len = index - start + 1\n                sub_string = string[start: index + 1]\n        used_char[char] = index\n    return max_len, sub_string"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npushing the item in the priority queue.", "response": "def push(self, item, priority=None):\n        \"\"\"Push the item in the priority queue.\n        if priority is not given, priority is set to the value of item.\n        \"\"\"\n        priority = item if priority is None else priority\n        node = PriorityQueueNode(item, priority)\n        for index, current in enumerate(self.priority_queue_list):\n            if current.priority < node.priority:\n                self.priority_queue_list.insert(index, node)\n                return\n        # when traversed complete queue\n        self.priority_queue_list.append(node)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating factorial iteratively. If mod is not None, then return (n! % mod) Time Complexity - O(n)", "response": "def factorial(n, mod=None):\n    \"\"\"Calculates factorial iteratively.\n    If mod is not None, then return (n! % mod)\n    Time Complexity - O(n)\"\"\"\n    if not (isinstance(n, int) and n >= 0):\n        raise ValueError(\"'n' must be a non-negative integer.\")\n    if mod is not None and not (isinstance(mod, int) and mod > 0):\n        raise ValueError(\"'mod' must be a positive integer\")\n    result = 1\n    if n == 0:\n        return 1\n    for i in range(2, n+1):\n        result *= i\n        if mod:\n            result %= mod\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate factorial recursively. If mod is not None, then return (n! % mod) Time Complexity - O(n)", "response": "def factorial_recur(n, mod=None):\n    \"\"\"Calculates factorial recursively.\n    If mod is not None, then return (n! % mod)\n    Time Complexity - O(n)\"\"\"\n    if not (isinstance(n, int) and n >= 0):\n        raise ValueError(\"'n' must be a non-negative integer.\")\n    if mod is not None and not (isinstance(mod, int) and mod > 0):\n        raise ValueError(\"'mod' must be a positive integer\")\n    if n == 0:\n        return 1\n    result = n * factorial(n - 1, mod)\n    if mod:\n        result %= mod\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef selection_sort(arr, simulation=False):\n    iteration = 0\n    if simulation:\n        print(\"iteration\",iteration,\":\",*arr)\n        \n    for i in range(len(arr)):\n        minimum = i\n        \n        for j in range(i + 1, len(arr)):\n            # \"Select\" the correct value\n            if arr[j] < arr[minimum]:\n                minimum = j\n\n        arr[minimum], arr[i] = arr[i], arr[minimum]\n        \n        if simulation:\n                iteration = iteration + 1\n                print(\"iteration\",iteration,\":\",*arr)\n            \n    return arr", "response": "Selection Sort\nCTYPE Complexity is O ( n^2 )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_dups(head):\n    hashset = set()\n    prev = Node()\n    while head:\n        if head.val in hashset:\n            prev.next = head.next\n        else:\n            hashset.add(head.val)\n            prev = head\n        head = head.next", "response": "Removes duplicate entries from the head node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving all the dups from the head sequence that are not in the wothout set.", "response": "def remove_dups_wothout_set(head):\n    \"\"\"\n    Time Complexity: O(N^2)\n    Space Complexity: O(1)\n    \"\"\"\n    current = head\n    while current:\n        runner = current\n        while runner.next:\n            if runner.next.val == current.val:\n                runner.next = runner.next.next\n            else:\n                runner = runner.next\n        current = current.next"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntransplants u with v", "response": "def transplant(self, node_u, node_v):\n        \"\"\"\n        replace u with v\n        :param node_u: replaced node\n        :param node_v: \n        :return: None\n        \"\"\"\n        if node_u.parent is None:\n            self.root = node_v\n        elif node_u is node_u.parent.left:\n            node_u.parent.left = node_v\n        elif node_u is node_u.parent.right:\n            node_u.parent.right = node_v\n        # check is node_v is None \n        if node_v:\n            node_v.parent = node_u.parent"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef maximum(self, node):\n        temp_node = node\n        while temp_node.right is not None:\n            temp_node = temp_node.right\n        return temp_node", "response": "find the maximum node in the tree"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef minimum(self, node):\n        temp_node = node\n        while temp_node.left:\n            temp_node = temp_node.left\n        return temp_node", "response": "find the minimum node when node regards as a root node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef modular_exponential(base, exponent, mod):\n    if exponent < 0:\n        raise ValueError(\"Exponent must be positive.\")\n    base %= mod\n    result = 1\n\n    while exponent > 0:\n        # If the last bit is 1, add 2^k.\n        if exponent & 1:\n            result = (result * base) % mod\n        exponent = exponent >> 1\n        # Utilize modular multiplication properties to combine the computed mod C values.\n        base = (base * base) % mod\n\n    return result", "response": "Computes the modular exponential of base and exponent."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if the given list of intervals can attend meetings.", "response": "def can_attend_meetings(intervals):\n    \"\"\"\n    :type intervals: List[Interval]\n    :rtype: bool\n    \"\"\"\n    intervals = sorted(intervals, key=lambda x: x.start)\n    for i in range(1, len(intervals)):\n        if intervals[i].start < intervals[i - 1].end:\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete a node from the tree.", "response": "def delete_node(self, root, key):\n        \"\"\"\n        :type root: TreeNode\n        :type key: int\n        :rtype: TreeNode\n        \"\"\"\n        if not root: return None\n\n        if root.val == key:\n            if root.left:\n                # Find the right most leaf of the left sub-tree\n                left_right_most = root.left\n                while left_right_most.right:\n                    left_right_most = left_right_most.right\n                # Attach right child to the right of that leaf\n                left_right_most.right = root.right\n                # Return left child instead of root, a.k.a delete root\n                return root.left\n            else:\n                return root.right\n        # If left or right child got deleted, the returned root is the child of the deleted node.\n        elif root.val > key:\n            root.left = self.deleteNode(root.left, key)\n        else:\n            root.right = self.deleteNode(root.right, key)\n        return root"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef simplify_path(path):\n    skip = {'..', '.', ''}\n    stack = []\n    paths = path.split('/')\n    for tok in paths:\n        if tok == '..':\n            if stack:\n                stack.pop()\n        elif tok not in skip:\n            stack.append(tok)\n    return '/' + '/'.join(stack)", "response": "Simplifies a path into a single node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef subsets(nums):\n    def backtrack(res, nums, stack, pos):\n        if pos == len(nums):\n            res.append(list(stack))\n        else:\n            # take nums[pos]\n            stack.append(nums[pos])\n            backtrack(res, nums, stack, pos+1)\n            stack.pop()\n            # dont take nums[pos]\n            backtrack(res, nums, stack, pos+1)\n\n    res = []\n    backtrack(res, nums, [], 0)\n    return res", "response": "O ( n ) subsets of a sequence of numbers."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef jump_search(arr,target):\n    n = len(arr)\n    block_size = int(math.sqrt(n))\n    block_prev = 0\n    block= block_size\n\n    # return -1 means that array doesn't contain taget value\n    # find block that contains target value\n    \n    if arr[n - 1] < target:\n        return -1  \n    while block <= n and arr[block - 1] < target:\n        block_prev = block\n        block += block_size\n\n    # find target value in block\n    \n    while arr[block_prev] < target :\n        block_prev += 1\n        if block_prev == min(block, n) :\n            return -1\n\n    # if there is target value in array, return it\n    \n    if arr[block_prev] == target :\n        return block_prev\n    else :\n        return -1", "response": "Jump search for the taget value in the array that contains the target value and return the first target value in that block."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nflattening an iterable into one dimensional generator.", "response": "def flatten_iter(iterable):\n    \"\"\"\n    Takes as input multi dimensional iterable and\n    returns generator which produces one dimensional output.\n    \"\"\"\n    for element in iterable:\n        if isinstance(element, Iterable):\n            yield from flatten_iter(element)    \n        else:\n            yield element"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ladder_length(begin_word, end_word, word_list):\n    if len(begin_word) != len(end_word):\n        return -1   # not possible\n\n    if begin_word == end_word:\n        return 0\n\n    # when only differ by 1 character\n    if sum(c1 != c2 for c1, c2 in zip(begin_word, end_word)) == 1:\n        return 1\n\n    begin_set = set()\n    end_set = set()\n    begin_set.add(begin_word)\n    end_set.add(end_word)\n    result = 2\n    while begin_set and end_set:\n\n        if len(begin_set) > len(end_set):\n            begin_set, end_set = end_set, begin_set\n\n        next_begin_set = set()\n        for word in begin_set:\n            for ladder_word in word_range(word):\n                if ladder_word in end_set:\n                    return result\n                if ladder_word in word_list:\n                    next_begin_set.add(ladder_word)\n                    word_list.remove(ladder_word)\n        begin_set = next_begin_set\n        result += 1\n        # print(begin_set)\n        # print(result)\n    return -1", "response": "This function returns the length of a single word in a set of words."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convolved(iterable, kernel_size=1, stride=1, padding=0, default_value=None):\n    # Input validation and error messages\n    if not hasattr(iterable, '__iter__'):\n        raise ValueError(\n            \"Can't iterate on object.\".format(\n                iterable))\n    if stride < 1:\n        raise ValueError(\n            \"Stride must be of at least one. Got `stride={}`.\".format(\n                stride))\n    if not (padding in ['SAME', 'VALID'] or type(padding) in [int]):\n        raise ValueError(\n            \"Padding must be an integer or a string with value `SAME` or `VALID`.\")\n    if not isinstance(padding, str):\n        if padding < 0:\n            raise ValueError(\n                \"Padding must be of at least zero. Got `padding={}`.\".format(\n                    padding))\n    else:\n        if padding == 'SAME':\n            padding = kernel_size // 2\n        elif padding == 'VALID':\n            padding = 0\n    if not type(iterable) == list:\n        iterable = list(iterable)\n\n    # Add padding to iterable\n    if padding > 0:\n        pad = [default_value] * padding\n        iterable = pad + list(iterable) + pad\n\n    # Fill missing value to the right\n    remainder = (kernel_size - len(iterable)) % stride\n    extra_pad = [default_value] * remainder\n    iterable = iterable + extra_pad\n\n    i = 0\n    while True:\n        if i > len(iterable) - kernel_size:\n            break\n        yield iterable[i:i + kernel_size]\n        i += stride", "response": "Iterate over the items in the given iterable and return the convolution window."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts integers to a list of integers to fit the number of dimensions.", "response": "def dimensionize(maybe_a_list, nd=2):\n    \"\"\"Convert integers to a list of integers to fit the number of dimensions if\n    the argument is not already a list.\n\n    For example:\n    `dimensionize(3, nd=2)`\n        will produce the following result:\n        `(3, 3)`.\n    `dimensionize([3, 1], nd=2)`\n        will produce the following result:\n        `[3, 1]`.\n\n    For more information, refer to:\n    - https://github.com/guillaume-chevalier/python-conv-lib/blob/master/conv/conv.py\n    - https://github.com/guillaume-chevalier/python-conv-lib\n    - MIT License, Copyright (c) 2018 Guillaume Chevalier\n    \"\"\"\n    if not hasattr(maybe_a_list, '__iter__'):\n        # Argument is probably an integer so we map it to a list of size `nd`.\n        now_a_list = [maybe_a_list] * nd\n        return now_a_list\n    else:\n        # Argument is probably an `nd`-sized list.\n        return maybe_a_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the max number of sliding windows.", "response": "def max_sliding_window(nums, k):\n    \"\"\"\n    :type nums: List[int]\n    :type k: int\n    :rtype: List[int]\n    \"\"\"\n    if not nums:\n        return nums\n    queue = collections.deque()\n    res = []\n    for num in nums:\n        if len(queue) < k:\n            queue.append(num)\n        else:\n            res.append(max(queue))\n            queue.popleft()\n            queue.append(num)\n    res.append(max(queue))\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmerge intervals in the form of a list.", "response": "def merge_intervals(intervals):\n    \"\"\" Merge intervals in the form of a list. \"\"\"\n    if intervals is None:\n        return None\n    intervals.sort(key=lambda i: i[0])\n    out = [intervals.pop(0)]\n    for i in intervals:\n        if out[-1][-1] >= i[0]:\n            out[-1][-1] = max(out[-1][-1], i[-1])\n        else:\n            out.append(i)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmerges two intervals into one.", "response": "def merge(intervals):\n        \"\"\" Merge two intervals into one. \"\"\"\n        out = []\n        for i in sorted(intervals, key=lambda i: i.start):\n            if out and i.start <= out[-1].end:\n                out[-1].end = max(out[-1].end, i.end)\n            else:\n                out += i,\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting out the intervals.", "response": "def print_intervals(intervals):\n        \"\"\" Print out the intervals. \"\"\"\n        res = []\n        for i in intervals:\n            res.append(repr(i))\n        print(\"\".join(res))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrotating the entire array k times T ( n - O ( kk ) - > array", "response": "def rotate_v1(array, k):\n    \"\"\"\n    Rotate the entire array 'k' times\n    T(n)- O(nk)\n\n    :type array: List[int]\n    :type k: int\n    :rtype: void Do not return anything, modify array in-place instead.\n    \"\"\"\n    array = array[:]\n    n = len(array)\n    for i in range(k):      # unused variable is not a problem\n        temp = array[n - 1]\n        for j in range(n-1, 0, -1):\n            array[j] = array[j - 1]\n        array[0] = temp\n    return array"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrotating the array in - place by a given k - th element.", "response": "def rotate_v2(array, k):\n    \"\"\"\n    Reverse segments of the array, followed by the entire array\n    T(n)- O(n)\n    :type array: List[int]\n    :type k: int\n    :rtype: void Do not return anything, modify nums in-place instead.\n    \"\"\"\n    array = array[:]\n\n    def reverse(arr, a, b):\n        while a < b:\n            arr[a], arr[b] = arr[b], arr[a]\n            a += 1\n            b -= 1\n\n    n = len(array)\n    k = k % n\n    reverse(array, 0, n - k - 1)\n    reverse(array, n - k, n - 1)\n    reverse(array, 0, n - 1)\n    return array"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pacific_atlantic(matrix):\n    n = len(matrix)\n    if not n: return []\n    m = len(matrix[0])\n    if not m: return []\n    res = []\n    atlantic = [[False for _ in range (n)] for _ in range(m)]\n    pacific =  [[False for _ in range (n)] for _ in range(m)]\n    for i in range(n):\n        dfs(pacific, matrix, float(\"-inf\"), i, 0)\n        dfs(atlantic, matrix, float(\"-inf\"), i, m-1)\n    for i in range(m):\n        dfs(pacific, matrix, float(\"-inf\"), 0, i)\n        dfs(atlantic, matrix, float(\"-inf\"), n-1, i)\n    for i in range(n):\n        for j in range(m):\n            if pacific[i][j] and atlantic[i][j]:\n                res.append([i, j])\n    return res", "response": "Returns a list of the pacific and atlantic ones."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_palindrome(s):\n    i = 0\n    j = len(s)-1\n    while i < j:\n        while i < j and not s[i].isalnum():\n            i += 1\n        while i < j and not s[j].isalnum():\n            j -= 1\n        if s[i].lower() != s[j].lower():\n            return False\n        i, j = i+1, j-1\n    return True", "response": "Checks if a string is a palindrome."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plus_one_v1(digits):\n    digits[-1] = digits[-1] + 1\n    res = []\n    ten = 0\n    i = len(digits)-1\n    while i >= 0 or ten == 1:\n        summ = 0\n        if i >= 0:\n            summ += digits[i]\n        if ten:\n            summ += 1\n        res.append(summ % 10)\n        ten = summ // 10\n        i -= 1\n    return res[::-1]", "response": ":type digits: List[int]\n    :rtype: List[int]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rotate_right(head, k):\n    if not head or not head.next:\n        return head\n    current = head\n    length = 1\n    # count length of the list\n    while current.next:\n        current = current.next\n        length += 1\n    # make it circular\n    current.next = head\n    k = k % length\n    # rotate until length-k\n    for i in range(length-k):\n        current = current.next\n    head = current.next\n    current.next = None\n    return head", "response": "rotate the list node to the right k - degree"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the number of digits in a string.", "response": "def num_decodings(s):\n    \"\"\"\n    :type s: str\n    :rtype: int\n    \"\"\"\n    if not s or s[0] == \"0\":\n        return 0\n    wo_last, wo_last_two = 1, 1\n    for i in range(1, len(s)):\n        x = wo_last if s[i] != \"0\" else 0\n        y = wo_last_two if int(s[i-1:i+1]) < 27 and s[i-1] != \"0\" else 0\n        wo_last_two = wo_last\n        wo_last = x+y\n    return wo_last"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches the list of nums to find the target.", "response": "def search_range(nums, target):\n    \"\"\"\n    :type nums: List[int]\n    :type target: int\n    :rtype: List[int]\n    \"\"\"\n    low = 0\n    high = len(nums) - 1\n    while low <= high:\n        mid = low + (high - low) // 2\n        if target < nums[mid]:\n            high = mid - 1\n        elif target > nums[mid]:\n            low = mid + 1\n        else:\n            break\n\n    for j in range(len(nums) - 1, -1, -1):\n        if nums[j] == target:\n            return [mid, j]\n\n    return [-1, -1]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the first node in the chain that is not in the head node.", "response": "def first_cyclic_node(head):\n    \"\"\"\n    :type head: Node\n    :rtype: Node\n    \"\"\"\n    runner = walker = head\n    while runner and runner.next:\n        runner = runner.next.next\n        walker = walker.next\n        if runner is walker:\n            break\n\n    if runner is None or runner.next is None:\n        return None\n\n    walker = head\n    while runner is not walker:\n        runner, walker = runner.next, walker.next\n    return runner"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nheaping Sort that uses a max heap to sort an array in ascending order Complexity is O ( n log ( n )", "response": "def max_heap_sort(arr, simulation=False):\n    \"\"\" Heap Sort that uses a max heap to sort an array in ascending order\n        Complexity: O(n log(n))\n    \"\"\"\n    iteration = 0\n    if simulation:\n        print(\"iteration\",iteration,\":\",*arr)\n        \n    for i in range(len(arr) - 1, 0, -1):\n        iteration = max_heapify(arr, i, simulation, iteration)\n\n    if simulation:\n                iteration = iteration + 1\n                print(\"iteration\",iteration,\":\",*arr)\n    return arr"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nheaping Sort that uses a min heap to sort an array in ascending order", "response": "def min_heap_sort(arr, simulation=False):\n    \"\"\" Heap Sort that uses a min heap to sort an array in ascending order\n        Complexity: O(n log(n))\n    \"\"\"\n    iteration = 0\n    if simulation:\n        print(\"iteration\",iteration,\":\",*arr)\n        \n    for i in range(0, len(arr) - 1):\n        iteration = min_heapify(arr, i, simulation, iteration)\n\n    return arr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef min_heapify(arr, start, simulation, iteration):\n    # Offset last_parent by the start (last_parent calculated as if start index was 0)\n    # All array accesses need to be offset by start\n    end = len(arr) - 1\n    last_parent = (end - start - 1) // 2\n\n    # Iterate from last parent to first\n    for parent in range(last_parent, -1, -1):\n        current_parent = parent\n\n        # Iterate from current_parent to last_parent\n        while current_parent <= last_parent:\n            # Find lesser child of current_parent\n            child = 2 * current_parent + 1\n            if child + 1 <= end - start and arr[child + start] > arr[\n                child + 1 + start]:\n                child = child + 1\n            \n            # Swap if child is less than parent\n            if arr[child + start] < arr[current_parent + start]:\n                arr[current_parent + start], arr[child + start] = \\\n                    arr[child + start], arr[current_parent + start]\n                current_parent = child\n                if simulation:\n                    iteration = iteration + 1\n                    print(\"iteration\",iteration,\":\",*arr)\n            # If no swap occured, no need to keep iterating\n            else:\n                break\n    return iteration", "response": "Min heapify helper for min_heap_sort\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_key(k, seed=None):\n\n    def modinv(a, m):\n        \"\"\"calculate the inverse of a mod m\n        that is, find b such that (a * b) % m == 1\"\"\"\n        b = 1\n        while not (a * b) % m == 1:\n            b += 1\n        return b\n\n    def gen_prime(k, seed=None):\n        \"\"\"generate a prime with k bits\"\"\"\n\n        def is_prime(num):\n            if num == 2:\n                return True\n            for i in range(2, int(num ** 0.5) + 1):\n                if num % i == 0:\n                    return False\n            return True\n\n        random.seed(seed)\n        while True:\n            key = random.randrange(int(2 ** (k - 1)), int(2 ** k))\n            if is_prime(key):\n                return key\n\n    # size in bits of p and q need to add up to the size of n\n    p_size = k / 2\n    q_size = k - p_size\n    \n    e = gen_prime(k, seed)  # in many cases, e is also chosen to be a small constant\n    \n    while True:\n        p = gen_prime(p_size, seed)\n        if p % e != 1:\n            break\n    \n    while True:\n        q = gen_prime(q_size, seed)\n        if q % e != 1:\n            break\n    \n    n = p * q\n    l = (p - 1) * (q - 1)  # calculate totient function\n    d = modinv(e, l)\n    \n    return int(n), int(e), int(d)", "response": "generate a RSA key"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef square_root(n, epsilon=0.001):\n    guess = n / 2\n\n    while abs(guess * guess - n) > epsilon:\n        guess = (guess + (n / guess)) / 2\n\n    return guess", "response": "Return square root of n with maximum absolute error epsilon"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef counting_sort(arr):\n\n    m = min(arr)\n    # in case there are negative elements, change the array to all positive element\n    different = 0\n    if m < 0:\n        # save the change, so that we can convert the array back to all positive number\n        different = -m\n        for i in range(len(arr)):\n            arr[i] += -m\n    k = max(arr)\n    temp_arr = [0] * (k + 1)\n    for i in range(0, len(arr)):\n        temp_arr[arr[i]] = temp_arr[arr[i]] + 1\n    # temp_array[i] contain the times the number i appear in arr\n\n    for i in range(1, k + 1):\n        temp_arr[i] = temp_arr[i] + temp_arr[i - 1]\n    # temp_array[i] contain the number of element less than or equal i in arr\n\n    result_arr = arr.copy()\n    # creating a result_arr an put the element in a correct positon\n    for i in range(len(arr) - 1, -1, -1):\n        result_arr[temp_arr[arr[i]] - 1] = arr[i] - different\n        temp_arr[arr[i]] = temp_arr[arr[i]] - 1\n\n    return result_arr", "response": "Count the array which has no element greater than k\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the powerset of any iterable.", "response": "def powerset(iterable):\n    \"\"\"Calculate the powerset of any iterable.\n\n    For a range of integers up to the length of the given list,\n    make all possible combinations and chain them together as one object.\n    From https://docs.python.org/3/library/itertools.html#itertools-recipes\n    \"\"\"\n    \"list(powerset([1,2,3])) --> [(), (1,), (2,), (3,), (1,2), (1,3), (2,3), (1,2,3)]\"\n    s = list(iterable)\n    return chain.from_iterable(combinations(s, r) for r in range(len(s) + 1))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napproximate greedy algorithm for set - covering.", "response": "def greedy_set_cover(universe, subsets, costs):\n    \"\"\"Approximate greedy algorithm for set-covering. Can be used on large\n    inputs - though not an optimal solution.\n\n    Args:\n        universe (list): Universe of elements\n        subsets (dict): Subsets of U {S1:elements,S2:elements}\n        costs (dict): Costs of each subset in S - {S1:cost, S2:cost...}\n    \"\"\"\n    elements = set(e for s in subsets.keys() for e in subsets[s])\n    # elements don't cover universe -> invalid input for set cover\n    if elements != universe:\n        return None\n\n    # track elements of universe covered\n    covered = set()\n    cover_sets = []\n\n    while covered != universe:\n        min_cost_elem_ratio = float(\"inf\")\n        min_set = None\n        # find set with minimum cost:elements_added ratio\n        for s, elements in subsets.items():\n            new_elements = len(elements - covered)\n            # set may have same elements as already covered -> new_elements = 0\n            # check to avoid division by 0 error\n            if new_elements != 0:\n                cost_elem_ratio = costs[s] / new_elements\n                if cost_elem_ratio < min_cost_elem_ratio:\n                    min_cost_elem_ratio = cost_elem_ratio\n                    min_set = s\n        cover_sets.append(min_set)\n        # union\n        covered |= subsets[min_set]\n    return cover_sets"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef num_trees(n):\n    dp = [0] * (n+1)\n    dp[0] = 1\n    dp[1] = 1\n    for i in range(2, n+1):\n        for j in range(i+1):\n            dp[i] += dp[i-j] * dp[j-1]\n    return dp[-1]", "response": "Returns the number of trees in the n - th tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds the next entry to the queue and returns the average of the entries", "response": "def next(self, val):\n        \"\"\"\n        :type val: int\n        :rtype: float\n        \"\"\"\n        self.queue.append(val)\n        return sum(self.queue) / len(self.queue)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef n_sum(n, nums, target, **kv):\n\n    def sum_closure_default(a, b):\n        return a + b\n\n    def compare_closure_default(num, target):\n        \"\"\" above, below, or right on? \"\"\"\n        if num < target:\n            return -1\n        elif num > target:\n            return 1\n        else:\n            return 0\n\n    def same_closure_default(a, b):\n        return a == b\n\n    def n_sum(n, nums, target):\n        if n == 2:      # want answers with only 2 terms? easy!\n            results = two_sum(nums, target)\n        else:\n            results = []\n            prev_num = None\n            for index, num in enumerate(nums):\n                if prev_num is not None and \\\n                   same_closure(prev_num, num):\n                    continue\n\n                prev_num = num\n                n_minus1_results = (\n                    n_sum(                      # recursive call\n                        n - 1,                  # a\n                        nums[index + 1:],       # b\n                        target - num            # c\n                        )   # x = n_sum( a, b, c )\n                    )   # n_minus1_results = x\n\n                n_minus1_results = (\n                    append_elem_to_each_list(num, n_minus1_results)\n                    )\n                results += n_minus1_results\n        return union(results)\n\n    def two_sum(nums, target):\n        nums.sort()\n        lt = 0\n        rt = len(nums) - 1\n        results = []\n        while lt < rt:\n            sum_ = sum_closure(nums[lt], nums[rt])\n            flag = compare_closure(sum_, target)\n            if flag == -1:\n                lt += 1\n            elif flag == 1:\n                rt -= 1\n            else:\n                results.append(sorted([nums[lt], nums[rt]]))\n                lt += 1\n                rt -= 1\n                while (lt < len(nums) and\n                       same_closure(nums[lt - 1], nums[lt])):\n                    lt += 1\n                while (0 <= rt and\n                       same_closure(nums[rt], nums[rt + 1])):\n                    rt -= 1\n        return results\n\n    def append_elem_to_each_list(elem, container):\n        results = []\n        for elems in container:\n            elems.append(elem)\n            results.append(sorted(elems))\n        return results\n\n    def union(duplicate_results):\n        results = []\n\n        if len(duplicate_results) != 0:\n            duplicate_results.sort()\n            results.append(duplicate_results[0])\n            for result in duplicate_results[1:]:\n                if results[-1] != result:\n                    results.append(result)\n\n        return results\n\n    sum_closure = kv.get('sum_closure', sum_closure_default)\n    same_closure = kv.get('same_closure', same_closure_default)\n    compare_closure = kv.get('compare_closure', compare_closure_default)\n    nums.sort()\n    return n_sum(n, nums, target)", "response": "Return a list of n elements with n = target."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pattern_match(pattern, string):\n    def backtrack(pattern, string, dic):\n\n        if len(pattern) == 0 and len(string) > 0:\n            return False\n\n        if len(pattern) == len(string) == 0:\n            return True\n\n        for end in range(1, len(string)-len(pattern)+2):\n            if pattern[0] not in dic and string[:end] not in dic.values():\n                dic[pattern[0]] = string[:end]\n                if backtrack(pattern[1:], string[end:], dic):\n                    return True\n                del dic[pattern[0]]\n            elif pattern[0] in dic and dic[pattern[0]] == string[:end]:\n                if backtrack(pattern[1:], string[end:], dic):\n                    return True\n        return False\n\n    return backtrack(pattern, string, {})", "response": "Returns True if pattern matches string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bogo_sort(arr, simulation=False):\n    \n    iteration = 0\n    if simulation:\n        print(\"iteration\",iteration,\":\",*arr)\n    \n    def is_sorted(arr):\n        #check the array is inorder\n        i = 0\n        arr_len = len(arr)\n        while i+1 < arr_len:\n            if arr[i] > arr[i+1]:\n                return False\n            i += 1\n            \n\n        return True\n    while not is_sorted(arr):\n        random.shuffle(arr)\n        \n        if simulation:\n            iteration = iteration + 1\n            print(\"iteration\",iteration,\":\",*arr)\n            \n    return arr", "response": "Bogo Sort the array by the best case and horstst case and average case."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef insert(self, key):\n        # Create new node\n        n = TreeNode(key)\n        if not self.node:\n            self.node = n\n            self.node.left = AvlTree()\n            self.node.right = AvlTree()\n        elif key < self.node.val:\n            self.node.left.insert(key)\n        elif key > self.node.val:\n            self.node.right.insert(key)\n        self.re_balance()", "response": "Insert new key into node"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the tree balance factor of the tree.", "response": "def update_balances(self, recursive=True):\n        \"\"\"\n        Calculate tree balance factor\n\n        \"\"\"\n        if self.node:\n            if recursive:\n                if self.node.left:\n                    self.node.left.update_balances()\n                if self.node.right:\n                    self.node.right.update_balances()\n\n            self.balance = self.node.left.height - self.node.right.height\n        else:\n            self.balance = 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rotate_right(self):\n        new_root = self.node.left.node\n        new_left_sub = new_root.right.node\n        old_root = self.node\n\n        self.node = new_root\n        old_root.left.node = new_left_sub\n        new_root.right.node = old_root", "response": "Rotate the tree from the right to the left."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrotates the tree from the left to the right", "response": "def rotate_left(self):\n        \"\"\"\n        Left rotation\n        \"\"\"\n        new_root = self.node.right.node\n        new_left_sub = new_root.left.node\n        old_root = self.node\n\n        self.node = new_root\n        old_root.right.node = new_left_sub\n        new_root.left.node = old_root"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef strobogrammatic_in_range(low, high):\n    res = []\n    count = 0\n    low_len = len(low)\n    high_len = len(high)\n    for i in range(low_len, high_len + 1):\n        res.extend(helper2(i, i))\n    for perm in res:\n        if len(perm) == low_len and int(perm) < int(low):\n            continue\n        elif len(perm) == high_len and int(perm) > int(high):\n            continue\n        else:\n            count += 1\n    return count", "response": "returns the number of strobogrammatic entries in a given range"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef kth_to_last_eval(head, k):\n    if not isinstance(k, int) or not head.val:\n        return False\n\n    nexts = '.'.join(['next' for n in range(1, k+1)])\n    seeker = str('.'.join(['head', nexts]))\n\n    while head:\n        if eval(seeker) is None:\n            return head\n        else:\n            head = head.next\n\n    return False", "response": "This method returns the last k - th entry in the list head."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef kth_to_last_dict(head, k):\n    if not (head and k > -1):\n        return False\n    d = dict()\n    count = 0\n    while head:\n        d[count] = head\n        head = head.next\n        count += 1\n    return len(d)-k in d and d[len(d)-k]", "response": "This function returns True if the key k is in the dict False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the skyline of a single entry in the list of available entries.", "response": "def get_skyline(lrh):\n    \"\"\"\n    Wortst Time Complexity: O(NlogN)\n    :type buildings: List[List[int]]\n    :rtype: List[List[int]]\n    \"\"\"\n    skyline, live = [], []\n    i, n = 0, len(lrh)\n    while i < n or live:\n        if not live or i < n and lrh[i][0] <= -live[0][1]:\n            x = lrh[i][0]\n            while i < n and lrh[i][0] == x:\n                heapq.heappush(live, (-lrh[i][2], -lrh[i][1]))\n                i += 1\n        else:\n            x = -live[0][1]\n            while live and -live[0][1] <= x:\n                heapq.heappop(live)\n        height = len(live) and -live[0][0]\n        if not skyline or height != skyline[-1][1]:\n            skyline += [x, height],\n    return skyline"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of lists of all the key - value pairs in the order of the elements in the array.", "response": "def summarize_ranges(array):\n    \"\"\"\n    :type array: List[int]\n    :rtype: List[]\n    \"\"\"\n    res = []\n    if len(array) == 1:\n        return [str(array[0])]\n    i = 0\n    while i < len(array):\n        num = array[i]\n        while i + 1 < len(array) and array[i + 1] - array[i] == 1:\n            i += 1\n        if array[i] != num:\n            res.append((num, array[i]))\n        else:\n            res.append((num, num))\n        i += 1\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nencodes a list of strings to a single string.", "response": "def encode(strs):\n    \"\"\"Encodes a list of strings to a single string.\n    :type strs: List[str]\n    :rtype: str\n    \"\"\"\n    res = ''\n    for string in strs.split():\n        res += str(len(string)) + \":\" + string\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decode(s):\n    strs = []\n    i = 0\n    while i < len(s):\n        index = s.find(\":\", i)\n        size = int(s[i:index])\n        strs.append(s[index+1: index+1+size])\n        i = index+1+size\n    return strs", "response": "Decodes a single string to a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef multiply(multiplicand: list, multiplier: list) -> list:\n    multiplicand_row, multiplicand_col = len(\n        multiplicand), len(multiplicand[0])\n    multiplier_row, multiplier_col = len(multiplier), len(multiplier[0])\n    if(multiplicand_col != multiplier_row):\n        raise Exception(\n            \"Multiplicand matrix not compatible with Multiplier matrix.\")\n    # create a result matrix\n    result = [[0] * multiplier_col for i in range(multiplicand_row)]\n    for i in range(multiplicand_row):\n        for j in range(multiplier_col):\n            for k in range(len(multiplier)):\n                result[i][j] += multiplicand[i][k] * multiplier[k][j]\n    return result", "response": "multiplies the multiplicand matrix with the multiplier matrix."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef combination(n, r):\n    if n == r or r == 0:\n        return 1\n    else:\n        return combination(n-1, r-1) + combination(n-1, r)", "response": "This function calculates nCr."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef combination_memo(n, r):\n    memo = {}\n    def recur(n, r):\n        if n == r or r == 0:\n            return 1\n        if (n, r) not in memo:\n            memo[(n, r)] = recur(n - 1, r - 1) + recur(n - 1, r)\n        return memo[(n, r)]\n    return recur(n, r)", "response": "This function calculates nCr using memoization method."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_anagram(s, t):\n    maps = {}\n    mapt = {}\n    for i in s:\n        maps[i] = maps.get(i, 0) + 1\n    for i in t:\n        mapt[i] = mapt.get(i, 0) + 1\n    return maps == mapt", "response": "Check if a sequence of words is ananagram."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pancake_sort(arr):\n\n    len_arr = len(arr)\n    if len_arr <= 1:\n        return arr\n    for cur in range(len(arr), 1, -1):\n        #Finding index of maximum number in arr\n        index_max = arr.index(max(arr[0:cur]))\n        if index_max+1 != cur:\n            #Needs moving\n            if index_max != 0:\n                #reverse from 0 to index_max\n                arr[:index_max+1] = reversed(arr[:index_max+1])\n            # Reverse list\n            arr[:cur] = reversed(arr[:cur])\n    return arr", "response": "Pancake_sort is a wrapper for the pancake_sort function that sorts a given array of items by mutation of selection"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef next(self):\n        v=self.queue.pop(0)\n        ret=v.pop(0)\n        if v: self.queue.append(v)\n        return ret", "response": "Returns the next entry in the queue."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the maximum profit of a list of classes.", "response": "def max_profit_naive(prices):\n    \"\"\"\n    :type prices: List[int]\n    :rtype: int\n    \"\"\"\n    max_so_far = 0\n    for i in range(0, len(prices) - 1):\n        for j in range(i + 1, len(prices)):\n            max_so_far = max(max_so_far, prices[j] - prices[i])\n    return max_so_far"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninputting [7, 1, 5, 3, 6, 4] diff : [X, -6, 4, -2, 3, -2] :type prices: List[int] :rtype: int", "response": "def max_profit_optimized(prices):\n    \"\"\"\n    input: [7, 1, 5, 3, 6, 4]\n    diff : [X, -6, 4, -2, 3, -2]\n    :type prices: List[int]\n    :rtype: int\n    \"\"\"\n    cur_max, max_so_far = 0, 0\n    for i in range(1, len(prices)):\n        cur_max = max(0, cur_max + prices[i] - prices[i-1])\n        max_so_far = max(max_so_far, cur_max)\n    return max_so_far"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef first_unique_char(s):\n    if (len(s) == 1):\n        return 0\n    ban = []\n    for i in range(len(s)):\n        if all(s[i] != s[k] for k in range(i + 1, len(s))) == True and s[i] not in ban:\n            return i\n        else:\n            ban.append(s[i])\n    return -1", "response": "Returns the first unique character in a sequence."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef kth_smallest(self, root, k):\n        count = []\n        self.helper(root, count)\n        return count[k-1]", "response": "returns the kth entry in the tree root"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef int_to_roman(num):\n    m = [\"\", \"M\", \"MM\", \"MMM\"];\n    c = [\"\", \"C\", \"CC\", \"CCC\", \"CD\", \"D\", \"DC\", \"DCC\", \"DCCC\", \"CM\"];\n    x = [\"\", \"X\", \"XX\", \"XXX\", \"XL\", \"L\", \"LX\", \"LXX\", \"LXXX\", \"XC\"];\n    i = [\"\", \"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\", \"VII\", \"VIII\", \"IX\"];\n    return m[num//1000] + c[(num%1000)//100] + x[(num%100)//10] + i[num%10];", "response": "Convert an integer to a Roman number."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef length_longest_path(input):\n    curr_len, max_len = 0, 0    # running length and max length\n    stack = []    # keep track of the name length\n    for s in input.split('\\n'):\n        print(\"---------\")\n        print(\"<path>:\", s)\n        depth = s.count('\\t')    # the depth of current dir or file\n        print(\"depth: \", depth)\n        print(\"stack: \", stack)\n        print(\"curlen: \", curr_len)\n        while len(stack) > depth:    # go back to the correct depth\n            curr_len -= stack.pop()\n        stack.append(len(s.strip('\\t'))+1)   # 1 is the length of '/'\n        curr_len += stack[-1]    # increase current length\n        print(\"stack: \", stack)\n        print(\"curlen: \", curr_len)\n        if '.' in s:    # update maxlen only when it is a file\n            max_len = max(max_len, curr_len-1)    # -1 is to minus one '/'\n    return max_len", "response": "returns the length of longest path in the input string"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef multiply(self, a, b):\n    if a is None or b is None: return None\n    m, n, l = len(a), len(b[0]), len(b[0])\n    if len(b) != n:\n        raise Exception(\"A's column number must be equal to B's row number.\")\n    c = [[0 for _ in range(l)] for _ in range(m)]\n    for i, row in enumerate(a):\n        for k, eleA in enumerate(row):\n            if eleA:\n                for j, eleB in enumerate(b[k]):\n                    if eleB: c[i][j] += eleA * eleB\n    return c", "response": "Multiplies two lists of lists a and b."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute strongly connected components of a graph", "response": "def scc(graph):\n    ''' Computes the strongly connected components of a graph '''\n    order = []\n    vis = {vertex: False for vertex in graph}\n\n    graph_transposed = {vertex: [] for vertex in graph}\n\n    for (v, neighbours) in graph.iteritems():\n        for u in neighbours:\n            add_edge(graph_transposed, u, v)\n\n    for v in graph:\n        if not vis[v]:\n            dfs_transposed(v, graph_transposed, order, vis)\n\n    vis = {vertex: False for vertex in graph}\n    vertex_scc = {}\n\n    current_comp = 0\n    for v in reversed(order):\n        if not vis[v]:\n            # Each dfs will visit exactly one component\n            dfs(v, current_comp, vertex_scc, graph, vis)\n            current_comp += 1\n\n    return vertex_scc"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_graph(formula):\n    ''' Builds the implication graph from the formula '''\n    graph = {}\n\n    for clause in formula:\n        for (lit, _) in clause:\n            for neg in [False, True]:\n                graph[(lit, neg)] = []\n\n    for ((a_lit, a_neg), (b_lit, b_neg)) in formula:\n        add_edge(graph, (a_lit, a_neg), (b_lit, not b_neg))\n        add_edge(graph, (b_lit, b_neg), (a_lit, not a_neg))\n\n    return graph", "response": "Builds the implication graph from the formula"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unique_array_sum_combinations(A, B, C, target):\n    def check_sum(n, *nums):\n        if sum(x for x in nums) == n:\n            return (True, nums)\n        else:\n            return (False, nums)\n\n    pro = itertools.product(A, B, C)\n    func = partial(check_sum, target)\n    sums = list(itertools.starmap(func, pro))\n\n    res = set()\n    for s in sums:\n        if s[0] is True and s[1] not in res:\n            res.add(s[1])\n\n    return list(res)", "response": "Return a list of unique array sum combinations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if the tree is a BST.", "response": "def is_bst(root):\n    \"\"\"\n    :type root: TreeNode\n    :rtype: bool\n    \"\"\"\n\n    stack = []\n    pre = None\n    \n    while root or stack:\n        while root:\n            stack.append(root)\n            root = root.left\n        root = stack.pop()\n        if pre and root.val <= pre.val:\n            return False\n        pre = root\n        root = root.right\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __get_depth(root):\n    if root is None:\n        return 0\n    left  = __get_depth(root.left)\n    right = __get_depth(root.right)\n    if abs(left-right) > 1 or -1 in [left, right]:\n        return -1\n    return 1 + max(left, right)", "response": "Get the depth of the root node."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncopies the random pointer from head to headRandomListNode.", "response": "def copy_random_pointer_v1(head):\n    \"\"\"\n    :type head: RandomListNode\n    :rtype: RandomListNode\n    \"\"\"\n    dic = dict()\n    m = n = head\n    while m:\n        dic[m] = RandomListNode(m.label)\n        m = m.next\n    while n:\n        dic[n].next = dic.get(n.next)\n        dic[n].random = dic.get(n.random)\n        n = n.next\n    return dic.get(head)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncopies the head node to the next node in the order they appear in the head node.", "response": "def copy_random_pointer_v2(head):\n    \"\"\"\n    :type head: RandomListNode\n    :rtype: RandomListNode\n    \"\"\"\n    copy = defaultdict(lambda: RandomListNode(0))\n    copy[None] = None\n    node = head\n    while node:\n        copy[node].label = node.label\n        copy[node].next = copy[node.next]\n        copy[node].random = copy[node.random]\n        node = node.next\n    return copy[head]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of lists of all factors of the n - term term.", "response": "def get_factors(n):\n    \"\"\"[summary]\n    \n    Arguments:\n        n {[int]} -- [to analysed number]\n    \n    Returns:\n        [list of lists] -- [all factors of the number n]\n    \"\"\"\n\n    def factor(n, i, combi, res):\n        \"\"\"[summary]\n        helper function\n\n        Arguments:\n            n {[int]} -- [number]\n            i {[int]} -- [to tested divisor]\n            combi {[list]} -- [catch divisors]\n            res {[list]} -- [all factors of the number n]\n        \n        Returns:\n            [list] -- [res]\n        \"\"\"\n\n        while i * i <= n:\n            if n % i == 0:\n                res += combi + [i, int(n/i)],\n                factor(n/i, i, combi+[i], res)\n            i += 1\n        return res\n    return factor(n, 2, [], [])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_factors_iterative1(n):\n\n    todo, res = [(n, 2, [])], []\n    while todo:\n        n, i, combi = todo.pop()\n        while i * i <= n:\n            if n % i == 0:\n                res += combi + [i, n//i],\n                todo.append((n//i, i, combi+[i])),\n            i += 1\n    return res", "response": "This function returns all factors of n in a call - stack modell."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef single_number3(nums):\n    # isolate a^b from pairs using XOR\n    ab = 0\n    for n in nums:\n        ab ^= n\n\n    # isolate right most bit from a^b\n    right_most = ab & (-ab)\n\n    # isolate a and b from a^b\n    a, b = 0, 0\n    for n in nums:\n        if n & right_most:\n            a ^= n\n        else:\n            b ^= n\n    return [a, b]", "response": "A function to isolate a and b from a list of numbers using XOR\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef distance(x,y):\n    assert len(x) == len(y), \"The vector must have same length\"\n    result = ()\n    sum = 0\n    for i in range(len(x)):\n        result += (x[i] -y[i],)\n    for component in result:\n        sum += component**2\n    return math.sqrt(sum)", "response": "Returns the eulidean distance between vector x and y."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef nearest_neighbor(x, tSet):\n    assert isinstance(x, tuple) and isinstance(tSet, dict)\n    current_key = ()\n    min_d = float('inf')\n    for key in tSet:\n        d = distance(x, key)\n        if d < min_d:\n            min_d = d\n            current_key = key\n    return tSet[current_key]", "response": "Returns the nearest neighbor of the given vector x in the given training set tSet."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if a string is a strobogrammatic version of the current language.", "response": "def is_strobogrammatic(num):\n    \"\"\"\n    :type num: str\n    :rtype: bool\n    \"\"\"\n    comb = \"00 11 88 69 96\"\n    i = 0\n    j = len(num) - 1\n    while i <= j:\n        x = comb.find(num[i]+num[j])\n        if x == -1:\n            return False\n        i += 1\n        j -= 1\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmerge sort array into a single node.", "response": "def merge_sort(arr):\n    \"\"\" Merge Sort\n        Complexity: O(n log(n))\n    \"\"\"\n    # Our recursive base case\n    if len(arr) <= 1:\n        return arr\n    mid = len(arr) // 2\n    # Perform merge_sort recursively on both halves\n    left, right = merge_sort(arr[:mid]), merge_sort(arr[mid:])\n\n    # Merge each side together\n    return merge(left, right, arr.copy())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef merge(left, right, merged):\n\n    left_cursor, right_cursor = 0, 0\n    while left_cursor < len(left) and right_cursor < len(right):\n        # Sort each one and place into the result\n        if left[left_cursor] <= right[right_cursor]:\n            merged[left_cursor+right_cursor]=left[left_cursor]\n            left_cursor += 1\n        else:\n            merged[left_cursor + right_cursor] = right[right_cursor]\n            right_cursor += 1\n    # Add the left overs if there's any left to the result\n    for left_cursor in range(left_cursor, len(left)):\n        merged[left_cursor + right_cursor] = left[left_cursor]\n    # Add the left overs if there's any left to the result\n    for right_cursor in range(right_cursor, len(right)):\n        merged[left_cursor + right_cursor] = right[right_cursor]\n\n    # Return result\n    return merged", "response": "Merge two helper\nAttributeNames into a single list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bucket_sort(arr):\n    ''' Bucket Sort\n        Complexity: O(n^2)\n        The complexity is dominated by nextSort\n    '''\n    # The number of buckets and make buckets\n    num_buckets = len(arr)\n    buckets = [[] for bucket in range(num_buckets)]\n    # Assign values into bucket_sort\n    for value in arr:\n        index = value * num_buckets // (max(arr) + 1)\n        buckets[index].append(value)\n    # Sort\n    sorted_list = []\n    for i in range(num_buckets):\n        sorted_list.extend(next_sort(buckets[i]))\n    return sorted_list", "response": "Bucket Sort\n    Complexity is O ( n^2 )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the k nearest points to the origin.", "response": "def k_closest(points, k, origin=(0, 0)):\n    # Time: O(k+(n-k)logk)\n    # Space: O(k)\n    \"\"\"Initialize max heap with first k points.\n    Python does not support a max heap; thus we can use the default min heap where the keys (distance) are negated.\n    \"\"\"\n    heap = [(-distance(p, origin), p) for p in points[:k]]\n    heapify(heap)\n\n    \"\"\"\n    For every point p in points[k:],\n    check if p is smaller than the root of the max heap;\n    if it is, add p to heap and remove root. Reheapify.\n    \"\"\"\n    for p in points[k:]:\n        d = distance(p, origin)\n\n        heappushpop(heap, (-d, p))  # heappushpop does conditional check\n        \"\"\"Same as:\n            if d < -heap[0][0]:\n                heappush(heap, (-d,p))\n                heappop(heap)\n\n        Note: heappushpop is more efficient than separate push and pop calls.\n        Each heappushpop call takes O(logk) time.\n        \"\"\"\n\n    return [p for nd, p in heap]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreverses the list of node in the order they appear.", "response": "def reverse_list(head):\n    \"\"\"\n    :type head: ListNode\n    :rtype: ListNode\n    \"\"\"\n    if not head or not head.next:\n        return head\n    prev = None\n    while head:\n        current = head\n        head = head.next\n        current.next = prev\n        prev = current\n    return prev"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef has_path_sum(root, sum):\n    if root is None:\n        return False\n    if root.left is None and root.right is None and root.val == sum:\n        return True\n    sum -= root.val\n    return has_path_sum(root.left, sum) or has_path_sum(root.right, sum)", "response": "Returns True if the sum of the nodes in the tree is greater than or equal to the sum of the nodes in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef int_to_base(n, base):\n    is_negative = False\n    if n == 0:\n        return '0'\n    elif n < 0:\n        is_negative = True\n        n *= -1\n    digit = string.digits + string.ascii_uppercase\n    res = ''\n    while n > 0:\n        res += digit[n % base]\n        n //= base\n    if is_negative:\n        return '-' + res[::-1]\n    else:\n        return res[::-1]", "response": "Converts an integer n to base string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef base_to_int(s, base):\n    \n    digit = {}\n    for i,c in enumerate(string.digits + string.ascii_uppercase):\n        digit[c] = i\n    multiplier = 1\n    res = 0\n    for c in s[::-1]:\n        res += digit[c] * multiplier\n        multiplier *= base\n    return res", "response": "Convert base to int."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if the node is cyclic.", "response": "def is_cyclic(head):\n    \"\"\"\n    :type head: Node\n    :rtype: bool\n    \"\"\"\n    if not head:\n        return False\n    runner = head\n    walker = head\n    while runner.next and runner.next.next:\n        runner = runner.next.next\n        walker = walker.next\n        if runner == walker:\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndecodes a string containing the n - tuple of key - value pairs into a string.", "response": "def decode_string(s):\n    \"\"\"\n    :type s: str\n    :rtype: str\n    \"\"\"\n    stack = []; cur_num = 0; cur_string = ''\n    for c in s:\n        if c == '[':\n            stack.append((cur_string, cur_num))\n            cur_string = ''\n            cur_num = 0\n        elif c == ']':\n            prev_string, num = stack.pop()\n            cur_string = prev_string + num * cur_string\n        elif c.isdigit():\n            cur_num = cur_num*10 + int(c)\n        else:\n            cur_string += c\n    return cur_string"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef palindromic_substrings_iter(s):\n    if not s:\n        yield []\n        return\n    for i in range(len(s), 0, -1):\n        sub = s[:i]\n        if sub == sub[::-1]:\n            for rest in palindromic_substrings_iter(s[i:]):\n                yield [sub] + rest", "response": "A slightly more Pythonic approach with a recursive generator with a recursive generator with a recursive generator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_isomorphic(s, t):\n    if len(s) != len(t):\n        return False\n    dict = {}\n    set_value = set()\n    for i in range(len(s)):\n        if s[i] not in dict:\n            if t[i] in set_value:\n                return False\n            dict[s[i]] = t[i]\n            set_value.add(t[i])\n        else:\n            if dict[s[i]] != t[i]:\n                return False\n    return True", "response": "Returns True if s and t are isomorphic."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the result of a given operation n2 n1 n2 n1 n2 n1 n2 n1 n2 n1 n2 operator Char Returns the result of the operation n1 n2 n1 n2 operator", "response": "def calc(n2, n1, operator):\r\n    \"\"\"\r\n    Calculate operation result\r\n\r\n    n2 Number: Number 2\r\n    n1 Number: Number 1\r\n    operator Char: Operation to calculate\r\n    \"\"\"\r\n    if operator == '-': return n1 - n2\r\n    elif operator == '+': return n1 + n2\r\n    elif operator == '*': return n1 * n2\r\n    elif operator == '/': return n1 / n2\r\n    elif operator == '^': return n1 ** n2\r\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply an operation to the first 2 items of the output queue", "response": "def apply_operation(op_stack, out_stack):\r\n    \"\"\"\r\n    Apply operation to the first 2 items of the output queue\r\n\r\n    op_stack Deque (reference)\r\n    out_stack Deque (reference)\r\n    \"\"\"\r\n    out_stack.append(calc(out_stack.pop(), out_stack.pop(), op_stack.pop()))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning array of parsed tokens in the expression", "response": "def parse(expression):\r\n    \"\"\"\r\n    Return array of parsed tokens in the expression\r\n\r\n    expression String: Math expression to parse in infix notation\r\n    \"\"\"\r\n    result = []\r\n    current = \"\"\r\n    for i in expression:\r\n        if i.isdigit() or i == '.':\r\n            current += i\r\n        else:\r\n            if len(current) > 0:\r\n                result.append(current)\r\n                current = \"\"\r\n            if i in __operators__ or i in __parenthesis__:\r\n                result.append(i)\r\n            else:\r\n                raise Exception(\"invalid syntax \" + i)\r\n\r\n    if len(current) > 0:\r\n        result.append(current)\r\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nevaluate the expression Taxonomy expression", "response": "def evaluate(expression):\r\n    \"\"\"\r\n    Calculate result of expression\r\n\r\n    expression String: The expression\r\n    type Type (optional): Number type [int, float]\r\n    \"\"\"\r\n    op_stack  = deque() # operator stack\r\n    out_stack = deque() # output stack (values)\r\n    tokens = parse(expression) # calls the function only once!\r\n    for token in tokens:\r\n        if numeric_value.match(token):\r\n            out_stack.append(float(token))\r\n        elif token == '(':\r\n            op_stack.append(token)\r\n        elif token == ')':\r\n            while len(op_stack) > 0 and op_stack[-1] != '(':\r\n                apply_operation(op_stack, out_stack)\r\n            op_stack.pop() # Remove remaining '('\r\n        else: # is_operator(token)\r\n            while len(op_stack) > 0 and is_operator(op_stack[-1]) and higher_priority(op_stack[-1], token):\r\n                apply_operation(op_stack, out_stack)\r\n            op_stack.append(token)\r\n\r\n    while len(op_stack) > 0:\r\n        apply_operation(op_stack, out_stack)\r\n\r\n    return out_stack[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef closest_value(root, target):\n    a = root.val\n    kid = root.left if target < a else root.right\n    if not kid:\n        return a\n    b = closest_value(kid, target)\n    return min((a,b), key=lambda x: abs(target-x))", "response": "Returns the value of the node closest to target."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_primes(n):\n    if n <= 0:\n        raise ValueError(\"'n' must be a positive integer.\")\n    # If x is even, exclude x from list (-1):\n    sieve_size = (n // 2 - 1) if n % 2 == 0 else (n // 2)\n    sieve = [True for _ in range(sieve_size)]   # Sieve\n    primes = []      # List of Primes\n    if n >= 2:\n        primes.append(2)      # 2 is prime by default\n    for i in range(sieve_size):\n        if sieve[i]:\n            value_at_i = i*2 + 3\n            primes.append(value_at_i)\n            for j in range(i, sieve_size, value_at_i):\n                sieve[j] = False\n    return primes", "response": "Return list of all primes less than n using sieve of Eratosthenes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef permute(elements):\n    if len(elements) <= 1:\n        return [elements]\n    else:\n        tmp = []\n        for perm in permute(elements[1:]):\n            for i in range(len(elements)):\n                tmp.append(perm[:i] + elements[0:1] + perm[i:])\n        return tmp", "response": "returns a list with the permuations."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extended_gcd(a, b):\n\n    old_s, s = 1, 0\n    old_t, t = 0, 1\n    old_r, r = a, b\n    \n    while r != 0:\n        quotient = old_r / r\n        \n        old_r, r = r, old_r - quotient * r\n        old_s, s = s, old_s - quotient * s\n        old_t, t = t, old_t - quotient * t\n    \n    return old_s, old_t, old_r", "response": "Extended GCD algorithm.\n    Return s, t, g\n    such that a * s + b * t = GCD(a, b)\n    and s and t are co-prime."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a binary tree to a list of objects", "response": "def bin_tree_to_list(root):\n    \"\"\"\n    type root: root class\n    \"\"\"\n    if not root:\n        return root\n    root = bin_tree_to_list_util(root)\n    while root.left:\n        root = root.left\n    return root"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding operators to the list of the n - grams that are used to create the n - grams.", "response": "def add_operators(num, target):\n    \"\"\"\n    :type num: str\n    :type target: int\n    :rtype: List[str]\n    \"\"\"\n\n    def dfs(res, path, num, target, pos, prev, multed):\n        if pos == len(num):\n            if target == prev:\n                res.append(path)\n            return\n        for i in range(pos, len(num)):\n            if i != pos and num[pos] == '0':  # all digits have to be used\n                break\n            cur = int(num[pos:i+1])\n            if pos == 0:\n                dfs(res, path + str(cur), num, target, i+1, cur, cur)\n            else:\n                dfs(res, path + \"+\" + str(cur), num, target,\n                    i+1, prev + cur, cur)\n                dfs(res, path + \"-\" + str(cur), num, target,\n                    i+1, prev - cur, -cur)\n                dfs(res, path + \"*\" + str(cur), num, target,\n                    i+1, prev - multed + multed * cur, multed * cur)\n\n    res = []\n    if not num:\n        return res\n    dfs(res, \"\", num, target, 0, 0, 0)\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize the rabit library with arguments", "response": "def init(args=None):\n    \"\"\"Initialize the rabit library with arguments\"\"\"\n    if args is None:\n        args = []\n    arr = (ctypes.c_char_p * len(args))()\n    arr[:] = args\n    _LIB.RabitInit(len(arr), arr)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting a message to the tracker.", "response": "def tracker_print(msg):\n    \"\"\"Print message to the tracker.\n\n    This function can be used to communicate the information of\n    the progress to the tracker\n\n    Parameters\n    ----------\n    msg : str\n        The message to be printed to tracker.\n    \"\"\"\n    if not isinstance(msg, STRING_TYPES):\n        msg = str(msg)\n    is_dist = _LIB.RabitIsDistributed()\n    if is_dist != 0:\n        _LIB.RabitTrackerPrint(c_str(msg))\n    else:\n        sys.stdout.write(msg)\n        sys.stdout.flush()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_processor_name():\n    mxlen = 256\n    length = ctypes.c_ulong()\n    buf = ctypes.create_string_buffer(mxlen)\n    _LIB.RabitGetProcessorName(buf, ctypes.byref(length), mxlen)\n    return buf.value", "response": "Get the name of the processor."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef broadcast(data, root):\n    rank = get_rank()\n    length = ctypes.c_ulong()\n    if root == rank:\n        assert data is not None, 'need to pass in data when broadcasting'\n        s = pickle.dumps(data, protocol=pickle.HIGHEST_PROTOCOL)\n        length.value = len(s)\n    # run first broadcast\n    _LIB.RabitBroadcast(ctypes.byref(length),\n                        ctypes.sizeof(ctypes.c_ulong), root)\n    if root != rank:\n        dptr = (ctypes.c_char * length.value)()\n        # run second\n        _LIB.RabitBroadcast(ctypes.cast(dptr, ctypes.c_void_p),\n                            length.value, root)\n        data = pickle.loads(dptr.raw)\n        del dptr\n    else:\n        _LIB.RabitBroadcast(ctypes.cast(ctypes.c_char_p(s), ctypes.c_void_p),\n                            length.value, root)\n        del s\n    return data", "response": "Broadcasts data from one node to all other nodes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nnormalize UNIX path to a native path.", "response": "def normpath(path):\n    \"\"\"Normalize UNIX path to a native path.\"\"\"\n    normalized = os.path.join(*path.split(\"/\"))\n    if os.path.isabs(path):\n        return os.path.abspath(\"/\") + normalized\n    else:\n        return normalized"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntrain a booster with given parameters.", "response": "def train(params, dtrain, num_boost_round=10, evals=(), obj=None, feval=None,\n          maximize=False, early_stopping_rounds=None, evals_result=None,\n          verbose_eval=True, xgb_model=None, callbacks=None, learning_rates=None):\n    # pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\n    \"\"\"Train a booster with given parameters.\n\n    Parameters\n    ----------\n    params : dict\n        Booster params.\n    dtrain : DMatrix\n        Data to be trained.\n    num_boost_round: int\n        Number of boosting iterations.\n    evals: list of pairs (DMatrix, string)\n        List of items to be evaluated during training, this allows user to watch\n        performance on the validation set.\n    obj : function\n        Customized objective function.\n    feval : function\n        Customized evaluation function.\n    maximize : bool\n        Whether to maximize feval.\n    early_stopping_rounds: int\n        Activates early stopping. Validation error needs to decrease at least\n        every **early_stopping_rounds** round(s) to continue training.\n        Requires at least one item in **evals**.\n        If there's more than one, will use the last.\n        Returns the model from the last iteration (not the best one).\n        If early stopping occurs, the model will have three additional fields:\n        ``bst.best_score``, ``bst.best_iteration`` and ``bst.best_ntree_limit``.\n        (Use ``bst.best_ntree_limit`` to get the correct value if\n        ``num_parallel_tree`` and/or ``num_class`` appears in the parameters)\n    evals_result: dict\n        This dictionary stores the evaluation results of all the items in watchlist.\n\n        Example: with a watchlist containing\n        ``[(dtest,'eval'), (dtrain,'train')]`` and\n        a parameter containing ``('eval_metric': 'logloss')``,\n        the **evals_result** returns\n\n        .. code-block:: python\n\n            {'train': {'logloss': ['0.48253', '0.35953']},\n             'eval': {'logloss': ['0.480385', '0.357756']}}\n\n    verbose_eval : bool or int\n        Requires at least one item in **evals**.\n        If **verbose_eval** is True then the evaluation metric on the validation set is\n        printed at each boosting stage.\n        If **verbose_eval** is an integer then the evaluation metric on the validation set\n        is printed at every given **verbose_eval** boosting stage. The last boosting stage\n        / the boosting stage found by using **early_stopping_rounds** is also printed.\n        Example: with ``verbose_eval=4`` and at least one item in **evals**, an evaluation metric\n        is printed every 4 boosting stages, instead of every boosting stage.\n    learning_rates: list or function (deprecated - use callback API instead)\n        List of learning rate for each boosting round\n        or a customized function that calculates eta in terms of\n        current number of round and the total number of boosting round (e.g. yields\n        learning rate decay)\n    xgb_model : file name of stored xgb model or 'Booster' instance\n        Xgb model to be loaded before training (allows training continuation).\n    callbacks : list of callback functions\n        List of callback functions that are applied at end of each iteration.\n        It is possible to use predefined callbacks by using\n        :ref:`Callback API <callback_api>`.\n        Example:\n\n        .. code-block:: python\n\n            [xgb.callback.reset_learning_rate(custom_rates)]\n\n    Returns\n    -------\n    Booster : a trained booster model\n    \"\"\"\n    callbacks = [] if callbacks is None else callbacks\n\n    # Most of legacy advanced options becomes callbacks\n    if isinstance(verbose_eval, bool) and verbose_eval:\n        callbacks.append(callback.print_evaluation())\n    else:\n        if isinstance(verbose_eval, int):\n            callbacks.append(callback.print_evaluation(verbose_eval))\n\n    if early_stopping_rounds is not None:\n        callbacks.append(callback.early_stop(early_stopping_rounds,\n                                             maximize=maximize,\n                                             verbose=bool(verbose_eval)))\n    if evals_result is not None:\n        callbacks.append(callback.record_evaluation(evals_result))\n\n    if learning_rates is not None:\n        warnings.warn(\"learning_rates parameter is deprecated - use callback API instead\",\n                      DeprecationWarning)\n        callbacks.append(callback.reset_learning_rate(learning_rates))\n\n    return _train_internal(params, dtrain,\n                           num_boost_round=num_boost_round,\n                           evals=evals,\n                           obj=obj, feval=feval,\n                           xgb_model=xgb_model, callbacks=callbacks)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes an n - fold list from random indices.", "response": "def mknfold(dall, nfold, param, seed, evals=(), fpreproc=None, stratified=False,\n            folds=None, shuffle=True):\n    \"\"\"\n    Make an n-fold list of CVPack from random indices.\n    \"\"\"\n    evals = list(evals)\n    np.random.seed(seed)\n\n    if stratified is False and folds is None:\n        # Do standard k-fold cross validation\n        if shuffle is True:\n            idx = np.random.permutation(dall.num_row())\n        else:\n            idx = np.arange(dall.num_row())\n        out_idset = np.array_split(idx, nfold)\n        in_idset = [\n            np.concatenate([out_idset[i] for i in range(nfold) if k != i])\n            for k in range(nfold)\n        ]\n    elif folds is not None:\n        # Use user specified custom split using indices\n        try:\n            in_idset = [x[0] for x in folds]\n            out_idset = [x[1] for x in folds]\n        except TypeError:\n            # Custom stratification using Sklearn KFoldSplit object\n            splits = list(folds.split(X=dall.get_label(), y=dall.get_label()))\n            in_idset = [x[0] for x in splits]\n            out_idset = [x[1] for x in splits]\n        nfold = len(out_idset)\n    else:\n        # Do standard stratefied shuffle k-fold split\n        sfk = XGBStratifiedKFold(n_splits=nfold, shuffle=True, random_state=seed)\n        splits = list(sfk.split(X=dall.get_label(), y=dall.get_label()))\n        in_idset = [x[0] for x in splits]\n        out_idset = [x[1] for x in splits]\n        nfold = len(out_idset)\n\n    ret = []\n    for k in range(nfold):\n        dtrain = dall.slice(in_idset[k])\n        dtest = dall.slice(out_idset[k])\n        # run preprocessing on the data set if needed\n        if fpreproc is not None:\n            dtrain, dtest, tparam = fpreproc(dtrain, dtest, param.copy())\n        else:\n            tparam = param\n        plst = list(tparam.items()) + [('eval_metric', itm) for itm in evals]\n        ret.append(CVPack(dtrain, dtest, plst))\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef aggcv(rlist):\n    # pylint: disable=invalid-name\n    \"\"\"\n    Aggregate cross-validation results.\n\n    If verbose_eval is true, progress is displayed in every call. If\n    verbose_eval is an integer, progress will only be displayed every\n    `verbose_eval` trees, tracked via trial.\n    \"\"\"\n    cvmap = {}\n    idx = rlist[0].split()[0]\n    for line in rlist:\n        arr = line.split()\n        assert idx == arr[0]\n        for it in arr[1:]:\n            if not isinstance(it, STRING_TYPES):\n                it = it.decode()\n            k, v = it.split(':')\n            if k not in cvmap:\n                cvmap[k] = []\n            cvmap[k].append(float(v))\n    msg = idx\n    results = []\n    for k, v in sorted(cvmap.items(), key=lambda x: (x[0].startswith('test'), x[0])):\n        v = np.array(v)\n        if not isinstance(msg, STRING_TYPES):\n            msg = msg.decode()\n        mean, std = np.mean(v), np.std(v)\n        results.extend([(k, mean, std)])\n    return results", "response": "Aggregate cross - validation results."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cv(params, dtrain, num_boost_round=10, nfold=3, stratified=False, folds=None,\n       metrics=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None,\n       fpreproc=None, as_pandas=True, verbose_eval=None, show_stdv=True,\n       seed=0, callbacks=None, shuffle=True):\n    # pylint: disable = invalid-name\n    \"\"\"Cross-validation with given parameters.\n\n    Parameters\n    ----------\n    params : dict\n        Booster params.\n    dtrain : DMatrix\n        Data to be trained.\n    num_boost_round : int\n        Number of boosting iterations.\n    nfold : int\n        Number of folds in CV.\n    stratified : bool\n        Perform stratified sampling.\n    folds : a KFold or StratifiedKFold instance or list of fold indices\n        Sklearn KFolds or StratifiedKFolds object.\n        Alternatively may explicitly pass sample indices for each fold.\n        For ``n`` folds, **folds** should be a length ``n`` list of tuples.\n        Each tuple is ``(in,out)`` where ``in`` is a list of indices to be used\n        as the training samples for the ``n`` th fold and ``out`` is a list of\n        indices to be used as the testing samples for the ``n`` th fold.\n    metrics : string or list of strings\n        Evaluation metrics to be watched in CV.\n    obj : function\n        Custom objective function.\n    feval : function\n        Custom evaluation function.\n    maximize : bool\n        Whether to maximize feval.\n    early_stopping_rounds: int\n        Activates early stopping. CV error needs to decrease at least\n        every <early_stopping_rounds> round(s) to continue.\n        Last entry in evaluation history is the one from best iteration.\n    fpreproc : function\n        Preprocessing function that takes (dtrain, dtest, param) and returns\n        transformed versions of those.\n    as_pandas : bool, default True\n        Return pd.DataFrame when pandas is installed.\n        If False or pandas is not installed, return np.ndarray\n    verbose_eval : bool, int, or None, default None\n        Whether to display the progress. If None, progress will be displayed\n        when np.ndarray is returned. If True, progress will be displayed at\n        boosting stage. If an integer is given, progress will be displayed\n        at every given `verbose_eval` boosting stage.\n    show_stdv : bool, default True\n        Whether to display the standard deviation in progress.\n        Results are not affected, and always contains std.\n    seed : int\n        Seed used to generate the folds (passed to numpy.random.seed).\n    callbacks : list of callback functions\n        List of callback functions that are applied at end of each iteration.\n        It is possible to use predefined callbacks by using\n        :ref:`Callback API <callback_api>`.\n        Example:\n\n        .. code-block:: python\n\n            [xgb.callback.reset_learning_rate(custom_rates)]\n    shuffle : bool\n        Shuffle data before creating folds.\n\n    Returns\n    -------\n    evaluation history : list(string)\n    \"\"\"\n    if stratified is True and not SKLEARN_INSTALLED:\n        raise XGBoostError('sklearn needs to be installed in order to use stratified cv')\n\n    if isinstance(metrics, str):\n        metrics = [metrics]\n\n    if isinstance(params, list):\n        _metrics = [x[1] for x in params if x[0] == 'eval_metric']\n        params = dict(params)\n        if 'eval_metric' in params:\n            params['eval_metric'] = _metrics\n    else:\n        params = dict((k, v) for k, v in params.items())\n\n    if (not metrics) and 'eval_metric' in params:\n        if isinstance(params['eval_metric'], list):\n            metrics = params['eval_metric']\n        else:\n            metrics = [params['eval_metric']]\n\n    params.pop(\"eval_metric\", None)\n\n    results = {}\n    cvfolds = mknfold(dtrain, nfold, params, seed, metrics, fpreproc,\n                      stratified, folds, shuffle)\n\n    # setup callbacks\n    callbacks = [] if callbacks is None else callbacks\n    if early_stopping_rounds is not None:\n        callbacks.append(callback.early_stop(early_stopping_rounds,\n                                             maximize=maximize,\n                                             verbose=False))\n\n    if isinstance(verbose_eval, bool) and verbose_eval:\n        callbacks.append(callback.print_evaluation(show_stdv=show_stdv))\n    else:\n        if isinstance(verbose_eval, int):\n            callbacks.append(callback.print_evaluation(verbose_eval, show_stdv=show_stdv))\n\n    callbacks_before_iter = [\n        cb for cb in callbacks if cb.__dict__.get('before_iteration', False)]\n    callbacks_after_iter = [\n        cb for cb in callbacks if not cb.__dict__.get('before_iteration', False)]\n\n    for i in range(num_boost_round):\n        for cb in callbacks_before_iter:\n            cb(CallbackEnv(model=None,\n                           cvfolds=cvfolds,\n                           iteration=i,\n                           begin_iteration=0,\n                           end_iteration=num_boost_round,\n                           rank=0,\n                           evaluation_result_list=None))\n        for fold in cvfolds:\n            fold.update(i, obj)\n        res = aggcv([f.eval(i, feval) for f in cvfolds])\n\n        for key, mean, std in res:\n            if key + '-mean' not in results:\n                results[key + '-mean'] = []\n            if key + '-std' not in results:\n                results[key + '-std'] = []\n            results[key + '-mean'].append(mean)\n            results[key + '-std'].append(std)\n        try:\n            for cb in callbacks_after_iter:\n                cb(CallbackEnv(model=None,\n                               cvfolds=cvfolds,\n                               iteration=i,\n                               begin_iteration=0,\n                               end_iteration=num_boost_round,\n                               rank=0,\n                               evaluation_result_list=res))\n        except EarlyStopException as e:\n            for k in results:\n                results[k] = results[k][:(e.best_iteration + 1)]\n            break\n    if as_pandas:\n        try:\n            import pandas as pd\n            results = pd.DataFrame.from_dict(results)\n        except ImportError:\n            pass\n    return results", "response": "Cross - validation with given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, iteration, fobj):\n        self.bst.update(self.dtrain, iteration, fobj)", "response": "Update the boosters for one iteration"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef eval(self, iteration, feval):\n        return self.bst.eval_set(self.watchlist, iteration, feval)", "response": "Evaluate the CVPack for one iteration."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_callback_context(env):\n    if env.model is not None and env.cvfolds is None:\n        context = 'train'\n    elif env.model is None and env.cvfolds is not None:\n        context = 'cv'\n    return context", "response": "return whether the current callback context is cv or train"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print_evaluation(period=1, show_stdv=True):\n    def callback(env):\n        \"\"\"internal function\"\"\"\n        if env.rank != 0 or (not env.evaluation_result_list) or period is False or period == 0:\n            return\n        i = env.iteration\n        if i % period == 0 or i + 1 == env.begin_iteration or i + 1 == env.end_iteration:\n            msg = '\\t'.join([_fmt_metric(x, show_stdv) for x in env.evaluation_result_list])\n            rabit.tracker_print('[%d]\\t%s\\n' % (i, msg))\n    return callback", "response": "Create a callback that prints the evaluation result for a single node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef record_evaluation(eval_result):\n    if not isinstance(eval_result, dict):\n        raise TypeError('eval_result has to be a dictionary')\n    eval_result.clear()\n\n    def init(env):\n        \"\"\"internal function\"\"\"\n        for k, _ in env.evaluation_result_list:\n            pos = k.index('-')\n            key = k[:pos]\n            metric = k[pos + 1:]\n            if key not in eval_result:\n                eval_result[key] = {}\n            if metric not in eval_result[key]:\n                eval_result[key][metric] = []\n\n    def callback(env):\n        \"\"\"internal function\"\"\"\n        if not eval_result:\n            init(env)\n        for k, v in env.evaluation_result_list:\n            pos = k.index('-')\n            key = k[:pos]\n            metric = k[pos + 1:]\n            eval_result[key][metric].append(v)\n    return callback", "response": "Create a callback that records the evaluation history into eval_result."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreset learning rate after iteration 1.", "response": "def reset_learning_rate(learning_rates):\n    \"\"\"Reset learning rate after iteration 1\n\n    NOTE: the initial learning rate will still take in-effect on first iteration.\n\n    Parameters\n    ----------\n    learning_rates: list or function\n        List of learning rate for each boosting round\n        or a customized function that calculates eta in terms of\n        current number of round and the total number of boosting round (e.g.\n        yields learning rate decay)\n\n        * list ``l``: ``eta = l[boosting_round]``\n        * function ``f``: ``eta = f(boosting_round, num_boost_round)``\n\n    Returns\n    -------\n    callback : function\n        The requested callback function.\n    \"\"\"\n    def get_learning_rate(i, n, learning_rates):\n        \"\"\"helper providing the learning rate\"\"\"\n        if isinstance(learning_rates, list):\n            if len(learning_rates) != n:\n                raise ValueError(\"Length of list 'learning_rates' has to equal 'num_boost_round'.\")\n            new_learning_rate = learning_rates[i]\n        else:\n            new_learning_rate = learning_rates(i, n)\n        return new_learning_rate\n\n    def callback(env):\n        \"\"\"internal function\"\"\"\n        context = _get_callback_context(env)\n\n        if context == 'train':\n            bst, i, n = env.model, env.iteration, env.end_iteration\n            bst.set_param('learning_rate', get_learning_rate(i, n, learning_rates))\n        elif context == 'cv':\n            i, n = env.iteration, env.end_iteration\n            for cvpack in env.cvfolds:\n                bst = cvpack.bst\n                bst.set_param('learning_rate', get_learning_rate(i, n, learning_rates))\n\n    callback.before_iteration = True\n    return callback"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef early_stop(stopping_rounds, maximize=False, verbose=True):\n    state = {}\n\n    def init(env):\n        \"\"\"internal function\"\"\"\n        bst = env.model\n\n        if not env.evaluation_result_list:\n            raise ValueError('For early stopping you need at least one set in evals.')\n        if len(env.evaluation_result_list) > 1 and verbose:\n            msg = (\"Multiple eval metrics have been passed: \"\n                   \"'{0}' will be used for early stopping.\\n\\n\")\n            rabit.tracker_print(msg.format(env.evaluation_result_list[-1][0]))\n        maximize_metrics = ('auc', 'aucpr', 'map', 'ndcg')\n        maximize_at_n_metrics = ('auc@', 'aucpr@', 'map@', 'ndcg@')\n        maximize_score = maximize\n        metric_label = env.evaluation_result_list[-1][0]\n        metric = metric_label.split('-', 1)[-1]\n\n        if any(metric.startswith(x) for x in maximize_at_n_metrics):\n            maximize_score = True\n\n        if any(metric.split(\":\")[0] == x for x in maximize_metrics):\n            maximize_score = True\n\n        if verbose and env.rank == 0:\n            msg = \"Will train until {} hasn't improved in {} rounds.\\n\"\n            rabit.tracker_print(msg.format(metric_label, stopping_rounds))\n\n        state['maximize_score'] = maximize_score\n        state['best_iteration'] = 0\n        if maximize_score:\n            state['best_score'] = float('-inf')\n        else:\n            state['best_score'] = float('inf')\n\n        if bst is not None:\n            if bst.attr('best_score') is not None:\n                state['best_score'] = float(bst.attr('best_score'))\n                state['best_iteration'] = int(bst.attr('best_iteration'))\n                state['best_msg'] = bst.attr('best_msg')\n            else:\n                bst.set_attr(best_iteration=str(state['best_iteration']))\n                bst.set_attr(best_score=str(state['best_score']))\n        else:\n            assert env.cvfolds is not None\n\n    def callback(env):\n        \"\"\"internal function\"\"\"\n        score = env.evaluation_result_list[-1][1]\n        if not state:\n            init(env)\n        best_score = state['best_score']\n        best_iteration = state['best_iteration']\n        maximize_score = state['maximize_score']\n        if (maximize_score and score > best_score) or \\\n                (not maximize_score and score < best_score):\n            msg = '[%d]\\t%s' % (\n                env.iteration,\n                '\\t'.join([_fmt_metric(x) for x in env.evaluation_result_list]))\n            state['best_msg'] = msg\n            state['best_score'] = score\n            state['best_iteration'] = env.iteration\n            # save the property to attributes, so they will occur in checkpoint.\n            if env.model is not None:\n                env.model.set_attr(best_score=str(state['best_score']),\n                                   best_iteration=str(state['best_iteration']),\n                                   best_msg=state['best_msg'])\n        elif env.iteration - best_iteration >= stopping_rounds:\n            best_msg = state['best_msg']\n            if verbose and env.rank == 0:\n                msg = \"Stopping. Best iteration:\\n{}\\n\\n\"\n                rabit.tracker_print(msg.format(best_msg))\n            raise EarlyStopException(best_iteration)\n    return callback", "response": "Create a callback function that activates early stopping."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns the doxygen make command in the designated folder.", "response": "def run_doxygen(folder):\n  \"\"\"Run the doxygen make command in the designated folder.\"\"\"\n  try:\n    retcode = subprocess.call(\"cd %s; make doxygen\" % folder, shell=True)\n    if retcode < 0:\n      sys.stderr.write(\"doxygen terminated by signal %s\" % (-retcode))\n  except OSError as e:\n    sys.stderr.write(\"doxygen execution failed: %s\" % e)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _objective_decorator(func):\n    def inner(preds, dmatrix):\n        \"\"\"internal function\"\"\"\n        labels = dmatrix.get_label()\n        return func(labels, preds)\n    return inner", "response": "Decorator that converts an objective function using the typical sklearn metrics\n    signature so that it is usable with xgboost. training. train."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the parameters of this estimator.", "response": "def set_params(self, **params):\n        \"\"\"Set the parameters of this estimator.\n        Modification of the sklearn method to allow unknown kwargs. This allows using\n        the full range of xgboost parameters that are not defined as member variables\n        in sklearn grid search.\n        Returns\n        -------\n        self\n        \"\"\"\n        if not params:\n            # Simple optimization to gain speed (inspect is slow)\n            return self\n\n        for key, value in params.items():\n            if hasattr(self, key):\n                setattr(self, key, value)\n            else:\n                self.kwargs[key] = value\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_xgb_params(self):\n        xgb_params = self.get_params()\n        random_state = xgb_params.pop('random_state')\n        if 'seed' in xgb_params and xgb_params['seed'] is not None:\n            warnings.warn('The seed parameter is deprecated as of version .6.'\n                          'Please use random_state instead.'\n                          'seed is deprecated.', DeprecationWarning)\n        else:\n            xgb_params['seed'] = random_state\n        n_jobs = xgb_params.pop('n_jobs')\n        if 'nthread' in xgb_params and xgb_params['nthread'] is not None:\n            warnings.warn('The nthread parameter is deprecated as of version .6.'\n                          'Please use n_jobs instead.'\n                          'nthread is deprecated.', DeprecationWarning)\n        else:\n            xgb_params['nthread'] = n_jobs\n\n        if 'silent' in xgb_params and xgb_params['silent'] is not None:\n            warnings.warn('The silent parameter is deprecated.'\n                          'Please use verbosity instead.'\n                          'silent is depreated', DeprecationWarning)\n            # TODO(canonizer): set verbosity explicitly if silent is removed from xgboost,\n            # but remains in this API\n        else:\n            # silent=None shouldn't be passed to xgboost\n            xgb_params.pop('silent', None)\n\n        if xgb_params['nthread'] <= 0:\n            xgb_params.pop('nthread', None)\n        return xgb_params", "response": "Get the xgboost type parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_model(self, fname):\n        if self._Booster is None:\n            self._Booster = Booster({'nthread': self.n_jobs})\n        self._Booster.load_model(fname)", "response": "Loads the model from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfits the gradient boosting model to the given data.", "response": "def fit(self, X, y, sample_weight=None, eval_set=None, eval_metric=None,\n            early_stopping_rounds=None, verbose=True, xgb_model=None,\n            sample_weight_eval_set=None, callbacks=None):\n        # pylint: disable=missing-docstring,invalid-name,attribute-defined-outside-init\n        \"\"\"\n        Fit the gradient boosting model\n\n        Parameters\n        ----------\n        X : array_like\n            Feature matrix\n        y : array_like\n            Labels\n        sample_weight : array_like\n            instance weights\n        eval_set : list, optional\n            A list of (X, y) tuple pairs to use as a validation set for\n            early-stopping\n        sample_weight_eval_set : list, optional\n            A list of the form [L_1, L_2, ..., L_n], where each L_i is a list of\n            instance weights on the i-th validation set.\n        eval_metric : str, callable, optional\n            If a str, should be a built-in evaluation metric to use. See\n            doc/parameter.rst. If callable, a custom evaluation metric. The call\n            signature is func(y_predicted, y_true) where y_true will be a\n            DMatrix object such that you may need to call the get_label\n            method. It must return a str, value pair where the str is a name\n            for the evaluation and value is the value of the evaluation\n            function. This objective is always minimized.\n        early_stopping_rounds : int\n            Activates early stopping. Validation error needs to decrease at\n            least every <early_stopping_rounds> round(s) to continue training.\n            Requires at least one item in evals.  If there's more than one,\n            will use the last. Returns the model from the last iteration\n            (not the best one). If early stopping occurs, the model will\n            have three additional fields: bst.best_score, bst.best_iteration\n            and bst.best_ntree_limit.\n            (Use bst.best_ntree_limit to get the correct value if num_parallel_tree\n            and/or num_class appears in the parameters)\n        verbose : bool\n            If `verbose` and an evaluation set is used, writes the evaluation\n            metric measured on the validation set to stderr.\n        xgb_model : str\n            file name of stored xgb model or 'Booster' instance Xgb model to be\n            loaded before training (allows training continuation).\n        callbacks : list of callback functions\n            List of callback functions that are applied at end of each iteration.\n            It is possible to use predefined callbacks by using :ref:`callback_api`.\n            Example:\n\n            .. code-block:: python\n\n                [xgb.callback.reset_learning_rate(custom_rates)]\n        \"\"\"\n        if sample_weight is not None:\n            trainDmatrix = DMatrix(X, label=y, weight=sample_weight,\n                                   missing=self.missing, nthread=self.n_jobs)\n        else:\n            trainDmatrix = DMatrix(X, label=y, missing=self.missing, nthread=self.n_jobs)\n\n        evals_result = {}\n\n        if eval_set is not None:\n            if sample_weight_eval_set is None:\n                sample_weight_eval_set = [None] * len(eval_set)\n            evals = list(\n                DMatrix(eval_set[i][0], label=eval_set[i][1], missing=self.missing,\n                        weight=sample_weight_eval_set[i], nthread=self.n_jobs)\n                for i in range(len(eval_set)))\n            evals = list(zip(evals, [\"validation_{}\".format(i) for i in\n                                     range(len(evals))]))\n        else:\n            evals = ()\n\n        params = self.get_xgb_params()\n\n        if callable(self.objective):\n            obj = _objective_decorator(self.objective)\n            params[\"objective\"] = \"reg:linear\"\n        else:\n            obj = None\n\n        feval = eval_metric if callable(eval_metric) else None\n        if eval_metric is not None:\n            if callable(eval_metric):\n                eval_metric = None\n            else:\n                params.update({'eval_metric': eval_metric})\n\n        self._Booster = train(params, trainDmatrix,\n                              self.get_num_boosting_rounds(), evals=evals,\n                              early_stopping_rounds=early_stopping_rounds,\n                              evals_result=evals_result, obj=obj, feval=feval,\n                              verbose_eval=verbose, xgb_model=xgb_model,\n                              callbacks=callbacks)\n\n        if evals_result:\n            for val in evals_result.items():\n                evals_result_key = list(val[1].keys())[0]\n                evals_result[val[0]][evals_result_key] = val[1][evals_result_key]\n            self.evals_result_ = evals_result\n\n        if early_stopping_rounds is not None:\n            self.best_score = self._Booster.best_score\n            self.best_iteration = self._Booster.best_iteration\n            self.best_ntree_limit = self._Booster.best_ntree_limit\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef predict(self, data, output_margin=False, ntree_limit=None, validate_features=True):\n        # pylint: disable=missing-docstring,invalid-name\n        test_dmatrix = DMatrix(data, missing=self.missing, nthread=self.n_jobs)\n        # get ntree_limit to use - if none specified, default to\n        # best_ntree_limit if defined, otherwise 0.\n        if ntree_limit is None:\n            ntree_limit = getattr(self, \"best_ntree_limit\", 0)\n        return self.get_booster().predict(test_dmatrix,\n                                          output_margin=output_margin,\n                                          ntree_limit=ntree_limit,\n                                          validate_features=validate_features)", "response": "Predict with `data`.\n\n        .. note:: This function is not thread safe.\n\n          For each booster object, predict can only be called from one thread.\n          If you want to run prediction using multiple thread, call ``xgb.copy()`` to make copies\n          of model object and then call ``predict()``.\n\n        .. note:: Using ``predict()`` with DART booster\n\n          If the booster object is DART type, ``predict()`` will perform dropouts, i.e. only\n          some of the trees will be evaluated. This will produce incorrect results if ``data`` is\n          not the training data. To obtain correct results on test sets, set ``ntree_limit`` to\n          a nonzero value, e.g.\n\n          .. code-block:: python\n\n            preds = bst.predict(dtest, ntree_limit=num_round)\n\n        Parameters\n        ----------\n        data : DMatrix\n            The dmatrix storing the input.\n        output_margin : bool\n            Whether to output the raw untransformed margin value.\n        ntree_limit : int\n            Limit number of trees in the prediction; defaults to best_ntree_limit if defined\n            (i.e. it has been trained with early stopping), otherwise 0 (use all trees).\n        validate_features : bool\n            When this is True, validate that the Booster's and data's feature_names are identical.\n            Otherwise, it is assumed that the feature_names are the same.\n        Returns\n        -------\n        prediction : numpy array"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef apply(self, X, ntree_limit=0):\n        test_dmatrix = DMatrix(X, missing=self.missing, nthread=self.n_jobs)\n        return self.get_booster().predict(test_dmatrix,\n                                          pred_leaf=True,\n                                          ntree_limit=ntree_limit)", "response": "Predict the predicted leaf every tree for each sample."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfeature importances property .. note:: Feature importance is defined only for tree boosters Feature importance is only defined when the decision tree model is chosen as base learner (`booster=gbtree`). It is not defined for other base learner types, such as linear learners (`booster=gblinear`). Returns ------- feature_importances_ : array of shape ``[n_features]``", "response": "def feature_importances_(self):\n        \"\"\"\n        Feature importances property\n\n        .. note:: Feature importance is defined only for tree boosters\n\n            Feature importance is only defined when the decision tree model is chosen as base\n            learner (`booster=gbtree`). It is not defined for other base learner types, such\n            as linear learners (`booster=gblinear`).\n\n        Returns\n        -------\n        feature_importances_ : array of shape ``[n_features]``\n\n        \"\"\"\n        if getattr(self, 'booster', None) is not None and self.booster != 'gbtree':\n            raise AttributeError('Feature importance is not defined for Booster type {}'\n                                 .format(self.booster))\n        b = self.get_booster()\n        score = b.get_score(importance_type=self.importance_type)\n        all_features = [score.get(f, 0.) for f in b.feature_names]\n        all_features = np.array(all_features, dtype=np.float32)\n        return all_features / all_features.sum()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef coef_(self):\n        if getattr(self, 'booster', None) is not None and self.booster != 'gblinear':\n            raise AttributeError('Coefficients are not defined for Booster type {}'\n                                 .format(self.booster))\n        b = self.get_booster()\n        coef = np.array(json.loads(b.get_dump(dump_format='json')[0])['weight'])\n        # Logic for multiclass classification\n        n_classes = getattr(self, 'n_classes_', None)\n        if n_classes is not None:\n            if n_classes > 2:\n                assert len(coef.shape) == 1\n                assert coef.shape[0] % n_classes == 0\n                coef = coef.reshape((n_classes, -1))\n        return coef", "response": "Returns the weighted probability matrix for the base learner."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nintercepting (bias) property .. note:: Intercept is defined only for linear learners Intercept (bias) is only defined when the linear model is chosen as base learner (`booster=gblinear`). It is not defined for other base learner types, such as tree learners (`booster=gbtree`). Returns ------- intercept_ : array of shape ``(1,)`` or ``[n_classes]``", "response": "def intercept_(self):\n        \"\"\"\n        Intercept (bias) property\n\n        .. note:: Intercept is defined only for linear learners\n\n            Intercept (bias) is only defined when the linear model is chosen as base\n            learner (`booster=gblinear`). It is not defined for other base learner types, such\n            as tree learners (`booster=gbtree`).\n\n        Returns\n        -------\n        intercept_ : array of shape ``(1,)`` or ``[n_classes]``\n        \"\"\"\n        if getattr(self, 'booster', None) is not None and self.booster != 'gblinear':\n            raise AttributeError('Intercept (bias) is not defined for Booster type {}'\n                                 .format(self.booster))\n        b = self.get_booster()\n        return np.array(json.loads(b.get_dump(dump_format='json')[0])['bias'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fit(self, X, y, sample_weight=None, eval_set=None, eval_metric=None,\n            early_stopping_rounds=None, verbose=True, xgb_model=None,\n            sample_weight_eval_set=None, callbacks=None):\n        # pylint: disable = attribute-defined-outside-init,arguments-differ\n        \"\"\"\n        Fit gradient boosting classifier\n\n        Parameters\n        ----------\n        X : array_like\n            Feature matrix\n        y : array_like\n            Labels\n        sample_weight : array_like\n            Weight for each instance\n        eval_set : list, optional\n            A list of (X, y) pairs to use as a validation set for\n            early-stopping\n        sample_weight_eval_set : list, optional\n            A list of the form [L_1, L_2, ..., L_n], where each L_i is a list of\n            instance weights on the i-th validation set.\n        eval_metric : str, callable, optional\n            If a str, should be a built-in evaluation metric to use. See\n            doc/parameter.rst. If callable, a custom evaluation metric. The call\n            signature is func(y_predicted, y_true) where y_true will be a\n            DMatrix object such that you may need to call the get_label\n            method. It must return a str, value pair where the str is a name\n            for the evaluation and value is the value of the evaluation\n            function. This objective is always minimized.\n        early_stopping_rounds : int, optional\n            Activates early stopping. Validation error needs to decrease at\n            least every <early_stopping_rounds> round(s) to continue training.\n            Requires at least one item in evals. If there's more than one,\n            will use the last. If early stopping occurs, the model will have\n            three additional fields: bst.best_score, bst.best_iteration and\n            bst.best_ntree_limit (bst.best_ntree_limit is the ntree_limit parameter\n            default value in predict method if not any other value is specified).\n            (Use bst.best_ntree_limit to get the correct value if num_parallel_tree\n            and/or num_class appears in the parameters)\n        verbose : bool\n            If `verbose` and an evaluation set is used, writes the evaluation\n            metric measured on the validation set to stderr.\n        xgb_model : str\n            file name of stored xgb model or 'Booster' instance Xgb model to be\n            loaded before training (allows training continuation).\n        callbacks : list of callback functions\n            List of callback functions that are applied at end of each iteration.\n            It is possible to use predefined callbacks by using :ref:`callback_api`.\n            Example:\n\n            .. code-block:: python\n\n                [xgb.callback.reset_learning_rate(custom_rates)]\n        \"\"\"\n        evals_result = {}\n        self.classes_ = np.unique(y)\n        self.n_classes_ = len(self.classes_)\n\n        xgb_options = self.get_xgb_params()\n\n        if callable(self.objective):\n            obj = _objective_decorator(self.objective)\n            # Use default value. Is it really not used ?\n            xgb_options[\"objective\"] = \"binary:logistic\"\n        else:\n            obj = None\n\n        if self.n_classes_ > 2:\n            # Switch to using a multiclass objective in the underlying XGB instance\n            xgb_options[\"objective\"] = \"multi:softprob\"\n            xgb_options['num_class'] = self.n_classes_\n\n        feval = eval_metric if callable(eval_metric) else None\n        if eval_metric is not None:\n            if callable(eval_metric):\n                eval_metric = None\n            else:\n                xgb_options.update({\"eval_metric\": eval_metric})\n\n        self._le = XGBLabelEncoder().fit(y)\n        training_labels = self._le.transform(y)\n\n        if eval_set is not None:\n            if sample_weight_eval_set is None:\n                sample_weight_eval_set = [None] * len(eval_set)\n            evals = list(\n                DMatrix(eval_set[i][0], label=self._le.transform(eval_set[i][1]),\n                        missing=self.missing, weight=sample_weight_eval_set[i],\n                        nthread=self.n_jobs)\n                for i in range(len(eval_set))\n            )\n            nevals = len(evals)\n            eval_names = [\"validation_{}\".format(i) for i in range(nevals)]\n            evals = list(zip(evals, eval_names))\n        else:\n            evals = ()\n\n        self._features_count = X.shape[1]\n\n        if sample_weight is not None:\n            train_dmatrix = DMatrix(X, label=training_labels, weight=sample_weight,\n                                    missing=self.missing, nthread=self.n_jobs)\n        else:\n            train_dmatrix = DMatrix(X, label=training_labels,\n                                    missing=self.missing, nthread=self.n_jobs)\n\n        self._Booster = train(xgb_options, train_dmatrix, self.get_num_boosting_rounds(),\n                              evals=evals, early_stopping_rounds=early_stopping_rounds,\n                              evals_result=evals_result, obj=obj, feval=feval,\n                              verbose_eval=verbose, xgb_model=xgb_model,\n                              callbacks=callbacks)\n\n        self.objective = xgb_options[\"objective\"]\n        if evals_result:\n            for val in evals_result.items():\n                evals_result_key = list(val[1].keys())[0]\n                evals_result[val[0]][evals_result_key] = val[1][evals_result_key]\n            self.evals_result_ = evals_result\n\n        if early_stopping_rounds is not None:\n            self.best_score = self._Booster.best_score\n            self.best_iteration = self._Booster.best_iteration\n            self.best_ntree_limit = self._Booster.best_ntree_limit\n\n        return self", "response": "Fit gradient boosting classifier to the given data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef predict(self, data, output_margin=False, ntree_limit=None, validate_features=True):\n        test_dmatrix = DMatrix(data, missing=self.missing, nthread=self.n_jobs)\n        if ntree_limit is None:\n            ntree_limit = getattr(self, \"best_ntree_limit\", 0)\n        class_probs = self.get_booster().predict(test_dmatrix,\n                                                 output_margin=output_margin,\n                                                 ntree_limit=ntree_limit,\n                                                 validate_features=validate_features)\n        if output_margin:\n            # If output_margin is active, simply return the scores\n            return class_probs\n\n        if len(class_probs.shape) > 1:\n            column_indexes = np.argmax(class_probs, axis=1)\n        else:\n            column_indexes = np.repeat(0, class_probs.shape[0])\n            column_indexes[class_probs > 0.5] = 1\n        return self._le.inverse_transform(column_indexes)", "response": "Predict with `data`.\n\n        .. note:: This function is not thread safe.\n\n          For each booster object, predict can only be called from one thread.\n          If you want to run prediction using multiple thread, call ``xgb.copy()`` to make copies\n          of model object and then call ``predict()``.\n\n        .. note:: Using ``predict()`` with DART booster\n\n          If the booster object is DART type, ``predict()`` will perform dropouts, i.e. only\n          some of the trees will be evaluated. This will produce incorrect results if ``data`` is\n          not the training data. To obtain correct results on test sets, set ``ntree_limit`` to\n          a nonzero value, e.g.\n\n          .. code-block:: python\n\n            preds = bst.predict(dtest, ntree_limit=num_round)\n\n        Parameters\n        ----------\n        data : DMatrix\n            The dmatrix storing the input.\n        output_margin : bool\n            Whether to output the raw untransformed margin value.\n        ntree_limit : int\n            Limit number of trees in the prediction; defaults to best_ntree_limit if defined\n            (i.e. it has been trained with early stopping), otherwise 0 (use all trees).\n        validate_features : bool\n            When this is True, validate that the Booster's and data's feature_names are identical.\n            Otherwise, it is assumed that the feature_names are the same.\n        Returns\n        -------\n        prediction : numpy array"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef predict_proba(self, data, ntree_limit=None, validate_features=True):\n        test_dmatrix = DMatrix(data, missing=self.missing, nthread=self.n_jobs)\n        if ntree_limit is None:\n            ntree_limit = getattr(self, \"best_ntree_limit\", 0)\n        class_probs = self.get_booster().predict(test_dmatrix,\n                                                 ntree_limit=ntree_limit,\n                                                 validate_features=validate_features)\n        if self.objective == \"multi:softprob\":\n            return class_probs\n        classone_probs = class_probs\n        classzero_probs = 1.0 - classone_probs\n        return np.vstack((classzero_probs, classone_probs)).transpose()", "response": "Predict the probability of each data example being of a given class."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfitting the gradient boosting model to the data points X and y.", "response": "def fit(self, X, y, group, sample_weight=None, eval_set=None, sample_weight_eval_set=None,\n            eval_group=None, eval_metric=None, early_stopping_rounds=None,\n            verbose=False, xgb_model=None, callbacks=None):\n        # pylint: disable = attribute-defined-outside-init,arguments-differ\n        \"\"\"\n        Fit the gradient boosting model\n\n        Parameters\n        ----------\n        X : array_like\n            Feature matrix\n        y : array_like\n            Labels\n        group : array_like\n            group size of training data\n        sample_weight : array_like\n            group weights\n\n            .. note:: Weights are per-group for ranking tasks\n\n                In ranking task, one weight is assigned to each group (not each data\n                point). This is because we only care about the relative ordering of\n                data points within each group, so it doesn't make sense to assign\n                weights to individual data points.\n\n        eval_set : list, optional\n            A list of (X, y) tuple pairs to use as a validation set for\n            early-stopping\n        sample_weight_eval_set : list, optional\n            A list of the form [L_1, L_2, ..., L_n], where each L_i is a list of\n            group weights on the i-th validation set.\n\n            .. note:: Weights are per-group for ranking tasks\n\n                In ranking task, one weight is assigned to each group (not each data\n                point). This is because we only care about the relative ordering of\n                data points within each group, so it doesn't make sense to assign\n                weights to individual data points.\n\n        eval_group : list of arrays, optional\n            A list that contains the group size corresponds to each\n            (X, y) pair in eval_set\n        eval_metric : str, callable, optional\n            If a str, should be a built-in evaluation metric to use. See\n            doc/parameter.rst. If callable, a custom evaluation metric. The call\n            signature is func(y_predicted, y_true) where y_true will be a\n            DMatrix object such that you may need to call the get_label\n            method. It must return a str, value pair where the str is a name\n            for the evaluation and value is the value of the evaluation\n            function. This objective is always minimized.\n        early_stopping_rounds : int\n            Activates early stopping. Validation error needs to decrease at\n            least every <early_stopping_rounds> round(s) to continue training.\n            Requires at least one item in evals.  If there's more than one,\n            will use the last. Returns the model from the last iteration\n            (not the best one). If early stopping occurs, the model will\n            have three additional fields: bst.best_score, bst.best_iteration\n            and bst.best_ntree_limit.\n            (Use bst.best_ntree_limit to get the correct value if num_parallel_tree\n            and/or num_class appears in the parameters)\n        verbose : bool\n            If `verbose` and an evaluation set is used, writes the evaluation\n            metric measured on the validation set to stderr.\n        xgb_model : str\n            file name of stored xgb model or 'Booster' instance Xgb model to be\n            loaded before training (allows training continuation).\n        callbacks : list of callback functions\n            List of callback functions that are applied at end of each iteration.\n            It is possible to use predefined callbacks by using :ref:`callback_api`.\n            Example:\n\n            .. code-block:: python\n\n                [xgb.callback.reset_learning_rate(custom_rates)]\n        \"\"\"\n        # check if group information is provided\n        if group is None:\n            raise ValueError(\"group is required for ranking task\")\n\n        if eval_set is not None:\n            if eval_group is None:\n                raise ValueError(\"eval_group is required if eval_set is not None\")\n            if len(eval_group) != len(eval_set):\n                raise ValueError(\"length of eval_group should match that of eval_set\")\n            if any(group is None for group in eval_group):\n                raise ValueError(\"group is required for all eval datasets for ranking task\")\n\n        def _dmat_init(group, **params):\n            ret = DMatrix(**params)\n            ret.set_group(group)\n            return ret\n\n        if sample_weight is not None:\n            train_dmatrix = _dmat_init(group, data=X, label=y, weight=sample_weight,\n                                       missing=self.missing, nthread=self.n_jobs)\n        else:\n            train_dmatrix = _dmat_init(group, data=X, label=y,\n                                       missing=self.missing, nthread=self.n_jobs)\n\n        evals_result = {}\n\n        if eval_set is not None:\n            if sample_weight_eval_set is None:\n                sample_weight_eval_set = [None] * len(eval_set)\n            evals = [_dmat_init(eval_group[i], data=eval_set[i][0], label=eval_set[i][1],\n                                missing=self.missing, weight=sample_weight_eval_set[i],\n                                nthread=self.n_jobs) for i in range(len(eval_set))]\n            nevals = len(evals)\n            eval_names = [\"eval_{}\".format(i) for i in range(nevals)]\n            evals = list(zip(evals, eval_names))\n        else:\n            evals = ()\n\n        params = self.get_xgb_params()\n\n        feval = eval_metric if callable(eval_metric) else None\n        if eval_metric is not None:\n            if callable(eval_metric):\n                eval_metric = None\n            else:\n                params.update({'eval_metric': eval_metric})\n\n        self._Booster = train(params, train_dmatrix,\n                              self.n_estimators,\n                              early_stopping_rounds=early_stopping_rounds, evals=evals,\n                              evals_result=evals_result, feval=feval,\n                              verbose_eval=verbose, xgb_model=xgb_model,\n                              callbacks=callbacks)\n\n        self.objective = params[\"objective\"]\n\n        if evals_result:\n            for val in evals_result.items():\n                evals_result_key = list(val[1].keys())[0]\n                evals_result[val[0]][evals_result_key] = val[1][evals_result_key]\n            self.evals_result = evals_result\n\n        if early_stopping_rounds is not None:\n            self.best_score = self._Booster.best_score\n            self.best_iteration = self._Booster.best_iteration\n            self.best_ntree_limit = self._Booster.best_ntree_limit\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_pystr_to_cstr(data):\n\n    if not isinstance(data, list):\n        raise NotImplementedError\n    pointers = (ctypes.c_char_p * len(data))()\n    if PY3:\n        data = [bytes(d, 'utf-8') for d in data]\n    else:\n        data = [d.encode('utf-8') if isinstance(d, unicode) else d  # pylint: disable=undefined-variable\n                for d in data]\n    pointers[:] = data\n    return pointers", "response": "Convert a list of Python str to C pointer"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_cstr_to_pystr(data, length):\n    if PY3:\n        res = []\n        for i in range(length.value):\n            try:\n                res.append(str(data[i].decode('ascii')))\n            except UnicodeDecodeError:\n                res.append(str(data[i].decode('utf-8')))\n    else:\n        res = []\n        for i in range(length.value):\n            try:\n                res.append(str(data[i].decode('ascii')))\n            except UnicodeDecodeError:\n                # pylint: disable=undefined-variable\n                res.append(unicode(data[i].decode('utf-8')))\n    return res", "response": "Revert C pointer to Python str\n    Parameters ---------- data - ctypes pointer to data length - ctypes pointer to length of data Returns ------- list of strings"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a ctypes pointer array to a numpy array.", "response": "def ctypes2numpy(cptr, length, dtype):\n    \"\"\"Convert a ctypes pointer array to a numpy array.\n    \"\"\"\n    NUMPY_TO_CTYPES_MAPPING = {\n        np.float32: ctypes.c_float,\n        np.uint32: ctypes.c_uint,\n    }\n    if dtype not in NUMPY_TO_CTYPES_MAPPING:\n        raise RuntimeError('Supported types: {}'.format(NUMPY_TO_CTYPES_MAPPING.keys()))\n    ctype = NUMPY_TO_CTYPES_MAPPING[dtype]\n    if not isinstance(cptr, ctypes.POINTER(ctype)):\n        raise RuntimeError('expected {} pointer'.format(ctype))\n    res = np.zeros(length, dtype=dtype)\n    if not ctypes.memmove(res.ctypes.data, cptr, length * res.strides[0]):\n        raise RuntimeError('memmove failed')\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting ctypes pointer to buffer type.", "response": "def ctypes2buffer(cptr, length):\n    \"\"\"Convert ctypes pointer to buffer type.\"\"\"\n    if not isinstance(cptr, ctypes.POINTER(ctypes.c_char)):\n        raise RuntimeError('expected char pointer')\n    res = bytearray(length)\n    rptr = (ctypes.c_char * length).from_buffer(res)\n    if not ctypes.memmove(rptr, cptr, length):\n        raise RuntimeError('memmove failed')\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef c_array(ctype, values):\n    if isinstance(values, np.ndarray) and values.dtype.itemsize == ctypes.sizeof(ctype):\n        return (ctype * len(values)).from_buffer_copy(values)\n    return (ctype * len(values))(*values)", "response": "Convert a python string to c array."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _maybe_pandas_data(data, feature_names, feature_types):\n\n    if not isinstance(data, DataFrame):\n        return data, feature_names, feature_types\n\n    data_dtypes = data.dtypes\n    if not all(dtype.name in PANDAS_DTYPE_MAPPER for dtype in data_dtypes):\n        bad_fields = [data.columns[i] for i, dtype in\n                      enumerate(data_dtypes) if dtype.name not in PANDAS_DTYPE_MAPPER]\n\n        msg = \"\"\"DataFrame.dtypes for data must be int, float or bool.\n                Did not expect the data types in fields \"\"\"\n        raise ValueError(msg + ', '.join(bad_fields))\n\n    if feature_names is None:\n        if isinstance(data.columns, MultiIndex):\n            feature_names = [\n                ' '.join([str(x) for x in i])\n                for i in data.columns\n            ]\n        else:\n            feature_names = data.columns.format()\n\n    if feature_types is None:\n        feature_types = [PANDAS_DTYPE_MAPPER[dtype.name] for dtype in data_dtypes]\n\n    data = data.values.astype('float')\n\n    return data, feature_names, feature_types", "response": "Extract internal data from pandas. DataFrame for DMatrix data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating data and return a new table with the correct feature names and feature types.", "response": "def _maybe_dt_data(data, feature_names, feature_types):\n    \"\"\"\n    Validate feature names and types if data table\n    \"\"\"\n    if not isinstance(data, DataTable):\n        return data, feature_names, feature_types\n\n    data_types_names = tuple(lt.name for lt in data.ltypes)\n    bad_fields = [data.names[i]\n                  for i, type_name in enumerate(data_types_names)\n                  if type_name not in DT_TYPE_MAPPER]\n    if bad_fields:\n        msg = \"\"\"DataFrame.types for data must be int, float or bool.\n                Did not expect the data types in fields \"\"\"\n        raise ValueError(msg + ', '.join(bad_fields))\n\n    if feature_names is None:\n        feature_names = data.names\n\n        # always return stypes for dt ingestion\n        if feature_types is not None:\n            raise ValueError('DataTable has own feature types, cannot pass them in')\n        feature_types = np.vectorize(DT_TYPE_MAPPER2.get)(data_types_names)\n\n    return data, feature_names, feature_types"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _maybe_dt_array(array):\n    if not isinstance(array, DataTable) or array is None:\n        return array\n\n    if array.shape[1] > 1:\n        raise ValueError('DataTable for label or weight cannot have multiple columns')\n\n    # below requires new dt version\n    # extract first column\n    array = array.to_numpy()[:, 0].astype('float')\n\n    return array", "response": "Extract numpy array from single column data table"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _init_from_csr(self, csr):\n        if len(csr.indices) != len(csr.data):\n            raise ValueError('length mismatch: {} vs {}'.format(len(csr.indices), len(csr.data)))\n        handle = ctypes.c_void_p()\n        _check_call(_LIB.XGDMatrixCreateFromCSREx(c_array(ctypes.c_size_t, csr.indptr),\n                                                  c_array(ctypes.c_uint, csr.indices),\n                                                  c_array(ctypes.c_float, csr.data),\n                                                  ctypes.c_size_t(len(csr.indptr)),\n                                                  ctypes.c_size_t(len(csr.data)),\n                                                  ctypes.c_size_t(csr.shape[1]),\n                                                  ctypes.byref(handle)))\n        self.handle = handle", "response": "Initialize data from a CSR matrix."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _init_from_csc(self, csc):\n        if len(csc.indices) != len(csc.data):\n            raise ValueError('length mismatch: {} vs {}'.format(len(csc.indices), len(csc.data)))\n        handle = ctypes.c_void_p()\n        _check_call(_LIB.XGDMatrixCreateFromCSCEx(c_array(ctypes.c_size_t, csc.indptr),\n                                                  c_array(ctypes.c_uint, csc.indices),\n                                                  c_array(ctypes.c_float, csc.data),\n                                                  ctypes.c_size_t(len(csc.indptr)),\n                                                  ctypes.c_size_t(len(csc.data)),\n                                                  ctypes.c_size_t(csc.shape[0]),\n                                                  ctypes.byref(handle)))\n        self.handle = handle", "response": "Initialize data from a CSC matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_from_npy2d(self, mat, missing, nthread):\n        if len(mat.shape) != 2:\n            raise ValueError('Input numpy.ndarray must be 2 dimensional')\n        # flatten the array by rows and ensure it is float32.\n        # we try to avoid data copies if possible (reshape returns a view when possible\n        # and we explicitly tell np.array to try and avoid copying)\n        data = np.array(mat.reshape(mat.size), copy=False, dtype=np.float32)\n        handle = ctypes.c_void_p()\n        missing = missing if missing is not None else np.nan\n        if nthread is None:\n            _check_call(_LIB.XGDMatrixCreateFromMat(\n                data.ctypes.data_as(ctypes.POINTER(ctypes.c_float)),\n                c_bst_ulong(mat.shape[0]),\n                c_bst_ulong(mat.shape[1]),\n                ctypes.c_float(missing),\n                ctypes.byref(handle)))\n        else:\n            _check_call(_LIB.XGDMatrixCreateFromMat_omp(\n                data.ctypes.data_as(ctypes.POINTER(ctypes.c_float)),\n                c_bst_ulong(mat.shape[0]),\n                c_bst_ulong(mat.shape[1]),\n                ctypes.c_float(missing),\n                ctypes.byref(handle),\n                nthread))\n        self.handle = handle", "response": "Initialize data from a 2 - D numpy matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _init_from_dt(self, data, nthread):\n        ptrs = (ctypes.c_void_p * data.ncols)()\n        if hasattr(data, \"internal\") and hasattr(data.internal, \"column\"):\n            # datatable>0.8.0\n            for icol in range(data.ncols):\n                col = data.internal.column(icol)\n                ptr = col.data_pointer\n                ptrs[icol] = ctypes.c_void_p(ptr)\n        else:\n            # datatable<=0.8.0\n            from datatable.internal import frame_column_data_r  # pylint: disable=no-name-in-module,import-error\n            for icol in range(data.ncols):\n                ptrs[icol] = frame_column_data_r(data, icol)\n\n        # always return stypes for dt ingestion\n        feature_type_strings = (ctypes.c_char_p * data.ncols)()\n        for icol in range(data.ncols):\n            feature_type_strings[icol] = ctypes.c_char_p(data.stypes[icol].name.encode('utf-8'))\n\n        handle = ctypes.c_void_p()\n        _check_call(_LIB.XGDMatrixCreateFromDT(\n            ptrs, feature_type_strings,\n            c_bst_ulong(data.shape[0]),\n            c_bst_ulong(data.shape[1]),\n            ctypes.byref(handle),\n            nthread))\n        self.handle = handle", "response": "Initialize data from a datatable Frame."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_float_info(self, field, data):\n        if getattr(data, 'base', None) is not None and \\\n           data.base is not None and isinstance(data, np.ndarray) \\\n           and isinstance(data.base, np.ndarray) and (not data.flags.c_contiguous):\n            self.set_float_info_npy2d(field, data)\n            return\n        c_data = c_array(ctypes.c_float, data)\n        _check_call(_LIB.XGDMatrixSetFloatInfo(self.handle,\n                                               c_str(field),\n                                               c_data,\n                                               c_bst_ulong(len(data))))", "response": "Set the float type property into the DMatrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_float_info_npy2d(self, field, data):\n        if getattr(data, 'base', None) is not None and \\\n           data.base is not None and isinstance(data, np.ndarray) \\\n           and isinstance(data.base, np.ndarray) and (not data.flags.c_contiguous):\n            warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n                          \"because it will generate extra copies and increase memory consumption\")\n            data = np.array(data, copy=True, dtype=np.float32)\n        else:\n            data = np.array(data, copy=False, dtype=np.float32)\n        c_data = data.ctypes.data_as(ctypes.POINTER(ctypes.c_float))\n        _check_call(_LIB.XGDMatrixSetFloatInfo(self.handle,\n                                               c_str(field),\n                                               c_data,\n                                               c_bst_ulong(len(data))))", "response": "Set the float type property into the DMatrix holding the contents of the numpy array input."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_uint_info(self, field, data):\n        if getattr(data, 'base', None) is not None and \\\n           data.base is not None and isinstance(data, np.ndarray) \\\n           and isinstance(data.base, np.ndarray) and (not data.flags.c_contiguous):\n            warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n                          \"because it will generate extra copies and increase memory consumption\")\n            data = np.array(data, copy=True, dtype=ctypes.c_uint)\n        else:\n            data = np.array(data, copy=False, dtype=ctypes.c_uint)\n        _check_call(_LIB.XGDMatrixSetUIntInfo(self.handle,\n                                              c_str(field),\n                                              c_array(ctypes.c_uint, data),\n                                              c_bst_ulong(len(data))))", "response": "Set the uint type property into the DMatrix."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving DMatrix to an XGBoost buffer.", "response": "def save_binary(self, fname, silent=True):\n        \"\"\"Save DMatrix to an XGBoost buffer.  Saved binary can be later loaded\n        by providing the path to :py:func:`xgboost.DMatrix` as input.\n\n        Parameters\n        ----------\n        fname : string\n            Name of the output buffer file.\n        silent : bool (optional; default: True)\n            If set, the output is suppressed.\n        \"\"\"\n        _check_call(_LIB.XGDMatrixSaveBinary(self.handle,\n                                             c_str(fname),\n                                             ctypes.c_int(silent)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_group(self, group):\n        _check_call(_LIB.XGDMatrixSetGroup(self.handle,\n                                           c_array(ctypes.c_uint, group),\n                                           c_bst_ulong(len(group))))", "response": "Set the size of DMatrix."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget feature names (column labels). Returns ------- feature_names : list or None", "response": "def feature_names(self):\n        \"\"\"Get feature names (column labels).\n\n        Returns\n        -------\n        feature_names : list or None\n        \"\"\"\n        if self._feature_names is None:\n            self._feature_names = ['f{0}'.format(i) for i in range(self.num_col())]\n        return self._feature_names"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the feature names for the current locale.", "response": "def feature_names(self, feature_names):\n        \"\"\"Set feature names (column labels).\n\n        Parameters\n        ----------\n        feature_names : list or None\n            Labels for features. None will reset existing feature names\n        \"\"\"\n        if feature_names is not None:\n            # validate feature name\n            try:\n                if not isinstance(feature_names, str):\n                    feature_names = [n for n in iter(feature_names)]\n                else:\n                    feature_names = [feature_names]\n            except TypeError:\n                feature_names = [feature_names]\n\n            if len(feature_names) != len(set(feature_names)):\n                raise ValueError('feature_names must be unique')\n            if len(feature_names) != self.num_col():\n                msg = 'feature_names must have the same length as data'\n                raise ValueError(msg)\n            # prohibit to use symbols may affect to parse. e.g. []<\n            if not all(isinstance(f, STRING_TYPES) and\n                       not any(x in f for x in set(('[', ']', '<')))\n                       for f in feature_names):\n                raise ValueError('feature_names may not contain [, ] or <')\n        else:\n            # reset feature_types also\n            self.feature_types = None\n        self._feature_names = feature_names"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef feature_types(self, feature_types):\n        if feature_types is not None:\n            if self._feature_names is None:\n                msg = 'Unable to set feature types before setting names'\n                raise ValueError(msg)\n\n            if isinstance(feature_types, STRING_TYPES):\n                # single string will be applied to all columns\n                feature_types = [feature_types] * self.num_col()\n\n            try:\n                if not isinstance(feature_types, str):\n                    feature_types = [n for n in iter(feature_types)]\n                else:\n                    feature_types = [feature_types]\n            except TypeError:\n                feature_types = [feature_types]\n\n            if len(feature_types) != self.num_col():\n                msg = 'feature_types must have the same length as data'\n                raise ValueError(msg)\n\n            valid = ('int', 'float', 'i', 'q')\n            if not all(isinstance(f, STRING_TYPES) and f in valid\n                       for f in feature_types):\n                raise ValueError('All feature_names must be {int, float, i, q}')\n        self._feature_types = feature_types", "response": "Set the feature types of the log entry."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_rabit_checkpoint(self):\n        version = ctypes.c_int()\n        _check_call(_LIB.XGBoosterLoadRabitCheckpoint(\n            self.handle, ctypes.byref(version)))\n        return version.value", "response": "Initialize the model by load from rabit checkpoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef attr(self, key):\n        ret = ctypes.c_char_p()\n        success = ctypes.c_int()\n        _check_call(_LIB.XGBoosterGetAttr(\n            self.handle, c_str(key), ctypes.byref(ret), ctypes.byref(success)))\n        if success.value != 0:\n            return py_str(ret.value)\n        return None", "response": "Get the attribute string from the Booster."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the attributes stored in the Booster as a dictionary.", "response": "def attributes(self):\n        \"\"\"Get attributes stored in the Booster as a dictionary.\n\n        Returns\n        -------\n        result : dictionary of  attribute_name: attribute_value pairs of strings.\n            Returns an empty dict if there's no attributes.\n        \"\"\"\n        length = c_bst_ulong()\n        sarr = ctypes.POINTER(ctypes.c_char_p)()\n        _check_call(_LIB.XGBoosterGetAttrNames(self.handle,\n                                               ctypes.byref(length),\n                                               ctypes.byref(sarr)))\n        attr_names = from_cstr_to_pystr(sarr, length)\n        return {n: self.attr(n) for n in attr_names}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_attr(self, **kwargs):\n        for key, value in kwargs.items():\n            if value is not None:\n                if not isinstance(value, STRING_TYPES):\n                    raise ValueError(\"Set Attr only accepts string values\")\n                value = c_str(str(value))\n            _check_call(_LIB.XGBoosterSetAttr(\n                self.handle, c_str(key), value))", "response": "Set the attribute of the Booster."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets parameters into the Booster.", "response": "def set_param(self, params, value=None):\n        \"\"\"Set parameters into the Booster.\n\n        Parameters\n        ----------\n        params: dict/list/str\n           list of key,value pairs, dict of key to value or simply str key\n        value: optional\n           value of the specified parameter, when params is str key\n        \"\"\"\n        if isinstance(params, Mapping):\n            params = params.items()\n        elif isinstance(params, STRING_TYPES) and value is not None:\n            params = [(params, value)]\n        for key, val in params:\n            _check_call(_LIB.XGBoosterSetParam(self.handle, c_str(key), c_str(str(val))))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nevaluate the model on the input data.", "response": "def eval(self, data, name='eval', iteration=0):\n        \"\"\"Evaluate the model on mat.\n\n        Parameters\n        ----------\n        data : DMatrix\n            The dmatrix storing the input.\n\n        name : str, optional\n            The name of the dataset.\n\n        iteration : int, optional\n            The current iteration number.\n\n        Returns\n        -------\n        result: str\n            Evaluation result string.\n        \"\"\"\n        self._validate_features(data)\n        return self.eval_set([(data, name)], iteration)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npredict with data. .. note:: This function is not thread safe. For each booster object, predict can only be called from one thread. If you want to run prediction using multiple thread, call ``bst.copy()`` to make copies of model object and then call ``predict()``. .. note:: Using ``predict()`` with DART booster If the booster object is DART type, ``predict()`` will perform dropouts, i.e. only some of the trees will be evaluated. This will produce incorrect results if ``data`` is not the training data. To obtain correct results on test sets, set ``ntree_limit`` to a nonzero value, e.g. .. code-block:: python preds = bst.predict(dtest, ntree_limit=num_round) Parameters ---------- data : DMatrix The dmatrix storing the input. output_margin : bool Whether to output the raw untransformed margin value. ntree_limit : int Limit number of trees in the prediction; defaults to 0 (use all trees). pred_leaf : bool When this option is on, the output will be a matrix of (nsample, ntrees) with each record indicating the predicted leaf index of each sample in each tree. Note that the leaf index of a tree is unique per tree, so you may find leaf 1 in both tree 1 and tree 0. pred_contribs : bool When this is True the output will be a matrix of size (nsample, nfeats + 1) with each record indicating the feature contributions (SHAP values) for that prediction. The sum of all feature contributions is equal to the raw untransformed margin value of the prediction. Note the final column is the bias term. approx_contribs : bool Approximate the contributions of each feature pred_interactions : bool When this is True the output will be a matrix of size (nsample, nfeats + 1, nfeats + 1) indicating the SHAP interaction values for each pair of features. The sum of each row (or column) of the interaction values equals the corresponding SHAP value (from pred_contribs), and the sum of the entire matrix equals the raw untransformed margin value of the prediction. Note the last row and column correspond to the bias term. validate_features : bool When this is True, validate that the Booster's and data's feature_names are identical. Otherwise, it is assumed that the feature_names are the same. Returns ------- prediction : numpy array", "response": "def predict(self, data, output_margin=False, ntree_limit=0, pred_leaf=False,\n                pred_contribs=False, approx_contribs=False, pred_interactions=False,\n                validate_features=True):\n        \"\"\"\n        Predict with data.\n\n        .. note:: This function is not thread safe.\n\n          For each booster object, predict can only be called from one thread.\n          If you want to run prediction using multiple thread, call ``bst.copy()`` to make copies\n          of model object and then call ``predict()``.\n\n        .. note:: Using ``predict()`` with DART booster\n\n          If the booster object is DART type, ``predict()`` will perform dropouts, i.e. only\n          some of the trees will be evaluated. This will produce incorrect results if ``data`` is\n          not the training data. To obtain correct results on test sets, set ``ntree_limit`` to\n          a nonzero value, e.g.\n\n          .. code-block:: python\n\n            preds = bst.predict(dtest, ntree_limit=num_round)\n\n        Parameters\n        ----------\n        data : DMatrix\n            The dmatrix storing the input.\n\n        output_margin : bool\n            Whether to output the raw untransformed margin value.\n\n        ntree_limit : int\n            Limit number of trees in the prediction; defaults to 0 (use all trees).\n\n        pred_leaf : bool\n            When this option is on, the output will be a matrix of (nsample, ntrees)\n            with each record indicating the predicted leaf index of each sample in each tree.\n            Note that the leaf index of a tree is unique per tree, so you may find leaf 1\n            in both tree 1 and tree 0.\n\n        pred_contribs : bool\n            When this is True the output will be a matrix of size (nsample, nfeats + 1)\n            with each record indicating the feature contributions (SHAP values) for that\n            prediction. The sum of all feature contributions is equal to the raw untransformed\n            margin value of the prediction. Note the final column is the bias term.\n\n        approx_contribs : bool\n            Approximate the contributions of each feature\n\n        pred_interactions : bool\n            When this is True the output will be a matrix of size (nsample, nfeats + 1, nfeats + 1)\n            indicating the SHAP interaction values for each pair of features. The sum of each\n            row (or column) of the interaction values equals the corresponding SHAP value (from\n            pred_contribs), and the sum of the entire matrix equals the raw untransformed margin\n            value of the prediction. Note the last row and column correspond to the bias term.\n\n        validate_features : bool\n            When this is True, validate that the Booster's and data's feature_names are identical.\n            Otherwise, it is assumed that the feature_names are the same.\n\n        Returns\n        -------\n        prediction : numpy array\n        \"\"\"\n        option_mask = 0x00\n        if output_margin:\n            option_mask |= 0x01\n        if pred_leaf:\n            option_mask |= 0x02\n        if pred_contribs:\n            option_mask |= 0x04\n        if approx_contribs:\n            option_mask |= 0x08\n        if pred_interactions:\n            option_mask |= 0x10\n\n        if validate_features:\n            self._validate_features(data)\n\n        length = c_bst_ulong()\n        preds = ctypes.POINTER(ctypes.c_float)()\n        _check_call(_LIB.XGBoosterPredict(self.handle, data.handle,\n                                          ctypes.c_int(option_mask),\n                                          ctypes.c_uint(ntree_limit),\n                                          ctypes.byref(length),\n                                          ctypes.byref(preds)))\n        preds = ctypes2numpy(preds, length.value, np.float32)\n        if pred_leaf:\n            preds = preds.astype(np.int32)\n        nrow = data.num_row()\n        if preds.size != nrow and preds.size % nrow == 0:\n            chunk_size = int(preds.size / nrow)\n\n            if pred_interactions:\n                ngroup = int(chunk_size / ((data.num_col() + 1) * (data.num_col() + 1)))\n                if ngroup == 1:\n                    preds = preds.reshape(nrow, data.num_col() + 1, data.num_col() + 1)\n                else:\n                    preds = preds.reshape(nrow, ngroup, data.num_col() + 1, data.num_col() + 1)\n            elif pred_contribs:\n                ngroup = int(chunk_size / (data.num_col() + 1))\n                if ngroup == 1:\n                    preds = preds.reshape(nrow, data.num_col() + 1)\n                else:\n                    preds = preds.reshape(nrow, ngroup, data.num_col() + 1)\n            else:\n                preds = preds.reshape(nrow, chunk_size)\n        return preds"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves the model to a file.", "response": "def save_model(self, fname):\n        \"\"\"\n        Save the model to a file.\n\n        The model is saved in an XGBoost internal binary format which is\n        universal among the various XGBoost interfaces. Auxiliary attributes of\n        the Python Booster object (such as feature_names) will not be saved.\n        To preserve all attributes, pickle the Booster object.\n\n        Parameters\n        ----------\n        fname : string\n            Output file name\n        \"\"\"\n        if isinstance(fname, STRING_TYPES):  # assume file name\n            _check_call(_LIB.XGBoosterSaveModel(self.handle, c_str(fname)))\n        else:\n            raise TypeError(\"fname must be a string\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_model(self, fname):\n        if isinstance(fname, STRING_TYPES):\n            # assume file name, cannot use os.path.exist to check, file can be from URL.\n            _check_call(_LIB.XGBoosterLoadModel(self.handle, c_str(fname)))\n        else:\n            buf = fname\n            length = c_bst_ulong(len(buf))\n            ptr = (ctypes.c_char * len(buf)).from_buffer(buf)\n            _check_call(_LIB.XGBoosterLoadModelFromBuffer(self.handle, ptr, length))", "response": "Load the model from a file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndumping the model into a text or JSON file.", "response": "def dump_model(self, fout, fmap='', with_stats=False, dump_format=\"text\"):\n        \"\"\"\n        Dump model into a text or JSON file.\n\n        Parameters\n        ----------\n        fout : string\n            Output file name.\n        fmap : string, optional\n            Name of the file containing feature map names.\n        with_stats : bool, optional\n            Controls whether the split statistics are output.\n        dump_format : string, optional\n            Format of model dump file. Can be 'text' or 'json'.\n        \"\"\"\n        if isinstance(fout, STRING_TYPES):\n            fout = open(fout, 'w')\n            need_close = True\n        else:\n            need_close = False\n        ret = self.get_dump(fmap, with_stats, dump_format)\n        if dump_format == 'json':\n            fout.write('[\\n')\n            for i, _ in enumerate(ret):\n                fout.write(ret[i])\n                if i < len(ret) - 1:\n                    fout.write(\",\\n\")\n            fout.write('\\n]')\n        else:\n            for i, _ in enumerate(ret):\n                fout.write('booster[{}]:\\n'.format(i))\n                fout.write(ret[i])\n        if need_close:\n            fout.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the model dump as a list of strings.", "response": "def get_dump(self, fmap='', with_stats=False, dump_format=\"text\"):\n        \"\"\"\n        Returns the model dump as a list of strings.\n\n        Parameters\n        ----------\n        fmap : string, optional\n            Name of the file containing feature map names.\n        with_stats : bool, optional\n            Controls whether the split statistics are output.\n        dump_format : string, optional\n            Format of model dump. Can be 'text' or 'json'.\n        \"\"\"\n        length = c_bst_ulong()\n        sarr = ctypes.POINTER(ctypes.c_char_p)()\n        if self.feature_names is not None and fmap == '':\n            flen = len(self.feature_names)\n\n            fname = from_pystr_to_cstr(self.feature_names)\n\n            if self.feature_types is None:\n                # use quantitative as default\n                # {'q': quantitative, 'i': indicator}\n                ftype = from_pystr_to_cstr(['q'] * flen)\n            else:\n                ftype = from_pystr_to_cstr(self.feature_types)\n            _check_call(_LIB.XGBoosterDumpModelExWithFeatures(\n                self.handle,\n                ctypes.c_int(flen),\n                fname,\n                ftype,\n                ctypes.c_int(with_stats),\n                c_str(dump_format),\n                ctypes.byref(length),\n                ctypes.byref(sarr)))\n        else:\n            if fmap != '' and not os.path.exists(fmap):\n                raise ValueError(\"No such file: {0}\".format(fmap))\n            _check_call(_LIB.XGBoosterDumpModelEx(self.handle,\n                                                  c_str(fmap),\n                                                  ctypes.c_int(with_stats),\n                                                  c_str(dump_format),\n                                                  ctypes.byref(length),\n                                                  ctypes.byref(sarr)))\n        res = from_cstr_to_pystr(sarr, length)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the score of each feature in the given feature map file.", "response": "def get_score(self, fmap='', importance_type='weight'):\n        \"\"\"Get feature importance of each feature.\n        Importance type can be defined as:\n\n        * 'weight': the number of times a feature is used to split the data across all trees.\n        * 'gain': the average gain across all splits the feature is used in.\n        * 'cover': the average coverage across all splits the feature is used in.\n        * 'total_gain': the total gain across all splits the feature is used in.\n        * 'total_cover': the total coverage across all splits the feature is used in.\n\n        .. note:: Feature importance is defined only for tree boosters\n\n            Feature importance is only defined when the decision tree model is chosen as base\n            learner (`booster=gbtree`). It is not defined for other base learner types, such\n            as linear learners (`booster=gblinear`).\n\n        Parameters\n        ----------\n        fmap: str (optional)\n           The name of feature map file.\n        importance_type: str, default 'weight'\n            One of the importance types defined above.\n        \"\"\"\n        if getattr(self, 'booster', None) is not None and self.booster not in {'gbtree', 'dart'}:\n            raise ValueError('Feature importance is not defined for Booster type {}'\n                             .format(self.booster))\n\n        allowed_importance_types = ['weight', 'gain', 'cover', 'total_gain', 'total_cover']\n        if importance_type not in allowed_importance_types:\n            msg = (\"importance_type mismatch, got '{}', expected one of \" +\n                   repr(allowed_importance_types))\n            raise ValueError(msg.format(importance_type))\n\n        # if it's weight, then omap stores the number of missing values\n        if importance_type == 'weight':\n            # do a simpler tree dump to save time\n            trees = self.get_dump(fmap, with_stats=False)\n\n            fmap = {}\n            for tree in trees:\n                for line in tree.split('\\n'):\n                    # look for the opening square bracket\n                    arr = line.split('[')\n                    # if no opening bracket (leaf node), ignore this line\n                    if len(arr) == 1:\n                        continue\n\n                    # extract feature name from string between []\n                    fid = arr[1].split(']')[0].split('<')[0]\n\n                    if fid not in fmap:\n                        # if the feature hasn't been seen yet\n                        fmap[fid] = 1\n                    else:\n                        fmap[fid] += 1\n\n            return fmap\n\n        average_over_splits = True\n        if importance_type == 'total_gain':\n            importance_type = 'gain'\n            average_over_splits = False\n        elif importance_type == 'total_cover':\n            importance_type = 'cover'\n            average_over_splits = False\n\n        trees = self.get_dump(fmap, with_stats=True)\n\n        importance_type += '='\n        fmap = {}\n        gmap = {}\n        for tree in trees:\n            for line in tree.split('\\n'):\n                # look for the opening square bracket\n                arr = line.split('[')\n                # if no opening bracket (leaf node), ignore this line\n                if len(arr) == 1:\n                    continue\n\n                # look for the closing bracket, extract only info within that bracket\n                fid = arr[1].split(']')\n\n                # extract gain or cover from string after closing bracket\n                g = float(fid[1].split(importance_type)[1].split(',')[0])\n\n                # extract feature name from string before closing bracket\n                fid = fid[0].split('<')[0]\n\n                if fid not in fmap:\n                    # if the feature hasn't been seen yet\n                    fmap[fid] = 1\n                    gmap[fid] = g\n                else:\n                    fmap[fid] += 1\n                    gmap[fid] += g\n\n        # calculate average value (gain/cover) for each feature\n        if average_over_splits:\n            for fid in gmap:\n                gmap[fid] = gmap[fid] / fmap[fid]\n\n        return gmap"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trees_to_dataframe(self, fmap=''):\n        # pylint: disable=too-many-locals\n        if not PANDAS_INSTALLED:\n            raise Exception(('pandas must be available to use this method.'\n                             'Install pandas before calling again.'))\n\n        if getattr(self, 'booster', None) is not None and self.booster not in {'gbtree', 'dart'}:\n            raise ValueError('This method is not defined for Booster type {}'\n                             .format(self.booster))\n\n        tree_ids = []\n        node_ids = []\n        fids = []\n        splits = []\n        y_directs = []\n        n_directs = []\n        missings = []\n        gains = []\n        covers = []\n\n        trees = self.get_dump(fmap, with_stats=True)\n        for i, tree in enumerate(trees):\n            for line in tree.split('\\n'):\n                arr = line.split('[')\n                # Leaf node\n                if len(arr) == 1:\n                    # Last element of line.split is an empy string\n                    if arr == ['']:\n                        continue\n                    # parse string\n                    parse = arr[0].split(':')\n                    stats = re.split('=|,', parse[1])\n\n                    # append to lists\n                    tree_ids.append(i)\n                    node_ids.append(int(re.findall(r'\\b\\d+\\b', parse[0])[0]))\n                    fids.append('Leaf')\n                    splits.append(float('NAN'))\n                    y_directs.append(float('NAN'))\n                    n_directs.append(float('NAN'))\n                    missings.append(float('NAN'))\n                    gains.append(float(stats[1]))\n                    covers.append(float(stats[3]))\n                # Not a Leaf Node\n                else:\n                    # parse string\n                    fid = arr[1].split(']')\n                    parse = fid[0].split('<')\n                    stats = re.split('=|,', fid[1])\n\n                    # append to lists\n                    tree_ids.append(i)\n                    node_ids.append(int(re.findall(r'\\b\\d+\\b', arr[0])[0]))\n                    fids.append(parse[0])\n                    splits.append(float(parse[1]))\n                    str_i = str(i)\n                    y_directs.append(str_i + '-' + stats[1])\n                    n_directs.append(str_i + '-' + stats[3])\n                    missings.append(str_i + '-' + stats[5])\n                    gains.append(float(stats[7]))\n                    covers.append(float(stats[9]))\n\n        ids = [str(t_id) + '-' + str(n_id) for t_id, n_id in zip(tree_ids, node_ids)]\n        df = DataFrame({'Tree': tree_ids, 'Node': node_ids, 'ID': ids,\n                        'Feature': fids, 'Split': splits, 'Yes': y_directs,\n                        'No': n_directs, 'Missing': missings, 'Gain': gains,\n                        'Cover': covers})\n\n        if callable(getattr(df, 'sort_values', None)):\n            # pylint: disable=no-member\n            return df.sort_values(['Tree', 'Node']).reset_index(drop=True)\n        # pylint: disable=no-member\n        return df.sort(['Tree', 'Node']).reset_index(drop=True)", "response": "Parse a boosted tree model text dump into a pandas DataFrame structure."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _validate_features(self, data):\n        if self.feature_names is None:\n            self.feature_names = data.feature_names\n            self.feature_types = data.feature_types\n        else:\n            # Booster can't accept data with different feature names\n            if self.feature_names != data.feature_names:\n                dat_missing = set(self.feature_names) - set(data.feature_names)\n                my_missing = set(data.feature_names) - set(self.feature_names)\n\n                msg = 'feature_names mismatch: {0} {1}'\n\n                if dat_missing:\n                    msg += ('\\nexpected ' + ', '.join(str(s) for s in dat_missing) +\n                            ' in input data')\n\n                if my_missing:\n                    msg += ('\\ntraining data did not have the following fields: ' +\n                            ', '.join(str(s) for s in my_missing))\n\n                raise ValueError(msg.format(self.feature_names,\n                                            data.feature_names))", "response": "Validate Booster and data s feature_names are identical."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_split_value_histogram(self, feature, fmap='', bins=None, as_pandas=True):\n        xgdump = self.get_dump(fmap=fmap)\n        values = []\n        regexp = re.compile(r\"\\[{0}<([\\d.Ee+-]+)\\]\".format(feature))\n        for i, _ in enumerate(xgdump):\n            m = re.findall(regexp, xgdump[i])\n            values.extend([float(x) for x in m])\n\n        n_unique = len(np.unique(values))\n        bins = max(min(n_unique, bins) if bins is not None else n_unique, 1)\n\n        nph = np.histogram(values, bins=bins)\n        nph = np.column_stack((nph[1][1:], nph[0]))\n        nph = nph[nph[:, 1] > 0]\n\n        if as_pandas and PANDAS_INSTALLED:\n            return DataFrame(nph, columns=['SplitValue', 'Count'])\n        if as_pandas and not PANDAS_INSTALLED:\n            sys.stderr.write(\n                \"Returning histogram as ndarray (as_pandas == True, but pandas is not installed).\")\n        return nph", "response": "Get the split value histogram of a feature."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_importance(booster, ax=None, height=0.2,\n                    xlim=None, ylim=None, title='Feature importance',\n                    xlabel='F score', ylabel='Features',\n                    importance_type='weight', max_num_features=None,\n                    grid=True, show_values=True, **kwargs):\n    \"\"\"Plot importance based on fitted trees.\n\n    Parameters\n    ----------\n    booster : Booster, XGBModel or dict\n        Booster or XGBModel instance, or dict taken by Booster.get_fscore()\n    ax : matplotlib Axes, default None\n        Target axes instance. If None, new figure and axes will be created.\n    grid : bool, Turn the axes grids on or off.  Default is True (On).\n    importance_type : str, default \"weight\"\n        How the importance is calculated: either \"weight\", \"gain\", or \"cover\"\n\n        * \"weight\" is the number of times a feature appears in a tree\n        * \"gain\" is the average gain of splits which use the feature\n        * \"cover\" is the average coverage of splits which use the feature\n          where coverage is defined as the number of samples affected by the split\n    max_num_features : int, default None\n        Maximum number of top features displayed on plot. If None, all features will be displayed.\n    height : float, default 0.2\n        Bar height, passed to ax.barh()\n    xlim : tuple, default None\n        Tuple passed to axes.xlim()\n    ylim : tuple, default None\n        Tuple passed to axes.ylim()\n    title : str, default \"Feature importance\"\n        Axes title. To disable, pass None.\n    xlabel : str, default \"F score\"\n        X axis title label. To disable, pass None.\n    ylabel : str, default \"Features\"\n        Y axis title label. To disable, pass None.\n    show_values : bool, default True\n        Show values on plot. To disable, pass False.\n    kwargs :\n        Other keywords passed to ax.barh()\n\n    Returns\n    -------\n    ax : matplotlib Axes\n    \"\"\"\n    try:\n        import matplotlib.pyplot as plt\n    except ImportError:\n        raise ImportError('You must install matplotlib to plot importance')\n\n    if isinstance(booster, XGBModel):\n        importance = booster.get_booster().get_score(importance_type=importance_type)\n    elif isinstance(booster, Booster):\n        importance = booster.get_score(importance_type=importance_type)\n    elif isinstance(booster, dict):\n        importance = booster\n    else:\n        raise ValueError('tree must be Booster, XGBModel or dict instance')\n\n    if not importance:\n        raise ValueError('Booster.get_score() results in empty')\n\n    tuples = [(k, importance[k]) for k in importance]\n    if max_num_features is not None:\n        # pylint: disable=invalid-unary-operand-type\n        tuples = sorted(tuples, key=lambda x: x[1])[-max_num_features:]\n    else:\n        tuples = sorted(tuples, key=lambda x: x[1])\n    labels, values = zip(*tuples)\n\n    if ax is None:\n        _, ax = plt.subplots(1, 1)\n\n    ylocs = np.arange(len(values))\n    ax.barh(ylocs, values, align='center', height=height, **kwargs)\n\n    if show_values is True:\n        for x, y in zip(values, ylocs):\n            ax.text(x + 1, y, x, va='center')\n\n    ax.set_yticks(ylocs)\n    ax.set_yticklabels(labels)\n\n    if xlim is not None:\n        if not isinstance(xlim, tuple) or len(xlim) != 2:\n            raise ValueError('xlim must be a tuple of 2 elements')\n    else:\n        xlim = (0, max(values) * 1.1)\n    ax.set_xlim(xlim)\n\n    if ylim is not None:\n        if not isinstance(ylim, tuple) or len(ylim) != 2:\n            raise ValueError('ylim must be a tuple of 2 elements')\n    else:\n        ylim = (-1, len(values))\n    ax.set_ylim(ylim)\n\n    if title is not None:\n        ax.set_title(title)\n    if xlabel is not None:\n        ax.set_xlabel(xlabel)\n    if ylabel is not None:\n        ax.set_ylabel(ylabel)\n    ax.grid(grid)\n    return ax", "response": "Plots the importance of the fitted trees."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_graphviz(booster, fmap='', num_trees=0, rankdir='UT',\n                yes_color='#0000FF', no_color='#FF0000',\n                condition_node_params=None, leaf_node_params=None, **kwargs):\n    \"\"\"Convert specified tree to graphviz instance. IPython can automatically plot the\n    returned graphiz instance. Otherwise, you should call .render() method\n    of the returned graphiz instance.\n\n    Parameters\n    ----------\n    booster : Booster, XGBModel\n        Booster or XGBModel instance\n    fmap: str (optional)\n       The name of feature map file\n    num_trees : int, default 0\n        Specify the ordinal number of target tree\n    rankdir : str, default \"UT\"\n        Passed to graphiz via graph_attr\n    yes_color : str, default '#0000FF'\n        Edge color when meets the node condition.\n    no_color : str, default '#FF0000'\n        Edge color when doesn't meet the node condition.\n    condition_node_params : dict (optional)\n        condition node configuration,\n        {'shape':'box',\n               'style':'filled,rounded',\n               'fillcolor':'#78bceb'\n        }\n    leaf_node_params : dict (optional)\n        leaf node configuration\n        {'shape':'box',\n               'style':'filled',\n               'fillcolor':'#e48038'\n        }\n    kwargs :\n        Other keywords passed to graphviz graph_attr\n\n    Returns\n    -------\n    ax : matplotlib Axes\n    \"\"\"\n\n    if condition_node_params is None:\n        condition_node_params = {}\n    if leaf_node_params is None:\n        leaf_node_params = {}\n\n    try:\n        from graphviz import Digraph\n    except ImportError:\n        raise ImportError('You must install graphviz to plot tree')\n\n    if not isinstance(booster, (Booster, XGBModel)):\n        raise ValueError('booster must be Booster or XGBModel instance')\n\n    if isinstance(booster, XGBModel):\n        booster = booster.get_booster()\n\n    tree = booster.get_dump(fmap=fmap)[num_trees]\n    tree = tree.split()\n\n    kwargs = kwargs.copy()\n    kwargs.update({'rankdir': rankdir})\n    graph = Digraph(graph_attr=kwargs)\n\n    for i, text in enumerate(tree):\n        if text[0].isdigit():\n            node = _parse_node(\n                graph, text, condition_node_params=condition_node_params,\n                leaf_node_params=leaf_node_params)\n        else:\n            if i == 0:\n                # 1st string must be node\n                raise ValueError('Unable to parse given string as tree')\n            _parse_edge(graph, node, text, yes_color=yes_color,\n                        no_color=no_color)\n\n    return graph", "response": "Convert a tree to graphviz."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new action and assign callbacks shortcuts etc.", "response": "def newAction(parent, text, slot=None, shortcut=None, icon=None,\n              tip=None, checkable=False, enabled=True):\n    \"\"\"Create a new action and assign callbacks, shortcuts, etc.\"\"\"\n    a = QAction(text, parent)\n    if icon is not None:\n        a.setIcon(newIcon(icon))\n    if shortcut is not None:\n        if isinstance(shortcut, (list, tuple)):\n            a.setShortcuts(shortcut)\n        else:\n            a.setShortcut(shortcut)\n    if tip is not None:\n        a.setToolTip(tip)\n        a.setStatusTip(tip)\n    if slot is not None:\n        a.triggered.connect(slot)\n    if checkable:\n        a.setCheckable(True)\n    a.setEnabled(enabled)\n    return a"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsorts the list into natural alphanumeric order.", "response": "def natural_sort(list, key=lambda s:s):\n    \"\"\"\n    Sort the list into natural alphanumeric order.\n    \"\"\"\n    def get_alphanum_key_func(key):\n        convert = lambda text: int(text) if text.isdigit() else text\n        return lambda s: [convert(c) for c in re.split('([0-9]+)', key(s))]\n    sort_key = get_alphanum_key_func(key)\n    list.sort(key=sort_key)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating line with last point and current coordinates.", "response": "def mouseMoveEvent(self, ev):\n        \"\"\"Update line with last point and current coordinates.\"\"\"\n        pos = self.transformPos(ev.pos())\n\n        # Update coordinates in status bar if image is opened\n        window = self.parent().window()\n        if window.filePath is not None:\n            self.parent().window().labelCoordinates.setText(\n                'X: %d; Y: %d' % (pos.x(), pos.y()))\n\n        # Polygon drawing.\n        if self.drawing():\n            self.overrideCursor(CURSOR_DRAW)\n            if self.current:\n                color = self.drawingLineColor\n                if self.outOfPixmap(pos):\n                    # Don't allow the user to draw outside the pixmap.\n                    # Project the point to the pixmap's edges.\n                    pos = self.intersectionPoint(self.current[-1], pos)\n                elif len(self.current) > 1 and self.closeEnough(pos, self.current[0]):\n                    # Attract line to starting point and colorise to alert the\n                    # user:\n                    pos = self.current[0]\n                    color = self.current.line_color\n                    self.overrideCursor(CURSOR_POINT)\n                    self.current.highlightVertex(0, Shape.NEAR_VERTEX)\n\n                if self.drawSquare:\n                    initPos = self.current[0]\n                    minX = initPos.x()\n                    minY = initPos.y()\n                    min_size = min(abs(pos.x() - minX), abs(pos.y() - minY))\n                    directionX = -1 if pos.x() - minX < 0 else 1\n                    directionY = -1 if pos.y() - minY < 0 else 1\n                    self.line[1] = QPointF(minX + directionX * min_size, minY + directionY * min_size)\n                else:\n                    self.line[1] = pos\n\n                self.line.line_color = color\n                self.prevPoint = QPointF()\n                self.current.highlightClear()\n            else:\n                self.prevPoint = pos\n            self.repaint()\n            return\n\n        # Polygon copy moving.\n        if Qt.RightButton & ev.buttons():\n            if self.selectedShapeCopy and self.prevPoint:\n                self.overrideCursor(CURSOR_MOVE)\n                self.boundedMoveShape(self.selectedShapeCopy, pos)\n                self.repaint()\n            elif self.selectedShape:\n                self.selectedShapeCopy = self.selectedShape.copy()\n                self.repaint()\n            return\n\n        # Polygon/Vertex moving.\n        if Qt.LeftButton & ev.buttons():\n            if self.selectedVertex():\n                self.boundedMoveVertex(pos)\n                self.shapeMoved.emit()\n                self.repaint()\n            elif self.selectedShape and self.prevPoint:\n                self.overrideCursor(CURSOR_MOVE)\n                self.boundedMoveShape(self.selectedShape, pos)\n                self.shapeMoved.emit()\n                self.repaint()\n            return\n\n        # Just hovering over the canvas, 2 posibilities:\n        # - Highlight shapes\n        # - Highlight vertex\n        # Update shape/vertex fill and tooltip value accordingly.\n        self.setToolTip(\"Image\")\n        for shape in reversed([s for s in self.shapes if self.isVisible(s)]):\n            # Look for a nearby vertex to highlight. If that fails,\n            # check if we happen to be inside a shape.\n            index = shape.nearestVertex(pos, self.epsilon)\n            if index is not None:\n                if self.selectedVertex():\n                    self.hShape.highlightClear()\n                self.hVertex, self.hShape = index, shape\n                shape.highlightVertex(index, shape.MOVE_VERTEX)\n                self.overrideCursor(CURSOR_POINT)\n                self.setToolTip(\"Click & drag to move point\")\n                self.setStatusTip(self.toolTip())\n                self.update()\n                break\n            elif shape.containsPoint(pos):\n                if self.selectedVertex():\n                    self.hShape.highlightClear()\n                self.hVertex, self.hShape = None, shape\n                self.setToolTip(\n                    \"Click & drag to move shape '%s'\" % shape.label)\n                self.setStatusTip(self.toolTip())\n                self.overrideCursor(CURSOR_GRAB)\n                self.update()\n                break\n        else:  # Nothing found, clear highlights, reset state.\n            if self.hShape:\n                self.hShape.highlightClear()\n                self.update()\n            self.hVertex, self.hShape = None, None\n            self.overrideCursor(CURSOR_DEFAULT)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef selectShapePoint(self, point):\n        self.deSelectShape()\n        if self.selectedVertex():  # A vertex is marked for selection.\n            index, shape = self.hVertex, self.hShape\n            shape.highlightVertex(index, shape.MOVE_VERTEX)\n            self.selectShape(shape)\n            return\n        for shape in reversed(self.shapes):\n            if self.isVisible(shape) and shape.containsPoint(point):\n                self.selectShape(shape)\n                self.calculateOffsets(shape, point)\n                return", "response": "Select the first shape created which contains this point."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef snapPointToCanvas(self, x, y):\n        if x < 0 or x > self.pixmap.width() or y < 0 or y > self.pixmap.height():\n            x = max(x, 0)\n            y = max(y, 0)\n            x = min(x, self.pixmap.width())\n            y = min(y, self.pixmap.height())\n            return x, y, True\n\n        return x, y, False", "response": "Moves a point x y to within the boundaries of the canvas."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_main_app(argv=[]):\n    app = QApplication(argv)\n    app.setApplicationName(__appname__)\n    app.setWindowIcon(newIcon(\"app\"))\n    # Tzutalin 201705+: Accept extra agruments to change predefined class file\n    # Usage : labelImg.py image predefClassFile saveDir\n    win = MainWindow(argv[1] if len(argv) >= 2 else None,\n                     argv[2] if len(argv) >= 3 else os.path.join(\n                         os.path.dirname(sys.argv[0]),\n                         'data', 'predefined_classes.txt'),\n                     argv[3] if len(argv) >= 4 else None)\n    win.show()\n    return app, win", "response": "Returns a QApplication and MainWindow object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef toggleActions(self, value=True):\n        for z in self.actions.zoomActions:\n            z.setEnabled(value)\n        for action in self.actions.onLoadActive:\n            action.setEnabled(value)", "response": "Enable or disable widgets which depend on an opened image."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef toggleDrawingSensitive(self, drawing=True):\n        self.actions.editMode.setEnabled(not drawing)\n        if not drawing and self.beginner():\n            # Cancel creation.\n            print('Cancel creation.')\n            self.canvas.setEditing(True)\n            self.canvas.restoreCursor()\n            self.actions.create.setEnabled(True)", "response": "In the middle of drawing toggling between modes should be disabled."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef btnstate(self, item= None):\n        if not self.canvas.editing():\n            return\n\n        item = self.currentItem()\n        if not item: # If not selected Item, take the first one\n            item = self.labelList.item(self.labelList.count()-1)\n\n        difficult = self.diffcButton.isChecked()\n\n        try:\n            shape = self.itemsToShapes[item]\n        except:\n            pass\n        # Checked and Update\n        try:\n            if difficult != shape.difficult:\n                shape.difficult = difficult\n                self.setDirty()\n            else:  # User probably changed item visibility\n                self.canvas.setShapeVisible(shape, item.checkState() == Qt.Checked)\n        except:\n            pass", "response": "Function to handle difficult examples\n            Update on each object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef newShape(self):\n        if not self.useDefaultLabelCheckbox.isChecked() or not self.defaultLabelTextLine.text():\n            if len(self.labelHist) > 0:\n                self.labelDialog = LabelDialog(\n                    parent=self, listItem=self.labelHist)\n\n            # Sync single class mode from PR#106\n            if self.singleClassMode.isChecked() and self.lastLabel:\n                text = self.lastLabel\n            else:\n                text = self.labelDialog.popUp(text=self.prevLabelText)\n                self.lastLabel = text\n        else:\n            text = self.defaultLabelTextLine.text()\n\n        # Add Chris\n        self.diffcButton.setChecked(False)\n        if text is not None:\n            self.prevLabelText = text\n            generate_color = generateColorByText(text)\n            shape = self.canvas.setLastLabel(text, generate_color, generate_color)\n            self.addLabel(shape)\n            if self.beginner():  # Switch to edit mode.\n                self.canvas.setEditing(True)\n                self.actions.create.setEnabled(True)\n            else:\n                self.actions.editMode.setEnabled(True)\n            self.setDirty()\n\n            if text not in self.labelHist:\n                self.labelHist.append(text)\n        else:\n            # self.canvas.undoLastLine()\n            self.canvas.resetAllLines()", "response": "Pop - up and give focus to the label editor."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading the specified file and return the ID of the loaded image.", "response": "def loadFile(self, filePath=None):\n        \"\"\"Load the specified file, or the last opened file if None.\"\"\"\n        self.resetState()\n        self.canvas.setEnabled(False)\n        if filePath is None:\n            filePath = self.settings.get(SETTING_FILENAME)\n\n        # Make sure that filePath is a regular python string, rather than QString\n        filePath = ustr(filePath)\n\n        unicodeFilePath = ustr(filePath)\n        # Tzutalin 20160906 : Add file list and dock to move faster\n        # Highlight the file item\n        if unicodeFilePath and self.fileListWidget.count() > 0:\n            index = self.mImgList.index(unicodeFilePath)\n            fileWidgetItem = self.fileListWidget.item(index)\n            fileWidgetItem.setSelected(True)\n\n        if unicodeFilePath and os.path.exists(unicodeFilePath):\n            if LabelFile.isLabelFile(unicodeFilePath):\n                try:\n                    self.labelFile = LabelFile(unicodeFilePath)\n                except LabelFileError as e:\n                    self.errorMessage(u'Error opening file',\n                                      (u\"<p><b>%s</b></p>\"\n                                       u\"<p>Make sure <i>%s</i> is a valid label file.\")\n                                      % (e, unicodeFilePath))\n                    self.status(\"Error reading %s\" % unicodeFilePath)\n                    return False\n                self.imageData = self.labelFile.imageData\n                self.lineColor = QColor(*self.labelFile.lineColor)\n                self.fillColor = QColor(*self.labelFile.fillColor)\n                self.canvas.verified = self.labelFile.verified\n            else:\n                # Load image:\n                # read data first and store for saving into label file.\n                self.imageData = read(unicodeFilePath, None)\n                self.labelFile = None\n                self.canvas.verified = False\n\n            image = QImage.fromData(self.imageData)\n            if image.isNull():\n                self.errorMessage(u'Error opening file',\n                                  u\"<p>Make sure <i>%s</i> is a valid image file.\" % unicodeFilePath)\n                self.status(\"Error reading %s\" % unicodeFilePath)\n                return False\n            self.status(\"Loaded %s\" % os.path.basename(unicodeFilePath))\n            self.image = image\n            self.filePath = unicodeFilePath\n            self.canvas.loadPixmap(QPixmap.fromImage(image))\n            if self.labelFile:\n                self.loadLabels(self.labelFile.shapes)\n            self.setClean()\n            self.canvas.setEnabled(True)\n            self.adjustScale(initial=True)\n            self.paintCanvas()\n            self.addRecentFile(self.filePath)\n            self.toggleActions(True)\n\n            # Label xml file and show bound box according to its filename\n            # if self.usingPascalVocFormat is True:\n            if self.defaultSaveDir is not None:\n                basename = os.path.basename(\n                    os.path.splitext(self.filePath)[0])\n                xmlPath = os.path.join(self.defaultSaveDir, basename + XML_EXT)\n                txtPath = os.path.join(self.defaultSaveDir, basename + TXT_EXT)\n\n                \"\"\"Annotation file priority:\n                PascalXML > YOLO\n                \"\"\"\n                if os.path.isfile(xmlPath):\n                    self.loadPascalXMLByFilename(xmlPath)\n                elif os.path.isfile(txtPath):\n                    self.loadYOLOTXTByFilename(txtPath)\n            else:\n                xmlPath = os.path.splitext(filePath)[0] + XML_EXT\n                txtPath = os.path.splitext(filePath)[0] + TXT_EXT\n                if os.path.isfile(xmlPath):\n                    self.loadPascalXMLByFilename(xmlPath)\n                elif os.path.isfile(txtPath):\n                    self.loadYOLOTXTByFilename(txtPath)\n\n            self.setWindowTitle(__appname__ + ' ' + filePath)\n\n            # Default : select last item if there is at least one item\n            if self.labelList.count():\n                self.labelList.setCurrentItem(self.labelList.item(self.labelList.count()-1))\n                self.labelList.item(self.labelList.count()-1).setSelected(True)\n\n            self.canvas.setFocus(True)\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfigures out the size of the pixmap in order to fit the main widget.", "response": "def scaleFitWindow(self):\n        \"\"\"Figure out the size of the pixmap in order to fit the main widget.\"\"\"\n        e = 2.0  # So that no scrollbars are generated.\n        w1 = self.centralWidget().width() - e\n        h1 = self.centralWidget().height() - e\n        a1 = w1 / h1\n        # Calculate a new scale value based on the pixmap's aspect ratio.\n        w2 = self.canvas.pixmap.width() - 0.0\n        h2 = self.canvas.pixmap.height() - 0.0\n        a2 = w2 / h2\n        return w1 / w2 if a2 >= a1 else h1 / h2"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ustr(x):\n    '''py2/py3 unicode helper'''\n\n    if sys.version_info < (3, 0, 0):\n        from PyQt4.QtCore import QString\n        if type(x) == str:\n            return x.decode(DEFAULT_ENCODING)\n        if type(x) == QString:\n            #https://blog.csdn.net/friendan/article/details/51088476\n            #https://blog.csdn.net/xxm524/article/details/74937308\n            return unicode(x.toUtf8(), DEFAULT_ENCODING, 'ignore')\n        return x\n    else:\n        return x", "response": "py2. py3 unicode helper"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prettify(self, elem):\n        rough_string = ElementTree.tostring(elem, 'utf8')\n        root = etree.fromstring(rough_string)\n        return etree.tostring(root, pretty_print=True, encoding=ENCODE_METHOD).replace(\"  \".encode(), \"\\t\".encode())\n        # minidom does not support UTF-8\n        '''reparsed = minidom.parseString(rough_string)\n        return reparsed.toprettyxml(indent=\"\\t\", encoding=ENCODE_METHOD)'''", "response": "Return a pretty - printed XML string for the Element."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates XML for a new object.", "response": "def genXML(self):\n        \"\"\"\n            Return XML root\n        \"\"\"\n        # Check conditions\n        if self.filename is None or \\\n                self.foldername is None or \\\n                self.imgSize is None:\n            return None\n\n        top = Element('annotation')\n        if self.verified:\n            top.set('verified', 'yes')\n\n        folder = SubElement(top, 'folder')\n        folder.text = self.foldername\n\n        filename = SubElement(top, 'filename')\n        filename.text = self.filename\n\n        if self.localImgPath is not None:\n            localImgPath = SubElement(top, 'path')\n            localImgPath.text = self.localImgPath\n\n        source = SubElement(top, 'source')\n        database = SubElement(source, 'database')\n        database.text = self.databaseSrc\n\n        size_part = SubElement(top, 'size')\n        width = SubElement(size_part, 'width')\n        height = SubElement(size_part, 'height')\n        depth = SubElement(size_part, 'depth')\n        width.text = str(self.imgSize[1])\n        height.text = str(self.imgSize[0])\n        if len(self.imgSize) == 3:\n            depth.text = str(self.imgSize[2])\n        else:\n            depth.text = '1'\n\n        segmented = SubElement(top, 'segmented')\n        segmented.text = '0'\n        return top"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform a HTTP request and return decoded JSON data", "response": "async def fetch(self, url, method='GET', headers=None, body=None):\n        \"\"\"Perform a HTTP request and return decoded JSON data\"\"\"\n        request_headers = self.prepare_request_headers(headers)\n        url = self.proxy + url\n\n        if self.verbose:\n            print(\"\\nRequest:\", method, url, headers, body)\n        self.logger.debug(\"%s %s, Request: %s %s\", method, url, headers, body)\n\n        encoded_body = body.encode() if body else None\n        session_method = getattr(self.session, method.lower())\n\n        response = None\n        http_response = None\n        json_response = None\n        try:\n            async with session_method(yarl.URL(url, encoded=True),\n                                      data=encoded_body,\n                                      headers=request_headers,\n                                      timeout=(self.timeout / 1000),\n                                      proxy=self.aiohttp_proxy) as response:\n                http_response = await response.text()\n                json_response = self.parse_json(http_response) if self.is_json_encoded_object(http_response) else None\n                headers = response.headers\n                if self.enableLastHttpResponse:\n                    self.last_http_response = http_response\n                if self.enableLastResponseHeaders:\n                    self.last_response_headers = headers\n                if self.enableLastJsonResponse:\n                    self.last_json_response = json_response\n                if self.verbose:\n                    print(\"\\nResponse:\", method, url, response.status, headers, http_response)\n                self.logger.debug(\"%s %s, Response: %s %s %s\", method, url, response.status, headers, http_response)\n\n        except socket.gaierror as e:\n            self.raise_error(ExchangeNotAvailable, url, method, e, None)\n\n        except concurrent.futures._base.TimeoutError as e:\n            self.raise_error(RequestTimeout, method, url, e, None)\n\n        except aiohttp.client_exceptions.ClientConnectionError as e:\n            self.raise_error(ExchangeNotAvailable, url, method, e, None)\n\n        except aiohttp.client_exceptions.ClientError as e:  # base exception class\n            self.raise_error(ExchangeError, url, method, e, None)\n\n        self.handle_errors(response.status, response.reason, url, method, headers, http_response, json_response)\n        self.handle_rest_errors(None, response.status, http_response, url, method)\n        self.handle_rest_response(http_response, json_response, url, method, headers, body)\n        if json_response is not None:\n            return json_response\n        return http_response"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_broadly_matched_key(self, broad, string):\n        keys = list(broad.keys())\n        for i in range(0, len(keys)):\n            key = keys[i]\n            if string.find(key) >= 0:\n                return key\n        return None", "response": "A helper method for matching error strings exactly vs broadly"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fetch(self, url, method='GET', headers=None, body=None):\n        request_headers = self.prepare_request_headers(headers)\n        url = self.proxy + url\n\n        if self.verbose:\n            print(\"\\nRequest:\", method, url, request_headers, body)\n        self.logger.debug(\"%s %s, Request: %s %s\", method, url, request_headers, body)\n\n        if body:\n            body = body.encode()\n\n        self.session.cookies.clear()\n\n        response = None\n        http_response = None\n        json_response = None\n        try:\n            response = self.session.request(\n                method,\n                url,\n                data=body,\n                headers=request_headers,\n                timeout=int(self.timeout / 1000),\n                proxies=self.proxies\n            )\n            http_response = response.text\n            json_response = self.parse_json(http_response) if self.is_json_encoded_object(http_response) else None\n            headers = response.headers\n            # FIXME remove last_x_responses from subclasses\n            if self.enableLastHttpResponse:\n                self.last_http_response = http_response\n            if self.enableLastJsonResponse:\n                self.last_json_response = json_response\n            if self.enableLastResponseHeaders:\n                self.last_response_headers = headers\n            if self.verbose:\n                print(\"\\nResponse:\", method, url, response.status_code, headers, http_response)\n            self.logger.debug(\"%s %s, Response: %s %s %s\", method, url, response.status_code, headers, http_response)\n            response.raise_for_status()\n\n        except Timeout as e:\n            self.raise_error(RequestTimeout, method, url, e)\n\n        except TooManyRedirects as e:\n            self.raise_error(ExchangeError, url, method, e)\n\n        except SSLError as e:\n            self.raise_error(ExchangeError, url, method, e)\n\n        except HTTPError as e:\n            self.handle_errors(response.status_code, response.reason, url, method, headers, http_response, json_response)\n            self.handle_rest_errors(e, response.status_code, http_response, url, method)\n            self.raise_error(ExchangeError, url, method, e, http_response)\n\n        except RequestException as e:  # base exception class\n            error_string = str(e)\n            if ('ECONNRESET' in error_string) or ('Connection aborted.' in error_string):\n                self.raise_error(NetworkError, url, method, e)\n            else:\n                self.raise_error(ExchangeError, url, method, e)\n\n        self.handle_errors(response.status_code, response.reason, url, method, headers, http_response, json_response)\n        self.handle_rest_response(http_response, json_response, url, method, headers, body)\n        if json_response is not None:\n            return json_response\n        return http_response", "response": "Perform a HTTP request and return decoded JSON data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef truncate_to_string(num, precision=0):\n        if precision > 0:\n            parts = ('{0:.%df}' % precision).format(Decimal(num)).split('.')\n            decimal_digits = parts[1][:precision].rstrip('0')\n            decimal_digits = decimal_digits if len(decimal_digits) else '0'\n            return parts[0] + '.' + decimal_digits\n        return ('%d' % num)", "response": "Truncates a number to a given number of digits."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck an address is not the same character repeated or an empty sequence", "response": "def check_address(self, address):\n        \"\"\"Checks an address is not the same character repeated or an empty sequence\"\"\"\n        if address is None:\n            self.raise_error(InvalidAddress, details='address is None')\n        if all(letter == address[0] for letter in address) or len(address) < self.minFundingAddressLength or ' ' in address:\n            self.raise_error(InvalidAddress, details='address is invalid or has less than ' + str(self.minFundingAddressLength) + ' characters: \"' + str(address) + '\"')\n        return address"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reduce_filename(f):\n    r'''\n    Expects something like /tmp/tmpAjry4Gdsbench/test.weights.e5.XXX.YYY.pb\n    Where XXX is a variation on the model size for example\n    And where YYY is a const related to the training dataset\n    '''\n\n    f = os.path.basename(f).split('.')\n    return keep_only_digits(f[-3])", "response": "r Returns a string that can be used as a filename for the training dataset."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef keep_only_digits(s):\n    r'''\n    local helper to just keep digits\n    '''\n    fs = ''\n    for c in s:\n        if c.isdigit():\n            fs += c\n\n    return int(fs)", "response": "r Helper to just keep digits in a list of items"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_stm_file(stm_file):\n    stm_segments = []\n    with codecs.open(stm_file, encoding=\"utf-8\") as stm_lines:\n        for stm_line in stm_lines:\n            stmSegment = STMSegment(stm_line)\n            if not \"ignore_time_segment_in_scoring\" == stmSegment.transcript:\n                stm_segments.append(stmSegment)\n    return stm_segments", "response": "r Parses an STM file at stm_file into a list of STMSegment objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_wave(path):\n    with contextlib.closing(wave.open(path, 'rb')) as wf:\n        num_channels = wf.getnchannels()\n        assert num_channels == 1\n        sample_width = wf.getsampwidth()\n        assert sample_width == 2\n        sample_rate = wf.getframerate()\n        assert sample_rate in (8000, 16000, 32000)\n        frames = wf.getnframes()\n        pcm_data = wf.readframes(frames)\n        duration = frames / sample_rate\n        return pcm_data, sample_rate, duration", "response": "Reads a. wav file and returns the PCM audio data sample rate and duration."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites a. wav file.", "response": "def write_wave(path, audio, sample_rate):\n    \"\"\"Writes a .wav file.\n\n    Takes path, PCM audio data, and sample rate.\n    \"\"\"\n    with contextlib.closing(wave.open(path, 'wb')) as wf:\n        wf.setnchannels(1)\n        wf.setsampwidth(2)\n        wf.setframerate(sample_rate)\n        wf.writeframes(audio)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating audio frames from the PCM audio data.", "response": "def frame_generator(frame_duration_ms, audio, sample_rate):\n    \"\"\"Generates audio frames from PCM audio data.\n\n    Takes the desired frame duration in milliseconds, the PCM data, and\n    the sample rate.\n\n    Yields Frames of the requested duration.\n    \"\"\"\n    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n    offset = 0\n    timestamp = 0.0\n    duration = (float(n) / sample_rate) / 2.0\n    while offset + n < len(audio):\n        yield Frame(audio[offset:offset + n], timestamp, duration)\n        timestamp += duration\n        offset += n"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize the runner function with the passed args kwargs Initialise the runner function with the passed args kwargs", "response": "def run(self):\n        '''\n        Initialise the runner function with the passed args, kwargs\n        '''\n\n        # Retrieve args/kwargs here; and fire up the processing using them\n        try:\n            transcript = self.fn(*self.args, **self.kwargs)\n        except:\n            traceback.print_exc()\n            exctype, value = sys.exc_info()[:2]\n            self.signals.error.emit((exctype, value, traceback.format_exc()))\n        else:\n            # Return the result of the processing\n            self.signals.result.emit(transcript)\n        finally:\n            # Done\n            self.signals.finished.emit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extract_native_client_tarball(dir):\n    r'''\n    Download a native_client.tar.xz file from TaskCluster and extract it to dir.\n    '''\n    assert_valid_dir(dir)\n\n    target_tarball = os.path.join(dir, 'native_client.tar.xz')\n    if os.path.isfile(target_tarball) and os.stat(target_tarball).st_size == 0:\n        return\n\n    subprocess.check_call(['pixz', '-d', 'native_client.tar.xz'], cwd=dir)\n    subprocess.check_call(['tar', 'xf', 'native_client.tar'], cwd=dir)\n    os.unlink(os.path.join(dir, 'native_client.tar'))\n    open(target_tarball, 'w').close()", "response": "r Downloads a native_client. tar. xz file from TaskCluster and extracts it to dir."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef maybe_inspect_zip(models):\n    r'''\n    Detect if models is a list of protocolbuffer files or a ZIP file.\n    If the latter, then unzip it and return the list of protocolbuffer files\n    that were inside.\n    '''\n\n    if not(is_zip_file(models)):\n        return models\n\n    if len(models) > 1:\n        return models\n\n    if len(models) < 1:\n        raise AssertionError('No models at all')\n\n    return zipfile.ZipFile(models[0]).namelist()", "response": "r Detects if models is a list of protocolbuffer files or a ZIP file. If the latter then unzip it and return the list of protocolbuffer files that were inside."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef all_files(models=[]):\n    r'''\n    Return a list of full path of files matching 'models', sorted in human\n    numerical order (i.e., 0 1 2 ..., 10 11 12, ..., 100, ..., 1000).\n\n    Files are supposed to be named identically except one variable component\n    e.g. the list,\n      test.weights.e5.lstm1200.ldc93s1.pb\n      test.weights.e5.lstm1000.ldc93s1.pb\n      test.weights.e5.lstm800.ldc93s1.pb\n    gets sorted:\n      test.weights.e5.lstm800.ldc93s1.pb\n      test.weights.e5.lstm1000.ldc93s1.pb\n      test.weights.e5.lstm1200.ldc93s1.pb\n    '''\n\n    def nsort(a, b):\n        fa = os.path.basename(a).split('.')\n        fb = os.path.basename(b).split('.')\n        elements_to_remove = []\n\n        assert len(fa) == len(fb)\n\n        for i in range(0, len(fa)):\n            if fa[i] == fb[i]:\n                elements_to_remove.append(fa[i])\n\n        for e in elements_to_remove:\n            fa.remove(e)\n            fb.remove(e)\n\n        assert len(fa) == len(fb)\n        assert len(fa) == 1\n\n        fa = keep_only_digits(fa[0])\n        fb = keep_only_digits(fb[0])\n\n        if fa < fb:\n            return -1\n        if fa == fb:\n            return 0\n        if fa > fb:\n            return 1\n\n    base = list(map(lambda x: os.path.abspath(x), maybe_inspect_zip(models)))\n    base.sort(cmp=nsort)\n\n    return base", "response": "r Returns a list of full path of files matching models sorted in human\n    numerical order"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setup_tempdir(dir, models, wav, alphabet, lm_binary, trie, binaries):\n    r'''\n    Copy models, libs and binary to a directory (new one if dir is None)\n    '''\n    if dir is None:\n        dir = tempfile.mkdtemp(suffix='dsbench')\n\n    sorted_models = all_files(models=models)\n    if binaries is None:\n        maybe_download_binaries(dir)\n    else:\n        print('Using local binaries: %s' % (binaries))\n        shutil.copy2(binaries, dir)\n    extract_native_client_tarball(dir)\n\n    filenames = map(lambda x: os.path.join(dir, os.path.basename(x)), sorted_models)\n    missing_models = filter(lambda x: not os.path.isfile(x), filenames)\n    if len(missing_models) > 0:\n        # If we have a ZIP file, directly extract it to the proper path\n        if is_zip_file(models):\n            print('Extracting %s to %s' % (models[0], dir))\n            zipfile.ZipFile(models[0]).extractall(path=dir)\n            print('Extracted %s.' % models[0])\n        else:\n            # If one model is missing, let's copy everything again. Be safe.\n            for f in sorted_models:\n                print('Copying %s to %s' % (f, dir))\n                shutil.copy2(f, dir)\n\n    for extra_file in [ wav, alphabet, lm_binary, trie ]:\n        if extra_file and not os.path.isfile(os.path.join(dir, os.path.basename(extra_file))):\n            print('Copying %s to %s' % (extra_file, dir))\n            shutil.copy2(extra_file, dir)\n\n    if ssh_conn:\n        copy_tree(dir)\n\n    return dir, sorted_models", "response": "r Create a temporary directory and copy models libs and binary to a directory."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_sshconfig():\n    r'''\n    Read user's SSH configuration file\n    '''\n\n    with open(os.path.expanduser('~/.ssh/config')) as f:\n        cfg = paramiko.SSHConfig()\n        cfg.parse(f)\n        ret_dict = {}\n        for d in cfg._config:\n            _copy = dict(d)\n            # Avoid buggy behavior with strange host definitions, we need\n            # Hostname and not Host.\n            del _copy['host']\n            for host in d['host']:\n                ret_dict[host] = _copy['config']\n\n        return ret_dict", "response": "r Read user s SSH configuration file and return a dictionary of all hosts and their SSH configuration values."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef establish_ssh(target=None, auto_trust=False, allow_agent=True, look_keys=True):\n    r'''\n    Establish a SSH connection to a remote host. It should be able to use\n    SSH's config file Host name declarations. By default, will not automatically\n    add trust for hosts, will use SSH agent and will try to load keys.\n    '''\n\n    def password_prompt(username, hostname):\n        r'''\n        If the Host is relying on password authentication, lets ask it.\n        Relying on SSH itself to take care of that would not work when the\n        remote authentication is password behind a SSH-key+2FA jumphost.\n        '''\n        return getpass.getpass('No SSH key for %s@%s, please provide password: ' % (username, hostname))\n\n    ssh_conn = None\n    if target is not None:\n        ssh_conf = get_sshconfig()\n        cfg = {\n            'hostname': None,\n            'port': 22,\n            'allow_agent': allow_agent,\n            'look_for_keys': look_keys\n        }\n        if ssh_conf.has_key(target):\n            user_config = ssh_conf.get(target)\n\n            # If ssh_config file's Host defined 'User' instead of 'Username'\n            if user_config.has_key('user') and not user_config.has_key('username'):\n                user_config['username'] = user_config['user']\n                del user_config['user']\n\n            for k in ('username', 'hostname', 'port'):\n                if k in user_config:\n                    cfg[k] = user_config[k]\n\n            # Assume Password auth. If we don't do that, then when connecting\n            # through a jumphost we will run into issues and the user will\n            # not be able to input his password to the SSH prompt.\n            if 'identityfile' in user_config:\n                cfg['key_filename'] = user_config['identityfile']\n            else:\n                cfg['password'] = password_prompt(cfg['username'], cfg['hostname'] or target)\n\n            # Should be the last one, since ProxyCommand will issue connection to remote host\n            if 'proxycommand' in user_config:\n                cfg['sock'] = paramiko.ProxyCommand(user_config['proxycommand'])\n\n        else:\n            cfg['username'] = target.split('@')[0]\n            cfg['hostname'] = target.split('@')[1].split(':')[0]\n            cfg['password'] = password_prompt(cfg['username'], cfg['hostname'])\n            try:\n                cfg['port'] = int(target.split('@')[1].split(':')[1])\n            except IndexError:\n                # IndexError will happen if no :PORT is there.\n                # Default value 22 is defined above in 'cfg'.\n                pass\n\n        ssh_conn = paramiko.SSHClient()\n        if auto_trust:\n            ssh_conn.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n\n        ssh_conn.connect(**cfg)\n\n    return ssh_conn", "response": "r Establish an SSH connection to a remote host."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a function that downloads a file based on the given parameters", "response": "def _parallel_downloader(voxforge_url, archive_dir, total, counter):\n    \"\"\"Generate a function to download a file based on given parameters\n    This works by currying the above given arguments into a closure\n    in the form of the following function.\n\n    :param voxforge_url: the base voxforge URL\n    :param archive_dir:  the location to store the downloaded file\n    :param total:        the total number of files to download\n    :param counter:      an atomic counter to keep track of # of downloaded files\n    :return:             a function that actually downloads a file given these params\n    \"\"\"\n    def download(d):\n        \"\"\"Binds voxforge_url, archive_dir, total, and counter into this scope\n        Downloads the given file\n        :param d: a tuple consisting of (index, file) where index is the index\n                  of the file to download and file is the name of the file to download\n        \"\"\"\n        (i, file) = d\n        download_url = voxforge_url + '/' + file\n        c = counter.increment()\n        print('Downloading file {} ({}/{})...'.format(i+1, c, total))\n        maybe_download(filename_of(download_url), archive_dir, download_url)\n    return download"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a function to extract a tar file based on given parameters This works by currying the above given arguments into a closure in the form of the following function. :param data_dir: the target directory to extract into :param number_of_test: the number of files to keep as the test set :param number_of_dev: the number of files to keep as the dev set :param total: the total number of files to extract :param counter: an atomic counter to keep track of # of extracted files :return: a function that actually extracts a tar file given these params", "response": "def _parallel_extracter(data_dir, number_of_test, number_of_dev, total, counter):\n    \"\"\"Generate a function to extract a tar file based on given parameters\n    This works by currying the above given arguments into a closure\n    in the form of the following function.\n\n    :param data_dir:       the target directory to extract into\n    :param number_of_test: the number of files to keep as the test set\n    :param number_of_dev:  the number of files to keep as the dev set\n    :param total:          the total number of files to extract\n    :param counter:        an atomic counter to keep track of # of extracted files\n    :return:               a function that actually extracts a tar file given these params\n    \"\"\"\n    def extract(d):\n        \"\"\"Binds data_dir, number_of_test, number_of_dev, total, and counter into this scope\n        Extracts the given file\n        :param d: a tuple consisting of (index, file) where index is the index\n                  of the file to extract and file is the name of the file to extract\n        \"\"\"\n        (i, archive) = d\n        if i < number_of_test:\n            dataset_dir = path.join(data_dir, \"test\")\n        elif i<number_of_test+number_of_dev:\n            dataset_dir = path.join(data_dir, \"dev\")\n        else:\n            dataset_dir = path.join(data_dir, \"train\")\n        if not gfile.Exists(path.join(dataset_dir, '.'.join(filename_of(archive).split(\".\")[:-1]))):\n            c = counter.increment()\n            print('Extracting file {} ({}/{})...'.format(i+1, c, total))\n            tar = tarfile.open(archive)\n            tar.extractall(dataset_dir)\n            tar.close()\n    return extract"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef increment(self, amount=1):\n        self.__lock.acquire()\n        self.__count += amount\n        v = self.value()\n        self.__lock.release()\n        return v", "response": "Increments the counter by the given amount"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sparse_tensor_value_to_texts(value, alphabet):\n    return sparse_tuple_to_texts((value.indices, value.values, value.dense_shape), alphabet)", "response": "r Given a tf. SparseTensor value return an array of Python strings\n    representing its values converting tokens to strings using alphabet."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses command line parameters into a namespace.", "response": "def parse_args(args):\n    \"\"\"Parse command line parameters\n    Args:\n      args ([str]): Command line parameters as list of strings\n    Returns:\n      :obj:`argparse.Namespace`: command line parameters namespace\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Imports GramVaani data for Deep Speech\"\n    )\n    parser.add_argument(\n        \"--version\",\n        action=\"version\",\n        version=\"GramVaaniImporter {ver}\".format(ver=__version__),\n    )\n    parser.add_argument(\n        \"-v\",\n        \"--verbose\",\n        action=\"store_const\",\n        required=False,\n        help=\"set loglevel to INFO\",\n        dest=\"loglevel\",\n        const=logging.INFO,\n    )\n    parser.add_argument(\n        \"-vv\",\n        \"--very-verbose\",\n        action=\"store_const\",\n        required=False,\n        help=\"set loglevel to DEBUG\",\n        dest=\"loglevel\",\n        const=logging.DEBUG,\n    )\n    parser.add_argument(\n        \"-c\",\n        \"--csv_filename\",\n        required=True,\n        help=\"Path to the GramVaani csv\",\n        dest=\"csv_filename\",\n    )\n    parser.add_argument(\n        \"-t\",\n        \"--target_dir\",\n        required=True,\n        help=\"Directory in which to save the importer GramVaani data\",\n        dest=\"target_dir\",\n    )\n    return parser.parse_args(args)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup_logging(level):\n    format = \"[%(asctime)s] %(levelname)s:%(name)s:%(message)s\"\n    logging.basicConfig(\n        level=level, stream=sys.stdout, format=format, datefmt=\"%Y-%m-%d %H:%M:%S\"\n    )", "response": "Setup basic logging for the current log level"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndownload the data associated with this instance returning the mp3_directory", "response": "def download(self):\n        \"\"\"Downloads the data associated with this instance\n        Return:\n          mp3_directory (os.path): The directory into which the associated mp3's were downloaded\n        \"\"\"\n        mp3_directory = self._pre_download()\n        self.data.swifter.apply(func=lambda arg: self._download(*arg, mp3_directory), axis=1, raw=True)\n        return mp3_directory"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert(self):\n        wav_directory = self._pre_convert()\n        for mp3_filename in self.mp3_directory.glob('**/*.mp3'):\n            wav_filename = path.join(wav_directory, os.path.splitext(os.path.basename(mp3_filename))[0] + \".wav\")\n            if not path.exists(wav_filename):\n                _logger.debug(\"Converting mp3 file %s to wav file %s\" % (mp3_filename, wav_filename))\n                transformer = Transformer()\n                transformer.convert(samplerate=SAMPLE_RATE, n_channels=N_CHANNELS, bitdepth=BITDEPTH)\n                transformer.build(str(mp3_filename), str(wav_filename))\n            else:\n                _logger.debug(\"Already converted mp3 file %s to wav file %s\" % (mp3_filename, wav_filename))\n        return wav_directory", "response": "Converts the mp3 s associated with this instance to wav s\n        Return the directory into which the associated wav s were downloaded"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef text_to_char_array(original, alphabet):\n    return np.asarray([alphabet.label_from_string(c) for c in original])", "response": "r Given a Python string original remove unsupported characters map characters\n    to integers and return a numpy array representing the processed string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wer_cer_batch(originals, results):\n    # The WER is calculated on word (and NOT on character) level.\n    # Therefore we split the strings into words first\n    assert len(originals) == len(results)\n\n    total_cer = 0.0\n    total_char_length = 0.0\n\n    total_wer = 0.0\n    total_word_length = 0.0\n\n    for original, result in zip(originals, results):\n        total_cer += levenshtein(original, result)\n        total_char_length += len(original)\n\n        total_wer += levenshtein(original.split(), result.split())\n        total_word_length += len(original.split())\n\n    return total_wer / total_word_length, total_cer / total_char_length", "response": "r Calculate the WER and CER for a batch of strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef export():\n    r'''\n    Restores the trained variables into a simpler graph that will be exported for serving.\n    '''\n    log_info('Exporting the model...')\n    from tensorflow.python.framework.ops import Tensor, Operation\n\n    inputs, outputs, _ = create_inference_graph(batch_size=FLAGS.export_batch_size, n_steps=FLAGS.n_steps, tflite=FLAGS.export_tflite)\n    output_names_tensors = [tensor.op.name for tensor in outputs.values() if isinstance(tensor, Tensor)]\n    output_names_ops = [op.name for op in outputs.values() if isinstance(op, Operation)]\n    output_names = \",\".join(output_names_tensors + output_names_ops)\n\n    if not FLAGS.export_tflite:\n        mapping = {v.op.name: v for v in tf.global_variables() if not v.op.name.startswith('previous_state_')}\n    else:\n        # Create a saver using variables from the above newly created graph\n        def fixup(name):\n            if name.startswith('rnn/lstm_cell/'):\n                return name.replace('rnn/lstm_cell/', 'lstm_fused_cell/')\n            return name\n\n        mapping = {fixup(v.op.name): v for v in tf.global_variables()}\n\n    saver = tf.train.Saver(mapping)\n\n    # Restore variables from training checkpoint\n    checkpoint = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)\n    checkpoint_path = checkpoint.model_checkpoint_path\n\n    output_filename = 'output_graph.pb'\n    if FLAGS.remove_export:\n        if os.path.isdir(FLAGS.export_dir):\n            log_info('Removing old export')\n            shutil.rmtree(FLAGS.export_dir)\n    try:\n        output_graph_path = os.path.join(FLAGS.export_dir, output_filename)\n\n        if not os.path.isdir(FLAGS.export_dir):\n            os.makedirs(FLAGS.export_dir)\n\n        def do_graph_freeze(output_file=None, output_node_names=None, variables_blacklist=None):\n            return freeze_graph.freeze_graph_with_def_protos(\n                input_graph_def=tf.get_default_graph().as_graph_def(),\n                input_saver_def=saver.as_saver_def(),\n                input_checkpoint=checkpoint_path,\n                output_node_names=output_node_names,\n                restore_op_name=None,\n                filename_tensor_name=None,\n                output_graph=output_file,\n                clear_devices=False,\n                variable_names_blacklist=variables_blacklist,\n                initializer_nodes='')\n\n        if not FLAGS.export_tflite:\n            frozen_graph = do_graph_freeze(output_node_names=output_names, variables_blacklist='previous_state_c,previous_state_h')\n            frozen_graph.version = int(file_relative_read('GRAPH_VERSION').strip())\n\n            # Add a no-op node to the graph with metadata information to be loaded by the native client\n            metadata = frozen_graph.node.add()\n            metadata.name = 'model_metadata'\n            metadata.op = 'NoOp'\n            metadata.attr['sample_rate'].i = FLAGS.audio_sample_rate\n            metadata.attr['feature_win_len'].i = FLAGS.feature_win_len\n            metadata.attr['feature_win_step'].i = FLAGS.feature_win_step\n            if FLAGS.export_language:\n                metadata.attr['language'].s = FLAGS.export_language.encode('ascii')\n\n            with open(output_graph_path, 'wb') as fout:\n                fout.write(frozen_graph.SerializeToString())\n        else:\n            frozen_graph = do_graph_freeze(output_node_names=output_names, variables_blacklist='')\n            output_tflite_path = os.path.join(FLAGS.export_dir, output_filename.replace('.pb', '.tflite'))\n\n            converter = tf.lite.TFLiteConverter(frozen_graph, input_tensors=inputs.values(), output_tensors=outputs.values())\n            converter.post_training_quantize = True\n            # AudioSpectrogram and Mfcc ops are custom but have built-in kernels in TFLite\n            converter.allow_custom_ops = True\n            tflite_model = converter.convert()\n\n            with open(output_tflite_path, 'wb') as fout:\n                fout.write(tflite_model)\n\n            log_info('Exported model for TF Lite engine as {}'.format(os.path.basename(output_tflite_path)))\n\n        log_info('Models exported at %s' % (FLAGS.export_dir))\n    except RuntimeError as e:\n        log_error(str(e))", "response": "r Export the current model to a simpler graph."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ctc_beam_search_decoder(probs_seq,\n                            alphabet,\n                            beam_size,\n                            cutoff_prob=1.0,\n                            cutoff_top_n=40,\n                            scorer=None):\n    \"\"\"Wrapper for the CTC Beam Search Decoder.\n\n    :param probs_seq: 2-D list of probability distributions over each time\n                      step, with each element being a list of normalized\n                      probabilities over alphabet and blank.\n    :type probs_seq: 2-D list\n    :param alphabet: alphabet list.\n    :alphabet: Alphabet\n    :param beam_size: Width for beam search.\n    :type beam_size: int\n    :param cutoff_prob: Cutoff probability in pruning,\n                        default 1.0, no pruning.\n    :type cutoff_prob: float\n    :param cutoff_top_n: Cutoff number in pruning, only top cutoff_top_n\n                         characters with highest probs in alphabet will be\n                         used in beam search, default 40.\n    :type cutoff_top_n: int\n    :param scorer: External scorer for partially decoded sentence, e.g. word\n                   count or language model.\n    :type scorer: Scorer\n    :return: List of tuples of log probability and sentence as decoding\n             results, in descending order of the probability.\n    :rtype: list\n    \"\"\"\n    beam_results = swigwrapper.ctc_beam_search_decoder(\n        probs_seq, alphabet.config_file(), beam_size, cutoff_prob, cutoff_top_n,\n        scorer)\n    beam_results = [(res.probability, alphabet.decode(res.tokens)) for res in beam_results]\n    return beam_results", "response": "Wrapper for the CTC Beam Search Decoder."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwrapping for the batched CTC beam search decoder.", "response": "def ctc_beam_search_decoder_batch(probs_seq,\n                                  seq_lengths,\n                                  alphabet,\n                                  beam_size,\n                                  num_processes,\n                                  cutoff_prob=1.0,\n                                  cutoff_top_n=40,\n                                  scorer=None):\n    \"\"\"Wrapper for the batched CTC beam search decoder.\n\n    :param probs_seq: 3-D list with each element as an instance of 2-D list\n                      of probabilities used by ctc_beam_search_decoder().\n    :type probs_seq: 3-D list\n    :param alphabet: alphabet list.\n    :alphabet: Alphabet\n    :param beam_size: Width for beam search.\n    :type beam_size: int\n    :param num_processes: Number of parallel processes.\n    :type num_processes: int\n    :param cutoff_prob: Cutoff probability in alphabet pruning,\n                        default 1.0, no pruning.\n    :type cutoff_prob: float\n    :param cutoff_top_n: Cutoff number in pruning, only top cutoff_top_n\n                         characters with highest probs in alphabet will be\n                         used in beam search, default 40.\n    :type cutoff_top_n: int\n    :param num_processes: Number of parallel processes.\n    :type num_processes: int\n    :param scorer: External scorer for partially decoded sentence, e.g. word\n                   count or language model.\n    :type scorer: Scorer\n    :return: List of tuples of log probability and sentence as decoding\n             results, in descending order of the probability.\n    :rtype: list\n    \"\"\"\n    batch_beam_results = swigwrapper.ctc_beam_search_decoder_batch(\n        probs_seq, seq_lengths, alphabet.config_file(), beam_size, num_processes,\n        cutoff_prob, cutoff_top_n, scorer)\n    batch_beam_results = [\n        [(res.probability, alphabet.decode(res.tokens)) for res in beam_results]\n        for beam_results in batch_beam_results\n    ]\n    return batch_beam_results"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resample(self, data, input_rate):\n        data16 = np.fromstring(string=data, dtype=np.int16)\n        resample_size = int(len(data16) / self.input_rate * self.RATE_PROCESS)\n        resample = signal.resample(data16, resample_size)\n        resample16 = np.array(resample, dtype=np.int16)\n        return resample16.tostring()", "response": "Resample from input_rate to RATE_PROCESS"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a block of audio data resampled to 16000hz blocking if necessary.", "response": "def read_resampled(self):\n        \"\"\"Return a block of audio data resampled to 16000hz, blocking if necessary.\"\"\"\n        return self.resample(data=self.buffer_queue.get(),\n                             input_rate=self.input_rate)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cut(sentence, HMM=True):\n    global dt\n    if jieba.pool is None:\n        for w in dt.cut(sentence, HMM=HMM):\n            yield w\n    else:\n        parts = strdecode(sentence).splitlines(True)\n        if HMM:\n            result = jieba.pool.map(_lcut_internal, parts)\n        else:\n            result = jieba.pool.map(_lcut_internal_no_hmm, parts)\n        for r in result:\n            for w in r:\n                yield w", "response": "Yields all the words in the sentence."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef enable_parallel(processnum=None):\n    global pool, dt, cut, cut_for_search\n    from multiprocessing import cpu_count\n    if os.name == 'nt':\n        raise NotImplementedError(\n            \"jieba: parallel mode only supports posix system\")\n    else:\n        from multiprocessing import Pool\n    dt.check_initialized()\n    if processnum is None:\n        processnum = cpu_count()\n    pool = Pool(processnum)\n    cut = _pcut\n    cut_for_search = _pcut_for_search", "response": "Enable the module s parallel version."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nyields the words that are in the sentence.", "response": "def cut_for_search(self, sentence, HMM=True):\n        \"\"\"\n        Finer segmentation for search engines.\n        \"\"\"\n        words = self.cut(sentence, HMM=HMM)\n        for w in words:\n            if len(w) > 2:\n                for i in xrange(len(w) - 1):\n                    gram2 = w[i:i + 2]\n                    if self.FREQ.get(gram2):\n                        yield gram2\n            if len(w) > 3:\n                for i in xrange(len(w) - 2):\n                    gram3 = w[i:i + 3]\n                    if self.FREQ.get(gram3):\n                        yield gram3\n            yield w"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading personalized dictionary from file.", "response": "def load_userdict(self, f):\n        '''\n        Load personalized dict to improve detect rate.\n\n        Parameter:\n            - f : A plain text file contains words and their ocurrences.\n                  Can be a file-like object, or the path of the dictionary file,\n                  whose encoding must be utf-8.\n\n        Structure of dict file:\n        word1 freq1 word_type1\n        word2 freq2 word_type2\n        ...\n        Word type may be ignored\n        '''\n        self.check_initialized()\n        if isinstance(f, string_types):\n            f_name = f\n            f = open(f, 'rb')\n        else:\n            f_name = resolve_filename(f)\n        for lineno, ln in enumerate(f, 1):\n            line = ln.strip()\n            if not isinstance(line, text_type):\n                try:\n                    line = line.decode('utf-8').lstrip('\\ufeff')\n                except UnicodeDecodeError:\n                    raise ValueError('dictionary file %s must be utf-8' % f_name)\n            if not line:\n                continue\n            # match won't be None because there's at least one character\n            word, freq, tag = re_userdict.match(line).groups()\n            if freq is not None:\n                freq = freq.strip()\n            if tag is not None:\n                tag = tag.strip()\n            self.add_word(word, freq, tag)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_word(self, word, freq=None, tag=None):\n        self.check_initialized()\n        word = strdecode(word)\n        freq = int(freq) if freq is not None else self.suggest_freq(word, False)\n        self.FREQ[word] = freq\n        self.total += freq\n        if tag:\n            self.user_word_tag_tab[word] = tag\n        for ch in xrange(len(word)):\n            wfrag = word[:ch + 1]\n            if wfrag not in self.FREQ:\n                self.FREQ[wfrag] = 0\n        if freq == 0:\n            finalseg.add_force_split(word)", "response": "Add a word to the dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsuggests the frequency of a word in a segment.", "response": "def suggest_freq(self, segment, tune=False):\n        \"\"\"\n        Suggest word frequency to force the characters in a word to be\n        joined or splitted.\n\n        Parameter:\n            - segment : The segments that the word is expected to be cut into,\n                        If the word should be treated as a whole, use a str.\n            - tune : If True, tune the word frequency.\n\n        Note that HMM may affect the final result. If the result doesn't change,\n        set HMM=False.\n        \"\"\"\n        self.check_initialized()\n        ftotal = float(self.total)\n        freq = 1\n        if isinstance(segment, string_types):\n            word = segment\n            for seg in self.cut(word, HMM=False):\n                freq *= self.FREQ.get(seg, 1) / ftotal\n            freq = max(int(freq * self.total) + 1, self.FREQ.get(word, 1))\n        else:\n            segment = tuple(map(strdecode, segment))\n            word = ''.join(segment)\n            for seg in segment:\n                freq *= self.FREQ.get(seg, 1) / ftotal\n            freq = min(int(freq * self.total), self.FREQ.get(word, 0))\n        if tune:\n            add_word(word, freq)\n        return freq"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting keywords from a sentence using TextRank algorithm.", "response": "def textrank(self, sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v'), withFlag=False):\n        \"\"\"\n        Extract keywords from sentence using TextRank algorithm.\n        Parameter:\n            - topK: return how many top keywords. `None` for all possible words.\n            - withWeight: if True, return a list of (word, weight);\n                          if False, return a list of words.\n            - allowPOS: the allowed POS list eg. ['ns', 'n', 'vn', 'v'].\n                        if the POS of w is not in this list, it will be filtered.\n            - withFlag: if True, return a list of pair(word, weight) like posseg.cut\n                        if False, return a list of words\n        \"\"\"\n        self.pos_filt = frozenset(allowPOS)\n        g = UndirectWeightedGraph()\n        cm = defaultdict(int)\n        words = tuple(self.tokenizer.cut(sentence))\n        for i, wp in enumerate(words):\n            if self.pairfilter(wp):\n                for j in xrange(i + 1, i + self.span):\n                    if j >= len(words):\n                        break\n                    if not self.pairfilter(words[j]):\n                        continue\n                    if allowPOS and withFlag:\n                        cm[(wp, words[j])] += 1\n                    else:\n                        cm[(wp.word, words[j].word)] += 1\n\n        for terms, w in cm.items():\n            g.addEdge(terms[0], terms[1], w)\n        nodes_rank = g.rank()\n        if withWeight:\n            tags = sorted(nodes_rank.items(), key=itemgetter(1), reverse=True)\n        else:\n            tags = sorted(nodes_rank, key=nodes_rank.__getitem__, reverse=True)\n\n        if topK:\n            return tags[:topK]\n        else:\n            return tags"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_tags(self, sentence, topK=20, withWeight=False, allowPOS=(), withFlag=False):\n        if allowPOS:\n            allowPOS = frozenset(allowPOS)\n            words = self.postokenizer.cut(sentence)\n        else:\n            words = self.tokenizer.cut(sentence)\n        freq = {}\n        for w in words:\n            if allowPOS:\n                if w.flag not in allowPOS:\n                    continue\n                elif not withFlag:\n                    w = w.word\n            wc = w.word if allowPOS and withFlag else w\n            if len(wc.strip()) < 2 or wc.lower() in self.stop_words:\n                continue\n            freq[w] = freq.get(w, 0.0) + 1.0\n        total = sum(freq.values())\n        for k in freq:\n            kw = k.word if allowPOS and withFlag else k\n            freq[k] *= self.idf_freq.get(kw, self.median_idf) / total\n\n        if withWeight:\n            tags = sorted(freq.items(), key=itemgetter(1), reverse=True)\n        else:\n            tags = sorted(freq, key=freq.__getitem__, reverse=True)\n        if topK:\n            return tags[:topK]\n        else:\n            return tags", "response": "Extract keywords from a sentence using TF - IDF algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef paracrawl_v3_pairs(paracrawl_file):\n  raw_sentences = _raw_sentences(paracrawl_file)\n  for s_en in raw_sentences:\n    try:\n      s_xx = next(raw_sentences)\n      if s_en and s_xx:  # Prevent empty string examples.\n        yield s_en, s_xx\n    except StopIteration:\n      tf.logging.error(\n          'Unmatched final sentence while reading in sentence pairs: [%s]',\n          s_en)", "response": "Generates raw ( English other ) pairs from a ParaCrawl V3. 0 data file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _raw_sentences(paracrawl_file):\n  for line_utf8 in paracrawl_file:\n    line_uni = line_utf8.decode('UTF-8')\n    text_match = re.match(r' +<seg>(.*)</seg>$', line_uni)\n    if text_match:\n      txt = text_match.group(1)\n      txt = re.sub(r'&amp;', r'&', txt)\n      txt = re.sub(r'& ?amp;', r'&', txt)\n      txt = re.sub(r'& ?apos;', r\"'\", txt)\n      txt = re.sub(r'& ?quot;', r'\"', txt)\n      txt = re.sub(r'& ?lt;', r'<', txt)\n      txt = re.sub(r'& ?gt;', r'>', txt)\n      yield txt", "response": "Generates Unicode strings for each segment in a ParaCrawl data file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clean_en_xx_pairs(en_xx_pairs):\n  for s1, s2 in en_xx_pairs:\n    if _regex_filter(s1):\n      continue\n    s1_list, s2_list = _split_sentences(s1, s2)\n    if len(s1_list) != len(s2_list):\n      continue  # discard this pair\n    elif len(s1_list) == 1:\n      yield s1, s2\n    else:\n      for s1_subsentence, s2_subsentence in itertools.izip(s1_list, s2_list):\n        if _regex_filter(s1_subsentence):\n          continue\n        yield s1_subsentence, s2_subsentence", "response": "Generates a stream of ( English other ) translation pairs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of image paths corresponding to training or eval case.", "response": "def _get_case_file_paths(tmp_dir, case, training_fraction=0.95):\n  \"\"\"Obtain a list of image paths corresponding to training or eval case.\n\n  Args:\n    tmp_dir: str, the root path to which raw images were written, at the\n      top level having meta/ and raw/ subdirs.\n    case: bool, whether obtaining file paths for training (true) or eval\n      (false).\n    training_fraction: float, the fraction of the sub-image path list to\n      consider as the basis for training examples.\n\n  Returns:\n    list: A list of file paths.\n\n  Raises:\n    ValueError: if images not found in tmp_dir, or if training_fraction would\n      leave no examples for eval.\n  \"\"\"\n\n  paths = tf.gfile.Glob(\"%s/*.jpg\" % tmp_dir)\n\n  if not paths:\n    raise ValueError(\"Search of tmp_dir (%s) \" % tmp_dir,\n                     \"for subimage paths yielded an empty list, \",\n                     \"can't proceed with returning training/eval split.\")\n\n  split_index = int(math.floor(len(paths)*training_fraction))\n\n  if split_index >= len(paths):\n    raise ValueError(\"For a path list of size %s \"\n                     \"and a training_fraction of %s \"\n                     \"the resulting split_index of the paths list, \"\n                     \"%s, would leave no elements for the eval \"\n                     \"condition.\" % (len(paths),\n                                     training_fraction,\n                                     split_index))\n\n  if case:\n    return paths[:split_index]\n  else:\n    return paths[split_index:]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads a set of images from api. brain - map. org to target_dir.", "response": "def maybe_download_image_dataset(image_ids, target_dir):\n  \"\"\"Download a set of images from api.brain-map.org to `target_dir`.\n\n  Args:\n    image_ids: list, a list of image ids.\n    target_dir: str, a directory to which to download the images.\n  \"\"\"\n\n  tf.gfile.MakeDirs(target_dir)\n\n  num_images = len(image_ids)\n\n  for i, image_id in enumerate(image_ids):\n\n    destination = os.path.join(target_dir, \"%s.jpg\" % i)\n    tmp_destination = \"%s.temp\" % destination\n\n    source_url = (\"http://api.brain-map.org/api/v2/\"\n                  \"section_image_download/%s\" % image_id)\n\n    if tf.gfile.Exists(destination):\n      tf.logging.info(\"Image with ID already present, \"\n                      \"skipping download (%s of %s).\" % (\n                          i+1, num_images\n                      ))\n      continue\n\n    tf.logging.info(\"Downloading image with id %s (%s of %s)\" % (\n        image_id, i+1, num_images\n    ))\n\n    response = requests.get(source_url, stream=True)\n\n    response.raise_for_status()\n\n    with tf.gfile.Open(tmp_destination, \"w\") as f:\n      for block in response.iter_content(1024):\n        f.write(block)\n\n    tf.gfile.Rename(tmp_destination, destination)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a numpy array with specified shape and masked fraction.", "response": "def random_square_mask(shape, fraction):\n  \"\"\"Create a numpy array with specified shape and masked fraction.\n\n  Args:\n    shape: tuple, shape of the mask to create.\n    fraction: float, fraction of the mask area to populate with `mask_scalar`.\n\n  Returns:\n    numpy.array: A numpy array storing the mask.\n  \"\"\"\n\n  mask = np.ones(shape)\n\n  patch_area = shape[0]*shape[1]*fraction\n  patch_dim = np.int(math.floor(math.sqrt(patch_area)))\n  if patch_area == 0 or patch_dim == 0:\n    return mask\n\n  x = np.random.randint(shape[0] - patch_dim)\n  y = np.random.randint(shape[1] - patch_dim)\n\n  mask[x:(x + patch_dim), y:(y + patch_dim), :] = 0\n\n  return mask"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _generator(tmp_dir, training, size=_BASE_EXAMPLE_IMAGE_SIZE,\n               training_fraction=0.95):\n  \"\"\"Base problem example generator for Allen Brain Atlas problems.\n\n  Args:\n\n    tmp_dir: str, a directory where raw example input data has been stored.\n    training: bool, whether the mode of operation is training (or,\n      alternatively, evaluation), determining whether examples in tmp_dir\n      prefixed with train or dev will be used.\n    size: int, the image size to add to the example annotation.\n    training_fraction: float, the fraction of the sub-image path list to\n      consider as the basis for training examples.\n\n  Yields:\n    A dictionary representing the images with the following fields:\n      * image/encoded: The string encoding the image as JPEG.\n      * image/format: The string \"jpeg\" indicating the image format.\n      * image/height: The integer indicating the image height.\n      * image/width: The integer indicating the image height.\n\n  \"\"\"\n\n  maybe_download_image_dataset(_IMAGE_IDS, tmp_dir)\n\n  image_files = _get_case_file_paths(tmp_dir=tmp_dir,\n                                     case=training,\n                                     training_fraction=training_fraction)\n\n  image_obj = PIL_Image()\n\n  tf.logging.info(\"Loaded case file paths (n=%s)\" % len(image_files))\n  height = size\n  width = size\n\n  for input_path in image_files:\n\n    img = image_obj.open(input_path)\n    img = np.float32(img)\n    shape = np.shape(img)\n\n    for h_index in range(0, int(math.floor(shape[0]/size))):\n\n      h_offset = h_index * size\n      h_end = h_offset + size - 1\n\n      for v_index in range(0, int(math.floor(shape[1]/size))):\n\n        v_offset = v_index * size\n        v_end = v_offset + size - 1\n\n        # Extract a sub-image tile.\n        subimage = np.uint8(img[h_offset:h_end, v_offset:v_end])  # pylint: disable=invalid-sequence-index\n\n        # Filter images that are likely background (not tissue).\n        if np.amax(subimage) < 230:\n          continue\n\n        subimage = image_obj.fromarray(subimage)\n        buff = BytesIO()\n        subimage.save(buff, format=\"JPEG\")\n        subimage_encoded = buff.getvalue()\n\n        yield {\n            \"image/encoded\": [subimage_encoded],\n            \"image/format\": [\"jpeg\"],\n            \"image/height\": [height],\n            \"image/width\": [width]\n        }", "response": "Base problem example generator for Allen Brain Atlas problems."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transformer_moe_2k():\n  hparams = transformer_moe_8k()\n  hparams.batch_size = 2048\n\n  hparams.default_ff = \"sep\"\n\n  # hparams.layer_types contains the network architecture:\n  encoder_archi = \"a/a/a/a/a\"\n  decoder_archi = \"a-sepm/a-sepm/a-moe/a-sepm/a-sepm\"\n  hparams.layer_types = \"{}#{}\".format(encoder_archi, decoder_archi)\n\n  return hparams", "response": "Base transformers model with moe.\n Will have the following architecture."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmodel which formulate a seq2seq problem as language modeling.", "response": "def transformer_moe_prepend_8k():\n  \"\"\"Model which formulate a seq2seq problem as language modeling.\"\"\"\n  hparams = transformer_moe_8k()\n  hparams.prepend_mode = \"prepend_inputs_masked_attention\"\n  hparams.eval_drop_long_sequences = False\n  hparams.max_input_seq_length = 7500\n  hparams.default_ff = \"sepm\"\n  hparams.layer_types = \"locm/redm/locm-moe/redm/locm\"\n  hparams.moe_num_experts = 256\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply residual function for RevNet.", "response": "def f(x, depth1, depth2, dim='2d', first_batch_norm=True, stride=1,\n      training=True, bottleneck=True, padding='SAME'):\n  \"\"\"Applies residual function for RevNet.\n\n  Args:\n    x: input tensor\n    depth1: Number of output channels for the first and second conv layers.\n    depth2: Number of output channels for the third conv layer.\n    dim: '2d' if 2-dimensional, '3d' if 3-dimensional.\n    first_batch_norm: Whether to keep the first batch norm layer or not.\n      Typically used in the first RevNet block.\n    stride: Stride for the first conv filter. Note that this particular\n      RevNet architecture only varies the stride for the first conv\n      filter. The stride for the second conv filter is always set to 1.\n    training: True for train phase, False for eval phase.\n    bottleneck: If true, apply bottleneck 1x1 down/up sampling.\n    padding: Padding for each conv layer.\n\n  Returns:\n    Output tensor after applying residual function for RevNet.\n  \"\"\"\n  conv = CONFIG[dim]['conv']\n  with tf.variable_scope('f', reuse=tf.AUTO_REUSE):\n    if first_batch_norm:\n      net = tf.layers.batch_normalization(x, training=training)\n      net = tf.nn.relu(net)\n    else:\n      net = x\n\n    if bottleneck:\n      net = conv(net, depth1, 1, strides=stride,\n                 padding=padding, activation=None)\n\n      net = tf.layers.batch_normalization(net, training=training)\n      net = tf.nn.relu(net)\n      net = conv(net, depth1, 3, strides=1,\n                 padding=padding, activation=None)\n\n      net = tf.layers.batch_normalization(net, training=training)\n      net = tf.nn.relu(net)\n      net = conv(net, depth2, 1, strides=1,\n                 padding=padding, activation=None)\n    else:\n      net = conv(net, depth2, 3, strides=stride,\n                 padding=padding, activation=None)\n      net = tf.layers.batch_normalization(x, training=training)\n      net = tf.nn.relu(net)\n      net = conv(net, depth2, 3, strides=stride,\n                 padding=padding, activation=None)\n\n    return net"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef downsample_residual(x, output_channels, dim='2d', stride=1, scope='h'):\n  with tf.variable_scope(scope):\n    if stride > 1:\n      avg_pool = CONFIG[dim]['avg_pool']\n      x = avg_pool(x,\n                   pool_size=(stride, stride),\n                   strides=(stride, stride),\n                   padding='VALID')\n\n    input_channels = tf.shape(x)[3]\n    diff = output_channels - input_channels\n    x = tf.pad(\n        x, [[0, 0], [0, 0], [0, 0],\n            [diff // 2, diff // 2]])\n    return x", "response": "Downsamples x by stride using average pooling."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nimplementing bottleneck RevNet architecture.", "response": "def unit(x1, x2, block_num, depth, num_layers, dim='2d',\n         bottleneck=True, first_batch_norm=True, stride=1, training=True):\n  \"\"\"Implements bottleneck RevNet unit from authors' RevNet architecture.\n\n  Args:\n    x1: [N, H, W, C] tensor of network activations.\n    x2: [N, H, W, C] tensor of network activations.\n    block_num: integer ID of block\n    depth: First depth in bottleneck residual unit.\n    num_layers: Number of layers in the RevNet block.\n    dim: '2d' if 2-dimensional, '3d' if 3-dimensional.\n    bottleneck: Should a bottleneck layer be used.\n    first_batch_norm: Whether to keep the first batch norm layer or not.\n      Typically used in the first RevNet block.\n    stride: Stride for the residual function.\n    training: True for train phase, False for eval phase.\n\n  Returns:\n    Two [N, H, W, C] output activation tensors.\n  \"\"\"\n  scope_name = 'unit_%d' % block_num\n  if bottleneck:\n    depth1 = depth\n    depth2 = depth * 4\n  else:\n    depth1 = depth2 = depth\n\n  residual = wrapped_partial(f,\n                             depth1=depth1, depth2=depth2, dim=dim,\n                             training=training, bottleneck=bottleneck)\n\n  with tf.variable_scope(scope_name):\n    downsample = downsample_bottleneck if bottleneck else downsample_residual\n    # Manual implementation of downsampling\n    with tf.variable_scope('downsampling'):\n      with tf.variable_scope('x1'):\n        hx1 = downsample(x1, depth2, dim=dim, stride=stride)\n        fx2 = residual(x2, stride=stride, first_batch_norm=first_batch_norm)\n        x1 = hx1 + fx2\n      with tf.variable_scope('x2'):\n        hx2 = downsample(x2, depth2, dim=dim, stride=stride)\n        fx1 = residual(x1)\n        x2 = hx2 + fx1\n\n    # Full block using memory-efficient rev_block implementation.\n    with tf.variable_scope('full_block'):\n      x1, x2 = tf.contrib.layers.rev_block(x1, x2,\n                                           residual,\n                                           residual,\n                                           num_layers=num_layers)\n      return x1, x2"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef final_block(x1, x2, dim='2d', training=True, scope='final_block'):\n\n  # Final batch norm and relu\n  with tf.variable_scope(scope):\n    y = tf.concat([x1, x2], axis=CONFIG[dim]['split_axis'])\n    y = tf.layers.batch_normalization(y, training=training)\n    y = tf.nn.relu(y)\n\n    # Global average pooling\n    net = tf.reduce_mean(y, CONFIG[dim]['reduction_dimensions'],\n                         name='final_pool', keep_dims=True)\n\n    return net", "response": "Converts activations from last RevNet block to pre - logits."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuses Tensor2Tensor memory optimized RevNet block to build a RevNet block.", "response": "def revnet(inputs, hparams, reuse=None):\n  \"\"\"Uses Tensor2Tensor memory optimized RevNet block to build a RevNet.\n\n  Args:\n    inputs: [NxHxWx3] tensor of input images to the model.\n    hparams: HParams object that contains the following parameters,\n      in addition to the parameters contained in the basic_params1() object in\n      the common_hparams module:\n        num_channels_first - A Python list where each element represents the\n          depth of the first and third convolutional layers in the bottleneck\n          residual unit for a given block.\n        num_channels_second - A Python list where each element represents the\n          depth of the second convolutional layer in the bottleneck residual\n          unit for a given block.\n        num_layers_per_block - A Python list containing the number of RevNet\n          layers for each block.\n        first_batch_norm - A Python list containing booleans representing the\n          presence of a batch norm layer at the beginning of a given block.\n        strides - A Python list containing integers representing the stride of\n          the residual function for each block.\n        num_channels_init_block - An integer representing the number of channels\n          for the convolutional layer in the initial block.\n        dimension - A string (either \"2d\" or \"3d\") that decides if the RevNet is\n          2-dimensional or 3-dimensional.\n    reuse: Whether to reuse the default variable scope.\n\n  Returns:\n    [batch_size, hidden_dim] pre-logits tensor from the bottleneck RevNet.\n  \"\"\"\n  training = hparams.mode == tf.estimator.ModeKeys.TRAIN\n  with tf.variable_scope('RevNet', reuse=reuse):\n    x1, x2 = init(inputs,\n                  num_channels=hparams.num_channels_init_block,\n                  dim=hparams.dim,\n                  kernel_size=hparams.init_kernel_size,\n                  maxpool=hparams.init_maxpool,\n                  stride=hparams.init_stride,\n                  training=training)\n    for block_num in range(len(hparams.num_layers_per_block)):\n      block = {'depth': hparams.num_channels[block_num],\n               'num_layers': hparams.num_layers_per_block[block_num],\n               'first_batch_norm': hparams.first_batch_norm[block_num],\n               'stride': hparams.strides[block_num],\n               'bottleneck': hparams.bottleneck}\n      x1, x2 = unit(x1, x2, block_num, dim=hparams.dim, training=training,\n                    **block)\n    pre_logits = final_block(x1, x2, dim=hparams.dim, training=training)\n    return pre_logits"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef revnet_base():\n  hparams = common_hparams.basic_params1()\n  hparams.add_hparam('num_channels', [64, 128, 256, 416])\n  hparams.add_hparam('num_layers_per_block', [1, 1, 10, 1])\n  hparams.add_hparam('bottleneck', True)\n  hparams.add_hparam('first_batch_norm', [False, True, True, True])\n  hparams.add_hparam('init_stride', 2)\n  hparams.add_hparam('init_kernel_size', 7)\n  hparams.add_hparam('init_maxpool', True)\n  hparams.add_hparam('strides', [1, 2, 2, 2])\n  hparams.add_hparam('num_channels_init_block', 64)\n  hparams.add_hparam('dim', '2d')\n\n  # Variable init\n  hparams.initializer = 'normal_unit_scaling'\n  hparams.initializer_gain = 2.\n\n  # Optimization\n  hparams.optimizer = 'Momentum'\n  hparams.optimizer_momentum_momentum = 0.9\n  hparams.optimizer_momentum_nesterov = True\n  hparams.weight_decay = 1e-4\n  hparams.clip_grad_norm = 0.0\n  # (base_lr=0.1) * (batch_size=128*8 (on TPU, or 8 GPUs)=1024) / (256.)\n  hparams.learning_rate = 0.4\n  hparams.learning_rate_decay_scheme = 'cosine'\n  # For image_imagenet224, 120k training steps, which effectively makes this a\n  # cosine decay (i.e. no cycles).\n  hparams.learning_rate_cosine_cycle_steps = 120000\n\n  # Can run with a batch size of 128 with Problem ImageImagenet224\n  hparams.batch_size = 128\n  return hparams", "response": "Default hparams for Revnet."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef revnet_cifar_base():\n  hparams = revnet_base()\n  hparams.num_channels_init_block = 32\n  hparams.first_batch_norm = [False, True, True]\n  hparams.init_stride = 1\n  hparams.init_kernel_size = 3\n  hparams.init_maxpool = False\n  hparams.strides = [1, 2, 2]\n  hparams.batch_size = 128\n  hparams.weight_decay = 1e-4\n\n  hparams.learning_rate = 0.1\n  hparams.learning_rate_cosine_cycle_steps = 5000\n  return hparams", "response": "Tiny hparams suitable for CIFAR."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef revnet_110_cifar():\n  hparams = revnet_cifar_base()\n  hparams.bottleneck = False\n  hparams.num_channels = [16, 32, 64]\n  hparams.num_layers_per_block = [8, 8, 8]\n  return hparams", "response": "Tiny hparams suitable for CIFAR and etc."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef next_frame_basic_deterministic():\n  hparams = base.next_frame_base()\n  hparams.video_num_input_frames = 4\n  hparams.video_num_target_frames = 1\n  hparams.hidden_size = 64\n  hparams.batch_size = 4\n  hparams.num_hidden_layers = 2\n  hparams.optimizer = \"Adafactor\"\n  hparams.learning_rate_constant = 1.5\n  hparams.learning_rate_warmup_steps = 8000\n  hparams.learning_rate_schedule = \"linear_warmup * constant * rsqrt_decay\"\n  hparams.label_smoothing = 0.0\n  hparams.initializer = \"uniform_unit_scaling\"\n  hparams.initializer_gain = 1.3\n  hparams.weight_decay = 0.0\n  hparams.clip_grad_norm = 1.0\n  hparams.dropout = 0.1\n  hparams.add_hparam(\"residual_dropout\", 0.5)\n  hparams.add_hparam(\"num_compress_steps\", 6)\n  hparams.add_hparam(\"filter_double_steps\", 2)\n  hparams.add_hparam(\"pixel_sampling_temperature\", 0.0)\n  hparams.add_hparam(\"concat_internal_states\", False)\n  hparams.add_hparam(\"do_autoregressive_rnn\", False)\n  hparams.add_hparam(\"autoregressive_rnn_lookback\", 8)\n  hparams.add_hparam(\"autoregressive_rnn_warmup_steps\", 8000)\n  hparams.add_hparam(\"activation_fn\", \"relu\")\n  hparams.bottom[\"inputs\"] = modalities.video_identity_bottom\n  hparams.bottom[\"targets\"] = modalities.video_identity_bottom\n  return hparams", "response": "Basic 2 - frame conv model."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef next_frame_pixel_noise():\n  hparams = next_frame_basic_deterministic()\n  hparams.add_hparam(\"video_modality_input_noise\", 0.05)\n  hparams.bottom[\"inputs\"] = modalities.video_pixel_noise_bottom\n  hparams.top[\"inputs\"] = modalities.video_top\n  return hparams", "response": "Basic 2 - frame conv model with pixel noise."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef next_frame_sampling():\n  hparams = next_frame_basic_deterministic()\n  hparams.scheduled_sampling_mode = \"prob_inverse_exp\"\n  hparams.scheduled_sampling_max_prob = 1.0\n  hparams.scheduled_sampling_decay_steps = 10000\n  return hparams", "response": "Basic conv model with scheduled sampling."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef next_frame_ae_tiny():\n  hparams = next_frame_tiny()\n  hparams.bottom[\"inputs\"] = modalities.video_bitwise_bottom\n  hparams.top[\"inputs\"] = modalities.video_top\n  hparams.batch_size = 8\n  hparams.dropout = 0.4\n  return hparams", "response": "Conv autoencoder tiny set for testing."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef next_frame_l2():\n  hparams = next_frame_basic_deterministic()\n  hparams.loss[\"targets\"] = modalities.video_l2_loss\n  hparams.top[\"targets\"] = modalities.video_l1_top\n  hparams.video_modality_loss_cutoff = 2.4\n  return hparams", "response": "Basic conv model with L2 modality."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mqp_lm1b_base():\n  hparams = mtf_transformer2.mtf_unitransformer_base()\n  hparams.d_model = 1024\n  hparams.max_length = 256\n  hparams.batch_size = 256\n  # Parameters for my_layer_stack()\n  hparams.num_hidden_layers = 6\n  hparams.d_ff = 8192\n  hparams.d_kv = 128\n  hparams.num_heads = 8\n  hparams.learning_rate_decay_steps = 13600\n  hparams.layout = \"batch:batch;vocab:model;d_ff:model;heads:model\"\n  hparams.mesh_shape = \"batch:32\"\n  return hparams", "response": "Series of architectures for language modeling."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninitializes env_specs using the appropriate env.", "response": "def initialize_env_specs(hparams, env_problem_name):\n  \"\"\"Initializes env_specs using the appropriate env.\"\"\"\n  if env_problem_name:\n    env = registry.env_problem(env_problem_name, batch_size=hparams.batch_size)\n  else:\n    env = rl_utils.setup_env(hparams, hparams.batch_size,\n                             hparams.eval_max_num_noops,\n                             hparams.rl_env_max_episode_steps,\n                             env_name=hparams.rl_env_name)\n    env.start_new_epoch(0)\n\n  return rl.make_real_env_fn(env)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntrain the model using hparams.", "response": "def train(hparams, output_dir, env_problem_name, report_fn=None):\n  \"\"\"Train.\"\"\"\n  env_fn = initialize_env_specs(hparams, env_problem_name)\n\n  tf.logging.vlog(1, \"HParams in trainer_model_free.train : %s\",\n                  misc_utils.pprint_hparams(hparams))\n  tf.logging.vlog(1, \"Using hparams.base_algo: %s\", hparams.base_algo)\n  learner = rl_utils.LEARNERS[hparams.base_algo](\n      hparams.frame_stack_size, output_dir, output_dir, total_num_epochs=1\n  )\n\n  policy_hparams = trainer_lib.create_hparams(hparams.base_algo_params)\n  rl_utils.update_hparams_from_hparams(\n      policy_hparams, hparams, hparams.base_algo + \"_\"\n  )\n\n  tf.logging.vlog(1, \"Policy HParams : %s\",\n                  misc_utils.pprint_hparams(policy_hparams))\n\n  # TODO(konradczechowski): remove base_algo dependance, when evaluation method\n  # will be decided\n  if hparams.base_algo == \"ppo\":\n    total_steps = policy_hparams.epochs_num\n    tf.logging.vlog(2, \"total_steps: %d\", total_steps)\n\n    eval_every_epochs = policy_hparams.eval_every_epochs\n    tf.logging.vlog(2, \"eval_every_epochs: %d\", eval_every_epochs)\n\n    if eval_every_epochs == 0:\n      eval_every_epochs = total_steps\n    policy_hparams.eval_every_epochs = 0\n\n    metric_name = rl_utils.get_metric_name(\n        sampling_temp=hparams.eval_sampling_temps[0],\n        max_num_noops=hparams.eval_max_num_noops,\n        clipped=False\n    )\n\n    tf.logging.vlog(1, \"metric_name: %s\", metric_name)\n\n    eval_metrics_dir = os.path.join(output_dir, \"eval_metrics\")\n    eval_metrics_dir = os.path.expanduser(eval_metrics_dir)\n    tf.gfile.MakeDirs(eval_metrics_dir)\n    eval_metrics_writer = tf.summary.FileWriter(eval_metrics_dir)\n\n    def evaluate_on_new_model(model_dir_path):\n      global step\n      eval_metrics = rl_utils.evaluate_all_configs(hparams, model_dir_path)\n      tf.logging.info(\n          \"Agent eval metrics:\\n{}\".format(pprint.pformat(eval_metrics)))\n      rl_utils.summarize_metrics(eval_metrics_writer, eval_metrics, step)\n      if report_fn:\n        report_fn(eval_metrics[metric_name], step)\n      step += 1\n\n    policy_hparams.epochs_num = total_steps\n    policy_hparams.save_models_every_epochs = eval_every_epochs\n  else:\n    def evaluate_on_new_model(model_dir_path):\n      del model_dir_path\n      raise NotImplementedError(\n          \"This function is currently implemented only for ppo\")\n\n  learner.train(env_fn,\n                policy_hparams,\n                simulated=False,\n                save_continuously=True,\n                epoch=0,\n                model_save_fn=evaluate_on_new_model)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the designated learning rate factor from hparams.", "response": "def learning_rate_factor(name, step_num, hparams):\n  \"\"\"Compute the designated learning rate factor from hparams.\"\"\"\n  if name == \"constant\":\n    tf.logging.info(\"Base learning rate: %f\", hparams.learning_rate_constant)\n    return hparams.learning_rate_constant\n  elif name == \"linear_warmup\":\n    return tf.minimum(1.0, step_num / hparams.learning_rate_warmup_steps)\n  elif name == \"linear_decay\":\n    ret = (hparams.train_steps - step_num) / hparams.learning_rate_decay_steps\n    return tf.minimum(1.0, tf.maximum(0.0, ret))\n  elif name == \"cosdecay\":  # openai gpt\n    in_warmup = tf.cast(step_num <= hparams.learning_rate_warmup_steps,\n                        dtype=tf.float32)\n    ret = 0.5 * (1 + tf.cos(\n        np.pi * step_num / hparams.learning_rate_decay_steps))\n    # if in warmup stage return 1 else return the decayed value\n    return in_warmup * 1 + (1 - in_warmup) * ret\n  elif name == \"single_cycle_cos_decay\":\n    # Cosine decay to zero with a single cycle. This is different from\n    # \"cosdecay\" because it starts at 1 when the warmup steps end.\n    x = tf.maximum(step_num, hparams.learning_rate_warmup_steps)\n    step = x - hparams.learning_rate_warmup_steps\n    return tf.math.cos(\n        step * np.pi / hparams.learning_rate_decay_steps) / 2.0 + 0.5\n  elif name == \"rsqrt_decay\":\n    return tf.rsqrt(tf.maximum(step_num, hparams.learning_rate_warmup_steps))\n  elif name == \"rsqrt_normalized_decay\":\n    scale = tf.sqrt(tf.to_float(hparams.learning_rate_warmup_steps))\n    return scale * tf.rsqrt(tf.maximum(\n        step_num, hparams.learning_rate_warmup_steps))\n  elif name == \"exp_decay\":\n    decay_steps = hparams.learning_rate_decay_steps\n    warmup_steps = hparams.learning_rate_warmup_steps\n    p = (step_num - warmup_steps) / decay_steps\n    p = tf.maximum(p, 0.)\n    if hparams.learning_rate_decay_staircase:\n      p = tf.floor(p)\n    return tf.pow(hparams.learning_rate_decay_rate, p)\n  elif name == \"rsqrt_hidden_size\":\n    return hparams.hidden_size ** -0.5\n  elif name == \"legacy\":\n    return legacy_learning_rate_schedule(hparams)\n  else:\n    raise ValueError(\"unknown learning rate factor %s\" % name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef learning_rate_schedule(hparams):\n  mlperf_log.transformer_print(key=mlperf_log.OPT_LR, deferred=True)\n  mlperf_log.transformer_print(\n      key=mlperf_log.OPT_LR_WARMUP_STEPS,\n      value=hparams.learning_rate_warmup_steps)\n  step_num = _global_step(hparams)\n  schedule_string = hparams.learning_rate_schedule\n  names = schedule_string.split(\"*\")\n  names = [name.strip() for name in names if name.strip()]\n  ret = tf.constant(1.0)\n  for name in names:\n    ret *= learning_rate_factor(name, step_num, hparams)\n  return ret", "response": "Learning rate schedule based on hparams."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _global_step(hparams):\n  step = tf.to_float(tf.train.get_or_create_global_step())\n  multiplier = hparams.optimizer_multistep_accumulate_steps\n  if not multiplier:\n    return step\n\n  tf.logging.info(\"Dividing global step by %d for multi-step optimizer.\"\n                  % multiplier)\n  return step / tf.to_float(multiplier)", "response": "Adjust global step if a multi - step optimizer is used."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nscale learning rate according to the given schedule.", "response": "def _piecewise_learning_rate(step, boundaries, values):\n  \"\"\"Scale learning rate according to the given schedule.\n\n  Multipliers are not cumulative.\n\n  Args:\n    step: global step\n    boundaries: List of steps to transition on.\n    values: Multiplier to apply at each boundary transition.\n\n  Returns:\n    Scaled value for the learning rate.\n  \"\"\"\n  values = [1.0] + values\n  boundaries = [float(x) for x in boundaries]\n  return tf.train.piecewise_constant(\n      step, boundaries, values, name=\"piecewise_lr\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlearn rate decay multiplier.", "response": "def _learning_rate_decay(hparams, warmup_steps=0):\n  \"\"\"Learning rate decay multiplier.\"\"\"\n  scheme = hparams.learning_rate_decay_scheme\n  warmup_steps = tf.to_float(warmup_steps)\n  global_step = _global_step(hparams)\n\n  if not scheme or scheme == \"none\":\n    return tf.constant(1.)\n\n  tf.logging.info(\"Applying learning rate decay: %s.\", scheme)\n\n  if scheme == \"exp\":\n    decay_steps = hparams.learning_rate_decay_steps\n    p = (global_step - warmup_steps) / decay_steps\n    if hparams.learning_rate_decay_staircase:\n      p = tf.floor(p)\n    return tf.pow(hparams.learning_rate_decay_rate, p)\n\n  if scheme == \"piecewise\":\n    return _piecewise_learning_rate(global_step,\n                                    hparams.learning_rate_boundaries,\n                                    hparams.learning_rate_multiples)\n\n  if scheme == \"cosine\":\n    cycle_steps = hparams.learning_rate_cosine_cycle_steps\n    cycle_position = global_step % (2 * cycle_steps)\n    cycle_position = cycle_steps - tf.abs(cycle_steps - cycle_position)\n    return 0.5 * (1 + tf.cos(np.pi * cycle_position / cycle_steps))\n\n  if scheme == \"cyclelinear10x\":\n    # Cycle the rate linearly by 10x every warmup_steps, up and down.\n    cycle_steps = warmup_steps\n    cycle_position = global_step % (2 * cycle_steps)\n    cycle_position = tf.to_float(  # Normalize to the interval [-1, 1].\n        cycle_position - cycle_steps) / float(cycle_steps)\n    cycle_position = 1.0 - tf.abs(cycle_position)  # 0 to 1 and back to 0.\n    return (cycle_position + 0.1) * 3.0  # 10x difference each cycle (0.3-3).\n\n  if scheme == \"sqrt\":\n    return _legacy_sqrt_decay(global_step - warmup_steps)\n\n  raise ValueError(\"Unrecognized learning rate decay scheme: %s\" %\n                   hparams.learning_rate_decay_scheme)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _learning_rate_warmup(warmup_steps, warmup_schedule=\"exp\", hparams=None):\n  if not warmup_steps:\n    return tf.constant(1.)\n\n  tf.logging.info(\"Applying %s learning rate warmup for %d steps\",\n                  warmup_schedule, warmup_steps)\n\n  warmup_steps = tf.to_float(warmup_steps)\n  global_step = _global_step(hparams)\n\n  if warmup_schedule == \"exp\":\n    return tf.exp(tf.log(0.01) / warmup_steps)**(warmup_steps - global_step)\n  else:\n    assert warmup_schedule == \"linear\"\n    start = tf.constant(0.35)\n    return ((tf.constant(1.) - start) / warmup_steps) * global_step + start", "response": "Learning rate warmup multiplier."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_in_expr(expr, find):\n  return expr == find or (isinstance(expr, ExprNode) and expr.is_in(find))", "response": "Returns True if expr is a subtree of find."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef random_expr_with_required_var(depth, required_var, optional_list, ops):\n  if not depth:\n    if required_var:\n      return required_var\n    return str(optional_list[random.randrange(len(optional_list))])\n\n  max_depth_side = random.randrange(2)\n  other_side_depth = random.randrange(depth)\n\n  required_var_side = random.randrange(2)\n\n  left = random_expr_with_required_var(\n      depth - 1 if max_depth_side else other_side_depth, required_var\n      if required_var_side else None, optional_list, ops)\n  right = random_expr_with_required_var(\n      depth - 1 if not max_depth_side else other_side_depth, required_var\n      if not required_var_side else None, optional_list, ops)\n\n  op = ops[random.randrange(len(ops))]\n  return ExprNode(left, right, op)", "response": "Generate a random expression tree with a required variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a random expression tree.", "response": "def random_expr(depth, vlist, ops):\n  \"\"\"Generate a random expression tree.\n\n  Args:\n    depth: At least one leaf will be this many levels down from the top.\n    vlist: A list of chars. These chars are randomly selected as leaf values.\n    ops: A list of ExprOp instances.\n\n  Returns:\n    An ExprNode instance which is the root of the generated expression tree.\n  \"\"\"\n  if not depth:\n    return str(vlist[random.randrange(len(vlist))])\n\n  max_depth_side = random.randrange(2)\n  other_side_depth = random.randrange(depth)\n\n  left = random_expr(depth - 1\n                     if max_depth_side else other_side_depth, vlist, ops)\n  right = random_expr(depth - 1\n                      if not max_depth_side else other_side_depth, vlist, ops)\n\n  op = ops[random.randrange(len(ops))]\n  return ExprNode(left, right, op)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsolve for the value of the given var in an expression.", "response": "def algebra_inverse_solve(left, right, var, solve_ops):\n  \"\"\"Solves for the value of the given var in an expression.\n\n  Args:\n    left: The root of the ExprNode tree on the left side of the equals sign.\n    right: The root of the ExprNode tree on the right side of the equals sign.\n    var: A char. The variable to solve for.\n    solve_ops: A dictionary with the following properties.\n        * For each operator in the expression, there is a rule that determines\n          how to cancel out a value either to the left or the right of that\n          operator.\n        * For each rule, there is an entry in the dictionary. The key is two\n          chars- the op char, and either 'l' or 'r' meaning rule for canceling\n          out the left or right sides. For example, '+l', '+r', '-l', '-r'.\n        * The value of each entry is a function with the following signature:\n          (left, right, to_tree) -> (new_from_tree, new_to_tree)\n          left- Expression on left side of the op.\n          right- Expression on the right side of the op.\n          to_tree- The tree on the other side of the equal sign. The canceled\n              out expression will be moved here.\n          new_from_tree- The resulting from_tree after the algebraic\n              manipulation.\n          new_to_tree- The resulting to_tree after the algebraic manipulation.\n\n  Returns:\n    The root of an ExprNode tree which holds the value of `var` after solving.\n\n  Raises:\n    ValueError: If `var` does not appear exactly once in the equation (which\n        includes the left and right sides).\n  \"\"\"\n  is_in_left = is_in_expr(left, var)\n  is_in_right = is_in_expr(right, var)\n  if is_in_left == is_in_right:\n    if is_in_left:\n      raise ValueError(\"Solve-variable '%s' is on both sides of the equation. \"\n                       \"Only equations where the solve variable-appears once \"\n                       \"are supported by this solver. Left: '%s', right: '%s'\" %\n                       (var, str(left), str(right)))\n    else:\n      raise ValueError(\"Solve-variable '%s' is not present in the equation. It \"\n                       \"must appear once. Left: '%s', right: '%s'\" %\n                       (var, str(left), str(right)))\n\n  from_tree = left if is_in_left else right\n  to_tree = left if not is_in_left else right\n  while from_tree != var:\n    is_in_left = is_in_expr(from_tree.left, var)\n    is_in_right = is_in_expr(from_tree.right, var)\n    from_tree, to_tree = (solve_ops[str(from_tree.op)\n                                    + (\"l\" if is_in_left else \"r\")](\n                                        from_tree.left, from_tree.right,\n                                        to_tree))\n  return to_tree"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_sympy_expr(sympy_expr, functions=None):\n  if functions is None:\n    functions = {}\n  str_expr = str(sympy_expr)\n  result = str_expr.replace(\" \", \"\")\n  for fn_name, char in six.iteritems(functions):\n    result = result.replace(fn_name, char)\n  return result", "response": "Convert a sympy expression tree to a string which can be encoded."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_algebra_inverse_sample(vlist, ops, solve_ops, min_depth,\n                                    max_depth):\n  \"\"\"Randomly generate an algebra inverse dataset sample.\n\n  Given an input equation and variable, produce the expression equal to the\n  variable.\n\n  Args:\n    vlist: Variable list. List of chars that can be used in the expression.\n    ops: List of ExprOp instances. The allowed operators for the expression.\n    solve_ops: See `solve_ops` documentation in `algebra_inverse_solve`.\n    min_depth: Expression trees will not have a smaller depth than this. 0 means\n        there is just a variable. 1 means there is one operation.\n    max_depth: Expression trees will not have a larger depth than this. To make\n        all trees have the same depth, set this equal to `min_depth`.\n\n  Returns:\n    sample: String representation of the input. Will be of the form\n        'solve_var:left_side=right_side'.\n    target: String representation of the solution.\n  \"\"\"\n  side = random.randrange(2)\n  left_depth = random.randrange(min_depth if side else 0, max_depth + 1)\n  right_depth = random.randrange(min_depth if not side else 0, max_depth + 1)\n\n  var_index = random.randrange(len(vlist))\n  var = vlist[var_index]\n  consts = vlist[:var_index] + vlist[var_index + 1:]\n\n  left = random_expr_with_required_var(left_depth, var\n                                       if side else None, consts, ops)\n  right = random_expr_with_required_var(right_depth, var\n                                        if not side else None, consts, ops)\n\n  left_str = str(left)\n  right_str = str(right)\n  target = str(algebra_inverse_solve(left, right, var, solve_ops))\n  sample = \"%s:%s=%s\" % (var, left_str, right_str)\n  return sample, target", "response": "Generates an algebra inverse dataset sample."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating an algebra simplify dataset sample.", "response": "def generate_algebra_simplify_sample(vlist, ops, min_depth, max_depth):\n  \"\"\"Randomly generate an algebra simplify dataset sample.\n\n  Given an input expression, produce the simplified expression.\n\n  Args:\n    vlist: Variable list. List of chars that can be used in the expression.\n    ops: List of ExprOp instances. The allowed operators for the expression.\n    min_depth: Expression trees will not have a smaller depth than this. 0 means\n        there is just a variable. 1 means there is one operation.\n    max_depth: Expression trees will not have a larger depth than this. To make\n        all trees have the same depth, set this equal to `min_depth`.\n\n  Returns:\n    sample: String representation of the input.\n    target: String representation of the solution.\n  \"\"\"\n  depth = random.randrange(min_depth, max_depth + 1)\n  expr = random_expr(depth, vlist, ops)\n\n  sample = str(expr)\n  target = format_sympy_expr(sympy.simplify(sample))\n  return sample, target"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_calculus_integrate_sample(vlist, ops, min_depth, max_depth,\n                                       functions):\n  \"\"\"Randomly generate a symbolic integral dataset sample.\n\n  Given an input expression, produce the indefinite integral.\n\n  Args:\n    vlist: Variable list. List of chars that can be used in the expression.\n    ops: List of ExprOp instances. The allowed operators for the expression.\n    min_depth: Expression trees will not have a smaller depth than this. 0 means\n        there is just a variable. 1 means there is one operation.\n    max_depth: Expression trees will not have a larger depth than this. To make\n        all trees have the same depth, set this equal to `min_depth`.\n    functions: Defines special functions. A dict mapping human readable string\n        names, like \"log\", \"exp\", \"sin\", \"cos\", etc., to single chars. Each\n        function gets a unique token, like \"L\" for \"log\".\n\n  Returns:\n    sample: String representation of the input. Will be of the form\n        'var:expression'.\n    target: String representation of the solution.\n  \"\"\"\n  var_index = random.randrange(len(vlist))\n  var = vlist[var_index]\n  consts = vlist[:var_index] + vlist[var_index + 1:]\n\n  depth = random.randrange(min_depth, max_depth + 1)\n  expr = random_expr_with_required_var(depth, var, consts, ops)\n\n  expr_str = str(expr)\n  sample = var + \":\" + expr_str\n  target = format_sympy_expr(\n      sympy.integrate(expr_str, sympy.Symbol(var)), functions=functions)\n  return sample, target", "response": "Generates a symbolic integral dataset sample."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef math_dataset_init(alphabet_size=26, digits=None, functions=None):\n  ops_list = [\"+\", \"-\", \"*\", \"/\"]\n  ops = {\n      \"+\": ExprOp(\"+\", 0, True),\n      \"-\": ExprOp(\"-\", 0, False),\n      \"*\": ExprOp(\"*\", 1, True),\n      \"/\": ExprOp(\"/\", 1, False)\n  }\n  solve_ops = {\n      \"+l\": lambda l, r, to: (l, ExprNode(to, r, ops[\"-\"])),\n      \"+r\": lambda l, r, to: (r, ExprNode(to, l, ops[\"-\"])),\n      \"-l\": lambda l, r, to: (l, ExprNode(to, r, ops[\"+\"])),\n      \"-r\": lambda l, r, to: (r, ExprNode(l, to, ops[\"-\"])),\n      \"*l\": lambda l, r, to: (l, ExprNode(to, r, ops[\"/\"])),\n      \"*r\": lambda l, r, to: (r, ExprNode(to, l, ops[\"/\"])),\n      \"/l\": lambda l, r, to: (l, ExprNode(to, r, ops[\"*\"])),\n      \"/r\": lambda l, r, to: (r, ExprNode(l, to, ops[\"/\"])),\n  }\n  alphabet = (\n      [six.int2byte(ord(\"a\") + c).decode(\"utf-8\") for c in range(26)] +\n      [six.int2byte(ord(\"A\") + c).decode(\"utf-8\") for c in range(26)])\n  if alphabet_size > 52:\n    raise ValueError(\n        \"alphabet_size cannot be greater than 52. Got %s.\" % alphabet_size)\n  if alphabet_size < 2:\n    raise ValueError(\n        \"alphabet_size cannot be less than 2. Got %s.\" % alphabet_size)\n  if digits is not None and not 1 <= digits <= 10:\n    raise ValueError(\"digits cannot must be between 1 and 10. Got %s.\" % digits)\n  vlist = alphabet[:alphabet_size]\n  if digits is not None:\n    dlist = [str(d) for d in range(digits)]\n  else:\n    dlist = []\n  if functions is None:\n    functions = {}\n  flist = sorted(functions.values())\n  pad = \"_\"\n  tokens = [pad] + [\":\", \"(\", \")\", \"=\"] + ops_list + vlist + dlist + flist\n  if len(tokens) != len(set(tokens)):\n    raise ValueError(\"Duplicate token. Tokens: %s\" % tokens)\n  token_map = dict([(t, i) for i, t in enumerate(tokens)])\n\n  def int_encoder(sequence):\n    return [token_map[s] for s in sequence]\n\n  def int_decoder(tensor_1d):\n    return \"\".join([tokens[i] for i in tensor_1d])\n\n  return AlgebraConfig(\n      vlist=vlist,\n      dlist=dlist,\n      flist=flist,\n      functions=functions,\n      ops=ops,\n      solve_ops=solve_ops,\n      int_encoder=int_encoder,\n      int_decoder=int_decoder)", "response": "Initializes the internal state of the symbolic math dataset."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef algebra_inverse(alphabet_size=26, min_depth=0, max_depth=2,\n                    nbr_cases=10000):\n  \"\"\"Generate the algebra inverse dataset.\n\n  Each sample is a symbolic math equation involving unknown variables. The\n  task is to solve for the given variable. The target is the resulting\n  expression.\n\n  Args:\n    alphabet_size: How many possible variables there are. Max 52.\n    min_depth: Minimum depth of the expression trees on both sides of the\n        equals sign in the equation.\n    max_depth: Maximum depth of the expression trees on both sides of the\n        equals sign in the equation.\n    nbr_cases: The number of cases to generate.\n\n  Yields:\n    A dictionary {\"inputs\": input-list, \"targets\": target-list} where\n    input-list are the tokens encoding the variable to solve for and the math\n    equation, and target-list is a list of tokens encoding the resulting math\n    expression after solving for the variable.\n\n  Raises:\n    ValueError: If `max_depth` < `min_depth`.\n  \"\"\"\n\n  if max_depth < min_depth:\n    raise ValueError(\"max_depth must be greater than or equal to min_depth. \"\n                     \"Got max_depth=%s, min_depth=%s\" % (max_depth, min_depth))\n\n  alg_cfg = math_dataset_init(alphabet_size)\n  for _ in range(nbr_cases):\n    sample, target = generate_algebra_inverse_sample(\n        alg_cfg.vlist,\n        list(alg_cfg.ops.values()), alg_cfg.solve_ops, min_depth, max_depth)\n    yield {\n        \"inputs\": alg_cfg.int_encoder(sample),\n        \"targets\": alg_cfg.int_encoder(target)\n    }", "response": "Generate the algebra inverse dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef algebra_simplify(alphabet_size=26,\n                     min_depth=0,\n                     max_depth=2,\n                     nbr_cases=10000):\n  \"\"\"Generate the algebra simplify dataset.\n\n  Each sample is a symbolic math expression involving unknown variables. The\n  task is to simplify the expression. The target is the resulting expression.\n\n  Args:\n    alphabet_size: How many possible variables there are. Max 52.\n    min_depth: Minimum depth of the expression trees on both sides of the\n        equals sign in the equation.\n    max_depth: Maximum depth of the expression trees on both sides of the\n        equals sign in the equation.\n    nbr_cases: The number of cases to generate.\n\n  Yields:\n    A dictionary {\"inputs\": input-list, \"targets\": target-list} where\n    input-list are the tokens encoding the expression to simplify, and\n    target-list is a list of tokens encoding the resulting math expression after\n    simplifying.\n\n  Raises:\n    ValueError: If `max_depth` < `min_depth`.\n  \"\"\"\n  if max_depth < min_depth:\n    raise ValueError(\"max_depth must be greater than or equal to min_depth. \"\n                     \"Got max_depth=%s, min_depth=%s\" % (max_depth, min_depth))\n\n  alg_cfg = math_dataset_init(alphabet_size, digits=5)\n  for _ in range(nbr_cases):\n    sample, target = generate_algebra_simplify_sample(\n        alg_cfg.vlist, list(alg_cfg.ops.values()), min_depth, max_depth)\n    yield {\n        \"inputs\": alg_cfg.int_encoder(sample),\n        \"targets\": alg_cfg.int_encoder(target)\n    }", "response": "Generates the algebra simplify dataset."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating the calculus integrate dataset.", "response": "def calculus_integrate(alphabet_size=26,\n                       min_depth=0,\n                       max_depth=2,\n                       nbr_cases=10000):\n  \"\"\"Generate the calculus integrate dataset.\n\n  Each sample is a symbolic math expression involving unknown variables. The\n  task is to take the indefinite integral of the expression. The target is the\n  resulting expression.\n\n  Args:\n    alphabet_size: How many possible variables there are. Max 26.\n    min_depth: Minimum depth of the expression trees on both sides of the\n        equals sign in the equation.\n    max_depth: Maximum depth of the expression trees on both sides of the\n        equals sign in the equation.\n    nbr_cases: The number of cases to generate.\n\n  Yields:\n    A dictionary {\"inputs\": input-list, \"targets\": target-list} where\n    input-list are the tokens encoding the variable to integrate with respect\n    to and the expression to integrate, and target-list is a list of tokens\n    encoding the resulting math expression after integrating.\n\n  Raises:\n    ValueError: If `max_depth` < `min_depth`, or if alphabet_size > 26.\n  \"\"\"\n  if max_depth < min_depth:\n    raise ValueError(\"max_depth must be greater than or equal to min_depth. \"\n                     \"Got max_depth=%s, min_depth=%s\" % (max_depth, min_depth))\n\n  # Don't allow alphabet to use capital letters. Those are reserved for function\n  # names.\n  if alphabet_size > 26:\n    raise ValueError(\n        \"alphabet_size must not be greater than 26. Got %s.\" % alphabet_size)\n\n  functions = {\"log\": \"L\"}\n  alg_cfg = math_dataset_init(alphabet_size, digits=5, functions=functions)\n  nbr_case = 0\n  while nbr_case < nbr_cases:\n    try:\n      sample, target = generate_calculus_integrate_sample(\n          alg_cfg.vlist,\n          list(alg_cfg.ops.values()), min_depth, max_depth, alg_cfg.functions)\n      yield {\n          \"inputs\": alg_cfg.int_encoder(sample),\n          \"targets\": alg_cfg.int_encoder(target)\n      }\n    except:  # pylint:disable=bare-except\n      continue\n    if nbr_case % 10000 == 0:\n      print(\" calculus_integrate: generating case %d.\" % nbr_case)\n    nbr_case += 1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_in(self, expr):\n    if expr == self:\n      return True\n    is_in_left = is_in_expr(self.left, expr)\n    is_in_right = is_in_expr(self.right, expr)\n    return is_in_left or is_in_right", "response": "Returns True if expr is a subtree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef preprocess_example_common(example, mode, hparams):\n  if \"inputs\" in example and hparams.max_input_seq_length > 0:\n    example[\"inputs\"] = example[\"inputs\"][:hparams.max_input_seq_length]\n  if hparams.prepend_mode != \"none\":\n    if mode == tf.estimator.ModeKeys.PREDICT:\n      example[\"partial_targets\"] = tf.concat([example[\"inputs\"], [0]], 0)\n    else:\n      example[\"targets\"] = tf.concat(\n          [example[\"inputs\"], [0], example[\"targets\"]], 0)\n  if \"targets\" in example and hparams.max_target_seq_length > 0:\n    example[\"targets\"] = example[\"targets\"][:hparams.max_target_seq_length]\n  if hparams.split_to_length:\n    new_example = {}\n    for k, v in six.iteritems(example):\n      if k == \"targets\" or k == \"inputs\":\n        new_example[k] = tf.reshape(v, [-1, hparams.split_to_length, 1, 1])\n      else:\n        tf.logging.warning(\"Dropping feature %s\" % k)\n    return tf.data.Dataset.from_tensor_slices(new_example)\n  return example", "response": "Preprocessing steps common to all models."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _copy_problem_hparams(p_hparams):\n  p = p_hparams\n  # Duplicate input modality.\n  p.modality[\"targets\"] = p.modality[\"inputs\"]\n  # Duplicate input vocab size.\n  p.vocab_size[\"targets\"] = p.vocab_size[\"inputs\"]\n  # Duplicate input vocabulary.\n  p.vocabulary[\"targets\"] = p.vocabulary[\"inputs\"]\n  # Duplicate input space ids.\n  p.target_space_id = p.input_space_id\n  # Mark that p was reversed.\n  p.was_copy = True", "response": "Copy problem hparams to target modality vocab and space ids."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nswap input output modalities vocab and space ids.", "response": "def _reverse_problem_hparams(p_hparams):\n  \"\"\"Swap input/output modalities, vocab, and space ids.\"\"\"\n  p = p_hparams\n\n  # Swap modalities.\n  # TODO(trandustin): Note this assumes target modalities have feature name\n  # 'target', and each intended feature to swap has feature name 'input'.\n  # In the future, remove need for this behavior.\n  reversed_modality = {}\n  for feature_name in p.modality:\n    reversed_feature_name = feature_name.replace(\"target\", \"input\")\n    if \"target\" in feature_name and reversed_feature_name in p.modality:\n      reversed_modality[feature_name] = p.modality[reversed_feature_name]\n      reversed_modality[reversed_feature_name] = p.modality[feature_name]\n    else:\n      reversed_modality[feature_name] = p.modality[feature_name]\n\n  p.modality = reversed_modality\n\n  # Swap vocab sizes.\n  reversed_vocab_size = {}\n  for feature_name in p.vocab_size:\n    reversed_feature_name = feature_name.replace(\"target\", \"input\")\n    if \"target\" in feature_name and reversed_feature_name in p.vocab_size:\n      reversed_vocab_size[feature_name] = p.vocab_size[reversed_feature_name]\n      reversed_vocab_size[reversed_feature_name] = p.vocab_size[feature_name]\n    else:\n      reversed_vocab_size[feature_name] = p.vocab_size[feature_name]\n\n  p.vocab_size = reversed_vocab_size\n\n  # Swap vocabularies.\n  input_vocabulary = p.vocabulary.pop(\"inputs\", None)\n  target_vocabulary = p.vocabulary.pop(\"targets\", None)\n  if input_vocabulary is not None:\n    p.vocabulary[\"targets\"] = input_vocabulary\n  if target_vocabulary is not None:\n    p.vocabulary[\"inputs\"] = target_vocabulary\n\n  # Swap input/target space ids.\n  input_space_id = p.input_space_id\n  target_space_id = p.target_space_id\n  if input_space_id is not None:\n    p.target_space_id = input_space_id\n  else:\n    p.target_space_id = SpaceID.GENERIC\n  if target_space_id is not None:\n    p.input_space_id = target_space_id\n  else:\n    p.input_space_id = SpaceID.GENERIC\n\n  # Mark that p was reversed.\n  p.was_reversed = True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _default_hparams():\n  return hparam.HParams(\n      # Use this parameter to get comparable perplexity numbers with different\n      # tokenizations.  This value should be set to the ratio of the number of\n      # tokens in the test set according to the tokenization used to the number\n      # of tokens in the test set in the \"official\" tokenization.  For\n      # example, if we are using a word-piece based model and we want to\n      # compute per-word perplexity, then we set loss_multiplier to the number\n      # of wordpieces per word in the test set.\n      loss_multiplier=1.0,\n\n      # Use this parameter to allow for larger sequences in the batch. Without\n      # the use of this parameter, the size of the inner two dimensions will\n      # be used to judge the sequence length.\n      batch_size_multiplier=1,\n\n      # During inference for autoregressive problems, if the batch_size is 1,\n      # the inference will stop when the model predict a text_encoder.EOS_ID\n      # token.\n      stop_at_eos=False,\n\n      # Modalities used to map from features to a space compatible with\n      # chosen model architecture. It comprises key-value pairs of a feature\n      # name (str) and its modality type.\n      modality={},\n      vocab_size={},\n\n      # Identifiers used to tell the model which input/target space will be\n      # expected. For example, it can tell that we expect French as characters\n      # as output, or Spanish as sound. Spaces defined as constants in SpaceID\n      # class.\n      input_space_id=SpaceID.GENERIC,\n      target_space_id=SpaceID.GENERIC)", "response": "A set of basic model hyperparameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tpu_batch_size_per_shard(self, model_hparams):\n    if self.batch_size_means_tokens and not model_hparams.use_fixed_batch_size:\n      return model_hparams.batch_size // self.max_length(model_hparams)\n    else:\n      return model_hparams.batch_size", "response": "Batch size in examples per TPU core."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef preprocess(self, dataset, mode, hparams, interleave=True):\n    def _preprocess(example):\n      examples = self.preprocess_example(example, mode, hparams)\n      if not isinstance(examples, tf.data.Dataset):\n        examples = tf.data.Dataset.from_tensors(examples)\n      return examples\n\n    if interleave:\n      dataset = dataset.apply(\n          tf.data.experimental.parallel_interleave(\n              _preprocess, sloppy=True, cycle_length=8))\n    else:\n      dataset = dataset.flat_map(_preprocess)\n\n    return dataset", "response": "Runtime preprocessing on the whole dataset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the filepattern for data files for mode.", "response": "def filepattern(self, data_dir, mode, shard=None):\n    \"\"\"Get filepattern for data files for mode.\n\n    Matches mode to a suffix.\n    * DatasetSplit.TRAIN: train\n    * DatasetSplit.EVAL: dev\n    * DatasetSplit.TEST: test\n    * tf.estimator.ModeKeys.PREDICT: dev\n\n    Args:\n      data_dir: str, data directory.\n      mode: DatasetSplit\n      shard: int, if provided, will only read data from the specified shard.\n\n    Returns:\n      filepattern str\n    \"\"\"\n    path = os.path.join(data_dir, self.dataset_filename())\n    shard_str = \"-%05d\" % shard if shard is not None else \"\"\n    if mode == DatasetSplit.TRAIN:\n      suffix = \"train\"\n    elif mode in [DatasetSplit.EVAL, tf.estimator.ModeKeys.PREDICT]:\n      suffix = \"dev\"\n    else:\n      assert mode == DatasetSplit.TEST\n      suffix = \"test\"\n\n    return \"%s-%s%s*\" % (path, suffix, shard_str)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreversing features between inputs and targets if the problem is _rev.", "response": "def maybe_reverse_features(self, feature_map):\n    \"\"\"Reverse features between inputs and targets if the problem is '_rev'.\"\"\"\n    if not self._was_reversed:\n      return\n    inputs = feature_map.pop(\"inputs\", None)\n    targets = feature_map.pop(\"targets\", None)\n    inputs_seg = feature_map.pop(\"inputs_segmentation\", None)\n    targets_seg = feature_map.pop(\"targets_segmentation\", None)\n    inputs_pos = feature_map.pop(\"inputs_position\", None)\n    targets_pos = feature_map.pop(\"targets_position\", None)\n    if inputs is not None:\n      feature_map[\"targets\"] = inputs\n    if targets is not None:\n      feature_map[\"inputs\"] = targets\n    if inputs_seg is not None:\n      feature_map[\"targets_segmentation\"] = inputs_seg\n    if targets_seg is not None:\n      feature_map[\"inputs_segmentation\"] = targets_seg\n    if inputs_pos is not None:\n      feature_map[\"targets_position\"] = inputs_pos\n    if targets_pos is not None:\n      feature_map[\"inputs_position\"] = targets_pos"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dataset(self,\n              mode,\n              data_dir=None,\n              num_threads=None,\n              output_buffer_size=None,\n              shuffle_files=None,\n              hparams=None,\n              preprocess=True,\n              dataset_split=None,\n              shard=None,\n              partition_id=0,\n              num_partitions=1,\n              shuffle_buffer_size=1024,\n              max_records=-1):\n    \"\"\"Build a Dataset for this problem.\n\n    Args:\n      mode: tf.estimator.ModeKeys; determines which files to read from.\n      data_dir: directory that contains data files.\n      num_threads: int, number of threads to use for decode and preprocess\n        Dataset.map calls.\n      output_buffer_size: int, how many elements to prefetch at end of pipeline.\n      shuffle_files: whether to shuffle input files. Default behavior (i.e. when\n        shuffle_files=None) is to shuffle if mode == TRAIN.\n      hparams: HParams; hparams to be passed to\n        Problem.preprocess_example and Problem.hparams. If None, will use a\n        default set that is a no-op.\n      preprocess: bool, whether to map the Dataset through\n        Problem.preprocess_example.\n      dataset_split: DatasetSplit, which split to read data\n        from (TRAIN:\"-train\", EVAL:\"-dev\", \"test\":\"-test\"). Defaults to mode.\n      shard: int, if provided, will only read data from the specified shard.\n      partition_id: integer - which partition of the dataset to read from\n      num_partitions: how many partitions in the dataset\n      shuffle_buffer_size: if shuffle_files is True, this is the buffer size\n        used to shuffle records.\n      max_records: int, number of records to truncate to.\n\n    Returns:\n      Dataset containing dict<feature name, Tensor>.\n\n    Raises:\n      ValueError: if num_partitions is greater than the number of data files.\n    \"\"\"\n    is_training = mode == tf.estimator.ModeKeys.TRAIN\n    shuffle_files = shuffle_files or shuffle_files is None and is_training\n\n    dataset_split = dataset_split or mode\n    assert data_dir\n\n    if hparams is None:\n      hparams = default_model_hparams()\n\n    if not hasattr(hparams, \"data_dir\"):\n      hparams.add_hparam(\"data_dir\", data_dir)\n    if not hparams.data_dir:\n      hparams.data_dir = data_dir\n    # Construct the Problem's hparams so that items within it are accessible\n    _ = self.get_hparams(hparams)\n\n    data_filepattern = self.filepattern(data_dir, dataset_split, shard=shard)\n    tf.logging.info(\"Reading data files from %s\", data_filepattern)\n    data_files = sorted(tf.contrib.slim.parallel_reader.get_data_files(\n        data_filepattern))\n\n    # Functions used in dataset transforms below. `filenames` can be either a\n    # `tf.string` tensor or `tf.data.Dataset` containing one or more filenames.\n    def _load_records_and_preprocess(filenames):\n      \"\"\"Reads files from a string tensor or a dataset of filenames.\"\"\"\n      # Load records from file(s) with an 8MiB read buffer.\n      dataset = tf.data.TFRecordDataset(filenames, buffer_size=8 * 1024 * 1024)\n      # Decode.\n      dataset = dataset.map(self.decode_example, num_parallel_calls=num_threads)\n      # Preprocess if requested.\n      # Note that preprocessing should happen per-file as order may matter.\n      if preprocess:\n        dataset = self.preprocess(dataset, mode, hparams,\n                                  interleave=shuffle_files)\n      return dataset\n\n    if len(data_files) < num_partitions:\n      raise ValueError(\n          \"number of data files (%d) must be at least the number of hosts (%d)\"\n          % (len(data_files), num_partitions))\n    data_files = [f for (i, f) in enumerate(data_files)\n                  if i % num_partitions == partition_id]\n    tf.logging.info(\n        \"partition: %d num_data_files: %d\" % (partition_id, len(data_files)))\n    if shuffle_files:\n      mlperf_log.transformer_print(key=mlperf_log.INPUT_ORDER)\n      random.shuffle(data_files)\n\n    dataset = tf.data.Dataset.from_tensor_slices(tf.constant(data_files))\n    # Create data-set from files by parsing, pre-processing and interleaving.\n    if shuffle_files:\n      dataset = dataset.apply(\n          tf.data.experimental.parallel_interleave(\n              _load_records_and_preprocess, sloppy=True, cycle_length=8))\n    else:\n      dataset = _load_records_and_preprocess(dataset)\n\n    dataset = dataset.map(\n        self.maybe_reverse_and_copy, num_parallel_calls=num_threads)\n    dataset = dataset.take(max_records)\n\n    ## Shuffle records only for training examples.\n    if shuffle_files and is_training:\n      dataset = dataset.shuffle(shuffle_buffer_size)\n    if hparams.get(\"pack_dataset\", False):\n      dataset = generator_utils.pack_dataset(\n          dataset, hparams.max_length, keys=[\"inputs\", \"targets\"],\n          use_custom_ops=hparams.get(\"use_custom_ops\", False))\n    if output_buffer_size:\n      dataset = dataset.prefetch(output_buffer_size)\n\n    return dataset", "response": "Build a Dataset for this problem."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decode_example(self, serialized_example):\n    data_fields, data_items_to_decoders = self.example_reading_spec()\n    # Necessary to rejoin examples in the correct order with the Cloud ML Engine\n    # batch prediction API.\n    data_fields[\"batch_prediction_key\"] = tf.FixedLenFeature([1], tf.int64, 0)\n    if data_items_to_decoders is None:\n      data_items_to_decoders = {\n          field: tf.contrib.slim.tfexample_decoder.Tensor(field)\n          for field in data_fields\n      }\n\n    decoder = tf.contrib.slim.tfexample_decoder.TFExampleDecoder(\n        data_fields, data_items_to_decoders)\n\n    decode_items = list(sorted(data_items_to_decoders))\n    decoded = decoder.decode(serialized_example, items=decode_items)\n    return dict(zip(decode_items, decoded))", "response": "Return a dict of Tensors from a serialized tensorflow. Example."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving dict<feature name FeatureInfo >.", "response": "def feature_info(self):\n    \"\"\"Retrieve dict<feature name, FeatureInfo>.\n\n    Must first call Problem.get_hparams or Problem.dataset to have the problem's\n    internal hparams already constructed.\n\n    Returns:\n      dict<feature name, FeatureInfo>\n    \"\"\"\n    if self._feature_info is not None:\n      return self._feature_info\n\n    assert self._hparams is not None\n\n    hp = self.get_hparams()\n    if self.has_inputs:\n      in_id = hp.input_space_id\n    out_id = hp.target_space_id\n\n    features = collections.defaultdict(FeatureInfo)\n    for feature_name, modality_cls in six.iteritems(hp.modality):\n      finfo = features[feature_name]\n      finfo.modality = modality_cls\n      finfo.vocab_size = hp.vocab_size[feature_name]\n\n    vocabs = hp.vocabulary\n    for name, encoder in six.iteritems(vocabs):\n      features[name].encoder = encoder\n\n    if self.has_inputs:\n      features[\"inputs\"].space_id = in_id\n    features[\"targets\"].space_id = out_id\n\n    self._feature_info = features\n    return features"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_estimator_input_fn(self,\n                              mode,\n                              hparams,\n                              data_dir=None,\n                              force_repeat=False,\n                              prevent_repeat=False,\n                              dataset_kwargs=None):\n    \"\"\"Return input_fn wrapped for Estimator.\"\"\"\n\n    def estimator_input_fn(params, config):\n      return self.input_fn(\n          mode,\n          hparams,\n          data_dir=data_dir,\n          params=params,\n          config=config,\n          force_repeat=force_repeat,\n          prevent_repeat=prevent_repeat,\n          dataset_kwargs=dataset_kwargs)\n\n    return estimator_input_fn", "response": "Returns input_fn wrapped for Estimator."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _dataset_partition(self, mode, config, params):\n    if mode != tf.estimator.ModeKeys.TRAIN or not hasattr(config, \"tpu_config\"):\n      # Reset in the case when using TPU but alternating TRAIN and EVAL.\n      self._next_partition_id = 0\n      return 0, 1\n    phift = config.tpu_config.per_host_input_for_training\n    # This is the mesh-tensorflow case.\n    if (hasattr(tpu_config.InputPipelineConfig, \"BROADCAST\") and\n        phift == tpu_config.InputPipelineConfig.BROADCAST):\n      return 0, 1\n    if phift:\n      num_hosts = (params[\"context\"].num_hosts if \"context\" in params\n                   else config.tpu_config.num_shards // 8)\n      num_partitions = max(num_hosts, 1)\n    else:\n      num_partitions = config.tpu_config.num_shards\n    partition_id = getattr(self, \"_next_partition_id\", 0)\n    self._next_partition_id = partition_id + 1\n    tf.logging.info(\"num_partitions = %d partition_id = %d\" %\n                    (num_partitions, partition_id))\n    assert partition_id < num_partitions\n    return partition_id, num_partitions", "response": "This function returns the partition_id and number of partitions that can be used to read training data from the training data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds input pipeline for problem.", "response": "def input_fn(self,\n               mode,\n               hparams,\n               data_dir=None,\n               params=None,\n               config=None,\n               force_repeat=False,\n               prevent_repeat=False,\n               dataset_kwargs=None):\n    \"\"\"Builds input pipeline for problem.\n\n    Args:\n      mode: tf.estimator.ModeKeys\n      hparams: HParams, model hparams\n      data_dir: str, data directory; if None, will use hparams.data_dir\n      params: dict, may include \"batch_size\"\n      config: RunConfig; should have the data_parallelism attribute if not using\n        TPU\n      force_repeat: bool, whether to repeat the data even if not training\n      prevent_repeat: bool, whether to not repeat when in training mode.\n        Overrides force_repeat.\n      dataset_kwargs: dict, if passed, will pass as kwargs to self.dataset\n        method when called\n\n    Returns:\n      (features_dict<str name, Tensor feature>, Tensor targets)\n    \"\"\"\n    partition_id, num_partitions = self._dataset_partition(mode, config, params)\n    is_training = mode == tf.estimator.ModeKeys.TRAIN\n    if config and config.use_tpu:\n      num_threads = 64\n    else:\n      num_threads = data_reader.cpu_count() if is_training else 1\n    data_dir = data_dir or (hasattr(hparams, \"data_dir\") and hparams.data_dir)\n    dataset_kwargs = dataset_kwargs or {}\n    dataset_kwargs.update({\n        \"mode\": mode,\n        \"data_dir\": data_dir,\n        \"num_threads\": num_threads,\n        \"hparams\": hparams,\n        \"partition_id\": partition_id,\n        \"num_partitions\": num_partitions,\n    })\n    return data_reader.input_fn(\n        self.dataset(**dataset_kwargs),\n        self.filepattern(data_dir, mode),\n        self.skip_random_fraction_when_training,\n        self.batch_size_means_tokens,\n        self.get_hparams().batch_size_multiplier,\n        self.max_length(hparams),\n        mode,\n        hparams,\n        data_dir=data_dir,\n        params=params,\n        config=config,\n        force_repeat=force_repeat,\n        prevent_repeat=prevent_repeat)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef serving_input_fn(self, hparams, decode_hparams=None, use_tpu=False):\n    mode = tf.estimator.ModeKeys.PREDICT\n    serialized_example = tf.placeholder(\n        dtype=tf.string, shape=[None], name=\"serialized_example\")\n    dataset = tf.data.Dataset.from_tensor_slices(serialized_example)\n    dataset = dataset.map(self.decode_example)\n    dataset = dataset.map(lambda ex: self.preprocess_example(ex, mode, hparams))\n    dataset = dataset.map(data_reader.cast_ints_to_int32)\n\n    if use_tpu:\n      padded_shapes = data_reader.pad_for_tpu(dataset.output_shapes, hparams,\n                                              hparams.max_length)\n      batch_size = 1 if not decode_hparams else getattr(decode_hparams,\n                                                        \"batch_size\", 1)\n      dataset = dataset.padded_batch(\n          batch_size, padded_shapes, drop_remainder=False)\n      dataset = dataset.map(\n          functools.partial(data_reader.pad_batch, batch_multiple=batch_size))\n    else:\n      dataset = dataset.padded_batch(\n          tf.shape(serialized_example, out_type=tf.int64)[0],\n          dataset.output_shapes)\n\n    dataset = dataset.map(data_reader.standardize_shapes)\n    features = tf.data.experimental.get_single_element(dataset)\n\n    if self.has_inputs:\n      features.pop(\"targets\", None)\n\n    return tf.estimator.export.ServingInputReceiver(\n        features=features, receiver_tensors=serialized_example)", "response": "Input fn for serving export starting from serialized example."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets hyper - parameters file path.", "response": "def _get_hparams_path():\n  \"\"\"Get hyper-parameters file path.\"\"\"\n  hparams_path = None\n  if FLAGS.output_dir:\n    hparams_path = os.path.join(FLAGS.output_dir, \"hparams.json\")\n  else:\n    tf.logging.warning(\n        \"--output_dir not specified. Hyper-parameters will be infered from\"\n        \"--hparams_set and --hparams only. These may not match training time\"\n        \"hyper-parameters.\")\n  return hparams_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexports given checkpoint as tfhub module with given spec.", "response": "def export_module_spec_with_checkpoint(module_spec,\n                                       checkpoint_path,\n                                       export_path,\n                                       scope_prefix=\"\"):\n  \"\"\"Exports given checkpoint as tfhub module with given spec.\"\"\"\n\n  # The main requirement is that it is possible to know how to map from\n  # module variable name to checkpoint variable name.\n  # This is trivial if the original code used variable scopes,\n  # but can be messy if the variables to export are interwined\n  # with variables not export.\n  with tf.Graph().as_default():\n    m = hub.Module(module_spec)\n    assign_map = {\n        scope_prefix + name: value for name, value in m.variable_map.items()\n    }\n    tf.train.init_from_checkpoint(checkpoint_path, assign_map)\n    init_op = tf.initializers.global_variables()\n    with tf.Session() as session:\n      session.run(init_op)\n      m.export(export_path, session)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef export_as_tfhub_module(model_name,\n                           hparams,\n                           decode_hparams,\n                           problem,\n                           checkpoint_path,\n                           export_dir):\n  \"\"\"Exports the last checkpoint from the directory as tfhub module.\n\n  It creates the Module spec and signature (based on T2T problem information),\n  which is later used to create and export the hub module.\n  Module will be saved inside the ckpt_dir.\n\n  Args:\n    model_name: name of the model to be exported.\n    hparams: T2T parameters, model graph will be based on them.\n    decode_hparams: T2T parameters for decoding.\n    problem: the name of the problem\n    checkpoint_path: path to the checkpoint to be exported.\n    export_dir: Directory to write the exported model to.\n  \"\"\"\n\n  def hub_module_fn():\n    \"\"\"Creates the TF graph for the hub module.\"\"\"\n    model_fn = t2t_model.T2TModel.make_estimator_model_fn(\n        model_name,\n        hparams,\n        decode_hparams=decode_hparams,\n        use_tpu=FLAGS.use_tpu)\n    features = problem.serving_input_fn(\n        hparams, decode_hparams, use_tpu=FLAGS.use_tpu).features\n\n    # we must do a copy of the features, as the model_fn can add additional\n    # entries there (like hyperparameter settings etc).\n    original_features = features.copy()\n    spec = model_fn(features, labels=None, mode=tf.estimator.ModeKeys.PREDICT)\n\n    hub.add_signature(\n        inputs=original_features,\n        outputs=spec.export_outputs[\"serving_default\"].outputs)\n\n  # TFHub doesn't support the following collections.\n  drop_collections = [tf.GraphKeys.LOSSES,\n                      tf.GraphKeys.SUMMARIES, tf.GraphKeys.LOCAL_VARIABLES]\n  module_spec = hub.create_module_spec(\n      hub_module_fn, drop_collections=drop_collections)\n  # Loads the weights from the checkpoint using the model above\n  # and saves it in the export_path.\n  export_module_spec_with_checkpoint(\n      module_spec,\n      checkpoint_path=checkpoint_path,\n      export_path=export_dir,\n      scope_prefix=\"\")", "response": "Exports the last checkpoint from the directory as tfhub module."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_model(hparams_set, model_name, data_dir, problem_name, beam_size=1):\n  hparams = trainer_lib.create_hparams(\n      hparams_set, data_dir=data_dir, problem_name=problem_name)\n  translate_model = registry.model(model_name)(\n      hparams, tf.estimator.ModeKeys.EVAL)\n\n  inputs = tf.placeholder(tf.int32, shape=(1, None, 1, 1), name=\"inputs\")\n  targets = tf.placeholder(tf.int32, shape=(1, None, 1, 1), name=\"targets\")\n  translate_model({\n      \"inputs\": inputs,\n      \"targets\": targets,\n  })\n\n  # Must be called after building the training graph, so that the dict will\n  # have been filled with the attention tensors. BUT before creating the\n  # inference graph otherwise the dict will be filled with tensors from\n  # inside a tf.while_loop from decoding and are marked unfetchable.\n  att_mats = get_att_mats(translate_model)\n\n  with tf.variable_scope(tf.get_variable_scope(), reuse=True):\n    samples = translate_model.infer({\n        \"inputs\": inputs,\n    }, beam_size=beam_size)[\"outputs\"]\n\n  return inputs, targets, samples, att_mats", "response": "Builds the training graph required to fetch the attention weights."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget s the tensors representing the attentions from a build model.", "response": "def get_att_mats(translate_model):\n  \"\"\"Get's the tensors representing the attentions from a build model.\n\n  The attentions are stored in a dict on the Transformer object while building\n  the graph.\n\n  Args:\n    translate_model: Transformer object to fetch the attention weights from.\n\n  Returns:\n  Tuple of attention matrices; (\n      enc_atts: Encoder self attention weights.\n        A list of `num_layers` numpy arrays of size\n        (batch_size, num_heads, inp_len, inp_len)\n      dec_atts: Decoder self attetnion weights.\n        A list of `num_layers` numpy arrays of size\n        (batch_size, num_heads, out_len, out_len)\n      encdec_atts: Encoder-Decoder attention weights.\n        A list of `num_layers` numpy arrays of size\n        (batch_size, num_heads, out_len, inp_len)\n  )\n  \"\"\"\n  enc_atts = []\n  dec_atts = []\n  encdec_atts = []\n\n  prefix = \"transformer/body/\"\n  postfix_self_attention = \"/multihead_attention/dot_product_attention\"\n  if translate_model.hparams.self_attention_type == \"dot_product_relative\":\n    postfix_self_attention = (\"/multihead_attention/\"\n                              \"dot_product_attention_relative\")\n  postfix_encdec = \"/multihead_attention/dot_product_attention\"\n\n  for i in range(translate_model.hparams.num_hidden_layers):\n    enc_att = translate_model.attention_weights[\n        \"%sencoder/layer_%i/self_attention%s\"\n        % (prefix, i, postfix_self_attention)]\n    dec_att = translate_model.attention_weights[\n        \"%sdecoder/layer_%i/self_attention%s\"\n        % (prefix, i, postfix_self_attention)]\n    encdec_att = translate_model.attention_weights[\n        \"%sdecoder/layer_%i/encdec_attention%s\" % (prefix, i, postfix_encdec)]\n    enc_atts.append(enc_att)\n    dec_atts.append(dec_att)\n    encdec_atts.append(encdec_att)\n\n  return enc_atts, dec_atts, encdec_atts"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef encode(self, input_str):\n    inputs = self.encoders[\"inputs\"].encode(input_str) + [EOS_ID]\n    batch_inputs = np.reshape(inputs, [1, -1, 1, 1])  # Make it 3D.\n    return batch_inputs", "response": "Input str to features dict ready for inference."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndecoding a list of ints to str.", "response": "def decode(self, integers):\n    \"\"\"List of ints to str.\"\"\"\n    integers = list(np.squeeze(integers))\n    return self.encoders[\"inputs\"].decode(integers)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists of ints to list of str.", "response": "def decode_list(self, integers):\n    \"\"\"List of ints to list of str.\"\"\"\n    integers = list(np.squeeze(integers))\n    return self.encoders[\"inputs\"].decode_list(integers)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_vis_data_from_string(self, sess, input_string):\n    encoded_inputs = self.encode(input_string)\n\n    # Run inference graph to get the translation.\n    out = sess.run(self.samples, {\n        self.inputs: encoded_inputs,\n    })\n\n    # Run the decoded translation through the training graph to get the\n    # attention tensors.\n    att_mats = sess.run(self.att_mats, {\n        self.inputs: encoded_inputs,\n        self.targets: np.reshape(out, [1, -1, 1, 1]),\n    })\n\n    output_string = self.decode(out)\n    input_list = self.decode_list(encoded_inputs)\n    output_list = self.decode_list(out)\n\n    return output_string, input_list, output_list, att_mats", "response": "Constructs the data needed for visualizing attentions."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nshifts and pads with zero along an axis.", "response": "def shift_and_pad(tensor, shift, axis=0):\n  \"\"\"Shifts and pads with zero along an axis.\n\n  Example:\n    shift_and_pad([1, 2, 3, 4], 2)  --> [0, 0, 1, 2]\n    shift_and_pad([1, 2, 3, 4], -2) --> [3, 4, 0, 0]\n\n  Args:\n    tensor: Tensor; to be shifted and padded.\n    shift: int; number of positions to shift by.\n    axis: int; along which axis to shift and pad.\n\n  Returns:\n    A Tensor with the same shape as the input tensor.\n  \"\"\"\n  shape = tensor.shape\n  rank = len(shape)\n  assert 0 <= abs(axis) < rank\n\n  length = int(shape[axis])\n  assert 0 <= abs(shift) < length\n\n  paddings = [(0, 0)] * rank\n  begin = [0] * rank\n  size = [-1] * rank\n\n  if shift > 0:\n    paddings[axis] = (shift, 0)\n    size[axis] = length - shift\n  elif shift < 0:\n    paddings[axis] = (0, -shift)\n    begin[axis] = -shift\n\n  ret = tf.pad(tf.slice(tensor, begin, size), paddings)\n\n  return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets of hyperparameters for transformer.", "response": "def transformer_aux_base():\n  \"\"\"Set of hyperparameters.\"\"\"\n  hparams = transformer.transformer_base()\n  hparams.shared_embedding_and_softmax_weights = False\n  hparams.add_hparam(\"shift_values\", \"1,2,3,4\")\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset of hyperparameters for transformer on tiny model.", "response": "def transformer_aux_tiny():\n  \"\"\"Set of hyperparameters.\"\"\"\n  hparams = transformer.transformer_tiny()\n  hparams.shared_embedding_and_softmax_weights = False\n  hparams.add_hparam(\"shift_values\", \"1,2\")\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pixels_from_softmax(frame_logits, pure_sampling=False,\n                        temperature=1.0, gumbel_noise_factor=0.2):\n  \"\"\"Given frame_logits from a per-pixel softmax, generate colors.\"\"\"\n  # If we're purely sampling, just sample each pixel.\n  if pure_sampling or temperature == 0.0:\n    return common_layers.sample_with_temperature(frame_logits, temperature)\n\n  # Gumbel-sample from the pixel sofmax and average by pixel values.\n  pixel_range = tf.to_float(tf.range(256))\n  for _ in range(len(frame_logits.get_shape().as_list()) - 1):\n    pixel_range = tf.expand_dims(pixel_range, axis=0)\n\n  frame_logits = tf.nn.log_softmax(frame_logits)\n  gumbel_samples = discretization.gumbel_sample(\n      common_layers.shape_list(frame_logits)) * gumbel_noise_factor\n\n  frame = tf.nn.softmax((frame_logits + gumbel_samples) / temperature, axis=-1)\n  result = tf.reduce_sum(frame * pixel_range, axis=-1)\n  # Round on the forward pass, not on the backward one.\n  return result + tf.stop_gradient(tf.round(result) - result)", "response": "Given frame_logits from a per - pixel softmax generate colors."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef next_frame_base():\n  hparams = common_hparams.basic_params1()\n  # Loss cutoff.\n  hparams.add_hparam(\"video_modality_loss_cutoff\", 0.01)\n  # Additional resizing the frames before feeding them to model.\n  hparams.add_hparam(\"preprocess_resize_frames\", None)\n  # How many data points to suffle. Ideally should be part of problem not model!\n  hparams.add_hparam(\"shuffle_buffer_size\", 128)\n  # Tiny mode. For faster tests.\n  hparams.add_hparam(\"tiny_mode\", False)\n  # In case a model supports smaller/faster version.\n  hparams.add_hparam(\"small_mode\", False)\n  # In case a model has stochastic version.\n  hparams.add_hparam(\"stochastic_model\", False)\n  # Internal loss for recurrent models.\n  hparams.add_hparam(\"internal_loss\", True)\n  # choose from: concat, multiplicative, multi_additive\n  hparams.add_hparam(\"action_injection\", \"multi_additive\")\n  # Scheduled sampling method. Choose between\n  # ground_truth_only, prediction_only, prob, count, prob_inverse_exp.\n  hparams.add_hparam(\"scheduled_sampling_mode\", \"prediction_only\")\n  hparams.add_hparam(\"scheduled_sampling_decay_steps\", 10000)\n  hparams.add_hparam(\"scheduled_sampling_max_prob\", 1.0)\n  hparams.add_hparam(\"scheduled_sampling_k\", 900.0)\n  return hparams", "response": "Common HParams for next_frame models."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove TimeLimit Wrapper from top level if exists raises error if any other TimeLimit Wrapper is present in stack.", "response": "def remove_time_limit_wrapper(env):\n  \"\"\"Removes top level TimeLimit Wrapper.\n\n  Removes TimeLimit Wrapper from top level if exists, throws error if any other\n  TimeLimit Wrapper is present in stack.\n\n  Args:\n    env: environment\n\n  Returns:\n    the env with removed time limit wrapper.\n  \"\"\"\n  if isinstance(env, gym.wrappers.TimeLimit):\n    env = env.env\n  env_ = env\n  while isinstance(env_, gym.Wrapper):\n    if isinstance(env_, gym.wrappers.TimeLimit):\n      raise ValueError(\"Can remove only top-level TimeLimit gym.Wrapper.\")\n    env_ = env_.env\n  return env"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gym_env_wrapper(env, rl_env_max_episode_steps, maxskip_env, rendered_env,\n                    rendered_env_resize_to, sticky_actions):\n  \"\"\"Wraps a gym environment. see make_gym_env for details.\"\"\"\n  # rl_env_max_episode_steps is None or int.\n  assert ((not rl_env_max_episode_steps) or\n          isinstance(rl_env_max_episode_steps, int))\n\n  wrap_with_time_limit = ((not rl_env_max_episode_steps) or\n                          rl_env_max_episode_steps >= 0)\n\n  if wrap_with_time_limit:\n    env = remove_time_limit_wrapper(env)\n\n  if sticky_actions:\n    env = StickyActionEnv(env)\n\n  if maxskip_env:\n    env = MaxAndSkipEnv(env)  # pylint: disable=redefined-variable-type\n\n  if rendered_env:\n    env = RenderedEnv(env, resize_to=rendered_env_resize_to)\n\n  if wrap_with_time_limit:\n    env = gym.wrappers.TimeLimit(\n        env, max_episode_steps=rl_env_max_episode_steps)\n  return env", "response": "A wrapper for a gym environment."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a gym env optionally with a timelimit and maxskip wrapper.", "response": "def make_gym_env(name,\n                 rl_env_max_episode_steps=-1,\n                 maxskip_env=False,\n                 rendered_env=False,\n                 rendered_env_resize_to=None,\n                 sticky_actions=False):\n  \"\"\"Create a gym env optionally with a time limit and maxskip wrapper.\n\n  NOTE: The returned env may already be wrapped with TimeLimit!\n\n  Args:\n    name: `str` - base name of the gym env to make.\n    rl_env_max_episode_steps: `int` or None - Using any value < 0 returns the\n      env as-in, otherwise we impose the requested timelimit. Setting this to\n      None returns a wrapped env that doesn't have a step limit.\n    maxskip_env: whether to also use MaxAndSkip wrapper before time limit.\n    rendered_env: whether to force render for observations. Use this for\n      environments that are not natively rendering the scene for observations.\n    rendered_env_resize_to: a list of [height, width] to change the original\n      resolution of the native environment render.\n    sticky_actions: whether to use sticky_actions before MaxAndSkip wrapper.\n\n  Returns:\n    An instance of `gym.Env` or `gym.Wrapper`.\n  \"\"\"\n  env = gym.make(name)\n  return gym_env_wrapper(env, rl_env_max_episode_steps, maxskip_env,\n                         rendered_env, rendered_env_resize_to, sticky_actions)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering the class in Gym and returns the registered name and the env.", "response": "def register_gym_env(class_entry_point, version=\"v0\", kwargs=None):\n  \"\"\"Registers the class in Gym and returns the registered name and the env.\"\"\"\n\n  split_on_colon = class_entry_point.split(\":\")\n  assert len(split_on_colon) == 2\n\n  class_name = split_on_colon[1]\n  # We have to add the version to conform to gym's API.\n  env_name = \"T2TEnv-{}-{}\".format(class_name, version)\n  gym.envs.register(id=env_name, entry_point=class_entry_point, kwargs=kwargs)\n\n  tf.logging.info(\"Entry Point [%s] registered with id [%s]\", class_entry_point,\n                  env_name)\n\n  return env_name, gym.make(env_name)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef step(self, action):\n    total_reward = 0.0\n    done = None\n    for i in range(self._skip):\n      obs, reward, done, info = self.env.step(action)\n      if i == self._skip - 2:\n        self._obs_buffer[0] = obs\n      if i == self._skip - 1:\n        self._obs_buffer[1] = obs\n      total_reward += reward\n      if done:\n        break\n    # Note that the observation on the done=True frame doesn't matter.\n    max_frame = self._obs_buffer.max(axis=0)\n    return max_frame, total_reward, done, info", "response": "Repeat action sum reward and max over last observations."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _handle_errors(errors):\n  if not errors:\n    return\n  log_all = True  # pylint: disable=unused-variable\n  err_msg = \"T2T: skipped importing {num_missing} data_generators modules.\"\n  print(err_msg.format(num_missing=len(errors)))\n  for module, err in errors:\n    err_str = str(err)\n    if not _is_import_err_msg(err_str, module):\n      print(\"From module %s\" % module)\n      raise err\n    if log_all:\n      print(\"Did not import module: %s; Cause: %s\" % (module, err_str))", "response": "Log out and possibly reraise errors during import."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate HParams with data_dir and problem hparams.", "response": "def create_hparams(hparams_set,\n                   hparams_overrides_str=\"\",\n                   data_dir=None,\n                   problem_name=None,\n                   hparams_path=None):\n  \"\"\"Create HParams with data_dir and problem hparams, if kwargs provided.\"\"\"\n  hparams = registry.hparams(hparams_set)\n  if hparams_path and tf.gfile.Exists(hparams_path):\n    hparams = create_hparams_from_json(hparams_path, hparams)\n  if data_dir:\n    hparams.add_hparam(\"data_dir\", data_dir)\n  if hparams_overrides_str:\n    tf.logging.info(\"Overriding hparams in %s with %s\", hparams_set,\n                    hparams_overrides_str)\n    hparams = hparams.parse(hparams_overrides_str)\n  if problem_name:\n    add_problem_hparams(hparams, problem_name)\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_hparams_from_json(json_path, hparams=None):\n  tf.logging.info(\"Loading hparams from existing json %s\" % json_path)\n  with tf.gfile.Open(json_path, \"r\") as f:\n    hparams_values = json.load(f)\n    # Prevent certain keys from overwriting the passed-in hparams.\n    # TODO(trandustin): Remove this hack after registries are available to avoid\n    # saving them as functions.\n    hparams_values.pop(\"bottom\", None)\n    hparams_values.pop(\"loss\", None)\n    hparams_values.pop(\"name\", None)\n    hparams_values.pop(\"top\", None)\n    hparams_values.pop(\"weights_fn\", None)\n    new_hparams = hparam.HParams(**hparams_values)\n    # Some keys are in new_hparams but not hparams, so we need to be more\n    #   careful than simply using parse_json() from HParams\n    if hparams:  # hparams specified, so update values from json\n      for key in sorted(new_hparams.values().keys()):\n        if hasattr(hparams, key):  # Overlapped keys\n          value = getattr(hparams, key)\n          new_value = getattr(new_hparams, key)\n          if value != new_value:  # Different values\n            tf.logging.info(\"Overwrite key %s: %s -> %s\" % (\n                key, value, new_value))\n            setattr(hparams, key, new_value)\n    else:\n      hparams = new_hparams\n\n  return hparams", "response": "Load hparams from json file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd problem hparams for the problems.", "response": "def add_problem_hparams(hparams, problem_name_or_instance):\n  \"\"\"Add problem hparams for the problems.\"\"\"\n  if isinstance(problem_name_or_instance, problem_lib.Problem):\n    problem = problem_name_or_instance\n  else:\n    problem = registry.problem(problem_name_or_instance)\n  p_hparams = problem.get_hparams(hparams)\n  hparams.problem = problem\n  hparams.problem_hparams = p_hparams"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads examples from the tsv file.", "response": "def load_examples(tmp_dir, prop_train=0.09, prop_val=0.01):\n  \"\"\"Loads exampls from the tsv file.\n\n  Args:\n    tmp_dir: temp directory.\n    prop_train: proportion of the train data\n    prop_val: proportion of the validation data\n\n  Returns:\n    All examples in the dataset pluse train, test, and development splits.\n\n  \"\"\"\n\n  infile = generator_utils.maybe_download(tmp_dir, _TAR, _URL)\n  tf.logging.info('Loading examples')\n\n  all_examples = []\n  for i, d in enumerate(csv.DictReader(gzip.open(infile), delimiter='\\t')):\n    if i % 100000 == 0:\n      tf.logging.info('%d examples have been loaded....' % i)\n    ex = {x: int(y) if y.isdigit() else y for x, y in d.items()}\n    all_examples.append(ex)\n\n  random.seed(1)\n  random.shuffle(all_examples)\n  n_train = int(len(all_examples) * prop_train)\n  n_val = n_train + int(len(all_examples) * prop_val)\n  train = all_examples[:n_train]\n  val = all_examples[n_train:n_val]\n  test = []\n  for e in all_examples[n_val:]:\n    if e['n_intervening'] == e['n_diff_intervening']:\n      test.append(e)\n\n  return all_examples, train, val, test"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads and extract CIFAR to directory unless it is there.", "response": "def _get_cifar(directory, url):\n  \"\"\"Download and extract CIFAR to directory unless it is there.\"\"\"\n  filename = os.path.basename(url)\n  path = generator_utils.maybe_download(directory, filename, url)\n  tarfile.open(path, \"r:gz\").extractall(directory)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nimage generator for CIFAR - 10 and 100.", "response": "def cifar_generator(cifar_version, tmp_dir, training, how_many, start_from=0):\n  \"\"\"Image generator for CIFAR-10 and 100.\n\n  Args:\n    cifar_version: string; one of \"cifar10\" or \"cifar100\"\n    tmp_dir: path to temporary storage directory.\n    training: a Boolean; if true, we use the train set, otherwise the test set.\n    how_many: how many images and labels to generate.\n    start_from: from which image to start.\n\n  Returns:\n    An instance of image_generator that produces CIFAR-10 images and labels.\n  \"\"\"\n  if cifar_version == \"cifar10\":\n    url = _CIFAR10_URL\n    train_files = _CIFAR10_TRAIN_FILES\n    test_files = _CIFAR10_TEST_FILES\n    prefix = _CIFAR10_PREFIX\n    image_size = _CIFAR10_IMAGE_SIZE\n    label_key = \"labels\"\n  elif cifar_version == \"cifar100\" or cifar_version == \"cifar20\":\n    url = _CIFAR100_URL\n    train_files = _CIFAR100_TRAIN_FILES\n    test_files = _CIFAR100_TEST_FILES\n    prefix = _CIFAR100_PREFIX\n    image_size = _CIFAR100_IMAGE_SIZE\n    if cifar_version == \"cifar100\":\n      label_key = \"fine_labels\"\n    else:\n      label_key = \"coarse_labels\"\n\n  _get_cifar(tmp_dir, url)\n  data_files = train_files if training else test_files\n  all_images, all_labels = [], []\n  for filename in data_files:\n    path = os.path.join(tmp_dir, prefix, filename)\n    with tf.gfile.Open(path, \"rb\") as f:\n      if six.PY2:\n        data = cPickle.load(f)\n      else:\n        data = cPickle.load(f, encoding=\"latin1\")\n    images = data[\"data\"]\n    num_images = images.shape[0]\n    images = images.reshape((num_images, 3, image_size, image_size))\n    all_images.extend([\n        np.squeeze(images[j]).transpose((1, 2, 0)) for j in range(num_images)\n    ])\n    labels = data[label_key]\n    all_labels.extend([labels[j] for j in range(num_images)])\n  return image_utils.image_generator(\n      all_images[start_from:start_from + how_many],\n      all_labels[start_from:start_from + how_many])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rlmb_ppo_quick():\n  hparams = rlmb_ppo_base()\n  hparams.epochs = 2\n  hparams.model_train_steps = 25000\n  hparams.ppo_epochs_num = 700\n  hparams.ppo_epoch_length = 50\n  return hparams", "response": "Base setting but quicker with only 2 epochs."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbases setting with a stochastic next - frame model.", "response": "def rlmb_base_stochastic():\n  \"\"\"Base setting with a stochastic next-frame model.\"\"\"\n  hparams = rlmb_base()\n  hparams.initial_epoch_train_steps_multiplier = 5\n  hparams.generative_model = \"next_frame_basic_stochastic\"\n  hparams.generative_model_params = \"next_frame_basic_stochastic\"\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbasing setting with stochastic discrete model.", "response": "def rlmb_base_stochastic_discrete():\n  \"\"\"Base setting with stochastic discrete model.\"\"\"\n  hparams = rlmb_base()\n  hparams.learning_rate_bump = 1.0\n  hparams.grayscale = False\n  hparams.generative_model = \"next_frame_basic_stochastic_discrete\"\n  hparams.generative_model_params = \"next_frame_basic_stochastic_discrete\"\n  # The parameters below are the same as base, but repeated for easier reading.\n  hparams.ppo_epoch_length = 50\n  hparams.simulated_rollout_length = 50\n  hparams.simulated_batch_size = 16\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlonging setting with stochastic discrete model & deterministic sim starts.", "response": "def rlmb_long_stochastic_discrete_simulation_deterministic_starts():\n  \"\"\"Long setting with stochastic discrete model & deterministic sim starts.\"\"\"\n  hparams = rlmb_base_stochastic_discrete()\n  hparams.generative_model_params = \"next_frame_basic_stochastic_discrete_long\"\n  hparams.ppo_epochs_num = 1000\n  hparams.simulation_random_starts = False\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlong setting with stochastic discrete model changed ppo steps.", "response": "def rlmb_long_stochastic_discrete_100steps():\n  \"\"\"Long setting with stochastic discrete model, changed ppo steps.\"\"\"\n  hparams = rlmb_long_stochastic_discrete()\n  hparams.ppo_epoch_length = 100\n  hparams.simulated_rollout_length = 100\n  hparams.simulated_batch_size = 8\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlonging setting with stochastic discrete model changed ppo steps.", "response": "def rlmb_long_stochastic_discrete_25steps():\n  \"\"\"Long setting with stochastic discrete model, changed ppo steps.\"\"\"\n  hparams = rlmb_long_stochastic_discrete()\n  hparams.ppo_epoch_length = 25\n  hparams.simulated_rollout_length = 25\n  hparams.simulated_batch_size = 32\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rlmb_base_stochastic_discrete_noresize():\n  hparams = rlmb_base()\n  hparams.generative_model = \"next_frame_basic_stochastic_discrete\"\n  hparams.generative_model_params = \"next_frame_basic_stochastic_discrete\"\n  hparams.resize_height_factor = 1\n  hparams.resize_width_factor = 1\n  return hparams", "response": "Base setting with stochastic discrete model."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rlmb_base_sv2p():\n  hparams = rlmb_base()\n  hparams.learning_rate_bump = 1.0\n  hparams.generative_model = \"next_frame_sv2p\"\n  hparams.generative_model_params = \"next_frame_sv2p_atari\"\n  return hparams", "response": "Base setting with sv2p as world model."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _rlmb_tiny_overrides():\n  return dict(\n      epochs=1,\n      num_real_env_frames=128,\n      model_train_steps=2,\n      max_num_noops=1,\n      eval_max_num_noops=1,\n      generative_model_params=\"next_frame_tiny\",\n      stop_loop_early=True,\n      resize_height_factor=2,\n      resize_width_factor=2,\n      wm_eval_rollout_ratios=[1],\n      rl_env_max_episode_steps=7,\n      eval_rl_env_max_episode_steps=7,\n      simulated_rollout_length=2,\n      eval_sampling_temps=[0.0, 1.0],\n  )", "response": "Parameters to override for tiny setting excluding agent - related hparams."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rlmb_ppo_tiny():\n  hparams = rlmb_ppo_base()\n  hparams = hparams.override_from_dict(_rlmb_tiny_overrides())\n  update_hparams(hparams, dict(\n      ppo_epochs_num=2,\n      ppo_epoch_length=10,\n      real_ppo_epoch_length=36,\n      real_ppo_effective_num_agents=2,\n      real_batch_size=1,\n      eval_batch_size=1,\n  ))\n  return hparams", "response": "Tiny set for testing."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rlmb_tiny_recurrent():\n  hparams = rlmb_ppo_tiny()\n  hparams.epochs = 1  # Too slow with 2 for regular runs.\n  hparams.generative_model = \"next_frame_basic_recurrent\"\n  hparams.generative_model_params = \"next_frame_basic_recurrent\"\n  return hparams", "response": "Tiny setting with a recurrent next - frame model."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmerging multiple HParams into one with scopes.", "response": "def merge_unscoped_hparams(scopes_and_hparams):\n  \"\"\"Merge multiple HParams into one with scopes.\"\"\"\n  merged_values = {}\n  for (scope, hparams) in scopes_and_hparams:\n    for key, value in six.iteritems(hparams.values()):\n      scoped_key = \"%s.%s\" % (scope, key)\n      merged_values[scoped_key] = value\n\n  return hparam.HParams(**merged_values)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsplit single HParams with scoped keys into multiple.", "response": "def split_scoped_hparams(scopes, merged_hparams):\n  \"\"\"Split single HParams with scoped keys into multiple.\"\"\"\n  split_values = {scope: {} for scope in scopes}\n  merged_values = merged_hparams.values()\n  for scoped_key, value in six.iteritems(merged_values):\n    scope = scoped_key.split(\".\")[0]\n    key = scoped_key[len(scope) + 1:]\n    split_values[scope][key] = value\n\n  return [\n      hparam.HParams(**split_values[scope]) for scope in scopes\n  ]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef training_loop_hparams_from_scoped_overrides(scoped_overrides, trial_id):\n  trial_hp_overrides = scoped_overrides.values()\n\n  # Create loop, model, and ppo base HParams\n  loop_hp = create_loop_hparams()\n  model_hp_name = trial_hp_overrides.get(\n      \"loop.generative_model_params\", loop_hp.generative_model_params)\n  model_hp = registry.hparams(model_hp_name).parse(FLAGS.hparams)\n  base_algo_params_name = trial_hp_overrides.get(\n      \"loop.base_algo_params\", loop_hp.base_algo_params)\n  algo_hp = registry.hparams(base_algo_params_name)\n\n  # Merge them and then override with the scoped overrides\n  combined_hp = merge_unscoped_hparams(\n      zip(HP_SCOPES, [loop_hp, model_hp, algo_hp]))\n  combined_hp.override_from_dict(trial_hp_overrides)\n\n  # Split out the component hparams\n  loop_hp, model_hp, algo_hp = (\n      split_scoped_hparams(HP_SCOPES, combined_hp))\n\n  # Dynamic register the model hp and set the new name in loop_hp\n  model_hp_name = \"model_hp_%s\" % str(trial_id)\n  dynamic_register_hparams(model_hp_name, model_hp)\n  loop_hp.generative_model_params = model_hp_name\n\n  # Dynamic register the algo hp and set the new name in loop_hp\n  algo_hp_name = \"algo_hp_%s\" % str(trial_id)\n  dynamic_register_hparams(algo_hp_name, algo_hp)\n  loop_hp.base_algo_params = algo_hp_name\n\n  return loop_hp", "response": "Create HParams suitable for training loop from scoped HParams."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting mapping from keyboard keys to actions.", "response": "def get_keys_to_action(self):\n    \"\"\"Get mapping from keyboard keys to actions.\n\n    Required by gym.utils.play in environment or top level wrapper.\n\n    Returns:\n      {\n        Unicode code point for keyboard key: action (formatted for step()),\n        ...\n      }\n    \"\"\"\n    # Based on gym AtariEnv.get_keys_to_action()\n    keyword_to_key = {\n        \"UP\": ord(\"w\"),\n        \"DOWN\": ord(\"s\"),\n        \"LEFT\": ord(\"a\"),\n        \"RIGHT\": ord(\"d\"),\n        \"FIRE\": ord(\" \"),\n    }\n\n    keys_to_action = {}\n\n    for action_id, action_meaning in enumerate(self.action_meanings):\n      keys_tuple = tuple(sorted([\n          key for keyword, key in keyword_to_key.items()\n          if keyword in action_meaning]))\n      assert keys_tuple not in keys_to_action\n      keys_to_action[keys_tuple] = action_id\n\n    # Special actions:\n    keys_to_action[(ord(\"r\"),)] = self.RETURN_DONE_ACTION\n    keys_to_action[(ord(\"c\"),)] = self.TOGGLE_WAIT_ACTION\n    keys_to_action[(ord(\"n\"),)] = self.WAIT_MODE_NOOP_ACTION\n\n    return keys_to_action"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef step(self, action):\n    # Special codes\n    if action in self._player_actions():\n      envs_step_tuples = self._player_actions()[action]()\n    elif self._wait and action == self.name_to_action_num[\"NOOP\"]:\n      # Ignore no-op, do not pass to environment.\n      envs_step_tuples = self._last_step_tuples\n    else:\n      # Run action on environment(s).\n      if action == self.WAIT_MODE_NOOP_ACTION:\n        action = self.name_to_action_num[\"NOOP\"]\n      # Perform action on underlying environment(s).\n      envs_step_tuples = self._step_envs(action)\n      self._update_statistics(envs_step_tuples)\n\n    self._last_step_tuples = envs_step_tuples\n    ob, reward, done, info = self._player_step_tuple(envs_step_tuples)\n    return ob, reward, done, info", "response": "Pass action to underlying environment or perform special action."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexpands observation array with additional information header ( top rows.", "response": "def _augment_observation(self, ob, reward, cumulative_reward):\n    \"\"\"\"Expand observation array with additional information header (top rows).\n\n    Args:\n      ob: observation\n      reward: reward to be included in header.\n      cumulative_reward: total cumulated reward to be included in header.\n\n    Returns:\n      Expanded observation array.\n    \"\"\"\n    img = PIL_Image().new(\"RGB\",\n                          (ob.shape[1], self.HEADER_HEIGHT,))\n    draw = PIL_ImageDraw().Draw(img)\n    draw.text(\n        (1, 0), \"c:{:3}, r:{:3}\".format(int(cumulative_reward), int(reward)),\n        fill=(255, 0, 0)\n    )\n    draw.text(\n        (1, 15), \"fc:{:3}\".format(int(self._frame_counter)),\n        fill=(255, 0, 0)\n    )\n    header = np.asarray(img)\n    del img\n    header.setflags(write=1)\n    # Top row color indicates if WAIT MODE is on.\n    if self._wait:\n      pixel_fill = (0, 255, 0)\n    else:\n      pixel_fill = (255, 0, 0)\n    header[0, :, :] = pixel_fill\n    return np.concatenate([header, ob], axis=0)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconstructing observation return usual step tuple.", "response": "def _player_step_tuple(self, envs_step_tuples):\n    \"\"\"Construct observation, return usual step tuple.\n\n    Args:\n      envs_step_tuples: tuples.\n\n    Returns:\n      Step tuple: ob, reward, done, info\n        ob: concatenated images [simulated observation, real observation,\n          difference], with additional informations in header.\n        reward: real environment reward\n        done: True iff. envs_step_tuples['real_env'][2] is True\n        info: real environment info\n    \"\"\"\n    ob_real, reward_real, _, _ = envs_step_tuples[\"real_env\"]\n    ob_sim, reward_sim, _, _ = envs_step_tuples[\"sim_env\"]\n    ob_err = absolute_hinge_difference(ob_sim, ob_real)\n\n    ob_real_aug = self._augment_observation(ob_real, reward_real,\n                                            self.cumulative_real_reward)\n    ob_sim_aug = self._augment_observation(ob_sim, reward_sim,\n                                           self.cumulative_sim_reward)\n    ob_err_aug = self._augment_observation(\n        ob_err, reward_sim - reward_real,\n        self.cumulative_sim_reward - self.cumulative_real_reward\n    )\n    ob = np.concatenate([ob_sim_aug, ob_real_aug, ob_err_aug], axis=1)\n    _, reward, done, info = envs_step_tuples[\"real_env\"]\n    return ob, reward, done, info"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreset simulated and real environments.", "response": "def reset(self):\n    \"\"\"Reset simulated and real environments.\"\"\"\n    self._frame_counter = 0\n    ob_real = self.real_env.reset()\n    # Initialize simulated environment with frames from real one.\n    self.sim_env.add_to_initial_stack(ob_real)\n    for _ in range(3):\n      ob_real, _, _, _ = self.real_env.step(self.name_to_action_num[\"NOOP\"])\n      self.sim_env.add_to_initial_stack(ob_real)\n    ob_sim = self.sim_env.reset()\n    assert np.all(ob_real == ob_sim)\n    self._last_step_tuples = self._pack_step_tuples((ob_real, 0, False, {}),\n                                                    (ob_sim, 0, False, {}))\n    self.set_zero_cumulative_rewards()\n    ob, _, _, _ = self._player_step_tuple(self._last_step_tuples)\n    return ob"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming step on environments and update initial_frame_stack.", "response": "def _step_envs(self, action):\n    \"\"\"Perform step(action) on environments and update initial_frame_stack.\"\"\"\n    self._frame_counter += 1\n    real_env_step_tuple = self.real_env.step(action)\n    sim_env_step_tuple = self.sim_env.step(action)\n    self.sim_env.add_to_initial_stack(real_env_step_tuple[0])\n    return self._pack_step_tuples(real_env_step_tuple, sim_env_step_tuple)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\naugmenting observation return usual step tuple.", "response": "def _player_step_tuple(self, envs_step_tuples):\n    \"\"\"Augment observation, return usual step tuple.\"\"\"\n    ob, reward, done, info = envs_step_tuples[\"env\"]\n    ob = self._augment_observation(ob, reward, self.cumulative_reward)\n    return ob, reward, done, info"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing time first and second - order derivative channels.", "response": "def add_delta_deltas(filterbanks, name=None):\n  \"\"\"Compute time first and second-order derivative channels.\n\n  Args:\n    filterbanks: float32 tensor with shape [batch_size, len, num_bins, 1]\n    name: scope name\n\n  Returns:\n    float32 tensor with shape [batch_size, len, num_bins, 3]\n  \"\"\"\n  delta_filter = np.array([2, 1, 0, -1, -2])\n  delta_delta_filter = scipy.signal.convolve(delta_filter, delta_filter, \"full\")\n\n  delta_filter_stack = np.array(\n      [[0] * 4 + [1] + [0] * 4, [0] * 2 + list(delta_filter) + [0] * 2,\n       list(delta_delta_filter)],\n      dtype=np.float32).T[:, None, None, :]\n\n  delta_filter_stack /= np.sqrt(\n      np.sum(delta_filter_stack**2, axis=0, keepdims=True))\n\n  filterbanks = tf.nn.conv2d(\n      filterbanks, delta_filter_stack, [1, 1, 1, 1], \"SAME\", data_format=\"NHWC\",\n      name=name)\n  return filterbanks"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compute_mel_filterbank_features(\n    waveforms,\n    sample_rate=16000, dither=1.0 / np.iinfo(np.int16).max, preemphasis=0.97,\n    frame_length=25, frame_step=10, fft_length=None,\n    window_fn=functools.partial(tf.contrib.signal.hann_window, periodic=True),\n    lower_edge_hertz=80.0, upper_edge_hertz=7600.0, num_mel_bins=80,\n    log_noise_floor=1e-3, apply_mask=True):\n  \"\"\"Implement mel-filterbank extraction using tf ops.\n\n  Args:\n    waveforms: float32 tensor with shape [batch_size, max_len]\n    sample_rate: sampling rate of the waveform\n    dither: stddev of Gaussian noise added to waveform to prevent quantization\n      artefacts\n    preemphasis: waveform high-pass filtering constant\n    frame_length: frame length in ms\n    frame_step: frame_Step in ms\n    fft_length: number of fft bins\n    window_fn: windowing function\n    lower_edge_hertz: lowest frequency of the filterbank\n    upper_edge_hertz: highest frequency of the filterbank\n    num_mel_bins: filterbank size\n    log_noise_floor: clip small values to prevent numeric overflow in log\n    apply_mask: When working on a batch of samples, set padding frames to zero\n  Returns:\n    filterbanks: a float32 tensor with shape [batch_size, len, num_bins, 1]\n  \"\"\"\n  # `stfts` is a complex64 Tensor representing the short-time Fourier\n  # Transform of each signal in `signals`. Its shape is\n  # [batch_size, ?, fft_unique_bins]\n  # where fft_unique_bins = fft_length // 2 + 1\n\n  # Find the wave length: the largest index for which the value is !=0\n  # note that waveforms samples that are exactly 0.0 are quite common, so\n  # simply doing sum(waveforms != 0, axis=-1) will not work correctly.\n  wav_lens = tf.reduce_max(\n      tf.expand_dims(tf.range(tf.shape(waveforms)[1]), 0) *\n      tf.to_int32(tf.not_equal(waveforms, 0.0)),\n      axis=-1) + 1\n  if dither > 0:\n    waveforms += tf.random_normal(tf.shape(waveforms), stddev=dither)\n  if preemphasis > 0:\n    waveforms = waveforms[:, 1:] - preemphasis * waveforms[:, :-1]\n    wav_lens -= 1\n  frame_length = int(frame_length * sample_rate / 1e3)\n  frame_step = int(frame_step * sample_rate / 1e3)\n  if fft_length is None:\n    fft_length = int(2**(np.ceil(np.log2(frame_length))))\n\n  stfts = tf.contrib.signal.stft(\n      waveforms,\n      frame_length=frame_length,\n      frame_step=frame_step,\n      fft_length=fft_length,\n      window_fn=window_fn,\n      pad_end=True)\n\n  stft_lens = (wav_lens + (frame_step - 1)) // frame_step\n  masks = tf.to_float(tf.less_equal(\n      tf.expand_dims(tf.range(tf.shape(stfts)[1]), 0),\n      tf.expand_dims(stft_lens, 1)))\n\n  # An energy spectrogram is the magnitude of the complex-valued STFT.\n  # A float32 Tensor of shape [batch_size, ?, 257].\n  magnitude_spectrograms = tf.abs(stfts)\n\n  # Warp the linear-scale, magnitude spectrograms into the mel-scale.\n  num_spectrogram_bins = magnitude_spectrograms.shape[-1].value\n  linear_to_mel_weight_matrix = (\n      tf.contrib.signal.linear_to_mel_weight_matrix(\n          num_mel_bins, num_spectrogram_bins, sample_rate, lower_edge_hertz,\n          upper_edge_hertz))\n  mel_spectrograms = tf.tensordot(\n      magnitude_spectrograms, linear_to_mel_weight_matrix, 1)\n  # Note: Shape inference for tensordot does not currently handle this case.\n  mel_spectrograms.set_shape(magnitude_spectrograms.shape[:-1].concatenate(\n      linear_to_mel_weight_matrix.shape[-1:]))\n\n  log_mel_sgram = tf.log(tf.maximum(log_noise_floor, mel_spectrograms))\n\n  if apply_mask:\n    log_mel_sgram *= tf.expand_dims(tf.to_float(masks), -1)\n\n  return tf.expand_dims(log_mel_sgram, -1, name=\"mel_sgrams\")", "response": "Implement mel - filterbank extraction using tf ops."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef play_env_problem_randomly(env_problem,\n                              num_steps):\n  \"\"\"Plays the env problem by randomly sampling actions for `num_steps`.\"\"\"\n  # Reset all environments.\n  env_problem.reset()\n\n  # Play all environments, sampling random actions each time.\n  for _ in range(num_steps):\n    # Sample batch_size actions from the action space and stack them.\n    actions = np.stack([env_problem.action_space.sample() for _ in range(\n        env_problem.batch_size)])\n\n    # Execute actions, observations are stored in `env_problem`.\n    _, _, dones, _ = env_problem.step(actions)\n\n    # Get the indices where we are done and reset those.\n    env_problem.reset(indices=done_indices(dones))", "response": "Plays the env problem by randomly sampling actions for num_steps."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_plaintext_random(plain_vocab, distribution, train_samples,\n                              length):\n  \"\"\"Generates samples of text from the provided vocabulary.\n\n  Args:\n    plain_vocab: vocabulary.\n    distribution: distribution.\n    train_samples: samples for training.\n    length: length.\n\n  Returns:\n    train_indices (np.array of Integers): random integers for training.\n      shape = [num_samples, length]\n    test_indices (np.array of Integers): random integers for testing.\n      shape = [num_samples, length]\n    plain_vocab   (list of Integers): unique vocabularies.\n  \"\"\"\n  if distribution is not None:\n    assert len(distribution) == len(plain_vocab)\n\n  train_indices = np.random.choice(\n      range(len(plain_vocab)), (train_samples, length), p=distribution)\n\n  return train_indices", "response": "Generates samples of text from the provided vocabulary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef encipher_shift(plaintext, plain_vocab, shift):\n  ciphertext = []\n  cipher = ShiftEncryptionLayer(plain_vocab, shift)\n\n  for _, sentence in enumerate(plaintext):\n    cipher_sentence = []\n    for _, character in enumerate(sentence):\n      encrypted_char = cipher.encrypt_character(character)\n      cipher_sentence.append(encrypted_char)\n    ciphertext.append(cipher_sentence)\n\n  return ciphertext", "response": "Encipher a list of plain text with a single shift layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nencrypts plain text with given key. Args: plaintext (list of list of Strings): a list of plain text to encrypt. plain_vocab (list of Integer): unique vocabularies being used. key (list of Integer): key to encrypt cipher using Vigenere table. Returns: ciphertext (list of Strings): encrypted plain text.", "response": "def encipher_vigenere(plaintext, plain_vocab, key):\n  \"\"\"Encrypt plain text with given key.\n\n  Args:\n    plaintext (list of list of Strings): a list of plain text to encrypt.\n    plain_vocab (list of Integer): unique vocabularies being used.\n    key (list of Integer): key to encrypt cipher using Vigenere table.\n\n  Returns:\n    ciphertext (list of Strings): encrypted plain text.\n  \"\"\"\n  ciphertext = []\n  # generate Vigenere table\n  layers = [\n      ShiftEncryptionLayer(plain_vocab, i) for i in range(len(plain_vocab))\n  ]\n\n  for i, sentence in enumerate(plaintext):\n    cipher_sentence = []\n    for j, character in enumerate(sentence):\n      key_idx = key[j % len(key)]\n      encrypted_char = layers[key_idx].encrypt_character(character)\n      cipher_sentence.append(encrypted_char)\n    ciphertext.append(cipher_sentence)\n\n  return ciphertext"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _super_stack(inputs,\n                 attention_bias,\n                 hparams,\n                 mp,\n                 padding=\"LEFT\"):\n  \"\"\"A stack of super_lm layers.\n\n  Args:\n    inputs: a list of Tensors\n    attention_bias: list of bias Tensor for self-attention\n      (see common_attention.attention_bias())\n    hparams: hyperparameters for model\n    mp: a Parallelism object\n    padding: a string\n\n  Returns:\n    y: a list of Tensors\n    extra_loss: an optional scalar\n  \"\"\"\n  layers = hparams.layers.strip(\",\").split(\",\")\n  moe_hidden_sizes = [int(s) for s in hparams.moe_hidden_sizes.split(\",\")]\n  if hparams.diet_experts:\n    hsize, = moe_hidden_sizes\n    def _diet_expert(x):\n      return diet.diet_expert(x, hsize, diet.diet_adam_optimizer_params())\n    expert_fn = _diet_expert\n  else:\n    expert_fn = expert_utils.ffn_expert_fn(\n        hparams.hidden_size, moe_hidden_sizes, hparams.hidden_size)\n  # scaled_dot_product_attention_with_projections uses a 3d attention bias\n  # (no heads), where multihead_attention uses 4d attention bias.\n  attention_bias_3d = mp(tf.squeeze, attention_bias, 1)\n  mix_size = int(hparams.mix_fraction * hparams.hidden_size)\n  accumulator = inputs\n  x = inputs\n  extra_losses = []\n  for layer_num, layer_type in enumerate(layers):\n    with tf.variable_scope(\"%s_%d\" % (layer_type, layer_num)):\n      tf.logging.info(\"%s_%d\" % (layer_type, layer_num))\n      if layer_type == \"a\":\n        # accumulate\n        accumulator = mp(tf.add, x, accumulator)\n        x = accumulator\n      elif layer_type == \"n\":\n        # normalize\n        x = mp(common_layers.apply_norm,\n               x, hparams.norm_type, hparams.hidden_size, hparams.norm_epsilon)\n      elif layer_type == \"d\":\n        # dropout\n        x = mp(tf.nn.dropout, x, 1.0 - hparams.layer_prepostprocess_dropout)\n      elif layer_type == \"m\":\n        # mix across shards\n        def _split(t):\n          return tuple(tf.split(\n              t, [mix_size, hparams.hidden_size - mix_size], 2))\n        to_mix, to_keep = mp(_split, x)\n        mixed = expert_utils.all_reduce_ring(to_mix, mp)\n        mixed = mp(tf.multiply, mixed, mp.n ** -0.5)\n        x = mp(lambda a, b: tf.concat([a, b], 2), mixed, to_keep)\n      elif layer_type == \"att\":\n        # single-head attention\n        q = mp(tf.layers.dense, x, hparams.hidden_size, use_bias=False,\n               name=\"q_transform\")\n        x = mp(\n            common_attention.scaled_dot_product_attention_simple,\n            q, x, x, attention_bias_3d)\n        x = mp(tf.layers.dense, x, hparams.hidden_size, use_bias=False,\n               name=\"o_transform\")\n      elif layer_type == \"multihead-att\":\n        # multi-head attention\n        x = mp(\n            common_attention.multihead_attention,\n            x,\n            None,\n            attention_bias,  # bias\n            hparams.multihead_attention_key_channels or hparams.hidden_size,\n            hparams.multihead_attention_value_channels or hparams.hidden_size,\n            hparams.hidden_size,\n            hparams.multihead_attention_num_heads,\n            hparams.attention_dropout)\n      elif layer_type == \"ffn\":\n        x = mp(\n            common_layers.dense_relu_dense, x,\n            hparams.filter_size, hparams.hidden_size)\n      elif layer_type == \"conv\":\n        # convolution\n        x = mp(\n            common_layers.conv1d,\n            x,\n            hparams.hidden_size,\n            hparams.kernel_height,\n            activation=tf.nn.relu,\n            padding=padding,\n        )\n      elif layer_type == \"moe\":\n        # mixture of experts - each model shard has its own local MoE.\n        x, loss = mp(\n            expert_utils.local_moe,\n            x,\n            train=hparams.mode == tf.estimator.ModeKeys.TRAIN,\n            expert_fn=expert_fn,\n            num_experts=hparams.moe_num_experts,\n            k=hparams.moe_k,\n            loss_coef=hparams.moe_loss_coef)\n        extra_losses.extend(loss)\n      else:\n        assert False, \"unknown sublayer %s\" % layer_type\n  if extra_losses:\n    extra_loss = tf.add_n(extra_losses)\n  else:\n    extra_loss = None\n  return x, extra_loss", "response": "A stack of super_lm layers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset of hyperparameters for super - lm model.", "response": "def super_lm_base():\n  \"\"\"Set of hyperparameters.\"\"\"\n  hparams = common_hparams.basic_params1()\n  hparams.hidden_size = 512\n  hparams.moe_hidden_sizes = \"512\"\n  hparams.batch_size = 16384\n  hparams.max_length = 0\n  # All hyperparameters ending in \"dropout\" are automatically set to 0.0\n  # when not in training mode.\n  hparams.layer_prepostprocess_dropout = 0.0\n  hparams.symbol_dropout = 0.1\n  hparams.add_hparam(\"attention_dropout\", 0.0)\n  hparams.label_smoothing = 0.0\n  hparams.clip_grad_norm = 0.  # i.e. no gradient clipping\n  hparams.optimizer = \"Adafactor\"\n  hparams.learning_rate_decay_scheme = \"noam\"\n  hparams.learning_rate = 0.1\n  hparams.learning_rate_warmup_steps = 8000\n  hparams.initializer_gain = 1.0\n  hparams.initializer = \"uniform_unit_scaling\"\n  hparams.weight_decay = 0.0\n  hparams.shared_embedding_and_softmax_weights = False\n  hparams.layer_preprocess_sequence = \"n\"\n  hparams.layer_postprocess_sequence = \"da\"\n  # we only want one data shard.\n  hparams.no_data_parallelism = True\n  # bypass the symbol modality so that we can use model parallelism.\n  hparams.bottom = {\n      \"inputs\": modalities.identity_bottom,\n      \"targets\": modalities.identity_bottom,\n  }\n  hparams.top = {\n      \"targets\": modalities.identity_top,\n  }\n  hparams.add_hparam(\"filter_size\", 512)\n  hparams.add_hparam(\"mix_fraction\", 0.5)\n  # attention-related flags\n  hparams.add_hparam(\"multihead_attention_num_heads\", 4)\n  hparams.add_hparam(\"multihead_attention_key_channels\", 0)\n  hparams.add_hparam(\"multihead_attention_value_channels\", 0)\n  hparams.add_hparam(\"pos\", \"timing\")  # timing, none\n  hparams.add_hparam(\n      \"layers\", (\"n,att,m,d,a,\" \"n,ffn,m,d,a,\") * 4 + \"n,ffn,d\")\n  # Number of model shards - each one has separate parameters.\n  # Changing this number invalidates checkpoints.\n  hparams.add_hparam(\"num_model_shards\", 8)\n  hparams.add_hparam(\"diet_experts\", False)\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef super_lm_moe():\n  hparams = super_lm_base()\n  hparams.layers = (\n      (\"n,att,m,d,a,\" \"n,moe,m,d,a,\") * 4 + \"n,ffn,d\")\n  hparams.moe_num_experts = 32\n  hparams.moe_hidden_sizes = \"1024\"\n  return hparams", "response": "Add mixture of experts with ~1B params."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef xmoe_tr_dense_2k():\n  hparams = mtf_transformer2.mtf_bitransformer_base()\n  hparams.encoder_layers = [\"self_att\", \"drd\"] * 4\n  hparams.decoder_layers = [\"self_att\", \"enc_att\", \"drd\"] * 4\n  hparams.batch_size = 64\n  hparams.shared_embedding_and_softmax_weights = True\n  hparams.mesh_shape = \"batch:8\"\n  return hparams", "response": "Series of architectural experiments on Translation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef xmoe_tr_2d():\n  hparams = xmoe_tr_dense_2k()\n  hparams.mesh_shape = \"b0:2;b1:4\"\n  hparams.outer_batch_size = 4\n  hparams.layout = \"outer_batch:b0;inner_batch:b1,expert_x:b1,expert_y:b0\"\n  hparams.encoder_layers = [\"self_att\", \"moe_2d\"] * 4\n  hparams.decoder_layers = [\"self_att\", \"enc_att\", \"moe_2d\"] * 4\n  hparams.moe_hidden_size = 2048\n  hparams.moe_experts_x = 4\n  hparams.moe_experts_y = 4\n  return hparams", "response": "Mixture of experts (16 experts).\n\n  623M Params, einsum=1.09e13\n\n  Returns:\n    a hparams"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef xmoe_dense_4k():\n  hparams = mtf_transformer.mtf_transformer_base_lm()\n  hparams.attention_dropout = 0.0\n  hparams.relu_dropout = 0.0\n  hparams.layer_prepostprocess_dropout = 0.0\n\n  # The following hparams are constant across all these experiments.\n  hparams.batch_size = 128\n  hparams.d_model = 512\n  hparams.d_kv = 128\n  hparams.num_heads = 4\n  hparams.decoder_layers = [\"att\", \"drd\"] * 4\n  hparams.shared_embedding_and_softmax_weights = False\n  hparams.learning_rate_schedule = \"rsqrt_decay\"\n\n  # We will vary the following parameters related to the ffn/moe layers.\n  hparams.d_ff = 4096\n  hparams.layout = \"batch:batch;vocab:model;d_ff:model;heads:model\"\n  hparams.mesh_shape = \"batch:8\"\n  return hparams", "response": "Series of architectural experiments on cheap language models on cheap language models on cheap language models on 32000 steps."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef xmoe_top_2():\n  hparams = xmoe_dense_4k()\n  moe.set_default_moe_hparams(hparams)\n  hparams.mesh_shape = \"all:8\"\n  hparams.layout = \"batch:all;experts:all\"\n  return hparams", "response": "Mixture of experts ( 16 experts."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef xmoe2_v1():\n  hparams = xmoe2_dense(0)\n  moe.set_default_moe_hparams(hparams)\n  hparams.decoder_layers = (\n      [\"local_att\", \"local_att\", \"drd\",\n       \"att\", \"drd\", \"local_att\", \"local_att\", \"hmoe\"] * 4)[:-1]\n  hparams.d_ff = 2048\n  hparams.d_kv = 128\n  hparams.moe_hidden_size = 32768\n  hparams.mesh_shape = \"b0:4;b1:8\"\n  hparams.layout = \"outer_batch:b0;inner_batch:b1,expert_x:b1,expert_y:b0\"\n  hparams.outer_batch_size = 4\n  hparams.moe_num_experts = [8, 4]\n  hparams.num_heads = 4\n  return hparams", "response": "Model incorporating mixture - of - experts and local - attention."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef xmoe2_v1_x128():\n  hparams = xmoe2_v1()\n  hparams.moe_num_experts = [16, 8]\n  hparams.outer_batch_size = 8\n  hparams.mesh_shape = \"b0:8;b1:16\"\n  hparams.batch_size = 512\n  hparams.learning_rate_decay_steps = 16384\n  return hparams", "response": "128 experts ~25B params - Train for 131072 steps on 8x8."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntests on local cpu.", "response": "def xmoe2_tiny():\n  \"\"\"Test on local cpu.\"\"\"\n  hparams = xmoe2_v1()\n  hparams.decoder_layers = [\n      \"local_att\", \"att\", \"compressed_att\", \"drd\", \"hmoe\"]\n  hparams.d_model = 128\n  hparams.moe_hidden_size = 512\n  hparams.outer_batch_size = 0\n  hparams.batch_size = 2\n  hparams.mesh_shape = \"\"\n  hparams.activation_dtype = \"float32\"\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets of architectural experiments - language model on wikipedia on a 2x2. 1 epoch = ~180k steps at batch size 32 - we may never finish an epoch! Returns: a hparams", "response": "def wiki_2x2_base():\n  \"\"\"Set of architectural experiments - language model on wikipedia on a 2x2.\n\n  1 epoch = ~180k steps at batch size 32 - we may never finish an epoch!\n\n  Returns:\n    a hparams\n  \"\"\"\n  hparams = mtf_transformer.mtf_transformer_base_lm()\n  hparams.shared_embedding_and_softmax_weights = False\n  # no dropout - dataset is big enough to avoid overfitting.\n  hparams.attention_dropout = 0.0\n  hparams.relu_dropout = 0.0\n  hparams.layer_prepostprocess_dropout = 0.0\n  hparams.max_length = 1024\n  # 4 sequences per core\n  hparams.batch_size = 32\n  # We don't use linear decay in these experiments, since we don't want\n  # a sharp jump in quality at the end of the training schedule.\n  # You can insert this once you find the right architecture.\n  hparams.learning_rate_schedule = \"rsqrt_decay\"\n  hparams.mesh_shape = \"all:8\"\n  hparams.layout = \"batch:all;experts:all\"\n\n  # parameters for mixture-of-experts\n  moe.set_default_moe_hparams(hparams)\n  hparams.moe_num_experts = 16\n  hparams.moe_hidden_size = 8192\n\n  hparams.decoder_layers = [\"att\", \"drd\"] * 6\n  hparams.d_model = 1024\n  hparams.d_ff = 2048\n  hparams.d_kv = 128\n  hparams.num_heads = 4\n\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreplacing tokens instead of masking.", "response": "def denoise_z15():\n  \"\"\"Replace tokens instead of masking.\"\"\"\n  hparams = xmoe2_dense_0()\n  hparams.decoder_type = \"denoising\"\n  hparams.noising_spec_train = {\"type\": \"random_zipfian\", \"prob\": 0.15}\n  hparams.noising_use_eval_during_train = 0.25\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndownload and extracts the dataset.", "response": "def _download_mlu_data(tmp_dir, data_dir):\n  \"\"\"Downloads and extracts the dataset.\n\n  Args:\n    tmp_dir: temp directory to download and extract the dataset\n    data_dir: The base directory where data and vocab files are stored.\n\n  Returns:\n    tmp_dir: temp directory containing the raw data.\n  \"\"\"\n  if not tf.gfile.Exists(data_dir):\n    tf.gfile.MakeDirs(data_dir)\n\n  filename = os.path.basename(_URL)\n  file_path = os.path.join(tmp_dir, filename)\n  headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_1) \"\n                           \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n                           \"Chrome/63.0.3239.132 Safari/537.36\"}\n  resp = requests.get(_URL, headers=headers)\n  with open(file_path, \"wb\") as f:\n    f.write(resp.content)\n\n  with tarfile.open(file_path, \"r:gz\") as tar:\n    tar.extractall(tmp_dir)\n\n  return tmp_dir"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_ngram_counter(ids, n):\n  # Remove zero IDs used to pad the sequence.\n  ids = [token_id for token_id in ids if token_id != 0]\n  ngram_list = [tuple(ids[i:i + n]) for i in range(len(ids) + 1 - n)]\n  ngrams = set(ngram_list)\n  counts = collections.Counter()\n  for ngram in ngrams:\n    counts[ngram] = 1\n  return counts", "response": "Get a Counter with the ngrams of the given ID list."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_fbeta_score(true_positives, selected, relevant, beta=1):\n  precision = 1\n  if selected > 0:\n    precision = true_positives / selected\n  if beta == 0:\n    return precision\n  recall = 1\n  if relevant > 0:\n    recall = true_positives / relevant\n  if precision > 0 and recall > 0:\n    beta2 = beta * beta\n    return (1 + beta2) * precision * recall / (beta2 * precision + recall)\n  else:\n    return 0", "response": "Compute Fbeta score.\n\n  Args:\n    true_positives: Number of true positive ngrams.\n    selected: Number of selected ngrams.\n    relevant: Number of relevant ngrams.\n    beta: 0 gives precision only, 1 gives F1 score, and Inf gives recall only.\n\n  Returns:\n    Fbeta score."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the addition score.", "response": "def get_addition_score(source_counts, prediction_counts, target_counts):\n  \"\"\"Compute the addition score (Equation 4 in the paper).\"\"\"\n  added_to_prediction_counts = prediction_counts - source_counts\n  true_positives = sum((added_to_prediction_counts & target_counts).values())\n  selected = sum(added_to_prediction_counts.values())\n  # Note that in the paper the summation is done over all the ngrams in the\n  # output rather than the ngrams in the following set difference. Since the\n  # former does not make as much sense we compute the latter, which is also done\n  # in the GitHub implementation.\n  relevant = sum((target_counts - source_counts).values())\n  return _get_fbeta_score(true_positives, selected, relevant)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_keep_score(source_counts, prediction_counts, target_counts):\n  source_and_prediction_counts = source_counts & prediction_counts\n  source_and_target_counts = source_counts & target_counts\n  true_positives = sum((source_and_prediction_counts &\n                        source_and_target_counts).values())\n  selected = sum(source_and_prediction_counts.values())\n  relevant = sum(source_and_target_counts.values())\n  return _get_fbeta_score(true_positives, selected, relevant)", "response": "Compute the keep score."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the deletion score.", "response": "def get_deletion_score(source_counts, prediction_counts, target_counts, beta=0):\n  \"\"\"Compute the deletion score (Equation 6 in the paper).\"\"\"\n  source_not_prediction_counts = source_counts - prediction_counts\n  source_not_target_counts = source_counts - target_counts\n  true_positives = sum((source_not_prediction_counts &\n                        source_not_target_counts).values())\n  selected = sum(source_not_prediction_counts.values())\n  relevant = sum(source_not_target_counts.values())\n  return _get_fbeta_score(true_positives, selected, relevant, beta=beta)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_sari_score(source_ids, prediction_ids, list_of_targets,\n                   max_gram_size=4, beta_for_deletion=0):\n  \"\"\"Compute the SARI score for a single prediction and one or more targets.\n\n  Args:\n    source_ids: a list / np.array of SentencePiece IDs\n    prediction_ids: a list / np.array of SentencePiece IDs\n    list_of_targets: a list of target ID lists / np.arrays\n    max_gram_size: int. largest n-gram size we care about (e.g. 3 for unigrams,\n        bigrams, and trigrams)\n    beta_for_deletion: beta for deletion F score.\n\n  Returns:\n    the SARI score and its three components: add, keep, and deletion scores\n  \"\"\"\n  addition_scores = []\n  keep_scores = []\n  deletion_scores = []\n  for n in range(1, max_gram_size + 1):\n    source_counts = _get_ngram_counter(source_ids, n)\n    prediction_counts = _get_ngram_counter(prediction_ids, n)\n    # All ngrams in the targets with count 1.\n    target_counts = collections.Counter()\n    # All ngrams in the targets with count r/num_targets, where r is the number\n    # of targets where the ngram occurs.\n    weighted_target_counts = collections.Counter()\n    num_nonempty_targets = 0\n    for target_ids_i in list_of_targets:\n      target_counts_i = _get_ngram_counter(target_ids_i, n)\n      if target_counts_i:\n        weighted_target_counts += target_counts_i\n        num_nonempty_targets += 1\n    for gram in weighted_target_counts.keys():\n      weighted_target_counts[gram] /= num_nonempty_targets\n      target_counts[gram] = 1\n    keep_scores.append(get_keep_score(source_counts, prediction_counts,\n                                      weighted_target_counts))\n    deletion_scores.append(get_deletion_score(source_counts, prediction_counts,\n                                              weighted_target_counts,\n                                              beta_for_deletion))\n    addition_scores.append(get_addition_score(source_counts, prediction_counts,\n                                              target_counts))\n\n  avg_keep_score = sum(keep_scores) / max_gram_size\n  avg_addition_score = sum(addition_scores) / max_gram_size\n  avg_deletion_score = sum(deletion_scores) / max_gram_size\n  sari = (avg_keep_score + avg_addition_score + avg_deletion_score) / 3.0\n  return sari, avg_keep_score, avg_addition_score, avg_deletion_score", "response": "Compute the SARI score for a single prediction and one or more targets."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_sari(source_ids, prediction_ids, target_ids, max_gram_size=4):\n\n  def get_sari_numpy(source_ids, prediction_ids, target_ids):\n    \"\"\"Iterate over elements in the batch and call the SARI function.\"\"\"\n    sari_scores = []\n    keep_scores = []\n    add_scores = []\n    deletion_scores = []\n    # Iterate over elements in the batch.\n    for source_ids_i, prediction_ids_i, target_ids_i in zip(\n        source_ids, prediction_ids, target_ids):\n      sari, keep, add, deletion = get_sari_score(\n          source_ids_i, prediction_ids_i, target_ids_i, max_gram_size,\n          BETA_FOR_SARI_DELETION_F_MEASURE)\n      sari_scores.append(sari)\n      keep_scores.append(keep)\n      add_scores.append(add)\n      deletion_scores.append(deletion)\n    return (np.asarray(sari_scores), np.asarray(keep_scores),\n            np.asarray(add_scores), np.asarray(deletion_scores))\n\n  sari, keep, add, deletion = tf.py_func(\n      get_sari_numpy,\n      [source_ids, prediction_ids, target_ids],\n      [tf.float64, tf.float64, tf.float64, tf.float64])\n  return sari, keep, add, deletion", "response": "Computes the SARI scores from the given source prediction and target."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the SARI score from the given predictions and labels.", "response": "def sari_score(predictions, labels, features, **unused_kwargs):\n  \"\"\"Computes the SARI scores from the given source, prediction and targets.\n\n  An approximate SARI scoring method since we do not glue word pieces or\n  decode the ids and tokenize the output. By default, we use ngram order of 4.\n  Also, this does not have beam search.\n\n  Args:\n    predictions: tensor, model predictions.\n    labels: tensor, gold output.\n    features: dict, containing inputs.\n\n  Returns:\n    sari: int, approx sari score\n  \"\"\"\n  if \"inputs\" not in features:\n    raise ValueError(\"sari_score requires inputs feature\")\n\n  # Convert the inputs and outputs to a [batch_size, sequence_length] tensor.\n  inputs = tf.squeeze(features[\"inputs\"], axis=[-1, -2])\n  outputs = tf.to_int32(tf.argmax(predictions, axis=-1))\n  outputs = tf.squeeze(outputs, axis=[-1, -2])\n\n  # Convert the labels to a [batch_size, 1, sequence_length] tensor.\n  labels = tf.squeeze(labels, axis=[-1, -2])\n  labels = tf.expand_dims(labels, axis=1)\n\n  score, _, _, _ = get_sari(inputs, outputs, labels)\n  return score, tf.constant(1.0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_mnist(directory):\n  for filename in [\n      _MNIST_TRAIN_DATA_FILENAME, _MNIST_TRAIN_LABELS_FILENAME,\n      _MNIST_TEST_DATA_FILENAME, _MNIST_TEST_LABELS_FILENAME\n  ]:\n    generator_utils.maybe_download(directory, filename, _MNIST_URL + filename)", "response": "Download all MNIST files to directory unless they are there."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts images from an MNIST file into a numpy array.", "response": "def _extract_mnist_images(filename, num_images):\n  \"\"\"Extract images from an MNIST file into a numpy array.\n\n  Args:\n    filename: The path to an MNIST images file.\n    num_images: The number of images in the file.\n\n  Returns:\n    A numpy array of shape [number_of_images, height, width, channels].\n  \"\"\"\n  with gzip.open(filename) as bytestream:\n    bytestream.read(16)\n    buf = bytestream.read(_MNIST_IMAGE_SIZE * _MNIST_IMAGE_SIZE * num_images)\n    data = np.frombuffer(buf, dtype=np.uint8)\n    data = data.reshape(num_images, _MNIST_IMAGE_SIZE, _MNIST_IMAGE_SIZE, 1)\n  return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract labels from an MNIST file into integers.", "response": "def _extract_mnist_labels(filename, num_labels):\n  \"\"\"Extract labels from an MNIST file into integers.\n\n  Args:\n    filename: The path to an MNIST labels file.\n    num_labels: The number of labels in the file.\n\n  Returns:\n    A int64 numpy array of shape [num_labels]\n  \"\"\"\n  with gzip.open(filename) as bytestream:\n    bytestream.read(8)\n    buf = bytestream.read(num_labels)\n    labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n  return labels"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nimaging generator for MNIST. Args: tmp_dir: path to temporary storage directory. training: a Boolean; if true, we use the train set, otherwise the test set. how_many: how many images and labels to generate. data_filename: file that contains features data. label_filename: file that contains labels. start_from: from which image to start. Returns: An instance of image_generator that produces MNIST images.", "response": "def mnist_common_generator(tmp_dir,\n                           training,\n                           how_many,\n                           data_filename,\n                           label_filename,\n                           start_from=0):\n  \"\"\"Image generator for MNIST.\n\n  Args:\n    tmp_dir: path to temporary storage directory.\n    training: a Boolean; if true, we use the train set, otherwise the test set.\n    how_many: how many images and labels to generate.\n    data_filename: file that contains features data.\n    label_filename: file that contains labels.\n    start_from: from which image to start.\n\n  Returns:\n    An instance of image_generator that produces MNIST images.\n  \"\"\"\n  data_path = os.path.join(tmp_dir, data_filename)\n  labels_path = os.path.join(tmp_dir, label_filename)\n  images = _extract_mnist_images(data_path, 60000 if training else 10000)\n  labels = _extract_mnist_labels(labels_path, 60000 if training else 10000)\n  # Shuffle the data to make sure classes are well distributed.\n  data = list(zip(images, labels))\n  random.shuffle(data)\n  images, labels = list(zip(*data))\n  return image_utils.image_generator(images[start_from:start_from + how_many],\n                                     labels[start_from:start_from + how_many])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nimage generator for MNIST.", "response": "def mnist_generator(tmp_dir, training, how_many, start_from=0):\n  \"\"\"Image generator for MNIST.\n\n  Args:\n    tmp_dir: path to temporary storage directory.\n    training: a Boolean; if true, we use the train set, otherwise the test set.\n    how_many: how many images and labels to generate.\n    start_from: from which image to start.\n\n  Returns:\n    An instance of image_generator that produces MNIST images.\n  \"\"\"\n  _get_mnist(tmp_dir)\n  d = _MNIST_TRAIN_DATA_FILENAME if training else _MNIST_TEST_DATA_FILENAME\n  l = _MNIST_TRAIN_LABELS_FILENAME if training else _MNIST_TEST_LABELS_FILENAME\n  return mnist_common_generator(tmp_dir, training, how_many, d, l, start_from)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads all FashionMNIST files to directory unless they are there.", "response": "def _get_fashion_mnist(directory):\n  \"\"\"Download all FashionMNIST files to directory unless they are there.\"\"\"\n  # Fashion mnist files have the same names as MNIST.\n  # We must choose a separate name (by adding 'fashion-' prefix) in the tmp_dir.\n  for filename in [\n      _MNIST_TRAIN_DATA_FILENAME, _MNIST_TRAIN_LABELS_FILENAME,\n      _MNIST_TEST_DATA_FILENAME, _MNIST_TEST_LABELS_FILENAME\n  ]:\n    generator_utils.maybe_download(directory,\n                                   _FASHION_MNIST_LOCAL_FILE_PREFIX + filename,\n                                   _FASHION_MNIST_URL + filename)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nimage generator for FashionMNIST.", "response": "def fashion_mnist_generator(tmp_dir, training, how_many, start_from=0):\n  \"\"\"Image generator for FashionMNIST.\n\n  Args:\n    tmp_dir: path to temporary storage directory.\n    training: a Boolean; if true, we use the train set, otherwise the test set.\n    how_many: how many images and labels to generate.\n    start_from: from which image to start.\n\n  Returns:\n    An instance of image_generator that produces MNIST images.\n  \"\"\"\n  _get_fashion_mnist(tmp_dir)\n  d = _FASHION_MNIST_LOCAL_FILE_PREFIX + (\n      _MNIST_TRAIN_DATA_FILENAME if training else _MNIST_TEST_DATA_FILENAME)\n  l = _FASHION_MNIST_LOCAL_FILE_PREFIX + (\n      _MNIST_TRAIN_LABELS_FILENAME if training else _MNIST_TEST_LABELS_FILENAME)\n  return mnist_common_generator(tmp_dir, training, how_many, d, l, start_from)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating synthetic data points for a given number of data points.", "response": "def generate_data(timeseries_length, timeseries_params):\n  \"\"\"Generates synthetic timeseries using input parameters.\n\n  Each generated timeseries has timeseries_length data points.\n  Parameters for each timeseries are specified by timeseries_params.\n\n  Args:\n    timeseries_length: Number of data points to generate for each timeseries.\n    timeseries_params: Parameters used to generate the timeseries. The following\n      parameters need to be specified for each timeseries:\n      m = Slope of the timeseries used to compute the timeseries trend.\n      b = y-intercept of the timeseries used to compute the timeseries trend.\n      A = Timeseries amplitude used to compute timeseries period.\n      freqcoeff = Frequency coefficient used to compute timeseries period.\n      rndA = Random amplitude used to inject noise into the timeseries.\n      fn = Base timeseries function (np.cos or np.sin).\n      Example params for two timeseries.\n      [{\"m\": 0.006, \"b\": 300.0, \"A\":50.0, \"freqcoeff\":1500.0, \"rndA\":15.0,\n      \"fn\": np.sin},\n      {\"m\": 0.000, \"b\": 500.0, \"A\":35.0, \"freqcoeff\":3500.0, \"rndA\":25.0,\n      \"fn\": np.cos}]\n\n  Returns:\n    Multi-timeseries (list of list).\n  \"\"\"\n  x = range(timeseries_length)\n\n  multi_timeseries = []\n  for p in timeseries_params:\n    # Trend\n    y1 = [p[\"m\"] * i + p[\"b\"] for i in x]\n    # Period\n    y2 = [p[\"A\"] * p[\"fn\"](i / p[\"freqcoeff\"]) for i in x]\n    # Noise\n    y3 = np.random.normal(0, p[\"rndA\"], timeseries_length).tolist()\n    # Sum of Trend, Period and Noise. Replace negative values with zero.\n    y = [max(a + b + c, 0) for a, b, c in zip(y1, y2, y3)]\n    multi_timeseries.append(y)\n\n  return multi_timeseries"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef next_frame_sampling_stochastic():\n  hparams = basic_deterministic_params.next_frame_sampling()\n  hparams.stochastic_model = True\n  hparams.add_hparam(\"latent_channels\", 1)\n  hparams.add_hparam(\"latent_std_min\", -5.0)\n  hparams.add_hparam(\"num_iterations_1st_stage\", 15000)\n  hparams.add_hparam(\"num_iterations_2nd_stage\", 15000)\n  hparams.add_hparam(\"latent_loss_multiplier\", 1e-3)\n  hparams.add_hparam(\"latent_loss_multiplier_dynamic\", False)\n  hparams.add_hparam(\"latent_loss_multiplier_alpha\", 1e-5)\n  hparams.add_hparam(\"latent_loss_multiplier_epsilon\", 1.0)\n  hparams.add_hparam(\"latent_loss_multiplier_schedule\", \"constant\")\n  hparams.add_hparam(\"latent_num_frames\", 0)  # 0 means use all frames.\n  hparams.add_hparam(\"anneal_end\", 40000)\n  hparams.add_hparam(\"information_capacity\", 0.0)\n  return hparams", "response": "Basic 2 - frame conv model with stochastic tower."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef next_frame_stochastic_discrete_range(rhp):\n  rhp.set_float(\"learning_rate_constant\", 0.001, 0.01)\n  rhp.set_float(\"dropout\", 0.2, 0.6)\n  rhp.set_int(\"filter_double_steps\", 3, 5)\n  rhp.set_discrete(\"hidden_size\", [64, 96, 128])\n  rhp.set_discrete(\"bottleneck_bits\", [32, 64, 128, 256])\n  rhp.set_discrete(\"video_num_target_frames\", [4])\n  rhp.set_float(\"bottleneck_noise\", 0.0, 0.2)", "response": "Next frame stochastic discrete tuning grid."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmaps the function f to the nested structure x.", "response": "def nested_map(x, f):\n  \"\"\"Map the function f to the nested structure x (dicts, tuples, lists).\"\"\"\n  if isinstance(x, list):\n    return [nested_map(y, f) for y in x]\n  if isinstance(x, tuple):\n    return tuple([nested_map(y, f) for y in x])\n  if isinstance(x, dict):\n    return {k: nested_map(x[k], f) for k in x}\n  return f(x)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a structure of shapes for a structure of nested arrays.", "response": "def shapes(x):\n  \"\"\"Get a structure of shapes for a structure of nested arrays.\"\"\"\n  def shape(x):\n    try:\n      return x.shape\n    except Exception:  # pylint: disable=broad-except\n      return []\n  return nested_map(x, shape)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a structure of sizes for a structure of nested arrays.", "response": "def sizes(x):\n  \"\"\"Get a structure of sizes for a structure of nested arrays.\"\"\"\n  def size(x):\n    try:\n      return x.size\n    except Exception:  # pylint: disable=broad-except\n      return 0\n  return nested_map(x, size)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the frame with the caller on the stack.", "response": "def _find_frame(stack, start=0):\n  \"\"\"Find the frame with the caller on the stack.\"\"\"\n  # We want to find the first place where the layer was called\n  # that is *not* an __init__ function of an inheriting layer.\n  frame = inspect.getframeinfo(stack[start][0])\n  # If we are in an init, move on.\n  if frame.function == '__init__':\n    return _find_frame(stack, start + 1)\n  return frame"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _shorten_file_path(line):\n  start = line.lower().find('file')\n  if start < 0:\n    return line\n  first_quote = line.find('\"', start)\n  if first_quote < 0:\n    return line\n  second_quote = line.find('\"', first_quote + 1)\n  if second_quote < 0:\n    return line\n  path = line[first_quote + 1:second_quote]\n  new_path = '/'.join(path.split('/')[-3:])\n  return line[:first_quote] + '[...]/' + new_path + line[second_quote + 1:]", "response": "Shorten file path in error lines for more readable tracebacks."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncleans - up form of traceback.", "response": "def _short_traceback(skip=3):\n  \"\"\"Cleaned-up form of traceback.\"\"\"\n  counter, res = 0, []\n  # Skipping 3 lines by default: the top (useless) and self-call.\n  lines = traceback.format_exc().splitlines()[skip:]\n  for l in lines:\n    res.append(_shorten_file_path(l))\n    if counter % 2 == 1:\n      res.append('')\n    counter += 1\n    # If we see a LayerError, the traceback has already been processed.\n    if l.startswith('LayerError'):\n      # Skip 4 back except last as these are internal base-layer calls.\n      res = res[:-4] + [res[-1]]\n      res += lines[counter:]\n      break\n  return '\\n'.join(res)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef layer(output_shape=None, new_parameters=None):\n  def layer_decorator(call):\n    \"\"\"Decorating the call function.\"\"\"\n    def output_shape_fun(self, input_shape):\n      if output_shape is None:\n        return input_shape\n      kwargs = self._init_kwargs  # pylint: disable=protected-access\n      return output_shape(input_shape, **kwargs)\n\n    def new_parameters_fun(self, input_shape, rng):\n      if new_parameters is None:\n        return ()\n      kwargs = self._init_kwargs  # pylint: disable=protected-access\n      return new_parameters(input_shape, rng, **kwargs)\n\n    def call_fun(self, x, params=(), **kwargs):\n      \"\"\"The call function of the created class, derived from call.\"\"\"\n      # Merge on-call kwargs with class-kwargs.\n      call_kwargs = kwargs.copy()\n      call_kwargs.update(self._init_kwargs)  # pylint: disable=protected-access\n      # Call with the merged kwargs.\n      return call(x, params=params, **call_kwargs)\n\n    # Set doc for python help.\n    call_fun.__doc__ = call.__doc__\n    if output_shape is None:\n      output_shape_fun.__doc__ = output_shape.__doc__\n    if new_parameters is None:\n      new_parameters_fun.__doc__ = new_parameters.__doc__\n\n    # Create the class.\n    cls = type(call.__name__, (Layer,),\n               {'call': call_fun,\n                'output_shape': output_shape_fun,\n                'new_parameters': new_parameters_fun})\n\n    return cls\n  return layer_decorator", "response": "Create a layer class from a function."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef initialize(self, input_shape, rng):\n    try:\n      # Re-using this layer, no new parameters.\n      if not self._first_init:\n        return ()\n\n      # First call of this layer, create parameters.\n      self._first_init = False\n      self._params = self.new_parameters(input_shape, rng)\n      return self._params\n    except Exception:\n      name, trace = self.__class__.__name__, _short_traceback()\n      raise LayerError(name, 'initialize', self._caller, input_shape, trace)", "response": "Initialize the layer given an input shape and random number generator."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _references_content(ref_files):\n  example_spec = {\n      \"url\": tf.FixedLenFeature([], tf.string),\n      \"content\": tf.FixedLenFeature([], tf.string),\n  }\n  data = {}\n  for ex in generator_utils.tfrecord_iterator(\n      ref_files, gzipped=True, example_spec=example_spec):\n    data[ex[\"url\"]] = text_encoder.to_unicode(ex[\"content\"])\n  return data", "response": "Returns dict<str ref_url str ref_content >"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _wiki_urls_for_shard(shard_id, urls_dir=None):\n  urls_dir = urls_dir or WIKI_URLS_DIR\n  urls_filepath = os.path.join(urls_dir, WIKI_URLS_FILE % shard_id)\n  with tf.gfile.GFile(urls_filepath) as f:\n    return json.loads(f.read())", "response": "Urls for chunk: dict<str wiki_url, list<str> ref_urls>."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating WikipediaArticles from GCS that are part of shard shard_id.", "response": "def _wiki_articles(shard_id, wikis_dir=None):\n  \"\"\"Generates WikipediaArticles from GCS that are part of shard shard_id.\"\"\"\n  if not wikis_dir:\n    wikis_dir = WIKI_CONTENT_DIR\n  with tf.Graph().as_default():\n    dataset = tf.data.TFRecordDataset(\n        cc_utils.readahead(\n            os.path.join(wikis_dir, WIKI_CONTENT_FILE % shard_id)),\n        buffer_size=16 * 1000 * 1000)\n\n    def _parse_example(ex_ser):\n      \"\"\"Parse serialized Example containing Wikipedia article content.\"\"\"\n      features = {\n          \"url\": tf.VarLenFeature(tf.string),\n          \"title\": tf.VarLenFeature(tf.string),\n          \"section_titles\": tf.VarLenFeature(tf.string),\n          \"section_texts\": tf.VarLenFeature(tf.string),\n      }\n      ex = tf.parse_single_example(ex_ser, features)\n      for k in ex.keys():\n        ex[k] = ex[k].values\n      ex[\"url\"] = ex[\"url\"][0]\n      ex[\"title\"] = ex[\"title\"][0]\n      return ex\n\n    dataset = dataset.map(_parse_example, num_parallel_calls=32)\n    dataset = dataset.prefetch(100)\n    record_it = dataset.make_one_shot_iterator().get_next()\n\n    with tf.Session() as sess:\n      while True:\n        try:\n          ex = sess.run(record_it)\n        except tf.errors.OutOfRangeError:\n          break\n\n        sections = [\n            WikipediaSection(title=text_encoder.to_unicode(title),\n                             text=text_encoder.to_unicode(text))\n            for title, text in zip(ex[\"section_titles\"], ex[\"section_texts\"])\n        ]\n        yield WikipediaArticle(\n            url=text_encoder.to_unicode(ex[\"url\"]),\n            title=text_encoder.to_unicode(ex[\"title\"]),\n            sections=sections)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rank_reference_paragraphs(wiki_title, references_content, normalize=True):\n  normalized_title = _normalize_text(wiki_title)\n  title_tokens = _tokens_to_score(\n      set(tokenizer.encode(text_encoder.native_to_unicode(normalized_title))))\n  ref_paragraph_info = []\n  doc_counts = collections.defaultdict(int)\n  for ref in references_content:\n    for paragraph in ref.split(\"\\n\"):\n      normalized_paragraph = _normalize_text(paragraph)\n      if cc_utils.filter_paragraph(normalized_paragraph):\n        # Skip paragraph\n        continue\n      counts = _token_counts(normalized_paragraph, title_tokens)\n      for token in title_tokens:\n        if counts[token]:\n          doc_counts[token] += 1\n      content = normalized_paragraph if normalize else paragraph\n      info = {\"content\": content, \"counts\": counts}\n      ref_paragraph_info.append(info)\n\n  for info in ref_paragraph_info:\n    score = 0.\n    for token in title_tokens:\n      term_frequency = info[\"counts\"][token]\n      inv_doc_frequency = (\n          float(len(ref_paragraph_info)) / max(doc_counts[token], 1))\n      score += term_frequency * math.log(inv_doc_frequency)\n    info[\"score\"] = score\n\n  ref_paragraph_info.sort(key=lambda el: el[\"score\"], reverse=True)\n  return [info[\"content\"] for info in ref_paragraph_info]", "response": "Rank and return reference paragraphs by tf - idf score on title tokens."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nproducing examples from shard_ids to out_filepaths.", "response": "def produce_examples(shard_ids, wikis_dir, refs_dir, urls_dir, vocab_path,\n                     out_filepaths):\n  \"\"\"Produce examples from shard_ids to out_filepaths.\"\"\"\n  # * Join the Wikipedia articles with their references\n  # * Run Tf-idf to sort reference paragraphs\n  # * Encode the Wikipedia and reference text with the vocabulary\n  # * Write out TFRecords of tensorflow.Example\n  tf.logging.info(\"Processing %d input shards into %d output files.\",\n                  len(shard_ids), len(out_filepaths))\n\n  vocab = text_encoder.SubwordTextEncoder(vocab_path)\n  eot_ids = vocab.encode(EOT)\n\n  def example_generator():\n    \"\"\"Generate Example dicts.\"\"\"\n    stats = dict(total_original_wikis=0, total_original_refs=0,\n                 total_found_refs=0, ref_lengths=[], wiki_original_refs=[],\n                 wiki_found_refs=[], wikis_skipped_no_refs=0,\n                 wikis_skipped_short_lead=0, num_wikis_written=0)\n    ref_files_by_shard = _references_files_by_shard(refs_dir)\n    for shard_id in shard_ids:\n      tf.logging.info(\"Processing shard %d\", shard_id)\n      wiki_urls = _wiki_urls_for_shard(shard_id, urls_dir)\n      tf.logging.info(\"Loaded wiki URLs for shard\")\n      refs_content = _references_content(ref_files_by_shard[shard_id])\n      tf.logging.info(\"Loaded reference content for shard\")\n      for i, wiki in enumerate(_wiki_articles(shard_id, wikis_dir)):\n        if not i % 1000:\n          tf.logging.info(\"Processing wiki index %d for shard %d\", i, shard_id)\n        stats[\"total_original_wikis\"] += 1\n\n        # Get reference content\n        wiki_ref_content = []\n        ref_urls = wiki_urls[wiki.url][\"refs\"]\n        stats[\"total_original_refs\"] += len(ref_urls)\n        stats_wiki_original_refs = len(ref_urls)\n        stats_wiki_found_refs = 0\n        for ref_url in ref_urls:\n          ref_content = refs_content.get(ref_url)\n          if not ref_content:\n            continue\n          stats[\"total_found_refs\"] += 1\n          stats[\"ref_lengths\"].append(len(ref_content))\n          stats_wiki_found_refs += 1\n          wiki_ref_content.append(ref_content)\n\n        stats[\"wiki_original_refs\"].append(stats_wiki_original_refs)\n        stats[\"wiki_found_refs\"].append(stats_wiki_found_refs)\n        if not wiki_ref_content or len(wiki_ref_content) < _MIN_REFS:\n          # No/few refs were found\n          stats[\"wikis_skipped_no_refs\"] += 1\n          continue\n\n        # Rank reference paragraphs with TFIDF\n        wiki_title = _normalize_text(wiki.title)\n        ranked_paragraphs = rank_reference_paragraphs(wiki_title,\n                                                      wiki_ref_content)\n\n        # Construct inputs from Wiki title and references\n        inputs = []\n        inputs.extend(vocab.encode(wiki_title))\n        inputs.extend(eot_ids)\n        for paragraph in ranked_paragraphs:\n          if len(inputs) >= 1e6:\n            break\n          paragraph += \" \"\n          inputs.extend(vocab.encode(paragraph))\n\n        # Construct targets from article sections\n        targets, section_boundaries = _encode_wiki_sections(\n            wiki.sections, vocab)\n\n        # Skip if lead section is too short\n        if (not section_boundaries or\n            section_boundaries[0] < _MIN_LEADSECTION_TOKENS):\n          stats[\"wikis_skipped_short_lead\"] += 1\n          continue\n\n        inputs.append(text_encoder.EOS_ID)\n        targets.append(text_encoder.EOS_ID)\n\n        stats[\"num_wikis_written\"] += 1\n        yield {\n            \"inputs\": inputs,\n            \"targets\": targets,\n            \"section_boundaries\": section_boundaries,\n        }\n\n    tf.logging.info(\"Total: %d, Skipped: %d\",\n                    stats[\"num_wikis_written\"],\n                    stats[\"total_original_wikis\"] - stats[\"num_wikis_written\"])\n    tf.logging.info(\"Total refs: %d, Skipped refs: %d\",\n                    stats[\"total_found_refs\"],\n                    stats[\"total_original_refs\"] - stats[\"total_found_refs\"])\n    stats_fname = os.path.join(os.path.split(out_filepaths[0])[0],\n                               \"stats.%d.json\" % shard_ids[0])\n    with tf.gfile.Open(stats_fname, \"w\") as f:\n      f.write(json.dumps(stats))\n\n  generator_utils.generate_files(example_generator(), out_filepaths)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _encode_wiki_sections(sections, vocab):\n  ids = []\n  section_boundaries = []\n  for i, section in enumerate(sections):\n    if i > 0:\n      # Skip including article title\n      ids.extend(vocab.encode(_format_title(_normalize_text(section.title))))\n    ids.extend(vocab.encode(_normalize_text(section.text)))\n    section_boundaries.append(len(ids))\n\n  return ids, section_boundaries", "response": "Encodes sections with vocab. Returns ids and section boundaries."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract references from WET files into sharded output files.", "response": "def extract_references_from_wets(wet_files, metadata_dir, out_dir,\n                                 tmp_dir=None):\n  \"\"\"Extract references from WET files into sharded output files.\"\"\"\n  # Setup output files\n  shard_files = make_ref_shard_files(out_dir)\n\n  num_refs = 0\n  for i, wet_file in enumerate(wet_files):\n    num_refs_in_wet = 0\n    tf.logging.info(\"Processing file %d\", i)\n\n    # Read metadata file\n    metadata_fname = os.path.join(\n        metadata_dir, os.path.basename(wet_file)) + cc_utils.METADTA_SUFFIX\n    with tf.gfile.Open(cc_utils.readahead(metadata_fname)) as f:\n      wet_metadata = json.loads(f.read())\n\n    if not wet_metadata:\n      # No references in this WET file\n      continue\n\n    if wet_file.startswith(\"http\"):\n      # download\n      if not tmp_dir:\n        tmp_dir = tempfile.gettempdir()\n      record_gen = cc_utils.wet_records_from_url(wet_file, tmp_dir)\n    else:\n      # local\n      record_gen = cc_utils.wet_records_from_file_obj(\n          cc_utils.gzip_memfile(wet_file), take_ownership=True)\n\n    for wet_record in record_gen:\n      shard_ids = wet_metadata.get(wet_record.url)\n      if not shard_ids:\n        # URL not in dataset\n        continue\n\n      # Serialize and write out\n      ex = _make_example_from_record(wet_record)\n      ex_str = ex.SerializeToString()\n      for shard_id in shard_ids:\n        shard_files[shard_id].write(ex_str)\n      num_refs += 1\n      num_refs_in_wet += 1\n\n    tf.logging.info(\"Wrote out %d references for this WET\", num_refs_in_wet)\n\n  tf.logging.info(\"Wrote out %d references total\", num_refs)\n\n  # Cleanup\n  for shard_file in shard_files:\n    shard_file.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _dump_to_pages(dump):\n  pos = 0\n  ret = []\n  start_tag = u\"<page>\\n\"\n  end_tag = u\"</page>\\n\"\n  while True:\n    start_pos = dump.find(start_tag, pos)\n    if start_pos == -1:\n      break\n    start_pos += len(start_tag)\n    end_pos = dump.find(end_tag, start_pos)\n    if end_pos == -1:\n      break\n    ret.append(dump[start_pos:end_pos])\n    pos = end_pos + len(end_tag)\n  return ret", "response": "Extract pages from an xml dump.\n Returns a list of unicode strings\n Arguments : dump a unicode string\n  Returns : a list of unicode strings\n "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting the title from a page.", "response": "def _page_to_title(page):\n  \"\"\"Extract the title from a page.\n\n  Args:\n    page: a unicode string\n  Returns:\n    a unicode string\n  \"\"\"\n  # print(\"page=%s\" % page)\n  start_tag = u\"<title>\"\n  end_tag = u\"</title>\"\n  start_pos = page.find(start_tag)\n  end_pos = page.find(end_tag)\n  assert start_pos != -1\n  assert end_pos != -1\n  start_pos += len(start_tag)\n  return page[start_pos:end_pos]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting the text from a page.", "response": "def _page_to_text(page):\n  \"\"\"Extract the text from a page.\n\n  Args:\n    page: a unicode string\n  Returns:\n    a unicode string\n  \"\"\"\n  # text start tag looks like \"<text ..otherstuff>\"\n  start_pos = page.find(u\"<text\")\n  assert start_pos != -1\n  end_tag_pos = page.find(u\">\", start_pos)\n  assert end_tag_pos != -1\n  end_tag_pos += len(u\">\")\n  end_pos = page.find(u\"</text>\")\n  if end_pos == -1:\n    return u\"\"\n  return page[end_tag_pos:end_pos]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds and replace all occurrences of start_string and end_string.", "response": "def _find_and_replace(text, start_string, end_string, replace_fn):\n  \"\"\"Remove everything found between instances of start_string and end_string.\n\n  Replace each such instance with replace_fn(removed_text)\n\n  e.g. _find_and_replace(u\"the [[fat]] cat [[sat]]\", u\"[[\", u\"]]\", lambda x: x)\n    = u\"the fat cat sat\"\n\n  Args:\n    text: a unicode string\n    start_string: a unicode string\n    end_string: a unicode string\n    replace_fn: a unary function from unicode string to unicode string\n\n  Returns:\n    a string\n  \"\"\"\n  ret = u\"\"\n  current_pos = 0\n  while True:\n    start_pos = text.find(start_string, current_pos)\n    if start_pos == -1:\n      ret += text[current_pos:]\n      break\n    ret += text[current_pos:start_pos]\n    end_pos = text.find(end_string, start_pos + len(start_string))\n    if end_pos == -1:\n      break\n    ret += replace_fn(text[start_pos + len(start_string):end_pos])\n    current_pos = end_pos + len(end_string)\n  return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _remove_double_brackets(text):\n  def replacement_fn(s):\n    if u\":\" in s:\n      # this is probably a category or something like that.\n      return \"\"\n    # keep the part after the bar.\n    bar_pos = s.find(u\"|\")\n    if bar_pos == -1:\n      return s\n    return s[bar_pos + 1:]\n  return _find_and_replace(text, u\"[[\", u\"]]\", replacement_fn)", "response": "Remove double brackets and leave the viewable text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef image_encoder(image_feat,\n                  hparams,\n                  name=\"image_encoder\",\n                  save_weights_to=None,\n                  make_image_summary=True):\n  \"\"\"A stack of self attention layers.\"\"\"\n\n  x = image_feat\n  image_hidden_size = hparams.image_hidden_size or hparams.hidden_size\n  image_filter_size = hparams.image_filter_size or hparams.filter_size\n  with tf.variable_scope(name):\n    for layer in range(hparams.num_encoder_layers or hparams.num_hidden_layers):\n      with tf.variable_scope(\"layer_%d\" % layer):\n        with tf.variable_scope(\"self_attention\"):\n          y = vqa_layers.multihead_attention(\n              common_layers.layer_preprocess(x, hparams),\n              None,\n              None,\n              hparams.attention_key_channels or image_hidden_size,\n              hparams.attention_value_channels or image_hidden_size,\n              image_hidden_size,\n              hparams.num_heads,\n              hparams.attention_dropout,\n              attention_type=hparams.image_self_attention_type,\n              save_weights_to=save_weights_to,\n              make_image_summary=make_image_summary,\n              scale_dotproduct=hparams.scale_dotproduct,\n          )\n          utils.collect_named_outputs(\n              \"norms\", \"image_feat_self_attention_%d\"%(layer),\n              tf.norm(y, axis=-1))\n          x = common_layers.layer_postprocess(x, y, hparams)\n          utils.collect_named_outputs(\n              \"norms\", \"image_feat_self_attention_postprocess_%d\"%(layer),\n              tf.norm(x, axis=-1))\n        with tf.variable_scope(\"ffn\"):\n          y = common_layers.dense_relu_dense(\n              common_layers.layer_preprocess(x, hparams),\n              image_filter_size,\n              image_hidden_size,\n              dropout=hparams.relu_dropout,\n          )\n          utils.collect_named_outputs(\n              \"norms\", \"image_feat_ffn_%d\"%(layer), tf.norm(y, axis=-1))\n          x = common_layers.layer_postprocess(x, y, hparams)\n          utils.collect_named_outputs(\n              \"norms\", \"image_feat_ffn_postprocess_%d\"%(layer),\n              tf.norm(x, axis=-1))\n    # if normalization is done in layer_preprocess, then it should also be done\n    # on the output, since the output can grow very large, being the sum of\n    # a whole stack of unnormalized layer outputs.\n    return common_layers.layer_preprocess(x, hparams)", "response": "A stack of self - attention and fermipy - dense layers."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprepares question encoder. Args: inputs: a Tensor. hparams: run hyperparameters Returns: encoder_input: a Tensor, bottom of encoder stack encoder_self_attention_bias: a bias tensor for use in encoder self-attention", "response": "def prepare_question_encoder(inputs, hparams):\n  \"\"\"Prepare question encoder.\n\n  Args:\n    inputs: a Tensor.\n    hparams: run hyperparameters\n\n  Returns:\n    encoder_input: a Tensor, bottom of encoder stack\n    encoder_self_attention_bias: a bias tensor for use in encoder self-attention\n  \"\"\"\n  encoder_input = inputs\n  # Usual case - not a packed dataset.\n  encoder_padding = common_attention.embedding_to_padding(encoder_input)\n  ignore_padding = common_attention.attention_bias_ignore_padding(\n      encoder_padding)\n  encoder_self_attention_bias = ignore_padding\n  if hparams.pos == \"timing\":\n    encoder_input = common_attention.add_timing_signal_1d(encoder_input)\n  elif hparams.pos == \"emb\":\n    encoder_input = common_attention.add_positional_embedding(\n        encoder_input, hparams.max_length, \"inputs_positional_embedding\",\n        None)\n  return (encoder_input, encoder_self_attention_bias)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef question_encoder(question,\n                     question_self_attention_bias,\n                     hparams,\n                     name=\"question_encoder\",\n                     save_weights_to=None,\n                     make_image_summary=True):\n  \"\"\"A stack of self attention layers.\"\"\"\n  x = question\n  with tf.variable_scope(name):\n    for layer in range(hparams.num_encoder_layers or hparams.num_hidden_layers):\n      with tf.variable_scope(\"layer_%d\" % layer):\n        with tf.variable_scope(\"self_attention\"):\n          y = vqa_layers.multihead_attention(\n              common_layers.layer_preprocess(x, hparams),\n              None,\n              question_self_attention_bias,\n              hparams.attention_key_channels or hparams.hidden_size,\n              hparams.attention_value_channels or hparams.hidden_size,\n              hparams.hidden_size,\n              hparams.num_heads,\n              hparams.attention_dropout,\n              attention_type=hparams.question_self_attention_type,\n              block_length=hparams.block_length,\n              save_weights_to=save_weights_to,\n              make_image_summary=make_image_summary,\n              scale_dotproduct=hparams.scale_dotproduct,\n          )\n          utils.collect_named_outputs(\n              \"norms\", \"query_self_attention_%d\"%(layer),\n              tf.norm(y, axis=-1))\n          x = common_layers.layer_postprocess(x, y, hparams)\n          utils.collect_named_outputs(\n              \"norms\", \"query_self_attention_postprocess_%d\"%(layer),\n              tf.norm(x, axis=-1))\n        with tf.variable_scope(\"ffn\"):\n          y = common_layers.dense_relu_dense(\n              common_layers.layer_preprocess(x, hparams),\n              hparams.filter_size,\n              hparams.hidden_size,\n              dropout=hparams.relu_dropout,\n              )\n          utils.collect_named_outputs(\n              \"norms\", \"query_ffn_%d\"%(layer), tf.norm(y, axis=-1))\n          x = common_layers.layer_postprocess(x, y, hparams)\n          utils.collect_named_outputs(\n              \"norms\", \"query_ffn_postprocess_%d\"%(layer),\n              tf.norm(x, axis=-1))\n    # if normalization is done in layer_preprocess, then it should also be done\n    # on the output, since the output can grow very large, being the sum of\n    # a whole stack of unnormalized layer outputs.\n    return common_layers.layer_preprocess(x, hparams)", "response": "A stack of self - attention and ferminal encoder layers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mlp(feature, hparams, name=\"mlp\"):\n  with tf.variable_scope(name, \"mlp\", values=[feature]):\n    num_mlp_layers = hparams.num_mlp_layers\n    mlp_size = hparams.mlp_size\n    for _ in range(num_mlp_layers):\n      feature = common_layers.dense(feature, mlp_size, activation=None)\n      utils.collect_named_outputs(\"norms\", \"mlp_feature\",\n                                  tf.norm(feature, axis=-1))\n      feature = common_layers.layer_norm(feature)\n      feature = tf.nn.relu(feature)\n      feature = tf.nn.dropout(feature, keep_prob=1.-hparams.dropout)\n    return feature", "response": "Multi layer perceptron with dropout and relu activation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npreparing encoder. Args: image_feat: a Tensor. question: a Tensor. hparams: run hyperparameters Returns: encoder_input: a Tensor, bottom of encoder stack encoder_self_attention_bias: a bias tensor for use in encoder self-attention", "response": "def prepare_image_question_encoder(image_feat, question, hparams):\n  \"\"\"Prepare encoder.\n\n  Args:\n    image_feat: a Tensor.\n    question: a Tensor.\n    hparams: run hyperparameters\n\n  Returns:\n    encoder_input: a Tensor, bottom of encoder stack\n    encoder_self_attention_bias: a bias tensor for use in encoder self-attention\n  \"\"\"\n\n  encoder_input = tf.concat([image_feat, question], axis=1)\n  encoder_padding = common_attention.embedding_to_padding(encoder_input)\n  ignore_padding = common_attention.attention_bias_ignore_padding(\n      encoder_padding)\n  encoder_self_attention_bias = ignore_padding\n  encoder_decoder_attention_bias = ignore_padding\n  # Usual case - not a packed dataset.\n  if hparams.pos == \"timing\":\n    question = common_attention.add_timing_signal_1d(question)\n  elif hparams.pos == \"emb\":\n    question = common_attention.add_positional_embedding(\n        question, hparams.max_length, \"inputs_positional_embedding\",\n        None)\n  encoder_input = tf.concat([image_feat, question], axis=1)\n\n  return (encoder_input, encoder_self_attention_bias,\n          encoder_decoder_attention_bias)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef image_question_encoder(encoder_inputs,\n                           encoder_self_attention_bias,\n                           hparams,\n                           query=None,\n                           name=\"image_question_encoder\",\n                           save_weights_to=None,\n                           make_image_summary=True):\n  \"\"\"A stack of self attention layers.\"\"\"\n  x = encoder_inputs\n  with tf.variable_scope(name):\n    for layer in range(hparams.num_encoder_layers or hparams.num_hidden_layers):\n      with tf.variable_scope(\"layer_%d\" % layer):\n        with tf.variable_scope(\"self_attention\"):\n          y = vqa_layers.multihead_attention(\n              common_layers.layer_preprocess(x, hparams),\n              None,\n              encoder_self_attention_bias,\n              hparams.attention_key_channels or hparams.hidden_size,\n              hparams.attention_value_channels or hparams.hidden_size,\n              hparams.hidden_size,\n              hparams.num_heads,\n              hparams.attention_dropout,\n              attention_type=hparams.self_attention_type,\n              block_length=hparams.block_length,\n              save_weights_to=save_weights_to,\n              make_image_summary=make_image_summary,\n              scale_dotproduct=hparams.scale_dotproduct,\n          )\n          utils.collect_named_outputs(\n              \"norms\", \"encoder_self_attention_%d\"%(layer),\n              tf.norm(y, axis=-1))\n          x = common_layers.layer_postprocess(x, y, hparams)\n          utils.collect_named_outputs(\n              \"norms\", \"encoder_self_attention_postprocess_%d\"%(layer),\n              tf.norm(x, axis=-1))\n        if query is not None:\n          with tf.variable_scope(\"encdec_attention\"):\n            y = common_attention.multihead_attention(\n                common_layers.layer_preprocess(x, hparams),\n                query,\n                None,\n                hparams.attention_key_channels or hparams.hidden_size,\n                hparams.attention_value_channels or hparams.hidden_size,\n                hparams.hidden_size,\n                hparams.num_heads,\n                hparams.attention_dropout,\n                attention_type=hparams.self_attention_type,\n                block_length=hparams.block_length,\n                save_weights_to=save_weights_to,\n                make_image_summary=make_image_summary,\n                scale_dotproduct=hparams.scale_dotproduct,\n            )\n            utils.collect_named_outputs(\n                \"norms\",\n                \"encoder_decoder_attention_%d\"%(layer),\n                tf.norm(y, axis=-1))\n            x = common_layers.layer_postprocess(x, y, hparams)\n            utils.collect_named_outputs(\n                \"norms\",\n                \"encoder_decoder_attention_post_%d\"%(layer),\n                tf.norm(x, axis=-1))\n        with tf.variable_scope(\"ffn\"):\n          y = common_layers.dense_relu_dense(\n              common_layers.layer_preprocess(x, hparams),\n              hparams.filter_size,\n              hparams.hidden_size,\n              dropout=hparams.relu_dropout,\n              )\n          utils.collect_named_outputs(\n              \"norms\", \"encoder_ffn_%d\"%(layer), tf.norm(y, axis=-1))\n          x = common_layers.layer_postprocess(x, y, hparams)\n          utils.collect_named_outputs(\n              \"norms\", \"encoder_ffn_postprocess_%d\"%(layer),\n              tf.norm(x, axis=-1))\n    # if normalization is done in layer_preprocess, then it should also be done\n    # on the output, since the output can grow very large, being the sum of\n    # a whole stack of unnormalized layer outputs.\n    return common_layers.layer_preprocess(x, hparams)", "response": "A stack of self - attention layers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef decoder(decoder_input,\n            encoder_output,\n            decoder_self_attention_bias,\n            encoder_decoder_attention_bias,\n            hparams,\n            name=\"decoder\",\n            save_weights_to=None,\n            make_image_summary=True,):\n  \"\"\"A stack of transformer layers.\n\n  Args:\n    decoder_input: a Tensor\n    encoder_output: a Tensor\n    decoder_self_attention_bias: bias Tensor for self-attention\n      (see common_attention.attention_bias())\n    encoder_decoder_attention_bias: bias Tensor for encoder-decoder attention\n      (see common_attention.attention_bias())\n    hparams: hyperparameters for model\n    name: a string\n    save_weights_to: an optional dictionary to capture attention weights\n      for visualization; the weights tensor will be appended there under\n      a string key created from the variable scope (including name).\n    make_image_summary: Whether to make an attention image summary.\n\n  Returns:\n    y: a Tensors\n  \"\"\"\n  x = decoder_input\n  with tf.variable_scope(name):\n    for layer in range(hparams.num_decoder_layers or hparams.num_hidden_layers):\n      layer_name = \"layer_%d\" % layer\n      with tf.variable_scope(layer_name):\n        with tf.variable_scope(\"self_attention\"):\n          y = common_attention.multihead_attention(\n              common_layers.layer_preprocess(x, hparams),\n              None,\n              decoder_self_attention_bias,\n              hparams.attention_key_channels or hparams.hidden_size,\n              hparams.attention_value_channels or hparams.hidden_size,\n              hparams.hidden_size,\n              hparams.num_heads,\n              hparams.attention_dropout,\n              attention_type=hparams.self_attention_type,\n              save_weights_to=save_weights_to,\n              make_image_summary=make_image_summary,\n              )\n          utils.collect_named_outputs(\"norms\",\n                                      \"decoder_self_attention_%d\"%(layer),\n                                      tf.norm(y, axis=-1))\n          x = common_layers.layer_postprocess(x, y, hparams)\n          utils.collect_named_outputs(\"norms\",\n                                      \"decoder_self_attention_post_%d\"%(layer),\n                                      tf.norm(x, axis=-1))\n        if encoder_output is not None:\n          with tf.variable_scope(\"encdec_attention\"):\n            y = common_attention.multihead_attention(\n                common_layers.layer_preprocess(x, hparams),\n                encoder_output,\n                encoder_decoder_attention_bias,\n                hparams.attention_key_channels or hparams.hidden_size,\n                hparams.attention_value_channels or hparams.hidden_size,\n                hparams.hidden_size,\n                hparams.num_heads,\n                hparams.attention_dropout,\n                save_weights_to=save_weights_to,\n                make_image_summary=make_image_summary,\n                )\n            utils.collect_named_outputs(\n                \"norms\",\n                \"decoder_encoder_attention_%d\"%(layer),\n                tf.norm(y, axis=-1))\n            x = common_layers.layer_postprocess(x, y, hparams)\n            utils.collect_named_outputs(\n                \"norms\",\n                \"decoder_encoder_attention_post_%d\"%(layer),\n                tf.norm(x, axis=-1))\n        with tf.variable_scope(\"ffn\"):\n          y = common_layers.dense_relu_dense(\n              common_layers.layer_preprocess(x, hparams),\n              hparams.filter_size,\n              hparams.hidden_size,\n              dropout=hparams.relu_dropout,\n          )\n          utils.collect_named_outputs(\"norms\", \"decoder_ffn_%d\"%(layer),\n                                      tf.norm(y, axis=-1))\n          x = common_layers.layer_postprocess(x, y, hparams)\n          utils.collect_named_outputs(\"norms\", \"decoder_ffn_post_%d\"%(layer),\n                                      tf.norm(x, axis=-1))\n    # if normalization is done in layer_preprocess, then it should also be done\n    # on the output, since the output can grow very large, being the sum of\n    # a whole stack of unnormalized layer outputs.\n    return common_layers.layer_preprocess(x, hparams)", "response": "A stack of transformer layers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef batching_scheme(batch_size,\n                    max_length,\n                    min_length_bucket,\n                    length_bucket_step,\n                    drop_long_sequences=False,\n                    shard_multiplier=1,\n                    length_multiplier=1,\n                    min_length=0):\n  \"\"\"A batching scheme based on model hyperparameters.\n\n  Every batch contains a number of sequences divisible by `shard_multiplier`.\n\n  Args:\n    batch_size: int, total number of tokens in a batch.\n    max_length: int, sequences longer than this will be skipped. Defaults to\n      batch_size.\n    min_length_bucket: int\n    length_bucket_step: float greater than 1.0\n    drop_long_sequences: bool, if True, then sequences longer than\n      `max_length` are dropped.  This prevents generating batches with\n      more than the usual number of tokens, which can cause out-of-memory\n      errors.\n    shard_multiplier: an integer increasing the batch_size to suit splitting\n      across datashards.\n    length_multiplier: an integer multiplier that is used to increase the\n      batch sizes and sequence length tolerance.\n    min_length: int, sequences shorter than this will be skipped.\n\n  Returns:\n     A dictionary with parameters that can be passed to input_pipeline:\n       * boundaries: list of bucket boundaries\n       * batch_sizes: list of batch sizes for each length bucket\n       * max_length: int, maximum length of an example\n\n  Raises:\n    ValueError: If min_length > max_length\n  \"\"\"\n  max_length = max_length or batch_size\n  if max_length < min_length:\n    raise ValueError(\"max_length must be greater or equal to min_length\")\n\n  boundaries = _bucket_boundaries(max_length, min_length_bucket,\n                                  length_bucket_step)\n  boundaries = [boundary * length_multiplier for boundary in boundaries]\n  max_length *= length_multiplier\n\n  batch_sizes = [\n      max(1, batch_size // length) for length in boundaries + [max_length]\n  ]\n  max_batch_size = max(batch_sizes)\n  # Since the Datasets API only allows a single constant for window_size,\n  # and it needs divide all bucket_batch_sizes, we pick a highly-composite\n  # window size and then round down all batch sizes to divisors of that window\n  # size, so that a window can always be divided evenly into batches.\n  # TODO(noam): remove this when Dataset API improves.\n  highly_composite_numbers = [\n      1, 2, 4, 6, 12, 24, 36, 48, 60, 120, 180, 240, 360, 720, 840, 1260, 1680,\n      2520, 5040, 7560, 10080, 15120, 20160, 25200, 27720, 45360, 50400, 55440,\n      83160, 110880, 166320, 221760, 277200, 332640, 498960, 554400, 665280,\n      720720, 1081080, 1441440, 2162160, 2882880, 3603600, 4324320, 6486480,\n      7207200, 8648640, 10810800, 14414400, 17297280, 21621600, 32432400,\n      36756720, 43243200, 61261200, 73513440, 110270160\n  ]\n  window_size = max(\n      [i for i in highly_composite_numbers if i <= 3 * max_batch_size])\n  divisors = [i for i in range(1, window_size + 1) if window_size % i == 0]\n  batch_sizes = [max([d for d in divisors if d <= bs]) for bs in batch_sizes]\n  window_size *= shard_multiplier\n  batch_sizes = [bs * shard_multiplier for bs in batch_sizes]\n  # The Datasets API splits one window into multiple batches, which\n  # produces runs of many consecutive batches of the same size.  This\n  # is bad for training.  To solve this, we will shuffle the batches\n  # using a queue which must be several times as large as the maximum\n  # number of batches per window.\n  max_batches_per_window = window_size // min(batch_sizes)\n  shuffle_queue_size = max_batches_per_window * 3\n\n  ret = {\n      \"boundaries\": boundaries,\n      \"batch_sizes\": batch_sizes,\n      \"min_length\": min_length,\n      \"max_length\": (max_length if drop_long_sequences else 10**9),\n      \"shuffle_queue_size\": shuffle_queue_size,\n  }\n  return ret", "response": "A batching scheme based on model hyperparameters."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwraps around _batching_scheme with hparams.", "response": "def hparams_to_batching_scheme(hparams,\n                               drop_long_sequences=False,\n                               shard_multiplier=1,\n                               length_multiplier=1):\n  \"\"\"Wrapper around _batching_scheme with hparams.\"\"\"\n  return batching_scheme(\n      batch_size=hparams.batch_size,\n      min_length=hparams.min_length,\n      max_length=hparams.max_length,\n      min_length_bucket=hparams.min_length_bucket,\n      length_bucket_step=hparams.length_bucket_step,\n      drop_long_sequences=drop_long_sequences,\n      shard_multiplier=shard_multiplier,\n      length_multiplier=length_multiplier)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npad unknown features dimensions for TPU.", "response": "def pad_for_tpu(shapes_dict, hparams, max_length):\n  \"\"\"Pads unknown features' dimensions for TPU.\"\"\"\n  padded_shapes = {}\n\n  def get_filler(specified_max_length):\n    if not specified_max_length:\n      return max_length\n    return min(specified_max_length, max_length)\n\n  inputs_none_filler = get_filler(hparams.max_input_seq_length)\n  targets_none_filler = get_filler(hparams.max_target_seq_length)\n\n  def pad_one_shape(shape, none_filler):\n    return [\n        (dim if dim is not None else none_filler) for dim in shape.as_list()\n    ]\n\n  for key, shape in six.iteritems(shapes_dict):\n    if key == \"inputs\":\n      padded_shapes[key] = pad_one_shape(shape, inputs_none_filler)\n    elif key == \"targets\":\n      padded_shapes[key] = pad_one_shape(shape, targets_none_filler)\n    else:\n      padded_shapes[key] = pad_one_shape(shape, max_length)\n  return padded_shapes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef standardize_shapes(features, batch_size=None):\n  for fname in [\"inputs\", \"targets\"]:\n    if fname not in features:\n      continue\n    f = features[fname]\n    while len(f.get_shape()) < 4:\n      f = tf.expand_dims(f, axis=-1)\n    features[fname] = f\n\n  if batch_size:\n    # Ensure batch size is set on all features\n    for _, t in six.iteritems(features):\n      shape = t.get_shape().as_list()\n      shape[0] = batch_size\n      t.set_shape(t.get_shape().merge_with(shape))\n      # Assert shapes are fully known\n      t.get_shape().assert_is_fully_defined()\n\n  return features", "response": "Set the right shapes for the features."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the number of TFRecords in a file.", "response": "def _file_num_records_cached(filename):\n  \"\"\"Return the number of TFRecords in a file.\"\"\"\n  # Cache the result, as this is expensive to compute\n  if filename in _file_num_records_cache:\n    return _file_num_records_cache[filename]\n  ret = 0\n  for _ in tf.python_io.tf_record_iterator(filename):\n    ret += 1\n  _file_num_records_cache[filename] = ret\n  return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npad batch dim of features to nearest multiple of batch_multiple.", "response": "def pad_batch(features, batch_multiple):\n  \"\"\"Pad batch dim of features to nearest multiple of batch_multiple.\"\"\"\n  feature = list(features.items())[0][1]\n  batch_size = tf.shape(feature)[0]\n  mod = batch_size % batch_multiple\n  has_mod = tf.cast(tf.cast(mod, tf.bool), tf.int32)\n  batch_padding = batch_multiple * has_mod - mod\n\n  padded_features = {}\n  for k, feature in features.items():\n    rank = len(feature.shape)\n    paddings = [[0, 0] for _ in range(rank)]\n    paddings[0][1] = batch_padding\n    padded_feature = tf.pad(feature, paddings)\n    padded_features[k] = padded_feature\n  return padded_features"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild input function for the input problem.", "response": "def input_fn(dataset,\n             filepattern,\n             skip_random_fraction_when_training,\n             batch_size_means_tokens_param,\n             batch_size_multiplier,\n             max_length,\n             mode,\n             hparams,\n             data_dir=None,\n             params=None,\n             config=None,\n             force_repeat=False,\n             prevent_repeat=False):\n  \"\"\"Builds input pipeline for problem.\n\n  Args:\n    dataset: the dataset to make input function from.\n    filepattern: the pattern of files to read from.\n    skip_random_fraction_when_training: whether to skip randomly when training.\n    batch_size_means_tokens_param: whether batch size should mean tokens.\n    batch_size_multiplier: how to multiply batch size when bucketing.\n    max_length: maximum length,\n    mode: tf.estimator.ModeKeys\n    hparams: HParams, model hparams\n    data_dir: str, data directory; if None, will use hparams.data_dir\n    params: dict, may include \"batch_size\"\n    config: RunConfig; should have the data_parallelism attribute if not using\n      TPU\n    force_repeat: bool, whether to repeat the data even if not training\n    prevent_repeat: bool, whether to not repeat when in training mode.\n      Overrides force_repeat.\n\n  Returns:\n    (features_dict<str name, Tensor feature>, Tensor targets)\n  \"\"\"\n  is_training = mode == tf.estimator.ModeKeys.TRAIN\n  if config and config.use_tpu:\n    num_threads = 64\n  else:\n    num_threads = cpu_count() if is_training else 1\n\n  if config and hasattr(config,\n                        \"data_parallelism\") and config.data_parallelism:\n    num_shards = config.data_parallelism.n\n  else:\n    num_shards = 1\n\n  mlperf_log.transformer_print(\n      key=mlperf_log.INPUT_MAX_LENGTH, value=max_length)\n\n  def tpu_valid_size(example):\n    return example_valid_size(example, hparams.min_length, max_length)\n\n  def gpu_valid_size(example):\n    drop_long_sequences = is_training or hparams.eval_drop_long_sequences\n    max_validate_length = max_length if drop_long_sequences else 10**9\n    return example_valid_size(example, hparams.min_length, max_validate_length)\n\n  def define_shapes(example):\n    batch_size = config and config.use_tpu and params[\"batch_size\"]\n    return standardize_shapes(example, batch_size=batch_size)\n\n  # Read and preprocess\n  data_dir = data_dir or (hasattr(hparams, \"data_dir\") and hparams.data_dir)\n\n  if (force_repeat or is_training) and not prevent_repeat:\n    # Repeat and skip a random number of records\n    dataset = dataset.repeat()\n\n  if is_training and skip_random_fraction_when_training:\n    data_files = tf.contrib.slim.parallel_reader.get_data_files(filepattern)\n    #  In continuous_train_and_eval when switching between train and\n    #  eval, this input_fn method gets called multiple times and it\n    #  would give you the exact same samples from the last call\n    #  (because the Graph seed is set). So this skip gives you some\n    #  shuffling.\n    dataset = skip_random_fraction(dataset, data_files[0])\n\n  dataset = dataset.map(cast_ints_to_int32, num_parallel_calls=num_threads)\n\n  if batch_size_means_tokens_param:\n    batch_size_means_tokens = True\n  else:\n    if _are_shapes_fully_defined(dataset.output_shapes):\n      batch_size_means_tokens = False\n    else:\n      tf.logging.warning(\n          \"Shapes are not fully defined. Assuming batch_size means tokens.\")\n      batch_size_means_tokens = True\n\n  # Batching\n  if not batch_size_means_tokens:\n    # Batch size means examples per datashard.\n    if config and config.use_tpu:\n      # on TPU, we use params[\"batch_size\"], which specifies the number of\n      # examples across all datashards\n      batch_size = params[\"batch_size\"]\n      dataset = dataset.batch(batch_size, drop_remainder=True)\n    else:\n      batch_size = hparams.batch_size * num_shards\n      dataset = dataset.batch(batch_size)\n  else:\n    # batch_size means tokens per datashard\n    if config and config.use_tpu:\n      dataset = dataset.filter(tpu_valid_size)\n      padded_shapes = pad_for_tpu(dataset.output_shapes, hparams, max_length)\n      # on TPU, we use params[\"batch_size\"], which specifies the number of\n      # examples across all datashards\n      batch_size = params[\"batch_size\"]\n      if hparams.pad_batch:\n        tf.logging.warn(\n            \"Padding the batch to ensure that remainder eval batches are \"\n            \"processed. This may lead to incorrect metrics for \"\n            \"non-zero-padded features, e.g. images. Use a smaller batch \"\n            \"size that has no remainder in that case.\")\n        dataset = dataset.padded_batch(\n            batch_size, padded_shapes, drop_remainder=False)\n        dataset = dataset.map(\n            functools.partial(pad_batch, batch_multiple=batch_size),\n            num_parallel_calls=num_threads)\n      else:\n        dataset = dataset.padded_batch(\n            batch_size, padded_shapes, drop_remainder=True)\n    else:\n      # On GPU, bucket by length\n      dataset = dataset.filter(gpu_valid_size)\n      cur_batching_scheme = hparams_to_batching_scheme(\n          hparams,\n          shard_multiplier=num_shards,\n          length_multiplier=batch_size_multiplier)\n      if hparams.use_fixed_batch_size:\n        # Here  batch_size really means examples per datashard.\n        cur_batching_scheme[\"batch_sizes\"] = [hparams.batch_size]\n        cur_batching_scheme[\"boundaries\"] = []\n      dataset = dataset.apply(\n          tf.data.experimental.bucket_by_sequence_length(\n              example_length, cur_batching_scheme[\"boundaries\"],\n              cur_batching_scheme[\"batch_sizes\"]))\n\n      if not is_training:\n        batch_multiple = num_shards\n        if hparams.use_fixed_batch_size:\n          # Make sure the last batch has the same fixed size as the rest.\n          batch_multiple *= hparams.batch_size\n        if batch_multiple > 1:\n          tf.logging.warn(\n              \"Padding the batch to ensure that remainder eval batches have \"\n              \"a batch size divisible by the number of data shards. This may \"\n              \"lead to incorrect metrics for non-zero-padded features, e.g. \"\n              \"images. Use a single datashard (i.e. 1 GPU) in that case.\")\n          dataset = dataset.map(\n              functools.partial(pad_batch, batch_multiple=batch_multiple),\n              num_parallel_calls=num_threads)\n\n  dataset = dataset.map(define_shapes, num_parallel_calls=num_threads)\n\n  # Add shuffling for training batches. This is necessary along with record\n  # level shuffling in the dataset generation. Record shuffling will shuffle\n  # the examples. However, in some cases, it's possible that the shuffle\n  # buffer size for record shuffling is smaller than the batch size. In such\n  # cases, adding batch shuffling ensures that the data is in random order\n  # during training\n  if (is_training and hasattr(hparams, \"batch_shuffle_size\") and\n      hparams.batch_shuffle_size):\n    dataset = dataset.shuffle(hparams.batch_shuffle_size)\n\n  # Split batches into chunks if targets are too long.\n  # The new \"chunk_number\" feature is 0 for the first chunk and goes up then.\n  # Chunks are reversed so the 0th chunk comes first, then the 1st and so on,\n  # so models can attend to them in the order they arrive. The last chunk is\n  # usually the one containing the end of the target sentence (EOS).\n  chunk_length = hparams.get(\"split_targets_chunk_length\", 0)\n  max_chunks = hparams.get(\"split_targets_max_chunks\", 100)\n  if chunk_length > 0:\n    def is_nonzero_chunk(example):\n      \"\"\"A chunk is zero if all targets are 0s.\"\"\"\n      return tf.less(0, tf.reduce_sum(tf.abs(example[\"targets\"])))\n\n    def split_on_length(example):\n      \"\"\"Split a batch of ditcs on length.\"\"\"\n      x = example[\"targets\"]\n      # TODO(kitaev): This code breaks if chunk_length * max_chunks < batch_size\n      length_diff = chunk_length * max_chunks - tf.shape(x)[1]\n      padded_x = tf.pad(x, [(0, 0), (0, length_diff), (0, 0), (0, 0)])\n      chunks = [padded_x[:, i*chunk_length:(i+1)*chunk_length, :, :]\n                for i in range(max_chunks - 1)]\n      chunks.append(padded_x[:, (max_chunks - 1)*chunk_length:, :, :])\n      new_example = {}\n      # Setting chunk_number to be tf.range(max_chunks) is incompatible with TPU\n      new_example[\"chunk_number\"] = tf.concat([\n          tf.expand_dims(tf.ones_like(c) * n, axis=0)\n          for n, c in enumerate(chunks)\n      ],\n                                              axis=0)\n      new_example[\"targets\"] = tf.concat(\n          [tf.expand_dims(c, axis=0) for c in chunks], axis=0)\n      for k in example:\n        if k != \"targets\":\n          assert k != \"chunk_number\", (\n              \"Chunking code expects the chunk_number feature name to be \"\n              \"available\"\n          )\n          new_example[k] = tf.concat(\n              [tf.expand_dims(example[k], axis=0) for _ in range(max_chunks)],\n              axis=0)\n      return tf.data.Dataset.from_tensor_slices(new_example)\n\n    dataset = dataset.flat_map(split_on_length)\n    dataset = dataset.filter(is_nonzero_chunk)\n\n    # The chunking data pipeline thus far creates batches of examples where all\n    # of the examples have the same chunk number. This can lead to periodic\n    # fluctuations in the loss; for example, when all examples in the batch have\n    # chunk number 0 the loss may be higher than midway through a sequence.\n    # Enabling split_targets_strided_training adjusts the data so that each\n    # batch includes examples at various points within a sequence.\n    if is_training and hparams.split_targets_strided_training:\n      # TODO(kitaev): make sure that shape inference works on GPU, not just TPU.\n      inferred_batch_size = dataset.output_shapes[\"targets\"].as_list()[0]\n      if inferred_batch_size is None:\n        raise ValueError(\n            \"Strided training is only implemented when the batch size can be \"\n            \"inferred statically, for example when training on TPU.\"\n        )\n      chunk_stride = inferred_batch_size * max(\n          1, max_chunks // inferred_batch_size) + 1\n\n      def collapse_nested_datasets(example):\n        \"\"\"Converts a dataset of datasets to a dataset of tensor features.\"\"\"\n        new_example = {}\n        for k, v in example.items():\n          v = tf.data.experimental.get_single_element(\n              v.batch(inferred_batch_size, drop_remainder=True))\n          new_example[k] = v\n        return tf.data.Dataset.from_tensor_slices(new_example)\n\n      dataset = dataset.apply(tf.data.experimental.unbatch())\n      dataset = dataset.window(inferred_batch_size, inferred_batch_size,\n                               chunk_stride)\n      dataset = dataset.flat_map(collapse_nested_datasets)\n      dataset = dataset.batch(inferred_batch_size, drop_remainder=True)\n\n  def prepare_for_output(example):\n    if not config or not config.use_tpu:\n      _summarize_features(example, num_shards)\n    if mode == tf.estimator.ModeKeys.PREDICT:\n      example[\"infer_targets\"] = example.pop(\"targets\")\n      return example\n    else:\n      return example, example[\"targets\"]\n\n  dataset = dataset.map(prepare_for_output, num_parallel_calls=num_threads)\n  dataset = dataset.prefetch(2)\n\n  if mode == tf.estimator.ModeKeys.PREDICT:\n    # This is because of a bug in the Estimator that short-circuits prediction\n    # if it doesn't see a QueueRunner. DummyQueueRunner implements the\n    # minimal expected interface but does nothing.\n    tf.add_to_collection(tf.GraphKeys.QUEUE_RUNNERS, DummyQueueRunner())\n\n  return dataset"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate start and end indices per outfile.", "response": "def generate_shard_args(outfiles, num_examples):\n  \"\"\"Generate start and end indices per outfile.\"\"\"\n  num_shards = len(outfiles)\n  num_examples_per_shard = num_examples // num_shards\n  start_idxs = [i * num_examples_per_shard for i in range(num_shards)]\n  end_idxs = list(start_idxs)\n  end_idxs.pop(0)\n  end_idxs.append(num_examples)\n  return zip(start_idxs, end_idxs, outfiles)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates example dicts for a dataset.", "response": "def dataset_generator(filepath,\n                      dataset,\n                      chunk_size=1,\n                      start_idx=None,\n                      end_idx=None):\n  \"\"\"Generate example dicts.\"\"\"\n  encoder = dna_encoder.DNAEncoder(chunk_size=chunk_size)\n  with h5py.File(filepath, \"r\") as h5_file:\n    # Get input keys from h5_file\n    src_keys = [s % dataset for s in [\"%s_in\", \"%s_na\", \"%s_out\"]]\n    src_values = [h5_file[k] for k in src_keys]\n    inp_data, mask_data, out_data = src_values\n    assert len(set([v.len() for v in src_values])) == 1\n\n    if start_idx is None:\n      start_idx = 0\n    if end_idx is None:\n      end_idx = inp_data.len()\n\n    for i in range(start_idx, end_idx):\n      if i % 100 == 0:\n        print(\"Generating example %d for %s\" % (i, dataset))\n      inputs, mask, outputs = inp_data[i], mask_data[i], out_data[i]\n      ex_dict = to_example_dict(encoder, inputs, mask, outputs)\n      # Original data has one output for every 128 input bases. Ensure that the\n      # ratio has been maintained given the chunk size and removing EOS.\n      assert (len(ex_dict[\"inputs\"]) - 1) == ((\n          128 // chunk_size) * ex_dict[\"targets_shape\"][0])\n      yield ex_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_example_dict(encoder, inputs, mask, outputs):\n  # Inputs\n  bases = []\n  input_ids = []\n  last_idx = -1\n  for row in np.argwhere(inputs):\n    idx, base_id = row\n    idx, base_id = int(idx), int(base_id)\n    assert idx > last_idx  # if not, means 2 True values in 1 row\n    # Some rows are all False. Those rows are mapped to UNK_ID.\n    while idx != last_idx + 1:\n      bases.append(encoder.UNK)\n      last_idx += 1\n    bases.append(encoder.BASES[base_id])\n    last_idx = idx\n  assert len(inputs) == len(bases)\n\n  input_ids = encoder.encode(bases)\n  input_ids.append(text_encoder.EOS_ID)\n\n  # Targets: mask and output\n  targets_mask = [float(v) for v in mask]\n  # The output is (n, m); store targets_shape so that it can be reshaped\n  # properly on the other end.\n  targets = [float(v) for v in outputs.flatten()]\n  targets_shape = [int(dim) for dim in outputs.shape]\n  assert mask.shape[0] == outputs.shape[0]\n\n  example_keys = [\"inputs\", \"targets_mask\", \"targets\", \"targets_shape\"]\n  ex_dict = dict(\n      zip(example_keys, [input_ids, targets_mask, targets, targets_shape]))\n  return ex_dict", "response": "Convert a single h5 record to an example dict."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef linear_interpolate_rank(tensor1, tensor2, coeffs, rank=1):\n  # sum across space, max across channels.\n  _, _, _, num_channels = common_layers.shape_list(tensor1)\n  diff_sq_sum = tf.reduce_sum((tensor1 - tensor2)**2, axis=(0, 1, 2))\n  _, feature_ranks = tf.math.top_k(diff_sq_sum, k=rank)\n  feature_rank = feature_ranks[-1]\n  channel_inds = tf.range(num_channels, dtype=tf.int32)\n  channel_mask = tf.equal(channel_inds, feature_rank)\n  ones_t = tf.ones(num_channels, dtype=tf.float32)\n  zeros_t = tf.zeros(num_channels, dtype=tf.float32)\n\n  interp_tensors = []\n  for coeff in coeffs:\n    curr_coeff = tf.where(channel_mask, coeff * ones_t, zeros_t)\n    interp_tensor = tensor1 + curr_coeff * (tensor2 - tensor1)\n    interp_tensors.append(interp_tensor)\n  return tf.concat(interp_tensors, axis=0)", "response": "Linearly interpolate channel at rank between two tensors."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts x from 0. 5 0. 5 to 255.", "response": "def postprocess(x, n_bits_x=8):\n  \"\"\"Converts x from [-0.5, 0.5], to [0, 255].\n\n  Args:\n    x: 3-D or 4-D Tensor normalized between [-0.5, 0.5]\n    n_bits_x: Number of bits representing each pixel of the output.\n              Defaults to 8, to default to 256 possible values.\n  Returns:\n    x: 3-D or 4-D Tensor representing images or videos.\n  \"\"\"\n  x = tf.where(tf.is_finite(x), x, tf.ones_like(x))\n  x = tf.clip_by_value(x, -0.5, 0.5)\n  x += 0.5\n  x = x * 2**n_bits_x\n  return tf.cast(tf.clip_by_value(x, 0, 255), dtype=tf.uint8)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_cond_latents_at_level(cond_latents, level, hparams):\n  if cond_latents:\n    if hparams.latent_dist_encoder in [\"conv_net\", \"conv3d_net\"]:\n      return [cond_latent[level] for cond_latent in cond_latents]\n    elif hparams.latent_dist_encoder in [\"pointwise\", \"conv_lstm\"]:\n      return cond_latents[level]", "response": "Returns a single or list of conditional latents at level level."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshape checking for cond_latents.", "response": "def check_cond_latents(cond_latents, hparams):\n  \"\"\"Shape checking for cond_latents.\"\"\"\n  if cond_latents is None:\n    return\n  if not isinstance(cond_latents[0], list):\n    cond_latents = [cond_latents]\n  exp_num_latents = hparams.num_cond_latents\n  if hparams.latent_dist_encoder == \"conv_net\":\n    exp_num_latents += int(hparams.cond_first_frame)\n  if len(cond_latents) != exp_num_latents:\n    raise ValueError(\"Expected number of cond_latents: %d, got %d\" %\n                     (exp_num_latents, len(cond_latents)))\n  for cond_latent in cond_latents:\n    if len(cond_latent) != hparams.n_levels - 1:\n      raise ValueError(\"Expected level_latents to be %d, got %d\" %\n                       (hparams.n_levels - 1, len(cond_latent)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwrapping for data - dependent initialization.", "response": "def get_variable_ddi(name, shape, initial_value, dtype=tf.float32, init=False,\n                     trainable=True):\n  \"\"\"Wrapper for data-dependent initialization.\"\"\"\n  # If init is a tf bool: w is assigned dynamically at runtime.\n  # If init is a python bool: then w is determined during graph construction.\n  w = tf.get_variable(name, shape, dtype, None, trainable=trainable)\n  if isinstance(init, bool):\n    if init:\n      return assign(w, initial_value)\n    return w\n  else:\n    return tf.cond(init, lambda: assign(w, initial_value), lambda: w)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_dropout(x, rate=0.0, init=True):\n  if init or rate == 0:\n    return x\n  return tf.layers.dropout(x, rate=rate, training=True)", "response": "Dropout x with dropout_rate = rate."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef actnorm_3d(name, x, logscale_factor=3.):\n  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n    x = tf.unstack(x, axis=1)\n    x_normed = []\n    for ind, x_step in enumerate(x):\n      x_step, _ = actnorm(\"actnorm_%d\" % ind, x_step,\n                          logscale_factor=logscale_factor)\n      x_normed.append(x_step)\n    return tf.stack(x_normed, axis=1), None", "response": "Applies actnorm to each time - step independently."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef actnorm(name, x, logscale_factor=3., reverse=False, init=False,\n            trainable=True):\n  \"\"\"x_{ij} = s x x_{ij} + b. Per-channel scaling and bias.\n\n  If init is set to True, the scaling and bias are initialized such\n  that the mean and variance of the output activations of the first minibatch\n  are zero and one respectively.\n\n  Args:\n    name: variable scope.\n    x: input\n    logscale_factor: Used in actnorm_scale. Optimizes f(ls*s') instead of f(s)\n                     where s' = s / ls. Helps in faster convergence.\n    reverse: forward or reverse operation.\n    init: Whether or not to do data-dependent initialization.\n    trainable:\n\n  Returns:\n    x: output after adding bias and scaling.\n    objective: log(sum(s))\n  \"\"\"\n  var_arg_scope = arg_scope([get_variable_ddi], trainable=trainable)\n  var_scope = tf.variable_scope(name, reuse=tf.AUTO_REUSE)\n\n  with var_scope, var_arg_scope:\n    if not reverse:\n      x = actnorm_center(name + \"_center\", x, reverse, init=init)\n      x, objective = actnorm_scale(\n          name + \"_scale\", x, logscale_factor=logscale_factor,\n          reverse=reverse, init=init)\n    else:\n      x, objective = actnorm_scale(\n          name + \"_scale\", x, logscale_factor=logscale_factor,\n          reverse=reverse, init=init)\n      x = actnorm_center(name + \"_center\", x, reverse, init=init)\n    return x, objective", "response": "Per - channel actnorm."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef actnorm_center(name, x, reverse=False, init=False):\n  shape = common_layers.shape_list(x)\n  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n    assert len(shape) == 2 or len(shape) == 4\n    if len(shape) == 2:\n      x_mean = tf.reduce_mean(x, [0], keepdims=True)\n      b = get_variable_ddi(\"b\", (1, shape[1]), initial_value=-x_mean,\n                           init=init)\n    elif len(shape) == 4:\n      x_mean = tf.reduce_mean(x, [0, 1, 2], keepdims=True)\n      b = get_variable_ddi(\n          \"b\", (1, 1, 1, shape[3]), initial_value=-x_mean, init=init)\n\n    if not reverse:\n      x += b\n    else:\n      x -= b\n    return x", "response": "Add a bias to x."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_edge_bias(x, filter_size):\n  x_shape = common_layers.shape_list(x)\n  if filter_size[0] == 1 and filter_size[1] == 1:\n    return x\n  a = (filter_size[0] - 1) // 2  # vertical padding size\n  b = (filter_size[1] - 1) // 2  # horizontal padding size\n  padding = [[0, 0], [a, a], [b, b], [0, 0]]\n  x_bias = tf.zeros(x_shape[:-1] + [1])\n\n  x = tf.pad(x, padding)\n  x_pad = tf.pad(x_bias, padding, constant_values=1)\n  return tf.concat([x, x_pad], axis=3)", "response": "Pad x and concatenates an edge bias across the depth of x."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npad left across time and pad valid across the spatial components.", "response": "def time_pad(x, filter_size, dilations):\n  \"\"\"Pad left across time and pad valid across the spatial components.\n\n  Also concats a binary feature that indicates if a feature is padded or not.\n\n  Args:\n    x: 5-D Tensor, (NTHWC)\n    filter_size: list of ints\n    dilations: list of ints, dilations - 1 specifies the number of holes\n               between two filter elements.\n  Returns:\n    x_pad: 5-D Tensor.\n  \"\"\"\n  x_shape = common_layers.shape_list(x)\n  if filter_size == [1, 1, 1]:\n    return x\n  _, h, w = filter_size\n  eff_h = h + (h - 1)*(dilations[2] - 1)\n  eff_w = w + (w - 1)*(dilations[3] - 1)\n  a = (eff_h - 1) // 2  # vertical padding size\n  b = (eff_w - 1) // 2  # horizontal padding size\n  c = filter_size[0] - 1\n\n  # pad across edges.\n  padding = [[0, 0], [c, 0], [a, a], [b, b], [0, 0]]\n\n  # concat a binary feature across channels to indicate a padding.\n  # 1 indicates that the feature is a padding.\n  x_bias = tf.zeros(x_shape[:-1] + [1])\n  x_bias = tf.pad(x_bias, padding, constant_values=1)\n  x_pad = tf.pad(x, padding)\n  x_pad = tf.concat((x_bias, x_pad), axis=-1)\n  return x_pad"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef conv_block(name, x, mid_channels, dilations=None, activation=\"relu\",\n               dropout=0.0):\n  \"\"\"2 layer conv block used in the affine coupling layer.\n\n  Args:\n    name: variable scope.\n    x: 4-D or 5-D Tensor.\n    mid_channels: Output channels of the second layer.\n    dilations: Optional, list of integers.\n    activation: relu or gatu.\n      If relu, the second layer is relu(W*x)\n      If gatu, the second layer is tanh(W1*x) * sigmoid(W2*x)\n    dropout: Dropout probability.\n  Returns:\n    x: 4-D Tensor: Output activations.\n  \"\"\"\n  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n\n    x_shape = common_layers.shape_list(x)\n    is_2d = len(x_shape) == 4\n    num_steps = x_shape[1]\n    if is_2d:\n      first_filter = [3, 3]\n      second_filter = [1, 1]\n    else:\n      # special case when number of steps equal 1 to avoid\n      # padding.\n      if num_steps == 1:\n        first_filter = [1, 3, 3]\n      else:\n        first_filter = [2, 3, 3]\n      second_filter = [1, 1, 1]\n\n    # Edge Padding + conv2d + actnorm + relu:\n    # [output: 512 channels]\n    x = conv(\"1_1\", x, output_channels=mid_channels, filter_size=first_filter,\n             dilations=dilations)\n    x = tf.nn.relu(x)\n    x = get_dropout(x, rate=dropout)\n\n    # Padding + conv2d + actnorm + activation.\n    # [input, output: 512 channels]\n    if activation == \"relu\":\n      x = conv(\"1_2\", x, output_channels=mid_channels,\n               filter_size=second_filter, dilations=dilations)\n      x = tf.nn.relu(x)\n    elif activation == \"gatu\":\n      # x = tanh(w1*x) * sigm(w2*x)\n      x_tanh = conv(\"1_tanh\", x, output_channels=mid_channels,\n                    filter_size=second_filter, dilations=dilations)\n      x_sigm = conv(\"1_sigm\", x, output_channels=mid_channels,\n                    filter_size=second_filter, dilations=dilations)\n      x = tf.nn.tanh(x_tanh) * tf.nn.sigmoid(x_sigm)\n\n    x = get_dropout(x, rate=dropout)\n    return x", "response": "2 - layer conv block used in the affine coupling layer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndilating convolutional stack. Features at different rates are computed independently using a 3 layer convolutional stack and added. Args: name: variable scope. x: 5-D Tensor. mid_channels: Number of output channels of the first layer in the conv stack. output_channels: Number of output channels of the last layer. dilation_rates: A list of dilation rates. activation: Can be either \"relu\" or \"gatu\" dropout: dropout. Returns: output: 5-D Tensor.", "response": "def dilated_conv_stack(name, x, mid_channels, output_channels,\n                       dilation_rates, activation=\"relu\",\n                       dropout=0.0):\n  \"\"\"Dilated convolutional stack.\n\n  Features at different rates are computed independently using a 3 layer\n  convolutional stack and added.\n\n  Args:\n    name: variable scope.\n    x: 5-D Tensor.\n    mid_channels: Number of output channels of the first layer in the conv\n                  stack.\n    output_channels: Number of output channels of the last layer.\n    dilation_rates: A list of dilation rates.\n    activation: Can be either \"relu\" or \"gatu\"\n    dropout: dropout.\n  Returns:\n    output: 5-D Tensor.\n  \"\"\"\n  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n    output = 0.0\n    for dil_ind, dil_rate in enumerate(dilation_rates):\n      # TODO(mechcoder) try (concat across channels + 1x1) modulo memory issues.\n      curr_out = conv_stack(\"dil_%d\" % dil_ind, x, mid_channels=mid_channels,\n                            output_channels=output_channels, dilations=dil_rate,\n                            activation=activation, dropout=dropout)\n      output += curr_out\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef conv_stack(name, x, mid_channels, output_channels, dilations=None,\n               activation=\"relu\", dropout=0.0):\n  \"\"\"3-layer convolutional stack.\n\n  Args:\n    name: variable scope.\n    x: 5-D Tensor.\n    mid_channels: Number of output channels of the first layer.\n    output_channels: Number of output channels.\n    dilations: Dilations to apply in the first 3x3 layer and the last 3x3 layer.\n               By default, apply no dilations.\n    activation: relu or gatu.\n      If relu, the second layer is relu(W*x)\n      If gatu, the second layer is tanh(W1*x) * sigmoid(W2*x)\n    dropout: float, 0.0\n  Returns:\n    output: output of 3 layer conv network.\n  \"\"\"\n  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n\n    x = conv_block(\"conv_block\", x, mid_channels=mid_channels,\n                   dilations=dilations, activation=activation,\n                   dropout=dropout)\n\n    # Final layer.\n    x = conv(\"zeros\", x, apply_actnorm=False, conv_init=\"zeros\",\n             output_channels=output_channels, dilations=dilations)\n  return x", "response": "3 - layer convolutional stack."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef additive_coupling(name, x, mid_channels=512, reverse=False,\n                      activation=\"relu\", dropout=0.0):\n  \"\"\"Reversible additive coupling layer.\n\n  Args:\n    name: variable scope.\n    x: 4-D Tensor, shape=(NHWC).\n    mid_channels: number of channels in the coupling layer.\n    reverse: Forward or reverse operation.\n    activation: \"relu\" or \"gatu\"\n    dropout: default, 0.0\n  Returns:\n    output: 4-D Tensor, shape=(NHWC)\n    objective: 0.0\n  \"\"\"\n  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n    output_channels = common_layers.shape_list(x)[-1] // 2\n    x1, x2 = tf.split(x, num_or_size_splits=2, axis=-1)\n\n    z1 = x1\n    shift = conv_stack(\"nn\", x1, mid_channels, output_channels=output_channels,\n                       activation=activation, dropout=dropout)\n\n    if not reverse:\n      z2 = x2 + shift\n    else:\n      z2 = x2 - shift\n    return tf.concat([z1, z2], axis=3), 0.0", "response": "Reversible additive coupling layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef affine_coupling(name, x, mid_channels=512, activation=\"relu\",\n                    reverse=False, dropout=0.0):\n  \"\"\"Reversible affine coupling layer.\n\n  Args:\n    name: variable scope.\n    x: 4-D Tensor.\n    mid_channels: number of channels in the coupling layer.\n    activation: Can be either \"relu\" or \"gatu\".\n    reverse: Forward or reverse operation.\n    dropout: default, 0.0\n  Returns:\n    output: x shifted and scaled by an affine transformation.\n    objective: log-determinant of the jacobian\n  \"\"\"\n  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n    x_shape = common_layers.shape_list(x)\n    x1, x2 = tf.split(x, num_or_size_splits=2, axis=-1)\n\n    # scale, shift = NN(x1)\n    # If reverse:\n    # z2 = scale * (x2 + shift)\n    # Else:\n    # z2 = (x2 / scale) - shift\n    z1 = x1\n    log_scale_and_shift = conv_stack(\n        \"nn\", x1, mid_channels, x_shape[-1], activation=activation,\n        dropout=dropout)\n    shift = log_scale_and_shift[:, :, :, 0::2]\n    scale = tf.nn.sigmoid(log_scale_and_shift[:, :, :, 1::2] + 2.0)\n    if not reverse:\n      z2 = (x2 + shift) * scale\n    else:\n      z2 = x2 / scale - shift\n\n    objective = tf.reduce_sum(tf.log(scale), axis=[1, 2, 3])\n    if reverse:\n      objective *= -1\n    return tf.concat([z1, z2], axis=3), objective", "response": "Reversible affine coupling layer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nblock - wise spatial squeezing of x to increase the number of channels.", "response": "def squeeze(name, x, factor=2, reverse=True):\n  \"\"\"Block-wise spatial squeezing of x to increase the number of channels.\n\n  Args:\n    name: Used for variable scoping.\n    x: 4-D Tensor of shape (batch_size X H X W X C)\n    factor: Factor by which the spatial dimensions should be squeezed.\n    reverse: Squueze or unsqueeze operation.\n\n  Returns:\n    x: 4-D Tensor of shape (batch_size X (H//factor) X (W//factor) X\n       (cXfactor^2). If reverse is True, then it is factor = (1 / factor)\n  \"\"\"\n  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n    shape = common_layers.shape_list(x)\n    if factor == 1:\n      return x\n    height = int(shape[1])\n    width = int(shape[2])\n    n_channels = int(shape[3])\n\n    if not reverse:\n      assert height % factor == 0 and width % factor == 0\n      x = tf.reshape(x, [-1, height//factor, factor,\n                         width//factor, factor, n_channels])\n      x = tf.transpose(x, [0, 1, 3, 5, 2, 4])\n      x = tf.reshape(x, [-1, height//factor, width //\n                         factor, n_channels*factor*factor])\n    else:\n      x = tf.reshape(\n          x, (-1, height, width, int(n_channels/factor**2), factor, factor))\n      x = tf.transpose(x, [0, 1, 4, 2, 5, 3])\n      x = tf.reshape(x, (-1, int(height*factor),\n                         int(width*factor), int(n_channels/factor**2)))\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a list of valid dilation rates.", "response": "def get_dilation_rates(hparams, width):\n  \"\"\"Get a list of valid dilation rates.\n\n  Args:\n    hparams: HParams.\n    width: spatial dimension. Ensures that the effective filter size is\n           not larger than the spatial dimension.\n  Returns:\n    allowed_dilations: A list of dilation rates.\n  \"\"\"\n  # dil_rate=1 means no dilation.\n  allowed_dilations = [[1]*5]\n  apply_dilations = hparams.get(\"latent_apply_dilations\", False)\n  dilation_rates = hparams.get(\"latent_dilation_rates\", [1, 3])\n  if apply_dilations:\n    for rate in dilation_rates:\n      # k + (k - 1) * rate but k is harcoded to be 3 everywhere.\n      filter_size = 3 + 2 * rate\n      if filter_size <= width:\n        curr_dilation = [1, 1, rate+1, rate+1, 1]\n        allowed_dilations.append(curr_dilation)\n  return allowed_dilations"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef temporal_latent_to_dist(name, x, hparams, output_channels=None):\n  _, _, width, _, res_channels = common_layers.shape_list(x)\n  if output_channels is None:\n    output_channels = res_channels\n  dilation_rates = get_dilation_rates(hparams, width)\n  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n    h = x\n    for i in range(hparams.latent_encoder_depth):\n      if hparams.latent_apply_dilations:\n        h2 = dilated_conv_stack(\"dil_latent_3d_res_%d\" % i, h,\n                                mid_channels=hparams.latent_encoder_width,\n                                output_channels=res_channels,\n                                dilation_rates=dilation_rates,\n                                activation=hparams.latent_activation,\n                                dropout=hparams.latent_dropout)\n      else:\n        h2 = conv_stack(\"latent_3d_res_%d\" % i, h,\n                        mid_channels=hparams.latent_encoder_width,\n                        output_channels=res_channels,\n                        activation=hparams.latent_activation,\n                        dropout=hparams.latent_dropout)\n      h += h2\n\n    # take last activation that should capture all context since padding is\n    # on left.\n    h = h[:, -1, :, :, :]\n    h = conv(\"res_final\", h, apply_actnorm=False, conv_init=\"zeros\",\n             output_channels=2*output_channels, filter_size=[1, 1])\n    mean, log_scale = h[:, :, :, 0::2], h[:, :, :, 1::2]\n  return tfp.distributions.Normal(mean, tf.exp(log_scale))", "response": "Network that maps a time - indexed list of 3 - D latents to a gaussian."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef single_conv_dist(name, x, output_channels=None):\n  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n    x_shape = common_layers.shape_list(x)\n    if output_channels is None:\n      output_channels = x_shape[-1]\n    mean_log_scale = conv(\"conv2d\", x, output_channels=2*output_channels,\n                          conv_init=\"zeros\", apply_actnorm=False)\n    mean = mean_log_scale[:, :, :, 0::2]\n    log_scale = mean_log_scale[:, :, :, 1::2]\n    return tf.distributions.Normal(mean, tf.exp(log_scale))", "response": "A 3x3 convolution mapping x to a standard normal distribution at init."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmapping latent to the mean and log - scale of a Gaussian.", "response": "def latent_to_dist(name, x, hparams, output_channels=None):\n  \"\"\"Map latent to the mean and log-scale of a Gaussian.\n\n  Args:\n    name: variable scope.\n    x: 4-D Tensor of shape (NHWC)\n    hparams: HParams.\n      latent_architecture - can be \"single_conv\", \"glow_nn\" or \"glow_resnet\",\n                            default = single_conv\n      latent_encoder_depth - int, depth of architecture, valid if\n                             latent_architecture is \"glow_nn\" or \"glow_resnet\".\n      latent_pre_output_channels - 512, valid only when latent_architecture\n                                   is \"glow_nn\".\n      latent_encoder_width - 512, maximum width of the network\n    output_channels: int, number of output channels of the mean (and std).\n                     if not provided, set it to be the output channels of x.\n  Returns:\n    dist: instance of tfp.distributions.Normal\n  Raises:\n    ValueError: If architecture not in [\"single_conv\", \"glow_nn\"]\n  \"\"\"\n  architecture = hparams.get(\"latent_architecture\", \"single_conv\")\n  depth = hparams.get(\"latent_encoder_depth\", 1)\n  pre_output_channels = hparams.get(\"latent_pre_output_channels\", 512)\n  width = hparams.get(\"latent_encoder_width\", 512)\n\n  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n    x_shape = common_layers.shape_list(x)\n    if output_channels is None:\n      output_channels = x_shape[-1]\n    if architecture == \"single_conv\":\n      return single_conv_dist(\"single_conv\", x, output_channels)\n    if architecture == \"glow_nn\":\n      mean_log_scale = x\n      for layer in range(1, depth + 1):\n        mid_channels = pre_output_channels // 2**(depth - layer)\n        mean_log_scale = conv_block(\"glow_nn_%d\" % layer, mean_log_scale,\n                                    mid_channels=mid_channels)\n      mean_log_scale = conv(\"glow_nn_zeros\", mean_log_scale,\n                            filter_size=[3, 3], stride=[1, 1],\n                            output_channels=2*output_channels,\n                            apply_actnorm=False, conv_init=\"zeros\")\n    elif architecture == \"glow_resnet\":\n      h = x\n      for layer in range(depth):\n        h3 = conv_stack(\"latent_resnet_%d\" % layer, h,\n                        mid_channels=width, output_channels=x_shape[-1],\n                        dropout=hparams.coupling_dropout)\n        h += h3\n      mean_log_scale = conv(\"glow_res_final\", h, conv_init=\"zeros\",\n                            output_channels=2*output_channels,\n                            apply_actnorm=False)\n    else:\n      raise ValueError(\"expected architecture to be single_conv or glow_nn \"\n                       \"got %s\" % architecture)\n\n    mean = mean_log_scale[:, :, :, 0::2]\n    log_scale = mean_log_scale[:, :, :, 1::2]\n    return tfp.distributions.Normal(mean, tf.exp(log_scale))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef noise_op(latents, hparams):\n  if hparams.latent_noise == 0 or hparams.mode != tf.estimator.ModeKeys.TRAIN:\n    return latents\n  latent_shape = common_layers.shape_list(latents)\n  return latents + tf.random_normal(latent_shape, stddev=hparams.latent_noise)", "response": "Adds isotropic gaussian - noise to each latent."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merge_level_and_latent_dist(level_dist, latent_dist,\n                                merge_std=\"prev_level\"):\n  \"\"\"Merge level_dist and latent_dist.\n\n  new_dist ~ N(level_dist.mean + latent_dis.mean, std) where std is determined\n  according to merge_std.\n\n  Args:\n    level_dist: instance of tfp.distributions.Normal\n    latent_dist: instance of tfp.distributions.Normal\n    merge_std: can be \"prev_level\", \"prev_step\" or \"normal\".\n  Returns:\n    merged_dist: instance of tfp.distributions.Normal\n  \"\"\"\n  level_mean, level_std = level_dist.loc, level_dist.scale\n  latent_mean, latent_std = latent_dist.loc, latent_dist.scale\n  new_mean = level_mean + latent_mean\n  if merge_std == \"normal\":\n    z_shape = common_layers.shape_list(latent_mean)\n    log_scale = tf.get_variable(\n        \"merge_std\", shape=z_shape, dtype=tf.float32,\n        initializer=tf.zeros_initializer(), trainable=False)\n    scale = tf.exp(log_scale * 3.0)\n  elif merge_std == \"prev_level\":\n    scale = level_std\n  elif merge_std == \"prev_step\":\n    scale = latent_std\n  return tfp.distributions.Normal(loc=new_mean, scale=scale)", "response": "Merge level_dist and latent_dist."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a conditional prior for each level.", "response": "def level_cond_prior(prior_dist, z, latent, hparams, state):\n  \"\"\"Returns a conditional prior for each level.\n\n  Args:\n    prior_dist: Distribution conditioned on the previous levels.\n    z: Tensor, output of the previous levels.\n    latent: Tensor or a list of tensors to condition the latent_distribution.\n    hparams: next_frame_glow hparams.\n    state: Current LSTM state. Used only if hparams.latent_dist_encoder is\n           a lstm.\n  Raises:\n    ValueError: If hparams.latent_dist_encoder is \"pointwise\" and if the shape\n                of latent is different from z.\n  \"\"\"\n  latent_dist_encoder = hparams.get(\"latent_dist_encoder\", None)\n  latent_skip = hparams.get(\"latent_skip\", False)\n  if latent_dist_encoder == \"pointwise\":\n    last_latent = latent\n    merge_std = hparams.level_scale\n    latent_shape = common_layers.shape_list(latent)\n    z_shape = common_layers.shape_list(z)\n    if latent_shape != z_shape:\n      raise ValueError(\"Expected latent_shape to be %s, got %s\" %\n                       (latent_shape, z_shape))\n    latent_dist = scale_gaussian_prior(\n        \"latent_prior\", latent, logscale_factor=3.0)\n    cond_dist = merge_level_and_latent_dist(prior_dist, latent_dist,\n                                            merge_std=merge_std)\n\n  elif latent_dist_encoder == \"conv_net\":\n    output_channels = common_layers.shape_list(z)[-1]\n    last_latent = latent[-1]\n    latent_stack = tf.concat([prior_dist.loc] + latent, axis=-1)\n    latent_stack = noise_op(latent_stack, hparams)\n    cond_dist = latent_to_dist(\n        \"latent_stack\", latent_stack, hparams=hparams,\n        output_channels=output_channels)\n\n  elif latent_dist_encoder == \"conv3d_net\":\n    last_latent = latent[-1]\n    output_channels = common_layers.shape_list(last_latent)[-1]\n    num_steps = len(latent)\n\n    # Stack across time.\n    cond_latents = tf.stack(latent, axis=1)\n\n    # Concat latents from previous levels across channels.\n    prev_latents = tf.tile(tf.expand_dims(prior_dist.loc, axis=1),\n                           [1, num_steps, 1, 1, 1])\n    cond_latents = tf.concat((cond_latents, prev_latents), axis=-1)\n    cond_latents = noise_op(cond_latents, hparams)\n    cond_dist = temporal_latent_to_dist(\n        \"latent_stack\", cond_latents, hparams, output_channels=output_channels)\n\n  elif latent_dist_encoder == \"conv_lstm\":\n    last_latent = latent\n    output_channels = common_layers.shape_list(z)[-1]\n    latent_stack = tf.concat((prior_dist.loc, latent), axis=-1)\n    latent_stack = noise_op(latent_stack, hparams)\n    _, state = common_video.conv_lstm_2d(\n        latent_stack, state, hparams.latent_encoder_width, kernel_size=3,\n        name=\"conv_lstm\")\n\n    cond_dist = single_conv_dist(\n        \"state_to_dist\", state.h, output_channels=output_channels)\n  if latent_skip:\n    new_mean = cond_dist.loc + last_latent\n    cond_dist = tfp.distributions.Normal(new_mean, cond_dist.scale)\n  return cond_dist.loc, cond_dist.scale, state"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compute_prior(name, z, latent, hparams, condition=False, state=None,\n                  temperature=1.0):\n  \"\"\"Distribution on z_t conditioned on z_{t-1} and latent.\n\n  Args:\n    name: variable scope.\n    z: 4-D Tensor.\n    latent: optional,\n            if hparams.latent_dist_encoder == \"pointwise\", this is a list\n            of 4-D Tensors of length hparams.num_cond_latents.\n            else, this is just a 4-D Tensor\n            The first-three dimensions of the latent should be the same as z.\n    hparams: next_frame_glow_hparams.\n    condition: Whether or not to condition the distribution on latent.\n    state: tf.nn.rnn_cell.LSTMStateTuple.\n           the current state of a LSTM used to model the distribution. Used\n           only if hparams.latent_dist_encoder = \"conv_lstm\".\n    temperature: float, temperature with which to sample from the Gaussian.\n  Returns:\n    prior_dist: instance of tfp.distributions.Normal\n    state: Returns updated state.\n  Raises:\n    ValueError: If hparams.latent_dist_encoder is \"pointwise\" and if the shape\n                of latent is different from z.\n  \"\"\"\n  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n    if isinstance(condition, bool):\n      condition = tf.constant(condition, dtype=tf.bool)\n    prior_dist = single_conv_dist(\"level_prior\", z)\n    prior_mean, prior_scale = prior_dist.loc, prior_dist.scale\n\n    if latent is None:\n      mean, scale = prior_mean, prior_scale\n    else:\n      cond_mean, cond_scale, state = level_cond_prior(\n          prior_dist, z, latent, hparams, state)\n      mean, scale = tf.cond(\n          condition, lambda: (cond_mean, cond_scale),\n          lambda: (prior_mean, prior_scale))\n    dist = TemperedNormal(mean, scale, temperature)\n    return dist, state", "response": "Compute prior distribution on z_t conditioned on z_t and latent."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsplits x into x1 and x2 across number of channels.", "response": "def split(name, x, reverse=False, eps=None, eps_std=None, cond_latents=None,\n          hparams=None, state=None, condition=False, temperature=1.0):\n  \"\"\"Splits / concatenates x into x1 and x2 across number of channels.\n\n  For the forward pass, x2 is assumed be gaussian,\n  i.e P(x2 | x1) ~ N(mu, sigma) where mu and sigma are the outputs of\n  a network conditioned on x1 and optionally on cond_latents.\n  For the reverse pass, x2 is determined from mu(x1) and sigma(x1).\n  This is deterministic/stochastic depending on whether eps is provided.\n\n  Args:\n    name: variable scope.\n    x: 4-D Tensor, shape (NHWC).\n    reverse: Forward or reverse pass.\n    eps: If eps is provided, x2 is set to be mu(x1) + eps * sigma(x1).\n    eps_std: Sample x2 with the provided eps_std.\n    cond_latents: optionally condition x2 on cond_latents.\n    hparams: next_frame_glow hparams.\n    state: tf.nn.rnn_cell.LSTMStateTuple.. Current state of the LSTM over z_2.\n           Used only when hparams.latent_dist_encoder == \"conv_lstm\"\n    condition: bool, Whether or not to condition the distribution on\n               cond_latents.\n    temperature: Temperature with which to sample from the gaussian.\n\n  Returns:\n    If reverse:\n      x: 4-D Tensor, concats input and x2 across channels.\n      x2: 4-D Tensor, a sample from N(mu(x1), sigma(x1))\n    Else:\n      x1: 4-D Tensor, Output of the split operation.\n      logpb: log-probability of x2 belonging to mu(x1), sigma(x1)\n      eps: 4-D Tensor, (x2 - mu(x1)) / sigma(x1)\n      x2: 4-D Tensor, Latent representation at the current level.\n    state: Current LSTM state.\n           4-D Tensor, only if hparams.latent_dist_encoder is set to conv_lstm.\n  Raises:\n    ValueError: If latent is provided and shape is not equal to NHW(C/2)\n                where (NHWC) is the size of x.\n  \"\"\"\n  # TODO(mechcoder) Change the return type to be a dict.\n  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n    if not reverse:\n      x1, x2 = tf.split(x, num_or_size_splits=2, axis=-1)\n\n      # objective: P(x2|x1) ~N(x2 ; NN(x1))\n      prior_dist, state = compute_prior(\n          \"prior_on_z2\", x1, cond_latents, hparams, condition, state=state)\n      logpb = tf.reduce_sum(prior_dist.log_prob(x2), axis=[1, 2, 3])\n      eps = get_eps(prior_dist, x2)\n      return x1, logpb, eps, x2, state\n    else:\n      prior_dist, state = compute_prior(\n          \"prior_on_z2\", x, cond_latents, hparams, condition, state=state,\n          temperature=temperature)\n      if eps is not None:\n        x2 = set_eps(prior_dist, eps)\n      elif eps_std is not None:\n        x2 = eps_std * tf.random_normal(common_layers.shape_list(x))\n      else:\n        x2 = prior_dist.sample()\n      return tf.concat([x, x2], 3), x2, state"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef revnet_step(name, x, hparams, reverse=True):\n  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n    if hparams.coupling == \"additive\":\n      coupling_layer = functools.partial(\n          additive_coupling, name=\"additive\", reverse=reverse,\n          mid_channels=hparams.coupling_width,\n          activation=hparams.activation, dropout=hparams.coupling_dropout)\n    else:\n      coupling_layer = functools.partial(\n          affine_coupling, name=\"affine\", reverse=reverse,\n          mid_channels=hparams.coupling_width,\n          activation=hparams.activation, dropout=hparams.coupling_dropout)\n    ops = [\n        functools.partial(actnorm, name=\"actnorm\", reverse=reverse),\n        functools.partial(invertible_1x1_conv, name=\"invertible\",\n                          reverse=reverse), coupling_layer]\n\n    if reverse:\n      ops = ops[::-1]\n\n    objective = 0.0\n    for op in ops:\n      x, curr_obj = op(x=x)\n      objective += curr_obj\n    return x, objective", "response": "One step of glow generative flow."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns N where s^i and std^i are pre - component.", "response": "def scale_gaussian_prior(name, z, logscale_factor=3.0, trainable=True):\n  \"\"\"Returns N(s^i * z^i, std^i) where s^i and std^i are pre-component.\n\n  s^i is a learnable parameter with identity initialization.\n  std^i is optionally learnable with identity initialization.\n\n  Args:\n    name: variable scope.\n    z: input_tensor\n    logscale_factor: equivalent to scaling up the learning_rate by a factor\n                     of logscale_factor.\n    trainable: Whether or not std^i is learnt.\n  \"\"\"\n  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n    z_shape = common_layers.shape_list(z)\n    latent_multiplier = tf.get_variable(\n        \"latent_multiplier\", shape=z_shape, dtype=tf.float32,\n        initializer=tf.ones_initializer())\n    log_scale = tf.get_variable(\n        \"log_scale_latent\", shape=z_shape, dtype=tf.float32,\n        initializer=tf.zeros_initializer(), trainable=trainable)\n    log_scale = log_scale * logscale_factor\n    return tfp.distributions.Normal(\n        loc=latent_multiplier * z, scale=tf.exp(log_scale))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreplaces x^i with q^i ( x ) = x + q^i ( x + 1. 0 / 256. 0", "response": "def uniform_binning_correction(x, n_bits=8):\n  \"\"\"Replaces x^i with q^i(x) = U(x, x + 1.0 / 256.0).\n\n  Args:\n    x: 4-D Tensor of shape (NHWC)\n    n_bits: optional.\n  Returns:\n    x: x ~ U(x, x + 1.0 / 256)\n    objective: Equivalent to -q(x)*log(q(x)).\n  \"\"\"\n  n_bins = 2**n_bits\n  batch_size, height, width, n_channels = common_layers.shape_list(x)\n  hwc = float(height * width * n_channels)\n\n  x = x + tf.random_uniform(\n      shape=(batch_size, height, width, n_channels),\n      minval=0.0, maxval=1.0/n_bins)\n  objective = -np.log(n_bins) * hwc * tf.ones(batch_size)\n  return x, objective"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nglowing encoder - decoder. n_levels of Squeeze + Flow + Split.", "response": "def encoder_decoder(name, x, hparams, eps=None, reverse=False,\n                    cond_latents=None, condition=False, states=None,\n                    temperature=1.0):\n  \"\"\"Glow encoder-decoder. n_levels of (Squeeze + Flow + Split.) operations.\n\n  Args:\n    name: variable scope.\n    x: 4-D Tensor, shape=(NHWC).\n    hparams: HParams.\n    eps: Stores (glow(x) - mu) / sigma during the forward pass.\n         Used only to test if the network is reversible.\n    reverse: Forward or reverse pass.\n    cond_latents: list of lists of tensors.\n                  outer length equals hparams.num_cond_latents\n                  innter length equals hparams.num_levels - 1.\n    condition: If set to True, condition the encoder/decoder on cond_latents.\n    states: LSTM states, used only if hparams.latent_dist_encoder is set\n            to \"conv_lstm.\n    temperature: Temperature set during sampling.\n  Returns:\n    x: If reverse, decoded image, else the encoded glow latent representation.\n    objective: log-likelihood.\n    eps: list of tensors, shape=(num_levels-1).\n         Stores (glow(x) - mu_level(x)) / sigma_level(x)) for each level.\n    all_latents: list of tensors, shape=(num_levels-1).\n                 Latent representatios for each level.\n    new_states: list of tensors, shape=(num_levels-1).\n                useful only if hparams.latent_dist_encoder=\"conv_lstm\", returns\n                the current state of each level.\n  \"\"\"\n  # TODO(mechcoder) Change return_type to a dict to be backward compatible.\n  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n\n    if states and len(states) != hparams.n_levels - 1:\n      raise ValueError(\"Expected length of states to be %d, got %d\" %\n                       (hparams.n_levels - 1, len(states)))\n    if states is None:\n      states = [None] * (hparams.n_levels - 1)\n    if eps and len(eps) != hparams.n_levels - 1:\n      raise ValueError(\"Expected length of eps to be %d, got %d\" %\n                       (hparams.n_levels - 1, len(eps)))\n    if eps is None:\n      eps = [None] * (hparams.n_levels - 1)\n    check_cond_latents(cond_latents, hparams)\n\n    objective = 0.0\n    all_eps = []\n    all_latents = []\n    new_states = []\n\n    if not reverse:\n      # Squeeze + Flow + Split\n      for level in range(hparams.n_levels):\n        x = squeeze(\"squeeze_%d\" % level, x, factor=2, reverse=False)\n\n        x, obj = revnet(\"revnet_%d\" % level, x, hparams, reverse=False)\n        objective += obj\n\n        if level < hparams.n_levels - 1:\n          curr_cond_latents = get_cond_latents_at_level(\n              cond_latents, level, hparams)\n          x, obj, eps, z, state = split(\"split_%d\" % level, x, reverse=False,\n                                        cond_latents=curr_cond_latents,\n                                        condition=condition,\n                                        hparams=hparams, state=states[level])\n          objective += obj\n          all_eps.append(eps)\n          all_latents.append(z)\n          new_states.append(state)\n\n      return x, objective, all_eps, all_latents, new_states\n\n    else:\n      for level in reversed(range(hparams.n_levels)):\n        if level < hparams.n_levels - 1:\n\n          curr_cond_latents = get_cond_latents_at_level(\n              cond_latents, level, hparams)\n\n          x, latent, state = split(\"split_%d\" % level, x, eps=eps[level],\n                                   reverse=True, cond_latents=curr_cond_latents,\n                                   condition=condition, hparams=hparams,\n                                   state=states[level],\n                                   temperature=temperature)\n          new_states.append(state)\n          all_latents.append(latent)\n\n        x, obj = revnet(\n            \"revnet_%d\" % level, x, hparams=hparams, reverse=True)\n        objective += obj\n        x = squeeze(\"squeeze_%d\" % level, x, reverse=True)\n      return x, objective, all_latents[::-1], new_states[::-1]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsimulate quantization to num_bits bits with externally - stored scale.", "response": "def simulated_quantize(x, num_bits, noise):\n  \"\"\"Simulate quantization to num_bits bits, with externally-stored scale.\n\n  num_bits is the number of bits used to store each value.\n  noise is a float32 Tensor containing values in [0, 1).\n  Each value in noise should take different values across\n  different steps, approximating a uniform distribution over [0, 1).\n  In the case of replicated TPU training, noise should be identical\n  across replicas in order to keep the parameters identical across replicas.\n\n  The natural choice for noise would be tf.random_uniform(),\n  but this is not possible for TPU, since there is currently no way to seed\n  the different cores to produce identical values across replicas.  Instead we\n  use noise_from_step_num() (see below).\n\n  The quantization scheme is as follows:\n\n  Compute the maximum absolute value by row (call this max_abs).\n  Store this either in an auxiliary variable or in an extra column.\n\n  Divide the parameters by (max_abs / (2^(num_bits-1)-1)).  This gives a\n  float32 value in the range [-2^(num_bits-1)-1, 2^(num_bits-1)-1]\n\n  Unbiased randomized roundoff by adding noise and rounding down.\n\n  This produces a signed integer with num_bits bits which can then be stored.\n\n  Args:\n    x: a float32 Tensor\n    num_bits: an integer between 1 and 22\n    noise: a float Tensor broadcastable to the shape of x.\n\n  Returns:\n    a float32 Tensor\n  \"\"\"\n  shape = x.get_shape().as_list()\n  if not (len(shape) >= 2 and shape[-1] > 1):\n    return x\n  max_abs = tf.reduce_max(tf.abs(x), -1, keepdims=True) + 1e-9\n  max_int = 2 ** (num_bits - 1) - 1\n  scale = max_abs / max_int\n  x /= scale\n  x = tf.floor(x + noise)\n  # dequantize before storing (since this is a simulation)\n  x *= scale\n  return x"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _randomized_roundoff_to_bfloat16(x, noise, cand1, cand2):\n  cand1_f = tf.to_float(cand1)\n  cand2_f = tf.to_float(cand2)\n  step_size = cand2_f - cand1_f\n  fpart = (x - cand1_f) / step_size\n  ret = tf.where(tf.greater(fpart, noise), cand2, cand1)\n  return ret", "response": "Round - off x to cand1 or cand2 in an unbiased way."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _to_bfloat16_unbiased(x, noise):\n  x_sign = tf.sign(x)\n  # Make sure x is positive.  If it is zero, the two candidates are identical.\n  x = x * x_sign + 1e-30\n  cand1 = tf.to_bfloat16(x)\n  cand1_f = tf.to_float(cand1)\n  # This relies on the fact that for a positive bfloat16 b,\n  # b * 1.005 gives you the next higher bfloat16 and b*0.995 gives you the\n  # next lower one. Both 1.005 and 0.995 are ballpark estimation.\n  cand2 = tf.to_bfloat16(\n      tf.where(tf.greater(x, cand1_f), cand1_f * 1.005, cand1_f * 0.995))\n  ret = _randomized_roundoff_to_bfloat16(x, noise, cand1, cand2)\n  return ret * tf.to_bfloat16(x_sign)", "response": "Convert a float32 to a bfloat16 using randomized roundoff."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading videos from files.", "response": "def load_videos(template, video_length, frame_shape):\n  \"\"\"Loads videos from files.\n\n  Args:\n    template: template string for listing the image files.\n    video_length: length of the video.\n    frame_shape: shape of each frame.\n\n  Returns:\n    dataset: the tf dataset frame by frame.\n    dataset_len: number of the items which is the number of image files.\n\n  Raises:\n    ValueError: if no files found.\n  \"\"\"\n  filenames = tf.gfile.Glob(template)\n  if not filenames:\n    raise ValueError(\"no files found.\")\n  filenames = sorted(filenames)\n  dataset_len = len(filenames)\n  filenames = tf.constant(filenames)\n  dataset = tf.data.Dataset.from_tensor_slices(filenames)\n  dataset = dataset.apply(tf.data.experimental.map_and_batch(\n      lambda filename: load_image_map_function(filename, frame_shape),\n      video_length, drop_remainder=True))\n  return dataset, dataset_len"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the PSNR and SSIM.", "response": "def psnr_and_ssim(output, target):\n  \"\"\"Compute the PSNR and SSIM.\n\n  Args:\n    output: 4-D Tensor, shape=(num_frames, height, width, num_channels)\n    target: 4-D Tensor, shape=(num_frames, height, width, num_channels)\n  Returns:\n    psnr: 1-D Tensor, shape=(num_frames,)\n    ssim: 1-D Tensor, shape=(num_frames,)\n  \"\"\"\n  output = tf.cast(output, dtype=tf.int32)\n  target = tf.cast(target, dtype=tf.int32)\n  psnr = tf.image.psnr(output, target, max_val=255)\n  ssim = tf.image.ssim(output, target, max_val=255)\n  return psnr, ssim"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_zipped_dataset_from_predictions(predictions):\n  targets = stack_data_given_key(predictions, \"targets\")\n  outputs = stack_data_given_key(predictions, \"outputs\")\n  num_videos, num_steps = targets.shape[:2]\n\n  # Truncate output time-steps to match target time-steps\n  outputs = outputs[:, :num_steps]\n\n  targets_placeholder = tf.placeholder(targets.dtype, targets.shape)\n  outputs_placeholder = tf.placeholder(outputs.dtype, outputs.shape)\n  dataset = tf.data.Dataset.from_tensor_slices(\n      (targets_placeholder, outputs_placeholder))\n  iterator = dataset.make_initializable_iterator()\n  feed_dict = {targets_placeholder: targets,\n               outputs_placeholder: outputs}\n  return iterator, feed_dict, num_videos", "response": "Creates a dataset from in - memory predictions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the average of all the metric for one decoding.", "response": "def compute_one_decoding_video_metrics(iterator, feed_dict, num_videos):\n  \"\"\"Computes the average of all the metric for one decoding.\n\n  Args:\n    iterator: dataset iterator.\n    feed_dict: feed dict to initialize iterator.\n    num_videos: number of videos.\n\n  Returns:\n    all_psnr: 2-D Numpy array, shape=(num_samples, num_frames)\n    all_ssim: 2-D Numpy array, shape=(num_samples, num_frames)\n  \"\"\"\n  output, target = iterator.get_next()\n  metrics = psnr_and_ssim(output, target)\n\n  with tf.Session() as sess:\n    sess.run(tf.local_variables_initializer())\n    initalizer = iterator._initializer  # pylint: disable=protected-access\n    if initalizer is not None:\n      sess.run(initalizer, feed_dict=feed_dict)\n\n    all_psnr, all_ssim = [], []\n    for i in range(num_videos):\n      print(\"Computing video: %d\" % i)\n      psnr_np, ssim_np = sess.run(metrics)\n      all_psnr.append(psnr_np)\n      all_ssim.append(ssim_np)\n    all_psnr = np.array(all_psnr)\n    all_ssim = np.array(all_ssim)\n    return all_psnr, all_ssim"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reduce_to_best_decode(metrics, reduce_func):\n  num_videos = metrics.shape[1]\n  # Take mean of the metric across the frames to approximate the video\n  # closest to the ground truth.\n  mean_across_frames = np.mean(metrics, axis=-1)\n\n  # For every sample, use the decode that has a maximum mean-metric.\n  best_decode_ind = reduce_func(mean_across_frames, axis=0)\n  best_metrics = metrics[best_decode_ind, np.arange(num_videos), :]\n  return best_metrics, best_decode_ind", "response": "Extracts the best - decode from the metrics according to reduce_func."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes statistics of metrics across multiple decodings.", "response": "def compute_all_metrics_statistics(all_results):\n  \"\"\"Computes statistics of metrics across multiple decodings.\n\n  Args:\n    all_results: dict of 3-D numpy arrays.\n                 Each array has shape=(num_decodes, num_samples, num_frames).\n  Returns:\n    statistics: dict of 1-D numpy arrays, shape=(num_frames).\n                First the statistic (max/mean/std) is computed across the\n                decodes, then the mean is taken across num_samples.\n    decode_inds: dict of 1-D numpy arrays, shape=(num_samples,)\n                 Each element represents the index of the decode corresponding\n                 to the best statistic.\n  \"\"\"\n  statistics = {}\n  decode_inds = {}\n  all_metrics = all_results.keys()\n\n  for key in all_metrics:\n    values = all_results[key]\n    statistics[key + \"_MEAN\"] = np.mean(values, axis=0)\n    statistics[key + \"_STD\"] = np.std(values, axis=0)\n    min_stats, min_decode_ind = reduce_to_best_decode(values, np.argmin)\n    statistics[key + \"_MIN\"] = min_stats\n    decode_inds[key + \"_MIN_DECODE\"] = min_decode_ind\n    max_stats, max_decode_ind = reduce_to_best_decode(values, np.argmax)\n    statistics[key + \"_MAX\"] = max_stats\n    decode_inds[key + \"_MAX_DECODE\"] = max_decode_ind\n\n  # Computes mean of each statistic across the dataset.\n  for key in statistics:\n    statistics[key] = np.mean(statistics[key], axis=0)\n  return statistics, decode_inds"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compute_video_metrics_from_predictions(predictions, decode_hparams):\n  all_results = {}\n\n\n  ssim_all_decodes, psnr_all_decodes = [], []\n  for single_decode in predictions:\n    args = get_zipped_dataset_from_predictions(single_decode)\n    psnr_single, ssim_single = compute_one_decoding_video_metrics(*args)\n    psnr_all_decodes.append(psnr_single)\n    ssim_all_decodes.append(ssim_single)\n  psnr_all_decodes = np.array(psnr_all_decodes)\n  ssim_all_decodes = np.array(ssim_all_decodes)\n  all_results.update({\"PSNR\": psnr_all_decodes, \"SSIM\": ssim_all_decodes})\n  return compute_all_metrics_statistics(all_results)", "response": "Computes metrics from predictions."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compute_video_metrics_from_png_files(\n    output_dirs, problem_name, video_length, frame_shape):\n  \"\"\"Computes the average of all the metric for one decoding.\n\n  This function assumes that all the predicted and target frames\n  have been saved on the disk and sorting them by name will result\n  to consecutive frames saved in order.\n\n  Args:\n    output_dirs: directory with all the saved frames.\n    problem_name: prefix of the saved frames usually name of the problem.\n    video_length: length of the videos.\n    frame_shape: shape of each frame in HxWxC format.\n\n  Returns:\n    Dictionary which contains the average of each metric per frame.\n  \"\"\"\n  ssim_all_decodes, psnr_all_decodes = [], []\n  for output_dir in output_dirs:\n    output_files, target_files = get_target_and_output_filepatterns(\n        output_dir, problem_name)\n    args = get_zipped_dataset_from_png_files(\n        output_files, target_files, video_length, frame_shape)\n    psnr_single, ssim_single = compute_one_decoding_video_metrics(*args)\n    psnr_all_decodes.append(psnr_single)\n    ssim_all_decodes.append(ssim_single)\n\n  psnr_all_decodes = np.array(psnr_all_decodes)\n  ssim_all_decodes = np.array(ssim_all_decodes)\n  all_results = {\"PSNR\": psnr_all_decodes, \"SSIM\": ssim_all_decodes}\n  return compute_all_metrics_statistics(all_results)", "response": "Computes the average of all the metric for one decoding."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compute_and_save_video_metrics(\n    output_dirs, problem_name, video_length, frame_shape):\n  \"\"\"Compute and saves the video metrics.\"\"\"\n  statistics, all_results = compute_video_metrics_from_png_files(\n      output_dirs, problem_name, video_length, frame_shape)\n  for results, output_dir in zip(all_results, output_dirs):\n    save_results(results, output_dir, problem_name)\n\n  parent_dir = os.path.join(output_dirs[0], os.pardir)\n  final_dir = os.path.join(parent_dir, \"decode\")\n  tf.gfile.MakeDirs(parent_dir)\n\n  save_results(statistics, final_dir, problem_name)", "response": "Compute and saves the video metrics."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef swap_time_and_batch_axes(inputs):\n  transposed_axes = tf.concat([[1, 0], tf.range(2, tf.rank(inputs))], axis=0)\n  return tf.transpose(inputs, transposed_axes)", "response": "Swaps time and batch axis."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef encode_to_shape(inputs, shape, scope):\n  with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n    w, h = shape[1], shape[2]\n    x = inputs\n    x = tfl.flatten(x)\n    x = tfl.dense(x, w * h, activation=None, name=\"enc_dense\")\n    x = tf.reshape(x, (-1, w, h, 1))\n    return x", "response": "Encode the given tensor to given image shape."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nencode the given tensor to given image shape.", "response": "def decode_to_shape(inputs, shape, scope):\n  \"\"\"Encode the given tensor to given image shape.\"\"\"\n  with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n    x = inputs\n    x = tfl.flatten(x)\n    x = tfl.dense(x, shape[2], activation=None, name=\"dec_dense\")\n    x = tf.expand_dims(x, axis=1)\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef scheduled_sample_count(ground_truth_x,\n                           generated_x,\n                           batch_size,\n                           scheduled_sample_var):\n  \"\"\"Sample batch with specified mix of groundtruth and generated data points.\n\n  Args:\n    ground_truth_x: tensor of ground-truth data points.\n    generated_x: tensor of generated data points.\n    batch_size: batch size\n    scheduled_sample_var: number of ground-truth examples to include in batch.\n  Returns:\n    New batch with num_ground_truth sampled from ground_truth_x and the rest\n    from generated_x.\n  \"\"\"\n  num_ground_truth = scheduled_sample_var\n  idx = tf.random_shuffle(tf.range(batch_size))\n  ground_truth_idx = tf.gather(idx, tf.range(num_ground_truth))\n  generated_idx = tf.gather(idx, tf.range(num_ground_truth, batch_size))\n\n  ground_truth_examps = tf.gather(ground_truth_x, ground_truth_idx)\n  generated_examps = tf.gather(generated_x, generated_idx)\n\n  output = tf.dynamic_stitch([ground_truth_idx, generated_idx],\n                             [ground_truth_examps, generated_examps])\n  # if batch size is known set it.\n  if isinstance(batch_size, int):\n    output.set_shape([batch_size] + common_layers.shape_list(output)[1:])\n  return output", "response": "Sample a batch with specified mix of groundtruth and generated data points."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninject the additional input into the layer.", "response": "def inject_additional_input(layer, inputs, name, mode=\"concat\"):\n  \"\"\"Injects the additional input into the layer.\n\n  Args:\n    layer: layer that the input should be injected to.\n    inputs: inputs to be injected.\n    name: TF scope name.\n    mode: how the infor should be added to the layer:\n      \"concat\" concats as additional channels.\n      \"multiplicative\" broadcasts inputs and multiply them to the channels.\n      \"multi_additive\" broadcasts inputs and multiply and add to the channels.\n\n  Returns:\n    updated layer.\n\n  Raises:\n    ValueError: in case of unknown mode.\n  \"\"\"\n  layer_shape = common_layers.shape_list(layer)\n  input_shape = common_layers.shape_list(inputs)\n  zeros_mask = tf.zeros(layer_shape, dtype=tf.float32)\n  if mode == \"concat\":\n    emb = encode_to_shape(inputs, layer_shape, name)\n    layer = tf.concat(values=[layer, emb], axis=-1)\n  elif mode == \"multiplicative\":\n    filters = layer_shape[-1]\n    input_reshaped = tf.reshape(inputs, [-1, 1, 1, input_shape[-1]])\n    input_mask = tf.layers.dense(input_reshaped, filters, name=name)\n    input_broad = input_mask + zeros_mask\n    layer *= input_broad\n  elif mode == \"multi_additive\":\n    filters = layer_shape[-1]\n    input_reshaped = tf.reshape(inputs, [-1, 1, 1, input_shape[-1]])\n    input_mul = tf.layers.dense(input_reshaped, filters, name=name + \"_mul\")\n    layer *= tf.nn.sigmoid(input_mul)\n    input_add = tf.layers.dense(input_reshaped, filters, name=name + \"_add\")\n    layer += input_add\n  else:\n    raise ValueError(\"Unknown injection mode: %s\" % mode)\n\n  return layer"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef scheduled_sample_prob(ground_truth_x,\n                          generated_x,\n                          batch_size,\n                          scheduled_sample_var):\n  \"\"\"Probability based scheduled sampling.\n\n  Args:\n    ground_truth_x: tensor of ground-truth data points.\n    generated_x: tensor of generated data points.\n    batch_size: batch size\n    scheduled_sample_var: probability of choosing from ground_truth.\n  Returns:\n    New batch with randomly selected data points.\n  \"\"\"\n  probability_threshold = scheduled_sample_var\n  probability_of_generated = tf.random_uniform([batch_size])\n  return tf.where(probability_of_generated > probability_threshold,\n                  generated_x, ground_truth_x)", "response": "Probability based scheduled sampling."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\napply dynamic neural advection to previous image.", "response": "def dna_transformation(prev_image, dna_input, dna_kernel_size, relu_shift):\n  \"\"\"Apply dynamic neural advection to previous image.\n\n  Args:\n    prev_image: previous image to be transformed.\n    dna_input: hidden lyaer to be used for computing DNA transformation.\n    dna_kernel_size: dna kernel size.\n    relu_shift: shift for ReLU function.\n  Returns:\n    List of images transformed by the predicted CDNA kernels.\n  \"\"\"\n  # Construct translated images.\n  prev_image_pad = tf.pad(prev_image, [[0, 0], [2, 2], [2, 2], [0, 0]])\n  image_height = int(prev_image.get_shape()[1])\n  image_width = int(prev_image.get_shape()[2])\n\n  inputs = []\n  for xkern in range(dna_kernel_size):\n    for ykern in range(dna_kernel_size):\n      inputs.append(\n          tf.expand_dims(\n              tf.slice(prev_image_pad, [0, xkern, ykern, 0],\n                       [-1, image_height, image_width, -1]), [3]))\n  inputs = tf.concat(axis=3, values=inputs)\n\n  # Normalize channels to 1.\n  kernel = tf.nn.relu(dna_input - relu_shift) + relu_shift\n  kernel = tf.expand_dims(\n      kernel / tf.reduce_sum(kernel, [3], keep_dims=True), [4])\n  return tf.reduce_sum(kernel * inputs, [3], keep_dims=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying convolutional dynamic neural advection to previous image.", "response": "def cdna_transformation(prev_image, cdna_input, num_masks, color_channels,\n                        dna_kernel_size, relu_shift):\n  \"\"\"Apply convolutional dynamic neural advection to previous image.\n\n  Args:\n    prev_image: previous image to be transformed.\n    cdna_input: hidden lyaer to be used for computing CDNA kernels.\n    num_masks: number of masks and hence the number of CDNA transformations.\n    color_channels: the number of color channels in the images.\n    dna_kernel_size: dna kernel size.\n    relu_shift: shift for ReLU function.\n  Returns:\n    List of images transformed by the predicted CDNA kernels.\n  \"\"\"\n  batch_size = tf.shape(cdna_input)[0]\n  height = int(prev_image.get_shape()[1])\n  width = int(prev_image.get_shape()[2])\n\n  # Predict kernels using linear function of last hidden layer.\n  cdna_kerns = tfl.dense(\n      cdna_input, dna_kernel_size * dna_kernel_size * num_masks,\n      name=\"cdna_params\",\n      activation=None)\n\n  # Reshape and normalize.\n  cdna_kerns = tf.reshape(\n      cdna_kerns, [batch_size, dna_kernel_size, dna_kernel_size, 1, num_masks])\n  cdna_kerns = (tf.nn.relu(cdna_kerns - relu_shift) + relu_shift)\n  norm_factor = tf.reduce_sum(cdna_kerns, [1, 2, 3], keep_dims=True)\n  cdna_kerns /= norm_factor\n\n  # Treat the color channel dimension as the batch dimension since the same\n  # transformation is applied to each color channel.\n  # Treat the batch dimension as the channel dimension so that\n  # depthwise_conv2d can apply a different transformation to each sample.\n  cdna_kerns = tf.transpose(cdna_kerns, [1, 2, 0, 4, 3])\n  cdna_kerns = tf.reshape(\n      cdna_kerns, [dna_kernel_size, dna_kernel_size, batch_size, num_masks])\n  # Swap the batch and channel dimensions.\n  prev_image = tf.transpose(prev_image, [3, 1, 2, 0])\n\n  # Transform image.\n  transformed = tf.nn.depthwise_conv2d(\n      prev_image, cdna_kerns, [1, 1, 1, 1], \"SAME\")\n\n  # Transpose the dimensions to where they belong.\n  transformed = tf.reshape(\n      transformed, [color_channels, height, width, batch_size, num_masks])\n  transformed = tf.transpose(transformed, [3, 1, 2, 0, 4])\n  transformed = tf.unstack(transformed, axis=-1)\n  return transformed"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tile_and_concat(image, latent, concat_latent=True):\n  if not concat_latent:\n    return image\n  image_shape = common_layers.shape_list(image)\n  latent_shape = common_layers.shape_list(latent)\n  height, width = image_shape[1], image_shape[2]\n  latent_dims = latent_shape[1]\n  height_multiples = height // latent_dims\n  pad = height - (height_multiples * latent_dims)\n  latent = tf.reshape(latent, (-1, latent_dims, 1, 1))\n  latent = tf.tile(latent, (1, height_multiples, width, 1))\n  latent = tf.pad(latent, [[0, 0], [pad // 2, pad // 2], [0, 0], [0, 0]])\n  return tf.concat([image, latent], axis=-1)", "response": "Tile latent and concatenate to image across depth."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _encode_gif(images, fps):\n  writer = WholeVideoWriter(fps)\n  writer.write_multi(images)\n  return writer.finish()", "response": "Encodes numpy images into gif string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntrying to encode images with ffmpeg to check if it works.", "response": "def ffmpeg_works():\n  \"\"\"Tries to encode images with ffmpeg to check if it works.\"\"\"\n  images = np.zeros((2, 32, 32, 3), dtype=np.uint8)\n  try:\n    _encode_gif(images, 2)\n    return True\n  except (IOError, OSError):\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\noutputting a tf. Summary protocol buffer with gif animations.", "response": "def py_gif_summary(tag, images, max_outputs, fps, return_summary_value=False):\n  \"\"\"Outputs a `Summary` protocol buffer with gif animations.\n\n  Args:\n    tag: Name of the summary.\n    images: A 5-D `uint8` `np.array` of shape `[batch_size, time, height, width,\n      channels]` where `channels` is 1 or 3.\n    max_outputs: Max number of batch elements to generate gifs for.\n    fps: frames per second of the animation.\n    return_summary_value: If set to True, return a list of tf.Summary.Value\n                          objects in addition to the protocol buffer.\n\n  Returns:\n    The serialized `Summary` protocol buffer.\n\n  Raises:\n    ValueError: If `images` is not a 5-D `uint8` array with 1 or 3 channels.\n  \"\"\"\n  images = np.asarray(images)\n  if images.dtype != np.uint8:\n    raise ValueError(\"Tensor must have dtype uint8 for gif summary.\")\n  if images.ndim != 5:\n    raise ValueError(\"Tensor must be 5-D for gif summary.\")\n  batch_size, _, height, width, channels = images.shape\n  if channels not in (1, 3):\n    raise ValueError(\"Tensors must have 1 or 3 channels for gif summary.\")\n\n  summ = tf.Summary()\n  all_summ_values = []\n  num_outputs = min(batch_size, max_outputs)\n  for i in range(num_outputs):\n    image_summ = tf.Summary.Image()\n    image_summ.height = height\n    image_summ.width = width\n    image_summ.colorspace = channels  # 1: grayscale, 3: RGB\n    try:\n      image_summ.encoded_image_string = _encode_gif(images[i], fps)\n    except (IOError, OSError) as e:\n      tf.logging.warning(\n          \"Unable to encode images to a gif string because either ffmpeg is \"\n          \"not installed or ffmpeg returned an error: %s. Falling back to an \"\n          \"image summary of the first frame in the sequence.\", e)\n      try:\n        from PIL import Image  # pylint: disable=g-import-not-at-top\n        import io  # pylint: disable=g-import-not-at-top\n        with io.BytesIO() as output:\n          Image.fromarray(images[i][0]).save(output, \"PNG\")\n          image_summ.encoded_image_string = output.getvalue()\n      except ImportError as e:\n        tf.logging.warning(\n            \"Gif summaries requires ffmpeg or PIL to be installed: %s\", e)\n        image_summ.encoded_image_string = \"\"\n    if num_outputs == 1:\n      summ_tag = \"{}/gif\".format(tag)\n    else:\n      summ_tag = \"{}/gif/{}\".format(tag, i)\n    curr_summ_value = tf.Summary.Value(tag=summ_tag, image=image_summ)\n    all_summ_values.append(curr_summ_value)\n    summ.value.add(tag=summ_tag, image=image_summ)\n  summ_str = summ.SerializeToString()\n  if return_summary_value:\n    return all_summ_values, summ_str\n  return summ_str"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\noutput a Summary protocol buffer with gif animations.", "response": "def gif_summary(name, tensor, max_outputs=3, fps=10, collections=None,\n                family=None):\n  \"\"\"Outputs a `Summary` protocol buffer with gif animations.\n\n  Args:\n    name: Name of the summary.\n    tensor: A 5-D `uint8` `Tensor` of shape `[batch_size, time, height, width,\n      channels]` where `channels` is 1 or 3.\n    max_outputs: Max number of batch elements to generate gifs for.\n    fps: frames per second of the animation\n    collections: Optional list of tf.GraphKeys.  The collections to add the\n      summary to.  Defaults to [tf.GraphKeys.SUMMARIES]\n    family: Optional; if provided, used as the prefix of the summary tag name,\n      which controls the tab name used for display on Tensorboard.\n\n  Returns:\n    A scalar `Tensor` of type `string`. The serialized `Summary` protocol\n    buffer.\n\n  Raises:\n    ValueError: if the given tensor has the wrong shape.\n  \"\"\"\n  tensor = tf.convert_to_tensor(tensor)\n  if len(tensor.get_shape()) != 5:\n    raise ValueError(\"Assuming videos given as tensors in the format \"\n                     \"[batch, time, height, width, channels] but got one \"\n                     \"of shape: %s\" % str(tensor.get_shape()))\n  tensor = tf.cast(tensor, tf.uint8)\n  if distribute_summary_op_util.skip_summary():\n    return tf.constant(\"\")\n  with summary_op_util.summary_scope(\n      name, family, values=[tensor]) as (tag, scope):\n    val = tf.py_func(\n        py_gif_summary,\n        [tag, tensor, max_outputs, fps],\n        tf.string,\n        stateful=False,\n        name=scope)\n    summary_op_util.collect(val, collections, [tf.GraphKeys.SUMMARIES])\n  return val"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding a convolutional latent tower for stochastic model.", "response": "def conv_latent_tower(images, time_axis, latent_channels=1, min_logvar=-5,\n                      is_training=False, random_latent=False,\n                      tiny_mode=False, small_mode=False):\n  \"\"\"Builds convolutional latent tower for stochastic model.\n\n  At training time this tower generates a latent distribution (mean and std)\n  conditioned on the entire video. This latent variable will be fed to the\n  main tower as an extra variable to be used for future frames prediction.\n  At inference time, the tower is disabled and only returns latents sampled\n  from N(0,1).\n  If the multi_latent flag is on, a different latent for every timestep would\n  be generated.\n\n  Args:\n    images: tensor of ground truth image sequences\n    time_axis: the time axis  in images tensor\n    latent_channels: number of latent channels\n    min_logvar: minimum value for log_var\n    is_training: whether or not it is training mode\n    random_latent: whether or not generate random latents\n    tiny_mode: whether or not it is tiny_mode. tiny_mode sets the number\n        of conv channels to 1 at each layer. useful for testing the\n        integration tests.\n    small_mode: whether or not it is small_mode. small mode is the same model\n        with less conv and lstm layers and also lower number of channels.\n        suitable for videos with less complexity and testing.\n  Returns:\n    latent_mean: predicted latent mean\n    latent_logvar: predicted latent log variance\n  \"\"\"\n  conv_size = tinyify([32, 64, 64], tiny_mode, small_mode)\n  with tf.variable_scope(\"latent\", reuse=tf.AUTO_REUSE):\n    images = tf.to_float(images)\n    images = tf.unstack(images, axis=time_axis)\n    images = tf.concat(images, axis=3)\n\n    x = images\n    x = common_layers.make_even_size(x)\n    x = tfl.conv2d(x, conv_size[0], [3, 3], strides=(2, 2),\n                   padding=\"SAME\", activation=tf.nn.relu, name=\"latent_conv1\")\n    x = tfcl.layer_norm(x)\n    if not small_mode:\n      x = tfl.conv2d(x, conv_size[1], [3, 3], strides=(2, 2),\n                     padding=\"SAME\", activation=tf.nn.relu, name=\"latent_conv2\")\n      x = tfcl.layer_norm(x)\n    x = tfl.conv2d(x, conv_size[2], [3, 3], strides=(1, 1),\n                   padding=\"SAME\", activation=tf.nn.relu, name=\"latent_conv3\")\n    x = tfcl.layer_norm(x)\n\n    nc = latent_channels\n    mean = tfl.conv2d(x, nc, [3, 3], strides=(2, 2),\n                      padding=\"SAME\", activation=None, name=\"latent_mean\")\n    logv = tfl.conv2d(x, nc, [3, 3], strides=(2, 2),\n                      padding=\"SAME\", activation=tf.nn.relu, name=\"latent_std\")\n    logvar = logv + min_logvar\n\n    # No latent tower at inference time, just standard gaussian.\n    if not is_training:\n      return tf.zeros_like(mean), tf.zeros_like(logvar)\n\n    # No latent in the first phase\n    ret_mean, ret_logvar = tf.cond(\n        random_latent,\n        lambda: (tf.zeros_like(mean), tf.zeros_like(logvar)),\n        lambda: (mean, logvar))\n\n    return ret_mean, ret_logvar"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the KL multiplier based on the schedule.", "response": "def beta_schedule(schedule, global_step, final_beta, decay_start, decay_end):\n  \"\"\"Get KL multiplier (beta) based on the schedule.\"\"\"\n  if decay_start > decay_end:\n    raise ValueError(\"decay_end is smaller than decay_end.\")\n\n  # Since some of the TF schedules do not support incrementing a value,\n  # in all of the schedules, we anneal the beta from final_beta to zero\n  # and then reverse it at the bottom.\n  if schedule == \"constant\":\n    decayed_value = 0.0\n  elif schedule == \"linear\":\n    decayed_value = tf.train.polynomial_decay(\n        learning_rate=final_beta,\n        global_step=global_step - decay_start,\n        decay_steps=decay_end - decay_start,\n        end_learning_rate=0.0)\n  elif schedule == \"noisy_linear_cosine_decay\":\n    decayed_value = tf.train.noisy_linear_cosine_decay(\n        learning_rate=final_beta,\n        global_step=global_step - decay_start,\n        decay_steps=decay_end - decay_start)\n  # TODO(mechcoder): Add log_annealing schedule.\n  else:\n    raise ValueError(\"Unknown beta schedule.\")\n\n  increased_value = final_beta - decayed_value\n  increased_value = tf.maximum(0.0, increased_value)\n\n  beta = tf.case(\n      pred_fn_pairs={\n          tf.less(global_step, decay_start): lambda: 0.0,\n          tf.greater(global_step, decay_end): lambda: final_beta},\n      default=lambda: increased_value)\n  return beta"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_multi(self, frames, encoded_frames=None):\n    if encoded_frames is None:\n      # Infinite iterator.\n      encoded_frames = iter(lambda: None, 1)\n    for (frame, encoded_frame) in zip(frames, encoded_frames):\n      self.write(frame, encoded_frame)", "response": "Writes multiple video frames."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __init_ffmpeg(self, image_shape):\n    import itertools  # pylint: disable=g-import-not-at-top\n    from subprocess import Popen, PIPE  # pylint: disable=g-import-not-at-top,g-multiple-import,g-importing-member\n    ffmpeg = \"ffmpeg\"\n    height, width, channels = image_shape\n    self.cmd = [\n        ffmpeg, \"-y\",\n        \"-f\", \"rawvideo\",\n        \"-vcodec\", \"rawvideo\",\n        \"-r\", \"%.02f\" % self.fps,\n        \"-s\", \"%dx%d\" % (width, height),\n        \"-pix_fmt\", {1: \"gray\", 3: \"rgb24\"}[channels],\n        \"-i\", \"-\",\n        \"-filter_complex\", \"[0:v]split[x][z];[x]fifo[w];[z]palettegen,fifo[y];\"\n                           \"[w][y]paletteuse,fifo\",\n        \"-r\", \"%.02f\" % self.fps,\n        \"-f\", self.file_format,\n        \"-qscale\", \"0\",\n        \"-\"\n    ]\n    self.proc = Popen(\n        self.cmd, stdin=PIPE, stdout=PIPE, stderr=PIPE, bufsize=-1\n    )\n    (self._out_thread, self._err_thread) = itertools.starmap(\n        self._start_reader_thread, [\n            (self.proc.stdout, self._out_chunks),\n            (self.proc.stderr, self._err_chunks)\n        ]\n    )", "response": "Initializes the ffmpeg to read frames."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart a thread for reading output from the given stream.", "response": "def _start_reader_thread(self, stream, chunks):\n    \"\"\"Starts a thread for reading output from FFMPEG.\n\n    The thread reads consecutive chunks from the stream and saves them in\n    the given list.\n\n    Args:\n      stream: output stream of the FFMPEG process.\n      chunks: list to save output chunks to.\n\n    Returns:\n      Thread\n    \"\"\"\n    import io  # pylint: disable=g-import-not-at-top\n    import threading  # pylint: disable=g-import-not-at-top\n    def target():\n      while True:\n        chunk = stream.read(io.DEFAULT_BUFFER_SIZE)\n        if not chunk:\n          break\n        chunks.append(chunk)\n    thread = threading.Thread(target=target)\n    thread.start()\n    return thread"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef finish(self):\n    if self.proc is None:\n      return None\n    self.proc.stdin.close()\n    for thread in (self._out_thread, self._err_thread):\n      thread.join()\n    (out, err) = [\n        b\"\".join(chunks) for chunks in (self._out_chunks, self._err_chunks)\n    ]\n    self.proc.stdout.close()\n    self.proc.stderr.close()\n    if self.proc.returncode:\n      err = \"\\n\".join([\" \".join(self.cmd), err.decode(\"utf8\")])\n      raise IOError(err)\n    del self.proc\n    self.proc = None\n    return out", "response": "Finishes transconding and returns the video."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates flags are set to acceptable values.", "response": "def validate_flags():\n  \"\"\"Validates flags are set to acceptable values.\"\"\"\n  if FLAGS.cloud_mlengine_model_name:\n    assert not FLAGS.server\n    assert not FLAGS.servable_name\n  else:\n    assert FLAGS.server\n    assert FLAGS.servable_name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_request_fn():\n  if FLAGS.cloud_mlengine_model_name:\n    request_fn = serving_utils.make_cloud_mlengine_request_fn(\n        credentials=GoogleCredentials.get_application_default(),\n        model_name=FLAGS.cloud_mlengine_model_name,\n        version=FLAGS.cloud_mlengine_model_version)\n  else:\n\n    request_fn = serving_utils.make_grpc_request_fn(\n        servable_name=FLAGS.servable_name,\n        server=FLAGS.server,\n        timeout_secs=FLAGS.timeout_secs)\n  return request_fn", "response": "Returns a request function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget expected fully connected shape after a series of convolutions.", "response": "def get_fc_dimensions(self, strides, kernel_sizes):\n    \"\"\"Get expected fully connected shape after a series of convolutions.\"\"\"\n    output_height, output_width, _ = self.hparams.problem.frame_shape\n    output_steps = self.hparams.video_num_target_frames\n    output_shape = np.array([output_steps, output_height, output_width])\n    for curr_stride, kernel_size in zip(strides, kernel_sizes):\n      output_shape = self.expected_output_shape(\n          output_shape, np.array(curr_stride), 1, kernel_size)\n    return np.prod(output_shape) * self.hparams.num_discriminator_filters * 8"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef d_step(self, true_frames, gen_frames):\n    hparam_to_disc_loss = {\n        \"least_squares\": gan_losses.least_squares_discriminator_loss,\n        \"cross_entropy\": gan_losses.modified_discriminator_loss,\n        \"wasserstein\": gan_losses.wasserstein_discriminator_loss}\n\n    # Concat across batch-axis.\n    _, batch_size, _, _, _ = common_layers.shape_list(true_frames)\n    all_frames = tf.concat(\n        [true_frames, tf.stop_gradient(gen_frames)], axis=1)\n\n    all_logits = self.discriminator(all_frames)\n    true_logits, fake_logits_stop = \\\n      all_logits[:batch_size], all_logits[batch_size:]\n    mean_true_logits = tf.reduce_mean(true_logits)\n    tf.summary.scalar(\"mean_true_logits\", mean_true_logits)\n\n    mean_fake_logits_stop = tf.reduce_mean(fake_logits_stop)\n    tf.summary.scalar(\"mean_fake_logits_stop\", mean_fake_logits_stop)\n\n    discriminator_loss_func = hparam_to_disc_loss[self.hparams.gan_loss]\n    gan_d_loss = discriminator_loss_func(\n        discriminator_real_outputs=true_logits,\n        discriminator_gen_outputs=fake_logits_stop,\n        add_summaries=True)\n    return gan_d_loss, true_logits, fake_logits_stop", "response": "Performs the discriminator step in computing the GAN loss."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming the generator step in computing the GAN loss.", "response": "def g_step(self, gen_frames, fake_logits_stop):\n    \"\"\"Performs the generator step in computing the GAN loss.\n\n    Args:\n      gen_frames: Generated frames\n      fake_logits_stop: Logits corresponding to the generated frames as per\n                        the discriminator. Assumed to have a stop-gradient term.\n    Returns:\n      gan_g_loss_pos_d: Loss.\n      gan_g_loss_neg_d: -gan_g_loss_pos_d but with a stop gradient on generator.\n    \"\"\"\n    hparam_to_gen_loss = {\n        \"least_squares\": gan_losses.least_squares_generator_loss,\n        \"cross_entropy\": gan_losses.modified_generator_loss,\n        \"wasserstein\": gan_losses.wasserstein_generator_loss\n    }\n\n    fake_logits = self.discriminator(gen_frames)\n    mean_fake_logits = tf.reduce_mean(fake_logits)\n    tf.summary.scalar(\"mean_fake_logits\", mean_fake_logits)\n\n    # Generator loss.\n    # Using gan_g_loss_pos_d updates the discriminator as well.\n    # To avoid this add gan_g_loss_neg_d = -gan_g_loss_pos_d\n    # but with stop gradient on the generator.\n    # This makes sure that the net gradient on the discriminator is zero and\n    # net-gradient on the generator is just due to the gan_g_loss_pos_d.\n    generator_loss_func = hparam_to_gen_loss[self.hparams.gan_loss]\n    gan_g_loss_pos_d = generator_loss_func(\n        discriminator_gen_outputs=fake_logits, add_summaries=True)\n    gan_g_loss_neg_d = -generator_loss_func(\n        discriminator_gen_outputs=fake_logits_stop, add_summaries=True)\n    return gan_g_loss_pos_d, gan_g_loss_neg_d"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_gan_loss(self, true_frames, gen_frames, name):\n    # D - STEP\n    with tf.variable_scope(\"%s_discriminator\" % name, reuse=tf.AUTO_REUSE):\n      gan_d_loss, _, fake_logits_stop = self.d_step(\n          true_frames, gen_frames)\n\n    # G - STEP\n    with tf.variable_scope(\"%s_discriminator\" % name, reuse=True):\n      gan_g_loss_pos_d, gan_g_loss_neg_d = self.g_step(\n          gen_frames, fake_logits_stop)\n    gan_g_loss = gan_g_loss_pos_d + gan_g_loss_neg_d\n    tf.summary.scalar(\"gan_loss_%s\" % name, gan_g_loss_pos_d + gan_d_loss)\n\n    if self.hparams.gan_optimization == \"joint\":\n      gan_loss = gan_g_loss + gan_d_loss\n    else:\n      curr_step = self.get_iteration_num()\n      gan_loss = tf.cond(\n          tf.logical_not(curr_step % 2 == 0), lambda: gan_g_loss,\n          lambda: gan_d_loss)\n    return gan_loss", "response": "This function performs an 1 - 1 update of the discriminator and generator at every step."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets extra loss from VAE and GAN.", "response": "def get_extra_loss(self, latent_means=None, latent_stds=None,\n                     true_frames=None, gen_frames=None):\n    \"\"\"Gets extra loss from VAE and GAN.\"\"\"\n    if not self.is_training:\n      return 0.0\n\n    vae_loss, d_vae_loss, d_gan_loss = 0.0, 0.0, 0.0\n    # Use sv2p's KL divergence computation.\n    if self.hparams.use_vae:\n      vae_loss = super(NextFrameSavpBase, self).get_extra_loss(\n          latent_means=latent_means, latent_stds=latent_stds)\n\n    if self.hparams.use_gan:\n      # Strip out the first context_frames for the true_frames\n      # Strip out the first context_frames - 1 for the gen_frames\n      context_frames = self.hparams.video_num_input_frames\n      true_frames = tf.stack(\n          tf.unstack(true_frames, axis=0)[context_frames:])\n\n      # discriminator for VAE.\n      if self.hparams.use_vae:\n        gen_enc_frames = tf.stack(\n            tf.unstack(gen_frames, axis=0)[context_frames-1:])\n        d_vae_loss = self.get_gan_loss(true_frames, gen_enc_frames, name=\"vae\")\n\n      # discriminator for GAN.\n      gen_prior_frames = tf.stack(\n          tf.unstack(self.gen_prior_video, axis=0)[context_frames-1:])\n      d_gan_loss = self.get_gan_loss(true_frames, gen_prior_frames, name=\"gan\")\n\n    return (\n        vae_loss + self.hparams.gan_loss_multiplier * d_gan_loss +\n        self.hparams.gan_vae_loss_multiplier * d_vae_loss)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npad apply 3 - D convolution and leaky relu.", "response": "def pad_conv3d_lrelu(self, activations, n_filters, kernel_size, strides,\n                       scope):\n    \"\"\"Pad, apply 3-D convolution and leaky relu.\"\"\"\n    padding = [[0, 0], [1, 1], [1, 1], [1, 1], [0, 0]]\n\n    # tf.nn.conv3d accepts a list of 5 values for strides\n    # with first and last value equal to 1\n    if isinstance(strides, numbers.Integral):\n      strides = [strides] * 3\n    strides = [1] + strides + [1]\n\n    # Filter_shape = [K, K, K, num_input, num_output]\n    filter_shape = (\n        [kernel_size]*3 + activations.shape[-1:].as_list() + [n_filters])\n\n    with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n      conv_filter = tf.get_variable(\n          \"conv_filter\", shape=filter_shape,\n          initializer=tf.truncated_normal_initializer(stddev=0.02))\n\n      if self.hparams.use_spectral_norm:\n        conv_filter, assign_op = common_layers.apply_spectral_norm(conv_filter)\n        if self.is_training:\n          tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, assign_op)\n\n      padded = tf.pad(activations, padding)\n      convolved = tf.nn.conv3d(\n          padded, conv_filter, strides=strides, padding=\"VALID\")\n      rectified = tf.nn.leaky_relu(convolved, alpha=0.2)\n    return rectified"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef weight(w, sparsity):\n  w_shape = common_layers.shape_list(w)\n  k = int(np.prod(w_shape[:-1]))\n  count = tf.to_int32(k * sparsity)\n  mask = common_layers.weight_targeting(w, count)\n  return (1 - mask) * w", "response": "Weight - level magnitude pruning."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprune the weights of a model and evaluate.", "response": "def sparsify(sess, eval_model, pruning_strategy, pruning_params):\n  \"\"\"Prune the weights of a model and evaluate.\"\"\"\n  weights = tf.trainable_variables()\n\n  def should_prune(name):\n    \"\"\"Whether to prune a weight or not.\"\"\"\n    in_whitelist = not pruning_params.white_list or any(\n        e in name for e in pruning_params.white_list)\n    in_blacklist = any(e in name for e in pruning_params.black_list)\n\n    if pruning_params.white_list and not in_whitelist:\n      return False\n    elif in_blacklist:\n      return False\n\n    return True\n\n  weights = [w for w in weights if should_prune(w.name)]\n  tf.logging.info(\"Pruning weights: %s\" % weights)\n  unpruned_weights = sess.run(weights)\n\n  reset_op = tf.no_op()\n  for w, ow in zip(weights, unpruned_weights):\n    op = tf.assign(w, ow)\n    reset_op = tf.group(reset_op, op)\n\n  for sparsity in pruning_params.sparsities:\n    set_weights_op = tf.no_op()\n    for w in weights:\n      op = tf.assign(w, pruning_strategy(w, sparsity))\n      set_weights_op = tf.group(set_weights_op, op)\n    sess.run(set_weights_op)\n\n    acc = eval_model()\n    tf.logging.info(\"\\tPruning to sparsity = %f: acc = %f\" % (sparsity, acc))\n    sess.run(reset_op)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload the configuration from the options.", "response": "def load_config(self):\n    \"\"\"Loads the configuration.\"\"\"\n    config = dict([(key, value) for key, value in iteritems(self.options)\n                   if key in self.cfg.settings and value is not None])\n    for key, value in iteritems(config):\n      self.cfg.set(key.lower(), value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset of hyperparameters for PPO base model v1.", "response": "def ppo_base_v1():\n  \"\"\"Set of hyperparameters.\"\"\"\n  hparams = common_hparams.basic_params1()\n  hparams.learning_rate_schedule = \"constant\"\n  hparams.learning_rate_constant = 1e-4\n  hparams.clip_grad_norm = 0.5\n  hparams.weight_decay = 0\n  # If set, extends the LR warmup to all epochs except the final one.\n  hparams.add_hparam(\"lr_decay_in_final_epoch\", False)\n  hparams.add_hparam(\"init_mean_factor\", 0.1)\n  hparams.add_hparam(\"init_logstd\", 0.1)\n  hparams.add_hparam(\"policy_layers\", (100, 100))\n  hparams.add_hparam(\"value_layers\", (100, 100))\n  hparams.add_hparam(\"clipping_coef\", 0.2)\n  hparams.add_hparam(\"gae_gamma\", 0.99)\n  hparams.add_hparam(\"gae_lambda\", 0.95)\n  hparams.add_hparam(\"entropy_loss_coef\", 0.01)\n  hparams.add_hparam(\"value_loss_coef\", 1)\n  hparams.add_hparam(\"optimization_epochs\", 15)\n  hparams.add_hparam(\"epoch_length\", 200)\n  hparams.add_hparam(\"epochs_num\", 2000)\n  hparams.add_hparam(\"eval_every_epochs\", 10)\n  hparams.add_hparam(\"save_models_every_epochs\", 30)\n  hparams.add_hparam(\"optimization_batch_size\", 50)\n  hparams.add_hparam(\"intrinsic_reward_scale\", 0.)\n  hparams.add_hparam(\"logits_clip\", 0.0)\n  hparams.add_hparam(\"dropout_ppo\", 0.1)\n  hparams.add_hparam(\"effective_num_agents\", None)\n  # TODO(afrozm): Clean this up, this is used in PPO learner to get modalities.\n  hparams.add_hparam(\"policy_problem_name\", \"dummy_policy_problem\")\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ppo_original_params():\n  hparams = ppo_atari_base()\n  hparams.learning_rate_constant = 2.5e-4\n  hparams.gae_gamma = 0.99\n  hparams.gae_lambda = 0.95\n  hparams.clipping_coef = 0.1\n  hparams.value_loss_coef = 1\n  hparams.entropy_loss_coef = 0.01\n  hparams.eval_every_epochs = 200\n  hparams.dropout_ppo = 0.1\n  # The parameters below are modified to accommodate short epoch_length (which\n  # is needed for model based rollouts).\n  hparams.epoch_length = 50\n  hparams.optimization_batch_size = 20\n  return hparams", "response": "Parameters based on the original PPO paper."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ppo_tiny_world_model():\n  hparams = ppo_original_params()\n  hparams.policy_network = \"next_frame_basic_deterministic\"\n  hparams_keys = hparams.values().keys()\n  video_hparams = basic_deterministic_params.next_frame_tiny()\n  for (name, value) in six.iteritems(video_hparams.values()):\n    if name in hparams_keys:\n      hparams.set_hparam(name, value)\n    else:\n      hparams.add_hparam(name, value)\n  hparams.weight_decay = 0\n  return hparams", "response": "Atari parameters with world model as policy."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_simulated_env_fn(**env_kwargs):\n  def env_fn(in_graph):\n    class_ = SimulatedBatchEnv if in_graph else SimulatedBatchGymEnv\n    return class_(**env_kwargs)\n  return env_fn", "response": "Returns a function creating a simulated env."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_simulated_env_kwargs(real_env, hparams, **extra_kwargs):\n  objs_and_attrs = [\n      (real_env, [\n          \"reward_range\", \"observation_space\", \"action_space\", \"frame_height\",\n          \"frame_width\"\n      ]),\n      (hparams, [\"frame_stack_size\", \"intrinsic_reward_scale\"])\n  ]\n  kwargs = {\n      attr: getattr(obj, attr)  # pylint: disable=g-complex-comprehension\n      for (obj, attrs) in objs_and_attrs for attr in attrs\n  }\n  kwargs[\"model_name\"] = hparams.generative_model\n  kwargs[\"model_hparams\"] = trainer_lib.create_hparams(\n      hparams.generative_model_params\n  )\n  if hparams.wm_policy_param_sharing:\n    kwargs[\"model_hparams\"].optimizer_zero_grads = True\n  kwargs.update(extra_kwargs)\n  return kwargs", "response": "Extracts simulated env kwargs from real_env and loop hparams."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_policy(observations, hparams, action_space):\n  if not isinstance(action_space, gym.spaces.Discrete):\n    raise ValueError(\"Expecting discrete action space.\")\n\n  obs_shape = common_layers.shape_list(observations)\n  (frame_height, frame_width) = obs_shape[2:4]\n\n  # TODO(afrozm): We have these dummy problems mainly for hparams, so cleanup\n  # when possible and do this properly.\n  if hparams.policy_problem_name == \"dummy_policy_problem_ttt\":\n    tf.logging.info(\"Using DummyPolicyProblemTTT for the policy.\")\n    policy_problem = tic_tac_toe_env.DummyPolicyProblemTTT()\n  else:\n    tf.logging.info(\"Using DummyPolicyProblem for the policy.\")\n    policy_problem = DummyPolicyProblem(action_space, frame_height, frame_width)\n\n  trainer_lib.add_problem_hparams(hparams, policy_problem)\n  hparams.force_full_predict = True\n  model = registry.model(hparams.policy_network)(\n      hparams, tf.estimator.ModeKeys.TRAIN\n  )\n  try:\n    num_target_frames = hparams.video_num_target_frames\n  except AttributeError:\n    num_target_frames = 1\n  features = {\n      \"inputs\": observations,\n      \"input_action\": tf.zeros(obs_shape[:2] + [1], dtype=tf.int32),\n      \"input_reward\": tf.zeros(obs_shape[:2] + [1], dtype=tf.int32),\n      \"targets\": tf.zeros(obs_shape[:1] + [num_target_frames] + obs_shape[2:]),\n      \"target_action\": tf.zeros(\n          obs_shape[:1] + [num_target_frames, 1], dtype=tf.int32),\n      \"target_reward\": tf.zeros(\n          obs_shape[:1] + [num_target_frames, 1], dtype=tf.int32),\n      \"target_policy\": tf.zeros(\n          obs_shape[:1] + [num_target_frames] + [action_space.n]),\n      \"target_value\": tf.zeros(\n          obs_shape[:1] + [num_target_frames])\n  }\n  with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE):\n    t2t_model.create_dummy_vars()\n    (targets, _) = model(features)\n  return (targets[\"target_policy\"][:, 0, :], targets[\"target_value\"][:, 0])", "response": "Get a policy network."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbases set of hparams for model - free PPO.", "response": "def rlmf_tictactoe():\n  \"\"\"Base set of hparams for model-free PPO.\"\"\"\n  hparams = rlmf_original()\n  hparams.game = \"tictactoe\"\n  hparams.rl_env_name = \"T2TEnv-TicTacToeEnv-v0\"\n  # Since we don't have any no-op actions, otherwise we have to have an\n  # attribute called `get_action_meanings`.\n  hparams.eval_max_num_noops = 0\n  hparams.max_num_noops = 0\n  hparams.rl_should_derive_observation_space = False\n\n  hparams.policy_network = \"feed_forward_categorical_policy\"\n  hparams.base_algo_params = \"ppo_ttt_params\"\n\n  # Number of last observations to feed to the agent\n  hparams.frame_stack_size = 1\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rlmf_eval():\n  hparams = rlmf_original()\n  hparams.batch_size = 8\n  hparams.eval_sampling_temps = [0.0, 0.5, 1.0]\n  hparams.eval_rl_env_max_episode_steps = -1\n  hparams.add_hparam(\"ppo_epoch_length\", 128)\n  hparams.add_hparam(\"ppo_optimization_batch_size\", 32)\n  hparams.add_hparam(\"ppo_epochs_num\", 10000)\n  hparams.add_hparam(\"ppo_eval_every_epochs\", 500)\n  hparams.add_hparam(\"attempt\", 0)\n  hparams.add_hparam(\"moe_loss_coef\", 0)\n  return hparams", "response": "Eval set of hparams for model - free PPO."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfeeding - forward Gaussian.", "response": "def feed_forward_gaussian_fun(action_space, config, observations):\n  \"\"\"Feed-forward Gaussian.\"\"\"\n  if not isinstance(action_space, gym.spaces.box.Box):\n    raise ValueError(\"Expecting continuous action space.\")\n\n  mean_weights_initializer = tf.initializers.variance_scaling(\n      scale=config.init_mean_factor)\n  logstd_initializer = tf.random_normal_initializer(config.init_logstd, 1e-10)\n\n  flat_observations = tf.reshape(observations, [\n      tf.shape(observations)[0], tf.shape(observations)[1],\n      functools.reduce(operator.mul, observations.shape.as_list()[2:], 1)])\n\n  with tf.variable_scope(\"network_parameters\"):\n    with tf.variable_scope(\"policy\"):\n      x = flat_observations\n      for size in config.policy_layers:\n        x = tf.layers.dense(x, size, activation=tf.nn.relu)\n      mean = tf.layers.dense(\n          x, action_space.shape[0], activation=tf.tanh,\n          kernel_initializer=mean_weights_initializer)\n      logstd = tf.get_variable(\n          \"logstd\", mean.shape[2:], tf.float32, logstd_initializer)\n      logstd = tf.tile(\n          logstd[None, None],\n          [tf.shape(mean)[0], tf.shape(mean)[1]] + [1] * (mean.shape.ndims - 2))\n    with tf.variable_scope(\"value\"):\n      x = flat_observations\n      for size in config.value_layers:\n        x = tf.layers.dense(x, size, activation=tf.nn.relu)\n      value = tf.layers.dense(x, 1)[..., 0]\n  mean = tf.check_numerics(mean, \"mean\")\n  logstd = tf.check_numerics(logstd, \"logstd\")\n  value = tf.check_numerics(value, \"value\")\n\n  policy = tfp.distributions.MultivariateNormalDiag(mean, tf.exp(logstd))\n\n  return NetworkOutput(policy, value, lambda a: tf.clip_by_value(a, -2., 2))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _curvature_range(self):\n    self._curv_win = tf.get_variable(\"curv_win\",\n                                     dtype=tf.float32,\n                                     trainable=False,\n                                     shape=[self.curvature_window_width,],\n                                     initializer=tf.zeros_initializer)\n    # We use log smoothing for curvature range\n    self._curv_win = tf.scatter_update(self._curv_win,\n                                       self._step % self.curvature_window_width,\n                                       tf.log(self._grad_norm_squared))\n    # Note here the iterations start from iteration 0\n    valid_window = tf.slice(self._curv_win,\n                            tf.constant([0,]),\n                            tf.expand_dims(\n                                tf.minimum(\n                                    tf.constant(self.curvature_window_width),\n                                    self._step + 1), dim=0))\n    self._h_min_t = tf.reduce_min(valid_window)\n    self._h_max_t = tf.reduce_max(valid_window)\n\n    curv_range_ops = []\n    with tf.control_dependencies([self._h_min_t, self._h_max_t]):\n      avg_op = self._moving_averager.apply([self._h_min_t, self._h_max_t])\n      with tf.control_dependencies([avg_op]):\n        self._h_min = tf.exp(\n            tf.identity(self._moving_averager.average(self._h_min_t)))\n        self._h_max = tf.exp(\n            tf.identity(self._moving_averager.average(self._h_max_t)))\n        if self._sparsity_debias:\n          self._h_min *= self._sparsity_avg\n          self._h_max *= self._sparsity_avg\n    curv_range_ops.append(avg_op)\n    return curv_range_ops", "response": "Internal function that creates the curvature range."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _grad_variance(self):\n    grad_var_ops = []\n    tensor_to_avg = []\n    for t, g in zip(self._vars, self._grad):\n      if isinstance(g, tf.IndexedSlices):\n        tensor_to_avg.append(\n            tf.reshape(tf.unsorted_segment_sum(g.values,\n                                               g.indices,\n                                               g.dense_shape[0]),\n                       shape=t.get_shape()))\n      else:\n        tensor_to_avg.append(g)\n    avg_op = self._moving_averager.apply(tensor_to_avg)\n    grad_var_ops.append(avg_op)\n    with tf.control_dependencies([avg_op]):\n      self._grad_avg = [self._moving_averager.average(val)\n                        for val in tensor_to_avg]\n      self._grad_avg_squared = [tf.square(val) for val in self._grad_avg]\n\n    # Compute Variance\n    self._grad_var = tf.maximum(\n        tf.constant(1e-6, dtype=self._grad_norm_squared_avg.dtype),\n        self._grad_norm_squared_avg\n        - tf.add_n([tf.reduce_sum(val) for val in self._grad_avg_squared]))\n    if self._sparsity_debias:\n      self._grad_var *= self._sparsity_avg\n    return grad_var_ops", "response": "Estimate of gradient Variance."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndistances to optimum. Returns: D_t ops", "response": "def _dist_to_opt(self):\n    \"\"\"Distance to optimum.\n\n    Returns:\n      D_t ops\n    \"\"\"\n    dist_to_opt_ops = []\n    # Running average of the norm of gradient\n    self._grad_norm = tf.sqrt(self._grad_norm_squared)\n    avg_op = self._moving_averager.apply([self._grad_norm,])\n    dist_to_opt_ops.append(avg_op)\n    with tf.control_dependencies([avg_op]):\n      self._grad_norm_avg = self._moving_averager.average(self._grad_norm)\n      # Single iteration distance estimation, note here\n      # self._grad_norm_avg is per variable\n      self._d_t = self._grad_norm_avg / self._grad_norm_squared_avg\n    # Running average of distance\n    avg_op = self._moving_averager.apply([self._d_t])\n    dist_to_opt_ops.append(avg_op)\n    with tf.control_dependencies([avg_op]):\n      self._dist_to_opt_avg = tf.identity(\n          self._moving_averager.average(self._d_t))\n      if self._sparsity_debias:\n        self._dist_to_opt_avg /= tf.sqrt(self._sparsity_avg)\n    return dist_to_opt_ops"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprepares Variables for YellowFin.", "response": "def _prepare_variables(self):\n    \"\"\"Prepare Variables for YellowFin.\n\n    Returns:\n      Grad**2, Norm, Norm**2, Mean(Norm**2) ops\n    \"\"\"\n    self._moving_averager = tf.train.ExponentialMovingAverage(\n        decay=self._beta, zero_debias=self._zero_debias)\n    # assert self._grad is not None and len(self._grad) > 0\n    # List for the returned Operations\n    prepare_variables_op = []\n\n    # Get per var g**2 and norm**2\n    self._grad_squared = []\n    self._grad_norm_squared = []\n\n    # Gradient squared\n    for v, g in zip(self._vars, self._grad):\n      if g is None: continue\n      with tf.colocate_with(v):\n        self._grad_squared.append(tf.square(g))\n\n    # Norm squared.\n    self._grad_norm_squared = [tf.reduce_sum(g_sq)\n                               for g_sq in self._grad_squared]\n\n    if self._sparsity_debias:\n      avg_op_sparsity = self._grad_sparsity()\n      prepare_variables_op.append(avg_op_sparsity)\n\n    # The following running average on squared norm of gradient\n    # is shared by grad_var and dist_to_opt\n    avg_op = self._moving_averager.apply(self._grad_norm_squared)\n\n    with tf.control_dependencies([avg_op]):\n      self._grad_norm_squared_avg = [self._moving_averager.average(val)\n                                     for val in self._grad_norm_squared]\n      self._grad_norm_squared = tf.add_n(self._grad_norm_squared)\n      self._grad_norm_squared_avg = tf.add_n(self._grad_norm_squared_avg)\n\n    prepare_variables_op.append(avg_op)\n    return tf.group(*prepare_variables_op)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_cubic_root(self):\n    # We have the equation x^2 D^2 + (1-x)^4 * C / h_min^2\n    # where x = sqrt(mu).\n    # We substitute x, which is sqrt(mu), with x = y + 1.\n    # It gives y^3 + py = q\n    # where p = (D^2 h_min^2)/(2*C) and q = -p.\n    # We use the Vieta's substitution to compute the root.\n    # There is only one real solution y (which is in [0, 1] ).\n    # http://mathworld.wolfram.com/VietasSubstitution.html\n    assert_array = [\n        tf.Assert(\n            tf.logical_not(tf.is_nan(self._dist_to_opt_avg)),\n            [self._dist_to_opt_avg,]),\n        tf.Assert(\n            tf.logical_not(tf.is_nan(self._h_min)),\n            [self._h_min,]),\n        tf.Assert(\n            tf.logical_not(tf.is_nan(self._grad_var)),\n            [self._grad_var,]),\n        tf.Assert(\n            tf.logical_not(tf.is_inf(self._dist_to_opt_avg)),\n            [self._dist_to_opt_avg,]),\n        tf.Assert(\n            tf.logical_not(tf.is_inf(self._h_min)),\n            [self._h_min,]),\n        tf.Assert(\n            tf.logical_not(tf.is_inf(self._grad_var)),\n            [self._grad_var,])\n    ]\n    with tf.control_dependencies(assert_array):\n      p = self._dist_to_opt_avg**2 * self._h_min**2 / 2 / self._grad_var\n      w3 = (-tf.sqrt(p**2 + 4.0 / 27.0 * p**3) - p) / 2.0\n      w = tf.sign(w3) * tf.pow(tf.abs(w3), 1.0/3.0)\n      y = w - p / 3.0 / w\n      x = y + 1\n    return x", "response": "Get the cubic root."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_lr_tensor(self):\n    lr = tf.squared_difference(1.0, tf.sqrt(self._mu)) / self._h_min\n    return lr", "response": "Get lr minimizing the surrogate."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the min mu which minimize the surrogate.", "response": "def _get_mu_tensor(self):\n    \"\"\"Get the min mu which minimize the surrogate.\n\n    Returns:\n      The mu_t.\n    \"\"\"\n    root = self._get_cubic_root()\n    dr = self._h_max / self._h_min\n    mu = tf.maximum(\n        root**2, ((tf.sqrt(dr) - 1) / (tf.sqrt(dr) + 1))**2)\n    return mu"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _yellowfin(self):\n    # List for the returned Operations.\n    yellowfin_ops = []\n\n    # Curvature range ops.\n    curv_range_ops = self._curvature_range()\n    yellowfin_ops += curv_range_ops\n    # Estimate of gradient Variance ops.\n    grad_var_ops = self._grad_variance()\n    yellowfin_ops += grad_var_ops\n    # Distance to optimum ops.\n    dist_to_opt_ops = self._dist_to_opt()\n    yellowfin_ops += dist_to_opt_ops\n\n    # Single-Step: minimizes the surrogate for the expected\n    # squared distance from the optimum of a local quadratic\n    # approximation after a single step while keeping all directions in the\n    # robust region.\n    self._mu = tf.identity(tf.cond(self._do_tune,\n                                   self._get_mu_tensor,\n                                   lambda: self._mu_var))\n    with tf.control_dependencies([self._mu]):\n      self._lr = tf.identity(tf.cond(self._do_tune,\n                                     self._get_lr_tensor,\n                                     lambda: self._lr_var))\n\n    # Tune learning rate and momentum.\n    with tf.control_dependencies([self._mu, self._lr]):\n      self._mu = self._beta * self._mu_var + (1 - self._beta) * self._mu\n      self._lr = self._beta * self._lr_var + (1 - self._beta) * self._lr\n      yellowfin_ops.append(tf.assign(self._mu_var, self._mu))\n      yellowfin_ops.append(tf.assign(self._lr_var, self._lr))\n\n    yellowfin_ops = tf.group(*yellowfin_ops)\n    return yellowfin_ops", "response": "YellowFin auto - tuning optimizer based on momentum SGD."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\napply gradients and tune hyperparams with YellowFin.", "response": "def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n    \"\"\"Applying gradients and tune hyperparams with YellowFin.\n\n    Args:\n      grads_and_vars: List of (gradient, variable) pairs as returned by\n        compute_gradients().\n      global_step: Optional Variable to increment by one after the\n        variables have been updated.\n      name:  Optional name for the returned operation. Default to the\n        name passed to the Optimizer constructor.\n\n    Returns:\n        (A group of operations)\n        Variable Update with Momentum ops,\n        YellowFin ops(Curvature, Variance, Distance) ops,\n        SingleStep and lr_mu tuning ops,\n        Step increment ops.\n    \"\"\"\n    self._grad, self._vars = zip(*[(g, t)\n                                   for g, t in grads_and_vars if g is not None])\n\n    # Var update with Momentum.\n    with tf.variable_scope(\"apply_updates\"):\n      # Gradient Clipping?\n      if self._clip_thresh_var is not None:\n        self._grad, _ = tf.clip_by_global_norm(\n            self._grad, self._clip_thresh_var)\n\n        apply_grad_op = self._momentum_optimizer.apply_gradients(\n            zip(self._grad, self._vars),\n            global_step=global_step,\n            name=name)\n      else:\n        apply_grad_op = self._momentum_optimizer.apply_gradients(\n            zip(self._grad, self._vars),\n            global_step=global_step,\n            name=name)\n\n    # Begin lr and mu tuning.\n    with tf.variable_scope(\"prepare_yellowFin_variables\"):\n      # the dependencies ideally only need to be after clip is done,\n      # i.e. depends on self._grads. However, the control_dependencies\n      # does not support indexed slice for sparse gradients.\n      # The alternative dependencies here might be slightly slower due\n      # to less parallelization.\n      with tf.control_dependencies([apply_grad_op,]):\n        prepare_variables_op = self._prepare_variables()\n\n    with tf.variable_scope(\"yellowfin\"):\n      with tf.control_dependencies([prepare_variables_op]):\n        yellowfin_op = self._yellowfin()\n\n    # Update YellowFin step variable.\n    with tf.control_dependencies([yellowfin_op]):\n      self._increment_step_op = tf.assign_add(self._step, 1).op\n\n    return tf.group(apply_grad_op,\n                    prepare_variables_op,\n                    yellowfin_op,\n                    self._increment_step_op)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compute_gradients(self,\n                        loss,\n                        var_list,\n                        global_step=None,\n                        gate_gradients=GATE_OP,\n                        aggregation_method=None,\n                        colocate_gradients_with_ops=False,\n                        name=None,\n                        grad_loss=None):\n    \"\"\"Compute gradients through momentum optimizer.\n\n    Args:\n      loss: A Tensor containing the value to minimize.\n      var_list: Optional list or tuple of tf.Variable to update\n        to minimize loss. Defaults to the list of variables collected\n        in the graph under the key GraphKey.TRAINABLE_VARIABLES.\n      global_step: Optional Variable to increment by one after the\n        variables have been updated.\n      gate_gradients: How to gate the computation of gradients.\n        Can be GATE_NONE, GATE_OP, or GATE_GRAPH.\n      aggregation_method: Specifies the method used to combine\n        gradient terms. Valid values are defined in the class AggregationMethod.\n      colocate_gradients_with_ops: If True, try collocating gradients with\n        the corresponding op.\n      name: Optional name for the returned operation. Default to the name\n        passed to the Optimizer constructor.\n      grad_loss: Optional. A Tensor holding the gradient computed for loss.\n\n    Returns:\n      A list of (gradient, variable) pairs. Variable is always present,\n        but gradient can be None.\n    \"\"\"\n    del global_step, name  # Unused for now.\n    return self._momentum_optimizer.compute_gradients(\n        loss,\n        var_list=var_list,\n        gate_gradients=gate_gradients,\n        aggregation_method=aggregation_method,\n        colocate_gradients_with_ops=colocate_gradients_with_ops,\n        grad_loss=grad_loss)", "response": "Compute gradients through the momentum optimizer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadapting from TensorFlow Optimizer base class member function.", "response": "def minimize(self,\n               loss,\n               global_step=None,\n               var_list=None,\n               gate_gradients=GATE_OP,\n               aggregation_method=None,\n               colocate_gradients_with_ops=False,\n               name=None,\n               grad_loss=None):\n    \"\"\"Adapted from TensorFlow Optimizer base class member function.\n\n    Add operations to minimize `loss` by updating `var_list`.\n    This method simply combines calls `compute_gradients()` and\n    `apply_gradients()`. If you want to process the gradient before applying\n    them call `tf.gradients()` and `self.apply_gradients()` explicitly instead\n    of using this function.\n\n    Args:\n      loss: A Tensor containing the value to minimize.\n      global_step: Optional Variable to increment by one after the variables\n        have been updated.\n      var_list: Optional list or tuple of Variable objects to update to\n        minimize loss. Defaults to the list of variables collected in\n        the graph under the key GraphKeys.TRAINABLE_VARIABLES.\n      gate_gradients: How to gate the computation of gradients.\n        Can be GATE_NONE, GATE_OP, or GATE_GRAPH.\n      aggregation_method: Specifies the method used to combine gradient terms.\n        Valid values are defined in the class AggregationMethod.\n      colocate_gradients_with_ops: If True, try collocating gradients with\n        the corresponding op.\n      name: Optional name for the returned operation.\n      grad_loss: Optional. A Tensor holding the gradient computed for loss.\n\n    Returns:\n      An Operation that updates the variables in var_list.\n        If global_step was not None, that operation also increments global_step.\n\n    Raises:\n      ValueError: if no gradients are provided for any variable.\n    \"\"\"\n    grads_and_vars = self._momentum_optimizer.compute_gradients(\n        loss,\n        var_list=var_list,\n        gate_gradients=gate_gradients,\n        aggregation_method=aggregation_method,\n        colocate_gradients_with_ops=colocate_gradients_with_ops,\n        grad_loss=grad_loss)\n\n    vars_with_grad = [v for g, v in grads_and_vars if g is not None]\n    if not vars_with_grad:\n      raise ValueError(\n          \"No gradients provided for any variable, check your graph for ops\"\n          \" that do not support gradients, between variables %s and loss %s.\" %\n          ([str(v) for _, v in grads_and_vars], loss))\n    for g, v in grads_and_vars:\n      print(\"g \", g)\n      print(\"v \", v)\n\n    return self.apply_gradients(grads_and_vars,\n                                global_step=global_step,\n                                name=name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef residual_dilated_conv(x, repeat, padding, name, hparams):\n  with tf.variable_scope(name):\n    k = (hparams.kernel_height, hparams.kernel_width)\n    dilations_and_kernels = [((2**i, 1), k)\n                             for i in range(hparams.num_hidden_layers)]\n    for i in range(repeat):\n      with tf.variable_scope(\"repeat_%d\" % i):\n        y = common_layers.conv_block(\n            common_layers.layer_norm(x, hparams.hidden_size, name=\"lnorm\"),\n            hparams.hidden_size,\n            dilations_and_kernels,\n            padding=padding,\n            name=\"residual_conv\")\n        y = tf.nn.dropout(y, 1.0 - hparams.dropout)\n        x += y\n    return x", "response": "A stack of convolution blocks with residual connections."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads and prepairs the dataset to be parsed by the data_generator.", "response": "def _download_and_parse_dataset(tmp_dir, train):\n  \"\"\"Downloads and prepairs the dataset to be parsed by the data_generator.\"\"\"\n  file_path = generator_utils.maybe_download(tmp_dir, _SNLI_ZIP, _SNLI_URL)\n  zip_ref = zipfile.ZipFile(file_path, 'r')\n  zip_ref.extractall(tmp_dir)\n  zip_ref.close()\n\n  file_name = 'train' if train else 'dev'\n  dataset_file_path = os.path.join(tmp_dir, _SNLI_DATA_PATH % file_name)\n  _parse_dataset(dataset_file_path, tmp_dir, train)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_tokens_and_tags(parse_str):\n  tokens = []\n  parse_split = parse_str.split(' ')\n  for p in parse_split:\n    assert p.startswith('(') or p.endswith(')')\n    if p.endswith(')'):\n      token = p.replace(')', '')\n      tokens.append(token)\n\n  return tokens", "response": "Parse str to tokens and pos tags."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _parse_dataset(file_path, tmp_dir, train):\n  input_path = file_path\n  file_name = 'train' if train else 'dev'\n  gen_output_path = os.path.join(tmp_dir, file_name + '.txt')\n  example_output_path = os.path.join(tmp_dir, _EXAMPLES_FILE)\n\n  print('input path: ' + input_path)\n  print('gen_output_path: ' + gen_output_path)\n  print('example_output_path: ' + example_output_path)\n\n  input_file = tf.gfile.Open(input_path, mode='r')\n  examples = []\n  for counter, line in enumerate(input_file):\n    if counter == 0:  # Ignore first line since its a header.\n      continue\n    # Get the token and embedding vector.\n    line_split = line.split('\\t')\n\n    parse1 = line_split[_PARSE1_INDEX]\n    parse2 = line_split[_PARSE2_INDEX]\n    consensus_label = line_split[_LABEL_INDEX]\n\n    tokens1 = _get_tokens_and_tags(parse1)\n    tokens2 = _get_tokens_and_tags(parse2)\n\n    tokens1_str = ' '.join(tokens1)\n    tokens2_str = ' '.join(tokens2)\n\n    if consensus_label != '-':\n      examples.append([tokens1_str, tokens2_str, consensus_label])\n\n  input_file.close()\n\n  # Output tab delimited file of lines of examples (sentence1, sentence2, label)\n  with tf.gfile.GFile(gen_output_path, 'w') as f:\n    for tokens1_str, tokens2_str, consensus_label in examples:\n      f.write('%s\\t%s\\t%s\\n' % (tokens1_str, tokens2_str, consensus_label))\n\n  if train:\n    # Output file containing all the sentences for generating the vocab from.\n    with tf.gfile.GFile(example_output_path, 'w') as f:\n      for tokens1_str, tokens2_str, consensus_label in examples:\n        f.write('%s %s\\n' % (tokens1_str, tokens2_str))", "response": "Convert the dataset in to simpler format."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading or create vocabulary.", "response": "def _get_or_generate_vocab(tmp_dir, vocab_filename, vocab_size):\n  \"\"\"Read or create vocabulary.\"\"\"\n  vocab_filepath = os.path.join(tmp_dir, vocab_filename)\n  print('Vocab file written to: ' + vocab_filepath)\n\n  if tf.gfile.Exists(vocab_filepath):\n    gs = text_encoder.SubwordTextEncoder(vocab_filepath)\n    return gs\n  example_file = os.path.join(tmp_dir, _EXAMPLES_FILE)\n  gs = text_encoder.SubwordTextEncoder()\n  token_counts = tokenizer.corpus_token_counts(\n      example_file, corpus_max_lines=1000000)\n  gs = gs.build_to_target_size(\n      vocab_size, token_counts, min_val=1, max_val=1e3)\n  gs.store_to_file(vocab_filepath)\n  return gs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef shard(items, num_shards):\n  sharded = []\n  num_per_shard = len(items) // num_shards\n  start = 0\n  for _ in range(num_shards):\n    sharded.append(items[start:start + num_per_shard])\n    start += num_per_shard\n\n  remainder = len(items) % num_shards\n  start = len(items) - remainder\n  for i in range(remainder):\n    sharded[i].append(items[start + i])\n\n  assert sum([len(fs) for fs in sharded]) == len(items)\n  return sharded", "response": "Split items into num_shards groups."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef RandomNormalInitializer(stddev=1e-2):\n  def init(shape, rng):\n    return (stddev * backend.random.normal(rng, shape)).astype('float32')\n  return init", "response": "An initializer function for random normal coefficients."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmake a n + 1 dim one - hot array from n dim int - categorical array.", "response": "def one_hot(x, size, dtype=np.float32):\n  \"\"\"Make a n+1 dim one-hot array from n dim int-categorical array.\"\"\"\n  return np.array(x[..., np.newaxis] == np.arange(size), dtype)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies log softmax to x.", "response": "def LogSoftmax(x, params, axis=-1, **kwargs):\n  \"\"\"Apply log softmax to x: log-normalize along the given axis.\"\"\"\n  del params, kwargs\n  return x - backend.logsumexp(x, axis, keepdims=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\napply softmax to x.", "response": "def Softmax(x, params, axis=-1, **kwargs):\n  \"\"\"Apply softmax to x: exponentiate and normalize along the given axis.\"\"\"\n  del params, kwargs\n  return np.exp(x - backend.logsumexp(x, axis, keepdims=True))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef padtype_to_pads(in_shape, window_shape, window_strides, padding):\n  padding = padding.upper()\n  if padding == 'SAME':\n    out_shape = onp.ceil(\n        onp.true_divide(in_shape, window_strides)).astype(int)\n    pad_sizes = [max((out_size - 1) * stride + window_shape - in_size, 0)\n                 for out_size, stride, window_shape, in_size\n                 in zip(out_shape, window_strides, window_shape, in_shape)]\n    return [(pad_size // 2, pad_size - pad_size // 2)\n            for pad_size in pad_sizes]\n  elif padding == 'VALID':\n    return [(0, 0)] * len(in_shape)\n  else:\n    msg = 'Unknown padding type: {}.'\n    raise TypeError(msg.format(padding))", "response": "Convert padding string to list of pairs of pad values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\noutputting shape of a flatten layer.", "response": "def _flatten_output_shape(input_shape, num_axis_to_keep=1):\n  \"\"\"Output shape of a flatten layer.\"\"\"\n  if num_axis_to_keep >= len(input_shape):\n    raise ValueError(\n        \"num_axis_to_keep[%d] should be less than input's rank[%d]\" %\n        (num_axis_to_keep, len(input_shape)))\n  return tuple(input_shape[:num_axis_to_keep]) + (\n      reduce(op.mul, input_shape[num_axis_to_keep:], 1),)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef BatchNorm(x, params, axis=(0, 1, 2), epsilon=1e-5,\n              center=True, scale=True, **unused_kwargs):\n  \"\"\"Layer construction function for a batch normalization layer.\"\"\"\n  mean = np.mean(x, axis, keepdims=True)\n  # Fast but less numerically-stable variance calculation than np.var.\n  m1 = np.mean(x**2, axis, keepdims=True)\n  var = m1 - mean**2\n  z = (x - mean) / np.sqrt(var + epsilon)\n\n  # Expand the parameters to have the right axes.\n  beta, gamma = params\n  # TODO(phawkins): np.expand_dims should accept an axis tuple.\n  # (https://github.com/numpy/numpy/issues/12290)\n  ed = tuple(None if i in axis else slice(None) for i in range(np.ndim(x)))\n  beta = beta[ed]\n  gamma = gamma[ed]\n\n  # Return the z rescaled by the parameters if requested.\n  if center and scale:\n    return gamma * z + beta\n  if center:\n    return z + beta\n  if scale:\n    return gamma * z\n  return z", "response": "Layer construction function for a batch normalization layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _pooling_output_shape(input_shape, pool_size=(2, 2),\n                          strides=None, padding='VALID'):\n  \"\"\"Helper: compute the output shape for the pooling layer.\"\"\"\n  dims = (1,) + pool_size + (1,)  # NHWC\n  spatial_strides = strides or (1,) * len(pool_size)\n  strides = (1,) + spatial_strides + (1,)\n  pads = padtype_to_pads(input_shape, dims, strides, padding)\n  operand_padded = onp.add(input_shape, onp.add(*zip(*pads)))\n  t = onp.floor_divide(onp.subtract(operand_padded, dims), strides) + 1\n  return tuple(t)", "response": "Helper function to compute the output shape for the pooling layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Dropout(x, params, rate=0.0, mode='train', rng=None, **kwargs):\n  del params, kwargs\n  if rng is None:\n    msg = ('Dropout layer requires apply_fun to be called with a rng keyword '\n           'argument. That is, instead of `Dropout(params, inputs)`, call '\n           'it like `Dropout(params, inputs, rng=key)`.')\n    raise ValueError(msg)\n  if rate >= 1.0:\n    raise ValueError('Dropout rate (%f) must be lower than 1.' % rate)\n  if mode == 'train' and rate > 0.0:\n    keep = backend.random.bernoulli(rng, 1.0 - rate, x.shape)\n    return np.where(keep, x / (1.0 - rate), 0)\n  else:\n    return x", "response": "Layer construction function for a dropout layer with given rate."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _kernel_shape(self, input_shape):\n    kernel_size_iter = iter(self._kernel_size)\n    return [self._filters if c == 'O' else\n            input_shape[self._lhs_spec.index('C')] if c == 'I' else\n            next(kernel_size_iter) for c in self._rhs_spec]", "response": "Helper to calculate the kernel shape."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _conv_shape_tuple(self, lhs_shape, rhs_shape, strides, pads):\n    if isinstance(pads, str):\n      pads = padtype_to_pads(lhs_shape[2:], rhs_shape[2:], strides, pads)\n    if len(pads) != len(lhs_shape) - 2:\n      msg = 'Wrong number of explicit pads for conv: expected {}, got {}.'\n      raise TypeError(msg.format(len(lhs_shape) - 2, len(pads)))\n    lhs_padded = onp.add(lhs_shape[2:], onp.add(*zip(*pads)))\n    out_space = onp.floor_divide(\n        onp.subtract(lhs_padded, rhs_shape[2:]), strides) + 1\n    out_space = onp.maximum(0, out_space)\n    out_shape = (lhs_shape[0], rhs_shape[0]) + tuple(out_space)\n    return tuple(out_shape)", "response": "Compute the shape of a conv given input shapes in canonical order."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _conv_general_permutations(self, dimension_numbers):\n    lhs_spec, rhs_spec, out_spec = dimension_numbers\n    lhs_char, rhs_char, out_char = ('N', 'C'), ('O', 'I'), ('N', 'C')\n    charpairs = (lhs_char, rhs_char, out_char)\n    for i, (a, b) in enumerate(charpairs):\n      if not (dimension_numbers[i].count(a) == 1 and\n              dimension_numbers[i].count(b) == 1):\n        msg = ('convolution dimension_numbers[{}] must contain the characters '\n               '\"{}\" and \"{}\" exatly once, got {}.')\n        raise TypeError(msg.format(i, a, b, dimension_numbers[i]))\n      if len(dimension_numbers[i]) != len(set(dimension_numbers[i])):\n        msg = ('convolution dimension_numbers[{}] cannot have duplicate '\n               'characters, got {}.')\n        raise TypeError(msg.format(i, dimension_numbers[i]))\n    if not (set(lhs_spec) - set(lhs_char) == set(rhs_spec) - set(rhs_char) ==\n            set(out_spec) - set(out_char)):\n      msg = ('convolution dimension_numbers elements must each have the same '\n             'set of spatial characters, got {}.')\n      raise TypeError(msg.format(dimension_numbers))\n\n    def getperm(spec, charpair):\n      spatial = (i for i, c in enumerate(spec) if c not in charpair)\n      if spec is not rhs_spec:\n        spatial = sorted(spatial, key=lambda i: rhs_spec.index(spec[i]))\n      return (spec.index(charpair[0]), spec.index(charpair[1])) + tuple(spatial)\n\n    lhs_perm, rhs_perm, out_perm = map(getperm, dimension_numbers, charpairs)\n    return lhs_perm, rhs_perm, out_perm", "response": "Utility for convolution dimension permutations relative to Conv HLO."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngeneralizing computation of conv shape.", "response": "def _conv_general_shape_tuple(self, lhs_shape, rhs_shape, window_strides,\n                                padding, dimension_numbers):\n    \"\"\"Generalized computation of conv shape.\"\"\"\n    lhs_perm, rhs_perm, out_perm = self._conv_general_permutations(\n        dimension_numbers)\n    lhs_trans = onp.take(lhs_shape, lhs_perm)\n    rhs_trans = onp.take(rhs_shape, rhs_perm)\n    out_trans = self._conv_shape_tuple(\n        lhs_trans, rhs_trans, window_strides, padding)\n    return tuple(onp.take(out_trans, onp.argsort(out_perm)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a function that creates a new instance of the DQN agent.", "response": "def get_create_agent(agent_kwargs):\n  \"\"\"Factory for dopamine agent initialization.\n\n  Args:\n    agent_kwargs: dict of BatchDQNAgent parameters\n\n  Returns:\n    Function(sess, environment, summary_writer) -> BatchDQNAgent instance.\n  \"\"\"\n\n  def create_agent(sess, environment, summary_writer=None):\n    \"\"\"Creates a DQN agent.\n\n    Simplified version of `dopamine.discrete_domains.train.create_agent`\n\n    Args:\n      sess: a session\n      environment: an environment\n      summary_writer: a summary writer.\n\n    Returns:\n      a DQN agent.\n    \"\"\"\n    return BatchDQNAgent(\n        env_batch_size=environment.batch_size,\n        sess=sess,\n        num_actions=environment.action_space.n,\n        summary_writer=summary_writer,\n        tf_device=\"/gpu:*\",\n        **agent_kwargs)\n\n  return create_agent"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsplit hparams based on key prefixes. Returns a tuple of hparams for respectably", "response": "def _parse_hparams(hparams):\n  \"\"\"Split hparams, based on key prefixes.\n\n  Args:\n    hparams: hyperparameters\n\n  Returns:\n    Tuple of hparams for respectably: agent, optimizer, runner, replay_buffer.\n  \"\"\"\n  prefixes = [\"agent_\", \"optimizer_\", \"runner_\", \"replay_buffer_\"]\n  ret = []\n\n  for prefix in prefixes:\n    ret_dict = {}\n    for key in hparams.values():\n      if prefix in key:\n        par_name = key[len(prefix):]\n        ret_dict[par_name] = hparams.get(key)\n    ret.append(ret_dict)\n\n  return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding WrappedReplayBuffer with custom OutOfGraphReplayBuffer.", "response": "def _build_replay_buffer(self, use_staging):\n    \"\"\"Build WrappedReplayBuffer with custom OutOfGraphReplayBuffer.\"\"\"\n    replay_buffer_kwargs = dict(\n        observation_shape=dqn_agent.NATURE_DQN_OBSERVATION_SHAPE,\n        stack_size=dqn_agent.NATURE_DQN_STACK_SIZE,\n        replay_capacity=self._replay_capacity,\n        batch_size=self._buffer_batch_size,\n        update_horizon=self.update_horizon,\n        gamma=self.gamma,\n        extra_storage_types=None,\n        observation_dtype=np.uint8,\n    )\n    replay_memory = _OutOfGraphReplayBuffer(\n        artificial_done=not self._generates_trainable_dones,\n        **replay_buffer_kwargs)\n\n    return circular_replay_buffer.WrappedReplayBuffer(\n        wrapped_memory=replay_memory,\n        use_staging=use_staging,\n        **replay_buffer_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds an item to the queue.", "response": "def add(self, observation, action, reward, terminal, *args):\n    \"\"\"Append artificial_done to *args and run parent method.\"\"\"\n    # If this will be a problem for maintenance, we could probably override\n    # DQNAgent.add() method instead.\n    artificial_done = self._artificial_done and terminal\n    args = list(args)\n    args.append(artificial_done)\n    return super(_OutOfGraphReplayBuffer, self).add(observation, action, reward,\n                                                    terminal, *args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef next_frame_glow_bair_quant():\n  hparams = next_frame_glow_hparams()\n  hparams.video_num_input_frames = 3\n  hparams.video_num_target_frames = 10\n  hparams.num_train_frames = 4\n  hparams.num_cond_latents = 3\n  hparams.depth = 24\n  hparams.latent_dist_encoder = \"conv3d_net\"\n  hparams.latent_encoder_width = 256\n  hparams.latent_architecture = \"glow_resnet\"\n  hparams.latent_encoder_depth = 5\n  hparams.latent_apply_dilations = True\n  hparams.latent_activation = \"gatu\"\n  hparams.activation = \"gatu\"\n  hparams.learning_rate_constant = 3e-4\n  hparams.learning_rate_schedule = \"constant*linear_warmup\"\n  hparams.learning_rate_warmup_steps = 10000\n  hparams.init_batch_size = 128\n  hparams.batch_size = 5\n  return hparams", "response": "Hparams to reproduce bits - per - pixel results on BAIR action - free dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef next_frame_glow_bair_qual():\n  hparams = next_frame_glow_bair_quant()\n  hparams.coupling = \"additive\"\n  hparams.temperature = 0.5\n  hparams.coupling_width = 392\n  return hparams", "response": "Hparams for qualitative video generation results."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef next_frame_glow_shapes():\n  hparams = next_frame_glow_bair_quant()\n  hparams.video_num_input_frames = 1\n  hparams.video_num_target_frames = 2\n  hparams.num_train_frames = 2\n  hparams.num_cond_latents = 1\n  hparams.coupling = \"additive\"\n  hparams.coupling_width = 512\n  hparams.latent_encoder_depth = 10\n  hparams.latent_skip = False\n  hparams.learning_rate_constant = 1e-4\n  hparams.batch_size = 10\n  return hparams", "response": "Hparams for qualitative and quantitative results on shapes dataset."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting conditional latents given z^1.. t - 1.", "response": "def get_cond_latents(all_latents=None, hparams=None):\n  \"\"\"Get z^{cond}_{t} given z^{1..t-1}.\n\n  Args:\n    all_latents: list of list of tensors,\n                 outer-size equals no.of time_steps-1\n                 inner-size equals hparams.n_levels.\n    hparams: See next_frame_glow_hparams.\n  Returns:\n    cond_latents: conditional latents at time-step t.\n  \"\"\"\n  cond_latents = None\n  if hparams.gen_mode == \"conditional\":\n    if hparams.latent_dist_encoder in [\"conv_net\", \"conv3d_net\"]:\n      num_cond_latents = (hparams.num_cond_latents +\n                          int(hparams.cond_first_frame))\n      if len(all_latents) >= num_cond_latents:\n        cond_latents = all_latents[-hparams.num_cond_latents:]\n        if hparams.cond_first_frame:\n          cond_latents = [all_latents[0]] + cond_latents\n    elif hparams.latent_dist_encoder in [\"pointwise\", \"conv_lstm\"]:\n      if all_latents:\n        cond_latents = all_latents[-1]\n\n  if hparams.gen_mode == \"conditional\":\n    global_step = tf.train.get_or_create_global_step()\n    condition = tf.greater(global_step, hparams.pretrain_steps)\n  else:\n    condition = tf.constant(False, dtype=tf.bool)\n  return condition, cond_latents"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _layer_stack(mp,\n                 inputs,\n                 self_attention_bias,\n                 layers,\n                 hparams,\n                 encoder_output=None,\n                 encoder_decoder_attention_bias=None):\n  \"\"\"A stack of layers.\n\n  Args:\n    mp: a Parallelism object\n    inputs: a list of Tensors\n    self_attention_bias: list of bias Tensor for self-attention\n      (see common_attention.attention_bias())\n    layers: a string\n    hparams: hyperparameters for model\n    encoder_output: optional list of tensors\n    encoder_decoder_attention_bias: optional list of tensors\n\n  Returns:\n    y: a list of Tensors\n  \"\"\"\n  layers = layers.strip(\",\").split(\",\")\n\n  # scaled_dot_product_attention_with_projections uses a 3d attention bias\n  # (no heads), where multihead_attention uses 4d attention bias.\n  self_attention_bias_3d = mp(tf.squeeze, self_attention_bias, 1)\n  if encoder_decoder_attention_bias is not None:\n    encoder_decoder_attention_bias_3d = mp(\n        tf.squeeze, encoder_decoder_attention_bias, 1)\n  relu_dropout_broadcast_dims = (\n      common_layers.comma_separated_string_to_integer_list(\n          getattr(hparams, \"relu_dropout_broadcast_dims\", \"\")))\n  mix_size = int(hparams.mix_fraction * hparams.hidden_size)\n  accumulator = inputs\n  x = inputs\n  for layer_num, layer_type in enumerate(layers):\n    with tf.variable_scope(\"%s_%d\" % (layer_type, layer_num)):\n      tf.logging.info(\"%s_%d\" % (layer_type, layer_num))\n      if layer_type == \"a\":\n        # accumulate\n        accumulator = mp(tf.add, x, accumulator)\n        x = accumulator\n      elif layer_type == \"n\":\n        # normalize\n        x = mp(common_layers.apply_norm,\n               x, hparams.norm_type, hparams.hidden_size, hparams.norm_epsilon)\n      elif layer_type == \"d\":\n        # dropout\n        x = mp(tf.nn.dropout, x, 1.0 - hparams.layer_prepostprocess_dropout)\n      elif layer_type == \"m\":\n        if mix_size > 0:\n          # mix across shards\n          def _split(t):\n            return tuple(tf.split(\n                t, [mix_size, hparams.hidden_size - mix_size], 2))\n          to_mix, to_keep = mp(_split, x)\n          mixed = expert_utils.all_reduce_ring(to_mix, mp)\n          mixed = mp(tf.multiply, mixed, mp.n ** -0.5)\n          x = mp(lambda a, b: tf.concat([a, b], 2), mixed, to_keep)\n      elif layer_type == \"att\":\n        # single-head attention\n        q = mp(tf.layers.dense, x, hparams.hidden_size, use_bias=False,\n               name=\"q_transform\")\n        x = mp(\n            common_attention.scaled_dot_product_attention_simple,\n            q, x, x, self_attention_bias_3d)\n        x = mp(tf.layers.dense, x, hparams.hidden_size, use_bias=False,\n               name=\"o_transform\")\n      elif layer_type == \"enc-att\":\n        # single-head attention over encoder\n        q = mp(tf.layers.dense, x, hparams.hidden_size, use_bias=False,\n               name=\"q_transform\")\n        assert encoder_output is not None\n        x = mp(\n            common_attention.scaled_dot_product_attention_simple,\n            q, encoder_output, encoder_output,\n            encoder_decoder_attention_bias_3d)\n        x = mp(tf.layers.dense, x, hparams.hidden_size, use_bias=False,\n               name=\"o_transform\")\n      elif layer_type == \"multihead-att\":\n        # multi-head attention\n        x = mp(\n            common_attention.multihead_attention,\n            x,\n            None,\n            self_attention_bias,  # bias\n            hparams.multihead_attention_key_channels or hparams.hidden_size,\n            hparams.multihead_attention_value_channels or hparams.hidden_size,\n            hparams.hidden_size,\n            hparams.multihead_attention_num_heads,\n            hparams.attention_dropout)\n      elif layer_type == \"enc-multihead-att\":\n        # multi-head attention\n        x = mp(\n            common_attention.multihead_attention,\n            x,\n            encoder_output,\n            encoder_decoder_attention_bias,  # bias\n            hparams.multihead_attention_key_channels or hparams.hidden_size,\n            hparams.multihead_attention_value_channels or hparams.hidden_size,\n            hparams.hidden_size,\n            hparams.multihead_attention_num_heads,\n            hparams.attention_dropout)\n      elif layer_type == \"ffn\":\n        x = mp(\n            common_layers.dense_relu_dense, x,\n            hparams.filter_size, hparams.hidden_size,\n            dropout=hparams.relu_dropout,\n            dropout_broadcast_dims=[relu_dropout_broadcast_dims] * mp.n)\n      else:\n        assert False, \"unknown sublayer %s\" % layer_type\n  return x", "response": "A stack of layers."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting of hyperparameters for transformer_symshard.", "response": "def transformer_symshard_base():\n  \"\"\"Set of hyperparameters.\"\"\"\n  hparams = common_hparams.basic_params1()\n  hparams.hidden_size = 256\n  hparams.batch_size = 2048\n  hparams.max_length = 0\n  # All hyperparameters ending in \"dropout\" are automatically set to 0.0\n  # when not in training mode.\n  hparams.layer_prepostprocess_dropout = 0.2\n  hparams.add_hparam(\"attention_dropout\", 0.1)\n  hparams.add_hparam(\"relu_dropout\", 0.0)\n  hparams.add_hparam(\"relu_dropout_broadcast_dims\", \"1\")\n  hparams.layer_prepostprocess_dropout = 0.1\n  hparams.layer_prepostprocess_dropout_broadcast_dims = \"1\"  # length\n  hparams.label_smoothing = 0.1\n  hparams.clip_grad_norm = 0.  # i.e. no gradient clipping\n  hparams.optimizer = \"Adafactor\"\n  hparams.learning_rate_schedule = \"rsqrt_decay\"\n  hparams.learning_rate_warmup_steps = 10000\n  hparams.initializer_gain = 1.0\n  hparams.initializer = \"uniform_unit_scaling\"\n  hparams.weight_decay = 0.0\n  # TODO(noam): use this to control sharing.  We now share always\n  hparams.shared_embedding_and_softmax_weights = True\n  # we only want one data shard.\n  hparams.no_data_parallelism = True\n  # bypass the symbol modality so that we can use model parallelism.\n  hparams.bottom = {\n      \"inputs\": modalities.identity_bottom,\n      \"targets\": modalities.identity_bottom,\n  }\n  hparams.top = {\n      \"targets\": modalities.identity_top,\n  }\n  hparams.add_hparam(\"filter_size\", 1280)\n  hparams.add_hparam(\"mix_fraction\", 0.5)\n  # attention-related flags\n  hparams.add_hparam(\"multihead_attention_num_heads\", 4)\n  hparams.add_hparam(\"multihead_attention_key_channels\", 0)\n  hparams.add_hparam(\"multihead_attention_value_channels\", 0)\n  hparams.add_hparam(\"pos\", \"timing\")  # timing, none\n  hparams.add_hparam(\n      \"encoder_layers\", (\"n,att,m,d,a,\" \"n,ffn,m,d,a,\") * 6 + \"n,d\")\n  hparams.add_hparam(\n      \"decoder_layers\",\n      (\"n,att,m,d,a,\" \"n,enc-att,m,d,a,\" \"n,ffn,m,d,a,\") * 6 + \"n,d\")\n  # Number of model shards - each one has separate parameters.\n  # Changing this number invalidates checkpoints.\n  hparams.add_hparam(\"num_model_shards\", 8)\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nimages generator for Imagenet 64x64 downsampled images.", "response": "def imagenet_pixelrnn_generator(tmp_dir,\n                                training,\n                                size=_IMAGENET_SMALL_IMAGE_SIZE):\n  \"\"\"Image generator for Imagenet 64x64 downsampled images.\n\n  It assumes that the data has been downloaded from\n  http://image-net.org/small/*_32x32.tar or\n  http://image-net.org/small/*_64x64.tar into tmp_dir.\n  Args:\n    tmp_dir: path to temporary storage directory.\n    training: a Boolean; if true, we use the train set, otherwise the test set.\n    size: image size (assumes height and width are same)\n\n  Yields:\n    A dictionary representing the images with the following fields:\n    * image/encoded: the string encoding the image as JPEG,\n    * image/format: the string \"jpeg\" representing image format,\n    * image/height: an integer representing the height,\n    * image/width: an integer representing the width.\n    Every field is actually a list of the corresponding type.\n  \"\"\"\n  if size == _IMAGENET_SMALL_IMAGE_SIZE:\n    train_prefix = _IMAGENET_SMALL_TRAIN_PREFIX\n    eval_prefix = _IMAGENET_SMALL_EVAL_PREFIX\n  else:\n    train_prefix = _IMAGENET_MEDIUM_TRAIN_PREFIX\n    eval_prefix = _IMAGENET_MEDIUM_EVAL_PREFIX\n  prefix = train_prefix if training else eval_prefix\n  images_filepath = os.path.join(tmp_dir, prefix)\n  image_files = tf.gfile.Glob(images_filepath + \"/*\")\n  height = size\n  width = size\n  const_label = 0\n  for filename in image_files:\n    with tf.gfile.Open(filename, \"r\") as f:\n      encoded_image = f.read()\n      yield {\n          \"image/encoded\": [encoded_image],\n          \"image/format\": [\"png\"],\n          \"image/class/label\": [const_label],\n          \"image/height\": [height],\n          \"image/width\": [width]\n      }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef imagenet_preprocess_example(example, mode, resize_size=None,\n                                normalize=True):\n  \"\"\"Preprocessing used for Imagenet and similar problems.\"\"\"\n  resize_size = resize_size or [299, 299]\n  assert resize_size[0] == resize_size[1]\n\n  image = example[\"inputs\"]\n  if mode == tf.estimator.ModeKeys.TRAIN:\n    image = preprocess_for_train(image, image_size=resize_size[0],\n                                 normalize=normalize)\n  else:\n    image = preprocess_for_eval(image, image_size=resize_size[0],\n                                normalize=normalize)\n\n  example[\"inputs\"] = image\n  return example", "response": "Preprocessing used for Imagenet and similar problems."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _crop(image, offset_height, offset_width, crop_height, crop_width):\n  original_shape = tf.shape(image)\n\n  rank_assertion = tf.Assert(\n      tf.equal(tf.rank(image), 3), [\"Rank of image must be equal to 3.\"])\n  with tf.control_dependencies([rank_assertion]):\n    cropped_shape = tf.stack([crop_height, crop_width, original_shape[2]])\n\n  size_assertion = tf.Assert(\n      tf.logical_and(\n          tf.greater_equal(original_shape[0], crop_height),\n          tf.greater_equal(original_shape[1], crop_width)),\n      [\"Crop size greater than the image size.\"])\n\n  offsets = tf.to_int32(tf.stack([offset_height, offset_width, 0]))\n\n  # Use tf.slice instead of crop_to_bounding box as it accepts tensors to\n  # define the crop size.\n  with tf.control_dependencies([size_assertion]):\n    image = tf.slice(image, offsets, cropped_shape)\n  return tf.reshape(image, cropped_shape)", "response": "Crops the given image using the provided offsets and sizes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a random cropped image using a bounding box.", "response": "def distorted_bounding_box_crop(image,\n                                bbox,\n                                min_object_covered=0.1,\n                                aspect_ratio_range=(0.75, 1.33),\n                                area_range=(0.05, 1.0),\n                                max_attempts=100,\n                                scope=None):\n  \"\"\"Generates cropped_image using a one of the bboxes randomly distorted.\n\n  See `tf.image.sample_distorted_bounding_box` for more documentation.\n\n  Args:\n    image: `Tensor` of image (it will be converted to floats in [0, 1]).\n    bbox: `Tensor` of bounding boxes arranged `[1, num_boxes, coords]`\n        where each coordinate is [0, 1) and the coordinates are arranged\n        as `[ymin, xmin, ymax, xmax]`. If num_boxes is 0 then use the whole\n        image.\n    min_object_covered: An optional `float`. Defaults to `0.1`. The cropped\n        area of the image must contain at least this fraction of any bounding\n        box supplied.\n    aspect_ratio_range: An optional list of `float`s. The cropped area of the\n        image must have an aspect ratio = width / height within this range.\n    area_range: An optional list of `float`s. The cropped area of the image\n        must contain a fraction of the supplied image within in this range.\n    max_attempts: An optional `int`. Number of attempts at generating a cropped\n        region of the image of the specified constraints. After `max_attempts`\n        failures, return the entire image.\n    scope: Optional `str` for name scope.\n  Returns:\n    (cropped image `Tensor`, distorted bbox `Tensor`).\n  \"\"\"\n  with tf.name_scope(scope, default_name=\"distorted_bounding_box_crop\",\n                     values=[image, bbox]):\n    # Each bounding box has shape [1, num_boxes, box coords] and\n    # the coordinates are ordered [ymin, xmin, ymax, xmax].\n\n    # A large fraction of image datasets contain a human-annotated bounding\n    # box delineating the region of the image containing the object of interest.\n    # We choose to create a new bounding box for the object which is a randomly\n    # distorted version of the human-annotated bounding box that obeys an\n    # allowed range of aspect ratios, sizes and overlap with the human-annotated\n    # bounding box. If no box is supplied, then we assume the bounding box is\n    # the entire image.\n    sample_distorted_bounding_box = tf.image.sample_distorted_bounding_box(\n        tf.shape(image),\n        bounding_boxes=bbox,\n        min_object_covered=min_object_covered,\n        aspect_ratio_range=aspect_ratio_range,\n        area_range=area_range,\n        max_attempts=max_attempts,\n        use_image_if_no_bounding_boxes=True)\n    bbox_begin, bbox_size, distort_bbox = sample_distorted_bounding_box\n\n    # Crop the image to the specified bounding box.\n    cropped_image = tf.slice(image, bbox_begin, bbox_size)\n    return cropped_image, distort_bbox"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _random_crop(image, size):\n  bbox = tf.constant([0.0, 0.0, 1.0, 1.0], dtype=tf.float32, shape=[1, 1, 4])\n  random_image, bbox = distorted_bounding_box_crop(\n      image,\n      bbox,\n      min_object_covered=0.1,\n      aspect_ratio_range=(3. / 4, 4. / 3.),\n      area_range=(0.08, 1.0),\n      max_attempts=1,\n      scope=None)\n  bad = _at_least_x_are_true(tf.shape(image), tf.shape(random_image), 3)\n\n  image = tf.cond(\n      bad, lambda: _center_crop(_do_scale(image, size), size),\n      lambda: tf.image.resize_bicubic([random_image], [size, size])[0])\n  return image", "response": "Make a random crop of size x size."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _do_scale(image, size):\n  shape = tf.cast(tf.shape(image), tf.float32)\n  w_greater = tf.greater(shape[0], shape[1])\n  shape = tf.cond(w_greater,\n                  lambda: tf.cast([shape[0] / shape[1] * size, size], tf.int32),\n                  lambda: tf.cast([size, shape[1] / shape[0] * size], tf.int32))\n\n  return tf.image.resize_bicubic([image], shape)[0]", "response": "Rescale the image by scaling the smaller spatial dimension to size."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _center_crop(image, size):\n  image_height = tf.shape(image)[0]\n  image_width = tf.shape(image)[1]\n\n  offset_height = ((image_height - size) + 1) / 2\n  offset_width = ((image_width - size) + 1) / 2\n  image = _crop(image, offset_height, offset_width, size, size)\n  return image", "response": "Crops to center of image with specified size."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _normalize(image):\n  offset = tf.constant(MEAN_RGB, shape=[1, 1, 3])\n  image -= offset\n\n  scale = tf.constant(STDDEV_RGB, shape=[1, 1, 3])\n  image /= scale\n  return image", "response": "Normalize the image to zero mean and unit variance."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a function that can be used to calculate the learning rate of a single object.", "response": "def MultifactorSchedule(history=None,\n                        factors=\"constant * linear_warmup * rsqrt_decay\",\n                        constant=0.1,\n                        warmup_steps=100,\n                        decay_factor=0.5,\n                        steps_per_decay=20000):\n  \"\"\"Factor-based learning rate schedule.\n\n  Interprets factors in the factors string which can consist of:\n  * constant: interpreted as the constant value,\n  * linear_warmup: interpreted as linear warmup until warmup_steps,\n  * rsqrt_decay: divide by square root of max(step, warmup_steps)\n  * decay_every: Every k steps decay the learning rate by decay_factor.\n\n  Args:\n    history: the history of training and evaluation (History object).\n    factors: a string with factors separated by \"*\" that defines the schedule.\n    constant: float, the starting constant for the learning rate schedule.\n    warmup_steps: how many steps to warm up for in the warmup schedule.\n    decay_factor: The amount to decay the learning rate by.\n    steps_per_decay: How often to decay the learning rate.\n\n  Returns:\n    a function learning_rate(step): float -> float, the step-dependent lr.\n  \"\"\"\n  del history\n\n  cache_args = (factors, constant, warmup_steps)\n  if cache_args in _memoized_multifactor_schedules:\n    return _memoized_multifactor_schedules[cache_args]\n\n  factors = [n.strip() for n in factors.split(\"*\")]\n\n  def learning_rate(step):  # pylint: disable=invalid-name\n    \"\"\"Step to learning rate function.\"\"\"\n    ret = 1.0\n    for name in factors:\n      if name == \"constant\":\n        ret *= constant\n      elif name == \"linear_warmup\":\n        ret *= np.minimum(1.0, step / warmup_steps)\n      elif name == \"rsqrt_decay\":\n        ret /= np.sqrt(np.maximum(step, warmup_steps))\n      elif name == \"decay_every\":\n        ret *= (decay_factor ** (step//steps_per_decay))\n      else:\n        raise ValueError(\"Unknown factor %s.\" % name)\n    return ret\n\n  _memoized_multifactor_schedules[cache_args] = learning_rate\n  return learning_rate"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef EvalAdjustingSchedule(history,\n                          constant=0.1,\n                          steps_to_decrease=20,\n                          improvement_margin=0.001,\n                          decrease_rate=1.5,\n                          history_mode=\"eval\",\n                          metric=\"metrics/accuracy\"):\n  \"\"\"Learning rate that decreases when eval metric stalls.\n\n  If the chosen metric does not improve by improvement_margin for as many as\n  steps_to_decrease steps, then the constant gets decreased by decrease rate.\n  Finally, the MultifactorSchedule gets called with the adjusted constant.\n\n  Args:\n    history: trax.history.History, the history of training and evaluation.\n    constant: float, the starting constant for the learning rate schedule.\n    steps_to_decrease: int, after how many steps without improvement\n      should we decrease the constant.\n    improvement_margin: how much we need to improve to consider the metric\n      improved.\n    decrease_rate: by what fraction to decrease (i.e. lr /= decrease_rate).\n    history_mode: str, which mode of the history to use.\n    metric: which evaluation metric to use for adjustments.\n\n  Returns:\n    a function learning_rate(step): float -> float, the step-dependent lr.\n  \"\"\"\n  metrics = history.get(history_mode, metric)\n  adjusted = constant\n  if len(metrics) < 2:\n    return MultifactorSchedule(history, constant=adjusted)\n\n  steps_without_improvement = 0\n  cur = metrics.pop()[1]  # The most-recent value of the metric.\n  while len(metrics) > 1:\n    # The one-before value of metrics as .pop() removes one element each time.\n    prev = metrics.pop()[1]\n    if cur < prev * (1 + improvement_margin):\n      steps_without_improvement += 1\n    else:\n      cur = prev\n      steps_without_improvement = 0\n    if steps_without_improvement >= steps_to_decrease:\n      adjusted /= decrease_rate\n      cur = prev\n      steps_without_improvement = 0\n\n  return MultifactorSchedule(history, constant=adjusted)", "response": "This function calculates the learning rate that decreases when eval metric stalls."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef project_hidden(x, projection_tensors, hidden_size, num_blocks):\n  batch_size, latent_dim, _ = common_layers.shape_list(x)\n  x = tf.reshape(x, shape=[1, -1, hidden_size])\n  x_tiled = tf.reshape(\n      tf.tile(x, multiples=[num_blocks, 1, 1]),\n      shape=[num_blocks, -1, hidden_size])\n  x_projected = tf.matmul(x_tiled, projection_tensors)\n  x_projected = tf.transpose(x_projected, perm=[1, 0, 2])\n  x_4d = tf.reshape(x_projected, [batch_size, latent_dim, num_blocks, -1])\n  return x_4d", "response": "Project encoder hidden state under num_blocks using projection tensors."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef slice_hidden(x, hidden_size, num_blocks):\n  batch_size, latent_dim, _ = common_layers.shape_list(x)\n  block_dim = hidden_size // num_blocks\n  x_sliced = tf.reshape(x,\n                        shape=[batch_size, latent_dim, num_blocks, block_dim])\n  return x_sliced", "response": "Slice encoder hidden state under num_blocks."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds the nearest element in means to elements in x.", "response": "def nearest_neighbor(x,\n                     means,\n                     block_v_size,\n                     random_top_k=1,\n                     soft_em=False,\n                     num_samples=1,\n                     sum_over_latents=False,\n                     summary=True):\n  \"\"\"Find the nearest element in means to elements in x.\n\n  Args:\n    x: Continuous encodings of shape [batch_size, latent_dim, num_blocks,\n      block_dim].\n    means: Embedding table of shape [num_blocks, block_v_size, block_dim].\n    block_v_size: Number of table entries per block.\n    random_top_k: Noisy top-k if this is bigger than 1.\n    soft_em: If True then use soft EM rather than hard EM.\n    num_samples: Number of samples to take in soft EM.\n    sum_over_latents: Whether to sum over non-batch dimensions when calculating\n      negative entropy loss. Used only when doing soft EM.\n    summary: If True then record summary histogram of entropies.\n\n  Returns:\n    Tensor with nearest element in mean encoded in one-hot notation\n    and distances.\n  \"\"\"\n  batch_size, latent_dim, num_blocks, block_dim = common_layers.shape_list(x)\n  x = tf.reshape(x, [batch_size * latent_dim, num_blocks, block_dim])\n  x_norm_sq = tf.reduce_sum(tf.square(x), axis=-1, keep_dims=True)\n  means_norm_sq = tf.reduce_sum(tf.square(means), axis=-1, keep_dims=True)\n  scalar_prod = tf.matmul(\n      tf.transpose(x, perm=[1, 0, 2]), tf.transpose(means, perm=[0, 2, 1]))\n  scalar_prod = tf.transpose(scalar_prod, perm=[1, 0, 2])\n  dist = x_norm_sq + tf.transpose(\n      means_norm_sq, perm=[2, 0, 1]) - 2 * scalar_prod\n\n  # computing cluster probabilities\n  if soft_em:\n    num_blocks = common_layers.shape_list(dist)[1]\n    nearest_idx = tf.stack(\n        [\n            tf.multinomial(-dist[:, i, :], num_samples=num_samples)\n            for i in range(num_blocks)\n        ],\n        axis=1)\n    nearest_hot = tf.one_hot(nearest_idx, depth=block_v_size)\n    neg_q_entropy = tf.reduce_sum(\n        nearest_hot * tf.expand_dims(tf.nn.log_softmax(-dist), 2), axis=2)\n    if sum_over_latents:\n      neg_q_entropy = tf.reduce_sum(neg_q_entropy, [1, 2])\n    neg_q_entropy = tf.reduce_mean(neg_q_entropy, axis=0)\n    nearest_hot = tf.reduce_mean(nearest_hot, axis=-2)\n    if summary:\n      tf.summary.histogram(\"neg_q_entropy\", tf.reshape(neg_q_entropy, [-1]))\n  else:\n    neg_q_entropy = 0.\n    if random_top_k > 1:\n      _, top_k_idx = tf.nn.top_k(-dist, k=random_top_k)\n      nearest_idx = tf.gather(\n          top_k_idx,\n          tf.random_uniform(\n              [1], minval=0, maxval=random_top_k - 1, dtype=tf.int32),\n          axis=-1)\n    else:\n      nearest_idx = tf.argmax(-dist, axis=-1)\n    nearest_hot = tf.one_hot(nearest_idx, block_v_size)\n  return nearest_hot, neg_q_entropy"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef embedding_lookup(x,\n                     means,\n                     num_blocks,\n                     block_v_size,\n                     bottleneck_kind=\"dvq\",\n                     random_top_k=1,\n                     soft_em=False,\n                     num_samples=1,\n                     do_hard_gumbel_softmax=False,\n                     temperature_warmup_steps=150000,\n                     num_flows=0,\n                     approximate_gs_entropy=False,\n                     sum_over_latents=False):\n  \"\"\"Compute nearest neighbors and loss for training the embeddings via DVQ.\n\n  Args:\n    x: Continuous encodings of shape [batch_size, latent_dim, num_blocks,\n      block_dim].\n    means: Embedding table of shape [num_blocks, block_v_size, block_dim].\n    num_blocks: Number of blocks in DVQ.\n    block_v_size: Number of table entries per block.\n    bottleneck_kind: Discrete bottleneck type.\n    random_top_k: Noisy top-k if this is bigger than 1.\n    soft_em: If True then use soft EM rather than hard EM.\n    num_samples: Number of samples to use for soft EM.\n    do_hard_gumbel_softmax: Whether to use hard or soft Gumbel-Softmax samples\n      for gumbel-softmax-dvq bottleneck.\n    temperature_warmup_steps: Number of steps it takes to decay temperature to\n      0. Used only if bottleneck_kind is gumbel-softmax-dvq.\n    num_flows: Number of inverse autoregressive flows for gumbel-softmax-dvq\n      bottleneck.\n    approximate_gs_entropy: Whether to approximate the Gumbel-Softmax density\n      as a categorical distribution when calculating the sample entropy. Used\n      only if bottleneck_kind is gumbel-softmax-dvq.\n    sum_over_latents: Whether to sum over non-batch dimensions when calculating\n      negative entropy loss. Used only if soft EM or when bottleneck_kind is\n      gumbel-softmax-dvq.\n\n  Returns:\n    x_means_hot: The nearest neighbor in one hot form, with shape\n      [batch_size * latent_dim, num_blocks, block_v_size].\n    x_means: The nearest neighbor itself, with shape [batch_size * latent_dim,\n      num_blocks, block_dim].\n    q_loss: Scalar Tensor representing codebook loss.\n    e_loss: Scalar Tensor representing commitment loss.\n    neg_q_entropy: Scalar Tensor representing negative entropy of variational\n      approximation (0 if it is deterministic).\n  \"\"\"\n  if bottleneck_kind == \"gumbel-softmax-dvq\":\n    x_means_hot, neg_q_entropy = gumbel_softmax_nearest_neighbor_dvq(\n        x,\n        means,\n        block_v_size,\n        hard=do_hard_gumbel_softmax,\n        num_samples=num_samples,\n        temperature_warmup_steps=temperature_warmup_steps,\n        num_flows=num_flows,\n        approximate_gs_entropy=approximate_gs_entropy,\n        sum_over_latents=sum_over_latents)\n  else:\n    x_means_hot, neg_q_entropy = nearest_neighbor(\n        x,\n        means,\n        block_v_size,\n        random_top_k,\n        soft_em=soft_em,\n        num_samples=num_samples,\n        sum_over_latents=sum_over_latents)\n  x_means_hot_flat = tf.reshape(x_means_hot, [-1, num_blocks, block_v_size])\n  x_means = tf.matmul(tf.transpose(x_means_hot_flat, perm=[1, 0, 2]), means)\n  x_means = tf.transpose(x_means, [1, 0, 2])\n  batch_size, latent_dim, num_blocks, block_dim = common_layers.shape_list(x)\n  x = tf.reshape(x, [batch_size * latent_dim, num_blocks, block_dim])\n\n  # Currently, we use the mean scaling for the commitment loss, as opposed to\n  # summing across all non-batch dimensions.\n  q_loss = tf.reduce_mean(tf.squared_difference(tf.stop_gradient(x), x_means))\n  e_loss = tf.reduce_mean(tf.squared_difference(x, tf.stop_gradient(x_means)))\n  return x_means_hot, x_means, q_loss, e_loss, neg_q_entropy", "response": "This function computes nearest neighbors and loss for training the embeddings via DVQ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nturning x_bit representing numbers bitwise ( lower - endian ) to int tensor.", "response": "def bit_to_int(x_bit, num_bits, base=2):\n  \"\"\"Turn x_bit representing numbers bitwise (lower-endian) to int tensor.\n\n  Args:\n    x_bit: Tensor containing numbers in a particular base to be converted to\n      int.\n    num_bits: Number of bits in the representation.\n    base: Base of the representation.\n\n  Returns:\n    Integer representation of this number.\n  \"\"\"\n  x_l = tf.stop_gradient(tf.to_int32(tf.reshape(x_bit, [-1, num_bits])))\n  x_labels = [\n      x_l[:, i] * tf.to_int32(base)**tf.to_int32(i) for i in range(num_bits)]\n  res = sum(x_labels)\n  return tf.to_int32(tf.reshape(res, common_layers.shape_list(x_bit)[:-1]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nturns x_int into a bitwise lower - endian tensor and embed densly.", "response": "def int_to_bit_embed(x_int, num_bits, embedding_size, base=2):\n  \"\"\"Turn x_int into a bitwise (lower-endian) tensor and embed densly.\"\"\"\n  shape = common_layers.shape_list(x_int)\n  inputs = int_to_bit(x_int, num_bits, base=base)\n  inputs = tf.reshape(inputs, shape[:-1] + [shape[-1] * 8])\n  inputs = 2.0 * tf.to_float(inputs) - 1.0  # Move from 0/1 to -1/1.\n  return tf.layers.dense(inputs, embedding_size, name=\"int_to_bit_embed\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nembed function that takes discrete latent and returns embedding.", "response": "def embed(x,\n          hidden_size,\n          z_size,\n          filter_size,\n          bottleneck_kind=\"dvq\",\n          soft_em=False,\n          num_blocks=2,\n          num_residuals=1,\n          block_v_size=None,\n          means=None,\n          name=None):\n  \"\"\"Embedding function that takes discrete latent and returns embedding.\n\n  Args:\n    x: Input to the discretization bottleneck.\n    hidden_size: Dimension of the latent state.\n    z_size: Number of bits, where discrete codes range from 1 to 2**z_size.\n    filter_size: Dimension to project embedding by. Used only if bottleneck_kind\n      is semhash.\n    bottleneck_kind: Kind of discretization bottleneck to use; one of dvq,\n      semhash, gumbel-softmax (Default: dvq).\n    soft_em: If True then it uses a multi-sample version of EM (Default: False).\n    num_blocks: Number of blocks in DVQ (Default: 2).\n    num_residuals: Number of residuals (Default: 1).\n    block_v_size: Number of embedding entries per block (Default: None).\n    means: The embedding table for dvq (Default: None).\n    name: Name for the bottleneck scope.\n\n  Returns:\n    Continuous embedding to be passed on to the decoder.\n\n  Raises:\n    ValueError: For unknown or missing arguments.\n  \"\"\"\n  with tf.variable_scope(name, default_name=\"embed\", reuse=tf.AUTO_REUSE):\n    if bottleneck_kind == \"semhash\":\n      c = int_to_bit(x, z_size)\n      h1a = tf.layers.dense(c, filter_size, name=\"vch1a\")\n      h1b = tf.layers.dense(1.0 - c, filter_size, name=\"vch1b\")\n      h1 = h1a + h1b\n    elif bottleneck_kind == \"gumbel-softmax\":\n      hot = tf.one_hot(x, 2**z_size)\n      h1 = tf.layers.dense(hot, hidden_size, name=\"dae_dense\")\n    elif bottleneck_kind in [\"dvq\", \"gumbel-softmax-dvq\"]:\n      if block_v_size is None:\n        raise ValueError(\"Bottleneck kind is dvq but block_v_size is None.\")\n\n      if soft_em:\n        assert num_residuals == 1\n        x_hot_flat = tf.reshape(x, shape=[-1, num_blocks, block_v_size])\n        h1 = tf.matmul(tf.transpose(x_hot_flat, perm=[1, 0, 2]), means[0])\n        h1 = tf.transpose(h1, perm=[1, 0, 2])\n        new_shape = common_layers.shape_list(x)\n        new_shape[-1] = hidden_size\n        h1 = tf.reshape(h1, shape=new_shape)\n      else:\n        shape_x = common_layers.shape_list(x)\n        x_flat = tf.reshape(x, [-1, 1])\n        c = int_to_bit(x_flat, num_bits=z_size, base=2)\n        shape = common_layers.shape_list(c)\n        new_shape = shape\n        new_shape[-1] = num_residuals\n        new_shape.append(num_blocks)\n        new_shape.append(int(z_size / (num_residuals * num_blocks)))\n        c = tf.to_int32(tf.reshape(c, shape=new_shape))\n        h1_shape = shape_x\n        h1_shape.append(hidden_size)\n        h1 = tf.zeros(dtype=tf.float32, shape=h1_shape)\n        for i in range(num_residuals):\n          c_residual = bit_to_int(\n              c[:, :, i, :, :],\n              num_bits=int(z_size / (num_residuals * num_blocks)),\n              base=2)\n          c_hot = tf.one_hot(c_residual, depth=block_v_size, axis=-1)\n          c_hot_flat = tf.reshape(c_hot, shape=[-1, num_blocks, block_v_size])\n          h1_residual = tf.matmul(\n              tf.transpose(c_hot_flat, perm=[1, 0, 2]), means[i])\n          h1_residual = tf.transpose(h1_residual, perm=[1, 0, 2])\n          h1_residual = tf.reshape(h1_residual, shape=h1_shape)\n          h1 += h1_residual\n    elif bottleneck_kind == \"rounding\":\n      h1 = x\n    else:\n      raise ValueError(\"Unknown bottleneck kind.\")\n\n    return h1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gumbel_sample(shape):\n  uniform_samples = tf.random_uniform(shape, minval=0.00001, maxval=0.99998)\n  return -tf.log(-tf.log(uniform_samples))", "response": "Sample from the Gumbel distribution protect from overflows."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gumbel_softmax(x,\n                   z_size,\n                   mode,\n                   softmax_k=0,\n                   temperature_warmup_steps=150000,\n                   summary=True,\n                   name=None):\n  \"\"\"Gumbel softmax discretization bottleneck.\n\n  Args:\n    x: Input to the discretization bottleneck.\n    z_size: Number of bits, where discrete codes range from 1 to 2**z_size.\n    mode: tf.estimator.ModeKeys.\n    softmax_k: If > 0 then do top-k softmax.\n    temperature_warmup_steps: Number of steps it takes to decay temperature to\n      0.\n    summary: Whether to write summaries.\n    name: Name for the bottleneck scope.\n\n  Returns:\n    Embedding function, discrete code, and loss.\n  \"\"\"\n  with tf.variable_scope(name, default_name=\"gumbel_softmax\"):\n    m = tf.layers.dense(x, 2**z_size, name=\"mask\")\n    if softmax_k > 0:\n      m, kl = top_k_softmax(m, softmax_k)\n      return m, m, 1.0 - tf.reduce_mean(kl)\n    logsm = tf.nn.log_softmax(m)\n\n    # Gumbel-softmax sample.\n    gumbel_samples = gumbel_sample(common_layers.shape_list(m))\n    steps = temperature_warmup_steps\n    gumbel_samples *= common_layers.inverse_exp_decay(steps // 5) * 0.5\n    temperature = 1.2 - common_layers.inverse_lin_decay(steps)\n\n    # 10% of the time keep reasonably high temperature to keep learning.\n    temperature = tf.cond(\n        tf.less(tf.random_uniform([]), 0.9), lambda: temperature,\n        lambda: tf.random_uniform([], minval=0.5, maxval=1.0))\n    s = tf.nn.softmax((logsm + gumbel_samples) / temperature)\n    m = tf.nn.softmax(m)\n    kl = -tf.reduce_max(logsm, axis=-1)\n\n    if summary:\n      tf.summary.histogram(\"max-log\", tf.reshape(kl, [-1]))\n\n    # Calculate the argmax and construct hot vectors.\n    maxvec = tf.reshape(tf.argmax(m, axis=-1), [-1])\n    maxvhot = tf.stop_gradient(tf.one_hot(maxvec, 2**z_size))\n\n    # Add losses that prevent too few being used.\n    distrib = tf.reshape(logsm, [-1, 2**z_size]) * maxvhot\n    d_mean = tf.reduce_mean(distrib, axis=[0], keep_dims=True)\n    d_variance = tf.reduce_mean(\n        tf.squared_difference(distrib, d_mean), axis=[0])\n    d_dev = -tf.reduce_mean(d_variance)\n    ret = s\n\n    if mode != tf.estimator.ModeKeys.TRAIN:\n      ret = tf.reshape(maxvhot, common_layers.shape_list(s))  # Just hot @eval.\n    return m, ret, d_dev * 5.0 + tf.reduce_mean(kl) * 0.002", "response": "Gumbel - softmax discretization bottleneck."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npredicting a sequence of bits with LSTM.", "response": "def predict_bits_with_lstm(prediction_source, state_size, total_num_bits,\n                           target_bits=None, extra_inputs=None,\n                           bits_at_once=8, temperature=1.0, dropout=0.1):\n  \"\"\"Predict a sequence of bits (a latent) with LSTM, both training and infer.\n\n  Given a tensor on which the predictions are based (prediction_source), we use\n  a single-layer LSTM with state of size state_size to predict total_num_bits,\n  which we predict in groups of size bits_at_once. During training, we use\n  target_bits as input to the LSTM (teacher forcing) and return the target_bits\n  together with the prediction loss. During inference, we sample with the given\n  temperature and return the predicted sequence and loss 0.\n\n  Args:\n    prediction_source: a Tensor of shape [batch_size, ...] used to create\n      the initial state and the first input to the LSTM.\n    state_size: python integer, the size of the LSTM state.\n    total_num_bits: python integer, how many bits in total to predict.\n    target_bits: a tensor of shape [batch_size, total_num_bits] used during\n      training as the target to predict; each element should be -1 or 1.\n    extra_inputs: a Tensor [batch_size, total_num_bits // bits_at_once, d]\n      of additional inputs, passed as additional LSTM inputs.\n    bits_at_once: pytho integer, how many bits to predict at once.\n    temperature: python float, temperature used for sampling during inference.\n    dropout: float, the amount of dropout to aply during training (0.1 default).\n\n  Returns:\n    a pair (bits, loss) with the predicted bit sequence, which is a Tensor of\n    shape [batch_size, total_num_bits] with elements either -1 or 1, and a loss\n    used to train the predictions against the provided target_bits.\n  \"\"\"\n\n  with tf.variable_scope(\"predict_bits_with_lstm\"):\n    # Layers and cell state creation.\n    lstm_cell = tf.nn.rnn_cell.LSTMCell(state_size)\n    discrete_predict = tf.layers.Dense(2**bits_at_once, name=\"discrete_predict\")\n    discrete_embed = tf.layers.Dense(state_size, name=\"discrete_embed\")\n    batch_size = common_layers.shape_list(prediction_source)[0]\n    layer_pred = tf.layers.flatten(prediction_source)\n    first_lstm_input = tf.layers.dense(layer_pred, state_size, name=\"istate\")\n    c_state = tf.layers.dense(layer_pred, state_size, name=\"cstate\")\n    m_state = tf.layers.dense(layer_pred, state_size, name=\"mstate\")\n    state = (c_state, m_state)\n\n    # Prediction mode if no targets are given.\n    if target_bits is None:\n      outputs = []\n      lstm_input = first_lstm_input\n      for i in range(total_num_bits // bits_at_once):\n        if extra_inputs is not None:\n          lstm_input = tf.concat([lstm_input, extra_inputs[:, i, :]], axis=1)\n        output, state = lstm_cell(lstm_input, state)\n        discrete_logits = discrete_predict(output)\n        discrete_samples = common_layers.sample_with_temperature(\n            discrete_logits, temperature)\n        outputs.append(tf.expand_dims(discrete_samples, axis=1))\n        lstm_input = discrete_embed(tf.one_hot(discrete_samples, 256))\n      outputs = tf.concat(outputs, axis=1)\n      outputs = int_to_bit(outputs, bits_at_once)\n      outputs = tf.reshape(outputs, [batch_size, total_num_bits])\n      return 2 * outputs - 1, 0.0\n\n    # Training mode, calculating loss.\n    assert total_num_bits % bits_at_once == 0\n    target_bits = tf.reshape(tf.maximum(tf.stop_gradient(target_bits), 0), [\n        batch_size, total_num_bits // bits_at_once, bits_at_once])\n    target_ints = bit_to_int(target_bits, bits_at_once)\n    tf.summary.histogram(\"target_integers\", tf.reshape(target_ints, [-1]))\n    target_hot = tf.one_hot(target_ints, 2**bits_at_once, axis=-1)\n    target_embedded = discrete_embed(target_hot)\n    target_embedded = tf.nn.dropout(target_embedded, 1.0 - dropout)\n    teacher_input = tf.concat(\n        [tf.expand_dims(first_lstm_input, axis=1), target_embedded], axis=1)\n    outputs = []\n    for i in range(total_num_bits // bits_at_once):\n      lstm_input = teacher_input[:, i, :]\n      if extra_inputs is not None:\n        lstm_input = tf.concat([lstm_input, extra_inputs[:, i, :]], axis=1)\n      output, state = lstm_cell(lstm_input, state)\n      outputs.append(tf.expand_dims(output, axis=1))\n    outputs = tf.concat(outputs, axis=1)\n    outputs = tf.nn.dropout(outputs, 1.0 - dropout)\n    d_int_pred = discrete_predict(outputs)\n    pred_loss = tf.losses.sparse_softmax_cross_entropy(\n        logits=d_int_pred, labels=target_ints)\n    pred_loss = tf.reduce_mean(pred_loss)\n    return d_int_pred, pred_loss"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_vq_codebook(codebook_size, hidden_size):\n  with tf.variable_scope(\"vq\", reuse=tf.AUTO_REUSE):\n    means = tf.get_variable(\n        name=\"means\",\n        shape=[codebook_size, hidden_size],\n        initializer=tf.uniform_unit_scaling_initializer())\n\n    ema_count = tf.get_variable(\n        name=\"ema_count\",\n        shape=[codebook_size],\n        initializer=tf.constant_initializer(0),\n        trainable=False)\n\n    with tf.colocate_with(means):\n      ema_means = tf.get_variable(\n          name=\"ema_means\",\n          initializer=means.initialized_value(),\n          trainable=False)\n\n  return means, ema_means, ema_count", "response": "Get lookup table for VQ bottleneck."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the nearest element in means to elements in x.", "response": "def vq_nearest_neighbor(x, means,\n                        soft_em=False, num_samples=10, temperature=None):\n  \"\"\"Find the nearest element in means to elements in x.\"\"\"\n  bottleneck_size = common_layers.shape_list(means)[0]\n  x_norm_sq = tf.reduce_sum(tf.square(x), axis=-1, keepdims=True)\n  means_norm_sq = tf.reduce_sum(tf.square(means), axis=-1, keepdims=True)\n  scalar_prod = tf.matmul(x, means, transpose_b=True)\n  dist = x_norm_sq + tf.transpose(means_norm_sq) - 2 * scalar_prod\n  if soft_em:\n    x_means_idx = tf.multinomial(-dist, num_samples=num_samples)\n    x_means_hot = tf.one_hot(\n        x_means_idx, depth=common_layers.shape_list(means)[0])\n    x_means_hot = tf.reduce_mean(x_means_hot, axis=1)\n  else:\n    if temperature is None:\n      x_means_idx = tf.argmax(-dist, axis=-1)\n    else:\n      x_means_idx = tf.multinomial(- dist / temperature, 1)\n      x_means_idx = tf.squeeze(x_means_idx, axis=-1)\n    if (common_layers.should_generate_summaries() and\n        not common_layers.is_xla_compiled()):\n      tf.summary.histogram(\"means_idx\", tf.reshape(x_means_idx, [-1]))\n    x_means_hot = tf.one_hot(x_means_idx, bottleneck_size)\n  x_means_hot_flat = tf.reshape(x_means_hot, [-1, bottleneck_size])\n  x_means = tf.matmul(x_means_hot_flat, means)\n  e_loss = tf.reduce_mean(tf.squared_difference(x, tf.stop_gradient(x_means)))\n  return x_means_hot, e_loss, dist"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef vq_body(x,\n            codebook_size,\n            beta=0.25,\n            decay=0.999,\n            epsilon=1e-5,\n            soft_em=False,\n            num_samples=10,\n            temperature=None,\n            do_update=True):\n  \"\"\"Discretize each x into one of codebook_size codes.\"\"\"\n  x_shape = common_layers.shape_list(x)\n  hidden_size = x_shape[-1]\n  means, ema_means, ema_count = get_vq_codebook(codebook_size, hidden_size)\n  x = tf.reshape(x, [-1, hidden_size])\n  x_means_hot, e_loss, distances = vq_nearest_neighbor(\n      x, means, soft_em=soft_em, num_samples=num_samples,\n      temperature=temperature)\n\n  def loss_with_update():\n    \"\"\"Update the ema variables and return loss triggering the update.\"\"\"\n    updated_ema_count = moving_averages.assign_moving_average(\n        ema_count,\n        tf.reduce_sum(tf.reshape(x_means_hot, shape=[-1, codebook_size]),\n                      axis=0),\n        decay,\n        zero_debias=False)\n\n    dw = tf.matmul(x_means_hot, x, transpose_a=True)\n    updated_ema_means = tf.identity(\n        moving_averages.assign_moving_average(\n            ema_means, dw, decay, zero_debias=False))\n    n = tf.reduce_sum(updated_ema_count, axis=-1, keepdims=True)\n    updated_ema_count = (\n        (updated_ema_count + epsilon) / (n + codebook_size * epsilon) * n)\n    updated_ema_means /= tf.expand_dims(updated_ema_count, axis=-1)\n    with tf.control_dependencies([e_loss]):\n      update_means = means.assign(updated_ema_means)\n      with tf.control_dependencies([update_means]):\n        return beta * e_loss\n\n  # Loss, also do update if requested.\n  if do_update:\n    loss = loss_with_update()\n  else:\n    loss = tf.cond(do_update, loss_with_update, lambda: beta * e_loss)\n\n  d = tf.reshape(x_means_hot, x_shape[:-1] + [codebook_size])\n  return d, loss, distances", "response": "Returns a single body of the VQ model."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef vq_loss(x,\n            targets,\n            codebook_size,\n            beta=0.25,\n            decay=0.999,\n            epsilon=1e-5,\n            soft_em=False,\n            num_samples=10,\n            temperature=None,\n            do_update=True):\n  \"\"\"Compute the loss of large vocab tensors using a VQAE codebook.\n\n  Args:\n    x: Tensor of inputs to be quantized to nearest code\n    targets: Tensor of target indices to target codes\n    codebook_size: Size of quantization codebook\n    beta: scalar float for moving averages\n    decay: scalar float for moving averages\n    epsilon: scalar float for moving averages\n    soft_em: boolean, whether to apply a soft sampling procedure\n    num_samples: if soft_em, number of samples to take\n    temperature: temperature if we want to sample nearest neighbors or None\n    do_update: whether to update the means; True by default, can be a Tensor\n\n  Returns:\n    discrete_x: one-hot Tensor indicating which codebook element is closest to x\n    x_means: Tensor, on the forward pass: closest codebook element to x, on the\n      backwards pass: soft convex-combination of codebook elements by proximity\n      to x\n    target_means: the codebook elements corresponding to the targets\n    code_loss: loss driving x closer to its nearest codebook element\n    targets_loss: cross-entropy loss driving x closer to code corresponding to\n      target\n  \"\"\"\n  x_shape = common_layers.shape_list(x)\n  target_shape = common_layers.shape_list(targets)\n  hidden_size = x_shape[-1]\n  means, _, _ = get_vq_codebook(codebook_size, hidden_size)\n  x = tf.reshape(x, [-1, hidden_size])\n  targets = tf.reshape(targets, [-1])\n  one_hot_targets = tf.one_hot(targets, codebook_size)\n  target_means = tf.matmul(one_hot_targets, means)\n\n  discrete_x, code_loss, distances = vq_body(\n      x,\n      codebook_size,\n      beta=beta,\n      decay=decay,\n      epsilon=epsilon,\n      soft_em=soft_em,\n      num_samples=num_samples,\n      temperature=temperature,\n      do_update=do_update)\n\n  logits = -distances\n  targets_loss = tf.losses.sparse_softmax_cross_entropy(\n      logits=logits, labels=targets)\n  targets_loss = tf.reduce_mean(targets_loss)\n\n  x_means = tf.matmul(discrete_x, means)\n  x_means = x + tf.stop_gradient(x_means - x)\n\n  discrete_x = tf.reshape(discrete_x, x_shape[:-1] + [codebook_size])\n  target_means = tf.reshape(target_means, target_shape + [hidden_size])\n  return discrete_x, x_means, target_means, code_loss, targets_loss", "response": "Compute the loss of large vocab tensors using a VQAE codebook."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gumbel_softmax_nearest_neighbor_dvq(x,\n                                        means,\n                                        block_v_size,\n                                        hard=False,\n                                        temperature_init=1.2,\n                                        num_samples=1,\n                                        temperature_warmup_steps=150000,\n                                        summary=True,\n                                        num_flows=0,\n                                        approximate_gs_entropy=False,\n                                        sum_over_latents=False):\n  \"\"\"Sample from Gumbel-Softmax and compute neighbors and losses.\n\n  Args:\n    x: A `float`-like `Tensor` of shape [batch_size, latent_dim, num_blocks,\n      block_dim] containing the latent vectors to be compared to the codebook.\n    means: Embedding table of shape [num_blocks, block_v_size, block_dim].\n    block_v_size: Number of discrete codes per block.\n    hard: Determines whether we take hard or soft Gumbel-Softmax samples\n      (Default: False).\n    temperature_init: Initial temperature used for Gumbel-Softmax samples,\n      after it which it decays to 0 (Default: 1.2).\n    num_samples: Number of samples drawn for each latent (Default: 1).\n    temperature_warmup_steps: Number of steps it takes to decay temperature to 0\n      (Default: 150000).\n    summary: When `True`, we save histogram summaries of the KL term (Default:\n      True).\n    num_flows: Number of inverse autoregressive flows with Gumbel-Softmax\n      samples.\n    approximate_gs_entropy: When `True`, we approximate Gumbel-Softmax\n      density as categorical when calculating sample entropy (Default: False).\n    sum_over_latents: Whether to sum over non-batch dimensions when calculating\n      negative entropy loss.\n\n  Returns:\n    x_means_assignments: A `float`-like `Tensor` containing the codebook\n      assignments, averaged over samples, with shape [batch_size * latent_dim,\n      num_blocks, block_v_size].\n    neg_q_entropy: The negative entropy of the variational distribution,\n      averaged over samples.\n  \"\"\"\n  batch_size, latent_dim, num_blocks, block_dim = common_layers.shape_list(x)\n\n  # Combine latent_dim and batch_size for computing distances.\n  x = tf.reshape(x, [-1, num_blocks, block_dim])\n\n  # Compute distances using (x - means)**2 = x**2 + means**2 - 2*x*means.\n  x_norm_sq = tf.reduce_sum(tf.square(x), axis=-1, keepdims=True)\n  means_norm_sq = tf.reduce_sum(tf.square(means), axis=-1, keepdims=True)\n  means_norm_sq = tf.transpose(means_norm_sq, perm=[2, 0, 1])\n  scalar_prod = tf.matmul(\n      tf.transpose(x, perm=[1, 0, 2]), tf.transpose(means, perm=[0, 2, 1]))\n  scalar_prod = tf.transpose(scalar_prod, perm=[1, 0, 2])\n  dist = x_norm_sq + means_norm_sq - 2 * scalar_prod\n\n  # IAF requires latents to have their own dimension, so reshape dist from\n  # [batch_size * latent_dim, num_blocks, block_v_size] to\n  # [batch_size * num_blocks, latent_dim, block_v_size].\n  dist = tf.reshape(dist, [batch_size, latent_dim, num_blocks, -1])\n  dist = tf.reshape(\n      tf.transpose(dist, perm=[0, 2, 1, 3]), [-1, latent_dim, block_v_size])\n  log_class_probs = tf.nn.log_softmax(-dist)\n\n  sample_shape = [num_samples] + common_layers.shape_list(dist)\n  gumbel_samples = gumbel_sample(sample_shape)\n\n  # Temperature decays linearly.\n  temperature = temperature_init - common_layers.inverse_lin_decay(\n      temperature_warmup_steps)\n\n  # 10% of the time keep reasonably high temperature to keep learning.\n  temperature = tf.cond(\n      tf.less(tf.random_uniform([]), 0.9), lambda: temperature,\n      lambda: tf.random_uniform([], minval=0.5, maxval=1.0))\n\n  gumbel_softmax_samples = tf.nn.softmax(\n      (tf.expand_dims(log_class_probs, 0) + gumbel_samples) / temperature)\n  q_samples = tf.clip_by_value(gumbel_softmax_samples, 1e-6, 1 - 1e-6)\n\n  if approximate_gs_entropy:\n    q_dist = tfp.distributions.Multinomial(total_count=1.0, logits=-dist)\n  else:\n    q_dist = tfp.distributions.RelaxedOneHotCategorical(\n        temperature, logits=-dist)\n\n  # Take mean over samples to approximate entropy.\n  neg_q_entropy = tf.reduce_mean(q_dist.log_prob(q_samples), 0)\n  if summary:\n    tf.summary.histogram(\"neg_q_entropy\", tf.reshape(neg_q_entropy, [-1]))\n  if sum_over_latents:\n    neg_q_entropy = tf.reshape(neg_q_entropy,\n                               [batch_size, num_blocks, latent_dim])\n    neg_q_entropy = tf.reduce_sum(neg_q_entropy, [1, 2])\n  neg_q_entropy = tf.reduce_mean(neg_q_entropy)\n\n  if num_flows > 0:\n    hparams = iaf_hparams(hidden_size=512, filter_size=4096)\n    q_samples = tf.reshape(q_samples, [-1, latent_dim, block_v_size])\n    for flow in range(num_flows):\n      shifted_samples = tf.pad(q_samples, [[0, 0], [1, 0], [0, 0]])[:, :-1, :]\n\n      # Project samples from  [batch_size, latent_size, block_v_size] to\n      # [batch_size, latent_size, hidden_size].\n      shifted_samples = common_layers.dense(shifted_samples,\n                                            hparams.hidden_size)\n      # TODO(vafa): Include masking as a flag.\n      mask = True\n      if mask:\n        attention_type = cia.AttentionType.LOCAL_1D\n      else:\n        attention_type = cia.AttentionType.GLOBAL\n      ffn_output = cia.transformer_decoder_layers(\n          inputs=shifted_samples,\n          encoder_output=None,\n          num_layers=6,\n          hparams=hparams,\n          attention_type=attention_type,\n          name=\"transformer_\" + str(flow))\n\n      # Project samples back to [batch_size, latent_size, block_v_size].\n      ffn_output = common_layers.dense(ffn_output, block_v_size)\n      log_pi = tf.nn.log_softmax(ffn_output)\n\n      # Flow 1: Adding log_pi to q_samples and dividing by the temperature.\n      # Note that we drop the last dimension of q_samples for centered-softmax,\n      # which we can do without recalculating probabilities because the last\n      # dimension of log_pi and q_samples are deterministic given the others.\n      # Flow 2: Centered-softmax.\n      chained_bijectors = tfp.bijectors.Chain([\n          tfp.bijectors.SoftmaxCentered(),\n          tfp.bijectors.Affine(\n              shift=log_pi[:, :, :-1],\n              scale_identity_multiplier=1. / temperature)\n      ])\n      q_samples = chained_bijectors.forward(q_samples[:, :, :-1])\n      log_det = chained_bijectors.inverse_log_det_jacobian(\n          q_samples, event_ndims=1)\n      log_det = tf.reshape(log_det,\n                           [num_samples, batch_size, num_blocks, latent_dim])\n      if sum_over_latents:\n        log_det = tf.reduce_sum(log_det, axis=[2, 3])\n      neg_q_entropy += tf.reduce_mean(log_det)\n\n    q_samples = tf.reshape(\n        q_samples,\n        [num_samples, batch_size * num_blocks, latent_dim, block_v_size])\n\n  if hard:\n    x_means_idx = tf.argmax(q_samples, -1)\n\n    # Take average of one-hot vectors over samples.\n    x_means_hot = tf.reduce_mean(tf.one_hot(x_means_idx, block_v_size), 0)\n    x_means_assignments = (\n        tf.reduce_mean(q_samples, 0) +\n        tf.stop_gradient(x_means_hot - tf.reduce_mean(q_samples, 0)))\n  else:\n    x_means_assignments = tf.reduce_mean(gumbel_softmax_samples, 0)\n\n  # Reshape assignments to [batch_size * latent_dim, num_blocks,\n  # block_v_size]. We have to transpose between reshapes to make sure the\n  # dimensions have the correct interpretation.\n  x_means_assignments = tf.reshape(\n      x_means_assignments, [batch_size, num_blocks, latent_dim, block_v_size])\n  x_means_assignments = tf.transpose(x_means_assignments, [0, 2, 1, 3])\n  x_means_assignments = tf.reshape(\n      x_means_assignments, [batch_size * latent_dim, num_blocks, block_v_size])\n\n  return x_means_assignments, neg_q_entropy", "response": "Sample from Gumbel - Softmax and compute neighbors and losses."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef isemhash_bottleneck(x,\n                        bottleneck_bits,\n                        bottleneck_noise,\n                        discretize_warmup_steps,\n                        mode,\n                        isemhash_noise_dev=0.5,\n                        isemhash_mix_prob=0.5):\n  \"\"\"Improved semantic hashing bottleneck.\"\"\"\n  with tf.variable_scope(\"isemhash_bottleneck\"):\n    x = tf.layers.dense(x, bottleneck_bits, name=\"dense\")\n    y = common_layers.saturating_sigmoid(x)\n    if isemhash_noise_dev > 0 and mode == tf.estimator.ModeKeys.TRAIN:\n      noise = tf.truncated_normal(\n          common_layers.shape_list(x), mean=0.0, stddev=isemhash_noise_dev)\n      y = common_layers.saturating_sigmoid(x + noise)\n    d = tf.to_float(tf.less(0.5, y)) + y - tf.stop_gradient(y)\n    d = 2.0 * d - 1.0  # Move from [0, 1] to [-1, 1].\n    if mode == tf.estimator.ModeKeys.TRAIN:  # Flip some bits.\n      noise = tf.random_uniform(common_layers.shape_list(x))\n      noise = 2.0 * tf.to_float(tf.less(bottleneck_noise, noise)) - 1.0\n      d *= noise\n      d = common_layers.mix(\n          d,\n          2.0 * y - 1.0,\n          discretize_warmup_steps,\n          mode == tf.estimator.ModeKeys.TRAIN,\n          max_prob=isemhash_mix_prob)\n    return d, 0.0", "response": "Improved semantic hashing bottleneck."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nimproving semantic hashing un - bottleneck.", "response": "def isemhash_unbottleneck(x, hidden_size, isemhash_filter_size_multiplier=1.0):\n  \"\"\"Improved semantic hashing un-bottleneck.\"\"\"\n  filter_size = int(hidden_size * isemhash_filter_size_multiplier)\n  x = 0.5 * (x - 1.0)  # Move from [-1, 1] to [0, 1].\n  with tf.variable_scope(\"isemhash_unbottleneck\"):\n    h1a = tf.layers.dense(x, filter_size, name=\"hidden1a\")\n    h1b = tf.layers.dense(1.0 - x, filter_size, name=\"hidden1b\")\n    h2 = tf.layers.dense(tf.nn.relu(h1a + h1b), filter_size, name=\"hidden2\")\n    return tf.layers.dense(tf.nn.relu(h2), hidden_size, name=\"final\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parametrized_unbottleneck(x, hidden_size, hparams):\n  if hparams.bottleneck_kind == \"tanh_discrete\":\n    return tanh_discrete_unbottleneck(x, hidden_size)\n  if hparams.bottleneck_kind == \"isemhash\":\n    return isemhash_unbottleneck(x, hidden_size,\n                                 hparams.isemhash_filter_size_multiplier)\n  if hparams.bottleneck_kind in [\"vq\", \"em\", \"gumbel_softmax\"]:\n    return vq_discrete_unbottleneck(x, hidden_size)\n  raise ValueError(\n      \"Unsupported hparams.bottleneck_kind %s\" % hparams.bottleneck_kind)", "response": "Meta - function calling all the above un - bottlenecks with hparams."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating hyperpameters for inverse autoregressive flows. Args: hidden_size: Width of attention layers and neural network output layer. filter_size: Hidden layer width for neural network. Returns: hparams: Hyperpameters with basic presets for inverse autoregressive flows.", "response": "def iaf_hparams(hidden_size=512, filter_size=4096):\n  \"\"\"Create hyperpameters for inverse autoregressive flows.\n\n  Args:\n    hidden_size: Width of attention layers and neural network output layer.\n    filter_size: Hidden layer width for neural network.\n\n  Returns:\n    hparams: Hyperpameters with basic presets for inverse autoregressive flows.\n  \"\"\"\n  hparams = common_hparams.basic_params1()\n\n  # Attention hyperparameters.\n  hparams.hidden_size = hidden_size\n  hparams.add_hparam(\"attention_key_channels\", None)\n  hparams.add_hparam(\"attention_value_channels\", None)\n  hparams.add_hparam(\"num_heads\", 4)\n  hparams.add_hparam(\"attention_dropout\", 0.1)\n  hparams.add_hparam(\"shared_rel\", False)\n  hparams.add_hparam(\"block_width\", 1)\n  hparams.add_hparam(\"block_length\", 1)\n  hparams.add_hparam(\"q_filter_width\", 1)\n  hparams.add_hparam(\"kv_filter_width\", 1)\n\n  # Preprocessing and postprocesing hyperparameters.\n  hparams.layer_preprocess_sequence = \"n\"\n  hparams.layer_prepostprocess_dropout = 0.1\n  hparams.norm_type = \"layer\"\n  hparams.norm_epsilon = 1e-06\n  hparams.layer_prepostprocess_dropout_broadcast_dims = \"\"\n  hparams.layer_postprocess_sequence = \"da\"\n\n  # Feedforward neural network hyperparameters.\n  hparams.add_hparam(\"filter_size\", filter_size)\n  hparams.add_hparam(\"ffn_layer\", \"conv_hidden_relu\")\n  hparams.add_hparam(\"relu_dropout\", 0.1)\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _original_vocab(tmp_dir):\n  vocab_url = (\"http://download.tensorflow.org/models/LM_LSTM_CNN/\"\n               \"vocab-2016-09-10.txt\")\n  vocab_filename = os.path.basename(vocab_url + \".en\")\n  vocab_filepath = os.path.join(tmp_dir, vocab_filename)\n  if not os.path.exists(vocab_filepath):\n    generator_utils.maybe_download(tmp_dir, vocab_filename, vocab_url)\n  return set([\n      text_encoder.native_to_unicode(l.strip())\n      for l in tf.gfile.Open(vocab_filepath)\n  ])", "response": "Returns a set containing the original vocabulary."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreplaces out - of - vocab words with UNK.", "response": "def _replace_oov(original_vocab, line):\n  \"\"\"Replace out-of-vocab words with \"UNK\".\n\n  This maintains compatibility with published results.\n\n  Args:\n    original_vocab: a set of strings (The standard vocabulary for the dataset)\n    line: a unicode string - a space-delimited sequence of words.\n\n  Returns:\n    a unicode string - a space-delimited sequence of words.\n  \"\"\"\n  return u\" \".join(\n      [word if word in original_vocab else u\"UNK\" for word in line.split()])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading and unpack the corpus.", "response": "def _maybe_download_corpus(tmp_dir):\n  \"\"\"Download and unpack the corpus.\n\n  Args:\n    tmp_dir: directory containing dataset.\n  \"\"\"\n  corpus_url = (\"http://www.statmt.org/lm-benchmark/\"\n                \"1-billion-word-language-modeling-benchmark-r13output.tar.gz\")\n  corpus_filename = os.path.basename(corpus_url)\n  corpus_filepath = os.path.join(tmp_dir, corpus_filename)\n  if not os.path.exists(corpus_filepath):\n    generator_utils.maybe_download(tmp_dir, corpus_filename, corpus_url)\n    with tarfile.open(corpus_filepath, \"r:gz\") as corpus_tar:\n      corpus_tar.extractall(tmp_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncycling GAN main step used for training.", "response": "def cycle_gan_internal(inputs, targets, _, hparams):\n  \"\"\"Cycle GAN, main step used for training.\"\"\"\n  with tf.variable_scope(\"cycle_gan\"):\n    # Embed inputs and targets.\n    inputs_orig, targets_orig = tf.to_int32(inputs), tf.to_int32(targets)\n    inputs = common_layers.embedding(\n        inputs_orig, hparams.vocab_size, hparams.hidden_size, \"embed\")\n    targets = common_layers.embedding(\n        targets_orig, hparams.vocab_size, hparams.hidden_size,\n        \"embed\", reuse=True)\n\n    x, _ = split_on_batch(inputs)\n    _, y = split_on_batch(targets)\n\n    # Y --> X\n    y_fake = generator(y, hparams, \"Fy\", reuse=False)\n    y_to_x_loss = lossfn(y, y_fake, True, hparams, True, \"YtoX\")\n\n    # X --> Y\n    x_fake = generator(x, hparams, \"Gx\", reuse=False)\n    x_to_y_loss = lossfn(y, x_fake, True, hparams, True, \"XtoY\")\n\n    # Cycle-Consistency\n    y_fake_ = generator(y_fake, hparams, \"Gx\", reuse=True)\n    x_fake_ = generator(x_fake, hparams, \"Fy\", reuse=True)\n    x_to_x_loss = hparams.cycle_loss_multiplier1 * tf.reduce_mean(\n        tf.abs(x_fake_ - x))\n    y_to_y_loss = hparams.cycle_loss_multiplier2 * tf.reduce_mean(\n        tf.abs(y_fake_ - y))\n    cycloss = x_to_x_loss + y_to_y_loss\n\n    sample_generated = generator(inputs, hparams, \"Gx\", reuse=True)\n    sample_generated = tf.layers.dense(\n        sample_generated, hparams.vocab_size, name=\"softmax\", reuse=None)\n    sample_generated = tf.stop_gradient(\n        tf.expand_dims(sample_generated, axis=2))\n\n    losses = {\"cycloss\": cycloss,\n              \"y_to_x_loss\": y_to_x_loss,\n              \"x_to_y_loss\": x_to_y_loss}\n\n    return sample_generated, losses"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cycle_gan_small():\n  hparams = transformer_vae.transformer_ae_small()\n  hparams.batch_size = 2048\n  hparams.bottom = {\n      \"inputs\": modalities.identity_bottom,\n      \"targets\": modalities.identity_bottom,\n  }\n  hparams.top = {\n      \"targets\": modalities.identity_top,\n  }\n  hparams.weight_decay = 3.0\n  hparams.learning_rate = 0.05\n  hparams.kl_warmup_steps = 5000\n  hparams.learning_rate_warmup_steps = 3000\n  hparams.add_hparam(\"vocab_size\", 66)  # Vocabulary size, need to set here.\n  hparams.add_hparam(\"cycle_loss_multiplier1\", 10.0)\n  hparams.add_hparam(\"cycle_loss_multiplier2\", 10.0)\n  return hparams", "response": "Set of hyperparameters for training on - the - fly."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef preprocess_frame(frame):\n  # Normalize from [0.0, 1.0] -> [-0.5, 0.5]\n  frame = common_layers.convert_rgb_to_real(frame)\n  frame = frame - 0.5\n  frame, _ = glow_ops.uniform_binning_correction(frame)\n  return frame", "response": "Preprocess frame.\n\n  1. Converts [0, 255] to [-0.5, 0.5]\n  2. Adds uniform noise.\n\n  Args:\n    frame: 3-D Tensor representing pixels.\n  Returns:\n    frame: 3-D Tensor with values in between [-0.5, 0.5]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef frame_to_latents(frame, hparams):\n  # Preprocess\n  frame = preprocess_frame(frame)\n\n  # Encode [X_t] to [z^1_t, z^2_t .. z^l_t]\n  glow_vals = glow_ops.encoder_decoder(\n      \"codec\", frame, hparams, eps=None, reverse=False)\n  z_top, _, level_eps, _, _ = glow_vals\n  return z_top, level_eps", "response": "Encode frames to latents."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndecode latents to frames.", "response": "def latents_to_frames(z_top_interp, level_eps_interp, hparams):\n  \"\"\"Decodes latents to frames.\"\"\"\n  # Decode [z^1_t, z^2_t .. z^l_t] to [X_t]\n  images, _, _, _ = glow_ops.encoder_decoder(\n      \"codec\", z_top_interp, hparams, eps=level_eps_interp, reverse=True)\n  images = glow_ops.postprocess(images)\n  return images"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef interpolate(features, hparams, decode_hp):\n  inputs, targets = features[\"inputs\"], features[\"targets\"]\n  inputs = tf.unstack(inputs, axis=1)\n  targets = tf.unstack(targets, axis=1)\n  coeffs = np.linspace(0.0, 1.0, decode_hp.num_interp)\n\n  # (X_1, X_t) -> (z_1, z_t)\n  first_frame, last_frame = inputs[0], targets[-1]\n  first_top_z, first_level_eps = frame_to_latents(first_frame, hparams)\n  last_top_z, last_level_eps = frame_to_latents(last_frame, hparams)\n\n  # Interpolate latents at all levels.\n  first_lats = first_level_eps + [first_top_z]\n  last_lats = last_level_eps + [last_top_z]\n  interp_lats = []\n  lat_iterator = enumerate(zip(first_lats, last_lats))\n  for level_ind, (first_lat, last_lat) in lat_iterator:\n    if level_ind in decode_hp.level_interp:\n      if decode_hp.channel_interp == \"all\":\n        interp_lat = glow_ops.linear_interpolate(first_lat, last_lat, coeffs)\n      else:\n        interp_lat = glow_ops.linear_interpolate_rank(\n            first_lat, last_lat, coeffs, decode_hp.rank_interp)\n    else:\n      interp_lat = tf.tile(first_lat, [decode_hp.num_interp, 1, 1, 1])\n    interp_lats.append(interp_lat)\n\n  level_eps_interp = interp_lats[:hparams.n_levels-1]\n  z_top_interp = interp_lats[-1]\n  images = latents_to_frames(z_top_interp, level_eps_interp, hparams)\n  return images, first_frame, last_frame", "response": "Interpolate between the first input frame and last target frame."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting nested summaries_log_dir based on decode_hp.", "response": "def get_summaries_log_dir(decode_hp, output_dir, dataset_split):\n  \"\"\"Get nested summaries_log_dir based on decode_hp.\"\"\"\n  child_dir = decode_hp.summaries_log_dir\n  level_dir = \"\".join([str(level) for level in decode_hp.level_interp])\n  if decode_hp.channel_interp == \"all\":\n    rank_dir = \"all\"\n  else:\n    rank_dir = \"rank_%d\" % decode_hp.rank_interp\n  child_dir = \"%s/%s_%s\" % (child_dir, level_dir, rank_dir)\n  if dataset_split is not None:\n    child_dir += \"_{}\".format(dataset_split)\n  return os.path.join(output_dir, child_dir)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert interpolated frames into a list of tf summaries.", "response": "def interpolations_to_summary(sample_ind, interpolations, first_frame,\n                              last_frame, hparams, decode_hp):\n  \"\"\"Converts interpolated frames into tf summaries.\n\n  The summaries consists of:\n    1. Image summary corresponding to the first frame.\n    2. Image summary corresponding to the last frame.\n    3. The interpolated frames as a gif summary.\n\n  Args:\n    sample_ind: int\n    interpolations: Numpy array, shape=(num_interp, H, W, 3)\n    first_frame: Numpy array, shape=(HWC)\n    last_frame: Numpy array, shape=(HWC)\n    hparams: HParams, train hparams\n    decode_hp: HParams, decode hparams\n  Returns:\n    summaries: list of tf Summary Values.\n  \"\"\"\n  parent_tag = \"sample_%d\" % sample_ind\n  frame_shape = hparams.problem.frame_shape\n  interp_shape = [hparams.batch_size, decode_hp.num_interp] + frame_shape\n  interpolations = np.reshape(interpolations, interp_shape)\n  interp_tag = \"%s/interp/%s\" % (parent_tag, decode_hp.channel_interp)\n  if decode_hp.channel_interp == \"ranked\":\n    interp_tag = \"%s/rank_%d\" % (interp_tag, decode_hp.rank_interp)\n  summaries, _ = common_video.py_gif_summary(\n      interp_tag, interpolations, return_summary_value=True,\n      max_outputs=decode_hp.max_display_outputs,\n      fps=decode_hp.frames_per_second)\n\n  if decode_hp.save_frames:\n    first_frame_summ = image_utils.image_to_tf_summary_value(\n        first_frame, \"%s/first\" % parent_tag)\n    last_frame_summ = image_utils.image_to_tf_summary_value(\n        last_frame, \"%s/last\" % parent_tag)\n    summaries.append(first_frame_summ)\n    summaries.append(last_frame_summ)\n  return summaries"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates slot variables for Adam with accumulated gradients.", "response": "def _create_slots(self, var_list):\n    \"\"\"Create slot variables for Adam with accumulated gradients.\"\"\"\n    super(MultistepAdamOptimizer, self)._create_slots(var_list)\n    first_var = min(var_list, key=lambda x: x.name)\n    self._create_non_slot_variable(initial_value=0 if self._n == 1 else 1,\n                                   name=\"iter\",\n                                   colocate_with=first_var)\n    for v in var_list:\n      self._zeros_slot(v, \"grad_acc\", self._name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _apply_cond(self, apply_fn, grad, var, *args, **kwargs):\n    grad_acc = self.get_slot(var, \"grad_acc\")\n\n    def apply_adam(grad_acc, apply_fn, grad, var, *args, **kwargs):\n      total_grad = (grad_acc + grad) / tf.cast(self._n_t, grad.dtype)\n      adam_op = apply_fn(total_grad, var, *args, **kwargs)\n      with tf.control_dependencies([adam_op]):\n        grad_acc_to_zero_op = grad_acc.assign(tf.zeros_like(grad_acc),\n                                              use_locking=self._use_locking)\n      return tf.group(adam_op, grad_acc_to_zero_op)\n\n    def accumulate_gradient(grad_acc, grad):\n      assign_op = tf.assign_add(grad_acc, grad, use_locking=self._use_locking)\n      return tf.group(assign_op)  # Strip return value\n\n    return tf.cond(\n        tf.equal(self._get_iter_variable(), 0),\n        lambda: apply_adam(grad_acc, apply_fn, grad, var, *args, **kwargs),\n        lambda: accumulate_gradient(grad_acc, grad))", "response": "Apply conditionally if counter is zero."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _finish(self, update_ops, name_scope):\n    iter_ = self._get_iter_variable()\n    beta1_power, beta2_power = self._get_beta_accumulators()\n    with tf.control_dependencies(update_ops):\n      with tf.colocate_with(iter_):\n\n        def update_beta_op():\n          update_beta1 = beta1_power.assign(\n              beta1_power * self._beta1_t,\n              use_locking=self._use_locking)\n          update_beta2 = beta2_power.assign(\n              beta2_power * self._beta2_t,\n              use_locking=self._use_locking)\n          return tf.group(update_beta1, update_beta2)\n        maybe_update_beta = tf.cond(\n            tf.equal(iter_, 0), update_beta_op, tf.no_op)\n        with tf.control_dependencies([maybe_update_beta]):\n          update_iter = iter_.assign(tf.mod(iter_ + 1, self._n_t),\n                                     use_locking=self._use_locking)\n    return tf.group(\n        *update_ops + [update_iter, maybe_update_beta], name=name_scope)", "response": "Updates beta_power variables every n batches and incrs counter."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transformer_revnet_decoder(decoder_input,\n                               encoder_output,\n                               decoder_self_attention_bias,\n                               encoder_decoder_attention_bias,\n                               hparams,\n                               name=\"decoder\"):\n  \"\"\"A stack of transformer layers.\n\n  Args:\n    decoder_input: a Tensor\n    encoder_output: a Tensor\n    decoder_self_attention_bias: bias Tensor for self-attention\n      (see common_attention.attention_bias())\n    encoder_decoder_attention_bias: bias Tensor for encoder-decoder attention\n      (see common_attention.attention_bias())\n    hparams: hyperparameters for model\n    name: a string\n\n  Returns:\n    y: a Tensors\n  \"\"\"\n\n  def f(x, side_input):\n    \"\"\"f(x) for reversible layer, self-attention and enc-dec attention.\"\"\"\n    decoder_self_attention_bias = side_input[0]\n    encoder_decoder_attention_bias = side_input[1]\n    encoder_output = side_input[2]\n\n    old_hid_size = hparams.hidden_size\n    hparams.hidden_size = old_hid_size // 2\n\n    with tf.variable_scope(\"self_attention\"):\n      y = common_attention.multihead_attention(\n          common_layers.layer_preprocess(\n              x, hparams), None, decoder_self_attention_bias,\n          hparams.attention_key_channels or hparams.hidden_size,\n          hparams.attention_value_channels or hparams.hidden_size,\n          hparams.hidden_size, hparams.num_heads, hparams.attention_dropout)\n      y = common_layers.layer_postprocess(x, y, hparams)\n      if encoder_output is not None:\n        with tf.variable_scope(\"encdec_attention\"):\n          y = common_attention.multihead_attention(\n              common_layers.layer_preprocess(\n                  x, hparams), encoder_output, encoder_decoder_attention_bias,\n              hparams.attention_key_channels or hparams.hidden_size,\n              hparams.attention_value_channels or hparams.hidden_size,\n              hparams.hidden_size, hparams.num_heads, hparams.attention_dropout)\n          y = common_layers.layer_postprocess(x, y, hparams)\n    hparams.hidden_size = old_hid_size\n    return y\n\n  def g(x):\n    \"\"\"g(x) for reversible layer, feed-forward layer.\"\"\"\n    old_hid_size = hparams.hidden_size\n    hparams.hidden_size = old_hid_size // 2\n    with tf.variable_scope(\"ffn\"):\n      y = transformer.transformer_ffn_layer(\n          common_layers.layer_preprocess(x, hparams), hparams)\n      y = common_layers.layer_postprocess(x, y, hparams)\n    hparams.hidden_size = old_hid_size\n    return y\n\n  x1, x2 = tf.split(decoder_input, 2, axis=-1)\n\n  with tf.variable_scope(name):\n    y1, y2 = tf.contrib.layers.rev_block(\n        x1,\n        x2,\n        f,\n        g,\n        num_layers=hparams.num_hidden_layers,\n        f_side_input=[\n            decoder_self_attention_bias, encoder_decoder_attention_bias,\n            encoder_output\n        ],\n        is_training=hparams.mode == tf.estimator.ModeKeys.TRAIN)\n    y = tf.concat([y1, y2], axis=-1)\n    return common_layers.layer_preprocess(y, hparams)", "response": "A stack of transformer layers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transformer_revnet_base():\n  hparams = transformer.transformer_big()\n\n  # Use settings from transformer_n_da\n  hparams.layer_preprocess_sequence = \"n\"\n  hparams.layer_postprocess_sequence = \"da\"\n  hparams.learning_rate = 0.4\n\n  return hparams", "response": "Base hparams for TransformerRevnet."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transformer_revnet_big():\n  hparams = transformer_revnet_base()\n\n  # The TransformerRevnet uses significantly less memory than the Transformer.\n  # Increase batch size and model size.\n  hparams.batch_size *= 2\n  hparams.hidden_size *= 2\n  hparams.num_heads *= 2\n  hparams.num_hidden_layers += 1\n  return hparams", "response": "Base hparams for TransformerRevnet with big batch size."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\novers which devices do we split each training batch. In old-fashioned async mode, we split the batch over all GPUs on the current worker. In sync mode, we split the batch over all the parameter server GPUs. This function returns an expert_utils.Parallelism object, which can be used to build the model. It is configured in a way that any variables created by `tf.get_variable` will be assigned to the parameter servers and shared between datashards. Args: daisy_chain_variables: whether to copy variables in a daisy chain on GPUs. all_workers: whether the devices are all async workers or just this one. Returns: a expert_utils.Parallelism.", "response": "def data_parallelism_from_flags(daisy_chain_variables=True, all_workers=False):\n  \"\"\"Over which devices do we split each training batch.\n\n  In old-fashioned async mode, we split the batch over all GPUs on the\n  current worker.\n\n  In sync mode, we split the batch over all the parameter server GPUs.\n\n  This function returns an expert_utils.Parallelism object, which can be used\n  to build the model.  It is configured in a way that any variables created\n  by `tf.get_variable` will be assigned to the parameter servers and shared\n  between datashards.\n\n  Args:\n    daisy_chain_variables: whether to copy variables in a daisy chain on GPUs.\n    all_workers: whether the devices are all async workers or just this one.\n\n  Returns:\n    a expert_utils.Parallelism.\n  \"\"\"\n  dp_arg_names = inspect.getargspec(data_parallelism).args\n\n  blacklist = [\"daisy_chain_variables\", \"all_workers\"]\n\n  kwargs = {}\n  for arg in dp_arg_names:\n    if arg in blacklist:\n      continue\n    kwargs[arg] = getattr(tf.flags.FLAGS, arg)\n\n  return data_parallelism(\n      daisy_chain_variables=daisy_chain_variables,\n      all_workers=all_workers,\n      **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of data_parallelism_from_flags.", "response": "def data_parallelism(daisy_chain_variables=True,\n                     all_workers=False,\n                     ps_replicas=0,\n                     ps_job=\"/job:ps\",\n                     ps_gpu=0,\n                     schedule=\"continuous_train_and_eval\",\n                     sync=False,\n                     worker_gpu=1,\n                     worker_replicas=1,\n                     worker_id=0,\n                     gpu_order=\"\",\n                     worker_job=\"/job:localhost\",\n                     no_data_parallelism=False):\n  \"\"\"See data_parallelism_from_flags.\"\"\"\n  tf.logging.info(\"schedule=%s\" % schedule)\n  tf.logging.info(\"worker_gpu=%s\" % worker_gpu)\n  tf.logging.info(\"sync=%s\" % sync)\n  def _ps_replicas(all_workers=False):\n    if all_workers:\n      return list(range(ps_replicas))\n    # Worker K will be using replicas {0,...n-1} + K*n if we have n replicas.\n    num_replicas = ps_replicas // worker_replicas\n    return [d + worker_id * num_replicas for d in range(num_replicas)]\n\n  def _gpu_order(num_gpus):\n    if gpu_order:\n      ret = [int(s) for s in gpu_order.split(\" \")]\n      if len(ret) == num_gpus:\n        return ret\n    return list(range(num_gpus))\n\n  def _ps_gpus(all_workers=False):\n    ps_gpus = []\n    for d in _ps_replicas(all_workers=all_workers):\n      ps_gpus.extend([(d, gpu) for gpu in _gpu_order(ps_gpu)])\n    return ps_gpus\n\n  def ps_devices(all_workers=False):\n    \"\"\"List of ps devices (where to put the experts).\n\n    Args:\n      all_workers: whether the list is for all async workers or just this one.\n\n    Returns:\n      a list of device names\n    \"\"\"\n    if ps_replicas > 0:\n      if ps_gpu > 0:\n        return [\n            ps_job + \"/task:%d/GPU:%d\" % (d, gpu)\n            for (d, gpu) in _ps_gpus(all_workers=all_workers)\n        ]\n      else:\n        return [\n            ps_job + \"/task:%d\" % d\n            for d in _ps_replicas(all_workers=all_workers)\n        ]\n    else:\n      if worker_gpu > 0:\n        return [\"gpu:%d\" % d for d in _gpu_order(worker_gpu)]\n      else:\n        return [\"\"]\n\n  def _replica_device_setter(worker_device):\n    if ps_replicas == 0:\n      return worker_device\n    return tf.train.replica_device_setter(\n        worker_device=worker_device,\n        ps_tasks=ps_replicas,\n        ps_device=ps_job + \"/GPU:0\" if ps_gpu > 0 else ps_job)\n\n  is_single_machine = ps_replicas == 0 and worker_replicas == 1\n\n  if no_data_parallelism:\n    datashard_devices = [\"\"]\n    caching_devices = None\n  elif is_single_machine:\n    tf.logging.warn(\n        \"Schedule=%s. Assuming that training is running on a single machine.\",\n        schedule)\n    datashard_devices = [\"gpu:%d\" % d for d in _gpu_order(worker_gpu)]\n    if worker_gpu < 1:\n      datashard_devices += [\"cpu:0\"]\n    caching_devices = None\n  elif sync and ps_replicas > 0:\n    # compute on ps\n    datashard_devices = [\n        _replica_device_setter(d) for d in ps_devices(all_workers=all_workers)\n    ]\n    if ps_gpu > 0 and ps_replicas > 1:\n      caching_devices = [\n          ps_job + \"/task:%d/cpu:0\" % d\n          for (d, _) in _ps_gpus(all_workers=all_workers)\n      ]\n    else:\n      caching_devices = None\n  else:\n    # compute on worker - this is either a single-worker setup or asynchronous\n    # with parameter servers.\n    if worker_gpu > 1:\n      datashard_devices = [\n          _replica_device_setter(worker_job + \"/GPU:%d\" % d)\n          for d in _gpu_order(worker_gpu)\n      ]\n      caching_devices = None\n    else:\n      datashard_devices = [_replica_device_setter(worker_job)]\n      caching_devices = None\n  tf.logging.info(\"datashard_devices: %s\", datashard_devices)\n  tf.logging.info(\"caching_devices: %s\", caching_devices)\n  tf.logging.info(\"ps_devices: %s\", ps_devices(all_workers=all_workers))\n  return eu.Parallelism(\n      datashard_devices,\n      caching_devices=caching_devices,\n      daisy_chain_variables=daisy_chain_variables,\n      ps_devices=ps_devices(all_workers=all_workers))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef concat_generator(filename, up_threshold, low_threshold=10):\n  txt = \"\"\n  for line in tf.gfile.Open(filename):\n    line = line.strip()\n    if len(txt) + len(line) + 1 >= up_threshold:\n      ret = txt\n      txt = \"\"\n      # We don't yield very short long parts to prevent noisy examples.\n      if len(ret) > low_threshold and len(ret) < up_threshold:\n        yield {\"targets\": ret}\n\n    if not txt:\n      txt = line\n    else:\n      txt = \" \".join([txt, line])", "response": "Generate concatenated lines from file upto up_threshold characters."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mix_generators(generator_list):\n  i = 0\n  l = len(generator_list)\n  stopiters_seen = 0\n  while stopiters_seen <= l:\n    try:\n      yield six.next(generator_list[i % l])\n      i += 1\n      stopiters_seen = 0\n    except StopIteration:\n      i += 1\n      stopiters_seen += 1", "response": "Given python generators generate from one then from another etc."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes BLEU core summaries using the decoder output.", "response": "def compute_bleu_summaries(hook_args):\n  \"\"\"Compute BLEU core summaries using the decoder output.\n\n  Args:\n    hook_args: DecodeHookArgs namedtuple\n  Returns:\n    A list of tf.Summary values if hook_args.hparams contains the\n    reference file and the translated file.\n  \"\"\"\n  decode_hparams = hook_args.decode_hparams\n\n  if not (decode_hparams.decode_reference and decode_hparams.decode_to_file):\n    return None\n\n  values = []\n  bleu = 100 * bleu_hook.bleu_wrapper(\n      decode_hparams.decode_reference, decode_hparams.decode_to_file)\n  values.append(tf.Summary.Value(tag=\"BLEU\", simple_value=bleu))\n  tf.logging.info(\"%s: BLEU = %6.2f\" % (decode_hparams.decode_to_file, bleu))\n  if hook_args.hparams.mlperf_mode:\n    current_step = decode_hparams.mlperf_decode_step\n    mlperf_log.transformer_print(\n        key=mlperf_log.EVAL_TARGET, value=decode_hparams.mlperf_threshold)\n    mlperf_log.transformer_print(\n        key=mlperf_log.EVAL_ACCURACY,\n        value={\n            \"epoch\": max(current_step // decode_hparams.iterations_per_loop - 1,\n                         0),\n            \"value\": bleu\n        })\n    mlperf_log.transformer_print(key=mlperf_log.EVAL_STOP)\n\n  if bleu >= decode_hparams.mlperf_threshold:\n    decode_hparams.set_hparam(\"mlperf_success\", True)\n\n  return values"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _preprocess_sgm(line, is_sgm):\n  if not is_sgm:\n    return line\n  # In SGM files, remove <srcset ...>, <p>, <doc ...> lines.\n  if line.startswith(\"<srcset\") or line.startswith(\"</srcset\"):\n    return \"\"\n  if line.startswith(\"<doc\") or line.startswith(\"</doc\"):\n    return \"\"\n  if line.startswith(\"<p>\") or line.startswith(\"</p>\"):\n    return \"\"\n  # Strip <seg> tags.\n  line = line.strip()\n  if line.startswith(\"<seg\") and line.endswith(\"</seg>\"):\n    i = line.index(\">\")\n    return line[i + 1:-6]", "response": "Preprocessing to strip tags in SGM files."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compile_data(tmp_dir, datasets, filename, datatypes_to_clean=None):\n  datatypes_to_clean = datatypes_to_clean or []\n  filename = os.path.join(tmp_dir, filename)\n  lang1_fname = filename + \".lang1\"\n  lang2_fname = filename + \".lang2\"\n  if tf.gfile.Exists(lang1_fname) and tf.gfile.Exists(lang2_fname):\n    tf.logging.info(\"Skipping compile data, found files:\\n%s\\n%s\", lang1_fname,\n                    lang2_fname)\n    return filename\n  with tf.gfile.GFile(lang1_fname, mode=\"w\") as lang1_resfile:\n    with tf.gfile.GFile(lang2_fname, mode=\"w\") as lang2_resfile:\n      for dataset in datasets:\n        url = dataset[0]\n        compressed_filename = os.path.basename(url)\n        compressed_filepath = os.path.join(tmp_dir, compressed_filename)\n        if url.startswith(\"http\"):\n          generator_utils.maybe_download(tmp_dir, compressed_filename, url)\n\n        if dataset[1][0] == \"tmx\":\n          cleaning_requested = \"tmx\" in datatypes_to_clean\n          tmx_filename = os.path.join(tmp_dir, dataset[1][1])\n          if tmx_filename.endswith(\".gz\"):\n            with gzip.open(tmx_filename, \"rb\") as tmx_file:\n              _tmx_to_source_target(tmx_file, lang1_resfile, lang2_resfile,\n                                    do_cleaning=cleaning_requested)\n          else:\n            with tf.gfile.Open(tmx_filename) as tmx_file:\n              _tmx_to_source_target(tmx_file, lang1_resfile, lang2_resfile,\n                                    do_cleaning=cleaning_requested)\n\n        elif dataset[1][0] == \"tsv\":\n          _, src_column, trg_column, glob_pattern = dataset[1]\n          filenames = tf.gfile.Glob(os.path.join(tmp_dir, glob_pattern))\n          if not filenames:\n            # Capture *.tgz and *.tar.gz too.\n            mode = \"r:gz\" if compressed_filepath.endswith(\"gz\") else \"r\"\n            with tarfile.open(compressed_filepath, mode) as corpus_tar:\n              corpus_tar.extractall(tmp_dir)\n            filenames = tf.gfile.Glob(os.path.join(tmp_dir, glob_pattern))\n          for tsv_filename in filenames:\n            if tsv_filename.endswith(\".gz\"):\n              new_filename = tsv_filename.strip(\".gz\")\n              generator_utils.gunzip_file(tsv_filename, new_filename)\n              tsv_filename = new_filename\n            with tf.gfile.Open(tsv_filename) as tsv_file:\n              for line in tsv_file:\n                if line and \"\\t\" in line:\n                  parts = line.split(\"\\t\")\n                  source, target = parts[src_column], parts[trg_column]\n                  source, target = source.strip(), target.strip()\n                  clean_pairs = [(source, target)]\n                  if \"tsv\" in datatypes_to_clean:\n                    clean_pairs = cleaner_en_xx.clean_en_xx_pairs(clean_pairs)\n                  for source, target in clean_pairs:\n                    if source and target:\n                      lang1_resfile.write(source)\n                      lang1_resfile.write(\"\\n\")\n                      lang2_resfile.write(target)\n                      lang2_resfile.write(\"\\n\")\n\n        else:\n          lang1_filename, lang2_filename = dataset[1]\n          lang1_filepath = os.path.join(tmp_dir, lang1_filename)\n          lang2_filepath = os.path.join(tmp_dir, lang2_filename)\n          is_sgm = (\n              lang1_filename.endswith(\"sgm\") and lang2_filename.endswith(\"sgm\"))\n\n          if not (tf.gfile.Exists(lang1_filepath) and\n                  tf.gfile.Exists(lang2_filepath)):\n            # For .tar.gz and .tgz files, we read compressed.\n            mode = \"r:gz\" if compressed_filepath.endswith(\"gz\") else \"r\"\n            with tarfile.open(compressed_filepath, mode) as corpus_tar:\n              corpus_tar.extractall(tmp_dir)\n          if lang1_filepath.endswith(\".gz\"):\n            new_filepath = lang1_filepath.strip(\".gz\")\n            generator_utils.gunzip_file(lang1_filepath, new_filepath)\n            lang1_filepath = new_filepath\n          if lang2_filepath.endswith(\".gz\"):\n            new_filepath = lang2_filepath.strip(\".gz\")\n            generator_utils.gunzip_file(lang2_filepath, new_filepath)\n            lang2_filepath = new_filepath\n\n          for example in text_problems.text2text_txt_iterator(\n              lang1_filepath, lang2_filepath):\n            line1res = _preprocess_sgm(example[\"inputs\"], is_sgm)\n            line2res = _preprocess_sgm(example[\"targets\"], is_sgm)\n            clean_pairs = [(line1res, line2res)]\n            if \"txt\" in datatypes_to_clean:\n              clean_pairs = cleaner_en_xx.clean_en_xx_pairs(clean_pairs)\n            for line1res, line2res in clean_pairs:\n              if line1res and line2res:\n                lang1_resfile.write(line1res)\n                lang1_resfile.write(\"\\n\")\n                lang2_resfile.write(line2res)\n                lang2_resfile.write(\"\\n\")\n\n  return filename", "response": "Concatenates all datasets and saves to filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_or_create_vocab(self, data_dir, tmp_dir, force_get=False):\n    # We assume that vocab file is present in data_dir directory where the\n    # data generated will be stored.\n    vocab_filepath = os.path.join(data_dir, self.vocab_filename)\n    encoder = text_encoder.SubwordTextEncoder(vocab_filepath)\n    return encoder", "response": "Get or create the vocab for distill problems."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting hparams overrides from unparsed command - line arguments.", "response": "def set_hparams_from_args(args):\n  \"\"\"Set hparams overrides from unparsed args list.\"\"\"\n  if not args:\n    return\n\n  hp_prefix = \"--hp_\"\n  tf.logging.info(\"Found unparsed command-line arguments. Checking if any \"\n                  \"start with %s and interpreting those as hparams \"\n                  \"settings.\", hp_prefix)\n\n  pairs = []\n  i = 0\n  while i < len(args):\n    arg = args[i]\n    if arg.startswith(hp_prefix):\n      pairs.append((arg[len(hp_prefix):], args[i+1]))\n      i += 2\n    else:\n      tf.logging.warn(\"Found unknown flag: %s\", arg)\n      i += 1\n\n  as_hparams = \",\".join([\"%s=%s\" % (key, val) for key, val in pairs])\n  if FLAGS.hparams:\n    as_hparams = \",\" + as_hparams\n  FLAGS.hparams += as_hparams"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_run_config(hp, output_dir=None):\n  save_ckpt_steps = max(FLAGS.iterations_per_loop, FLAGS.local_eval_frequency)\n  save_ckpt_secs = FLAGS.save_checkpoints_secs or None\n  if save_ckpt_secs:\n    save_ckpt_steps = None\n  assert FLAGS.output_dir or FLAGS.checkpoint_path\n  tpu_config_extra_kwargs = {}\n  if FLAGS.tpu_job_name is not None:\n    tpu_config_extra_kwargs[\"tpu_job_name\"] = FLAGS.tpu_job_name\n\n  if getattr(hp, \"mtf_mode\", False):\n    save_ckpt_steps = None  # Disable the default saver\n    save_ckpt_secs = None  # Disable the default saver\n    tpu_config_extra_kwargs = {\n        \"num_cores_per_replica\": 1,\n        \"per_host_input_for_training\": tpu_config.InputPipelineConfig.BROADCAST,\n    }\n\n  # the various custom getters we have written do not play well together yet.\n  # TODO(noam): ask rsepassi for help here.\n  daisy_chain_variables = (\n      hp.daisy_chain_variables and\n      hp.activation_dtype == \"float32\" and\n      hp.weight_dtype == \"float32\")\n  return trainer_lib.create_run_config(\n      model_name=FLAGS.model,\n      model_dir=output_dir or os.path.expanduser(FLAGS.output_dir),\n      master=FLAGS.master,\n      iterations_per_loop=FLAGS.iterations_per_loop,\n      num_shards=FLAGS.tpu_num_shards,\n      log_device_placement=FLAGS.log_device_placement,\n      save_checkpoints_steps=save_ckpt_steps,\n      save_checkpoints_secs=save_ckpt_secs,\n      keep_checkpoint_max=FLAGS.keep_checkpoint_max,\n      keep_checkpoint_every_n_hours=FLAGS.keep_checkpoint_every_n_hours,\n      num_gpus=FLAGS.worker_gpu,\n      gpu_order=FLAGS.gpu_order,\n      num_async_replicas=FLAGS.worker_replicas,\n      gpu_mem_fraction=FLAGS.worker_gpu_memory_fraction,\n      enable_graph_rewriter=FLAGS.enable_graph_rewriter,\n      use_tpu=FLAGS.use_tpu,\n      use_tpu_estimator=FLAGS.use_tpu_estimator,\n      xla_jit_level=FLAGS.xla_jit_level,\n      schedule=FLAGS.schedule,\n      no_data_parallelism=hp.no_data_parallelism,\n      optionally_use_dist_strat=FLAGS.optionally_use_dist_strat,\n      daisy_chain_variables=daisy_chain_variables,\n      ps_replicas=FLAGS.ps_replicas,\n      ps_job=FLAGS.ps_job,\n      ps_gpu=FLAGS.ps_gpu,\n      sync=FLAGS.sync,\n      worker_id=FLAGS.worker_id,\n      worker_job=FLAGS.worker_job,\n      random_seed=FLAGS.random_seed,\n      tpu_infeed_sleep_secs=FLAGS.tpu_infeed_sleep_secs,\n      inter_op_parallelism_threads=FLAGS.inter_op_parallelism_threads,\n      log_step_count_steps=FLAGS.log_step_count_steps,\n      intra_op_parallelism_threads=FLAGS.intra_op_parallelism_threads,\n      tpu_config_extra_kwargs=tpu_config_extra_kwargs,\n      cloud_tpu_name=FLAGS.cloud_tpu_name)", "response": "Create a run config."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_metadata(hparams):\n  output_dir = os.path.expanduser(FLAGS.output_dir)\n  if not tf.gfile.Exists(output_dir):\n    tf.gfile.MakeDirs(output_dir)\n\n  # Save FLAGS in txt file\n  if hasattr(FLAGS, \"flags_into_string\"):\n    flags_str = FLAGS.flags_into_string()\n    t2t_flags_str = \"\\n\".join([\n        \"--%s=%s\" % (f.name, f.value)\n        for f in FLAGS.flags_by_module_dict()[\"tensor2tensor.utils.flags\"]\n    ])\n  else:\n    flags_dict = FLAGS.__dict__[\"__flags\"]\n    flags_str = \"\\n\".join(\n        [\"--%s=%s\" % (name, str(f)) for (name, f) in flags_dict.items()])\n    t2t_flags_str = None\n\n  flags_txt = os.path.join(output_dir, \"flags.txt\")\n  with tf.gfile.Open(flags_txt, \"w\") as f:\n    f.write(flags_str)\n\n  if t2t_flags_str:\n    t2t_flags_txt = os.path.join(output_dir, \"flags_t2t.txt\")\n    with tf.gfile.Open(t2t_flags_txt, \"w\") as f:\n      f.write(t2t_flags_str)\n\n  # Save hparams as hparams.json\n  new_hparams = hparams_lib.copy_hparams(hparams)\n  # Modality class is not JSON serializable so remove.\n  new_hparams.del_hparam(\"modality\")\n\n  hparams_fname = os.path.join(output_dir, \"hparams.json\")\n  with tf.gfile.Open(hparams_fname, \"w\") as f:\n    f.write(new_hparams.to_json(indent=0, sort_keys=True))", "response": "Saves FLAGS and hparams to output_dir."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a plaintext representation of HTML content.", "response": "def get_text_from_html(html):\n  \"\"\"Returns a plaintext representation of HTML content.\"\"\"\n\n  try:\n    soup = bs4.BeautifulSoup(html, \"html.parser\")\n  except:  # pylint: disable=bare-except\n    # Some docs don't parse\n    return \"\"\n  # Remove script and style tags\n  for s in soup([\"script\", \"style\"]):\n    s.decompose()\n  return \"\\n\".join([s for s in _soup_strings(soup)])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nyield text strings in soup.", "response": "def _soup_strings(soup):\n  \"\"\"Return text strings in soup.\"\"\"\n  paragraph_tags = set([\n      \"caption\", \"details\", \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"li\", \"p\", \"td\",\n      \"div\", \"span\"\n  ])\n\n  skip_children = None\n  for descendant in soup.descendants:\n    # If we've treated a tag as a contiguous paragraph, don't re-emit the\n    # children (see below).\n    if skip_children is not None:\n      try:\n        in_skip = descendant in skip_children  # pylint: disable=unsupported-membership-test\n      except RecursionError:  # pylint: disable=undefined-variable\n        # Possible for this check to hit a nasty infinite recursion because of\n        # BeautifulSoup __eq__ checks.\n        in_skip = True\n      if in_skip:\n        continue\n      else:\n        skip_children = None\n\n    # Treat some tags as contiguous paragraphs, regardless of other tags nested\n    # inside (like <a> or <b>).\n    if isinstance(descendant, bs4.Tag):\n      if descendant.name in paragraph_tags:\n        if descendant.find_all(paragraph_tags):\n          # If there are nested paragraph tags, don't treat it as a single\n          # contiguous tag.\n          continue\n        skip_children = list(descendant.descendants)\n        text = \" \".join(descendant.get_text(\" \", strip=True).split())\n        if text:\n          yield text\n        continue\n\n    if (isinstance(descendant, bs4.Comment) or\n        not isinstance(descendant, bs4.NavigableString)):\n      continue\n\n    text = \" \".join(descendant.strip().split())\n    if text:\n      yield text"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbest config for 2. 90 bits / dim on CIFAR10 using cross entropy.", "response": "def imagetransformer_cifar10_base():\n  \"\"\"Best config for 2.90 bits/dim on CIFAR10 using cross entropy.\"\"\"\n  hparams = image_transformer_base()\n  hparams.batch_size = 4\n  hparams.num_heads = 4\n  hparams.num_decoder_layers = 12\n  hparams.block_length = 256\n  hparams.hidden_size = 512\n  hparams.filter_size = 2048\n  hparams.learning_rate = 0.5\n  hparams.learning_rate_warmup_steps = 4000\n  hparams.layer_preprocess_sequence = \"none\"\n  hparams.layer_postprocess_sequence = \"dan\"\n  hparams.layer_prepostprocess_dropout = 0.3\n  hparams.unconditional = True\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef imagetransformer_cifar10_base_dmol():\n  hparams = image_transformer_base()\n  hparams.likelihood = cia.DistributionType.DMOL\n  hparams.num_channels = 1\n  hparams.bottom[\"targets\"] = modalities.image_channel_compress_targets_bottom\n  hparams.top[\"targets\"] = modalities.identity_top\n  hparams.num_heads = 8\n  hparams.batch_size = 8\n  hparams.sampling_method = \"random\"\n  hparams.layer_preprocess_sequence = \"n\"\n  hparams.layer_postprocess_sequence = \"da\"\n  hparams.summarize_grads = True\n  hparams.hidden_size = 256\n  hparams.filter_size = 512\n  hparams.attention_key_channels = 512\n  hparams.attention_value_channels = 512\n  hparams.num_decoder_layers = 12\n  hparams.layer_prepostprocess_dropout = 0.1\n  hparams.learning_rate = 0.1\n  hparams.layer_preprocess_sequence = \"none\"\n  hparams.layer_postprocess_sequence = \"dan\"\n  hparams.pos = \"emb\"\n  hparams.unconditional = True\n  return hparams", "response": "Best config for 2. 90 bits / dim on CIFAR10 using DMOL."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef imagetransformerpp_base_8l_8h_big_cond_dr03_dan():\n  hparams = imagetransformerpp_sep_channels_8l_8h()\n  hparams.hidden_size = 512\n  hparams.num_heads = 8\n  hparams.filter_size = 2048\n  hparams.batch_size = 4\n  hparams.max_length = 3075\n  hparams.layer_prepostprocess_dropout = 0.3\n  hparams.layer_preprocess_sequence = \"none\"\n  hparams.layer_postprocess_sequence = \"dan\"\n  hparams.summarize_grads = True\n  hparams.learning_rate = 0.01\n  return hparams", "response": "big 1d model for conditional image generation. 2. 99 on cifar10."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets to 2. 92 in just under 4 days on 8 p100s.", "response": "def imagetransformerpp_base_14l_8h_big_uncond_dr03_dan_p():\n  \"\"\"Gets to 2.92 in just under 4 days on 8 p100s.\"\"\"\n  hparams = imagetransformerpp_base_12l_8h_big_uncond_dr03_dan_l()\n  hparams.num_decoder_layers = 14\n  hparams.batch_size = 8\n  hparams.layer_prepostprocess_dropout = 0.2\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef imagetransformer_base_12l_8h_big():\n  hparams = imagetransformer_sep_channels_8l_8h()\n  hparams.filter_size = 1024\n  hparams.num_decoder_layers = 12\n  hparams.batch_size = 1\n  hparams.hidden_size = 512\n  hparams.learning_rate_warmup_steps = 4000\n  hparams.sampling_method = \"random\"\n  hparams.beam_size = 1\n  hparams.block_width = 256\n  return hparams", "response": "big 1d model for conditional image generation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef imagetransformer1d_base_8l_64by64():\n  hparams = image_transformer_base()\n  hparams.num_heads = 8\n  hparams.hidden_size = 512\n  hparams.filter_size = 2048\n  hparams.num_decoder_layers = 8\n  hparams.batch_size = 1\n  hparams.block_length = 512\n  hparams.block_width = 768\n  hparams.layer_prepostprocess_dropout = 0.1\n  hparams.max_length = 14000\n  hparams.unconditional = int(False)\n  return hparams", "response": "Hparams fo 12 layer big 1d model for imagenet 64x64."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef imagetransformer_base_10l_16h_big_uncond_dr01_imgnet():\n  hparams = imagetransformer_base_14l_8h_big_dr01()\n  # num_hidden_layers\n  hparams.num_decoder_layers = 10\n  hparams.num_heads = 16\n  hparams.hidden_size = 1024\n  hparams.filter_size = 4096\n  hparams.batch_size = 1\n  hparams.layer_prepostprocess_dropout = 0.1\n  return hparams", "response": "big 1d model for conditional image generation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef imagetransformer_bas8l_8h_big_uncond_dr03_imgnet():\n  hparams = imagetransformer_base_14l_8h_big_dr01()\n  # num_hidden_layers\n  hparams.num_decoder_layers = 8\n  hparams.num_heads = 8\n  hparams.hidden_size = 512\n  hparams.filter_size = 2048\n  hparams.layer_prepostprocess_dropout = 0.3\n  return hparams", "response": "big 1d model for conditional image generation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset of hyperparameters for a very small imagetransformer with MoE.", "response": "def imagetransformer_moe_tiny():\n  \"\"\"Set of hyperparameters for a very small imagetransformer with MoE.\"\"\"\n  hparams = imagetransformer_tiny()\n  hparams.hidden_size = 64\n  hparams.batch_size = 1\n  hparams.num_hidden_layers = 3\n  hparams.dec_attention_type = cia.AttentionType.MOE_LOCAL_1D\n  hparams.add_hparam(\"moe_layers_decoder\", \"1\")  # Which layer is MoE.\n  hparams.moe_hidden_sizes = \"1024\"  # Hidden layer sizes (comma-separated).\n  hparams.moe_num_experts = 16  # Number of experts in each MoE layer.\n  hparams.moe_k = 2  # How many experts to use per batch element (try 2 or 4).\n  hparams.moe_loss_coef = 1e-2  # MoE loss coefficient (1e-2 is usually ok).\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef imagetransformer_b10l_4h_big_uncond_dr03_lr025_tpu():\n  hparams = imagetransformer_bas8l_8h_big_uncond_dr03_imgnet()\n  update_hparams_for_tpu(hparams)\n  hparams.batch_size = 4\n  hparams.num_heads = 4   # heads are expensive on tpu\n  hparams.num_decoder_layers = 10\n  hparams.learning_rate = 0.25\n  hparams.learning_rate_warmup_steps = 8000\n  hparams.layer_preprocess_sequence = \"none\"\n  hparams.layer_postprocess_sequence = \"dan\"\n  # hparams.unconditional = True\n  return hparams", "response": "TPU related small model."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef imagetransformer_b12l_4h_b256_uncond_dr03_tpu():\n  hparams = imagetransformer_bas8l_8h_big_uncond_dr03_imgnet()\n  update_hparams_for_tpu(hparams)\n  hparams.batch_size = 4\n  hparams.num_heads = 4   # heads are expensive on tpu\n  hparams.num_decoder_layers = 12\n  hparams.block_length = 256\n  hparams.hidden_size = 512\n  hparams.filter_size = 2048\n  hparams.learning_rate = 0.5\n  hparams.learning_rate_warmup_steps = 4000\n  hparams.layer_preprocess_sequence = \"none\"\n  hparams.layer_postprocess_sequence = \"dan\"\n  hparams.layer_prepostprocess_dropout = 0.3\n  hparams.unconditional = True\n  return hparams", "response": "Hparams for tpu - undirected dr03."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwork very well on 4x4.", "response": "def imagetransformer_b12l_4h_b256_uncond_dr03_rel_tpu():\n  \"\"\"works very well on 4x4.\"\"\"\n  hparams = imagetransformer_b12l_4h_b256_uncond_dr03_tpu()\n  hparams.shared_rel = True\n  hparams.dec_attention_type = cia.AttentionType.RELATIVE_LOCAL_1D\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nranging of hyperparameters for vizier.", "response": "def imagetransformer_cifar_tpu_range(rhp):\n  \"\"\"Range of hyperparameters for vizier.\"\"\"\n  # After starting from base, set intervals for some parameters.\n  rhp.set_float(\"learning_rate\", 0.01, 1.0, scale=rhp.LOG_SCALE)\n  rhp.set_discrete(\"num_decoder_layers\", [8, 10, 12, 14, 16])\n  rhp.set_discrete(\"hidden_size\", [256, 512, 1024])\n  rhp.set_discrete(\"block_length\", [128, 256, 512])\n  rhp.set_categorical(\"dec_attention_type\", [\n      cia.AttentionType.RELATIVE_LOCAL_1D, cia.AttentionType.LOCAL_1D])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef imagetransformer_b12l_8h_b256_uncond_dr03_tpu():\n  hparams = imagetransformer_bas8l_8h_big_uncond_dr03_imgnet()\n  update_hparams_for_tpu(hparams)\n  hparams.batch_size = 2\n  hparams.num_heads = 8   # heads are expensive on tpu\n  hparams.num_decoder_layers = 12\n  hparams.block_length = 256\n  hparams.hidden_size = 512\n  hparams.filter_size = 2048\n  hparams.layer_preprocess_sequence = \"none\"\n  hparams.layer_postprocess_sequence = \"dan\"\n  hparams.layer_prepostprocess_dropout = 0.3\n  return hparams", "response": "TPU related 12 layer 8 heads model."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef imagetransformer_b10l_4h_big_uncond_dr01_tpu():\n  hparams = imagetransformer_b12l_4h_big_uncond_dr03_tpu()\n  # num_hidden_layers\n  hparams.num_decoder_layers = 10\n  hparams.num_heads = 4\n  hparams.hidden_size = 1024\n  hparams.filter_size = 4096\n  hparams.batch_size = 1\n  hparams.layer_prepostprocess_dropout = 0.1\n  return hparams", "response": "big 1d model for conditional image generation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef training_loop(self):\n    if not self.restarting:\n      self._write_counters(self._local_step_at_start, self._global_step)\n\n    tf.logging.info(\n        \"Training %s up to %d, %d to go\", self.model_mode,\n        self.target_local_step, self.steps_to_go\n    )\n\n    yield\n\n    self._write_counters(self.target_local_step, -1)", "response": "Context manager wrapping the training loop."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread words from a file.", "response": "def _read_words(filename):\n  \"\"\"Reads words from a file.\"\"\"\n  with tf.gfile.GFile(filename, \"r\") as f:\n    if sys.version_info[0] >= 3:\n      return f.read().replace(\"\\n\", \" %s \" % EOS).split()\n    else:\n      return f.read().decode(\"utf-8\").replace(\"\\n\", \" %s \" % EOS).split()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _build_vocab(filename, vocab_path, vocab_size):\n  data = _read_words(filename)\n  counter = collections.Counter(data)\n  count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n  words, _ = list(zip(*count_pairs))\n  words = words[:vocab_size]\n  with open(vocab_path, \"w\") as f:\n    f.write(\"\\n\".join(words))", "response": "Reads a file to build a vocabulary of vocab_size most common words."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_token_encoder(vocab_dir, vocab_name, filename):\n  vocab_path = os.path.join(vocab_dir, vocab_name)\n  if not tf.gfile.Exists(vocab_path):\n    _build_vocab(filename, vocab_path, 10000)\n  return text_encoder.TokenTextEncoder(vocab_path)", "response": "Reads from file and returns a TokenTextEncoder for the vocabulary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _maybe_download_corpus(tmp_dir, vocab_type):\n  filename = os.path.basename(PTB_URL)\n  compressed_filepath = generator_utils.maybe_download(\n      tmp_dir, filename, PTB_URL)\n  ptb_files = []\n  ptb_char_files = []\n\n  with tarfile.open(compressed_filepath, \"r:gz\") as tgz:\n    files = []\n    # Selecting only relevant files.\n    for m in tgz.getmembers():\n      if \"ptb\" in m.name and \".txt\" in m.name:\n        if \"char\" in m.name:\n          ptb_char_files += [m.name]\n        else:\n          ptb_files += [m.name]\n        files += [m]\n\n    tgz.extractall(tmp_dir, members=files)\n\n  if vocab_type == text_problems.VocabType.CHARACTER:\n    return ptb_char_files\n  else:\n    return ptb_files", "response": "Download and unpack the corpus."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resize(att_mat, max_length=None):\n  for i, att in enumerate(att_mat):\n    # Add extra batch dim for viz code to work.\n    if att.ndim == 3:\n      att = np.expand_dims(att, axis=0)\n    if max_length is not None:\n      # Sum across different attention values for each token.\n      att = att[:, :, :max_length, :max_length]\n      row_sums = np.sum(att, axis=2)\n      # Normalize\n      att /= row_sums[:, :, np.newaxis]\n    att_mat[i] = att\n  return att_mat", "response": "Normalize attention matrices and reshape as necessary."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute representation of the attention ready for the d3 visualization.", "response": "def _get_attention(inp_text, out_text, enc_atts, dec_atts, encdec_atts):\n  \"\"\"Compute representation of the attention ready for the d3 visualization.\n\n  Args:\n    inp_text: list of strings, words to be displayed on the left of the vis\n    out_text: list of strings, words to be displayed on the right of the vis\n    enc_atts: numpy array, encoder self-attentions\n        [num_layers, batch_size, num_heads, enc_length, enc_length]\n    dec_atts: numpy array, decoder self-attentions\n        [num_layers, batch_size, num_heads, dec_length, dec_length]\n    encdec_atts: numpy array, encoder-decoder attentions\n        [num_layers, batch_size, num_heads, dec_length, enc_length]\n\n  Returns:\n    Dictionary of attention representations with the structure:\n    {\n      'all': Representations for showing all attentions at the same time.\n      'inp_inp': Representations for showing encoder self-attentions\n      'inp_out': Representations for showing encoder-decoder attentions\n      'out_out': Representations for showing decoder self-attentions\n    }\n    and each sub-dictionary has structure:\n    {\n      'att': list of inter attentions matrices, one for each attention head\n      'top_text': list of strings, words to be displayed on the left of the vis\n      'bot_text': list of strings, words to be displayed on the right of the vis\n    }\n  \"\"\"\n  def get_full_attention(layer):\n    \"\"\"Get the full input+output - input+output attentions.\"\"\"\n    enc_att = enc_atts[layer][0]\n    dec_att = dec_atts[layer][0]\n    encdec_att = encdec_atts[layer][0]\n    enc_att = np.transpose(enc_att, [0, 2, 1])\n    dec_att = np.transpose(dec_att, [0, 2, 1])\n    encdec_att = np.transpose(encdec_att, [0, 2, 1])\n    # [heads, query_length, memory_length]\n    enc_length = enc_att.shape[1]\n    dec_length = dec_att.shape[1]\n    num_heads = enc_att.shape[0]\n    first = np.concatenate([enc_att, encdec_att], axis=2)\n    second = np.concatenate(\n        [np.zeros((num_heads, dec_length, enc_length)), dec_att], axis=2)\n    full_att = np.concatenate([first, second], axis=1)\n    return [ha.T.tolist() for ha in full_att]\n\n  def get_inp_inp_attention(layer):\n    att = np.transpose(enc_atts[layer][0], (0, 2, 1))\n    return [ha.T.tolist() for ha in att]\n\n  def get_out_inp_attention(layer):\n    att = np.transpose(encdec_atts[layer][0], (0, 2, 1))\n    return [ha.T.tolist() for ha in att]\n\n  def get_out_out_attention(layer):\n    att = np.transpose(dec_atts[layer][0], (0, 2, 1))\n    return [ha.T.tolist() for ha in att]\n\n  def get_attentions(get_attention_fn):\n    num_layers = len(enc_atts)\n    return [get_attention_fn(i) for i in range(num_layers)]\n\n  attentions = {\n      'all': {\n          'att': get_attentions(get_full_attention),\n          'top_text': inp_text + out_text,\n          'bot_text': inp_text + out_text,\n      },\n      'inp_inp': {\n          'att': get_attentions(get_inp_inp_attention),\n          'top_text': inp_text,\n          'bot_text': inp_text,\n      },\n      'inp_out': {\n          'att': get_attentions(get_out_inp_attention),\n          'top_text': inp_text,\n          'bot_text': out_text,\n      },\n      'out_out': {\n          'att': get_attentions(get_out_out_attention),\n          'top_text': out_text,\n          'bot_text': out_text,\n      },\n  }\n\n  return attentions"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decode(tokens):\n  token_is_alnum = [t[0] in _ALPHANUMERIC_CHAR_SET for t in tokens]\n  ret = []\n  for i, token in enumerate(tokens):\n    if i > 0 and token_is_alnum[i - 1] and token_is_alnum[i]:\n      ret.append(u\" \")\n    ret.append(token)\n  return \"\".join(ret)", "response": "Decode a list of tokens to a unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _read_filepattern(filepattern, max_lines=None, split_on_newlines=True):\n  filenames = sorted(tf.gfile.Glob(filepattern))\n  lines_read = 0\n  for filename in filenames:\n    with tf.gfile.Open(filename) as f:\n      if split_on_newlines:\n        for line in f:\n          yield line.strip()\n          lines_read += 1\n          if max_lines and lines_read >= max_lines:\n            return\n\n      else:\n        if max_lines:\n          doc = []\n          for line in f:\n            doc.append(line)\n            lines_read += 1\n            if max_lines and lines_read >= max_lines:\n              yield \"\".join(doc)\n              return\n          yield \"\".join(doc)\n\n        else:\n          yield f.read()", "response": "Reads files matching a wildcard pattern yielding the contents."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef corpus_token_counts(\n    text_filepattern, corpus_max_lines, split_on_newlines=True):\n  \"\"\"Read the corpus and compute a dictionary of token counts.\n\n  Args:\n    text_filepattern: A pattern matching one or more files.\n    corpus_max_lines: An integer; maximum total lines to read.\n    split_on_newlines: A boolean. If true, then split files by lines and strip\n        leading and trailing whitespace from each line. Otherwise, treat each\n        file as a single string.\n\n  Returns:\n    a dictionary mapping token to count.\n  \"\"\"\n  counts = collections.Counter()\n  for doc in _read_filepattern(\n      text_filepattern,\n      max_lines=corpus_max_lines,\n      split_on_newlines=split_on_newlines):\n    counts.update(encode(_native_to_unicode(doc)))\n\n  mlperf_log.transformer_print(\n      key=mlperf_log.PREPROC_VOCAB_SIZE, value=len(counts))\n  return counts", "response": "Read the corpus and compute a dictionary of token counts."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a two - column CSV file and returns a dictionary of token counts.", "response": "def vocab_token_counts(text_filepattern, max_lines):\n  \"\"\"Read a vocab file and return a dictionary of token counts.\n\n  Reads a two-column CSV file of tokens and their frequency in a dataset. The\n  tokens are presumed to be generated by encode() or the equivalent.\n\n  Args:\n    text_filepattern: A pattern matching one or more files.\n    max_lines: An integer; maximum total lines to read.\n\n  Returns:\n    a dictionary mapping token to count.\n  \"\"\"\n  ret = {}\n  for i, line in enumerate(\n      _read_filepattern(text_filepattern, max_lines=max_lines)):\n    if \",\" not in line:\n      tf.logging.warning(\"Malformed vocab line #%d '%s'\", i, line)\n      continue\n\n    token, count = line.rsplit(\",\", 1)\n    ret[_native_to_unicode(token)] = int(count)\n\n  return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake a tf. train. Example for the problem.", "response": "def _make_example(input_ids, problem, input_feature_name=\"inputs\"):\n  \"\"\"Make a tf.train.Example for the problem.\n\n  features[input_feature_name] = input_ids\n\n  Also fills in any other required features with dummy values.\n\n  Args:\n    input_ids: list<int>.\n    problem: Problem.\n    input_feature_name: name of feature for input_ids.\n\n  Returns:\n    tf.train.Example\n  \"\"\"\n  features = {\n      input_feature_name:\n          tf.train.Feature(int64_list=tf.train.Int64List(value=input_ids))\n  }\n\n  # Fill in dummy values for any other required features that presumably\n  # will not actually be used for prediction.\n  data_fields, _ = problem.example_reading_spec()\n  for fname, ftype in data_fields.items():\n    if fname == input_feature_name:\n      continue\n    if not isinstance(ftype, tf.FixedLenFeature):\n      # Only FixedLenFeatures are required\n      continue\n    if ftype.default_value is not None:\n      # If there's a default value, no need to fill it in\n      continue\n    num_elements = functools.reduce(lambda acc, el: acc * el, ftype.shape, 1)\n    if ftype.dtype in [tf.int32, tf.int64]:\n      value = tf.train.Feature(\n          int64_list=tf.train.Int64List(value=[0] * num_elements))\n    if ftype.dtype in [tf.float32, tf.float64]:\n      value = tf.train.Feature(\n          float_list=tf.train.FloatList(value=[0.] * num_elements))\n    if ftype.dtype == tf.bytes:\n      value = tf.train.Feature(\n          bytes_list=tf.train.BytesList(value=[\"\"] * num_elements))\n    tf.logging.info(\"Adding dummy value for feature %s as it is required by \"\n                    \"the Problem.\", fname)\n    features[fname] = value\n  return tf.train.Example(features=tf.train.Features(feature=features))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_grpc_request_fn(servable_name, server, timeout_secs):\n  stub = _create_stub(server)\n\n  def _make_grpc_request(examples):\n    \"\"\"Builds and sends request to TensorFlow model server.\"\"\"\n    request = predict_pb2.PredictRequest()\n    request.model_spec.name = servable_name\n    request.inputs[\"input\"].CopyFrom(\n        tf.make_tensor_proto(\n            [ex.SerializeToString() for ex in examples], shape=[len(examples)]))\n    response = stub.Predict(request, timeout_secs)\n    outputs = tf.make_ndarray(response.outputs[\"outputs\"])\n    scores = tf.make_ndarray(response.outputs[\"scores\"])\n    assert len(outputs) == len(scores)\n    return [{  # pylint: disable=g-complex-comprehension\n        \"outputs\": output,\n        \"scores\": score\n    } for output, score in zip(outputs, scores)]\n\n  return _make_grpc_request", "response": "Wraps function to make grpc requests with runtime args."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_cloud_mlengine_request_fn(credentials, model_name, version):\n\n  def _make_cloud_mlengine_request(examples):\n    \"\"\"Builds and sends requests to Cloud ML Engine.\"\"\"\n    api = discovery.build(\"ml\", \"v1\", credentials=credentials)\n    parent = \"projects/%s/models/%s/versions/%s\" % (cloud.default_project(),\n                                                    model_name, version)\n    input_data = {\n        \"instances\": [{  # pylint: disable=g-complex-comprehension\n            \"input\": {\n                \"b64\": base64.b64encode(ex.SerializeToString())\n            }\n        } for ex in examples]\n    }\n    prediction = api.projects().predict(body=input_data, name=parent).execute()\n    return prediction[\"predictions\"]\n\n  return _make_cloud_mlengine_request", "response": "Wraps function to make CloudML Engine requests with runtime args."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef predict(inputs_list, problem, request_fn):\n  assert isinstance(inputs_list, list)\n  fname = \"inputs\" if problem.has_inputs else \"targets\"\n  input_encoder = problem.feature_info[fname].encoder\n  input_ids_list = [\n      _encode(inputs, input_encoder, add_eos=problem.has_inputs)\n      for inputs in inputs_list\n  ]\n  examples = [_make_example(input_ids, problem, fname)\n              for input_ids in input_ids_list]\n  predictions = request_fn(examples)\n  output_decoder = problem.feature_info[\"targets\"].encoder\n  outputs = [\n      (_decode(prediction[\"outputs\"], output_decoder),\n       prediction[\"scores\"])\n      for prediction in predictions\n  ]\n  return outputs", "response": "Encodes inputs makes request to deployed TF model and decodes outputs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tabbed_parsing_token_generator(data_dir, tmp_dir, train, prefix,\n                                   source_vocab_size, target_vocab_size):\n  \"\"\"Generate source and target data from a single file.\"\"\"\n  filename = \"parsing_{0}.pairs\".format(\"train\" if train else \"dev\")\n  source_vocab = generator_utils.get_or_generate_tabbed_vocab(\n      data_dir, tmp_dir, filename, 0,\n      prefix + \"_source.tokens.vocab.%d\" % source_vocab_size, source_vocab_size)\n  target_vocab = generator_utils.get_or_generate_tabbed_vocab(\n      data_dir, tmp_dir, filename, 1,\n      prefix + \"_target.tokens.vocab.%d\" % target_vocab_size, target_vocab_size)\n  pair_filepath = os.path.join(tmp_dir, filename)\n  return text_problems.text2text_generate_encoded(\n      text_problems.text2text_txt_tab_iterator(pair_filepath), source_vocab,\n      target_vocab)", "response": "Generate source and target data from a single file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate source and target data from a single file.", "response": "def tabbed_parsing_character_generator(tmp_dir, train):\n  \"\"\"Generate source and target data from a single file.\"\"\"\n  character_vocab = text_encoder.ByteTextEncoder()\n  filename = \"parsing_{0}.pairs\".format(\"train\" if train else \"dev\")\n  pair_filepath = os.path.join(tmp_dir, filename)\n  return text_problems.text2text_generate_encoded(\n      text_problems.text2text_txt_tab_iterator(pair_filepath), character_vocab)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmean of the inputs but counting only those where targets == mask_id.", "response": "def masked_mean(inputs, targets, mask_id=None):\n  \"\"\"Mean of the inputs but counting only those where targets != mask_id.\"\"\"\n  inputs = [x.astype(np.float32) for x in inputs]\n  # We assume all elements in the list contribute equally.\n  # TODO(lukaszkaiser): remove this assumption (e.g., when masks differ).\n  length = len(inputs)\n  if mask_id is None:\n    # TODO(lukaszkaiser): can we just divide the sum by length? XLA optimizes?\n    return sum([np.mean(x) / length for x in inputs])\n  unmask = [1.0 - np.equal(t, mask_id).astype(np.float32) for t in targets]\n  return sum([np.sum(x * m) / (length * np.sum(m))\n              for x, m in zip(inputs, unmask)])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates negative log perplexity.", "response": "def neg_log_perplexity(batch, model_predictions):\n  \"\"\"Calculate negative log perplexity.\"\"\"\n  _, targets = batch\n  model_predictions, targets = _make_list(model_predictions, targets)\n  xent = []\n  for (prediction, target) in zip(model_predictions, targets):\n    hot_target = layers.one_hot(target, prediction.shape[-1])\n    xent.append(np.sum(prediction * hot_target, axis=-1))\n  return masked_mean(xent, targets)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrestoring state from pickle file.", "response": "def restore_state(output_dir):\n  \"\"\"Restore State.\"\"\"\n  params_file = os.path.join(output_dir, \"model.pkl\")\n  if not gfile.exists(params_file):\n    return State(step=None, params=None, history=trax_history.History())\n\n  with gfile.GFile(params_file, \"rb\") as f:\n    (params, step, history) = pickle.load(f)\n  log(\"Model loaded from %s at step %d\" % (params_file, step))\n  logging.debug(\"From loaded model : history = %s\", history)\n  return State(step=step, params=params, history=history)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_state(state, output_dir, keep=False):\n  params_file = os.path.join(output_dir, \"model.pkl\")\n  with gfile.GFile(params_file, \"wb\") as f:\n    pickle.dump((state.params, state.step, state.history), f)\n  if keep:\n    params_file = os.path.join(output_dir, \"model_{}.pkl\".format(state.step))\n    with gfile.GFile(params_file, \"wb\") as f:\n      pickle.dump((state.params, state.step, state.history), f)\n  log(\"Model saved to %s\" % params_file, stdout=False)", "response": "Save state and optionally gin config."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nevaluating on train and eval data and log metrics.", "response": "def evaluate_train_and_eval(step, inputs, predict_fun, eval_steps, rng,\n                            train_sw=None, eval_sw=None, history=None):\n  \"\"\"Evalaute on train and eval data, and log metrics.\"\"\"\n  step_log(step, \"Evaluation\")\n  train_metrics, eval_metrics = [\n      evaluate(  # pylint: disable=g-complex-comprehension\n          itertools.islice(input_stream(), eval_steps),\n          predict_fun,\n          _METRICS,\n          rng)\n      for input_stream in\n      [inputs.train_eval_stream, inputs.eval_stream]]\n  if train_sw:\n    log_metrics(train_metrics, train_sw, \"train\", step, history=history)\n  if eval_sw:\n    log_metrics(eval_metrics, eval_sw, \"eval\", step, history=history)\n  step_log(step, \"Finished evaluation\")\n  return train_metrics, eval_metrics"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nevaluate Args: inputs_stream: iterable of inputs to evaluate on. predict_fun: function from inputs to predictions. params should already be partially applied. metric_funs: dict from metric name to metric function, which takes inputs and predictions and returns a scalar metric value. rng: random number generator. Returns: metrics: dict from metric name to metric value averaged over the number of inputs.", "response": "def evaluate(inputs_stream, predict_fun, metric_funs, rng):\n  \"\"\"Evaluate.\n\n  Args:\n    inputs_stream: iterable of inputs to evaluate on.\n    predict_fun: function from inputs to predictions. params should already be\n      partially applied.\n    metric_funs: dict from metric name to metric function, which takes inputs\n      and predictions and returns a scalar metric value.\n    rng: random number generator.\n\n  Returns:\n    metrics: dict from metric name to metric value averaged over the number of\n      inputs.\n  \"\"\"\n  metrics = collections.defaultdict(float)\n  count = 0\n  for inp in inputs_stream:\n    count += 1\n    rng, subrng = jax_random.split(rng)\n    preds = predict_fun(inp[0], rng=subrng)\n    for m, f in six.iteritems(metric_funs):\n      metrics[m] += f(inp, preds)\n  return {m: v / count for (m, v) in six.iteritems(metrics)}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef log_metrics(metrics, summ_writer, log_prefix, step, history=None):\n  rjust_len = max([len(name) for name in metrics])\n  for name, value in six.iteritems(metrics):\n    step_log(step, \"%s %s | % .8f\" % (\n        log_prefix.ljust(5), name.rjust(rjust_len), value))\n    full_name = \"metrics/\" + name\n    if history:\n      history.append(log_prefix, full_name, step, value)\n    if summ_writer:\n      summ_writer.scalar(full_name, value, step)", "response": "Log metrics to summary writer and history."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a JAX random number generator and set random seed everywhere.", "response": "def get_random_number_generator_and_set_seed(seed=None):\n  \"\"\"Get a JAX random number generator and set random seed everywhere.\"\"\"\n  random.seed(seed)\n  # While python random accepts None as seed and uses time/os seed then,\n  # some other functions expect integers so we create one here.\n  if seed is None:\n    seed = random.randint(0, 2**31 - 1)\n  tf.set_random_seed(seed)\n  numpy.random.seed(seed)\n  return jax_random.get_prng(seed)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _jit_predict_fun(model_predict, num_devices):\n  def predict(x, params=(), rng=None):\n    \"\"\"Predict function jited and parallelized as requested.\"\"\"\n    # On one device, jit and run.\n    if num_devices == 1:\n      return backend.jit(model_predict)(x, params, rng=rng)\n\n    # Multi-devices, pmap and run.\n    @functools.partial(backend.pmap, axis_name=\"batch\")\n    def mapped_predict(x, params, rng):\n      return model_predict(x, params, rng=rng)\n    pred = mapped_predict(\n        reshape_by_device(x, num_devices),\n        params,\n        jax_random.split(rng, num_devices))\n    # Need to reduce the [device, per-device-batch, ...] tensors back to\n    # a [batch, ...] tensor. The tensors may be nested.\n    if not isinstance(x, (list, tuple)):  # Not nested.\n      batch_size = x.shape[0]\n      return np.reshape(pred, [batch_size] + list(pred.shape[2:]))\n    batch_size = x[0].shape[0]\n    return [np.reshape(p, [batch_size] + list(p.shape[2:])) for p in pred]\n\n  return predict", "response": "Use jit on model_predict if required."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _jit_update_fun(predict_fun, loss_fun, optimizer, lr_fun, num_devices):\n  if num_devices == 1:  # TODO(lukaszkaiser): remove branch when not needed.\n    def single_update(i, opt_state, batch, rng):\n      rng, subrng = jax_random.split(rng[0])\n      _, opt_update = optimizer(lr_fun)\n      params = trax_opt.get_params(opt_state)\n      return opt_update(i, backend.grad(loss_fun)(\n          params, batch, predict_fun, rng), opt_state), [subrng]\n    return backend.jit(single_update)\n\n  @functools.partial(backend.pmap, axis_name=\"batch\")\n  def mapped_update(i, opt_state, batch, rng):\n    \"\"\"This is a multi-device version of the update function above.\"\"\"\n    # We assume all tensors have the first dimension = num_devices.\n    rng, subrng = jax_random.split(rng)\n    _, opt_update = optimizer(lr_fun)\n    params = trax_opt.get_params(opt_state)\n    grads = backend.grad(loss_fun)(params, batch, predict_fun, rng)\n    grads = jax.tree_util.tree_map(\n        lambda g: lax.psum(g, \"batch\"), grads)\n    return opt_update(i, grads, opt_state), subrng\n\n  def update(i, opt_state, batch, rng):\n    return mapped_update(jax.replicate(i), opt_state, batch, rng)\n\n  return update", "response": "Get jit - ed update function for loss optimizer learning rate function."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reshape_by_device(x, num_devices):\n  return layers.nested_map(\n      x, lambda x: _reshape_by_device_single(x, num_devices))", "response": "Reshape possibly nested x into a shape [ num_devices... ]."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef train(output_dir,\n          model=gin.REQUIRED,\n          loss_fun=loss,\n          inputs=trax_inputs.inputs,\n          optimizer=trax_opt.adam,\n          lr_schedule=lr.MultifactorSchedule,\n          train_steps=1000,\n          save_steps=None,\n          eval_steps=10,\n          eval_frequency=100,\n          num_devices=None,\n          random_seed=None,\n          run_debug_step=False,\n          save_forward_graph=False):\n  \"\"\"Train the model on the inputs.\n\n  Args:\n    output_dir: Directory where to put the logs and checkpoints.\n    model: The model to train as a callable returning 2 callables, an init_fun\n      and apply_fun.\n    loss_fun: callable with signature: params, trax.inputs.Inputs, model, rng\n      -> loss.\n    inputs: callable returning trax.inputs.Inputs.\n    optimizer: The optimizer as a callable taking a learning_rate callable and\n      returning 2 callables, opt_init and opt_update.\n    lr_schedule: A learning rate schedule as a function that takes history and\n      returns a function from step to learning rate (a float).\n    train_steps: int, total number of training steps.\n    save_steps: list of integers. Keep a model file at each of the supplied save\n      steps.\n    eval_steps: int, num of steps per evaluation. If None or 0, eval disabled.\n    eval_frequency: int, how often to run evaluation (every eval_frequency\n      steps). If None or 0, eval disabled.\n    num_devices: how many devices to use (if None, default, use all available)\n    random_seed: the random seed to use; time/os dependent if None (default).\n    run_debug_step: bool, if True, will run the model and loss without @jit for\n      one step.\n    save_forward_graph: bool, if True, save forward computation graph to file.\n\n  Returns:\n    trax.State\n  \"\"\"\n  if save_steps is None:\n    save_steps = []\n  num_devices = num_devices or jax.lib.xla_bridge.device_count()\n  rng = get_random_number_generator_and_set_seed(random_seed)\n  gfile.makedirs(output_dir)\n  # Create summary writers and history.\n  train_sw = jaxboard.SummaryWriter(os.path.join(output_dir, \"train\"))\n  eval_sw = jaxboard.SummaryWriter(os.path.join(output_dir, \"eval\"))\n\n  inputs = inputs(num_devices)\n\n  # Setup optimizer and model\n  state = restore_state(output_dir)\n  history = state.history\n  lr_fun = lr_schedule(history)\n  opt_init, _ = optimizer(lr_fun)\n  model_train = model(mode=\"train\")\n  model_predict_eval = model(mode=\"eval\")\n\n  # Setup state\n  step = state.step or 0\n  rng, init_rng = jax_random.split(rng)\n  rngs = jax_random.split(rng, num_devices)\n  first_shape = inputs.input_shape[0]\n  # If the inputs are a tuple/list, add [-1] (batch) to each element.\n  if isinstance(first_shape, (list, tuple)):\n    model_input_shape = tuple(\n        [tuple([-1] + list(shape)) for shape in inputs.input_shape])\n  else:  # Otherwise just add [-1] to the input shape.\n    model_input_shape = tuple([-1] + list(inputs.input_shape))\n  params = state.params or model_train.initialize(model_input_shape, init_rng)\n  opt_state = opt_init(params)\n  if num_devices > 1:  # TODO(lukaszkaiser): use everywhere when pmap is stable.\n    opt_state = jax.replicate(opt_state)\n\n  # jit model_predict and update so they're fast\n  jit_model_predict_eval = _jit_predict_fun(model_predict_eval, num_devices)\n  jit_update_fun = _jit_update_fun(\n      model_train, loss_fun, optimizer, lr_fun, num_devices)\n\n  train_stream = inputs.train_stream()\n  epoch_steps = [train_steps]  # Only training if eval_frequency is 0 or None.\n  if eval_frequency and eval_steps > 0:\n    epoch_steps = itertools.chain([1,  # first epoch only 1 step\n                                   eval_frequency - 1],\n                                  itertools.repeat(eval_frequency))\n  step_log(step, \"Starting training using %d devices\" % num_devices)\n\n  # Non-compiled debug step helps find problems in models easier.\n  if run_debug_step:\n    debug_loss = loss_fun(params, next(train_stream), model_train, rng)\n    step_log(step, \"Debug step loss %.8f\" % debug_loss)\n\n  for epoch, epoch_steps in epochs(train_steps, epoch_steps):\n    # Log separator\n    print()\n\n    # Timer\n    start_time = time.time()\n\n    for _ in range(epoch_steps):\n      # Train\n      next_train_batch = next(train_stream)\n      if num_devices > 1:  # TODO(lukaszkaiser): use everywhere when possible.\n        next_train_batch = reshape_by_device(next_train_batch, num_devices)\n      opt_state, rngs = jit_update_fun(step, opt_state, next_train_batch, rngs)\n      step += 1\n\n      if step in save_steps:\n        save_state(State(params=params, step=step, history=history),\n                   output_dir,\n                   keep=True)\n\n      # LR log\n      if step == 1 or step % 10 == 0:\n        train_sw.scalar(\"training/learning rate\",\n                        lr_fun(step), step=step)\n\n    # Timer\n    epoch_time = time.time() - start_time\n    step_log(step, \"Ran %d train steps in %0.2f secs\" %\n             (epoch_steps, epoch_time))\n    if epoch_steps > 1:\n      train_sw.scalar(\"training/steps per second\",\n                      epoch_steps / epoch_time, step=step)\n\n    # Print number of parameters\n    params = trax_opt.get_params(opt_state)\n    if step == 1:\n      sizes = layers.sizes(params)\n      total_size = layers.nested_reduce(sizes, sum)\n      step_log(step, \"Total trainable parameters size: %d\" % total_size)\n\n    # Evaluate\n    evaluate_train_and_eval(\n        step=step,\n        inputs=inputs,\n        predict_fun=functools.partial(jit_model_predict_eval, params=params),\n        eval_steps=eval_steps,\n        rng=rng,\n        train_sw=train_sw,\n        eval_sw=eval_sw,\n        history=history)\n\n    # Save computation graph\n    if save_forward_graph and step == 1:\n      # Dump forward computation graph to file.\n      computation = jax.xla_computation(model_predict_eval)(\n          next_train_batch[0], params=params, rng=rng)\n      with gfile.GFile(os.path.join(output_dir, \"forward_graph.dot\"), \"w\") as f:\n        f.write(computation.GetHloDotGraph())\n\n    # Save state\n    save_state(State(params=params, step=step, history=history), output_dir)\n\n    # Save Gin config\n    # Gin only tracks the used parameters, so we save it after the first epoch.\n    if epoch == 1:\n      save_gin(output_dir, train_sw)\n\n    # Update learning rate with new history\n    old_lr_fun = lr_fun\n    lr_fun = lr_schedule(history)\n    if lr_fun != old_lr_fun:  # For performance, only jit if there is a change.\n      jit_update_fun = _jit_update_fun(\n          model_train, loss_fun, optimizer, lr_fun, num_devices)\n\n    # Flush summary writers\n    train_sw.flush()\n    eval_sw.flush()\n\n  step_log(step, \"Training done\")\n  return State(params=params, step=step, history=history)", "response": "Train the model on the inputs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _compute_fans(shape):\n  if len(shape) < 1:  # Just to avoid errors for constants.\n    fan_in = fan_out = 1\n  elif len(shape) == 1:\n    fan_in = fan_out = shape[0]\n  elif len(shape) == 2:\n    fan_in = shape[0]\n    fan_out = shape[1]\n  else:\n    # Assuming convolution kernels (2D, 3D, or more).\n    # kernel shape: (..., input_depth, depth)\n    receptive_field_size = 1.\n    for dim in shape[:-2]:\n      receptive_field_size *= dim\n    fan_in = shape[-2] * receptive_field_size\n    fan_out = shape[-1] * receptive_field_size\n  if isinstance(fan_in, tf.Dimension):\n    fan_in = fan_in.value\n  if isinstance(fan_out, tf.Dimension):\n    fan_out = fan_out.value\n  return fan_in, fan_out", "response": "Computes the number of input and output units for a weight shape."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(identifier, value=None):\n  if value is None:\n    value = identifier\n  if identifier is None:\n    return None\n  elif isinstance(identifier, dict):\n    try:\n      return deserialize(identifier)\n    except ValueError:\n      return value\n  elif isinstance(identifier, six.string_types):\n    config = {'class_name': str(identifier), 'config': {}}\n    try:\n      return deserialize(config)\n    except ValueError:\n      return value\n  elif callable(identifier):\n    return identifier\n  return value", "response": "Getter for loading from strings ; returns value if can t load."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_time_step(self, **create_time_step_kwargs):\n    ts = time_step.TimeStep.create_time_step(**create_time_step_kwargs)\n    assert isinstance(ts, time_step.TimeStep)\n    self._time_steps.append(ts)", "response": "Creates a time - step and appends it to the list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef change_last_time_step(self, **replace_time_step_kwargs):\n\n    # Pre-conditions: self._time_steps shouldn't be empty.\n    assert self._time_steps\n    self._time_steps[-1] = self._time_steps[-1].replace(\n        **replace_time_step_kwargs)", "response": "Replace the last time - step with the given kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reward(self):\n    raw_rewards, processed_rewards = 0, 0\n    for ts in self.time_steps:\n      # NOTE: raw_reward and processed_reward are None for the first time-step.\n      if ts.raw_reward is not None:\n        raw_rewards += ts.raw_reward\n      if ts.processed_reward is not None:\n        processed_rewards += ts.processed_reward\n    return raw_rewards, processed_rewards", "response": "Returns a tuple of sum of raw and processed rewards."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _complete_trajectory(self, trajectory, index):\n\n    assert isinstance(trajectory, Trajectory)\n\n    # This *should* be the case.\n    assert trajectory.last_time_step.action is None\n\n    # Add to completed trajectories.\n    self._completed_trajectories.append(trajectory)\n\n    # Make a new one to replace it.\n    self._trajectories[index] = Trajectory()", "response": "Completes the given trajectory at the given index."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nresets trajectories at given indices and populates observations.", "response": "def reset(self, indices, observations):\n    \"\"\"Resets trajectories at given indices and populates observations.\n\n    Reset can either be called right at the beginning, when there are no\n    time-steps, or to reset a currently active trajectory.\n\n    If resetting a currently active trajectory then we save it in\n    self._completed_trajectories.\n\n    Args:\n      indices: 1-D np.ndarray stating the indices to reset.\n      observations: np.ndarray of shape (indices len, obs.shape) of observations\n    \"\"\"\n\n    # Pre-conditions: indices, observations are np arrays.\n    #               : indices is one-dimensional.\n    #               : their first dimension (batch) is the same.\n    assert isinstance(indices, np.ndarray)\n    assert len(indices.shape) == 1\n    assert isinstance(observations, np.ndarray)\n    assert indices.shape[0] == observations.shape[0]\n\n    for index, observation in zip(indices, observations):\n      trajectory = self._trajectories[index]\n\n      # Are we starting a new trajectory at the given index?\n      if not trajectory.is_active:\n        # Then create a new time-step here with the given observation.\n        trajectory.add_time_step(observation=observation)\n        # That's all we need to do here.\n        continue\n\n      # If however we are resetting a currently active trajectory then we need\n      # to put that in self._completed_trajectories and make a new trajectory\n      # with the current observation.\n\n      # TODO(afrozm): Should we mark these are done? Or is the done=False and\n      # this being the last time-step in the trajectory good enough to recognize\n      # that this was reset?\n\n      # Mark trajectory as completed and move into completed_trajectories.\n      self._complete_trajectory(trajectory, index)\n\n      # Put the observation in the newly created trajectory.\n      # TODO(afrozm): Add 0 reward.\n      self._trajectories[index].add_time_step(observation=observation)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef complete_all_trajectories(self):\n    for index in range(self.batch_size):\n      trajectory = self._trajectories[index]\n      assert trajectory.is_active\n      self._complete_trajectory(trajectory, index)", "response": "Complete all trajectory in the batch."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef step(self, observations, raw_rewards, processed_rewards, dones, actions):\n    # Pre-conditions\n    assert isinstance(observations, np.ndarray)\n    assert isinstance(raw_rewards, np.ndarray)\n    assert isinstance(processed_rewards, np.ndarray)\n    assert isinstance(dones, np.ndarray)\n    assert isinstance(actions, np.ndarray)\n\n    # We assume that we step in all envs, i.e. not like reset where we can reset\n    # some envs and not others.\n    assert self.batch_size == observations.shape[0]\n    assert self.batch_size == raw_rewards.shape[0]\n    assert self.batch_size == processed_rewards.shape[0]\n    assert self.batch_size == dones.shape[0]\n    assert self.batch_size == actions.shape[0]\n\n    for index in range(self.batch_size):\n      trajectory = self._trajectories[index]\n\n      # NOTE: If the trajectory isn't active, that means it doesn't have any\n      # time-steps in it, but we are in step, so the assumption is that it has\n      # a prior observation from which we are stepping away from.\n\n      # TODO(afrozm): Let's re-visit this if it becomes too restrictive.\n      assert trajectory.is_active\n\n      # To this trajectory's last time-step, set actions.\n      trajectory.change_last_time_step(action=actions[index])\n\n      # Create a new time-step to add observation, done & rewards (no actions).\n      trajectory.add_time_step(\n          observation=observations[index],\n          done=dones[index],\n          raw_reward=raw_rewards[index],\n          processed_reward=processed_rewards[index])\n\n      # If the trajectory is completed, i.e. dones[index] == True, then we\n      # account for it right-away.\n      if dones[index]:\n        self._complete_trajectory(trajectory, index)\n\n        # NOTE: The new trajectory at `index` is going to be in-active and\n        # `reset` should be called on it.\n        assert not self._trajectories[index].is_active", "response": "This function is called by the next step in all envs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the number of time - steps in completed and incomplete trajectories.", "response": "def num_time_steps(self):\n    \"\"\"Returns the number of time-steps in completed and incomplete trajectories.\"\"\"\n\n    num_time_steps = sum(t.num_time_steps for t in self.trajectories)\n    return num_time_steps + self.num_completed_time_steps"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef observations_np(self, boundary=20):\n    list_observations_np_ts = [t.observations_np for t in self.trajectories]\n    # Every element in `list_observations_np_ts` is shaped (t,) + OBS\n    OBS = list_observations_np_ts[0].shape[1:]  # pylint: disable=invalid-name\n\n    num_time_steps = [t.num_time_steps for t in self.trajectories]\n    t_max = max(num_time_steps)\n    # t_max is rounded to the next multiple of `boundary`\n    boundary = int(boundary)\n    bucket_length = boundary * int(np.ceil(float(t_max) / boundary))\n\n    def padding_config(obs):\n      # We're padding the first axis only, since that is the time-step.\n      num_to_pad = bucket_length + 1 - obs.shape[0]\n      return [(0, num_to_pad)] + [(0, 0)] * len(OBS)\n\n    return np.stack([\n        np.pad(obs, padding_config(obs), \"constant\")\n        for obs in list_observations_np_ts]), num_time_steps", "response": "Pads the observations in all the trajectories and returns them."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates squad examples. Args: tmp_dir: a string dataset_split: problem.DatasetSplit.TRAIN or problem.DatasetSplit.EVAL Yields: dictionaries representing examples", "response": "def _generate_examples(tmp_dir, dataset_split):\n  \"\"\"Generate squad examples.\n\n  Args:\n    tmp_dir: a string\n    dataset_split: problem.DatasetSplit.TRAIN or problem.DatasetSplit.EVAL\n  Yields:\n    dictionaries representing examples\n  \"\"\"\n  if dataset_split == problem.DatasetSplit.TRAIN:\n    file_name = _TRAINING_SET\n  else:\n    file_name = _DEV_SET\n  squad_file = generator_utils.maybe_download(tmp_dir,\n                                              file_name,\n                                              os.path.join(_URL, file_name))\n  with tf.gfile.GFile(squad_file, mode=\"r\") as fp:\n    squad = json.load(fp)\n\n  version = squad[\"version\"]\n  for article in squad[\"data\"]:\n    if \"title\" in article:\n      title = article[\"title\"].strip()\n    else:\n      title = \"no title\"\n    for paragraph in article[\"paragraphs\"]:\n      context = paragraph[\"context\"].strip()\n      for qa in paragraph[\"qas\"]:\n        question = qa[\"question\"].strip()\n        id_ = qa[\"id\"]\n        answer_starts = [answer[\"answer_start\"] for answer in qa[\"answers\"]]\n        answers = [answer[\"text\"].strip() for answer in qa[\"answers\"]]\n\n        # Features currently used are \"context\", \"question\", and \"answers\".\n        # Others are extracted here for the ease of future expansions.\n        example = {\n            \"version\": version,\n            \"title\": title,\n            \"context\": context,\n            \"question\": question,\n            \"id\": id_,\n            \"answer_starts\": answer_starts,\n            \"answers\": answers,\n            \"num_answers\": len(answers),\n            \"is_supervised\": True,\n        }\n        yield example"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef self_attention_layer(hparams, prefix):\n  return transformer_layers.SelfAttention(\n      num_heads=hparams.get(prefix + \"num_heads\"),\n      num_memory_heads=hparams.get(prefix + \"num_memory_heads\"),\n      key_value_size=hparams.d_kv,\n      shared_kv=hparams.get(prefix + \"shared_kv\", False),\n      attention_kwargs=attention_kwargs_from_hparams(hparams))", "response": "Create self - attention layer based on hyperparameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef local_self_attention_layer(hparams, prefix):\n  return transformer_layers.LocalSelfAttention(\n      num_heads=hparams.get(prefix + \"num_heads\"),\n      num_memory_heads=hparams.get(prefix + \"num_memory_heads\"),\n      radius=hparams.local_attention_radius,\n      key_value_size=hparams.d_kv,\n      shared_kv=hparams.get(prefix + \"shared_kv\", False),\n      attention_kwargs=attention_kwargs_from_hparams(hparams))", "response": "Create self - attention layer based on hyperparameters."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a layer stack based on the hyperparameter values.", "response": "def layer_stack_from_hparams(hparams, prefix):\n  \"\"\"Create a layer stack based on the hyperparameter values.\"\"\"\n  layers = hparams.get(prefix + \"layers\")\n  return transformer.LayerStack(\n      [layers_registry[l](hparams, prefix) for l in layers],\n      dropout_rate=hparams.layer_prepostprocess_dropout,\n      norm_epsilon=hparams.norm_epsilon)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmachines translation base configuration.", "response": "def mtf_bitransformer_base():\n  \"\"\"Machine translation base configuration.\"\"\"\n  hparams = mtf_transformer2_base()\n  hparams.max_length = 256\n  hparams.shared_embedding = True\n  # HYPERPARAMETERS FOR THE LAYER STACKS\n  hparams.add_hparam(\"encoder_layers\", [\"self_att\", \"drd\"] * 6)\n  hparams.add_hparam(\"decoder_layers\", [\"self_att\", \"enc_att\", \"drd\"] * 6)\n  hparams.add_hparam(\"encoder_num_layers\", 6)\n  hparams.add_hparam(\"decoder_num_layers\", 6)\n  # number of heads in multihead attention\n  hparams.add_hparam(\"encoder_num_heads\", 8)\n  hparams.add_hparam(\"decoder_num_heads\", 8)\n  hparams.add_hparam(\"local_attention_radius\", 128)\n\n  # default of 0 for standard transformer behavior\n  # 1 means a single set of keys and values that are read by all query heads\n  hparams.add_hparam(\"encoder_num_memory_heads\", 0)\n  hparams.add_hparam(\"decoder_num_memory_heads\", 0)\n  # share attention keys and values\n  hparams.add_hparam(\"encoder_shared_kv\", False)\n  hparams.add_hparam(\"decoder_shared_kv\", False)\n\n  # Parameters for computing the maximum decode length in beam search.\n  # Maximum decode length is:\n  #    min(max_length,\n  #        decode_length_multiplier * input_length + decode_length_constant)\n  hparams.add_hparam(\"decode_length_multiplier\", 1.5)\n  hparams.add_hparam(\"decode_length_constant\", 10.0)\n  # used during decoding\n  hparams.add_hparam(\"alpha\", 0.6)\n  hparams.sampling_temp = 0.0\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mtf_bitransformer_tiny():\n  hparams = mtf_bitransformer_base()\n  hparams.batch_size = 2\n  hparams.mesh_shape = \"\"\n  hparams.d_model = 128\n  hparams.encoder_layers = [\"self_att\", \"drd\"] * 2\n  hparams.decoder_layers = [\"self_att\", \"enc_att\", \"drd\"] * 2\n  hparams.num_heads = 4\n  hparams.d_ff = 512\n  return hparams", "response": "Small encoder - decoder model for testing."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mtf_unitransformer_all_layers_tiny():\n  hparams = mtf_unitransformer_tiny()\n  hparams.moe_num_experts = 4\n  hparams.moe_expert_x = 4\n  hparams.moe_expert_y = 4\n  hparams.moe_hidden_size = 512\n  hparams.layers = [\"self_att\", \"local_self_att\", \"moe_1d\", \"moe_2d\", \"drd\"]\n  return hparams", "response": "Test out all the layers on local CPU."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mtf_bitransformer_all_layers_tiny():\n  hparams = mtf_bitransformer_tiny()\n  hparams.moe_num_experts = 4\n  hparams.moe_expert_x = 4\n  hparams.moe_expert_y = 4\n  hparams.moe_hidden_size = 512\n  hparams.encoder_layers = [\n      \"self_att\", \"local_self_att\", \"moe_1d\", \"moe_2d\", \"drd\"]\n  hparams.decoder_layers = [\n      \"self_att\", \"local_self_att\", \"enc_att\", \"moe_1d\", \"moe_2d\", \"drd\"]\n  return hparams", "response": "Test out all the layers on local CPU."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mtr_lm_dense(sz):\n  n = 2 ** sz\n  hparams = mtf_unitransformer_base()\n  hparams.d_model = 1024\n  hparams.max_length = 1024\n  hparams.batch_size = 128\n  # Parameters for my_layer_stack()\n  hparams.num_hidden_layers = 6\n  hparams.d_ff = 8192 * n\n  hparams.d_kv = 256\n  hparams.num_heads = 8 * n\n  hparams.learning_rate_decay_steps = 65536\n  hparams.layout = \"batch:batch;vocab:model;d_ff:model;heads:model\"\n  hparams.mesh_shape = \"batch:32\"\n  return hparams", "response": "Series of architectures for language modeling."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mtr_lm_v1():\n  hparams = mtr_lm_dense(0)\n  hparams.layers = ([\"local_self_att\", \"local_self_att\", \"drd\",\n                     \"self_att\", \"drd\", \"local_self_att\",\n                     \"local_self_att\", \"moe_2d\"] * 4)[:-1]\n  hparams.d_kv = 128\n  hparams.moe_expert_x = 8\n  hparams.moe_expert_y = 4\n  hparams.moe_hidden_size = 32768\n  hparams.d_ff = 2048\n  hparams.num_memory_heads = 0\n  hparams.mesh_shape = \"b0:4;b1:8\"\n  hparams.layout = \"outer_batch:b0;inner_batch:b1,expert_x:b1,expert_y:b0\"\n  hparams.outer_batch_size = 4\n  return hparams", "response": "Model incorporating mixture - of - experts local and global attention."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mtr_tr_dense_local(sz):\n  hparams = mtr_tr_dense(sz)\n  hparams.decoder_layers = [\"local_self_att\", \"enc_att\", \"drd\"] * 6\n  hparams.local_attention_radius = 32\n  return hparams", "response": "With local self - attention in the decoder."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef batch_norm_relu(inputs, is_training, relu=True):\n  inputs = mtf.layers.batch_norm(\n      inputs,\n      is_training,\n      BATCH_NORM_DECAY,\n      epsilon=BATCH_NORM_EPSILON,\n      init_zero=(not relu))\n  if relu:\n    inputs = mtf.relu(inputs)\n  return inputs", "response": "Block of batch norm and relu."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bottleneck_block(inputs,\n                     filters,\n                     is_training,\n                     strides,\n                     projection_shortcut=None,\n                     row_blocks_dim=None,\n                     col_blocks_dim=None):\n  \"\"\"Bottleneck block variant for residual networks with BN after convolutions.\n\n  Args:\n    inputs: a `mtf.Tensor` of shape\n        `[batch_dim, row_blocks, col_blocks, rows, cols, in_channels]`.\n    filters: `int` number of filters for the first two convolutions. Note\n        that the third and final convolution will use 4 times as many filters.\n    is_training: `bool` for whether the model is in training mode.\n    strides: `int` block stride. If greater than 1, this block will ultimately\n        downsample the input.\n    projection_shortcut: `function` to use for projection shortcuts (typically\n        a 1x1 convolution to match the filter dimensions). If None, no\n        projection is used and the input is passed as unchanged through the\n        shortcut connection.\n    row_blocks_dim: a mtf.Dimension, row dimension which is\n        spatially partitioned along mesh axis\n    col_blocks_dim: a mtf.Dimension, row dimension which is\n        spatially partitioned along mesh axis\n\n  Returns:\n    The output `Tensor` of the block.\n  \"\"\"\n  shortcut = inputs\n\n  filter_h_dim = mtf.Dimension(\"filter_height\", 3)\n  filter_w_dim = mtf.Dimension(\"filter_width\", 3)\n  one_h_dim = mtf.Dimension(\"filter_height\", 1)\n  one_w_dim = mtf.Dimension(\"filter_width\", 1)\n\n  if projection_shortcut is not None:\n    filters_dim = mtf.Dimension(\"filtersp\", filters)\n    kernel = mtf.get_variable(\n        inputs.mesh, \"kernel\", mtf.Shape(\n            [one_h_dim, one_w_dim, inputs.shape.dims[-1], filters_dim]))\n    shortcut = projection_shortcut(inputs, kernel)\n\n  # First conv block\n  filters1_dim = mtf.Dimension(\"filters1\", filters)\n  kernel1 = mtf.get_variable(\n      inputs.mesh, \"kernel1\", mtf.Shape(\n          [one_h_dim, one_w_dim, inputs.shape.dims[-1], filters1_dim]))\n  inputs = mtf.conv2d_with_blocks(\n      inputs,\n      kernel1,\n      strides=[1, 1, 1, 1],\n      padding=\"SAME\",\n      h_blocks_dim=None, w_blocks_dim=col_blocks_dim)\n\n  # TODO(nikip): Add Dropout?\n  inputs = batch_norm_relu(inputs, is_training)\n\n  # Second conv block\n  filters2_dim = mtf.Dimension(\"filters2\", 4*filters)\n  kernel2 = mtf.get_variable(\n      inputs.mesh, \"kernel2\", mtf.Shape(\n          [filter_h_dim, filter_w_dim, filters1_dim, filters2_dim]))\n  inputs = mtf.conv2d_with_blocks(\n      inputs,\n      kernel2,\n      strides=[1, 1, 1, 1],\n      padding=\"SAME\",\n      h_blocks_dim=row_blocks_dim, w_blocks_dim=col_blocks_dim)\n\n  inputs = batch_norm_relu(inputs, is_training)\n\n  # Third wide conv filter block\n  filters3_dim = mtf.Dimension(\"filters3\", filters)\n  filters3_kernel = mtf.get_variable(\n      inputs.mesh, \"wide_kernel\", mtf.Shape(\n          [one_h_dim, one_w_dim, filters2_dim, filters3_dim]))\n  inputs = mtf.conv2d_with_blocks(\n      inputs,\n      filters3_kernel,\n      strides,\n      padding=\"SAME\",\n      h_blocks_dim=None, w_blocks_dim=col_blocks_dim)\n\n  # TODO(nikip): Althought the original resnet code has this batch norm, in our\n  # setup this is causing no gradients to be passed. Investigate further.\n  # inputs = batch_norm_relu(inputs, is_training, relu=True)\n\n  # TODO(nikip): Maybe add residual with a projection?\n  return mtf.relu(\n      shortcut + mtf.rename_dimension(\n          inputs, inputs.shape.dims[-1].name, shortcut.shape.dims[-1].name))", "response": "Bottleneck block variant for residual networks with BN after convolutions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef block_layer(inputs,\n                filters,\n                blocks,\n                strides,\n                is_training,\n                name,\n                row_blocks_dim=None,\n                col_blocks_dim=None):\n  \"\"\"Creates one layer of blocks for the ResNet model.\n\n  Args:\n    inputs: `Tensor` of size `[batch, channels, height, width]`.\n    filters: `int` number of filters for the first convolution of the layer.\n    blocks: `int` number of blocks contained in the layer.\n    strides: `int` stride to use for the first convolution of the layer. If\n        greater than 1, this layer will downsample the input.\n    is_training: `bool` for whether the model is training.\n    name: `str`name for the Tensor output of the block layer.\n    row_blocks_dim: a mtf.Dimension, row dimension which is\n        spatially partitioned along mesh axis\n    col_blocks_dim: a mtf.Dimension, row dimension which is\n        spatially partitioned along mesh axis\n\n  Returns:\n    The output `Tensor` of the block layer.\n  \"\"\"\n  with tf.variable_scope(name, default_name=\"block_layer\"):\n    # Only the first block per block_layer uses projection_shortcut and strides\n    def projection_shortcut(inputs, kernel):\n      \"\"\"Project identity branch.\"\"\"\n      inputs = mtf.conv2d_with_blocks(\n          inputs,\n          kernel,\n          strides=strides,\n          padding=\"SAME\",\n          h_blocks_dim=None, w_blocks_dim=col_blocks_dim)\n      return batch_norm_relu(\n          inputs, is_training, relu=False)\n\n    inputs = bottleneck_block(\n        inputs,\n        filters,\n        is_training,\n        strides=strides,\n        projection_shortcut=projection_shortcut,\n        row_blocks_dim=row_blocks_dim,\n        col_blocks_dim=col_blocks_dim)\n\n    for i in range(1, blocks):\n      with tf.variable_scope(\"bottleneck_%d\" % i):\n        inputs = bottleneck_block(\n            inputs,\n            filters,\n            is_training,\n            strides=[1, 1, 1, 1],\n            projection_shortcut=None,\n            row_blocks_dim=row_blocks_dim,\n            col_blocks_dim=col_blocks_dim)\n\n    return inputs", "response": "Creates a block layer for the ResNet model."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef universal_transformer_layer(x,\n                                hparams,\n                                ffn_unit,\n                                attention_unit,\n                                pad_remover=None):\n  \"\"\"Core function applying the universal transformer layer.\n\n  Args:\n    x: input\n    hparams: model hyper-parameters\n    ffn_unit: feed-forward unit\n    attention_unit: multi-head attention unit\n    pad_remover: to mask out padding in convolutional layers (efficiency).\n\n  Returns:\n    the output tensor,  extra output (can be memory, ponder time, etc.)\n\n  Raises:\n    ValueError: Unknown recurrence type\n  \"\"\"\n\n  def add_vanilla_transformer_layer(x, num_layers, name):\n    \"\"\"Passes the input through num_layers of vanilla transformer layers.\n\n    Args:\n     x: input\n     num_layers: number of layers\n     name: string, prefix of layer names\n\n    Returns:\n       output of vanilla_transformer_layer\n    \"\"\"\n    if hparams.add_position_timing_signal:\n      # In case of add_position_timing_signal=true, we set  hparams.pos=None\n      # and add position timing signal at the beginning of each step, so for\n      # the vanilla transformer, we need to add timing signal here.\n      x = common_attention.add_timing_signal_1d(x)\n    for layer in range(num_layers):\n      with tf.variable_scope(name + \"layer_%d\" % layer):\n        x = ffn_unit(attention_unit(x))\n    return x\n\n  with tf.variable_scope(\"universal_transformer_%s\" % hparams.recurrence_type):\n    if (hparams.mix_with_transformer and\n        \"before_ut\" in hparams.mix_with_transformer):\n      x = add_vanilla_transformer_layer(x, hparams.num_mixedin_layers,\n                                        \"before_ut_\")\n\n    if hparams.recurrence_type == \"act\":\n      output, extra_output = universal_transformer_act(\n          x, hparams, ffn_unit, attention_unit)\n\n    else:  # for all the other recurrency types with fixed number of steps\n\n      ut_function, initializer = get_ut_layer(x, hparams, ffn_unit,\n                                              attention_unit, pad_remover)\n\n      output, _, extra_output = tf.foldl(\n          ut_function, tf.range(hparams.num_rec_steps),\n          initializer=initializer)\n\n      # Right now, this is only possible when the transition function is an lstm\n      if (hparams.recurrence_type == \"lstm\" and\n          hparams.get(\"use_memory_as_final_state\", False)):\n        output = extra_output\n\n    if (hparams.mix_with_transformer and\n        \"after_ut\" in hparams.mix_with_transformer):\n      output = add_vanilla_transformer_layer(output, hparams.num_mixedin_layers,\n                                             \"after_ut_\")\n\n    return output, extra_output", "response": "Core function applying the universal transformer layer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the function that is used in universal transforemr steps.", "response": "def get_ut_layer(x,\n                 hparams,\n                 ffn_unit,\n                 attention_unit,\n                 pad_remover=None):\n  \"\"\"Provides the function that is used in universal transforemr steps.\n\n  Args:\n    x: input\n    hparams: model hyper-parameters\n    ffn_unit: feed-forward unit\n    attention_unit: multi-head attention unit\n    pad_remover: to mask out padding in convolutional layers (efficiency).\n\n  Returns:\n    ut_function and the ut_initializer\n\n  Raises:\n    ValueError: Unknown recurrence type\n  \"\"\"\n\n  if hparams.recurrence_type == \"basic\":\n    ut_initializer = (x, x, x)  # (state, input, memory)\n    ut_function = functools.partial(\n        universal_transformer_basic,\n        hparams=hparams,\n        ffn_unit=ffn_unit,\n        attention_unit=attention_unit)\n\n  elif hparams.recurrence_type == \"highway\":\n    ut_initializer = (x, x, x)  # (state, input, memory)\n    ut_function = functools.partial(\n        universal_transformer_highway,\n        hparams=hparams,\n        ffn_unit=ffn_unit,\n        attention_unit=attention_unit,\n        pad_remover=pad_remover)\n\n  elif hparams.recurrence_type == \"skip\":\n    ut_initializer = (x, x, x)  # (state, input, memory)\n    ut_function = functools.partial(\n        universal_transformer_skip,\n        hparams=hparams,\n        ffn_unit=ffn_unit,\n        attention_unit=attention_unit,\n        pad_remover=pad_remover)\n\n  elif hparams.recurrence_type == \"dwa\":\n    # memory contains the original input + all the states\n    memory_size = hparams.num_rec_steps + 1\n\n    # prepare initializer:\n    memory_empty = tf.zeros([memory_size] + common_layers.shape_list(x))\n\n    # filling the first slot with the original input\n    memory = fill_memory_slot(memory_empty, x, 0)\n\n    ut_initializer = (x, x, memory)  # (state, input, memory)\n    ut_function = functools.partial(\n        universal_transformer_depthwise_attention,\n        hparams=hparams,\n        ffn_unit=ffn_unit,\n        attention_unit=attention_unit)\n\n  elif hparams.recurrence_type == \"gru\":\n    ut_initializer = (x, x, x)  # (state, input, memory)\n    ut_function = functools.partial(\n        universal_transformer_with_gru_as_transition_function,\n        hparams=hparams,\n        ffn_unit=ffn_unit,\n        attention_unit=attention_unit,\n        pad_remover=pad_remover)\n\n  elif hparams.recurrence_type == \"lstm\":\n    memory = tf.zeros(common_layers.shape_list(x))\n    ut_initializer = (x, x, memory)  # (state, input, memory)\n    ut_function = functools.partial(\n        universal_transformer_with_lstm_as_transition_function,\n        hparams=hparams,\n        ffn_unit=ffn_unit,\n        attention_unit=attention_unit,\n        pad_remover=pad_remover)\n\n  else:\n    raise ValueError(\"Unknown recurrence type: %s\" % hparams.recurrence_type)\n\n  return ut_function, ut_initializer"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply a feed - forward function which is parametrised for encoding.", "response": "def transformer_encoder_ffn_unit(x,\n                                 hparams,\n                                 nonpadding_mask=None,\n                                 pad_remover=None):\n  \"\"\"Applies a feed-forward function which is parametrised for encoding.\n\n  Args:\n    x: input\n    hparams: model hyper-parameters\n    nonpadding_mask: optional Tensor with shape [batch_size, encoder_length]\n    indicating what positions are not padding.  This is used\n    to mask out padding in convoltutional layers.  We generally only\n    need this mask for \"packed\" datasets, because for ordinary datasets,\n    no padding is ever followed by nonpadding.\n    pad_remover: to mask out padding in convolutional layers (efficiency).\n\n  Returns:\n    the output tensor\n  \"\"\"\n\n  with tf.variable_scope(\"ffn\"):\n    if hparams.transformer_ffn_type == \"fc\":\n      y = transformer.transformer_ffn_layer(\n          common_layers.layer_preprocess(x, hparams),\n          hparams,\n          pad_remover,\n          conv_padding=\"SAME\",\n          nonpadding_mask=nonpadding_mask)\n\n    if hparams.transformer_ffn_type == \"sepconv\":\n      assert nonpadding_mask is not None, (\n          \"The nonpadding_mask should be provided, otherwise the model uses \"\n          \"the leaked padding information to estimate the length!\")\n      y = common_layers.sepconv_relu_sepconv(\n          common_layers.layer_preprocess(x, hparams),\n          filter_size=hparams.filter_size,\n          output_size=hparams.hidden_size,\n          first_kernel_size=(3, 1),\n          second_kernel_size=(5, 1),\n          padding=\"SAME\",\n          nonpadding_mask=nonpadding_mask,\n          dropout=hparams.relu_dropout)\n\n    x = common_layers.layer_postprocess(x, y, hparams)\n\n  return x"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transformer_encoder_attention_unit(x,\n                                       hparams,\n                                       encoder_self_attention_bias,\n                                       attention_dropout_broadcast_dims,\n                                       save_weights_to=None,\n                                       make_image_summary=True):\n  \"\"\"Applies multihead attention function which is parametrised for encoding.\n\n  Args:\n    x: input\n    hparams: model hyper-parameters\n    encoder_self_attention_bias: a bias tensor for use in encoder self-attention\n    attention_dropout_broadcast_dims: Fpr noise broadcasting in the dropout\n      layers to save memory during training\n    save_weights_to: an optional dictionary to capture attention weights for\n      visualization; the weights tensor will be appended there under a string\n      key created from the variable scope (including name).\n    make_image_summary: Whether to make an attention image summary.\n\n  Returns:\n    the output tensor\n\n  \"\"\"\n\n  with tf.variable_scope(\"self_attention\"):\n    y = common_attention.multihead_attention(\n        common_layers.layer_preprocess(x, hparams),\n        None,\n        encoder_self_attention_bias,\n        hparams.attention_key_channels or hparams.hidden_size,\n        hparams.attention_value_channels or hparams.hidden_size,\n        hparams.hidden_size,\n        hparams.num_heads,\n        hparams.attention_dropout,\n        attention_type=hparams.self_attention_type,\n        save_weights_to=save_weights_to,\n        max_relative_position=hparams.max_relative_position,\n        make_image_summary=make_image_summary,\n        dropout_broadcast_dims=attention_dropout_broadcast_dims,\n        hard_attention_k=hparams.hard_attention_k)\n    x = common_layers.layer_postprocess(x, y, hparams)\n  return x", "response": "Applies multihead attention function which is parametrised for encoding."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply multihead attention function which is parametrised for decoding.", "response": "def transformer_decoder_attention_unit(x,\n                                       hparams,\n                                       encoder_output,\n                                       decoder_self_attention_bias,\n                                       encoder_decoder_attention_bias,\n                                       attention_dropout_broadcast_dims,\n                                       save_weights_to=None,\n                                       make_image_summary=True):\n  \"\"\"Applies multihead attention function which is parametrised for decoding.\n\n  Args:\n    x: input (decoder input)\n    hparams: model hyper-parameters\n    encoder_output: Encoder representation. [batch_size, input_length,\n      hidden_dim]\n    decoder_self_attention_bias: Bias and mask weights for decoder\n      self-attention. [batch_size, decoder_length]\n    encoder_decoder_attention_bias: Bias and mask weights for encoder-decoder\n      attention. [batch_size, input_length]\n    attention_dropout_broadcast_dims: Fpr noise broadcasting in the dropout\n      layers to save memory during training\n    save_weights_to: an optional dictionary to capture attention weights for\n      visualization; the weights tensor will be appended there under a string\n      key created from the variable scope (including name).\n    make_image_summary: Whether to make an attention image summary.\n\n  Returns:\n    The output tensor\n  \"\"\"\n\n  with tf.variable_scope(\"self_attention\"):\n    y = common_attention.multihead_attention(\n        common_layers.layer_preprocess(x, hparams),\n        None,\n        decoder_self_attention_bias,\n        hparams.attention_key_channels or hparams.hidden_size,\n        hparams.attention_value_channels or hparams.hidden_size,\n        hparams.hidden_size,\n        hparams.num_heads,\n        hparams.attention_dropout,\n        attention_type=hparams.self_attention_type,\n        save_weights_to=save_weights_to,\n        max_relative_position=hparams.max_relative_position,\n        cache=None,\n        make_image_summary=make_image_summary,\n        dropout_broadcast_dims=attention_dropout_broadcast_dims,\n        hard_attention_k=hparams.hard_attention_k)\n    x = common_layers.layer_postprocess(x, y, hparams)\n  if encoder_output is not None:\n    with tf.variable_scope(\"encdec_attention\"):\n      y = common_attention.multihead_attention(\n          common_layers.layer_preprocess(x, hparams),\n          encoder_output,\n          encoder_decoder_attention_bias,\n          hparams.attention_key_channels or hparams.hidden_size,\n          hparams.attention_value_channels or hparams.hidden_size,\n          hparams.hidden_size,\n          hparams.num_heads,\n          hparams.attention_dropout,\n          save_weights_to=save_weights_to,\n          make_image_summary=make_image_summary,\n          dropout_broadcast_dims=attention_dropout_broadcast_dims,\n          hard_attention_k=hparams.hard_attention_k)\n      x = common_layers.layer_postprocess(x, y, hparams)\n  return x"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef universal_transformer_basic(layer_inputs,\n                                step, hparams,\n                                ffn_unit,\n                                attention_unit):\n  \"\"\"Basic Universal Transformer.\n\n  This model is pretty similar to the vanilla transformer in which weights are\n  shared between layers. For some tasks, this simple idea brings a\n  generalization that is not achievable by playing with the size of the model\n  or drop_out parameters in the vanilla transformer.\n\n  Args:\n    layer_inputs:\n        - state: state\n    step: indicates number of steps taken so far\n    hparams: model hyper-parameters\n    ffn_unit: feed-forward unit\n    attention_unit: multi-head attention unit\n\n  Returns:\n    layer_output:\n         new_state: new state\n  \"\"\"\n  state, inputs, memory = tf.unstack(layer_inputs, num=None, axis=0,\n                                     name=\"unstack\")\n  new_state = step_preprocess(state, step, hparams)\n\n  for i in range(hparams.num_inrecurrence_layers):\n    with tf.variable_scope(\"rec_layer_%d\" % i):\n      new_state = ffn_unit(attention_unit(new_state))\n\n  return new_state, inputs, memory", "response": "Basic Universal Transformer.\n\n  This model is pretty similar to the vanilla transformer in which weights are\n  shared between layers. For some tasks, this simple idea brings a\n  generalization that is not achievable by playing with the size of the model\n  or drop_out parameters in the vanilla transformer.\n\n  Args:\n    layer_inputs:\n        - state: state\n    step: indicates number of steps taken so far\n    hparams: model hyper-parameters\n    ffn_unit: feed-forward unit\n    attention_unit: multi-head attention unit\n\n  Returns:\n    layer_output:\n         new_state: new state"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef universal_transformer_depthwise_attention(layer_inputs,\n                                              step, hparams,\n                                              ffn_unit,\n                                              attention_unit):\n  \"\"\"universal_transformer with depth-wise attention.\n\n  It uses an attention mechanism-flipped vertically-\n  over all the states from previous steps to generate the new_state.\n\n  Args:\n    layer_inputs:\n      - state: state\n      - memory: contains states from all the previous steps.\n    step: indicating number of steps take so far\n    hparams: model hyper-parameters.\n    ffn_unit: feed-forward unit\n    attention_unit: multi-head attention unit\n\n\n  Returns:\n    layer_output:\n        new_state: new state\n        memory: contains states from all the previous steps.\n\n  \"\"\"\n  _, inputs, memory = layer_inputs\n  all_states = memory\n\n  # add depth signal\n  if hparams.depth_embedding:\n    all_states = add_depth_embedding(all_states)\n\n  # get the states up to the current step (non-zero part of the memory)\n  states_so_far = all_states[:step, :, :, :]\n\n  states_so_far_weights = tf.nn.softmax(\n      common_layers.dense(\n          states_so_far, (hparams.hidden_size if hparams.dwa_elements else 1),\n          activation=None,\n          use_bias=True),\n      axis=-1)\n\n  # prepare the state tensor that will be transformed\n  state_to_be_transformed = tf.reduce_sum(\n      (states_so_far * states_so_far_weights), axis=0)\n\n  new_state = step_preprocess(state_to_be_transformed, step, hparams)\n\n  for i in range(hparams.num_inrecurrence_layers):\n    with tf.variable_scope(\"rec_layer_%d\" % i):\n      new_state = ffn_unit(attention_unit(new_state))\n\n  # add the new state to the memory\n  memory = fill_memory_slot(memory, new_state, step + 1)\n\n  return new_state, inputs, memory", "response": "Universal Transformer with depth - wise attention."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef universal_transformer_act(x, hparams, ffn_unit, attention_unit):\n  if hparams.act_type not in [\"basic\", \"global\", \"random\", \"accumulated\"]:\n    raise ValueError(\"Unknown act type: %s\" % hparams.act_type)\n\n  state = x\n  act_max_steps = hparams.act_max_steps\n  threshold = 1.0 - hparams.act_epsilon\n  state_shape_static = state.get_shape()\n\n  state_slice = slice(0, 2)\n  if hparams.act_type == \"global\":\n    state_slice = slice(0, 1)\n\n  # Dynamic shape for update tensors below\n  update_shape = tf.shape(state)[state_slice]\n\n  # Halting probabilities (p_t^n in the paper)\n  halting_probability = tf.zeros(update_shape, name=\"halting_probability\")\n\n  # Remainders (R(t) in the paper)\n  remainders = tf.zeros(update_shape, name=\"remainder\")\n\n  # Number of updates performed (N(t) in the paper)\n  n_updates = tf.zeros(update_shape, name=\"n_updates\")\n\n  # Previous cell states (s_t in the paper)\n  previous_state = tf.zeros_like(state, name=\"previous_state\")\n  step = tf.constant(0, dtype=tf.int32)\n\n  def ut_function(state, step, halting_probability, remainders, n_updates,\n                  previous_state):\n    \"\"\"implements act (position-wise halting).\n\n    Args:\n      state: 3-D Tensor: [batch_size, length, channel]\n      step: indicates number of steps taken so far\n      halting_probability: halting probability\n      remainders: act remainders\n      n_updates: act n_updates\n      previous_state: previous state\n\n    Returns:\n      transformed_state: transformed state\n      step: step+1\n      halting_probability: halting probability\n      remainders: act remainders\n      n_updates: act n_updates\n      new_state: new state\n    \"\"\"\n    state = step_preprocess(state, step, hparams)\n\n    if hparams.act_type == \"random\":\n      # random as halting probability\n      p = tf.random_uniform(\n          shape=common_layers.shape_list(halting_probability))\n    else:\n      with tf.variable_scope(\"sigmoid_activation_for_pondering\"):\n        p = common_layers.dense(\n            state,\n            1,\n            activation=tf.nn.sigmoid,\n            use_bias=True,\n            bias_initializer=tf.constant_initializer(\n                hparams.act_halting_bias_init))\n\n        if hparams.act_type == \"global\":\n          # average over all positions (as a global halting prob)\n          p = tf.reduce_mean(p, axis=1)\n          p = tf.squeeze(p)\n        else:\n          # maintain position-wise probabilities\n          p = tf.squeeze(p, axis=-1)\n\n    # Mask for inputs which have not halted yet\n    still_running = tf.cast(tf.less(halting_probability, 1.0), tf.float32)\n\n    # Mask of inputs which halted at this step\n    new_halted = tf.cast(\n        tf.greater(halting_probability + p * still_running, threshold),\n        tf.float32) * still_running\n\n    # Mask of inputs which haven't halted, and didn't halt this step\n    still_running = tf.cast(\n        tf.less_equal(halting_probability + p * still_running, threshold),\n        tf.float32) * still_running\n\n    # Add the halting probability for this step to the halting\n    # probabilities for those input which haven't halted yet\n    halting_probability += p * still_running\n\n    # Compute remainders for the inputs which halted at this step\n    remainders += new_halted * (1 - halting_probability)\n\n    # Add the remainders to those inputs which halted at this step\n    halting_probability += new_halted * remainders\n\n    # Increment n_updates for all inputs which are still running\n    n_updates += still_running + new_halted\n\n    # Compute the weight to be applied to the new state and output\n    # 0 when the input has already halted\n    # p when the input hasn't halted yet\n    # the remainders when it halted this step\n    update_weights = tf.expand_dims(\n        p * still_running + new_halted * remainders, -1)\n    if hparams.act_type == \"global\":\n      update_weights = tf.expand_dims(update_weights, -1)\n\n    # apply transformation on the state\n    transformed_state = state\n    for i in range(hparams.num_inrecurrence_layers):\n      with tf.variable_scope(\"rec_layer_%d\" % i):\n        transformed_state = ffn_unit(attention_unit(transformed_state))\n\n    # update running part in the weighted state and keep the rest\n    new_state = ((transformed_state * update_weights) +\n                 (previous_state * (1 - update_weights)))\n\n    if hparams.act_type == \"accumulated\":\n      # Add in the weighted state\n      new_state = (transformed_state * update_weights) + previous_state\n\n    # remind TensorFlow of everything's shape\n    transformed_state.set_shape(state_shape_static)\n    for x in [halting_probability, remainders, n_updates]:\n      x.set_shape(state_shape_static[state_slice])\n    new_state.set_shape(state_shape_static)\n    step += 1\n    return (transformed_state, step, halting_probability, remainders, n_updates,\n            new_state)\n\n  # While loop stops when this predicate is FALSE.\n  # Ie all (probability < 1-eps AND counter < N) are false.\n  def should_continue(u0, u1, halting_probability, u2, n_updates, u3):\n    del u0, u1, u2, u3\n    return tf.reduce_any(\n        tf.logical_and(\n            tf.less(halting_probability, threshold),\n            tf.less(n_updates, act_max_steps)))\n\n  # Do while loop iterations until predicate above is false.\n  (_, _, _, remainder, n_updates, new_state) = tf.while_loop(\n      should_continue, ut_function,\n      (state, step, halting_probability, remainders, n_updates, previous_state),\n      maximum_iterations=act_max_steps + 1)\n\n  ponder_times = n_updates\n  remainders = remainder\n\n  tf.contrib.summary.scalar(\"ponder_times\", tf.reduce_mean(ponder_times))\n\n  return new_state, (ponder_times, remainders)", "response": "Universal Transformer for act based models."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nimplements a Feed - forward layer with multiple inputs.", "response": "def _ffn_layer_multi_inputs(inputs_list,\n                            hparams,\n                            ffn_layer_type=\"dense\",\n                            name=\"ffn\",\n                            kernel_initializer=None,\n                            bias_initializer=None,\n                            activation=None,\n                            pad_remover=None,\n                            preprocess=False,\n                            postprocess=False):\n  \"\"\"Implements a Feed-forward layer with multiple inputs, pad-removing, etc.\n\n  Args:\n    inputs_list: list of input tensors\n    hparams: hyper-parameters\n    ffn_layer_type: dense / dense_dropconnect/ dense_relu_dense\n    name: name\n    kernel_initializer: kernel initializer\n    bias_initializer: bias initializer\n    activation: activation function\n    pad_remover: pad remover\n    preprocess: if preprocess the input\n    postprocess: if postprocess the output\n\n  Returns:\n    a tensor\n  Raises:\n    ValueError: Unknown ffn_layer type.\n\n  \"\"\"\n\n  # need at least one inputs\n  num_inputs = len(inputs_list)\n  assert num_inputs > 0\n\n  if preprocess and num_inputs == 1:\n    inputs_list[0] = common_layers.layer_preprocess(inputs_list[0], hparams)\n\n  if postprocess:\n    original_inputs = inputs_list[0]\n\n  # the output size is the hidden size of the main inputs\n  main_input = inputs_list[0]\n  original_shape = common_layers.shape_list(main_input)\n  assert hparams.hidden_size == common_layers.shape_list(main_input)[-1]\n\n  # all the inputs are in the same shape with main inputs\n  for inputs in inputs_list:\n    main_input.get_shape().assert_is_compatible_with(inputs.get_shape())\n\n  def remove_pads(x):\n    original_shape = common_layers.shape_list(x)\n    # Collapse `x` across examples, and remove padding positions.\n    x = tf.reshape(x, tf.concat([[-1], original_shape[2:]], axis=0))\n    x = tf.expand_dims(pad_remover.remove(x), axis=0)\n    return x\n\n  if pad_remover:\n    for i, inputs in enumerate(inputs_list):\n      inputs_list[i] = remove_pads(inputs)\n\n  ffn_inputs = inputs_list[0]\n  if len(inputs_list) != 1:\n    ffn_inputs = tf.concat(inputs_list, axis=-1)\n\n  if ffn_layer_type == \"dense\":\n    output = common_layers.dense(\n        ffn_inputs,\n        hparams.hidden_size,\n        name=name,\n        activation=activation,\n        use_bias=True,\n        kernel_initializer=kernel_initializer,\n        bias_initializer=bias_initializer)\n\n  elif ffn_layer_type == \"dense_dropconnect\":\n    output = common_layers.dense_dropconnect(\n        ffn_inputs,\n        hparams.hidden_size,\n        name=name,\n        dropconnect_dropout=hparams.dropconnect_dropout,\n        output_activation=activation)\n    postprocess = False  # no dropout on the output unit\n\n  elif ffn_layer_type == \"dense_relu_dense\":\n    output = common_layers.dense_relu_dense(\n        ffn_inputs,\n        hparams.filter_size,\n        hparams.hidden_size,\n        name=name,\n        dropout=hparams.relu_dropout,\n        output_activation=activation,\n    )\n\n  else:\n    raise ValueError(\"Unknown ffn_layer type: %s\" % ffn_layer_type)\n\n  if pad_remover:\n    # Restore `output` to the original shape of `x`, including padding.\n    output = tf.reshape(\n        pad_remover.restore(tf.squeeze(output, axis=0)), original_shape)\n\n  if postprocess:\n    if num_inputs == 1:\n      output = common_layers.layer_postprocess(original_inputs, output, hparams)\n    else:  # only dropout (no residual)x\n      hp = copy.copy(hparams)\n      hp.layer_postprocess_sequence = hp.layer_postprocess_sequence.replace(\n          \"a\", \"\")\n      output = common_layers.layer_postprocess(original_inputs, output, hp)\n\n  return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfilling the memory at a particular index with the given value.", "response": "def fill_memory_slot(memory, value, index):\n  \"\"\"Fills the memory slot at a particular index with the given value.\n\n  Args:\n    memory: a 4-d tensor [memory_size, batch, length, channel] containing\n      the state of all steps\n    value: a 3-d tensor [batch, length, channel] as the sate\n    index: integer in [0, memory_size)\n\n  Returns:\n    filled memory\n\n  \"\"\"\n  mask = tf.to_float(\n      tf.one_hot(index,\n                 tf.shape(memory)[0])[:, None, None, None])\n  fill_memory = (1 - mask) * memory + mask * value[None, ...]\n  return fill_memory"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_depth_embedding(x):\n  x_shape = common_layers.shape_list(x)\n  depth = x_shape[-1]\n  num_steps = x_shape[0]\n  shape = [num_steps, 1, 1, depth]\n  depth_embedding = (\n      tf.get_variable(\n          \"depth_embedding\",\n          shape,\n          initializer=tf.random_normal_initializer(0, depth**-0.5)) * (depth**\n                                                                       0.5))\n\n  x += depth_embedding\n  return x", "response": "Adds n - dimensional embedding as the depth embedding."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_position_timing_signal(x, step, hparams):\n\n  if not hparams.position_start_index:\n    index = 0\n\n  elif hparams.position_start_index == \"random\":\n    # Shift all positions randomly\n    # TODO(dehghani): What would be reasonable for max number of shift?\n    index = tf.random_uniform(\n        [], maxval=common_layers.shape_list(x)[1], dtype=tf.int32)\n\n  elif hparams.position_start_index == \"step\":\n    # Shift positions based on the step\n    if hparams.recurrence_type == \"act\":\n      num_steps = hparams.act_max_steps\n    else:\n      num_steps = hparams.num_rec_steps\n    index = tf.cast(\n        common_layers.shape_list(x)[1] * step / num_steps, dtype=tf.int32)\n\n  # No need for the timing signal in the encoder/decoder input preparation\n  assert hparams.pos is None\n\n  length = common_layers.shape_list(x)[1]\n  channels = common_layers.shape_list(x)[2]\n  signal = common_attention.get_timing_signal_1d(\n      length, channels, start_index=index)\n\n  if hparams.add_or_concat_timing_signal == \"add\":\n    x_with_timing = x + common_layers.cast_like(signal, x)\n\n  elif hparams.add_or_concat_timing_signal == \"concat\":\n    batch_size = common_layers.shape_list(x)[0]\n    signal_tiled = tf.tile(signal, [batch_size, 1, 1])\n    x_with_timing = tf.concat((x, signal_tiled), axis=-1)\n\n  return x_with_timing", "response": "Add n - dimensional embedding as the position timing signal."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_step_timing_signal(x, step, hparams):\n  if hparams.recurrence_type == \"act\":\n    num_steps = hparams.act_max_steps\n  else:\n    num_steps = hparams.num_rec_steps\n  channels = common_layers.shape_list(x)[-1]\n\n  if hparams.step_timing_signal_type == \"learned\":\n    signal = common_attention.get_layer_timing_signal_learned_1d(\n        channels, step, num_steps)\n\n  elif hparams.step_timing_signal_type == \"sinusoid\":\n    signal = common_attention.get_layer_timing_signal_sinusoid_1d(\n        channels, step, num_steps)\n\n  if hparams.add_or_concat_timing_signal == \"add\":\n    x_with_timing = x + common_layers.cast_like(signal, x)\n\n  elif hparams.add_or_concat_timing_signal == \"concat\":\n    batch_size = common_layers.shape_list(x)[0]\n    length = common_layers.shape_list(x)[1]\n    signal_tiled = tf.tile(signal, [batch_size, length, 1])\n    x_with_timing = tf.concat((x, signal_tiled), axis=-1)\n\n  return x_with_timing", "response": "Adds a n - dimensional embedding as the step ( vertical ) timing signal."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\niterate through records in WET file object.", "response": "def wet_records_from_file_obj(f, take_ownership=False):\n  \"\"\"Iterate through records in WET file object.\"\"\"\n  while True:\n    record = WETRecord.read(f)\n\n    if record is None:\n      break\n\n    if not record.url:\n      continue\n\n    yield record\n\n  if take_ownership:\n    f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating WETRecords from filepath.", "response": "def wet_records(wet_filepath):\n  \"\"\"Generate WETRecords from filepath.\"\"\"\n  if wet_filepath.endswith('.gz'):\n    fopen = gzip.open\n  else:\n    fopen = tf.gfile.GFile\n\n  with fopen(wet_filepath) as f:\n    for record in wet_records_from_file_obj(f):\n      yield record"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filter_paragraph(p):\n  # Expect a minimum number of words.\n  tokens = p.split()\n  if len(tokens) < 6:\n    return True\n\n  # Require some letters.\n  if not re.search(_SOME_ALPHA_RE, p):\n    return True\n\n  # Keep this one at the end, probably the most complicated logic.\n  # We try to detect sentences, which should have a minimum of 3 tokens\n  # with only alphabetic characters.\n  last = 0\n  found_sentence = False\n  num_alpha = 0\n  for i, x in enumerate(tokens):\n    if x == '.':\n      if i - last > 3 and num_alpha >= 3:\n        found_sentence = True\n        break\n      last = i\n      num_alpha = 0\n    if re.match(_ONLY_ALPHA_RE, x):\n      num_alpha += 1\n  if not found_sentence:\n    return True\n\n  return False", "response": "Simple filter to remove obviously bad paragraphs."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef timing(name=''):\n  start = datetime.datetime.now()\n  timestamp = start.strftime('%H:%M')\n  tf.logging.info('Starting job [%s] at %s', name, timestamp)\n  yield\n  end = datetime.datetime.now()\n  timestamp = end.strftime('%H:%M')\n  tf.logging.info('Finished job [%s] at %s', name, timestamp)\n  duration = end - start\n  duration_mins = duration.total_seconds() / 60\n  tf.logging.info('Total time [%s] (m): %d', name, int(duration_mins))", "response": "Log start end and duration."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(cls, f):\n    url = None\n\n    line = f.readline()\n    if not line:\n      # EOF\n      return None\n    while not line.startswith(cls.LENGTH_HEADER):\n      if line.startswith(cls.URI_HEADER):\n        url = line[len(cls.URI_HEADER):].strip()\n      line = f.readline()\n\n    # Consume empty separator\n    f.readline()\n\n    # Read content\n    length = int(line.split(':')[1])\n\n    return cls(url, length)", "response": "Read header from file. Headers end with length and then 1 blank line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read(cls, f):\n    header = WETHeader.read(f)\n    if header is None:\n      # EOF\n      return None\n    content = f.read(header.length)\n\n    # Consume empty separators\n    f.readline()\n    f.readline()\n\n    return cls(header.url, content)", "response": "Read WETRecord from file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef MLP(num_hidden_layers=2,\n        hidden_size=512,\n        activation_fn=layers.Relu,\n        num_output_classes=10,\n        mode=\"train\"):\n  \"\"\"Multi-layer feed-forward neural network with non-linear activations.\"\"\"\n  del mode\n  cur_layers = [layers.Flatten()]\n  for _ in range(num_hidden_layers):\n    cur_layers += [layers.Dense(hidden_size), activation_fn()]\n  cur_layers += [layers.Dense(num_output_classes), layers.LogSoftmax()]\n  return layers.Serial(*cur_layers)", "response": "Multi - layer feed - forward neural network with non - linear activations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _verify_same_spaces(self):\n\n    # Pre-conditions: self._envs is initialized.\n\n    if self._envs is None:\n      raise ValueError(\"Environments not initialized.\")\n\n    if not isinstance(self._envs, list):\n      tf.logging.warning(\"Not checking observation and action space \"\n                         \"compatibility across envs, since there is just one.\")\n      return\n\n    # NOTE: We compare string representations of observation_space and\n    # action_space because compositional classes like space.Tuple don't return\n    # true on object comparison.\n\n    if not all(\n        str(env.observation_space) == str(self.observation_space)\n        for env in self._envs):\n      err_str = (\"All environments should have the same observation space, but \"\n                 \"don't.\")\n      tf.logging.error(err_str)\n      # Log all observation spaces.\n      for i, env in enumerate(self._envs):\n        tf.logging.error(\"Env[%d] has observation space [%s]\", i,\n                         env.observation_space)\n      raise ValueError(err_str)\n\n    if not all(\n        str(env.action_space) == str(self.action_space) for env in self._envs):\n      err_str = \"All environments should have the same action space, but don't.\"\n      tf.logging.error(err_str)\n      # Log all action spaces.\n      for i, env in enumerate(self._envs):\n        tf.logging.error(\"Env[%d] has action space [%s]\", i, env.action_space)\n      raise ValueError(err_str)", "response": "Verifies that all the envs have the same observation and action space."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef initialize_environments(self, batch_size=1):\n    assert batch_size >= 1\n    self._batch_size = batch_size\n\n    self._envs = [gym.make(self.base_env_name) for _ in range(batch_size)]\n    if self._env_wrapper_fn is not None:\n      self._envs = list(map(self._env_wrapper_fn, self._envs))\n\n    # If self.observation_space and self.action_space aren't None, then it means\n    # that this is a re-initialization of this class, in that case make sure\n    # that this matches our previous behaviour.\n    if self._observation_space:\n      assert str(self._observation_space) == str(\n          self._envs[0].observation_space)\n    else:\n      # This means that we are initializing this class for the first time.\n      #\n      # We set this equal to the first env's observation space, later on we'll\n      # verify that all envs have the same observation space.\n      self._observation_space = self._envs[0].observation_space\n\n    # Similarly for action_space\n    if self._action_space:\n      assert str(self._action_space) == str(self._envs[0].action_space)\n    else:\n      self._action_space = self._envs[0].action_space\n\n    self._verify_same_spaces()\n\n    # If self.reward_range is None, i.e. this means that we should take the\n    # reward range of the env.\n    if self.reward_range is None:\n      self._reward_range = self._envs[0].reward_range\n\n    # This data structure stores the history of each env.\n    #\n    # NOTE: Even if the env is a NN and can step in all batches concurrently, it\n    # is still valuable to store the trajectories separately.\n    self._trajectories = trajectory.BatchTrajectory(batch_size=batch_size)", "response": "Initializes the environments and trajectories."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_rewards(self, rewards):\n\n    min_reward, max_reward = self.reward_range\n\n    # Clips at min and max reward.\n    rewards = np.clip(rewards, min_reward, max_reward)\n    # Round to (nearest) int and convert to integral type.\n    rewards = np.around(rewards, decimals=0).astype(np.int64)\n    return rewards", "response": "Clips rounds and changes to integer type."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef num_rewards(self):\n\n    # Pre-conditions: reward range is finite.\n    #               : processed rewards are discrete.\n    if not self.is_reward_range_finite:\n      tf.logging.error(\"Infinite reward range, `num_rewards returning None`\")\n      return None\n    if not self.is_processed_rewards_discrete:\n      tf.logging.error(\n          \"Processed rewards are not discrete, `num_rewards` returning None\")\n      return None\n\n    min_reward, max_reward = self.reward_range\n    return max_reward - min_reward + 1", "response": "Returns the number of distinct rewards."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _reset(self, indices):\n\n    # Pre-conditions: common_preconditions, see `assert_common_preconditions`.\n    self.assert_common_preconditions()\n\n    # This returns a numpy array with first dimension `len(indices)` and the\n    # rest being the dimensionality of the observation.\n    return np.stack([self._envs[index].reset() for index in indices])", "response": "Resets the environments at indices should not pre - process or record."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reset(self, indices=None):\n\n    if indices is None:\n      indices = np.arange(self.trajectories.batch_size)\n\n    # If this is empty (not None) then don't do anything, no env was done.\n    if indices.size == 0:\n      tf.logging.warning(\n          \"`reset` called with empty indices array, this is a no-op.\")\n      return None\n\n    observations = self._reset(indices)\n    processed_observations = self.process_observations(observations)\n\n    # Record history.\n    self.trajectories.reset(indices, observations)\n\n    return processed_observations", "response": "Resets the environment at given indices."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _step(self, actions):\n\n    # Pre-conditions: common_preconditions, see `assert_common_preconditions`.\n    #               : len(actions) == len(self._envs)\n    self.assert_common_preconditions()\n    assert len(actions) == len(self._envs)\n\n    observations = []\n    rewards = []\n    dones = []\n    infos = []\n\n    # Take steps in all environments.\n    for env, action in zip(self._envs, actions):\n      observation, reward, done, info = env.step(action)\n\n      observations.append(observation)\n      rewards.append(reward)\n      dones.append(done)\n      infos.append(info)\n\n    # Convert each list (observations, rewards, ...) into np.array and return a\n    # tuple.\n    return tuple(map(np.stack, [observations, rewards, dones, infos]))", "response": "Takes a step in all environments should not pre - process or record."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef step(self, actions):\n\n    observations, raw_rewards, dones, infos = self._step(actions)\n\n    # Process rewards.\n    raw_rewards = raw_rewards.astype(np.float32)\n    processed_rewards = self.process_rewards(raw_rewards)\n\n    # Process observations.\n    processed_observations = self.process_observations(observations)\n\n    # Record history.\n    self.trajectories.step(processed_observations, raw_rewards,\n                           processed_rewards, dones, actions)\n\n    return processed_observations, processed_rewards, dones, infos", "response": "Takes a step in all environments and processes rewards and record history."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a tuple of data fields and data items to decoders.", "response": "def example_reading_spec(self):\n    \"\"\"Data fields to store on disk and their decoders.\"\"\"\n\n    # Subclasses can override and/or extend.\n\n    processed_reward_type = tf.float32\n    if self.is_processed_rewards_discrete:\n      processed_reward_type = tf.int64\n\n    data_fields = {\n        TIMESTEP_FIELD: tf.FixedLenFeature((1,), tf.int64),\n        RAW_REWARD_FIELD: tf.FixedLenFeature((1,), tf.float32),\n        PROCESSED_REWARD_FIELD: tf.FixedLenFeature((1,), processed_reward_type),\n        DONE_FIELD: tf.FixedLenFeature((1,), tf.int64),  # we wrote this as int.\n\n        # Special treatment because we need to determine type and shape, also\n        # enables classes to override.\n        OBSERVATION_FIELD: self.observation_spec,\n        ACTION_FIELD: self.action_spec,\n    }\n\n    data_items_to_decoders = {\n        field: tf.contrib.slim.tfexample_decoder.Tensor(field)\n        for field in data_fields\n    }\n\n    return data_fields, data_items_to_decoders"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _generate_time_steps(self, trajectory_list):\n    for single_trajectory in trajectory_list:\n      assert isinstance(single_trajectory, trajectory.Trajectory)\n\n      # Skip writing trajectories that have only a single time-step -- this\n      # could just be a repeated reset.\n\n      if single_trajectory.num_time_steps <= 1:\n        continue\n\n      for index, time_step in enumerate(single_trajectory.time_steps):\n\n        # The first time-step doesn't have reward/processed_reward, if so, just\n        # setting it to 0.0 / 0 should be OK.\n        raw_reward = time_step.raw_reward\n        if not raw_reward:\n          raw_reward = 0.0\n\n        processed_reward = time_step.processed_reward\n        if not processed_reward:\n          processed_reward = 0\n\n        action = time_step.action\n        if action is None:\n          # The last time-step doesn't have action, and this action shouldn't be\n          # used, gym's spaces have a `sample` function, so let's just sample an\n          # action and use that.\n          action = self.action_space.sample()\n        action = gym_spaces_utils.gym_space_encode(self.action_space, action)\n\n        if six.PY3:\n          # py3 complains that, to_example cannot handle np.int64 !\n\n          action_dtype = self.action_space.dtype\n          if action_dtype in [np.int64, np.int32]:\n            action = list(map(int, action))\n          elif action_dtype in [np.float64, np.float32]:\n            action = list(map(float, action))\n\n          # same with processed_reward.\n          processed_reward = int(processed_reward)\n\n        assert time_step.observation is not None\n\n        yield {\n            TIMESTEP_FIELD: [index],\n            ACTION_FIELD:\n                action,\n            # to_example errors on np.float32\n            RAW_REWARD_FIELD: [float(raw_reward)],\n            PROCESSED_REWARD_FIELD: [processed_reward],\n            # to_example doesn't know bools\n            DONE_FIELD: [int(time_step.done)],\n            OBSERVATION_FIELD:\n                gym_spaces_utils.gym_space_encode(self.observation_space,\n                                                  time_step.observation),\n        }", "response": "A generator to yield single time - steps from a list of trajectories."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init_vq_bottleneck(bottleneck_size, hidden_size):\n  means = tf.get_variable(\n      name=\"means\",\n      shape=[bottleneck_size, hidden_size],\n      initializer=tf.uniform_unit_scaling_initializer())\n  ema_count = tf.get_variable(\n      name=\"ema_count\",\n      shape=[bottleneck_size],\n      initializer=tf.constant_initializer(0),\n      trainable=False)\n  with tf.colocate_with(means):\n    ema_means = tf.get_variable(\n        name=\"ema_means\",\n        initializer=means.initialized_value(),\n        trainable=False)\n\n  return means, ema_means, ema_count", "response": "Initialize the lookup table for VQ bottleneck."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the nearest element in means to elements in x.", "response": "def vq_nearest_neighbor(x, hparams):\n  \"\"\"Find the nearest element in means to elements in x.\"\"\"\n  bottleneck_size = 2**hparams.bottleneck_bits\n  means = hparams.means\n  x_norm_sq = tf.reduce_sum(tf.square(x), axis=-1, keepdims=True)\n  means_norm_sq = tf.reduce_sum(tf.square(means), axis=-1, keepdims=True)\n  scalar_prod = tf.matmul(x, means, transpose_b=True)\n  dist = x_norm_sq + tf.transpose(means_norm_sq) - 2 * scalar_prod\n  if hparams.bottleneck_kind == \"em\":\n    x_means_idx = tf.multinomial(-dist, num_samples=hparams.num_samples)\n    x_means_hot = tf.one_hot(\n        x_means_idx, depth=bottleneck_size)\n    x_means_hot = tf.reduce_mean(x_means_hot, axis=1)\n  else:\n    x_means_idx = tf.argmax(-dist, axis=-1)\n    x_means_hot = tf.one_hot(x_means_idx, depth=bottleneck_size)\n  x_means = tf.matmul(x_means_hot, means)\n  e_loss = tf.reduce_mean(tf.squared_difference(x, tf.stop_gradient(x_means)))\n  return x_means_hot, e_loss"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compress(x, hparams, name):\n  with tf.variable_scope(name):\n    # Run compression by strided convs.\n    cur = x\n    k1 = (3, 1)\n    k2 = (2, 1)\n    cur = residual_conv(cur, hparams.num_compress_steps, k1, hparams, \"rc\")\n    for i in range(hparams.num_compress_steps):\n      cur = common_layers.conv_block(\n          cur,\n          hparams.hidden_size, [((1, 1), k2)],\n          strides=k2,\n          name=\"compress_%d\" % i)\n    return cur", "response": "Compress the input tensor x using strided convs."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_latent_pred_loss(latents_pred, latents_discrete_hot, hparams):\n  latents_logits = tf.layers.dense(\n      latents_pred, 2**hparams.bottleneck_bits, name=\"extra_logits\")\n  loss = tf.nn.softmax_cross_entropy_with_logits_v2(\n      labels=tf.stop_gradient(latents_discrete_hot), logits=latents_logits)\n  return loss", "response": "Get the loss for a given set of latents."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset of hyperparameters for transformer_nat_big.", "response": "def transformer_nat_small():\n  \"\"\"Set of hyperparameters.\"\"\"\n  hparams = transformer.transformer_small()\n  hparams.batch_size = 2048\n  hparams.learning_rate = 0.2\n  hparams.learning_rate_warmup_steps = 4000\n  hparams.num_hidden_layers = 3\n  hparams.hidden_size = 384\n  hparams.filter_size = 2048\n  hparams.label_smoothing = 0.0\n  hparams.force_full_predict = True\n  hparams.optimizer = \"adam\"\n  hparams.optimizer_adam_epsilon = 1e-9\n  hparams.optimizer_adam_beta1 = 0.9\n  hparams.optimizer_adam_beta2 = 0.997\n  hparams.add_hparam(\"bottleneck_kind\", \"vq\")\n  hparams.add_hparam(\"bottleneck_bits\", 12)\n  hparams.add_hparam(\"num_compress_steps\", 3)\n  hparams.add_hparam(\"beta\", 0.25)\n  hparams.add_hparam(\"epsilon\", 1e-5)\n  hparams.add_hparam(\"decay\", 0.999)\n  hparams.add_hparam(\"num_samples\", 10)\n  hparams.add_hparam(\"mask_startup_steps\", 50000)\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef policy_net(rng_key,\n               batch_observations_shape,\n               num_actions,\n               bottom_layers=None):\n  \"\"\"A policy net function.\"\"\"\n  # Use the bottom_layers as the bottom part of the network and just add the\n  # required layers on top of it.\n  if bottom_layers is None:\n    bottom_layers = []\n\n  # NOTE: The LogSoftmax instead of the Softmax.\n  bottom_layers.extend([layers.Dense(num_actions), layers.LogSoftmax()])\n  net = layers.Serial(*bottom_layers)\n\n  return net.initialize(batch_observations_shape, rng_key), net", "response": "A policy net function."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef value_net(rng_key,\n              batch_observations_shape,\n              num_actions,\n              bottom_layers=None):\n  \"\"\"A value net function.\"\"\"\n  del num_actions\n\n  if bottom_layers is None:\n    bottom_layers = []\n  bottom_layers.extend([\n      layers.Dense(1),\n  ])\n  net = layers.Serial(*bottom_layers)\n  return net.initialize(batch_observations_shape, rng_key), net", "response": "A value net function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef policy_and_value_net(rng_key,\n                         batch_observations_shape,\n                         num_actions,\n                         bottom_layers=None):\n  \"\"\"A policy and value net function.\"\"\"\n\n  # Layers.\n  cur_layers = []\n  if bottom_layers is not None:\n    cur_layers.extend(bottom_layers)\n\n  # Now, with the current logits, one head computes action probabilities and the\n  # other computes the value function.\n  # NOTE: The LogSoftmax instead of the Softmax because of numerical stability.\n  cur_layers.extend([layers.Branch(), layers.Parallel(\n      layers.Serial(layers.Dense(num_actions), layers.LogSoftmax()),\n      layers.Dense(1)\n  )])\n  net = layers.Serial(*cur_layers)\n  return net.initialize(batch_observations_shape, rng_key), net", "response": "A policy and value net function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef log_params(params, name=\"params\"):\n  for i, param in enumerate(params):\n    if not param:\n      # Empty tuple.\n      continue\n    if not isinstance(param, (list, tuple)):\n      logging.error(\n          \"%s[%d] : (%s) = [%s]\", name, i, param.shape, onp.array(param))\n    else:\n      for j, p in enumerate(param):\n        logging.error(\n            \"\\t%s[%d, %d] = [%s]\", name, i, j, onp.array(p))", "response": "Dumps the params with logging. error."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef collect_trajectories(env,\n                         policy_fun,\n                         num_trajectories=1,\n                         policy=\"greedy\",\n                         max_timestep=None,\n                         epsilon=0.1):\n  \"\"\"Collect trajectories with the given policy net and behaviour.\n\n  Args:\n    env: A gym env interface, for now this is not-batched.\n    policy_fun: observations(B,T+1) -> log-probabs(B,T+1, A) callable.\n    num_trajectories: int, number of trajectories.\n    policy: string, \"greedy\", \"epsilon-greedy\", or \"categorical-sampling\" i.e.\n        how to use the policy_fun to return an action.\n    max_timestep: int or None, the index of the maximum time-step at which we\n        return the trajectory, None for ending a trajectory only when env\n        returns done.\n    epsilon: float, the epsilon for `epsilon-greedy` policy.\n\n  Returns:\n    trajectory: list of (observation, action, reward) tuples, where each element\n    `i` is a tuple of numpy arrays with shapes as follows:\n    observation[i] = (B, T_i + 1)\n    action[i] = (B, T_i)\n    reward[i] = (B, T_i)\n  \"\"\"\n  trajectories = []\n\n  for t in range(num_trajectories):\n    t_start = time.time()\n    rewards = []\n    actions = []\n    done = False\n\n    observation = env.reset()\n\n    # This is currently shaped (1, 1) + OBS, but new observations will keep\n    # getting added to it, making it eventually (1, T+1) + OBS\n    observation_history = observation[np.newaxis, np.newaxis, :]\n\n    # Run either till we're done OR if max_timestep is defined only till that\n    # timestep.\n    ts = 0\n    while ((not done) and\n           (not max_timestep or observation_history.shape[1] < max_timestep)):\n      ts_start = time.time()\n      # Run the policy, to pick an action, shape is (1, t, A) because\n      # observation_history is shaped (1, t) + OBS\n      predictions = policy_fun(observation_history)\n\n      # We need the predictions for the last time-step, so squeeze the batch\n      # dimension and take the last time-step.\n      predictions = np.squeeze(predictions, axis=0)[-1]\n\n      # Policy can be run in one of the following ways:\n      #  - Greedy\n      #  - Epsilon-Greedy\n      #  - Categorical-Sampling\n      action = None\n      if policy == \"greedy\":\n        action = np.argmax(predictions)\n      elif policy == \"epsilon-greedy\":\n        # A schedule for epsilon is 1/k where k is the episode number sampled.\n        if onp.random.random() < epsilon:\n          # Choose an action at random.\n          action = onp.random.randint(0, high=len(predictions))\n        else:\n          # Return the best action.\n          action = np.argmax(predictions)\n      elif policy == \"categorical-sampling\":\n        # NOTE: The predictions aren't probabilities but log-probabilities\n        # instead, since they were computed with LogSoftmax.\n        # So just np.exp them to make them probabilities.\n        predictions = np.exp(predictions)\n        action = onp.argwhere(onp.random.multinomial(1, predictions) == 1)\n      else:\n        raise ValueError(\"Unknown policy: %s\" % policy)\n\n      # NOTE: Assumption, single batch.\n      try:\n        action = int(action)\n      except TypeError as err:\n        # Let's dump some information before we die off.\n        logging.error(\"Cannot convert action into an integer: [%s]\", err)\n        logging.error(\"action.shape: [%s]\", action.shape)\n        logging.error(\"action: [%s]\", action)\n        logging.error(\"predictions.shape: [%s]\", predictions.shape)\n        logging.error(\"predictions: [%s]\", predictions)\n        logging.error(\"observation_history: [%s]\", observation_history)\n        raise err\n\n      observation, reward, done, _ = env.step(action)\n\n      # observation is of shape OBS, so add extra dims and concatenate on the\n      # time dimension.\n      observation_history = np.concatenate(\n          [observation_history, observation[np.newaxis, np.newaxis, :]], axis=1)\n\n      rewards.append(reward)\n      actions.append(action)\n\n      ts += 1\n      logging.vlog(\n          2, \"  Collected time-step[ %5d] of trajectory[ %5d] in [%0.2f] msec.\",\n          ts, t, get_time(ts_start))\n    logging.vlog(\n        2, \" Collected trajectory[ %5d] in [%0.2f] msec.\", t, get_time(t_start))\n\n    # This means we are done we're been terminated early.\n    assert done or (\n        max_timestep and max_timestep >= observation_history.shape[1])\n    # observation_history is (1, T+1) + OBS, lets squeeze out the batch dim.\n    observation_history = np.squeeze(observation_history, axis=0)\n    trajectories.append(\n        (observation_history, np.stack(actions), np.stack(rewards)))\n\n  return trajectories", "response": "Collect trajectories with the given policy net and behaviour."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_padding_value(dtype):\n  padding_value = None\n  if dtype == np.uint8:\n    padding_value = np.uint8(0)\n  elif dtype == np.uint16:\n    padding_value = np.uint16(0)\n  elif dtype == np.float32:\n    padding_value = 0.0\n  else:\n    padding_value = 0\n  assert padding_value is not None\n  return padding_value", "response": "Returns the padding value given a dtype."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npad the given list of trajectories to a multiple of boundary.", "response": "def pad_trajectories(trajectories, boundary=20):\n  \"\"\"Pad trajectories to a bucket length that is a multiple of boundary.\n\n  Args:\n    trajectories: list[(observation, actions, rewards)], where each observation\n      is shaped (t+1,) + OBS and actions & rewards are shaped (t,), with the\n      length of the list being B (batch size).\n    boundary: int, bucket length, the actions and rewards are padded to integer\n      multiples of boundary.\n\n  Returns:\n    tuple: (padding lengths, reward_mask, padded_observations, padded_actions,\n        padded_rewards) where padded_observations is shaped (B, T+1) + OBS and\n        padded_actions, padded_rewards & reward_mask are shaped (B, T).\n        Where T is max(t) rounded up to an integer multiple of boundary.\n        padded_length is how much padding we've added and\n        reward_mask is 1s for actual rewards and 0s for the padding.\n  \"\"\"\n\n  # Let's compute max(t) over all trajectories.\n  t_max = max(r.shape[0] for (_, _, r) in trajectories)\n\n  # t_max is rounded to the next multiple of `boundary`\n  boundary = int(boundary)\n  bucket_length = boundary * int(np.ceil(float(t_max) / boundary))\n\n  # So all obs will be padded to t_max + 1 and actions and rewards to t_max.\n  padded_observations = []\n  padded_actions = []\n  padded_rewards = []\n  padded_lengths = []\n  reward_masks = []\n  for (o, a, r) in trajectories:\n    # Determine the amount to pad, this holds true for obs, actions and rewards.\n    num_to_pad = bucket_length + 1 - o.shape[0]\n    padded_lengths.append(num_to_pad)\n    if num_to_pad == 0:\n      padded_observations.append(o)\n      padded_actions.append(a)\n      padded_rewards.append(r)\n      reward_masks.append(onp.ones_like(r, dtype=np.int32))\n      continue\n\n    # First pad observations.\n    padding_config = [(0, num_to_pad, 0)]\n    for _ in range(o.ndim - 1):\n      padding_config.append((0, 0, 0))\n    padding_config = tuple(padding_config)\n\n    padding_value = get_padding_value(o.dtype)\n    action_padding_value = get_padding_value(a.dtype)\n    reward_padding_value = get_padding_value(r.dtype)\n\n    padded_obs = lax.pad(o, padding_value, padding_config)\n    padded_observations.append(padded_obs)\n\n    # Now pad actions and rewards.\n    assert a.ndim == 1 and r.ndim == 1\n    padding_config = ((0, num_to_pad, 0),)\n\n    padded_action = lax.pad(a, action_padding_value, padding_config)\n    padded_actions.append(padded_action)\n    padded_reward = lax.pad(r, reward_padding_value, padding_config)\n    padded_rewards.append(padded_reward)\n\n    # Also create the mask to use later.\n    reward_mask = onp.ones_like(r, dtype=np.int32)\n    reward_masks.append(lax.pad(reward_mask, 0, padding_config))\n\n  return padded_lengths, np.stack(reward_masks), np.stack(\n      padded_observations), np.stack(padded_actions), np.stack(padded_rewards)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rewards_to_go(rewards, mask, gamma=0.99):\n  B, T = rewards.shape  # pylint: disable=invalid-name,unused-variable\n\n  masked_rewards = rewards * mask  # (B, T)\n\n  # We use the following recurrence relation, derived from the equation above:\n  #\n  # r2g[t+1] = (r2g[t] - r[t]) / gamma\n  #\n  # This means we'll need to calculate r2g[0] first and then r2g[1] and so on ..\n  #\n  # **However** this leads to overflows for long sequences: r2g[t] - r[t] > 0\n  # and gamma < 1.0, so the division keeps increasing.\n  #\n  # So we just run the recurrence in reverse, i.e.\n  #\n  # r2g[t] = r[t] + (gamma*r2g[t+1])\n  #\n  # This is much better, but might have lost updates since the (small) rewards\n  # at earlier time-steps may get added to a (very?) large sum.\n\n  # Compute r2g_{T-1} at the start and then compute backwards in time.\n  r2gs = [masked_rewards[:, -1]]\n\n  # Go from T-2 down to 0.\n  for t in reversed(range(T - 1)):\n    r2gs.append(masked_rewards[:, t] + (gamma * r2gs[-1]))\n\n  # The list should have length T.\n  assert T == len(r2gs)\n\n  # First we stack them in the correct way to make it (B, T), but these are\n  # still from newest (T-1) to oldest (0), so then we flip it on time axis.\n  return np.flip(np.stack(r2gs, axis=1), axis=1)", "response": "r Computes the rewards to go."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef value_loss(value_net_apply,\n               value_net_params,\n               observations,\n               rewards,\n               reward_mask,\n               gamma=0.99):\n  \"\"\"Computes the value loss.\n\n  Args:\n    value_net_apply: value net apply function with signature (params, ndarray of\n      shape (B, T+1) + OBS) -> ndarray(B, T+1, 1)\n    value_net_params: params of value_net_apply.\n    observations: np.ndarray of shape (B, T+1) + OBS\n    rewards: np.ndarray of shape (B, T) of rewards.\n    reward_mask: np.ndarray of shape (B, T), the mask over rewards.\n    gamma: float, discount factor.\n\n  Returns:\n    The average L2 value loss, averaged over instances where reward_mask is 1.\n  \"\"\"\n\n  B, T = rewards.shape  # pylint: disable=invalid-name\n  assert (B, T + 1) == observations.shape[:2]\n\n  # NOTE: observations is (B, T+1) + OBS, value_prediction is (B, T+1, 1)\n  value_prediction = value_net_apply(observations, value_net_params)\n  assert (B, T + 1, 1) == value_prediction.shape\n\n  return value_loss_given_predictions(value_prediction, rewards, reward_mask,\n                                      gamma)", "response": "Computes the value loss given the value net parameters and the rewards."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the value loss given the prediction of the value function.", "response": "def value_loss_given_predictions(value_prediction,\n                                 rewards,\n                                 reward_mask,\n                                 gamma=0.99):\n  \"\"\"Computes the value loss given the prediction of the value function.\n\n  Args:\n    value_prediction: np.ndarray of shape (B, T+1, 1)\n    rewards: np.ndarray of shape (B, T) of rewards.\n    reward_mask: np.ndarray of shape (B, T), the mask over rewards.\n    gamma: float, discount factor.\n\n  Returns:\n    The average L2 value loss, averaged over instances where reward_mask is 1.\n  \"\"\"\n\n  B, T = rewards.shape  # pylint: disable=invalid-name\n  assert (B, T) == reward_mask.shape\n  assert (B, T + 1, 1) == value_prediction.shape\n\n  value_prediction = np.squeeze(value_prediction, axis=2)  # (B, T+1)\n  value_prediction = value_prediction[:, :-1] * reward_mask  # (B, T)\n  r2g = rewards_to_go(rewards, reward_mask, gamma=gamma)  # (B, T)\n  loss = (value_prediction - r2g)**2\n\n  # Take an average on only the points where mask != 0.\n  return np.sum(loss) / np.sum(reward_mask)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gae_advantages(td_deltas, mask, lambda_=0.95, gamma=0.99):\n\n  return rewards_to_go(td_deltas, mask, lambda_ * gamma)", "response": "r Computes the GAE advantages given the one step TD - residuals."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef chosen_probabs(probab_observations, actions):\n  B, T = actions.shape  # pylint: disable=invalid-name\n  assert (B, T + 1) == probab_observations.shape[:2]\n  return probab_observations[np.arange(B)[:, None], np.arange(T), actions]", "response": "Picks out the probabilities of the actions along batch and time - steps."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compute_probab_ratios(p_new, p_old, actions, reward_mask):\n\n  B, T = actions.shape  # pylint: disable=invalid-name\n  assert (B, T + 1) == p_old.shape[:2]\n  assert (B, T + 1) == p_new.shape[:2]\n\n  logp_old = chosen_probabs(p_old, actions)\n  logp_new = chosen_probabs(p_new, actions)\n\n  assert (B, T) == logp_old.shape\n  assert (B, T) == logp_new.shape\n\n  # Since these are log-probabilities, we just subtract them.\n  probab_ratios = np.exp(logp_new - logp_old) * reward_mask\n  assert (B, T) == probab_ratios.shape\n  return probab_ratios", "response": "Computes the probability ratios for each time - step in a trajectory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ppo_loss(policy_net_apply,\n             new_policy_params,\n             old_policy_params,\n             value_net_apply,\n             value_net_params,\n             padded_observations,\n             padded_actions,\n             padded_rewards,\n             reward_mask,\n             gamma=0.99,\n             lambda_=0.95,\n             epsilon=0.2):\n  \"\"\"PPO objective, with an eventual minus sign, given observations.\"\"\"\n  B, T = padded_rewards.shape  # pylint: disable=invalid-name\n  assert (B, T + 1) == padded_observations.shape[:2]\n  assert (B, T) == padded_actions.shape\n  assert (B, T) == padded_rewards.shape\n  assert (B, T) == reward_mask.shape\n\n  # Compute predicted values and predicted log-probs and hand it over to\n  # `ppo_loss_given_predictions`.\n\n  # (B, T+1, 1)\n  predicted_values = value_net_apply(padded_observations, value_net_params)\n  assert (B, T + 1, 1) == predicted_values.shape\n\n  # log_probab_actions_{old,new} are both (B, T+1, A)\n  log_probab_actions_old = policy_net_apply(padded_observations,\n                                            old_policy_params)\n  log_probab_actions_new = policy_net_apply(padded_observations,\n                                            new_policy_params)\n  assert (B, T + 1) == log_probab_actions_old.shape[:2]\n  assert (B, T + 1) == log_probab_actions_new.shape[:2]\n  assert log_probab_actions_old.shape[-1] == log_probab_actions_new.shape[-1]\n\n  return ppo_loss_given_predictions(log_probab_actions_new,\n                                    log_probab_actions_old,\n                                    predicted_values,\n                                    padded_actions,\n                                    padded_rewards,\n                                    reward_mask,\n                                    gamma=gamma,\n                                    lambda_=lambda_,\n                                    epsilon=epsilon)", "response": "PPO objective, with an eventual minus sign, given observations."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the combined loss given predictions.", "response": "def combined_loss_given_predictions(log_probab_actions_new,\n                                    log_probab_actions_old,\n                                    value_prediction,\n                                    padded_actions,\n                                    padded_rewards,\n                                    reward_mask,\n                                    gamma=0.99,\n                                    lambda_=0.95,\n                                    epsilon=0.2,\n                                    c1=1.0,\n                                    c2=0.01):\n  \"\"\"Computes the combined (clipped loss + value loss) given predictions.\"\"\"\n  loss_value = value_loss_given_predictions(\n      value_prediction, padded_rewards, reward_mask, gamma=gamma)\n  loss_ppo = ppo_loss_given_predictions(log_probab_actions_new,\n                                        log_probab_actions_old,\n                                        value_prediction,\n                                        padded_actions,\n                                        padded_rewards,\n                                        reward_mask,\n                                        gamma=gamma,\n                                        lambda_=lambda_,\n                                        epsilon=epsilon)\n  # TODO(afrozm): Add the entropy bonus, but since we don't do that in T2T\n  # we'll skip if for now.\n  entropy_bonus = 0.0\n  return (loss_ppo + (c1 * loss_value) - (c2 * entropy_bonus), loss_ppo,\n          loss_value, entropy_bonus)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the combined loss given observations.", "response": "def combined_loss(new_params,\n                  old_params,\n                  policy_and_value_net_apply,\n                  padded_observations,\n                  padded_actions,\n                  padded_rewards,\n                  reward_mask,\n                  gamma=0.99,\n                  lambda_=0.95,\n                  epsilon=0.2,\n                  c1=1.0,\n                  c2=0.01):\n  \"\"\"Computes the combined (clipped loss + value loss) given observations.\"\"\"\n  log_probab_actions_new, value_predictions = policy_and_value_net_apply(\n      padded_observations, new_params)\n\n  log_probab_actions_old, _ = policy_and_value_net_apply(\n      padded_observations, old_params)\n\n  # (combined_loss, ppo_loss, value_loss, entropy_bonus)\n  return combined_loss_given_predictions(log_probab_actions_new,\n                                         log_probab_actions_old,\n                                         value_predictions,\n                                         padded_actions,\n                                         padded_rewards,\n                                         reward_mask,\n                                         c1=c1,\n                                         c2=c2,\n                                         gamma=gamma,\n                                         lambda_=lambda_,\n                                         epsilon=epsilon)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef policy_and_value_opt_step(i,\n                              opt_state,\n                              opt_update,\n                              policy_and_value_net_apply,\n                              old_params,\n                              padded_observations,\n                              padded_actions,\n                              padded_rewards,\n                              reward_mask,\n                              c1=1.0,\n                              c2=0.01,\n                              gamma=0.99,\n                              lambda_=0.95,\n                              epsilon=0.1):\n  \"\"\"Policy and Value optimizer step.\"\"\"\n  # Combined loss function given the new params.\n  def policy_and_value_loss(params):\n    \"\"\"Returns the combined loss given just parameters.\"\"\"\n    (loss, _, _, _) = combined_loss(\n        params,\n        old_params,\n        policy_and_value_net_apply,\n        padded_observations,\n        padded_actions,\n        padded_rewards,\n        reward_mask,\n        c1=c1,\n        c2=c2,\n        gamma=gamma,\n        lambda_=lambda_,\n        epsilon=epsilon)\n    return loss\n\n  new_params = trax_opt.get_params(opt_state)\n  g = grad(policy_and_value_loss)(new_params)\n  return opt_update(i, g, opt_state)", "response": "This function is called by the optimizer step in the optimizer code. It is called by the optimizer code to update the state of the optimizer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the training loop for PPO with fixed policy and value nets.", "response": "def training_loop(env=None,\n                  env_name=\"CartPole-v0\",\n                  epochs=EPOCHS,\n                  policy_net_fun=None,\n                  value_net_fun=None,\n                  policy_and_value_net_fun=None,\n                  policy_optimizer_fun=None,\n                  value_optimizer_fun=None,\n                  policy_and_value_optimizer_fun=None,\n                  batch_size=BATCH_TRAJECTORIES,\n                  num_optimizer_steps=NUM_OPTIMIZER_STEPS,\n                  print_every_optimizer_steps=PRINT_EVERY_OPTIMIZER_STEP,\n                  boundary=20,\n                  max_timestep=None,\n                  random_seed=None,\n                  gamma=GAMMA,\n                  lambda_=LAMBDA,\n                  epsilon=EPSILON,\n                  c1=1.0,\n                  c2=0.01):\n  \"\"\"Runs the training loop for PPO, with fixed policy and value nets.\"\"\"\n  jax_rng_key = trax.get_random_number_generator_and_set_seed(random_seed)\n\n  value_losses = []\n  ppo_objective = []\n  combined_losses = []\n  average_rewards = []\n\n  env = env if env is not None else gym.make(env_name)\n\n  # Batch Observations Shape = [-1, -1] + OBS, because we will eventually call\n  # policy and value networks on shape [B, T] +_OBS\n  batch_observations_shape = (-1, -1) + env.observation_space.shape\n\n  assert isinstance(env.action_space, gym.spaces.Discrete)\n  num_actions = env.action_space.n\n\n  policy_and_value_net_params, policy_and_value_net_apply = None, None\n  policy_and_value_opt_state, policy_and_value_opt_update = None, None\n  policy_net_params, policy_net_apply = None, None\n  value_net_params, value_net_apply = None, None\n  if policy_and_value_net_fun is not None:\n    jax_rng_key, subkey = jax_random.split(jax_rng_key)\n\n    # Initialize the policy and value network.\n    policy_and_value_net_params, policy_and_value_net_apply = (\n        policy_and_value_net_fun(subkey, batch_observations_shape, num_actions))\n\n    # Initialize the optimizers.\n    policy_and_value_opt_state, policy_and_value_opt_update = (\n        policy_and_value_optimizer_fun(policy_and_value_net_params))\n  else:\n    # Initialize the policy and value functions.\n    assert policy_net_fun and value_net_fun\n    jax_rng_key, key1, key2 = jax_random.split(jax_rng_key, num=3)\n\n    policy_net_params, policy_net_apply = policy_net_fun(\n        key1, batch_observations_shape, num_actions)\n    value_net_params, value_net_apply = value_net_fun(key2,\n                                                      batch_observations_shape,\n                                                      num_actions)\n\n    # Initialize the optimizers.\n    ppo_opt_state, ppo_opt_update = policy_optimizer_fun(policy_net_params)\n    value_opt_state, value_opt_update = value_optimizer_fun(value_net_params)\n\n  # A function that will call the appropriate policy function with parameters.\n  def get_policy_output(observations):\n    if policy_net_apply is not None:\n      assert policy_net_params\n      return policy_net_apply(observations, policy_net_params)\n\n    assert policy_and_value_net_apply and policy_and_value_net_params\n    policy_predictions, unused_value_predictions = policy_and_value_net_apply(\n        observations, policy_and_value_net_params)\n    return policy_predictions\n\n  for i in range(epochs):\n    t = time.time()\n    t0 = t\n    logging.vlog(1, \"Epoch [% 6d] collecting trajectories.\", i)\n    trajs = collect_trajectories(\n        env,\n        policy_fun=get_policy_output,\n        num_trajectories=batch_size,\n        policy=POLICY,\n        max_timestep=max_timestep,\n        epsilon=(10.0 / (i + 10.0)))  # this is a different epsilon.\n\n    avg_reward = float(sum(np.sum(traj[2]) for traj in trajs)) / len(trajs)\n    max_reward = max(np.sum(traj[2]) for traj in trajs)\n    min_reward = min(np.sum(traj[2]) for traj in trajs)\n    average_rewards.append(avg_reward)\n\n    logging.vlog(1, \"Rewards average=[%0.2f], max=[%0.2f], min=[%0.2f]\",\n                 avg_reward, max_reward, min_reward)\n    logging.vlog(1, \"Collecting trajectories took %0.2f msec.\", get_time(t))\n    logging.vlog(1,\n                 \"Trajectory Length average=[%0.2f], max=[%0.2f], min=[%0.2f]\",\n                 float(sum(len(traj[0]) for traj in trajs)) / len(trajs),\n                 max(len(traj[0]) for traj in trajs),\n                 min(len(traj[0]) for traj in trajs))\n\n    t = time.time()\n    (_, reward_mask, padded_observations, padded_actions,\n     padded_rewards) = pad_trajectories(trajs, boundary=boundary)\n\n    logging.vlog(1, \"Padding trajectories took %0.2f msec.\", get_time(t))\n    logging.vlog(1, \"Padded Observations' shape [%s]\",\n                 str(padded_observations.shape))\n    logging.vlog(1, \"Padded Actions' shape [%s]\", str(padded_actions.shape))\n    logging.vlog(1, \"Padded Rewards' shape [%s]\", str(padded_rewards.shape))\n\n    # Some assertions.\n    B, T = padded_actions.shape  # pylint: disable=invalid-name\n    assert (B, T) == padded_rewards.shape\n    assert (B, T) == reward_mask.shape\n    assert (B, T + 1) == padded_observations.shape[:2]\n    assert (B, T + 1) + env.observation_space.shape == padded_observations.shape\n\n    # Linear annealing from 0.1 to 0.0\n    epsilon_schedule = epsilon if epochs == 1 else epsilon * (1.0 -\n                                                              (i /\n                                                               (epochs - 1)))\n\n    # Compute value and ppo losses.\n    cur_value_loss, cur_ppo_loss, cur_combined_loss = None, None, None\n    if policy_and_value_net_apply is not None:\n      t = time.time()\n      cur_combined_loss, cur_ppo_loss, cur_value_loss, _ = (\n          combined_loss(\n              policy_and_value_net_params,\n              policy_and_value_net_params,\n              policy_and_value_net_apply,\n              padded_observations,\n              padded_actions,\n              padded_rewards,\n              reward_mask,\n              gamma=gamma,\n              lambda_=lambda_,\n              epsilon=epsilon_schedule,\n              c1=c1,\n              c2=c2))\n      logging.vlog(\n          1, \"Calculating P&V loss [%10.2f(%10.2f, %10.2f)] took %0.2f msec.\",\n          cur_combined_loss, cur_value_loss, cur_ppo_loss, get_time(t))\n    else:\n      t = time.time()\n      cur_value_loss = value_loss(\n          value_net_apply,\n          value_net_params,\n          padded_observations,\n          padded_rewards,\n          reward_mask,\n          gamma=gamma)\n\n      logging.vlog(1, \"Calculating value loss took %0.2f msec.\", get_time(t))\n\n      t = time.time()\n      cur_ppo_loss = ppo_loss(\n          policy_net_apply,\n          policy_net_params,\n          policy_net_params,\n          value_net_apply,\n          value_net_params,\n          padded_observations,\n          padded_actions,\n          padded_rewards,\n          reward_mask,\n          gamma=gamma,\n          lambda_=lambda_,\n          epsilon=epsilon_schedule)\n      logging.vlog(1, \"Calculating PPO loss took %0.2f msec.\", get_time(t))\n\n    value_losses.append(cur_value_loss)\n    ppo_objective.append(-1.0 * cur_ppo_loss)\n    combined_losses.append(cur_combined_loss)\n\n    if policy_and_value_net_apply:\n      logging.vlog(1, \"Policy and Value Optimization\")\n      t1 = time.time()\n      for j in range(num_optimizer_steps):\n        t = time.time()\n        # Update the optimizer state.\n        policy_and_value_opt_state = policy_and_value_opt_step(\n            j,\n            policy_and_value_opt_state,\n            policy_and_value_opt_update,\n            policy_and_value_net_apply,\n            policy_and_value_net_params,\n            padded_observations,\n            padded_actions,\n            padded_rewards,\n            reward_mask,\n            c1=c1,\n            c2=c2,\n            gamma=gamma,\n            lambda_=lambda_,\n            epsilon=epsilon_schedule)\n        t2 = time.time()\n        # Get the new params.\n        new_policy_and_value_net_params = trax_opt.get_params(\n            policy_and_value_opt_state)\n        if ((j + 1) %\n            print_every_optimizer_steps == 0) or (j == num_optimizer_steps - 1):\n          # Compute and log the loss.\n          (loss_combined, loss_ppo, loss_value, unused_entropy_bonus) = (\n              combined_loss(\n                  new_policy_and_value_net_params,\n                  policy_and_value_net_params,  # old params\n                  policy_and_value_net_apply,\n                  padded_observations,\n                  padded_actions,\n                  padded_rewards,\n                  reward_mask,\n                  gamma=gamma,\n                  lambda_=lambda_,\n                  epsilon=epsilon_schedule,\n                  c1=c1,\n                  c2=c2))\n          logging.vlog(1, \"One Policy and Value grad desc took: %0.2f msec\",\n                       get_time(t, t2))\n          logging.vlog(\n              1,\n              \"Combined Loss(value, ppo) [%10.2f] -> [%10.2f(%10.2f,%10.2f)]\",\n              cur_combined_loss, loss_combined, loss_value, loss_ppo)\n        # Update the params.\n        policy_and_value_net_params = new_policy_and_value_net_params\n\n      logging.vlog(\n          1, \"Total PPO loss reduction [%0.2f]%%\",\n          (100 *\n           (cur_combined_loss - loss_combined) / np.abs(cur_combined_loss)))\n\n      logging.info(\n          \"Epoch [% 6d], Reward[min, max, avg] [%10.2f,%10.2f,%10.2f], Combined\"\n          \" Loss(value, ppo) [%10.2f(%10.2f,%10.2f)], took [%10.2f msec]\",\n          i, min_reward, max_reward, avg_reward, loss_combined, loss_value,\n          loss_ppo, get_time(t1))\n    else:\n      # Run optimizers.\n      logging.vlog(1, \"PPO Optimization\")\n      t1 = time.time()\n\n      for j in range(num_optimizer_steps):\n        t = time.time()\n        # Update the optimizer state.\n        ppo_opt_state = ppo_opt_step(\n            j,\n            ppo_opt_state,\n            ppo_opt_update,\n            policy_net_apply,\n            policy_net_params,\n            value_net_apply,\n            value_net_params,\n            padded_observations,\n            padded_actions,\n            padded_rewards,\n            reward_mask,\n            gamma=gamma,\n            lambda_=lambda_,\n            epsilon=epsilon_schedule,\n        )\n        t2 = time.time()\n        # Get the new params.\n        new_policy_net_params = trax_opt.get_params(ppo_opt_state)\n        if ((j + 1) %\n            print_every_optimizer_steps == 0) or (j == num_optimizer_steps - 1):\n          new_ppo_loss = ppo_loss(\n              policy_net_apply,\n              new_policy_net_params,\n              policy_net_params,\n              value_net_apply,\n              value_net_params,\n              padded_observations,\n              padded_actions,\n              padded_rewards,\n              reward_mask,\n              gamma=gamma,\n              lambda_=lambda_,\n              epsilon=epsilon_schedule,\n          )\n          logging.vlog(1, \"One PPO grad desc took: %0.2f msec\", get_time(t, t2))\n          logging.vlog(1, \"PPO loss [%10.2f] -> [%10.2f]\", cur_ppo_loss,\n                       new_ppo_loss)\n        # Update the params.\n        policy_net_params = new_policy_net_params\n\n      logging.vlog(1, \"Total PPO loss reduction [%0.2f]%%\",\n                   (100 * (cur_ppo_loss - new_ppo_loss) / np.abs(cur_ppo_loss)))\n\n      logging.vlog(1, \"Value Optimization\")\n\n      for j in range(num_optimizer_steps):\n        t = time.time()\n        value_opt_state = value_opt_step(\n            j,\n            value_opt_state,\n            value_opt_update,\n            value_net_apply,\n            padded_observations,\n            padded_rewards,\n            reward_mask,\n            gamma=gamma)\n        t2 = time.time()\n        value_net_params = trax_opt.get_params(value_opt_state)\n        if ((j + 1) %\n            print_every_optimizer_steps == 0) or (j == num_optimizer_steps - 1):\n          new_value_loss = value_loss(\n              value_net_apply,\n              value_net_params,\n              padded_observations,\n              padded_rewards,\n              reward_mask,\n              gamma=gamma)\n          logging.vlog(1, \"One value grad desc took: %0.2f msec\",\n                       get_time(t, t2))\n          logging.vlog(1, \"Value loss [%10.2f] -> [%10.2f]\", cur_value_loss,\n                       new_value_loss)\n      logging.vlog(1, \"Total value loss reduction [%0.2f]%%\",\n                   (100 *\n                    (cur_value_loss - new_value_loss) / np.abs(cur_value_loss)))\n\n      logging.vlog(1, \"Grad desc took %0.2f msec\", get_time(t1))\n\n      # Set the optimized params to new params.\n      policy_net_params = trax_opt.get_params(ppo_opt_state)\n      value_net_params = trax_opt.get_params(value_opt_state)\n\n      logging.info(\n          \"Epoch [% 6d], Reward[min, max, avg] [%10.2f,%10.2f,%10.2f], \"\n          \"ppo loss [%10.2f], value loss [%10.2f], took [%10.2f msec]\", i,\n          min_reward, max_reward, avg_reward, new_ppo_loss, new_value_loss,\n          get_time(t0))\n\n  # Log the parameters, just for the sake of it.\n  if policy_net_params:\n    log_params(policy_net_params, \"policy_net_params\")\n  if value_net_params:\n    log_params(value_net_params, \"value_net_params\")\n  if policy_and_value_net_params:\n    log_params(policy_and_value_net_params, \"policy_and_value_net_params\")\n\n  if value_losses:\n    logging.vlog(1, \"value_losses: %s\", np.stack(value_losses))\n  if ppo_objective:\n    logging.vlog(1, \"ppo_objective: %s\", np.stack(ppo_objective))\n  if average_rewards:\n    logging.vlog(1, \"average_rewards: %s\", average_rewards)\n\n  return ((policy_net_params, value_net_params), average_rewards,\n          np.stack(value_losses), np.stack(ppo_objective))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _maybe_download_corpora(tmp_dir):\n  mnli_filename = \"MNLI.zip\"\n  mnli_finalpath = os.path.join(tmp_dir, \"MNLI\")\n  if not tf.gfile.Exists(mnli_finalpath):\n    zip_filepath = generator_utils.maybe_download(\n        tmp_dir, mnli_filename, _MNLI_URL)\n    zip_ref = zipfile.ZipFile(zip_filepath, \"r\")\n    zip_ref.extractall(tmp_dir)\n    zip_ref.close()\n\n  return mnli_finalpath", "response": "Download corpora for multinli.\n \u00d7 MNLI."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate mnli examples. Args: filename: a string Yields: dictionaries containing \"premise\", \"hypothesis\" and \"label\" strings", "response": "def _example_generator(filename):\n  \"\"\"Generate mnli examples.\n\n  Args:\n    filename: a string\n  Yields:\n    dictionaries containing \"premise\", \"hypothesis\" and \"label\" strings\n  \"\"\"\n  for idx, line in enumerate(tf.gfile.Open(filename, \"rb\")):\n    if idx == 0: continue  # skip header\n    line = text_encoder.to_unicode_utf8(line.strip())\n    split_line = line.split(\"\\t\")\n    # Works for both splits even though dev has some extra human labels.\n    yield {\n        \"premise\": split_line[8],\n        \"hypothesis\": split_line[9],\n        \"label\": split_line[-1]\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef shake_shake_skip_connection(x, output_filters, stride, is_training):\n  curr_filters = common_layers.shape_list(x)[-1]\n  if curr_filters == output_filters:\n    return x\n  stride_spec = [1, stride, stride, 1]\n  # Skip path 1.\n  path1 = tf.nn.avg_pool(x, [1, 1, 1, 1], stride_spec, \"VALID\")\n  path1 = tf.layers.conv2d(\n      path1, int(output_filters / 2), (1, 1), padding=\"SAME\", name=\"path1_conv\")\n\n  # Skip path 2.\n  pad_arr = [[0, 0], [0, 1], [0, 1], [0, 0]]  # First pad with 0's then crop.\n  path2 = tf.pad(x, pad_arr)[:, 1:, 1:, :]\n  path2 = tf.nn.avg_pool(path2, [1, 1, 1, 1], stride_spec, \"VALID\")\n  path2 = tf.layers.conv2d(\n      path2, int(output_filters / 2), (1, 1), padding=\"SAME\", name=\"path2_conv\")\n\n  # Concat and apply BN.\n  final_path = tf.concat(values=[path1, path2], axis=-1)\n  final_path = tf.layers.batch_normalization(\n      final_path, training=is_training, name=\"final_path_bn\")\n  return final_path", "response": "Adds a residual connection to the filter x for the shake - shake model."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild a 2 branching convnet.", "response": "def shake_shake_branch(x, output_filters, stride, rand_forward, rand_backward,\n                       hparams):\n  \"\"\"Building a 2 branching convnet.\"\"\"\n  is_training = hparams.mode == tf.estimator.ModeKeys.TRAIN\n  x = tf.nn.relu(x)\n  x = tf.layers.conv2d(\n      x,\n      output_filters, (3, 3),\n      strides=(stride, stride),\n      padding=\"SAME\",\n      name=\"conv1\")\n  x = tf.layers.batch_normalization(x, training=is_training, name=\"bn1\")\n  x = tf.nn.relu(x)\n  x = tf.layers.conv2d(x, output_filters, (3, 3), padding=\"SAME\", name=\"conv2\")\n  x = tf.layers.batch_normalization(x, training=is_training, name=\"bn2\")\n  if is_training:\n    x = x * rand_backward + tf.stop_gradient(x * rand_forward -\n                                             x * rand_backward)\n  else:\n    x *= 1.0 / hparams.shake_shake_num_branches\n  return x"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef shake_shake_block(x, output_filters, stride, hparams):\n  is_training = hparams.mode == tf.estimator.ModeKeys.TRAIN\n  batch_size = common_layers.shape_list(x)[0]\n\n  # Generate random numbers for scaling the branches.\n  rand_forward = [\n      tf.random_uniform(\n          [batch_size, 1, 1, 1], minval=0, maxval=1, dtype=tf.float32)\n      for _ in range(hparams.shake_shake_num_branches)\n  ]\n  rand_backward = [\n      tf.random_uniform(\n          [batch_size, 1, 1, 1], minval=0, maxval=1, dtype=tf.float32)\n      for _ in range(hparams.shake_shake_num_branches)\n  ]\n  # Normalize so that all sum to 1.\n  total_forward = tf.add_n(rand_forward)\n  total_backward = tf.add_n(rand_backward)\n  rand_forward = [samp / total_forward for samp in rand_forward]\n  rand_backward = [samp / total_backward for samp in rand_backward]\n  zipped_rand = zip(rand_forward, rand_backward)\n\n  branches = []\n  for branch, (r_forward, r_backward) in enumerate(zipped_rand):\n    with tf.variable_scope(\"branch_{}\".format(branch)):\n      b = shake_shake_branch(x, output_filters, stride, r_forward, r_backward,\n                             hparams)\n      b = tf.nn.dropout(b, 1.0 - hparams.layer_prepostprocess_dropout)\n      branches.append(b)\n  res = shake_shake_skip_connection(x, output_filters, stride, is_training)\n  if hparams.shake_shake_concat:\n    concat_values = [res] + branches\n    concat_output = tf.concat(values=concat_values, axis=-1)\n    concat_output = tf.nn.relu(concat_output)\n    concat_output = tf.layers.conv2d(\n        concat_output, output_filters, (1, 1), name=\"concat_1x1\")\n    concat_output = tf.layers.batch_normalization(\n        concat_output, training=is_training, name=\"concat_bn\")\n    return concat_output\n  else:\n    return res + tf.add_n(branches)", "response": "Builds a full shake - shake - shake sub layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef shake_shake_layer(x, output_filters, num_blocks, stride, hparams):\n  for block_num in range(num_blocks):\n    curr_stride = stride if (block_num == 0) else 1\n    with tf.variable_scope(\"layer_{}\".format(block_num)):\n      x = shake_shake_block(x, output_filters, curr_stride, hparams)\n  return x", "response": "Builds a full layer with num_blocks sub layers."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef shakeshake_small():\n  hparams = common_hparams.basic_params1()\n  hparams.batch_size = 128\n  hparams.hidden_size = 32\n  hparams.layer_prepostprocess_dropout = 0.0\n  hparams.dropout = 0\n  hparams.label_smoothing = 0.0\n  hparams.clip_grad_norm = 0.0  # No clipping for now, one can also try 2.0.\n  hparams.num_hidden_layers = 26\n  hparams.learning_rate_decay_scheme = \"cosine\"\n  # Model should be run for 700000 steps with batch size 128 (~1800 epochs)\n  hparams.learning_rate_cosine_cycle_steps = 700000\n  hparams.learning_rate = 0.2\n  hparams.learning_rate_warmup_steps = 100  # That's basically unused.\n  hparams.initializer = \"uniform_unit_scaling\"\n  hparams.initializer_gain = 1.0\n  hparams.weight_decay = 1e-4\n  hparams.optimizer = \"Momentum\"\n  hparams.optimizer_momentum_momentum = 0.9\n  hparams.add_hparam(\"shake_shake_num_branches\", 2)\n  hparams.add_hparam(\"shake_shake_concat\", int(False))\n  return hparams", "response": "Parameters for CIFAR - 10. Gets to about 96% accuracy@700K steps 1 GPU."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef has_metric_plateaued(steps, values, num_steps=100, delta=0.1,\n                         decrease=True):\n  \"\"\"Check if metric has plateaued.\n\n  A metric has plateaued if the value has not increased/decreased (depending on\n  `decrease`) by `delta` for at least `num_steps`.\n\n  Args:\n    steps: list<int> list of global steps for values.\n    values: list<float> list of metric values.\n    num_steps: int, number of steps the metric has to have been plateaued for.\n    delta: float, how much the metric should have changed by over num_steps.\n    decrease: bool, whether to check if the metric has decreased by delta or\n      increased by delta.\n\n  Returns:\n    bool, whether the metric has plateaued.\n  \"\"\"\n  assert num_steps > 0\n  if len(steps) < 2:\n    return False\n\n  steps_at_least_num_steps_ago = [\n      s for s in steps if s <= (steps[-1] - num_steps)\n  ]\n  if not steps_at_least_num_steps_ago:\n    # Not enough steps yet\n    return False\n  delta_step_idx = len(steps_at_least_num_steps_ago) - 1\n\n  start_val = values[delta_step_idx]\n  values_to_check = values[delta_step_idx:]\n  observed_deltas = []\n  for val in values_to_check:\n    if decrease:\n      observed_delta = start_val - val\n    else:\n      observed_delta = val - start_val\n    observed_deltas.append(observed_delta)\n\n  within_range = [obs < delta for obs in observed_deltas]\n  return all(within_range)", "response": "Checks if a metric has plateaued."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef next_frame_savp_gan():\n  hparams = next_frame_savp()\n  hparams.use_gan = True\n  hparams.use_vae = False\n  hparams.gan_loss_multiplier = 0.001\n  hparams.optimizer_adam_beta1 = 0.5\n  hparams.learning_rate_constant = 2e-4\n  hparams.gan_loss = \"cross_entropy\"\n  hparams.learning_rate_decay_steps = 100000\n  hparams.learning_rate_schedule = \"constant*linear_decay\"\n  return hparams", "response": "SAVP - GAN only model."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndefaults hyperparameters for a DietAdamOptimizer.", "response": "def diet_adam_optimizer_params():\n  \"\"\"Default hyperparameters for a DietAdamOptimizer.\n\n  Returns:\n    a hyperparameters object.\n  \"\"\"\n  return hparam.HParams(\n      quantize=True,  # use 16-bit fixed-point\n      quantization_scale=10.0 / tf.int16.max,\n      optimizer=\"DietAdam\",\n      learning_rate=1.0,\n      learning_rate_warmup_steps=2000,\n      learning_rate_decay_scheme=\"noam\",  # \"noam\" or \"none\"\n      epsilon=1e-10,\n      beta1=0.0,  # we can save memory if beta1=0\n      beta2=0.98,\n      factored_second_moment_accumulator=True,  # this saves memory\n  )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _quantize(x, params, randomize=True):\n  if not params.quantize:\n    return x\n\n  if not randomize:\n    return tf.bitcast(\n        tf.cast(x / params.quantization_scale, tf.int16), tf.float16)\n\n  abs_x = tf.abs(x)\n  sign_x = tf.sign(x)\n  y = abs_x / params.quantization_scale\n  y = tf.floor(y + tf.random_uniform(common_layers.shape_list(x)))\n  y = tf.minimum(y, tf.int16.max) * sign_x\n  q = tf.bitcast(tf.cast(y, tf.int16), tf.float16)\n  return q", "response": "Quantize x according to params optionally randomizing the rounding."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _dequantize(q, params):\n  if not params.quantize:\n    return q\n  return tf.to_float(tf.bitcast(q, tf.int16)) * params.quantization_scale", "response": "Dequantize q according to params."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a custom variable getter for diet variables according to params.", "response": "def make_diet_var_getter(params):\n  \"\"\"Create a custom variable getter for diet variables according to params.\"\"\"\n\n  def diet_var_initializer(shape, dtype, partition_info=None):\n    \"\"\"Initializer for a diet variable.\"\"\"\n    del dtype\n    del partition_info\n\n    with common_layers.fn_device_dependency(\"diet_init\") as out_deps:\n      float_range = math.sqrt(3)\n      ret = tf.random_uniform(shape, -float_range, float_range)\n      if params.quantize:\n        ret = _quantize(ret, params, randomize=False)\n      out_deps.append(ret)\n      return ret\n\n  def diet_var_getter(getter, **kwargs):\n    \"\"\"Get diet variable and return it dequantized.\"\"\"\n    if params.quantize:\n      kwargs[\"dtype\"] = tf.float16\n    kwargs[\"initializer\"] = diet_var_initializer\n    kwargs[\"trainable\"] = False\n\n    base_var = getter(**kwargs)\n\n    dequantized = _dequantize(base_var, params)\n\n    if not hasattr(params, \"dequantized\"):\n      params.dequantized = defaultdict(list)\n    params.dequantized[base_var.name].append(dequantized)\n\n    return dequantized\n\n  return diet_var_getter"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls function with args ; use diet variables according to params.", "response": "def _fn_with_diet_vars(fn, args, params):\n  \"\"\"Call function with args; use diet variables according to params.\"\"\"\n\n  vs_ctr = []\n\n  def grad_fn(inputs, variables, outputs, output_grads):\n    \"\"\"Custom gradient function.\"\"\"\n    del outputs  # recomputing below\n    with common_layers.fn_device_dependency(\"diet_grad\",\n                                            output_grads[0].device) as out_dep:\n      with tf.variable_scope(vs_ctr[0], reuse=True):\n        outputs = fn(*inputs)\n\n      variables = [common_layers.underlying_variable_ref(v) for v in variables]\n      dequantized_variables = [\n          params.dequantized[v.name][-1] for v in variables\n      ]\n\n      grads = tf.gradients(outputs, inputs + dequantized_variables,\n                           output_grads)\n      grad_inputs = grads[:len(inputs)]\n      grad_variables = grads[len(inputs):]\n\n      opt = _create_diet_optimizer(params)\n\n      # Apply grad_variables here\n      var_updates = []\n      for v, dv in zip(variables, grad_variables):\n        with tf.variable_scope(vs_ctr[0].name):\n          opt.create_slots(v)\n        update_op = opt.update_variable(v, dv)\n        var_updates.append(update_op)\n\n      with tf.control_dependencies(var_updates):\n        grad_inputs = [tf.identity(dx) for dx in grad_inputs]\n\n      out_dep.append(grad_inputs)\n\n      return grad_inputs, [None] * len(variables)\n\n  @common_layers.fn_with_custom_grad(grad_fn, use_global_vars=True)\n  def forward(*inputs):\n    with tf.variable_scope(\n        None, default_name=\"diet\",\n        custom_getter=make_diet_var_getter(params)) as vs:\n      vs_ctr.append(vs)\n      outputs = fn(*inputs)\n      return outputs\n\n  with common_layers.fn_device_dependency(\"diet_forward\",\n                                          args[0].device) as out_dep:\n    outputs = forward(*args)\n    out_dep.append(outputs)\n  return outputs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_slots(self, var):\n    params = self.params\n    shape = var.get_shape().as_list()\n\n    if not hasattr(params, \"slots\"):\n      params.slots = defaultdict(dict)\n\n    name = var.op.name\n    slots = params.slots[name]\n\n    if params.factored_second_moment_accumulator and len(shape) == 2:\n      slots[\"adam_vr\"] = tf.get_variable(\n          name + \"_adam_vr\", [shape[0], 1],\n          trainable=False,\n          initializer=tf.zeros_initializer())\n      slots[\"adam_vc\"] = tf.get_variable(\n          name + \"_adam_vc\", [1, shape[1]],\n          trainable=False,\n          initializer=tf.zeros_initializer())\n    else:\n      slots[\"adam_v\"] = tf.get_variable(\n          name + \"_adam_v\",\n          shape,\n          trainable=False,\n          initializer=tf.zeros_initializer())\n    if params.beta1 != 0.0:\n      slots[\"adam_m\"] = tf.get_variable(\n          name + \"_adam_m\",\n          shape,\n          trainable=False,\n          initializer=tf.zeros_initializer())", "response": "Create the factorized Adam accumulators for diet variables."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_variable(self, var, grad_var):\n    params = self.params\n    global_step = tf.to_float(self.global_step) + 1\n\n    # compute learning rate\n    lrate = params.learning_rate\n    if params.learning_rate_decay_scheme == \"noam\":\n      lrate *= tf.minimum(global_step * params.learning_rate_warmup_steps**-1.5,\n                          global_step**-0.5)\n    else:\n      assert params.learning_rate_decay_scheme == \"none\"\n      lrate *= tf.minimum(global_step / params.learning_rate_warmup_steps, 1.0)\n\n    # compute adjustment due to second moment\n    slots = params.slots[var.op.name]\n    grad_squared = tf.square(grad_var)\n    beta2_pow = tf.pow(params.beta2, global_step)\n    if params.factored_second_moment_accumulator and len(var.shape) == 2:\n      vr_update = tf.assign(slots[\"adam_vr\"], slots[\"adam_vr\"] * params.beta2 +\n                            tf.reduce_mean(grad_squared, 1, keepdims=True) *\n                            (1.0 - params.beta2))\n      vc_update = tf.assign(slots[\"adam_vc\"], slots[\"adam_vc\"] * params.beta2 +\n                            tf.reduce_mean(grad_squared, 0, keepdims=True) *\n                            (1.0 - params.beta2))\n      with tf.control_dependencies([vr_update, vc_update]):\n        vr = tf.sqrt(slots[\"adam_vr\"] / (1.0 - beta2_pow)) + params.epsilon\n        vc = tf.sqrt(slots[\"adam_vc\"] / (1.0 - beta2_pow)) + params.epsilon\n        vc /= tf.reduce_mean(vc)\n        denom = vr * vc\n    else:\n      v_update = tf.assign(slots[\"adam_v\"],\n                           slots[\"adam_v\"] * params.beta2 + grad_squared *\n                           (1.0 - params.beta2))\n      with tf.control_dependencies([v_update]):\n        denom = tf.sqrt(slots[\"adam_v\"] / (1.0 - beta2_pow)) + params.epsilon\n\n    # compute momentum if applicable\n    if params.beta1 != 0.0:\n      m_update = tf.assign(slots[\"adam_m\"],\n                           slots[\"adam_m\"] * params.beta1 + grad_var *\n                           (1.0 - params.beta1))\n      with tf.control_dependencies([m_update]):\n        grad_var = slots[\"adam_m\"]\n\n    # update var\n    subtrahend = lrate * grad_var / denom\n    new_val = _quantize(_dequantize(var, params) - subtrahend, params)\n    return tf.assign(var, new_val)", "response": "Update the variable and its slots."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconstructs EstimatorSpec for EVAL mode.", "response": "def estimator_spec_eval(\n      self, features, logits, labels, loss, restore_hook, use_tpu):\n    \"\"\"Construct EstimatorSpec for EVAL mode.\"\"\"\n    hparams = self.hparams\n    problem = hparams.problem\n    if logits.get_shape().ndims == 3:\n      logits = tf.expand_dims(tf.expand_dims(logits, 2), 3)\n\n    # Support for multiproblem\n    task_list = [problem]\n    if hasattr(problem, \"task_list\"):\n      task_list = problem.task_list\n\n    eval_metrics_fns = metrics.create_evaluation_metrics(task_list, hparams)\n\n    if use_tpu:\n      def metric_fn(tf_logits, labels):\n        with tf.device(\"cpu:0\"), mtf.utils.outside_all_rewrites():\n          eval_metrics = {}\n          for metric_name, metric_fn in six.iteritems(eval_metrics_fns):\n            if metric_name.split(\"/\")[-1] not in t2t_model.TPU_METRIC_BLACKLIST:\n              eval_metrics[metric_name] = metric_fn(\n                  tf_logits, None, tf.identity(labels))\n          return eval_metrics\n      return tpu_estimator.TPUEstimatorSpec(\n          tf.estimator.ModeKeys.EVAL,\n          evaluation_hooks=[restore_hook],\n          loss=loss,\n          eval_metrics=(metric_fn, [logits, labels]))\n    else:\n      eval_metrics = {}\n      predictions = {\"predictions\": logits}\n      for metric_name, metric_fn in six.iteritems(eval_metrics_fns):\n        eval_metrics[metric_name] = metric_fn(logits, features,\n                                              features[\"targets\"])\n\n      return tf.estimator.EstimatorSpec(\n          tf.estimator.ModeKeys.EVAL,\n          predictions=predictions,\n          eval_metric_ops=eval_metrics,\n          evaluation_hooks=[restore_hook],\n          loss=loss)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a stack of LSTM layers on top of input.", "response": "def lstm(inputs, sequence_length, hparams, train, name, initial_state=None):\n  \"\"\"Adds a stack of LSTM layers on top of input.\n\n  Args:\n    inputs: The input `Tensor`, shaped `[batch_size, time_steps, hidden_size]`.\n    sequence_length: Lengths of the actual input sequence, excluding padding; a\n        `Tensor` shaped `[batch_size]`.\n    hparams: HParams; hyperparameters.\n    train: bool; `True` when constructing training graph to enable dropout.\n    name: string; Create variable names under this scope.\n    initial_state: tuple of `LSTMStateTuple`s; the initial state of each layer.\n\n  Returns:\n    A tuple (outputs, states), where:\n      outputs: The output `Tensor`, shaped `[batch_size, time_steps,\n        hidden_size]`.\n      states: A tuple of `LSTMStateTuple`s; the final state of each layer.\n        Bidirectional LSTM returns a concatenation of last forward and backward\n        state, reduced to the original dimensionality.\n  \"\"\"\n  layers = [_dropout_lstm_cell(hparams, train)\n            for _ in range(hparams.num_hidden_layers)]\n  with tf.variable_scope(name):\n    return tf.nn.dynamic_rnn(\n        tf.nn.rnn_cell.MultiRNNCell(layers),\n        inputs,\n        sequence_length,\n        initial_state=initial_state,\n        dtype=tf.float32,\n        time_major=False)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun LSTM cell with attention on inputs of shape [ batch x time x size.", "response": "def lstm_attention_decoder(inputs, hparams, train, name, initial_state,\n                           encoder_outputs, encoder_output_length,\n                           decoder_input_length):\n  \"\"\"Run LSTM cell with attention on inputs of shape [batch x time x size].\n\n  Args:\n    inputs: The decoder input `Tensor`, shaped `[batch_size, decoder_steps,\n        hidden_size]`.\n    hparams: HParams; hyperparameters.\n    train: bool; `True` when constructing training graph to enable dropout.\n    name: string; Create variable names under this scope.\n    initial_state: Tuple of `LSTMStateTuple`s; the initial state of each layer.\n    encoder_outputs: Encoder outputs; a `Tensor` shaped `[batch_size,\n        encoder_steps, hidden_size]`.\n    encoder_output_length: Lengths of the actual encoder outputs, excluding\n        padding; a `Tensor` shaped `[batch_size]`.\n    decoder_input_length: Lengths of the actual decoder inputs, excluding\n        padding; a `Tensor` shaped `[batch_size]`.\n\n  Raises:\n    ValueError: If the hparams.attention_mechanism is anything other than\n        luong or bahdanau.\n\n  Returns:\n    The decoder output `Tensor`, shaped `[batch_size, decoder_steps,\n    hidden_size]`.\n  \"\"\"\n  layers = [_dropout_lstm_cell(hparams, train)\n            for _ in range(hparams.num_hidden_layers)]\n  if hparams.attention_mechanism == \"luong\":\n    attention_mechanism_class = tf.contrib.seq2seq.LuongAttention\n  elif hparams.attention_mechanism == \"bahdanau\":\n    attention_mechanism_class = tf.contrib.seq2seq.BahdanauAttention\n  else:\n    raise ValueError(\"Unknown hparams.attention_mechanism = %s, must be \"\n                     \"luong or bahdanau.\" % hparams.attention_mechanism)\n  if hparams.get(\"max_area_width\", 1) > 1:\n    def _area_key_value_fn(keys, values):\n      \"\"\"Custom fn for computing area keys and values.\"\"\"\n      tf.logging.info(\"max_area_width=%d, area_key_mode=%s, area_value_mode=%s\",\n                      hparams.get(\"max_area_width\", 1),\n                      hparams.get(\"area_key_mode\", \"none\"),\n                      hparams.get(\"area_value_mode\", \"none\"))\n      keys = area_attention.compute_area_key(\n          keys, max_area_width=hparams.get(\"max_area_width\", 1),\n          mode=hparams.get(\"area_key_mode\", \"none\"), name=\"decoder_encoder\",\n          training=(hparams.mode == tf.estimator.ModeKeys.TRAIN))\n      if hparams.get(\"area_value_mode\", \"none\") == \"sum\":\n        _, _, values, _, _ = area_attention.compute_area_features(\n            values, max_area_width=hparams.get(\"max_area_width\", 1))\n      elif hparams.get(\"area_value_mode\", \"none\") == \"mean\":\n        values, _, _, _, _ = area_attention.compute_area_features(\n            values, max_area_width=hparams.get(\"max_area_width\", 1))\n      else:\n        raise ValueError(\n            \"Unsupported area_value_mode: %s\" % hparams.get(\n                \"area_value_mode\", \"none\"))\n      return keys, values\n    area_mask = area_attention.lengths_to_area_mask(\n        feature_length=encoder_output_length,\n        length=common_layers.shape_list(encoder_outputs)[1],\n        max_area_size=hparams.get(\"max_area_width\", \"1\"))\n    def _area_prob_fn(score):\n      alignments = tf.nn.softmax(score)\n      alignments = tf.where(area_mask, alignments, tf.zeros_like(alignments))\n      alignments = tf.div(alignments, tf.reduce_sum(\n          alignments, axis=-1, keepdims=True))\n      return alignments\n    attention_mechanism = attention_mechanism_class(\n        hparams.hidden_size, encoder_outputs,\n        memory_sequence_length=None,\n        probability_fn=_area_prob_fn,\n        custom_key_value_fn=_area_key_value_fn)\n  else:\n    attention_mechanism = attention_mechanism_class(hparams.hidden_size,\n                                                    encoder_outputs)\n  cell = tf.contrib.seq2seq.AttentionWrapper(\n      tf.nn.rnn_cell.MultiRNNCell(layers),\n      [attention_mechanism]*hparams.num_heads,\n      attention_layer_size=[hparams.attention_layer_size]*hparams.num_heads,\n      output_attention=(hparams.output_attention == 1))\n\n  batch_size = common_layers.shape_list(inputs)[0]\n\n  initial_state = cell.zero_state(batch_size, tf.float32).clone(\n      cell_state=initial_state)\n\n  with tf.variable_scope(name):\n    output, _ = tf.nn.dynamic_rnn(\n        cell,\n        inputs,\n        decoder_input_length,\n        initial_state=initial_state,\n        dtype=tf.float32,\n        time_major=False)\n    # output is [batch_size, decoder_steps, attention_size], where\n    # attention_size is either hparams.hidden_size (when\n    # hparams.output_attention is 0) or hparams.attention_layer_size (when\n    # hparams.output_attention is 1) times the number of attention heads.\n    #\n    # For multi-head attention project output back to hidden size.\n    if hparams.output_attention == 1 and hparams.num_heads > 1:\n      output = tf.layers.dense(output, hparams.hidden_size)\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lstm_seq2seq_internal_attention(inputs, targets, hparams, train,\n                                    inputs_length, targets_length):\n  \"\"\"LSTM seq2seq model with attention, main step used for training.\"\"\"\n  with tf.variable_scope(\"lstm_seq2seq_attention\"):\n    # Flatten inputs.\n    inputs = common_layers.flatten4d3d(inputs)\n\n    # LSTM encoder.\n    inputs = tf.reverse_sequence(inputs, inputs_length, seq_axis=1)\n    encoder_outputs, final_encoder_state = lstm(\n        inputs, inputs_length, hparams, train, \"encoder\")\n\n    # LSTM decoder with attention.\n    shifted_targets = common_layers.shift_right(targets)\n    # Add 1 to account for the padding added to the left from shift_right\n    targets_length = targets_length + 1\n    decoder_outputs = lstm_attention_decoder(\n        common_layers.flatten4d3d(shifted_targets), hparams, train, \"decoder\",\n        final_encoder_state, encoder_outputs, inputs_length, targets_length)\n    return tf.expand_dims(decoder_outputs, axis=2)", "response": "LSTM seq2seq model with attention main step used for training."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lstm_seq2seq_internal_bid_encoder(inputs, targets, hparams, train):\n  with tf.variable_scope(\"lstm_seq2seq_bid_encoder\"):\n    if inputs is not None:\n      inputs_length = common_layers.length_from_embedding(inputs)\n      # Flatten inputs.\n      inputs = common_layers.flatten4d3d(inputs)\n      # LSTM encoder.\n      _, final_encoder_state = lstm_bid_encoder(\n          inputs, inputs_length, hparams, train, \"encoder\")\n    else:\n      inputs_length = None\n      final_encoder_state = None\n    # LSTM decoder.\n    shifted_targets = common_layers.shift_right(targets)\n    # Add 1 to account for the padding added to the left from shift_right\n    targets_length = common_layers.length_from_embedding(shifted_targets) + 1\n    hparams_decoder = copy.copy(hparams)\n    hparams_decoder.hidden_size = 2 * hparams.hidden_size\n    decoder_outputs, _ = lstm(\n        common_layers.flatten4d3d(shifted_targets),\n        targets_length,\n        hparams_decoder,\n        train,\n        \"decoder\",\n        initial_state=final_encoder_state)\n    return tf.expand_dims(decoder_outputs, axis=2)", "response": "The basic LSTM seq2seq model with bidirectional encoder."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lstm_area_attention_base():\n  hparams = lstm_luong_attention()\n  hparams.batch_size = 16384\n  hparams.num_hidden_layers = 2\n  hparams.hidden_size = 1024\n  hparams.num_heads = 4\n  hparams.dropout = 0.2\n  hparams.learning_rate = 0.1\n  hparams.max_area_width = 2\n  hparams.area_key_mode = \"mean\"\n  hparams.area_value_mode = \"sum\"\n  return hparams", "response": "Hparams for LSTM with area attention."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a run config for a surrogate model.", "response": "def create_surrogate_run_config(hp):\n  \"\"\"Create a run config.\n\n  Args:\n    hp: model hyperparameters\n  Returns:\n    a run config\n  \"\"\"\n  save_ckpt_steps = max(FLAGS.iterations_per_loop, FLAGS.local_eval_frequency)\n  save_ckpt_secs = FLAGS.save_checkpoints_secs or None\n  if save_ckpt_secs:\n    save_ckpt_steps = None\n  assert FLAGS.surrogate_output_dir\n  # the various custom getters we have written do not play well together yet.\n  # TODO(noam): ask rsepassi for help here.\n  daisy_chain_variables = (\n      hp.daisy_chain_variables and hp.activation_dtype == \"float32\" and\n      hp.weight_dtype == \"float32\")\n  return trainer_lib.create_run_config(\n      model_name=FLAGS.model,\n      model_dir=os.path.expanduser(FLAGS.surrogate_output_dir),\n      master=FLAGS.master,\n      iterations_per_loop=FLAGS.iterations_per_loop,\n      num_shards=FLAGS.tpu_num_shards,\n      log_device_placement=FLAGS.log_device_placement,\n      save_checkpoints_steps=save_ckpt_steps,\n      save_checkpoints_secs=save_ckpt_secs,\n      keep_checkpoint_max=FLAGS.keep_checkpoint_max,\n      keep_checkpoint_every_n_hours=FLAGS.keep_checkpoint_every_n_hours,\n      num_gpus=FLAGS.worker_gpu,\n      gpu_order=FLAGS.gpu_order,\n      num_async_replicas=FLAGS.worker_replicas,\n      gpu_mem_fraction=FLAGS.worker_gpu_memory_fraction,\n      enable_graph_rewriter=FLAGS.enable_graph_rewriter,\n      use_tpu=FLAGS.use_tpu,\n      schedule=FLAGS.schedule,\n      no_data_parallelism=hp.no_data_parallelism,\n      daisy_chain_variables=daisy_chain_variables,\n      ps_replicas=FLAGS.ps_replicas,\n      ps_job=FLAGS.ps_job,\n      ps_gpu=FLAGS.ps_gpu,\n      sync=FLAGS.sync,\n      worker_id=FLAGS.worker_id,\n      worker_job=FLAGS.worker_job,\n      random_seed=FLAGS.random_seed,\n      tpu_infeed_sleep_secs=FLAGS.tpu_infeed_sleep_secs,\n      inter_op_parallelism_threads=FLAGS.inter_op_parallelism_threads,\n      log_step_count_steps=FLAGS.log_step_count_steps,\n      intra_op_parallelism_threads=FLAGS.intra_op_parallelism_threads)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef encode(self, s):\n    # Make sure that the data is a single channel, 16bit, 16kHz wave.\n    # TODO(chorowski): the directory may not be writable, this should fallback\n    # to a temp path, and provide instructions for installing sox.\n    if s.endswith(\".mp3\"):\n      # TODO(dliebling) On Linux, check if libsox-fmt-mp3 is installed.\n      out_filepath = s[:-4] + \".wav\"\n      call([\n          \"sox\", \"--guard\", s, \"-r\", \"16k\", \"-b\", \"16\", \"-c\", \"1\", out_filepath\n      ])\n      s = out_filepath\n    elif not s.endswith(\".wav\"):\n      out_filepath = s + \".wav\"\n      if not os.path.exists(out_filepath):\n        call([\"sox\", \"-r\", \"16k\", \"-b\", \"16\", \"-c\", \"1\", s, out_filepath])\n      s = out_filepath\n    rate, data = wavfile.read(s)\n    assert rate == self._sample_rate\n    assert len(data.shape) == 1\n    if data.dtype not in [np.float32, np.float64]:\n      data = data.astype(np.float32) / np.iinfo(data.dtype).max\n    return data.tolist()", "response": "Transform a string with a filename into a list of float32."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntransforms a sequence of float32 into a waveform.", "response": "def decode(self, ids):\n    \"\"\"Transform a sequence of float32 into a waveform.\n\n    Args:\n      ids: list of integers to be converted.\n\n    Returns:\n      Path to the temporary file where the waveform was saved.\n\n    Raises:\n      ValueError: if the ids are not of the appropriate size.\n    \"\"\"\n    _, tmp_file_path = tempfile.mkstemp()\n    wavfile.write(tmp_file_path, self._sample_rate, np.asarray(ids))\n    return tmp_file_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef new_vertex(self):\n    vertex = Vertex(len(self.vertices))\n    self.vertices.append(vertex)\n    return vertex", "response": "Creates and returns a new vertex."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_vertex(self, key):\n    if key in self.vertex_map:\n      return self.vertex_map[key]\n    vertex = self.new_vertex()\n    self.vertex_map[key] = vertex\n    return vertex", "response": "Returns or Creates a vertex in which the vertex is mapped to by key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding an edge connecting source and target vertices.", "response": "def add_edge(self, source, target):\n    \"\"\"Returns a new edge connecting source and target vertices.\n\n    Args:\n      source: The source Vertex.\n      target: The target Vertex.\n\n    Returns:\n      A new Edge linking source to target.\n    \"\"\"\n    edge = Edge(len(self.edges))\n    self.edges.append(edge)\n    source.out_edges.append(edge.idx)\n    target.in_edges.append(edge.idx)\n    edge.source = source.idx\n    edge.target = target.idx\n    return edge"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a simplified dictionary representing the Graph.", "response": "def to_dict(self):\n    \"\"\"Returns a simplified dictionary representing the Graph.\n\n    Returns:\n      A dictionary that can easily be serialized to JSON.\n    \"\"\"\n    return {\n        \"node\": [v.to_dict() for v in self.vertices],\n        \"edge\": [e.to_dict() for e in self.edges]\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nself - attention layer with source as memory antecedent.", "response": "def attend(x, source, hparams, name):\n  \"\"\"Self-attention layer with source as memory antecedent.\"\"\"\n  with tf.variable_scope(name):\n    x = tf.squeeze(x, axis=2)\n    if len(source.get_shape()) > 3:\n      source = tf.squeeze(source, axis=2)\n    source = common_attention.add_timing_signal_1d(source)\n    y = common_attention.multihead_attention(\n        common_layers.layer_preprocess(x, hparams), source, None,\n        hparams.attention_key_channels or hparams.hidden_size,\n        hparams.attention_value_channels or hparams.hidden_size,\n        hparams.hidden_size, hparams.num_heads,\n        hparams.attention_dropout)\n    res = common_layers.layer_postprocess(x, y, hparams)\n    return tf.expand_dims(res, axis=2)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef top_k_softmax(x, k):\n  x = tf.nn.softmax(x)\n  top_x, _ = tf.nn.top_k(x, k=k+1)\n  min_top = tf.reduce_min(top_x, axis=-1, keepdims=True)\n  x = tf.nn.relu((x - min_top) + 1e-12)\n  x /= tf.reduce_sum(x, axis=-1, keepdims=True)\n  return x, tf.reduce_max(top_x, axis=-1)", "response": "Calculate softmax ( x ) select top - k and rescale to sum to 1."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompress the input tensor x using strided convs.", "response": "def compress(x, c, is_2d, hparams, name):\n  \"\"\"Compress.\"\"\"\n  with tf.variable_scope(name):\n    # Run compression by strided convs.\n    cur = x\n    k1 = (3, 3) if is_2d else (3, 1)\n    k2 = (2, 2) if is_2d else (2, 1)\n    cur = residual_conv(cur, hparams.num_compress_steps, k1, hparams, \"rc\")\n    if c is not None and hparams.do_attend_compress:\n      cur = attend(cur, c, hparams, \"compress_attend\")\n    for i in range(hparams.num_compress_steps):\n      if hparams.do_residual_compress:\n        cur = residual_conv(cur, hparams.num_compress_steps, k1, hparams,\n                            \"rc_%d\" % i)\n      cur = common_layers.conv_block(\n          cur, hparams.hidden_size, [((1, 1), k2)],\n          strides=k2, name=\"compress_%d\" % i)\n    return cur"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ae_latent_softmax(latents_pred, latents_discrete, hparams):\n  vocab_size = 2 ** hparams.z_size\n  if hparams.num_decode_blocks < 2:\n    latents_logits = tf.layers.dense(latents_pred, vocab_size,\n                                     name=\"extra_logits\")\n    if hparams.logit_normalization:\n      latents_logits *= tf.rsqrt(1e-8 +\n                                 tf.reduce_mean(tf.square(latents_logits)))\n\n    loss = None\n    if latents_discrete is not None:\n      if hparams.soft_em:\n        # latents_discrete is actually one-hot of multinomial samples\n        assert hparams.num_decode_blocks == 1\n        loss = tf.nn.softmax_cross_entropy_with_logits_v2(\n            labels=latents_discrete, logits=latents_logits)\n      else:\n        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n            labels=latents_discrete, logits=latents_logits)\n    sample = multinomial_sample(\n        latents_logits, vocab_size, hparams.sampling_temp)\n    return sample, loss\n\n  # Multi-block case.\n  vocab_bits = int(math.log(vocab_size, 2))\n  assert vocab_size == 2**vocab_bits\n  assert vocab_bits % hparams.num_decode_blocks == 0\n  block_vocab_size = 2**(vocab_bits // hparams.num_decode_blocks)\n  latents_logits = [\n      tf.layers.dense(\n          latents_pred, block_vocab_size, name=\"extra_logits_%d\" % i)\n      for i in range(hparams.num_decode_blocks)\n  ]\n  loss = None\n  if latents_discrete is not None:\n    losses = []\n    for i in range(hparams.num_decode_blocks):\n      d = tf.floormod(tf.floordiv(latents_discrete,\n                                  block_vocab_size**i), block_vocab_size)\n      losses.append(tf.nn.sparse_softmax_cross_entropy_with_logits(\n          labels=d, logits=latents_logits[i]))\n    loss = sum(losses)\n  samples = [multinomial_sample(l, block_vocab_size, hparams.sampling_temp)\n             for l in latents_logits]\n  sample = sum([s * block_vocab_size**i for i, s in enumerate(samples)])\n  return sample, loss", "response": "A function that computes the softmax of the given set of latents."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ae_latent_sample(latents_dense, inputs, ed, embed, iters, hparams):\n  if hparams.num_decode_blocks < 2 and hparams.sampling_temp == 0.0:\n    # TODO(lukaszkaiser): beam-search only works in non-blocked mode for now.\n    tf.logging.info(\"Running beam-search for latents with beam size 1.\")\n    return ae_latent_sample_beam(latents_dense, inputs, ed, embed, hparams)\n  latents_pred = decode_transformer(inputs, ed, latents_dense, hparams, \"extra\")\n  latents_discrete, _ = ae_latent_softmax(latents_pred, None, hparams)\n\n  def next_bit(latents_discrete, i):\n    latents_discrete_prev = latents_discrete\n    with tf.variable_scope(tf.get_variable_scope(), reuse=True):\n      latents_dense = embed(latents_discrete)\n      latents_pred = decode_transformer(\n          inputs, ed, latents_dense, hparams, \"extra\")\n      latents_discrete, _ = ae_latent_softmax(latents_pred, None, hparams)\n      return tf.concat([latents_discrete_prev[:, :(i+1), :],\n                        latents_discrete[:, (i+1):, :]], axis=1)\n\n  for i in range(iters):\n    latents_discrete = next_bit(latents_discrete, i)\n  return latents_discrete", "response": "Sample from the latent space in the autoencoder."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ae_transformer_internal(inputs,\n                            targets,\n                            target_space,\n                            hparams,\n                            cache=None,\n                            predict_mask=1.0):\n  \"\"\"AE Transformer, main step used for training.\"\"\"\n  # Summaries break with the do_refine cond, turn them off in that case.\n  global _DO_SUMMARIES\n  if hparams.do_refine:\n    _DO_SUMMARIES = False\n\n  # Prepare.\n  if inputs is not None:\n    batch_size = common_layers.shape_list(inputs)[0]\n  else:\n    batch_size = common_layers.shape_list(targets)[0]\n  targets = tf.reshape(targets, [batch_size, -1, 1, hparams.hidden_size])\n\n  # Encoder.\n  if inputs is not None:\n    inputs = common_layers.flatten4d3d(inputs)\n    inputs, ed = encode(inputs, target_space, hparams, \"input_enc\")\n    inputs_ex, ed_ex = inputs, ed\n  else:\n    ed, inputs_ex, ed_ex = None, None, None\n\n  # Autoencoding.\n  losses = {\"extra\": tf.constant(0.0), \"latent_pred\": tf.constant(0.0),\n            \"neg_q_entropy\": tf.constant(0.0)}\n  if hparams.do_ae:\n    # flatten here\n    original_targets = targets\n    original_targets_shape = tf.shape(original_targets)\n    if hparams.task == \"image\":\n      cia.maybe_reshape_4d_to_3d(targets)\n    if hparams.task == \"translate\":\n      if inputs is not None:\n        max_targets_len_from_inputs = tf.concat([inputs, inputs], axis=1)\n      else:\n        max_targets_len_from_inputs = targets\n    else:\n      assert hparams.task == \"image\"\n      max_targets_len_from_inputs = targets\n    if hparams.word_shuffle:\n      tf.logging.info(\"Using word shuffle with rate = {}\".format(\n          hparams.word_shuffle))\n      targets_idx = tf.range(start=0,\n                             limit=common_layers.shape_list(targets)[1],\n                             delta=1)\n      targets_idx = tf.to_float(targets_idx)\n      noise = tf.random_uniform(shape=common_layers.shape_list(targets_idx),\n                                minval=0,\n                                maxval=1 + hparams.word_shuffle)\n      targets_idx += noise\n      permutation = tf.contrib.framework.argsort(targets_idx)\n      targets_permuted = tf.gather(targets, indices=permutation, axis=1)\n      targets = targets_permuted\n    targets, _ = common_layers.pad_to_same_length(\n        targets, max_targets_len_from_inputs,\n        final_length_divisible_by=2**hparams.num_compress_steps)\n    # Add positional information\n    targets_shape = common_layers.shape_list(targets)\n    targets = tf.reshape(targets, [targets_shape[0], targets_shape[1],\n                                   targets_shape[3]])\n    targets = common_attention.add_positional_embedding(\n        targets, hparams.max_length, name=\"targets_position\")\n    targets = tf.reshape(targets, shape=targets_shape)\n    if hparams.word_dropout:\n      mask = tf.random_uniform(shape=common_layers.shape_list(targets),\n                               minval=0.0, maxval=1.0)\n      targets_noisy = tf.where(mask > hparams.word_dropout, targets,\n                               tf.zeros_like(targets))\n    else:\n      targets_noisy = targets\n\n    targets_c = compress(targets_noisy, inputs, False, hparams, \"compress\")\n    if hparams.mode != tf.estimator.ModeKeys.PREDICT:\n      # Compress and bottleneck.\n      latents_dense, latents_discrete, extra_loss, embed, neg_q_entropy = (\n          hparams.bottleneck(inputs=targets_c,\n                             filter_size=hparams.compress_filter_size,\n                             mode=hparams.mode,\n                             name=\"vc\"))\n      if _DO_SUMMARIES:\n        tf.summary.histogram(\"b0\", tf.reshape(latents_discrete[:, 0, :], [-1]))\n      pc = common_layers.inverse_exp_decay(hparams.startup_steps)\n      pc = pc if hparams.mode == tf.estimator.ModeKeys.TRAIN else 1.0\n      cond = tf.less(tf.random_uniform([batch_size]), pc)\n      latents_dense = tf.where(cond, latents_dense, targets_c)\n      # TODO(lukaszkaiser): return extra losses batchwise, multiply before mean.\n      losses[\"extra\"] = extra_loss * tf.reduce_mean(tf.to_float(cond))\n      # Extra loss predicting latent code from input. Discrete only.\n      if hparams.bottleneck_kind not in [\"dense\", \"vae\"]:\n        latents_pred = decode_transformer(\n            inputs_ex, ed_ex,\n            embed(latents_discrete), hparams, \"extra\",\n            task=\"translate\")\n        _, latent_pred_loss = ae_latent_softmax(\n            latents_pred, tf.stop_gradient(latents_discrete), hparams)\n\n        # Scale by latent dimension for summary so we can compare across\n        # batches.\n        if _DO_SUMMARIES:\n          tf.summary.scalar(\"latent_pred_loss_mean\",\n                            tf.reduce_mean(latent_pred_loss))\n        if hparams.sum_over_latents:\n          latent_pred_loss = tf.reduce_sum(latent_pred_loss, [1, 2])\n\n        losses[\"latent_pred\"] = tf.reduce_mean(\n            latent_pred_loss * tf.to_float(cond)) * hparams.prior_scale\n        losses[\"neg_q_entropy\"] = neg_q_entropy * hparams.entropy_scale\n      else:\n        inputs_c = decode_transformer(inputs, ed, targets_c, hparams, \"dec_c\")\n        losses[\"latent_pred\"] = tf.reduce_mean(\n            tf.squared_difference(inputs_c, targets_c)) * 20\n        def bn_inputs():\n          with tf.variable_scope(tf.get_variable_scope(), reuse=True):\n            bn, _, _, _, _ = hparams.bottleneck(\n                inputs=inputs_c,\n                filter_size=hparams.compress_filter_size,\n                mode=hparams.mode,\n                name=\"vc\")\n          return bn\n        inputs_c = bn_inputs()\n        ptc = 1.0 - common_layers.inverse_lin_decay(200000) * 0.5\n        ptc = ptc if hparams.mode == tf.estimator.ModeKeys.TRAIN else 1.0\n        latents_dense = tf.where(tf.less(tf.random_uniform([batch_size]), ptc),\n                                 latents_dense, inputs_c)\n    else:\n      if hparams.bottleneck_kind in [\"dense\", \"vae\"]:\n        inputs_c = decode_transformer(inputs, ed, targets_c, hparams, \"dec_c\")\n        latents_dense, _, _, _, _ = hparams.bottleneck(\n            inputs=inputs_c,\n            filter_size=hparams.compress_filter_size,\n            mode=hparams.mode,\n            name=\"vc\")\n      else:\n        latent_len = common_layers.shape_list(targets_c)[1]\n        _, _, _, embed, _ = hparams.bottleneck(\n            inputs=targets_c,\n            filter_size=hparams.compress_filter_size,\n            name=\"vc\")\n        latents_dense = tf.zeros_like(targets_c[:, :latent_len, :, :])\n        if cache is None:\n          cache = ae_latent_sample(\n              latents_dense, inputs_ex, ed_ex, embed, 16, hparams)\n        latents_dense = embed(cache)\n    # Postprocess.\n    d = latents_dense\n    d_shape = common_layers.shape_list(d)\n    d = tf.reshape(d, [d_shape[0], d_shape[1], d_shape[3]])\n    d = common_attention.add_positional_embedding(\n        d, hparams.max_length, name=\"latents_position\")\n    d = tf.reshape(d, shape=d_shape)\n\n    # decompressing the dense latents\n    for i in range(hparams.num_compress_steps):\n      j = hparams.num_compress_steps - i - 1\n      d = residual_conv(d, 1, (3, 1), hparams, \"decompress_rc_%d\" % j)\n      if inputs is not None and hparams.do_attend_decompress:\n        d = attend(d, inputs, hparams, \"decompress_attend_%d\" % j)\n      d = decompress_step(d, hparams, i > 0, False, \"decompress_%d\" % j)\n\n    # Masking.\n    if hparams.do_mask:\n      masking = common_layers.inverse_lin_decay(hparams.mask_startup_steps)\n      masking *= common_layers.inverse_exp_decay(\n          hparams.mask_startup_steps // 4)  # Not much at start.\n      if not hparams.do_refine:\n        masking -= tf.random_uniform([]) * hparams.unmasked_percentage\n      masking = tf.minimum(tf.maximum(masking, 0.0), 1.0)\n      if hparams.use_predict_mask:\n        masking = predict_mask\n      if hparams.mode == tf.estimator.ModeKeys.PREDICT:\n        masking = predict_mask\n      mask = tf.less(masking, tf.random_uniform(\n          common_layers.shape_list(targets)[:-1]))\n      mask = tf.expand_dims(tf.to_float(mask), 3)\n\n      # targets is always [batch, length, 1, depth]\n      targets = mask * targets + (1.0 - mask) * d\n      # reshape back to 4d here\n      if hparams.task == \"image\":\n        targets = tf.reshape(targets, original_targets_shape)\n\n  res = decode_transformer(inputs, ed, targets, hparams, \"decoder\",\n                           causal=hparams.causal)\n  if hparams.do_ae:\n    if hparams.do_mask and hparams.do_refine:\n      def refine_res():\n        # return residual_conv(res, 1, (5, 1), hparams, \"refine\")\n        r, _ = encode(tf.squeeze(res, axis=[2]),\n                      target_space, hparams, \"refine_enc\")\n        return tf.expand_dims(r, axis=2)\n      masked_batches = tf.reduce_sum(mask, axis=[1, 2, 3])\n      all_masked = tf.less(masked_batches, 0.1)\n      res = tf.where(all_masked, refine_res(), res)\n    # We'll start training the extra model of latents after mask_startup_steps.\n    nonlatent_steps = hparams.mask_startup_steps\n    latent_time = tf.less(nonlatent_steps,\n                          tf.to_int32(tf.train.get_global_step()))\n    losses[\"latent_pred\"] *= tf.to_float(latent_time)\n\n  # res was generated from padded targets, which means it has some extra\n  # elements. These can cause shape problems when computing loss with respect to\n  # the original (unpadded) targets. So we remove their extra elements here.\n  res = res[:, :original_targets_shape[1], :, :]\n\n  data_dim = common_layers.shape_list(res)[1]\n  latent_dim = common_layers.shape_list(targets_c)[1]\n  return res, losses, cache, data_dim, latent_dim", "response": "A training step used for training."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transformer_ae_small():\n  hparams = transformer.transformer_small()\n  hparams.batch_size = 2048\n  hparams.learning_rate = 0.2\n  hparams.learning_rate_warmup_steps = 4000\n  hparams.num_hidden_layers = 3\n  hparams.hidden_size = 384\n  hparams.filter_size = 2048\n  hparams.add_hparam(\"compress_filter_size\", 2048 * 2)\n  hparams.label_smoothing = 0.0\n  hparams.optimizer = \"adam\"  # Can be unstable, maybe try Adam.\n  hparams.optimizer_adam_epsilon = 1e-9\n  hparams.optimizer_adam_beta1 = 0.9\n  hparams.optimizer_adam_beta2 = 0.997  # Needs tuning, try 0.98 to 0.999.\n  hparams.add_hparam(\"z_size\", 14)\n  hparams.add_hparam(\"noise_dev\", 0.5)\n  hparams.add_hparam(\"d_mix\", 0.5)\n  hparams.add_hparam(\"logit_normalization\", True)\n  hparams.add_hparam(\"word_dropout\", 0.)\n  # Bottleneck kinds supported: dense, vae, semhash, gumbel-softmax, dvq.\n  hparams.add_hparam(\"bottleneck_kind\", \"semhash\")\n  hparams.add_hparam(\"num_blocks\", 1)\n  hparams.add_hparam(\"num_decode_blocks\", 1)\n  # Add an hparam for number of reiduals\n  hparams.add_hparam(\"num_residuals\", 1)\n  # Reshape method for DVQ: slice, project\n  hparams.add_hparam(\"word_shuffle\", 0.5)\n  hparams.add_hparam(\"causal\", True)\n  hparams.add_hparam(\"reshape_method\", \"slice\")\n  hparams.add_hparam(\"trainable_projections\", False)\n  hparams.add_hparam(\"unmasked_percentage\", 0.1)\n  hparams.add_hparam(\"do_ae\", True)\n  hparams.add_hparam(\"do_mask\", True)\n  hparams.add_hparam(\"use_predict_mask\", True)\n  hparams.add_hparam(\"do_refine\", False)\n  hparams.add_hparam(\"do_attend_compress\", False)\n  hparams.add_hparam(\"do_attend_decompress\", True)\n  hparams.add_hparam(\"do_residual_compress\", False)\n  hparams.add_hparam(\"drop_inputs\", False)\n  hparams.add_hparam(\"v_size\", 1024*64)\n  hparams.add_hparam(\"max_context_length\", 64)\n  hparams.add_hparam(\"num_compress_steps\", 3)\n  hparams.add_hparam(\"startup_steps\", 10000)\n  hparams.add_hparam(\"mask_startup_steps\", 50000)\n  hparams.add_hparam(\"z_dropout\", 0.1)\n  hparams.add_hparam(\"is_2d\", 0)\n  hparams.add_hparam(\"softmax_k\", 0)\n  hparams.add_hparam(\"decode_autoregressive\", True)\n  hparams.add_hparam(\"do_vae\", True)\n  hparams.add_hparam(\"bit_vae\", True)\n  hparams.add_hparam(\"beta\", 0.25)\n  hparams.add_hparam(\"epsilon\", 1e-5)\n  hparams.add_hparam(\"decay\", 0.999)\n  hparams.add_hparam(\"ema\", True)\n  hparams.add_hparam(\"random_top_k\", 1)\n  hparams.add_hparam(\"soft_em\", False)\n  hparams.add_hparam(\"num_samples\", 10)\n  hparams.add_hparam(\"inv_temp\", 1.0)\n  hparams.add_hparam(\"entropy_scale\", 0.0)\n  hparams.add_hparam(\"prior_scale\", 1.0)\n  hparams.add_hparam(\"do_hard_gumbel_softmax\", False)\n  hparams.add_hparam(\"num_flows\", 0)\n  hparams.add_hparam(\"approximate_gs_entropy\", False)\n  hparams.add_hparam(\"temperature_warmup_steps\", 150000)\n  hparams.add_hparam(\"sum_over_latents\", False)\n  hparams.force_full_predict = True\n\n  # task params\n  hparams.add_hparam(\"task\", \"translate\")  # translate or image tasks supported\n  return hparams", "response": "Set of hyperparameters for training on AE."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef imagetransformer_ae_cifar():\n  hparams = transformer_ae_small()\n  hparams.filter_size = 512\n  hparams.num_compress_steps = 3\n  hparams.startup_steps = 10000\n  hparams.is_2d = 0\n  hparams.learning_rate_warmup_steps = 8000\n  hparams.learning_rate = 0.2\n  hparams.hidden_size = 512\n  hparams.batch_size = 1\n  hparams.max_length = 256\n  hparams.dropout = 0.0\n  hparams.clip_grad_norm = 0.  # i.e. no gradient clipping\n  hparams.optimizer_adam_epsilon = 1e-9\n  hparams.learning_rate_decay_scheme = \"noam\"\n  hparams.learning_rate = 0.1\n  hparams.initializer_gain = 0.2\n  hparams.num_hidden_layers = 6\n  hparams.initializer = \"uniform_unit_scaling\"\n  hparams.weight_decay = 0.0\n  hparams.optimizer_adam_beta1 = 0.9\n  hparams.optimizer_adam_beta2 = 0.98\n  hparams.label_smoothing = 0.0\n  hparams.norm_type = \"layer\"\n  hparams.layer_prepostprocess_dropout = 0.0\n  hparams.num_heads = 8\n  hparams.task = \"image\"\n  hparams.ffn_layer = \"conv_hidden_relu\"\n  # All hyperparameters ending in \"dropout\" are automatically set to 0.0\n  # when not in training mode.\n  hparams.attention_dropout = 0.0\n  hparams.relu_dropout = 0.\n  hparams.pos = \"timing\"  # timing, none\n  hparams.nbr_decoder_problems = 1\n  hparams.num_output_layers = 3\n  # TODO(trandustin): semhash doesn't work if filter_size != hidden_size. For\n  # now, set default to dvq.\n  hparams.bottleneck_kind = \"dvq\"\n  hparams.add_hparam(\"block_size\", 1)\n\n  # dilated attention based flags\n  hparams.add_hparam(\"gap_sizes\", [2, 4, 8, 16, 32, 64, 2, 4, 8, 16, 32, 64])\n  hparams.add_hparam(\"dilated_attention\", False)\n\n  # image size related flags\n  # assuming that the image has same height and width\n  hparams.add_hparam(\"img_len\", 32)\n  hparams.add_hparam(\"num_channels\", 3)\n  # Local attention params\n  hparams.add_hparam(\"local_and_global_att\", False)\n  hparams.add_hparam(\"block_length\", 256)\n  hparams.add_hparam(\"block_width\", 128)\n  hparams.num_encoder_layers = 4\n  hparams.num_decoder_layers = 12\n  hparams.add_hparam(\"dec_attention_type\", cia.AttentionType.LOCAL_1D)\n  hparams.add_hparam(\"block_raster_scan\", False)\n  hparams.add_hparam(\"shared_rel\", False)\n\n  # multipos attention params\n  hparams.add_hparam(\"q_filter_width\", 1)\n  hparams.add_hparam(\"kv_filter_width\", 1)\n\n  hparams.add_hparam(\"unconditional\", False)  # unconditional generation\n\n  hparams.bottom[\"targets\"] = modalities.image_channel_embeddings_bottom\n  hparams.top[\"targets\"] = modalities.image_channel_embeddings_top\n  hparams.drop_inputs = True\n  hparams.do_attend_compress = False\n  hparams.do_attend_decompress = False\n  return hparams", "response": "Hyperparameters for CIFAR - 10 experiments."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef imagetransformer_ae_imagenet():\n  hparams = imagetransformer_ae_cifar()\n  hparams.max_length = int(64 * 64 * 3)\n  hparams.img_len = 64\n  hparams.num_heads = 4  # Heads are expensive on TPUs.\n  # Reduce architecture from 32x32 CIFAR-10 in order to fit in memory.\n  hparams.num_decoder_layers = 8\n  hparams.num_compress_steps = 2\n  return hparams", "response": "For 64x64 ImageNet. ~56M trainable variables."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting of hyperparameters for AVA3.", "response": "def transformer_ae_a3():\n  \"\"\"Set of hyperparameters.\"\"\"\n  hparams = transformer_ae_base()\n  hparams.batch_size = 4096\n  hparams.layer_prepostprocess_dropout = 0.3\n  hparams.optimizer = \"Adafactor\"\n  hparams.learning_rate = 0.25\n  hparams.learning_rate_warmup_steps = 10000\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets of hyperparameters for training on AE - small.", "response": "def transformer_ae_small_noatt():\n  \"\"\"Set of hyperparameters.\"\"\"\n  hparams = transformer_ae_small()\n  hparams.reshape_method = \"slice\"\n  hparams.bottleneck_kind = \"dvq\"\n  hparams.hidden_size = 512\n  hparams.num_blocks = 1\n  hparams.num_decode_blocks = 1\n  hparams.z_size = 12\n  hparams.do_attend_decompress = False\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef layers():\n  global _cached_layers\n  if _cached_layers is not None:\n    return _cached_layers\n  layers_module = tf.layers\n  try:\n    from tensorflow.python import tf2  # pylint: disable=g-direct-tensorflow-import,g-import-not-at-top\n    if tf2.enabled():\n      tf.logging.info(\"Running in V2 mode, using Keras layers.\")\n      layers_module = tf.keras.layers\n  except ImportError:\n    pass\n  _cached_layers = layers_module\n  return layers_module", "response": "Get the layers module good for TF 1 and TF 2 work for now."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dropout_with_broadcast_dims(x, keep_prob, broadcast_dims=None, **kwargs):\n  assert \"noise_shape\" not in kwargs\n  if broadcast_dims:\n    shape = tf.shape(x)\n    ndims = len(x.get_shape())\n    # Allow dimensions like \"-1\" as well.\n    broadcast_dims = [dim + ndims if dim < 0 else dim for dim in broadcast_dims]\n    kwargs[\"noise_shape\"] = [\n        1 if i in broadcast_dims else shape[i] for i in range(ndims)\n    ]\n  return tf.nn.dropout(x, keep_prob, **kwargs)", "response": "Like tf. nn. dropout but takes broadcast_dims instead of noise_shape."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsaturate sigmoid: 1.2 * sigmoid(x) - 0.1 cut to [0, 1].", "response": "def saturating_sigmoid(x):\n  \"\"\"Saturating sigmoid: 1.2 * sigmoid(x) - 0.1 cut to [0, 1].\"\"\"\n  with tf.name_scope(\"saturating_sigmoid\", values=[x]):\n    y = tf.sigmoid(x)\n    return tf.minimum(1.0, tf.maximum(0.0, 1.2 * y - 0.1))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninverse - decay exponentially from 0. 01 to 1. 0 reached at max_step.", "response": "def inverse_exp_decay(max_step, min_value=0.01, step=None):\n  \"\"\"Inverse-decay exponentially from 0.01 to 1.0 reached at max_step.\"\"\"\n  inv_base = tf.exp(tf.log(min_value) / float(max_step))\n  if step is None:\n    step = tf.train.get_global_step()\n  if step is None:\n    return 1.0\n  step = to_float(step)\n  return inv_base**tf.maximum(float(max_step) - step, 0.0)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninverse - decay linearly from 0. 01 to 1. 0 reached at max_step.", "response": "def inverse_lin_decay(max_step, min_value=0.01, step=None):\n  \"\"\"Inverse-decay linearly from 0.01 to 1.0 reached at max_step.\"\"\"\n  if step is None:\n    step = tf.train.get_global_step()\n  if step is None:\n    return 1.0\n  step = to_float(step)\n  progress = tf.minimum(step / float(max_step), 1.0)\n  return progress * (1.0 - min_value) + min_value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef shakeshake2_py(x, y, equal=False, individual=False):\n  if equal:\n    alpha = 0.5\n  elif individual:\n    alpha = tf.random_uniform(tf.get_shape(x)[:1])\n  else:\n    alpha = tf.random_uniform([])\n\n  return alpha * x + (1.0 - alpha) * y", "response": "The shake - shake sum of 2 tensors python version."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef shakeshake2_grad(x1, x2, dy):\n  y = shakeshake2_py(x1, x2)\n  dx = tf.gradients(ys=[y], xs=[x1, x2], grad_ys=[dy])\n  return dx", "response": "Overriding gradient for shake - shake of 2 tensors."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\noverride gradient for shake - shake of 2 tensors.", "response": "def shakeshake2_indiv_grad(x1, x2, dy):\n  \"\"\"Overriding gradient for shake-shake of 2 tensors.\"\"\"\n  y = shakeshake2_py(x1, x2, individual=True)\n  dx = tf.gradients(ys=[y], xs=[x1, x2], grad_ys=[dy])\n  return dx"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef shakeshake2_equal_grad(x1, x2, dy):\n  y = shakeshake2_py(x1, x2, equal=True)\n  dx = tf.gradients(ys=[y], xs=[x1, x2], grad_ys=[dy])\n  return dx", "response": "Overriding gradient for shake - shake of 2 tensors."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef shakeshake(xs, equal_grad=False):\n  if len(xs) == 1:\n    return xs[0]\n  div = (len(xs) + 1) // 2\n  arg1 = shakeshake(xs[:div], equal_grad=equal_grad)\n  arg2 = shakeshake(xs[div:], equal_grad=equal_grad)\n  if equal_grad:\n    return shakeshake2_eqgrad(arg1, arg2)\n  return shakeshake2(arg1, arg2)", "response": "Multi - argument shake - shake - shake."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert_rgb_to_real(x):\n  with tf.name_scope(\"rgb_to_real\", values=[x]):\n    x = to_float(x)\n    x /= 255.0\n    return x", "response": "Conversion of pixel values to real numbers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert RGB values to real numbers.", "response": "def convert_rgb_to_symmetric_real(x):\n  \"\"\"Conversion of pixel values to real numbers.\"\"\"\n  with tf.name_scope(\"rgb_to_real\", values=[x]):\n    x = to_float(x)\n    # Convert each pixel intensity in [0, 1, 2, ..., 255] into a real number in\n    # the range [-1, 1].\n    x = (x / 127.5) - 1\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef expand_squeeze_to_nd(x, n, squeeze_dim=2, expand_dim=-1):\n  if len(x.shape) > n:\n    while len(x.shape) != n:\n      x = tf.squeeze(x, [squeeze_dim])\n  else:\n    while len(x.shape) != n:\n      x = tf.expand_dims(x, expand_dim)\n  return x", "response": "Make x n - d with squeeze and expand_dims."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nimaging standardization on batches and videos.", "response": "def standardize_images(x):\n  \"\"\"Image standardization on batches and videos.\"\"\"\n  with tf.name_scope(\"standardize_images\", values=[x]):\n    x_shape = shape_list(x)\n    x = to_float(tf.reshape(x, [-1] + x_shape[-3:]))\n    x_mean = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n    x_variance = tf.reduce_mean(\n        tf.squared_difference(x, x_mean), axis=[1, 2], keepdims=True)\n    num_pixels = to_float(x_shape[-2] * x_shape[-3])\n    x = (x - x_mean) / tf.maximum(tf.sqrt(x_variance), tf.rsqrt(num_pixels))\n    return tf.reshape(x, x_shape)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef flatten4d3d(x):\n  xshape = shape_list(x)\n  result = tf.reshape(x, [xshape[0], xshape[1] * xshape[2], xshape[3]])\n  return result", "response": "Flatten a 4d - tensor into a 3d - tensor by joining width and height."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nversioning of tf. gather that works faster on tpu.", "response": "def gather(params, indices, dtype=tf.float32):\n  \"\"\"Version of tf.gather that works faster on tpu.\"\"\"\n  if not is_xla_compiled():\n    return tf.gather(params, indices)\n  vocab_size = params.get_shape().as_list()[0]\n  indices_flat = tf.reshape(indices, [-1])\n  out = tf.matmul(tf.one_hot(indices_flat, vocab_size, dtype=dtype), params)\n  out = reshape_like(out, tf.expand_dims(indices, -1))\n  return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlikes tf. nn. dropout but does not scale up.", "response": "def dropout_no_scaling(x, keep_prob):\n  \"\"\"Like tf.nn.dropout, but does not scale up.  Works on integers also.\n\n  Args:\n    x: a Tensor\n    keep_prob: a floating point number\n\n  Returns:\n    Tensor of the same shape as x.\n  \"\"\"\n  if keep_prob == 1.0:\n    return x\n  mask = tf.less(tf.random_uniform(tf.shape(x)), keep_prob)\n  return x * cast_like(mask, x)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef embedding(x,\n              vocab_size,\n              dense_size,\n              name=None,\n              reuse=None,\n              multiplier=1.0,\n              symbol_dropout_rate=0.0,\n              embedding_var=None,\n              dtype=tf.float32):\n  \"\"\"Embed x of type int64 into dense vectors, reducing to max 4 dimensions.\"\"\"\n  with tf.variable_scope(\n      name, default_name=\"embedding\", values=[x], reuse=reuse, dtype=dtype):\n    if embedding_var is None:\n      embedding_var = tf.get_variable(\"kernel\", [vocab_size, dense_size])\n    # On the backwards pass, we want to convert the gradient from\n    # an indexed-slices to a regular tensor before sending it back to the\n    # parameter server. This avoids excess computation on the parameter server.\n    if not tf.executing_eagerly():\n      embedding_var = convert_gradient_to_tensor(embedding_var)\n    x = dropout_no_scaling(x, 1.0 - symbol_dropout_rate)\n    emb_x = gather(embedding_var, x, dtype)\n    if multiplier != 1.0:\n      emb_x *= multiplier\n    static_shape = emb_x.shape.as_list()\n    if len(static_shape) < 5:\n      return emb_x\n    assert len(static_shape) == 5\n    # If we had an extra channel dimension, assume it's 1, i.e. shape[3] == 1.\n    return tf.squeeze(emb_x, 3)", "response": "Embed x into dense vectors reducing to max 4 dimensions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshifting the second dimension of x right by one.", "response": "def shift_right(x, pad_value=None):\n  \"\"\"Shift the second dimension of x right by one.\"\"\"\n  if pad_value is None:\n    shifted_targets = tf.pad(x, [[0, 0], [1, 0], [0, 0], [0, 0]])[:, :-1, :, :]\n  else:\n    shifted_targets = tf.concat([pad_value, x], axis=1)[:, :-1, :, :]\n  return shifted_targets"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef shift_right_3d(x, pad_value=None):\n  if pad_value is None:\n    shifted_targets = tf.pad(x, [[0, 0], [1, 0], [0, 0]])[:, :-1, :]\n  else:\n    shifted_targets = tf.concat([pad_value, x], axis=1)[:, :-1, :]\n  return shifted_targets", "response": "Shift the second dimension of x right by one."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nshifts the second dimension of x right by one.", "response": "def shift_right_2d(x, pad_value=None):\n  \"\"\"Shift the second dimension of x right by one.\"\"\"\n  if pad_value is None:\n    shifted_targets = tf.pad(x, [[0, 0], [1, 0]])[:, :-1]\n  else:\n    shifted_targets = tf.concat([pad_value, x], axis=1)[:, :-1]\n  return shifted_targets"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nuse a strided convolution to downsample x by 2 n_steps times.", "response": "def conv_stride2_multistep(x, nbr_steps, output_filters, name=None, reuse=None):\n  \"\"\"Use a strided convolution to downsample x by 2, `nbr_steps` times.\n\n  We use stride and filter size 2 to avoid the checkerboard problem of deconvs.\n  As detailed in http://distill.pub/2016/deconv-checkerboard/.\n\n  Args:\n    x: a `Tensor` with shape `[batch, spatial, depth]` or\n     `[batch, spatial_1, spatial_2, depth]`\n    nbr_steps: number of halving downsample rounds to apply\n    output_filters: an int specifying the filter count for the convolutions\n    name: a string\n    reuse: a boolean\n\n  Returns:\n    a `Tensor` with shape `[batch, spatial / (2**nbr_steps), output_filters]` or\n     `[batch, spatial_1 / (2**nbr_steps), spatial_2 / (2**nbr_steps),\n       output_filters]`\n  \"\"\"\n  with tf.variable_scope(\n      name, default_name=\"conv_stride2_multistep\", values=[x], reuse=reuse):\n    if nbr_steps == 0:\n      out = conv(x, output_filters, (1, 1))\n      return out, [out]\n    hidden_layers = [x]\n    for i in range(nbr_steps):\n      hidden_layers.append(\n          conv(\n              hidden_layers[-1],\n              output_filters, (2, 2),\n              strides=2,\n              activation=tf.nn.relu,\n              name=\"conv\" + str(i)))\n    return hidden_layers[-1], hidden_layers"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuses a deconvolution to upsample x by 2 ** nbr_steps.", "response": "def deconv_stride2_multistep(x,\n                             nbr_steps,\n                             output_filters,\n                             name=None,\n                             reuse=None):\n  \"\"\"Use a deconvolution to upsample x by 2**`nbr_steps`.\n\n  Args:\n    x: a `Tensor` with shape `[batch, spatial, depth]` or\n     `[batch, spatial_1, spatial_2, depth]`\n    nbr_steps: an int specifying the number of doubling upsample rounds to\n     apply.\n    output_filters: an int specifying the filter count for the deconvolutions\n    name: a string\n    reuse: a boolean\n\n  Returns:\n    a `Tensor` with shape `[batch, spatial * (2**nbr_steps), output_filters]` or\n     `[batch, spatial_1 * (2**nbr_steps), spatial_2 * (2**nbr_steps),\n       output_filters]`\n  \"\"\"\n  with tf.variable_scope(\n      name, default_name=\"deconv_stride2_multistep\", values=[x], reuse=reuse):\n\n    def deconv1d(cur, i):\n      cur_shape = shape_list(cur)\n      thicker = conv(\n          cur,\n          output_filters * 2, (1, 1),\n          padding=\"SAME\",\n          activation=tf.nn.relu,\n          name=\"deconv1d\" + str(i))\n      return tf.reshape(thicker,\n                        [cur_shape[0], cur_shape[1] * 2, 1, output_filters])\n\n    def deconv2d(cur, i):\n      thicker = conv(\n          cur,\n          output_filters * 4, (1, 1),\n          padding=\"SAME\",\n          activation=tf.nn.relu,\n          name=\"deconv2d\" + str(i))\n      return tf.depth_to_space(thicker, 2)\n\n    cur = x\n    for i in range(nbr_steps):\n      if cur.get_shape()[2] == 1:\n        cur = deconv1d(cur, i)\n      else:\n        cur_dim = shape_list(cur)[2]\n        if isinstance(cur_dim, int):\n          if cur_dim == 1:\n            cur = deconv1d(cur, i)\n          else:\n            cur = deconv2d(cur, i)\n        else:\n          cur = tf.cond(\n              tf.equal(cur_dim, 1),\n              lambda idx=i: deconv1d(cur, idx),\n              lambda idx=i: deconv2d(cur, idx))\n    return cur"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef conv_internal(conv_fn, inputs, filters, kernel_size, **kwargs):\n  static_shape = inputs.get_shape()\n  if not static_shape or len(static_shape) != 4:\n    raise ValueError(\"Inputs to conv must have statically known rank 4. \"\n                     \"Shape: \" + str(static_shape))\n  # Add support for left padding.\n  if kwargs.get(\"padding\") == \"LEFT\":\n    dilation_rate = (1, 1)\n    if \"dilation_rate\" in kwargs:\n      dilation_rate = kwargs[\"dilation_rate\"]\n    assert kernel_size[0] % 2 == 1 and kernel_size[1] % 2 == 1\n    height_padding = 2 * (kernel_size[0] // 2) * dilation_rate[0]\n    cond_padding = tf.cond(\n        tf.equal(shape_list(inputs)[2], 1), lambda: tf.constant(0),\n        lambda: tf.constant(2 * (kernel_size[1] // 2) * dilation_rate[1]))\n    width_padding = 0 if static_shape[2] == 1 else cond_padding\n    padding = [[0, 0], [height_padding, 0], [width_padding, 0], [0, 0]]\n    inputs = tf.pad(inputs, padding)\n    # Set middle two dimensions to None to prevent convolution from complaining\n    inputs.set_shape([static_shape[0], None, None, static_shape[3]])\n    kwargs[\"padding\"] = \"VALID\"\n\n  def conv2d_kernel(kernel_size_arg, name_suffix):\n    \"\"\"Call conv2d but add suffix to name.\"\"\"\n    name = \"{}_{}\".format(kwargs.get(\"name\", \"conv\"), name_suffix)\n    original_name = kwargs.pop(\"name\", None)\n    original_force2d = kwargs.pop(\"force2d\", None)\n    result = conv_fn(inputs, filters, kernel_size_arg, name=name, **kwargs)\n    if original_name is not None:\n      kwargs[\"name\"] = original_name  # Restore for other calls.\n    if original_force2d is not None:\n      kwargs[\"force2d\"] = original_force2d\n    return result\n\n  return conv2d_kernel(kernel_size, \"single\")", "response": "Internal function for convolution."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsub - separable convolution.", "response": "def subseparable_conv(inputs, filters, kernel_size, **kwargs):\n  \"\"\"Sub-separable convolution. If separability == 0 it's a separable_conv.\"\"\"\n\n  def conv_fn(inputs, filters, kernel_size, **kwargs):\n    \"\"\"Sub-separable convolution, splits into separability-many blocks.\"\"\"\n    separability = None\n    if \"separability\" in kwargs:\n      separability = kwargs.pop(\"separability\")\n    if separability:\n      parts = []\n      abs_sep = separability if separability > 0 else -1 * separability\n      for split_idx, split in enumerate(tf.split(inputs, abs_sep, axis=3)):\n        with tf.variable_scope(\"part_%d\" % split_idx):\n          if separability > 0:\n            parts.append(\n                layers().Conv2D(filters // separability, kernel_size,\n                                **kwargs)(split))\n          else:\n            parts.append(\n                layers().SeparableConv2D(filters // abs_sep,\n                                         kernel_size, **kwargs)(split))\n      if separability > 1:\n        result = layers().Conv2D(filters, (1, 1))(tf.concat(parts, axis=3))\n      elif abs_sep == 1:  # If we have just one block, return it.\n        assert len(parts) == 1\n        result = parts[0]\n      else:\n        result = tf.concat(parts, axis=3)\n    else:\n      result = layers().SeparableConv2D(filters, kernel_size,\n                                        **kwargs)(inputs)\n    if separability is not None:\n      kwargs[\"separability\"] = separability\n    return result\n\n  return conv_internal(conv_fn, inputs, filters, kernel_size, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nversioning of conv1d that works on TPU.", "response": "def tpu_conv1d(inputs, filters, kernel_size, padding=\"SAME\", name=\"tpu_conv1d\"):\n  \"\"\"Version of conv1d that works on TPU (as of 11/2017).\n\n  Args:\n    inputs: a Tensor with shape [batch, length, input_depth].\n    filters: an integer.\n    kernel_size: an integer.\n    padding: a string - \"SAME\" or \"LEFT\".\n    name: a string.\n\n  Returns:\n    a Tensor with shape [batch, length, filters].\n  \"\"\"\n  if kernel_size == 1:\n    return dense(inputs, filters, name=name, use_bias=True)\n  if padding == \"SAME\":\n    assert kernel_size % 2 == 1\n    first_offset = -((kernel_size - 1) // 2)\n  else:\n    assert padding == \"LEFT\"\n    first_offset = -(kernel_size - 1)\n  last_offset = first_offset + kernel_size - 1\n  results = []\n  padded = tf.pad(inputs, [[0, 0], [-first_offset, last_offset], [0, 0]])\n  for i in range(kernel_size):\n    shifted = tf.slice(padded, [0, i, 0], tf.shape(inputs)) if i else inputs\n    shifted.set_shape(inputs.get_shape())\n    results.append(\n        dense(shifted, filters, use_bias=(i == 0), name=name + \"_%d\" % i))\n  ret = tf.add_n(results)\n  ret *= kernel_size**-0.5\n  return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef layer_norm_vars(filters):\n  scale = tf.get_variable(\n      \"layer_norm_scale\", [filters], initializer=tf.ones_initializer())\n  bias = tf.get_variable(\n      \"layer_norm_bias\", [filters], initializer=tf.zeros_initializer())\n  return scale, bias", "response": "Create Variables for layer norm."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef layer_norm_compute(x, epsilon, scale, bias, layer_collection=None):\n\n  # Save these before they get converted to tensors by the casting below\n  params = (scale, bias)\n\n  epsilon, scale, bias = [cast_like(t, x) for t in [epsilon, scale, bias]]\n  mean = tf.reduce_mean(x, axis=[-1], keepdims=True)\n  variance = tf.reduce_mean(\n      tf.squared_difference(x, mean), axis=[-1], keepdims=True)\n  norm_x = (x - mean) * tf.rsqrt(variance + epsilon)\n\n  output = norm_x * scale + bias\n\n\n  return output", "response": "Layer norm raw computation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlayering normalize the tensor x averaging over the last dimension.", "response": "def layer_norm(x,\n               filters=None,\n               epsilon=1e-6,\n               name=None,\n               reuse=None,\n               layer_collection=None):\n  \"\"\"Layer normalize the tensor x, averaging over the last dimension.\"\"\"\n  if filters is None:\n    filters = shape_list(x)[-1]\n  with tf.variable_scope(\n      name, default_name=\"layer_norm\", values=[x], reuse=reuse):\n    scale, bias = layer_norm_vars(filters)\n    return layer_norm_compute(x, epsilon, scale, bias,\n                              layer_collection=layer_collection)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngrouping normalization as in https://arxiv. org. abs. 1803. 08494.", "response": "def group_norm(x, filters=None, num_groups=8, epsilon=1e-5):\n  \"\"\"Group normalization as in https://arxiv.org/abs/1803.08494.\"\"\"\n  x_shape = shape_list(x)\n  if filters is None:\n    filters = x_shape[-1]\n  assert len(x_shape) == 4\n  assert filters % num_groups == 0\n  # Prepare variables.\n  scale = tf.get_variable(\n      \"group_norm_scale\", [filters], initializer=tf.ones_initializer())\n  bias = tf.get_variable(\n      \"group_norm_bias\", [filters], initializer=tf.zeros_initializer())\n  epsilon, scale, bias = [cast_like(t, x) for t in [epsilon, scale, bias]]\n  # Reshape and compute group norm.\n  x = tf.reshape(x, x_shape[:-1] + [num_groups, filters // num_groups])\n  # Calculate mean and variance on heights, width, channels (not groups).\n  mean, variance = tf.nn.moments(x, [1, 2, 4], keep_dims=True)\n  norm_x = (x - mean) * tf.rsqrt(variance + epsilon)\n  return tf.reshape(norm_x, x_shape) * scale + bias"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef l2_norm(x, filters=None, epsilon=1e-6, name=None, reuse=None):\n  if filters is None:\n    filters = shape_list(x)[-1]\n  with tf.variable_scope(name, default_name=\"l2_norm\", values=[x], reuse=reuse):\n    scale = tf.get_variable(\n        \"l2_norm_scale\", [filters], initializer=tf.ones_initializer())\n    bias = tf.get_variable(\n        \"l2_norm_bias\", [filters], initializer=tf.zeros_initializer())\n    epsilon, scale, bias = [cast_like(t, x) for t in [epsilon, scale, bias]]\n    mean = tf.reduce_mean(x, axis=[-1], keepdims=True)\n    l2norm = tf.reduce_sum(\n        tf.squared_difference(x, mean), axis=[-1], keepdims=True)\n    norm_x = (x - mean) * tf.rsqrt(l2norm + epsilon)\n    return norm_x * scale + bias", "response": "Layer normalization with l2 norm."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply_spectral_norm(x):\n  weights_shape = shape_list(x)\n  other, num_filters = tf.reduce_prod(weights_shape[:-1]), weights_shape[-1]\n\n  # Reshape into a 2-D matrix with outer size num_filters.\n  weights_2d = tf.reshape(x, (other, num_filters))\n\n  # v = Wu / ||W u||\n  with tf.variable_scope(\"u\", reuse=tf.AUTO_REUSE):\n    u = tf.get_variable(\n        \"u\", [num_filters, 1],\n        initializer=tf.truncated_normal_initializer(),\n        trainable=False)\n  v = tf.nn.l2_normalize(tf.matmul(weights_2d, u))\n\n  # u_new = vW / ||v W||\n  u_new = tf.nn.l2_normalize(tf.matmul(tf.transpose(v), weights_2d))\n\n  # s = v*W*u\n  spectral_norm = tf.squeeze(\n      tf.matmul(tf.transpose(v), tf.matmul(weights_2d, tf.transpose(u_new))))\n\n  # set u equal to u_new in the next iteration.\n  assign_op = tf.assign(u, tf.transpose(u_new))\n  return tf.divide(x, spectral_norm), assign_op", "response": "Normalizes x using the spectral norm."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef layer_prepostprocess(previous_value,\n                         x,\n                         sequence,\n                         dropout_rate,\n                         norm_type,\n                         depth,\n                         epsilon,\n                         default_name,\n                         name=None,\n                         dropout_broadcast_dims=None,\n                         layer_collection=None):\n  \"\"\"Apply a sequence of functions to the input or output of a layer.\n\n  The sequence is specified as a string which may contain the following\n  characters:\n    a: add previous_value\n    n: apply normalization\n    d: apply dropout\n    z: zero add\n\n  For example, if sequence==\"dna\", then the output is\n    previous_value + normalize(dropout(x))\n\n  Args:\n    previous_value: A Tensor, to be added as a residual connection ('a')\n    x: A Tensor to be transformed.\n    sequence: a string.\n    dropout_rate: a float\n    norm_type: a string (see apply_norm())\n    depth: an integer (size of last dimension of x).\n    epsilon: a float (parameter for normalization)\n    default_name: a string\n    name: a string\n    dropout_broadcast_dims:  an optional list of integers less than 3\n      specifying in which dimensions to broadcast the dropout decisions.\n      saves memory.\n    layer_collection: A tensorflow_kfac.LayerCollection. Only used by the\n      KFAC optimizer. Default is None.\n\n  Returns:\n    a Tensor\n  \"\"\"\n  with tf.variable_scope(name, default_name=default_name):\n    if sequence == \"none\":\n      return x\n    for c in sequence:\n      if c == \"a\":\n        x += previous_value\n      elif c == \"z\":\n        x = zero_add(previous_value, x)\n      elif c == \"n\":\n        x = apply_norm(\n            x, norm_type, depth, epsilon, layer_collection=layer_collection)\n      else:\n        assert c == \"d\", (\"Unknown sequence step %s\" % c)\n        x = dropout_with_broadcast_dims(\n            x, 1.0 - dropout_rate, broadcast_dims=dropout_broadcast_dims)\n    return x", "response": "Applies a sequence of functions to the input or output of a layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef layer_preprocess(layer_input, hparams, layer_collection=None):\n  assert \"a\" not in hparams.layer_preprocess_sequence, (\n      \"No residual connections allowed in hparams.layer_preprocess_sequence\")\n  assert \"z\" not in hparams.layer_preprocess_sequence, (\n      \"No residual connections allowed in hparams.layer_preprocess_sequence\")\n  return layer_prepostprocess(\n      None,\n      layer_input,\n      sequence=hparams.layer_preprocess_sequence,\n      dropout_rate=hparams.layer_prepostprocess_dropout,\n      norm_type=hparams.norm_type,\n      depth=None,\n      epsilon=hparams.norm_epsilon,\n      dropout_broadcast_dims=comma_separated_string_to_integer_list(\n          getattr(hparams, \"layer_prepostprocess_dropout_broadcast_dims\", \"\")),\n      default_name=\"layer_prepostprocess\",\n      layer_collection=layer_collection)", "response": "Apply layer preprocessing.\n\n  See layer_prepostprocess() for details.\n\n  A hyperparameters object is passed for convenience.  The hyperparameters\n  that may be used are:\n\n    layer_preprocess_sequence\n    layer_prepostprocess_dropout\n    norm_type\n    hidden_size\n    norm_epsilon\n\n  Args:\n    layer_input: a Tensor\n    hparams: a hyperparameters object.\n    layer_collection: A tensorflow_kfac.LayerCollection. Only used by the\n      KFAC optimizer. Default is None.\n\n  Returns:\n    a Tensor"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply layer postprocessing. See layer_prepostprocess() for details. A hyperparameters object is passed for convenience. The hyperparameters that may be used are: layer_postprocess_sequence layer_prepostprocess_dropout norm_type hidden_size norm_epsilon Args: layer_input: a Tensor layer_output: a Tensor hparams: a hyperparameters object. Returns: a Tensor", "response": "def layer_postprocess(layer_input, layer_output, hparams):\n  \"\"\"Apply layer postprocessing.\n\n  See layer_prepostprocess() for details.\n\n  A hyperparameters object is passed for convenience.  The hyperparameters\n  that may be used are:\n\n    layer_postprocess_sequence\n    layer_prepostprocess_dropout\n    norm_type\n    hidden_size\n    norm_epsilon\n\n  Args:\n    layer_input: a Tensor\n    layer_output: a Tensor\n    hparams: a hyperparameters object.\n\n  Returns:\n    a Tensor\n  \"\"\"\n  return layer_prepostprocess(\n      layer_input,\n      layer_output,\n      sequence=hparams.layer_postprocess_sequence,\n      dropout_rate=hparams.layer_prepostprocess_dropout,\n      norm_type=hparams.norm_type,\n      depth=None,\n      epsilon=hparams.norm_epsilon,\n      dropout_broadcast_dims=comma_separated_string_to_integer_list(\n          getattr(hparams, \"layer_prepostprocess_dropout_broadcast_dims\", \"\")),\n      default_name=\"layer_postprocess\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef conv_block_internal(conv_fn,\n                        inputs,\n                        filters,\n                        dilation_rates_and_kernel_sizes,\n                        first_relu=True,\n                        use_elu=False,\n                        separabilities=None,\n                        **kwargs):\n  \"\"\"A block of convolutions.\n\n  Args:\n    conv_fn: convolution function, e.g. conv or separable_conv.\n    inputs: a Tensor\n    filters: an Integer\n    dilation_rates_and_kernel_sizes: a list of tuples (dilation, (k_w, k_h))\n    first_relu: whether to do a relu at start (defaults to True)\n    use_elu: whether to use ELUs instead of ReLUs (defaults to False)\n    separabilities: list of separability factors (per-layer).\n    **kwargs: additional arguments (e.g., pooling)\n\n  Returns:\n     a Tensor.\n  \"\"\"\n\n  name = kwargs.pop(\"name\") if \"name\" in kwargs else None\n  mask = kwargs.pop(\"mask\") if \"mask\" in kwargs else None\n\n  # Usage for normalize_fn kwarg:\n  # if not specified, use layer norm\n  # if given normalize_fn=None, don't use any normalization\n  # if given normalize_fn=norm, use the specified norm function\n\n  use_layer_norm = \"normalizer_fn\" not in kwargs\n  norm = kwargs.pop(\"normalizer_fn\", None)\n  use_normalizer_fn = use_layer_norm or norm\n\n  if use_layer_norm:\n    norm = lambda x, name: layer_norm(x, filters, name=name)\n\n  with tf.variable_scope(name, \"conv_block\", [inputs]):\n    cur, counter = inputs, -1\n    for dilation_rate, kernel_size in dilation_rates_and_kernel_sizes:\n      counter += 1\n      if first_relu or counter > 0:\n        cur = tf.nn.elu(cur) if use_elu else tf.nn.relu(cur)\n      if mask is not None:\n        cur *= mask\n      if separabilities:\n        cur = conv_fn(\n            cur,\n            filters,\n            kernel_size,\n            dilation_rate=dilation_rate,\n            name=\"conv_block_%d\" % counter,\n            use_bias=norm is None,\n            separability=separabilities[counter],\n            **kwargs)\n      else:\n        cur = conv_fn(\n            cur,\n            filters,\n            kernel_size,\n            dilation_rate=dilation_rate,\n            name=\"conv_block_%d\" % counter,\n            use_bias=norm is None,\n            **kwargs)\n      if use_normalizer_fn:\n        cur = norm(cur, name=\"conv_block_norm_%d\" % counter)\n    return cur", "response": "Internal function for convolution block."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef conv_block(inputs, filters, dilation_rates_and_kernel_sizes, **kwargs):\n  return conv_block_internal(conv, inputs, filters,\n                             dilation_rates_and_kernel_sizes, **kwargs)", "response": "A block of standard 2d convolutions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef separable_conv_block(inputs, filters, dilation_rates_and_kernel_sizes,\n                         **kwargs):\n  \"\"\"A block of separable convolutions.\"\"\"\n  return conv_block_internal(separable_conv, inputs, filters,\n                             dilation_rates_and_kernel_sizes, **kwargs)", "response": "A block of separable convolutions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef subseparable_conv_block(inputs, filters, dilation_rates_and_kernel_sizes,\n                            **kwargs):\n  \"\"\"A block of separable convolutions.\"\"\"\n  return conv_block_internal(subseparable_conv, inputs, filters,\n                             dilation_rates_and_kernel_sizes, **kwargs)", "response": "A block of separable convolutions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef conv_block_downsample(x,\n                          kernel,\n                          strides,\n                          padding,\n                          separability=0,\n                          name=None,\n                          reuse=None):\n  \"\"\"Implements a downwards-striding conv block, like Xception exit flow.\"\"\"\n  with tf.variable_scope(\n      name, default_name=\"conv_block_downsample\", values=[x], reuse=reuse):\n    hidden_size = int(x.get_shape()[-1])\n    res = conv_block(\n        x,\n        int(1.25 * hidden_size), [((1, 1), kernel)],\n        padding=padding,\n        strides=strides,\n        name=\"res_conv\")\n\n    x = subseparable_conv_block(\n        x,\n        hidden_size, [((1, 1), kernel)],\n        padding=padding,\n        separability=separability,\n        name=\"conv0\")\n    x = subseparable_conv_block(\n        x,\n        int(1.25 * hidden_size), [((1, 1), kernel)],\n        padding=padding,\n        separability=separability,\n        name=\"conv1\")\n    x = pool(x, kernel, \"MAX\", padding, strides=strides)\n\n    x += res\n\n    x = subseparable_conv_block(\n        x,\n        2 * hidden_size, [((1, 1), kernel)],\n        first_relu=False,\n        padding=padding,\n        separability=separability,\n        name=\"conv2\")\n    x = subseparable_conv_block(\n        x,\n        int(2.5 * hidden_size), [((1, 1), kernel)],\n        padding=padding,\n        separability=separability,\n        name=\"conv3\")\n    return x", "response": "Implements a downwards - striding conv block like Xception exit flow."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_timing_signal(length,\n                      min_timescale=1,\n                      max_timescale=1e4,\n                      num_timescales=16):\n  \"\"\"Create Tensor of sinusoids of different frequencies.\n\n  Args:\n    length: Length of the Tensor to create, i.e. Number of steps.\n    min_timescale: a float\n    max_timescale: a float\n    num_timescales: an int\n\n  Returns:\n    Tensor of shape (length, 2*num_timescales)\n  \"\"\"\n  positions = to_float(tf.range(length))\n  log_timescale_increment = (\n      math.log(max_timescale / min_timescale) / (num_timescales - 1))\n  inv_timescales = min_timescale * tf.exp(\n      to_float(tf.range(num_timescales)) * -log_timescale_increment)\n  scaled_time = tf.expand_dims(positions, 1) * tf.expand_dims(inv_timescales, 0)\n  return tf.concat([tf.sin(scaled_time), tf.cos(scaled_time)], axis=1)", "response": "Create a Tensor of sinusoids of different frequencies."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_timing_signal(x, min_timescale=1, max_timescale=1e4, num_timescales=16):\n  length = shape_list(x)[1]\n  depth = shape_list(x)[3]\n  signal = get_timing_signal(length, min_timescale, max_timescale,\n                             num_timescales)\n  padded_signal = tf.pad(signal, [[0, 0], [0, depth - 2 * num_timescales]])\n  return x + tf.reshape(padded_signal, [1, length, 1, depth])", "response": "Adds a timing signal to a Tensor x."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mask_from_embedding(emb):\n  return weights_nonzero(tf.reduce_sum(tf.abs(emb), axis=3, keepdims=True))", "response": "Input embeddings -> padding mask.\n"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the length of each sequence in the batch.", "response": "def length_from_embedding(emb):\n  \"\"\"Compute the length of each sequence in the batch.\n\n  Args:\n    emb: a sequence embedding Tensor with shape [batch, max_time, 1, depth].\n  Returns:\n    a Tensor with shape [batch].\n  \"\"\"\n  return tf.cast(tf.reduce_sum(mask_from_embedding(emb), [1, 2, 3]), tf.int32)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef relu_density_logit(x, reduce_dims):\n  frac = tf.reduce_mean(to_float(x > 0.0), reduce_dims)\n  scaled = tf.log(frac + math.exp(-10)) - tf.log((1.0 - frac) + math.exp(-10))\n  return scaled", "response": "logit - density of a tensor x Useful for histograms."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhides layer with RELU activation followed by linear projection.", "response": "def dense_relu_dense(inputs,\n                     filter_size,\n                     output_size,\n                     output_activation=None,\n                     dropout=0.0,\n                     dropout_broadcast_dims=None,\n                     layer_collection=None,\n                     name=None):\n  \"\"\"Hidden layer with RELU activation followed by linear projection.\"\"\"\n  # layer_name is appended with \"conv1\" or \"conv2\" in this method only for\n  # historical reasons. These are in fact dense layers.\n  layer_name = \"%s_{}\" % name if name else \"{}\"\n  h = dense(\n      inputs,\n      filter_size,\n      use_bias=True,\n      activation=tf.nn.relu,\n      layer_collection=layer_collection,\n      name=layer_name.format(\"conv1\"))\n\n  if dropout != 0.0:\n    h = dropout_with_broadcast_dims(\n        h, 1.0 - dropout, broadcast_dims=dropout_broadcast_dims)\n  o = dense(\n      h,\n      output_size,\n      activation=output_activation,\n      use_bias=True,\n      layer_collection=layer_collection,\n      name=layer_name.format(\"conv2\"))\n  return o"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dense_dropconnect(inputs,\n                      output_size,\n                      dropconnect_dropout=0.0,\n                      name=\"dense_dropconnect\",\n                      **kwargs):\n  \"\"\"Dense layer with dropconnect.\"\"\"\n\n  if dropconnect_dropout != 0.0:\n    tf.logging.info(\"Applying dropconnect as the kernel regularization.\")\n    kwargs[\"kernel_regularizer\"] = functools.partial(\n        tf.nn.dropout, keep_prob=1.0 - dropconnect_dropout)\n\n  return dense(inputs, output_size, use_bias=True, name=name, **kwargs)", "response": "Dense layer with dropconnect."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef conv_relu_conv(inputs,\n                   filter_size,\n                   output_size,\n                   first_kernel_size=3,\n                   second_kernel_size=3,\n                   padding=\"SAME\",\n                   nonpadding_mask=None,\n                   dropout=0.0,\n                   name=None,\n                   cache=None,\n                   decode_loop_step=None):\n  \"\"\"Hidden layer with RELU activation followed by linear projection.\n\n  Args:\n    inputs: A tensor.\n    filter_size: An integer.\n    output_size: An integer.\n    first_kernel_size: An integer.\n    second_kernel_size: An integer.\n    padding: A string.\n    nonpadding_mask: A tensor.\n    dropout: A float.\n    name: A string.\n    cache: A dict, containing Tensors which are the results of previous\n        attentions, used for fast decoding.\n    decode_loop_step: An integer, step number of the decoding loop.\n        Only used for inference on TPU. If it is not None, the function\n        will do inplace update for the cache instead of concatenating the\n        current result to the cache.\n\n  Returns:\n    A Tensor.\n  \"\"\"\n  with tf.variable_scope(name, \"conv_relu_conv\", [inputs]):\n    inputs = maybe_zero_out_padding(inputs, first_kernel_size, nonpadding_mask)\n\n    if cache:\n      if decode_loop_step is None:\n        inputs = cache[\"f\"] = tf.concat([cache[\"f\"], inputs], axis=1)\n      else:\n        # Inplace update is required for inference on TPU.\n        # Inplace_ops only supports inplace_update on the first dimension.\n        # The performance of current implementation is better than updating\n        # the tensor by adding the result of matmul(one_hot,\n        # update_in_current_step)\n        tmp_f = tf.transpose(cache[\"f\"], perm=[1, 0, 2])\n        tmp_f = inplace_ops.alias_inplace_update(\n            tmp_f,\n            decode_loop_step * tf.shape(inputs)[1],\n            tf.transpose(inputs, perm=[1, 0, 2]))\n        inputs = cache[\"f\"] = tf.transpose(tmp_f, perm=[1, 0, 2])\n      inputs = cache[\"f\"] = inputs[:, -first_kernel_size:, :]\n\n    h = tpu_conv1d(\n        inputs, filter_size, first_kernel_size, padding=padding, name=\"conv1\")\n\n    if cache:\n      h = h[:, -1:, :]\n\n    h = tf.nn.relu(h)\n    if dropout != 0.0:\n      h = tf.nn.dropout(h, 1.0 - dropout)\n    h = maybe_zero_out_padding(h, second_kernel_size, nonpadding_mask)\n    return tpu_conv1d(\n        h, output_size, second_kernel_size, padding=padding, name=\"conv2\")", "response": "Hidden layer with RELU activation followed by linear projection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sepconv_relu_sepconv(inputs,\n                         filter_size,\n                         output_size,\n                         first_kernel_size=(1, 1),\n                         second_kernel_size=(1, 1),\n                         padding=\"LEFT\",\n                         nonpadding_mask=None,\n                         dropout=0.0,\n                         name=None):\n  \"\"\"Hidden layer with RELU activation followed by linear projection.\"\"\"\n  with tf.variable_scope(name, \"sepconv_relu_sepconv\", [inputs]):\n    inputs = maybe_zero_out_padding(inputs, first_kernel_size, nonpadding_mask)\n    if inputs.get_shape().ndims == 3:\n      is_3d = True\n      inputs = tf.expand_dims(inputs, 2)\n    else:\n      is_3d = False\n    h = separable_conv(\n        inputs,\n        filter_size,\n        first_kernel_size,\n        activation=tf.nn.relu,\n        padding=padding,\n        name=\"conv1\")\n    if dropout != 0.0:\n      h = tf.nn.dropout(h, 1.0 - dropout)\n    h = maybe_zero_out_padding(h, second_kernel_size, nonpadding_mask)\n    ret = separable_conv(\n        h, output_size, second_kernel_size, padding=padding, name=\"conv2\")\n    if is_3d:\n      ret = tf.squeeze(ret, 2)\n    return ret", "response": "Hidden layer with RELU activation followed by linear projection."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef conv_hidden_relu(inputs,\n                     hidden_size,\n                     output_size,\n                     kernel_size=(1, 1),\n                     second_kernel_size=(1, 1),\n                     dropout=0.0,\n                     **kwargs):\n  \"\"\"Hidden layer with RELU activation followed by linear projection.\"\"\"\n  name = kwargs.pop(\"name\") if \"name\" in kwargs else None\n  with tf.variable_scope(name, \"conv_hidden_relu\", [inputs]):\n    if inputs.get_shape().ndims == 3:\n      is_3d = True\n      inputs = tf.expand_dims(inputs, 2)\n    else:\n      is_3d = False\n    conv_f1 = conv if kernel_size == (1, 1) else separable_conv\n    h = conv_f1(\n        inputs,\n        hidden_size,\n        kernel_size,\n        activation=tf.nn.relu,\n        name=\"conv1\",\n        **kwargs)\n    if dropout != 0.0:\n      h = tf.nn.dropout(h, 1.0 - dropout)\n    conv_f2 = conv if second_kernel_size == (1, 1) else separable_conv\n    ret = conv_f2(h, output_size, second_kernel_size, name=\"conv2\", **kwargs)\n    if is_3d:\n      ret = tf.squeeze(ret, 2)\n    return ret", "response": "Hidden layer with RELU activation followed by linear projection."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npositioning - wise Feed - fwd GRU gates following MPNN.", "response": "def gru_feedfwd(a_t, h_prev, filters, name=None):\n  \"\"\"position-wise Feed-fwd GRU gates following the MPNN.\n\n  Args:\n    a_t: Tensor of shape [batch, length, depth] of current input\n    h_prev: Tensor of shape [batch, length, depth] of prev input\n    filters: an integer specifying number of dimensions of the filters\n    name: A string\n  Returns:\n    h_t: [batch, length, filters] hidden state\n  \"\"\"\n\n  with tf.variable_scope(name, default_name=\"GRU\", values=[a_t, h_prev]):\n    # we use right matrix multiplication to handle batches\n    # W_z and W_r have shape 2d, d. U_z U_r have shape d,d\n    z_t = (\n        tf.sigmoid(\n            tpu_conv1d(a_t, filters, 1, padding=\"SAME\", name=\"W_z\") +\n            tpu_conv1d(h_prev, filters, 1, padding=\"SAME\", name=\"U_z\")))\n    r_t = (\n        tf.sigmoid(\n            tpu_conv1d(a_t, filters, 1, padding=\"SAME\", name=\"W_r\") +\n            tpu_conv1d(h_prev, filters, 1, padding=\"SAME\", name=\"U_r\")))\n    h_tilde = (\n        tf.tanh(\n            tpu_conv1d(a_t, filters, 1, padding=\"SAME\", name=\"W\") +\n            tpu_conv1d(r_t * h_prev, filters, 1, padding=\"SAME\", name=\"U\")))\n    h_t = (1. - z_t) * h_prev + z_t * h_tilde\n\n  return h_t"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef conv_lstm(x,\n              kernel_size,\n              filters,\n              padding=\"SAME\",\n              dilation_rate=(1, 1),\n              name=None,\n              reuse=None):\n  \"\"\"Convolutional LSTM in 1 dimension.\"\"\"\n  with tf.variable_scope(\n      name, default_name=\"conv_lstm\", values=[x], reuse=reuse):\n    gates = conv(\n        x,\n        4 * filters,\n        kernel_size,\n        padding=padding,\n        dilation_rate=dilation_rate)\n    g = tf.split(layer_norm(gates, 4 * filters), 4, axis=3)\n    new_cell = tf.sigmoid(g[0]) * x + tf.sigmoid(g[1]) * tf.tanh(g[3])\n    return tf.sigmoid(g[2]) * tf.tanh(new_cell)", "response": "Convolutional LSTM in 1 dimension."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef diagonal_conv_gru(x,\n                      kernel_size,\n                      filters,\n                      dropout=0.0,\n                      name=None,\n                      reuse=None):\n  \"\"\"Diagonal Convolutional GRU as in https://arxiv.org/abs/1702.08727.\"\"\"\n\n  # Let's make a shorthand for conv call first.\n  def do_conv(args, name, bias_start):\n    return conv(\n        args,\n        filters,\n        kernel_size,\n        padding=\"SAME\",\n        bias_initializer=tf.constant_initializer(bias_start),\n        name=name)\n\n  # Here comes the GRU gate.\n  with tf.variable_scope(\n      name, default_name=\"diagonal_conv_gru\", values=[x], reuse=reuse):\n    reset, reset_cost = hard_sigmoid(do_conv(x, \"reset\", 0.5))\n    gate, gate_cost = hard_sigmoid(do_conv(x, \"gate\", 0.7))\n    candidate = tf.tanh(do_conv(reset * x, \"candidate\", 0.0))\n\n    if dropout > 0.0:\n      candidate = tf.nn.dropout(candidate, 1.0 - dropout)\n\n    # Diagonal shift.\n    shift_filters = filters // 3\n    base_filter = ([[0, 1, 0]] * (filters - 2 * shift_filters) +\n                   [[1, 0, 0]] * shift_filters + [[0, 0, 1]] * shift_filters)\n    shift_filter = tf.constant(np.transpose(base_filter), dtype=tf.float32)\n    shift_filter = tf.expand_dims(tf.expand_dims(shift_filter, 0), 3)\n    x_shifted = tf.nn.depthwise_conv2d(\n        x, shift_filter, [1, 1, 1, 1], padding=\"SAME\")\n\n    # Return the gated result and cost.\n    total_cost_avg = 0.5 * (reset_cost + gate_cost)\n    return gate * x_shifted + (1 - gate) * candidate, total_cost_avg", "response": "Diagonal Convolutional GRU as in https://arxiv.org/abs/1702.08727."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npad x and y on axis 1 so that they have the same length.", "response": "def pad_to_same_length(x, y, final_length_divisible_by=1, axis=1):\n  \"\"\"Pad tensors x and y on axis 1 so that they have the same length.\"\"\"\n  if axis not in [1, 2]:\n    raise ValueError(\"Only axis=1 and axis=2 supported for now.\")\n  with tf.name_scope(\"pad_to_same_length\", values=[x, y]):\n    x_length = shape_list(x)[axis]\n    y_length = shape_list(y)[axis]\n    if (isinstance(x_length, int) and isinstance(y_length, int) and\n        x_length == y_length and final_length_divisible_by == 1):\n      return x, y\n    max_length = tf.maximum(x_length, y_length)\n    if final_length_divisible_by > 1:\n      # Find the nearest larger-or-equal integer divisible by given number.\n      max_length += final_length_divisible_by - 1\n      max_length //= final_length_divisible_by\n      max_length *= final_length_divisible_by\n    length_diff1 = max_length - x_length\n    length_diff2 = max_length - y_length\n\n    def padding_list(length_diff, arg):\n      if axis == 1:\n        return [[[0, 0], [0, length_diff]],\n                tf.zeros([tf.rank(arg) - 2, 2], dtype=tf.int32)]\n      return [[[0, 0], [0, 0], [0, length_diff]],\n              tf.zeros([tf.rank(arg) - 3, 2], dtype=tf.int32)]\n\n    paddings1 = tf.concat(padding_list(length_diff1, x), axis=0)\n    paddings2 = tf.concat(padding_list(length_diff2, y), axis=0)\n    res_x = tf.pad(x, paddings1)\n    res_y = tf.pad(y, paddings2)\n    # Static shapes are the same except for axis=1.\n    x_shape = x.shape.as_list()\n    x_shape[axis] = None\n    res_x.set_shape(x_shape)\n    y_shape = y.shape.as_list()\n    y_shape[axis] = None\n    res_y.set_shape(y_shape)\n    return res_x, res_y"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pad_with_zeros(logits, labels):\n  with tf.name_scope(\"pad_with_zeros\", values=[logits, labels]):\n    logits, labels = pad_to_same_length(logits, labels)\n    if len(labels.shape) == 3:  # 2-d labels.\n      logits, labels = pad_to_same_length(logits, labels, axis=2)\n    return logits, labels", "response": "Pad labels on the length dimension to match logits length."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nassign weight 1. 0 to only the targets portion of the labels.", "response": "def weights_prepend_inputs_to_targets(labels):\n  \"\"\"Assign weight 1.0 to only the \"targets\" portion of the labels.\n\n  Weight 1.0 is assigned to all nonzero labels past the first zero.\n  See prepend_mode in common_hparams.py\n\n  Args:\n    labels: A Tensor of int32s.\n\n  Returns:\n    A Tensor of floats.\n  \"\"\"\n  past_first_zero = tf.cumsum(to_float(tf.equal(labels, 0)), axis=1)\n  nonzero = to_float(labels)\n  return to_float(tf.not_equal(past_first_zero * nonzero, 0))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_nonnegative(value):\n  if isinstance(value, tf.Tensor):\n    with tf.control_dependencies([tf.assert_greater_equal(value, 0)]):\n      value = tf.identity(value)\n  elif value < 0:\n    raise ValueError(\"Value must be non-negative.\")\n  return value", "response": "Check that the value is nonnegative."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nassigning weight 1. 0 to only the targets portion of the labels.", "response": "def weights_multi_problem(labels, taskid=-1):\n  \"\"\"Assign weight 1.0 to only the \"targets\" portion of the labels.\n\n  Weight 1.0 is assigned to all labels past the taskid.\n\n  Args:\n    labels: A Tensor of int32s.\n    taskid: an int32 representing the task id for a problem.\n\n  Returns:\n    A Tensor of floats.\n\n  Raises:\n    ValueError: The Task ID must be valid.\n  \"\"\"\n  taskid = check_nonnegative(taskid)\n  past_taskid = tf.cumsum(to_float(tf.equal(labels, taskid)), axis=1)\n  # Additionally zero out the task id location\n  past_taskid *= to_float(tf.not_equal(labels, taskid))\n  non_taskid = to_float(labels)\n  return to_float(tf.not_equal(past_taskid * non_taskid, 0))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nassigning weight 1. 0 to only examples from the given task.", "response": "def weights_multi_problem_all(labels, taskid=-1):\n  \"\"\"Assign weight 1.0 to only examples from the given task.\"\"\"\n  taskid = check_nonnegative(taskid)\n  weights = to_float(tf.not_equal(labels, 0))\n  past_taskid = tf.cumsum(to_float(tf.equal(labels, taskid)), axis=1)\n  # Additionally zero out the task id location\n  past_taskid *= to_float(tf.not_equal(labels, taskid))\n  non_taskid = to_float(labels)\n  example_mask = to_float(tf.not_equal(past_taskid * non_taskid, 0))\n  example_mask = tf.reduce_sum(example_mask, axis=1)\n  example_mask = to_float(\n      tf.greater(example_mask, tf.zeros_like(example_mask)))\n\n  return weights * tf.expand_dims(example_mask, axis=-1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nassign weight 1. 0 to only the inputs for the given task.", "response": "def weights_multi_problem_input(labels, taskid=-1):\n  \"\"\"Assign weight 1.0 to only the inputs for the given task.\"\"\"\n  taskid = check_nonnegative(taskid)\n  weights_all_tokens = weights_multi_problem_all(labels, taskid)\n  weights_target = weights_multi_problem(labels, taskid)\n  return weights_all_tokens - weights_target"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef weights_concatenated(labels):\n  eos_mask = tf.to_int32(tf.equal(labels, 1))\n  sentence_num = tf.cumsum(eos_mask, axis=1, exclusive=True)\n  in_target = tf.equal(tf.mod(sentence_num, 2), 1)\n  # first two tokens of each sentence are boilerplate.\n  sentence_num_plus_one = sentence_num + 1\n  shifted = tf.pad(sentence_num_plus_one,\n                   [[0, 0], [2, 0], [0, 0], [0, 0]])[:, :-2, :, :]\n  nonboilerplate = tf.equal(sentence_num_plus_one, shifted)\n  ret = to_float(tf.logical_and(nonboilerplate, in_target))\n  return ret", "response": "Assign weight 1. 0 to the target part of the concatenated labels."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the padded cross - entropy of the current state.", "response": "def padded_cross_entropy(logits,\n                         labels,\n                         label_smoothing,\n                         weights_fn=weights_nonzero,\n                         reduce_sum=True,\n                         cutoff=0.0,\n                         gaussian=False):\n  \"\"\"Compute cross-entropy assuming 0s are padding.\n\n  Computes a loss numerator (the sum of losses), and loss denominator\n  (the number of non-padding tokens).\n\n  Args:\n    logits: a `Tensor` with shape `[batch, timesteps, vocab_size]`.\n      optionally a FactoredTensor.\n    labels: an integer `Tensor` with shape `[batch, timesteps]`.\n    label_smoothing: a floating point `Scalar`.\n    weights_fn: A function from labels to weights.\n    reduce_sum: a Boolean, whether to sum at the end or not.\n    cutoff: a float, at which point to have no loss.\n    gaussian: If true, use a Gaussian distribution for label smoothing\n\n  Returns:\n    loss_numerator: a `Scalar`.  Sum of losses.\n    loss_denominator: a `Scalar.  The number of non-padding target tokens.\n\n  Raises:\n    ValueError: in case of unsupported argument types.\n  \"\"\"\n  if isinstance(logits, FactoredTensor):\n    if gaussian:\n      raise ValueError(\"Factored padded cross entropy with Gaussian smoothing \"\n                       \"is not implemented yet.\")\n    return padded_cross_entropy_factored(\n        logits,\n        labels,\n        label_smoothing,\n        weights_fn=weights_fn,\n        reduce_sum=reduce_sum)\n  confidence = 1.0 - label_smoothing\n  logits_shape = shape_list(logits)\n  vocab_size = logits_shape[-1]\n  with tf.name_scope(\"padded_cross_entropy\", values=[logits, labels]):\n    if len(logits_shape) == 2:\n      # Deal with the case where we did not insert extra dimensions due to\n      # TPU issues.  No pad-to-same-length happens in this case.\n      # TODO(noam): remove this logic once TPU can handle extra dimensions.\n      labels = tf.reshape(labels, [-1])\n    else:\n      logits, labels = pad_with_zeros(logits, labels)\n    logits = tf.reshape(\n        logits,\n        shape_list(labels) + [vocab_size],\n        name=\"padded_cross_entropy_size_check\")\n    logits = tf.cast(logits, tf.float32)\n    xent = smoothing_cross_entropy(\n        logits, labels, vocab_size, confidence, gaussian=gaussian)\n    weights = weights_fn(labels)\n    if cutoff > 0.0:\n      xent = tf.nn.relu(xent - cutoff)\n    if not reduce_sum:\n      return xent * weights, weights\n    return tf.reduce_sum(xent * weights), tf.reduce_sum(weights)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the cross - entropy of a mixture of tokens.", "response": "def padded_cross_entropy_mixture(logits,\n                                 labels,\n                                 label_smoothing,\n                                 num_mixtures,\n                                 weights_fn=weights_nonzero,\n                                 reduce_sum=False,\n                                 cutoff=0.0,\n                                 gaussian=False,\n                                 return_best_logits=False):\n  \"\"\"Compute cross-entropy assuming 0s are padding.\n\n  Computes a loss numerator (the sum of losses), and loss denominator\n  (the number of non-padding tokens).\n\n  Computes cross-entropy for each mixture, and returns the corresponding values\n  for the mixture with the highest probability\n\n  Args:\n    logits: `Tensor` with shape `[batch * num_mixtures, timesteps, vocab_size]`.\n      optionally a FactoredTensor.\n    labels: an integer `Tensor` with shape `[batch, timesteps]`.\n    label_smoothing: a floating point `Scalar`.\n    num_mixtures: an integer.\n    weights_fn: A function from labels to weights.\n    reduce_sum: a Boolean, whether to sum at the end or not.\n    cutoff: a float, at which point to have no loss.\n    gaussian: If true, use a Gaussian distribution for label smoothing\n    return_best_logits: If true, return the logits of the mixture with highest\n    probabilities for an example\n\n  Returns:\n    loss_numerator: a `Scalar`.  Sum of losses.\n    loss_denominator: a `Scalar.  The number of non-padding target tokens.\n\n  Raises:\n    ValueError: in case of unsupported argument types.\n  \"\"\"\n  logit_shapes = shape_list(\n      logits)  # batch_size * num_mixtures, timesteps, 1, 1, vocab_size\n  batch_size = tf.cast(logit_shapes[0] / num_mixtures, dtype=tf.int32)\n  timesteps = logit_shapes[1]\n  vocab_size = logit_shapes[4]\n\n  new_shape_for_xent = [num_mixtures] + shape_list(labels)\n  labels = tf.tile(labels, [num_mixtures, 1, 1, 1])\n\n  xent, weights = padded_cross_entropy(logits, labels, label_smoothing,\n                                       weights_fn, reduce_sum, cutoff, gaussian)\n\n  # reshape xent and weights to have the num_mixtures as first dimension\n  xent = tf.reshape(xent, new_shape_for_xent)\n  weights = tf.reshape(weights, new_shape_for_xent[:-1])\n\n  # sum up sentence neg log probs\n  xent = tf.reduce_sum(xent, axis=2)\n\n  # if we need to compute the best logits\n  if return_best_logits:\n    best_mixture_indices = tf.cast(tf.argmin(xent, 0), dtype=tf.int32)\n    individual_element_indices = tf.range(batch_size)\n    stacked_mixture_element_indices = tf.stack((tf.squeeze(\n        best_mixture_indices, axis=[1, 2]), individual_element_indices), -1)\n    best_logits = tf.reshape(logits,\n                             [num_mixtures, -1, timesteps, 1, 1, vocab_size])\n    best_logits = tf.gather_nd(best_logits, stacked_mixture_element_indices)\n    best_logits = tf.reshape(best_logits,\n                             [batch_size, timesteps, 1, 1, vocab_size])\n\n  with tf.control_dependencies([\n      tf.assert_equal(\n          tf.shape(xent)[:3], [num_mixtures, batch_size, 1],\n          message=\"Each batch element should have a probability value for each mixture element\"\n      )\n  ]):\n    xent_min = tf.reduce_min(xent, axis=0)\n    xent_max = tf.reduce_max(xent, axis=0)\n    weights = tf.reduce_mean(weights, axis=0)\n\n  with tf.control_dependencies([\n      tf.assert_equal(\n          tf.shape(xent_min)[0], [batch_size],\n          message=\"There should be batch_size elements after selecting best mixture probabilities\"\n      )\n  ]):\n    summed_xent_min = tf.reduce_sum(xent_min)\n    summed_xent_max = tf.reduce_sum(xent_max)\n    summed_weights = tf.reduce_sum(weights)\n\n    tf.summary.scalar(\"mixture_xents_min\", summed_xent_min / summed_weights)\n    tf.summary.scalar(\"mixture_xents_max\", summed_xent_max / summed_weights)\n\n  if return_best_logits:\n    return summed_xent_min, summed_weights, best_logits\n  else:\n    return summed_xent_min, summed_weights"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dml_loss(pred, labels, weights_fn=_weights_one_third, reduce_sum=True):\n  real_labels = convert_rgb_to_symmetric_real(labels)\n  dml_loss_value = discretized_mix_logistic_loss(pred=pred, labels=real_labels)\n  weights = weights_fn(labels)\n  loss_num = weights * dml_loss_value\n  loss_den = weights_nonzero(weights)\n  if reduce_sum:\n    loss_num = tf.reduce_sum(loss_num)\n    loss_den = tf.reduce_sum(loss_den)\n  return loss_num, loss_den", "response": "Discretized mixture of logistics loss."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef split_to_discretized_mix_logistic_params(inputs):\n  batch, height, width, output_dim = shape_list(inputs)  # pylint: disable=unbalanced-tuple-unpacking\n  num_mixtures = output_dim // 10\n  logits, locs, log_scales, coeffs = tf.split(\n      inputs,\n      num_or_size_splits=[\n          num_mixtures, num_mixtures * 3, num_mixtures * 3, num_mixtures * 3\n      ],\n      axis=-1)\n  split_shape = [batch, height, width, num_mixtures, 3]\n  locs = tf.reshape(locs, split_shape)\n  log_scales = tf.reshape(log_scales, split_shape)\n  log_scales = tf.maximum(log_scales, -7.)\n  coeffs = tf.reshape(coeffs, split_shape)\n  coeffs = tf.tanh(coeffs)\n  return logits, locs, log_scales, coeffs", "response": "Splits input tensor into logits locations scales and coefficients of discretized mixture logistic."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef discretized_mix_logistic_loss(pred, labels):\n\n  logits, locs, log_scales, coeffs = split_to_discretized_mix_logistic_params(\n      pred)\n\n  # Tile labels to broadcast compute across the mixture dimension.\n  batch, height, width, num_mixtures = shape_list(logits)  # pylint: disable=unbalanced-tuple-unpacking\n  labels = tf.tile(\n      tf.reshape(labels, [batch, height, width, 1, 3]),\n      [1, 1, 1, num_mixtures, 1])\n\n  # p(x) = sigmoid((x - means_i + 1/255.)/scale_i) -\n  #        sigmoid((x - means_i - 1/255.)/scale_i)\n  # for each channel i. The means are linearly parameterized.\n  means_0 = locs[..., 0]\n  means_1 = locs[..., 1] + coeffs[..., 0] * labels[..., 0]\n  means_2 = (\n      locs[..., 2] + coeffs[..., 1] * labels[..., 0] +\n      coeffs[..., 2] * labels[..., 1])\n  means = tf.stack([means_0, means_1, means_2], axis=-1)\n  centered_labels = labels - means\n  inv_stdv = tf.exp(-log_scales)\n  plus_in = inv_stdv * (centered_labels + 1. / 255.)\n  min_in = inv_stdv * (centered_labels - 1. / 255.)\n  cdf_plus = tf.nn.sigmoid(plus_in)\n  cdf_min = tf.nn.sigmoid(min_in)\n\n  # Compute log probability for edge case of 0 (before scaling), 255 (before\n  # scaling), and all other cases respectively.\n  log_prob_0 = plus_in - tf.nn.softplus(plus_in)\n  log_prob_255 = -tf.nn.softplus(min_in)\n  prob_event = tf.maximum(cdf_plus - cdf_min, 1e-12)\n  log_prob_event = tf.log(prob_event)\n\n  # Robustly select log-prob based on numerical edge-cases: (a) [-1, -1+eps);\n  # (b) (1-eps, 1]; (c) NaNs during `tf.gradients` of `tf.select`, which may\n  # cause `tf.log(0.)`; (d) p(x) < 1e-5.\n  mid_in = inv_stdv * centered_labels\n  log_prob_event_approx = (\n      mid_in - log_scales - 2. * tf.nn.softplus(mid_in) - np.log(127.5))\n  log_probs = tf.where(\n      labels < -0.999, log_prob_0,\n      tf.where(\n          labels > 0.999, log_prob_255,\n          tf.where(prob_event > 1e-5, log_prob_event, log_prob_event_approx)))\n\n  # Sum over channels and compute log-probability of each mixture.\n  log_probs = tf.reduce_sum(log_probs, -1) + tf.nn.log_softmax(logits, axis=-1)\n  output = -tf.reduce_logsumexp(log_probs, axis=-1)\n  return output", "response": "This function computes the negative log probability for the discretized mixture of logistics."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sample_from_discretized_mix_logistic(pred, seed=None):\n\n  logits, locs, log_scales, coeffs = split_to_discretized_mix_logistic_params(\n      pred)\n\n  # Sample mixture indicator given logits using the gumbel max trick.\n  num_mixtures = shape_list(logits)[-1]\n  gumbel_noise = -tf.log(-tf.log(\n      tf.random_uniform(\n          tf.shape(logits), minval=1e-5, maxval=1. - 1e-5, seed=seed)))\n  sel = tf.one_hot(\n      tf.argmax(logits + gumbel_noise, -1),\n      depth=num_mixtures,\n      dtype=tf.float32)\n\n  # Select mixture component's parameters.\n  sel = tf.expand_dims(sel, -1)\n  locs = tf.reduce_sum(locs * sel, 3)\n  log_scales = tf.reduce_sum(log_scales * sel, 3)\n  coeffs = tf.reduce_sum(coeffs * sel, 3)\n\n  # Sample from 3-D logistic & clip to interval. Note we don't round to the\n  # nearest 8-bit value when sampling.\n  uniform_noise = tf.random_uniform(\n      tf.shape(locs), minval=1e-5, maxval=1. - 1e-5, seed=seed)\n  logistic_noise = tf.log(uniform_noise) - tf.log1p(-uniform_noise)\n  x = locs + tf.exp(log_scales) * logistic_noise\n  x0 = x[..., 0]\n  x1 = x[..., 1] + coeffs[..., 0] * x0\n  x2 = x[..., 2] + coeffs[..., 1] * x0 + coeffs[..., 2] * x1\n  x = tf.stack([x0, x1, x2], axis=-1)\n  x = tf.clip_by_value(x, -1., 1.)\n  return x", "response": "Sampling from a discretized mixture of logistics."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef smoothing_cross_entropy(logits,\n                            labels,\n                            vocab_size,\n                            confidence,\n                            gaussian=False):\n  \"\"\"Cross entropy with label smoothing to limit over-confidence.\n\n  Args:\n    logits: Tensor of shape [batch_size, ?, ?, ?, vocab_size].\n    labels: Tensor of shape [batch_size, ?, ?, ?].\n    vocab_size: Tensor representing the size of the vocabulary.\n    confidence: Used to determine on and off values for label smoothing.\n      If `gaussian` is true, `confidence` is the variance to the Gaussian\n      distribution.\n    gaussian: Uses a Gaussian distribution for label smoothing\n\n  Returns:\n    Tensor of shape [batch_size, ?, ?, ?].\n  \"\"\"\n  with tf.name_scope(\"smoothing_cross_entropy\", values=[logits, labels]):\n    # Low confidence is given to all non-true labels, uniformly.\n    low_confidence = (1.0 - confidence) / to_float(vocab_size - 1)\n    # Normalizing constant is the best cross-entropy value with soft targets.\n    # We subtract it just for readability, makes no difference on learning.\n    normalizing = -(\n        confidence * tf.log(confidence) + to_float(vocab_size - 1) *\n        low_confidence * tf.log(low_confidence + 1e-20))\n\n    if gaussian and confidence > 0.0:\n      labels = tf.cast(labels, tf.float32)\n\n      normal_dist = tfp.distributions.Normal(loc=labels, scale=confidence)\n      # Locations to evaluate the probability distributions.\n      soft_targets = normal_dist.prob(\n          tf.cast(tf.range(vocab_size), tf.float32)[:, None, None, None, None])\n      # Reordering soft_targets from [vocab_size, batch_size, ?, ?, ?] to match\n      # logits: [batch_size, ?, ?, ?, vocab_size]\n      soft_targets = tf.transpose(soft_targets, perm=[1, 2, 3, 4, 0])\n    else:\n      soft_targets = tf.one_hot(\n          tf.cast(labels, tf.int32),\n          depth=vocab_size,\n          on_value=confidence,\n          off_value=low_confidence)\n    xentropy = tf.nn.softmax_cross_entropy_with_logits_v2(\n        logits=logits, labels=soft_targets)\n    return xentropy - normalizing", "response": "Cross entropy with label smoothing."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef global_pool_1d(inputs, pooling_type=\"MAX\", mask=None):\n  with tf.name_scope(\"global_pool\", values=[inputs]):\n    if mask is not None:\n      mask = tf.expand_dims(mask, axis=2)\n      inputs = tf.multiply(inputs, mask)\n\n    if pooling_type == \"MAX\":\n      # A tf.pool can be used here, but reduce is cleaner\n      output = tf.reduce_max(inputs, axis=1)\n    elif pooling_type == \"AVR\":\n      if mask is not None:\n        # Some elems are dummy elems so we can't just reduce the average.\n        output = tf.reduce_sum(inputs, axis=1)\n        num_elems = tf.reduce_sum(mask, axis=1, keepdims=True)\n        output = tf.div(output, tf.maximum(num_elems, 1))\n      else:\n        output = tf.reduce_mean(inputs, axis=1)\n\n  return output", "response": "This function is used to reduce the number of elements across the last dimension."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef running_global_pool_1d(inputs, pooling_type=\"MAX\"):\n  del pooling_type\n  with tf.name_scope(\"running_global_pool\", values=[inputs]):\n    scan_fct = tf.maximum\n    # Permute inputs so seq_length is first.\n    elems = tf.transpose(inputs, [1, 0, 2])\n    # Perform scan.\n    cumulatives = tf.scan(scan_fct, elems, swap_memory=True)\n    # Permute output to get back to original order.\n    output = tf.transpose(cumulatives, [1, 0, 2])\n  return output", "response": "Same global pool but only for the elements up to the current element."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef gated_linear_unit_layer(x, name=None):\n  with tf.variable_scope(name, default_name=\"glu_layer\", values=[x]):\n    depth = shape_list(x)[-1]\n    x = layers().Dense(depth * 2, activation=None)(x)\n    x, gating_x = tf.split(x, 2, axis=-1)\n    return x * tf.nn.sigmoid(gating_x)", "response": "Gated linear unit layer."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sru(x,\n        num_layers=2,\n        activation=None,\n        initial_state=None,\n        name=None,\n        reuse=None):\n  \"\"\"SRU cell as in https://arxiv.org/abs/1709.02755.\n\n  As defined in the paper:\n  (1) x'_t = W x_t\n  (2) f_t = sigmoid(Wf x_t + bf)\n  (3) r_t = sigmoid(Wr x_t + br)\n  (4) c_t = f_t * c_{t-1} + (1 - f_t) * x'_t\n  (5) h_t = r_t * activation(c_t) + (1 - r_t) * x_t\n\n  This version uses functional ops to be faster on GPUs with TF-1.9+.\n\n  Args:\n    x: A tensor of shape [batch, ..., channels] ; ... is treated as time.\n    num_layers: How many SRU layers; default is 2 as results for 1 disappoint.\n    activation: Optional activation function, try tf.nn.tanh or tf.nn.relu.\n    initial_state: Optional initial c-state, set to zeros if None.\n    name: Optional name, \"sru\" by default.\n    reuse: Optional reuse.\n\n  Returns:\n    A tensor of the same shape as x.\n\n  Raises:\n    ValueError: if num_layers is not positive.\n  \"\"\"\n  if num_layers < 1:\n    raise ValueError(\"Number of layers must be positive: %d\" % num_layers)\n  if is_xla_compiled():  # On TPU the XLA does a good job with while.\n    return sru_with_scan(x, num_layers, activation, initial_state, name, reuse)\n  try:\n    from tensorflow.contrib.recurrent.python.ops import functional_rnn  # pylint: disable=g-import-not-at-top\n  except ImportError:\n    tf.logging.info(\"functional_rnn not found, using sru_with_scan instead\")\n    return sru_with_scan(x, num_layers, activation, initial_state, name, reuse)\n\n  with tf.variable_scope(name, default_name=\"sru\", values=[x], reuse=reuse):\n    # We assume x is [batch, ..., channels] and treat all ... as time.\n    x_shape = shape_list(x)\n    x = tf.reshape(x, [x_shape[0], -1, x_shape[-1]])\n    initial_state = initial_state or tf.zeros([x_shape[0], x_shape[-1]])\n    cell = CumsumprodCell(initial_state)\n    # Calculate SRU on each layer.\n    for i in range(num_layers):\n      # The parallel part of the SRU.\n      x_orig = x\n      x, f, r = tf.split(\n          layers().Dense(3 * x_shape[-1], name=\"kernel_%d\" % i)(x), 3, axis=-1)\n      f, r = tf.sigmoid(f), tf.sigmoid(r)\n      x_times_one_minus_f = x * (1.0 - f)  # Compute in parallel for speed.\n      # Calculate states.\n      concat = tf.concat([x_times_one_minus_f, f], axis=-1)\n      c_states, _ = functional_rnn.functional_rnn(\n          cell, concat, time_major=False)\n      # Final output.\n      if activation is not None:\n        c_states = activation(c_states)\n      h = c_states * r + (1.0 - r) * x_orig\n      x = h  # Next layer.\n    return tf.reshape(x, x_shape)", "response": "SRU cell as in the paper."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef linear_set_layer(layer_size,\n                     inputs,\n                     context=None,\n                     activation_fn=tf.nn.relu,\n                     dropout=0.0,\n                     name=None):\n  \"\"\"Basic layer type for doing funky things with sets.\n\n  Applies a linear transformation to each element in the input set.\n  If a context is supplied, it is concatenated with the inputs.\n    e.g. One can use global_pool_1d to get a representation of the set which\n    can then be used as the context for the next layer.\n\n  TODO: Add bias add (or control the biases used).\n\n  Args:\n    layer_size: Dimension to transform the input vectors to.\n    inputs: A tensor of shape [batch_size, sequence_length, input_dims]\n      containing the sequences of input vectors.\n    context: A tensor of shape [batch_size, context_dims] containing a global\n      statistic about the set.\n    activation_fn: The activation function to use.\n    dropout: Dropout probability.\n    name: name.\n\n  Returns:\n    Tensor of shape [batch_size, sequence_length, output_dims] containing the\n    sequences of transformed vectors.\n  \"\"\"\n  with tf.variable_scope(\n      name, default_name=\"linear_set_layer\", values=[inputs]):\n    # Apply 1D convolution to apply linear filter to each element\n    # along the 2nd dimension.\n    outputs = conv1d(inputs, layer_size, 1, activation=None, name=\"set_conv\")\n\n    # Apply the context if it exists.\n    if context is not None:\n      # Unfortunately tf doesn't support broadcasting via concat, but we can\n      # simply add the transformed context to get the same effect.\n      if len(context.get_shape().as_list()) == 2:\n        context = tf.expand_dims(context, axis=1)\n      cont_tfm = conv1d(\n          context, layer_size, 1, activation=None, name=\"cont_conv\")\n      outputs += cont_tfm\n\n    if activation_fn is not None:\n      outputs = activation_fn(outputs)\n\n    if dropout != 0.0:\n      outputs = tf.nn.dropout(outputs, 1.0 - dropout)\n\n    return outputs", "response": "Basic layer type for doing funky things with sets."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ravanbakhsh_set_layer(layer_size,\n                          inputs,\n                          mask=None,\n                          sequential=False,\n                          activation_fn=tf.nn.tanh,\n                          dropout=0.0,\n                          name=None):\n  \"\"\"Layer from Deep Sets paper: https://arxiv.org/abs/1611.04500 .\n\n  More parameter-efficient version of a linear-set-layer with context.\n\n  Args:\n    layer_size: Dimension to transform the input vectors to.\n    inputs: A tensor of shape [batch_size, sequence_length, vector]\n      containing the sequences of input vectors.\n    mask: A tensor of shape [batch_size, sequence_length] containing a\n      mask for the inputs with 1's for existing elements, and 0's elsewhere.\n    sequential: If true, will use a running global pool so each element will\n      only depend on those before it. Set true if this layer is being used in\n      an output sequence.\n    activation_fn: The activation function to use.\n    dropout: dropout.\n    name: name.\n\n  Returns:\n    Tensor of shape [batch_size, sequence_length, vector] containing the\n    sequences of transformed vectors.\n  \"\"\"\n  del dropout\n  with tf.variable_scope(name, \"ravanbakhsh_set_layer\", [inputs]):\n    if sequential:\n      return linear_set_layer(\n          layer_size,\n          inputs - running_global_pool_1d(inputs),\n          activation_fn=activation_fn,\n          name=name)\n    return linear_set_layer(\n        layer_size,\n        inputs - tf.expand_dims(global_pool_1d(inputs, mask=mask), axis=1),\n        activation_fn=activation_fn,\n        name=name)", "response": "A linear - set layer from Deep Sets paper."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstating container for fn_device_dependency.", "response": "def fn_device_dependency_dict():\n  \"\"\"State container for fn_device_dependency.\"\"\"\n  default_graph = tf.get_default_graph()\n  if not hasattr(default_graph, \"dependency_dict\"):\n    default_graph.dependency_dict = collections.defaultdict(list)\n  return default_graph.dependency_dict"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding control deps for name and device.", "response": "def fn_device_dependency(name, device=\"\"):\n  \"\"\"Add control deps for name and device.\"\"\"\n  key = name + \"_\" + device\n  outs = []\n\n  def body():\n    with tf.control_dependencies(fn_device_dependency_dict()[key]):\n      yield outs\n      assert outs\n\n      deps = outs\n      if isinstance(outs[0], (list, tuple)):\n        assert len(outs) == 1\n        deps = outs[0]\n      fn_device_dependency_dict()[key] = deps\n\n  if device:\n    with tf.device(device):\n      return body()\n  else:\n    return body()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind the underlying variable ref.", "response": "def underlying_variable_ref(t):\n  \"\"\"Find the underlying variable ref.\n\n  Traverses through Identity, ReadVariableOp, and Enter ops.\n  Stops when op type has Variable or VarHandle in name.\n\n  Args:\n    t: a Tensor\n\n  Returns:\n    a Tensor that is a variable ref, or None on error.\n  \"\"\"\n  while t.op.type in [\"Identity\", \"ReadVariableOp\", \"Enter\"]:\n    t = t.op.inputs[0]\n\n  op_type = t.op.type\n  if \"Variable\" in op_type or \"VarHandle\" in op_type:\n    return t\n  else:\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef underlying_variable(t):\n  t = underlying_variable_ref(t)\n  assert t is not None\n  # make sure that the graph has a variable index and that it is up-to-date\n  if not hasattr(tf.get_default_graph(), \"var_index\"):\n    tf.get_default_graph().var_index = {}\n  var_index = tf.get_default_graph().var_index\n  for v in tf.global_variables()[len(var_index):]:\n    var_index[v.name] = v\n  return var_index[t.name]", "response": "Find the underlying tf. Variable object. naccesse"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef approximate_split(x, num_splits, axis=0):\n  size = shape_list(x)[axis]\n  size_splits = [tf.div(size + i, num_splits) for i in range(num_splits)]\n  return tf.split(x, size_splits, axis=axis)", "response": "Split approximately equally into num_splits parts."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef smoothing_cross_entropy_factored(a, b, labels, confidence):\n  num_splits = 16\n  vocab_size = shape_list(b)[0]\n  labels = approximate_split(labels, num_splits)\n  a = approximate_split(a, num_splits)\n  parts = []\n  for part in range(num_splits):\n    with tf.control_dependencies(parts[-1:]):\n      logits = tf.matmul(a[part], b, transpose_b=True)\n      parts.append(\n          smoothing_cross_entropy(logits, labels[part], vocab_size, confidence))\n  return tf.concat(parts, 0)", "response": "Memory - efficient computation of smoothing cross - entropy."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fn_with_custom_grad(grad_fn, use_global_vars=False):\n\n  def dec(fn):\n\n    @functools.wraps(fn)\n    def wrapped(*args):\n      return _fn_with_custom_grad(\n          fn, args, grad_fn, use_global_vars=use_global_vars)\n\n    return wrapped\n\n  return dec", "response": "Decorator to create a subgraph with a custom gradient function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _fn_with_custom_grad(fn, inputs, grad_fn, use_global_vars=False):\n  vs = tf.get_variable_scope()\n  get_vars_fn = (\n      vs.global_variables if use_global_vars else vs.trainable_variables)\n  len_before_vars = len(get_vars_fn())\n  inputs = list(inputs)\n  outputs = fn(*inputs)\n  train_vars = get_vars_fn()[len_before_vars:]\n\n  if grad_fn is None:\n    return outputs\n\n  if not isinstance(outputs, (tuple, list)):\n    outputs = [outputs]\n  outputs = list(outputs)\n\n  defun_inputs = [inputs, train_vars, outputs]\n\n  def custom_grad_fn(op, *dys):\n    \"\"\"Custom grad fn applying grad_fn for identity Defun.\"\"\"\n    fn_inputs, fn_vars, fn_outputs = tf.contrib.framework.nest.pack_sequence_as(\n        defun_inputs, list(op.inputs))\n    dys = list(dys)\n    assert len(fn_outputs) == len(outputs)\n    assert len(fn_outputs) == len(dys)\n\n    grad_inputs, grad_vars = grad_fn(fn_inputs, fn_vars, fn_outputs, dys)\n    grad_outputs = [None] * len(fn_outputs)\n    return tuple(grad_inputs + grad_vars + grad_outputs)\n\n  # The Defun takes as input the original inputs, the trainable variables\n  # created in fn, and the outputs. In the forward it passes through the\n  # outputs. In the backwards, it produces gradients for the original inputs\n  # and the trainable variables.\n  in_types = [t.dtype for t in inputs]\n  out_types = [t.dtype for t in outputs]\n  var_types = [t.dtype for t in train_vars]\n\n  @function.Defun(\n      *(in_types + var_types + out_types),\n      func_name=\"identity_custom_grad%d\" % ops.uid(),\n      python_grad_func=custom_grad_fn,\n      shape_func=lambda _: [t.get_shape() for t in outputs])\n  def identity(*args):\n    _, _, outs = tf.contrib.framework.nest.pack_sequence_as(defun_inputs, args)\n    return tuple([tf.identity(t) for t in outs])\n\n  flat_inputs = tf.contrib.framework.nest.flatten(defun_inputs)\n  id_out = identity(*flat_inputs)\n  return id_out", "response": "Create a subgraph with a custom gradient."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef shape_list(x):\n  x = tf.convert_to_tensor(x)\n\n  # If unknown rank, return dynamic shape\n  if x.get_shape().dims is None:\n    return tf.shape(x)\n\n  static = x.get_shape().as_list()\n  shape = tf.shape(x)\n\n  ret = []\n  for i, dim in enumerate(static):\n    if dim is None:\n      dim = shape[i]\n    ret.append(dim)\n  return ret", "response": "Return list of dims statically where possible."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sample_with_temperature(logits, temperature, sampling_keep_top_k=-1):\n  if temperature == 0.0:\n    # TF argmax doesn't handle >5 dimensions, so we reshape here.\n    logits_shape = shape_list(logits)\n    argmax = tf.argmax(tf.reshape(logits, [-1, logits_shape[-1]]), axis=1)\n    return tf.reshape(argmax, logits_shape[:-1])\n  else:\n    assert temperature > 0.0\n\n    if sampling_keep_top_k != -1:\n      if sampling_keep_top_k <= 0:\n        raise ValueError(\"sampling_keep_top_k must either be -1 or positive.\")\n\n      vocab_size = shape_list(logits)[1]\n\n      k_largest = tf.contrib.nn.nth_element(\n          logits, n=sampling_keep_top_k, reverse=True)\n      k_largest = tf.tile(tf.reshape(k_largest, [-1, 1]), [1, vocab_size])\n\n      # Force every position that is not in the top k to have probability near\n      # 0 by setting the logit to be very negative.\n      logits = tf.where(tf.less_equal(logits, k_largest),\n                        tf.ones_like(logits)*-1e6, logits)\n\n    reshaped_logits = (\n        tf.reshape(logits, [-1, shape_list(logits)[-1]]) / temperature)\n    choices = tf.multinomial(reshaped_logits, 1)\n    choices = tf.reshape(choices,\n                         shape_list(logits)[:logits.get_shape().ndims - 1])\n    return choices", "response": "Either argmax or random sampling."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reshape_like_all_dims(a, b):\n  ret = tf.reshape(a, tf.shape(b))\n  if not tf.executing_eagerly():\n    ret.set_shape(b.get_shape())\n  return ret", "response": "Reshapes a to match the shape of b."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dense(x, units, **kwargs):\n  layer_collection = kwargs.pop(\"layer_collection\", None)\n  activations = layers().Dense(units, **kwargs)(x)\n  if layer_collection:\n    # We need to find the layer parameters using scope name for the layer, so\n    # check that the layer is named. Otherwise parameters for different layers\n    # may get mixed up.\n    layer_name = tf.get_variable_scope().name\n    if (not layer_name) or (\"name\" not in kwargs):\n      raise ValueError(\n          \"Variable scope and layer name cannot be empty. Actual: \"\n          \"variable_scope={}, layer name={}\".format(\n              layer_name, kwargs.get(\"name\", None)))\n\n    layer_name += \"/\" + kwargs[\"name\"]\n    layer_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n                                     scope=layer_name)\n    assert layer_params\n    if len(layer_params) == 1:\n      layer_params = layer_params[0]\n\n    tf.logging.info(\n        \"Registering dense layer to collection for tensor: {}\".format(\n            layer_params))\n\n    x_shape = x.shape.as_list()\n    if len(x_shape) == 3:\n      # Handle [batch, time, depth] inputs by folding batch and time into\n      # one dimension: reshaping inputs to [batchxtime, depth].\n      x_2d = tf.reshape(x, [-1, x_shape[2]])\n      activations_shape = activations.shape.as_list()\n      activations_2d = tf.reshape(activations, [-1, activations_shape[2]])\n      layer_collection.register_fully_connected_multi(\n          layer_params, x_2d, activations_2d, num_uses=x_shape[1])\n      activations = tf.reshape(activations_2d, activations_shape)\n    else:\n      layer_collection.register_fully_connected(layer_params, x, activations)\n  return activations", "response": "Identical to layers. dense."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef batch_dense(inputs,\n                units,\n                activation=None,\n                kernel_initializer=None,\n                reuse=None,\n                name=None):\n  \"\"\"Multiply a batch of input matrices by a batch of parameter matrices.\n\n  Each input matrix is multiplied by the corresponding parameter matrix.\n\n  This is useful in a mixture-of-experts where the batch represents different\n  experts with different inputs.\n\n  Args:\n    inputs: a Tensor with shape [batch, length, input_units]\n    units: an integer\n    activation: an optional activation function to apply to the output\n    kernel_initializer: an optional initializer\n    reuse: whether to reuse the varaible scope\n    name: an optional string\n\n  Returns:\n    a Tensor with shape [batch, length, units]\n\n  Raises:\n    ValueError: if the \"batch\" or \"input_units\" dimensions of inputs are not\n      statically known.\n  \"\"\"\n  inputs_shape = shape_list(inputs)\n  if len(inputs_shape) != 3:\n    raise ValueError(\"inputs must have 3 dimensions\")\n  batch = inputs_shape[0]\n  input_units = inputs_shape[2]\n  if not isinstance(batch, int) or not isinstance(input_units, int):\n    raise ValueError(\"inputs must have static dimensions 0 and 2\")\n  with tf.variable_scope(\n      name,\n      default_name=\"batch_dense\",\n      values=[inputs],\n      reuse=reuse,\n      dtype=inputs.dtype):\n    if kernel_initializer is None:\n      kernel_initializer = tf.random_normal_initializer(\n          stddev=input_units**-0.5)\n    w = tf.get_variable(\n        \"w\", [batch, input_units, units],\n        initializer=kernel_initializer,\n        dtype=inputs.dtype)\n    y = tf.matmul(inputs, w)\n    if activation is not None:\n      y = activation(y)\n    return y", "response": "Multiply a batch of input matrices by a batch of parameter matrices."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mix(x1,\n        x2,\n        steps,\n        is_training,\n        min_prob=0.0,\n        max_prob=1.0,\n        mode=\"lin\",\n        simple=False,\n        broadcast_last=False):\n  \"\"\"Mix starting with x2, mixing mixing, going towards x1.\"\"\"\n  with tf.name_scope(\"mix\"):\n    if not is_training:\n      if max_prob >= 1.0:\n        return x1\n      alpha_shape = shape_list(x1)\n      if broadcast_last:\n        alpha_shape = alpha_shape[:-1] + [1]\n      alpha = tf.random_uniform(alpha_shape)\n      alpha = to_float(tf.less(alpha, max_prob))\n      return alpha * x1 + (1.0 - alpha) * x2\n\n    def get_res():\n      \"\"\"Create the result.\n\n      Separate function to speed it up later (see below).\n\n      Returns:\n        Tensor of mixed inputs.\n      \"\"\"\n      if mode == \"lin\":\n        alpha_p = inverse_lin_decay(steps)\n      else:\n        alpha_p = inverse_exp_decay(steps)\n      alpha_p = alpha_p * (max_prob - min_prob) + min_prob\n      if simple:\n        return alpha_p * x1 + (1.0 - alpha_p) * x2\n      alpha_shape = shape_list(x1)\n      if broadcast_last:\n        alpha_shape = alpha_shape[:-1] + [1]\n      alpha = tf.random_uniform(alpha_shape)\n      alpha = to_float(tf.less(alpha, alpha_p))\n      return alpha * x1 + (1.0 - alpha) * x2\n\n    if max_prob < 1.0:\n      return get_res()\n\n    # Prevent sampling after steps is passed to speed it up.\n    if is_xla_compiled():\n      return get_res()\n    else:\n      cur_step = tf.train.get_global_step()\n      if cur_step is None:\n        return x1  # Step not available, probably eval mode, don't mix.\n      return tf.cond(tf.less(cur_step, steps), get_res, lambda: x1)", "response": "Mix starting with x1 and going towards x2."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef brelu(x):\n  x_shape = shape_list(x)\n  x1, x2 = tf.split(tf.reshape(x, x_shape[:-1] + [-1, 2]), 2, axis=-1)\n  y1 = tf.nn.relu(x1)\n  y2 = -tf.nn.relu(-x2)\n  return tf.reshape(tf.concat([y1, y2], axis=-1), x_shape)", "response": "Bipolar ReLU as in https://arxiv. org. abs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef belu(x):\n  x_shape = shape_list(x)\n  x1, x2 = tf.split(tf.reshape(x, x_shape[:-1] + [-1, 2]), 2, axis=-1)\n  y1 = tf.nn.elu(x1)\n  y2 = -tf.nn.elu(-x2)\n  return tf.reshape(tf.concat([y1, y2], axis=-1), x_shape)", "response": "Bipolar ELU as in https://arxiv. org. abs. 1709. 04054."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef nac(x, depth, name=None, reuse=None):\n  with tf.variable_scope(name, default_name=\"nac\", values=[x], reuse=reuse):\n    x_shape = shape_list(x)\n    w = tf.get_variable(\"w\", [x_shape[-1], depth])\n    m = tf.get_variable(\"m\", [x_shape[-1], depth])\n    w = tf.tanh(w) * tf.nn.sigmoid(m)\n    x_flat = tf.reshape(x, [-1, x_shape[-1]])\n    res_flat = tf.matmul(x_flat, w)\n    return tf.reshape(res_flat, x_shape[:-1] + [depth])", "response": "NAC as in https://arxiv. org / abs / 1808. 00508."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef nalu(x, depth, epsilon=1e-30, name=None, reuse=None):\n  with tf.variable_scope(name, default_name=\"nalu\", values=[x], reuse=reuse):\n    x_shape = shape_list(x)\n    x_flat = tf.reshape(x, [-1, x_shape[-1]])\n    gw = tf.get_variable(\"w\", [x_shape[-1], depth])\n    g = tf.nn.sigmoid(tf.matmul(x_flat, gw))\n    g = tf.reshape(g, x_shape[:-1] + [depth])\n    a = nac(x, depth, name=\"nac_lin\")\n    log_x = tf.log(tf.abs(x) + epsilon)\n    m = nac(log_x, depth, name=\"nac_log\")\n    return g * a + (1 - g) * tf.exp(m)", "response": "NALU as in the arXiv. org."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef top_kth_iterative(x, k):\n  # The iterative computation is as follows:\n  #\n  # cur_x = x\n  # for _ in range(k):\n  #   top_x = maximum of elements of cur_x on the last axis\n  #   cur_x = cur_x where cur_x < top_x and 0 everywhere else (top elements)\n  #\n  # We encode this computation in a TF graph using tf.foldl, so the inner\n  # part of the above loop is called \"next_x\" and tf.foldl does the loop.\n  def next_x(cur_x, _):\n    top_x = tf.reduce_max(cur_x, axis=-1, keep_dims=True)\n    return cur_x * to_float(cur_x < top_x)\n  # We only do k-1 steps of the loop and compute the final max separately.\n  fin_x = tf.foldl(next_x, tf.range(k - 1), initializer=tf.stop_gradient(x),\n                   parallel_iterations=2, back_prop=False)\n  return tf.stop_gradient(tf.reduce_max(fin_x, axis=-1, keep_dims=True))", "response": "Compute the k - th top element of x on the last axis iteratively."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding max and argmax over the last dimension. TPU Works well on TPU Works well on TPU Works well on TPU", "response": "def top_1_tpu(inputs):\n  \"\"\"find max and argmax over the last dimension.\n\n  Works well on TPU\n\n  Args:\n    inputs: A tensor with shape [..., depth]\n\n  Returns:\n    values: a Tensor with shape [...]\n    indices: a Tensor with shape [...]\n  \"\"\"\n  inputs_max = tf.reduce_max(inputs, axis=-1, keepdims=True)\n  mask = tf.to_int32(tf.equal(inputs_max, inputs))\n  index = tf.range(tf.shape(inputs)[-1]) * mask\n  return tf.squeeze(inputs_max, -1), tf.reduce_max(index, axis=-1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef index_last_dim_with_indices(x, indices):\n  assert len(x.shape) == len(indices.shape) + 1\n\n  x_shape = shape_list(x)\n  vocab_size = x_shape[-1]\n\n  flat_x = tf.reshape(x, [list_product(x_shape[:-1]), vocab_size])\n  flat_indices = tf.reshape(indices, [list_product(x_shape[:-1])])\n\n  idx = tf.stack(\n      [\n          tf.range(tf.to_int64(shape_list(flat_indices)[0])),\n          tf.to_int64(flat_indices)\n      ],\n      axis=1)\n  flat_x_idx = tf.gather_nd(flat_x, idx)\n\n  x_idx = tf.reshape(flat_x_idx, x_shape[:-1])\n\n  return x_idx", "response": "Use indices to index into the last axis of x."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if the current context should generate summaries.", "response": "def should_generate_summaries():\n  \"\"\"Is this an appropriate context to generate summaries.\n\n  Returns:\n    a boolean\n  \"\"\"\n  name_scope = tf.contrib.framework.get_name_scope()\n  if name_scope and \"while/\" in name_scope:\n    # Summaries don't work well within tf.while_loop()\n    return False\n  if tf.get_variable_scope().reuse:\n    # Avoid generating separate summaries for different data shards\n    return False\n  return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reshape_like(a, b):\n  ret = tf.reshape(a, tf.concat([tf.shape(b)[:-1], tf.shape(a)[-1:]], 0))\n  if not tf.executing_eagerly():\n    ret.set_shape(b.get_shape().as_list()[:-1] + a.get_shape().as_list()[-1:])\n  return ret", "response": "Reshapes a to match the shape of b in all but the last dimension."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef summarize_video(video, prefix, max_outputs=1):\n  video_shape = shape_list(video)\n  if len(video_shape) != 5:\n    raise ValueError(\"Assuming videos given as tensors in the format \"\n                     \"[batch, time, height, width, channels] but got one \"\n                     \"of shape: %s\" % str(video_shape))\n  if tf.executing_eagerly():\n    return\n  if video.get_shape().as_list()[1] is None:\n    tf.summary.image(\n        \"%s_last_frame\" % prefix,\n        tf.cast(video[:, -1, :, :, :], tf.uint8),\n        max_outputs=max_outputs)\n  else:\n    for k in range(video_shape[1]):\n      tf.summary.image(\n          \"%s_frame_%d\" % (prefix, k),\n          tf.cast(video[:, k, :, :, :], tf.uint8),\n          max_outputs=max_outputs)", "response": "Summarize the video using image summaries starting with prefix."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cast_like(x, y):\n  x = tf.convert_to_tensor(x)\n  y = tf.convert_to_tensor(y)\n\n  if x.dtype.base_dtype == y.dtype.base_dtype:\n    return x\n\n  cast_x = tf.cast(x, y.dtype)\n  if cast_x.device != x.device:\n    x_name = \"(eager Tensor)\"\n    try:\n      x_name = x.name\n    except AttributeError:\n      pass\n    tf.logging.warning(\"Cast for %s may induce copy from '%s' to '%s'\", x_name,\n                       x.device, cast_x.device)\n  return cast_x", "response": "Cast x to y s dtype if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_even_size(x):\n  x_shape = x.get_shape().as_list()\n  assert len(x_shape) > 2, \"Only 3+-dimensional tensors supported.\"\n  shape = [dim if dim is not None else -1 for dim in x_shape]\n  new_shape = x_shape  # To make sure constant shapes remain constant.\n  if x_shape[1] is not None:\n    new_shape[1] = 2 * int(math.ceil(x_shape[1] * 0.5))\n  if x_shape[2] is not None:\n    new_shape[2] = 2 * int(math.ceil(x_shape[2] * 0.5))\n  if shape[1] % 2 == 0 and shape[2] % 2 == 0:\n    return x\n  if shape[1] % 2 == 0:\n    x, _ = pad_to_same_length(x, x, final_length_divisible_by=2, axis=2)\n    x.set_shape(new_shape)\n    return x\n  if shape[2] % 2 == 0:\n    x, _ = pad_to_same_length(x, x, final_length_divisible_by=2, axis=1)\n    x.set_shape(new_shape)\n    return x\n  x, _ = pad_to_same_length(x, x, final_length_divisible_by=2, axis=1)\n  x, _ = pad_to_same_length(x, x, final_length_divisible_by=2, axis=2)\n  x.set_shape(new_shape)\n  return x", "response": "Pad x to be even - sized on axis 1 and 2 but only if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sliced_gan_loss(input1,\n                    input2,\n                    discriminator,\n                    num_vecs,\n                    do_random_vecs=True,\n                    do_tanh=True,\n                    return_logits=False):\n  \"\"\"Loss inspired by the sliced WGAN paper: https://arxiv.org/abs/1804.01947.\n\n  Puts input1 and input2 through the provided discriminator to get logits.\n  Then, computes num_vecs random projections of the logits, sorts them on\n  the batch dimension and returns the L2 loss between the sorted vectors.\n  See the above-mentioned paper for the reasoning behind it.\n\n  Args:\n    input1: first discriminator inputs.\n    input2: second discriminator inputs.\n    discriminator: inputs -> logits function.\n    num_vecs: how many random vectors to use for projections.\n    do_random_vecs: whether to use random vectors or just tanh of the logits.\n    do_tanh: if true (default) we'll also just use tanh of the logits.\n    return_logits: Whether or not to return the logits.\n\n  Returns:\n    The generator loss, i.e., the sliced approximation of the distance between\n    the projected distributions (warning: discriminator should maximize it).\n  \"\"\"\n  with tf.variable_scope(\"sliced_gan\"):\n    with tf.variable_scope(\"discriminator\"):\n      logits1 = discriminator(input1)\n    with tf.variable_scope(\"discriminator\", reuse=True):\n      logits2 = discriminator(input2)\n\n    if do_random_vecs:\n      random_vecs = tf.nn.l2_normalize(\n          tf.random_uniform([shape_list(logits1)[-1], num_vecs]), axis=0)\n\n    def get_sorted_projections(x):\n      \"\"\"Make projections of x and sort them on the batch dimension.\"\"\"\n      x = tf.reshape(x, [-1, shape_list(x)[-1]])\n      batch_size = shape_list(x)[0]\n      if do_random_vecs and do_tanh:\n        n = tf.nn.l2_normalize(x, axis=1)\n        proj = tf.concat([tf.matmul(n, random_vecs), tf.tanh(n)], axis=1)\n      elif do_random_vecs:\n        n = tf.nn.l2_normalize(x, axis=1)\n        proj = tf.matmul(n, random_vecs)\n      else:\n        proj = tf.tanh(x)\n      proj = tf.transpose(proj, [1, 0])  # [num_vecs, batch] after this.\n\n      if is_xla_compiled():\n        proj_dtype = proj.dtype\n        proj = tf.cast(proj, tf.bfloat16)\n\n        # Currently TPU only supports 1-D top_k calls.\n        map_fn = lambda x: tf.nn.top_k(x, k=batch_size, sorted=True)[0]\n        values = tf.map_fn(map_fn, proj)\n\n        values = tf.cast(values, proj_dtype)\n      else:\n        values, _ = tf.nn.top_k(proj, k=batch_size, sorted=True)\n\n      return values\n\n    proj1 = get_sorted_projections(logits1)\n    proj2 = get_sorted_projections(logits2)\n    dist = tf.reduce_mean(tf.squared_difference(proj1, proj2))\n    if return_logits:\n      return dist, logits1, logits2\n    return dist", "response": "Returns the L2 loss inspired by the sliced WGAN paper."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deep_discriminator(x,\n                       batch_norm,\n                       is_training,\n                       filters=64,\n                       filter_size=4,\n                       stride=2,\n                       output_size=1024):\n  \"\"\"Discriminator architecture based on InfoGAN.\"\"\"\n  with tf.variable_scope(\n      \"discriminator\", initializer=tf.random_normal_initializer(stddev=0.02)):\n    batch_size, height, width = shape_list(x)[:3]  # pylint: disable=unbalanced-tuple-unpacking\n    net = layers().Conv2D(\n        filters, filter_size, strides=stride, padding=\"SAME\", name=\"conv1\")(x)\n    net = lrelu(net)\n    net = layers().Conv2D(\n        2 * filters,\n        filter_size,\n        strides=stride,\n        padding=\"SAME\",\n        name=\"conv2\")(net)\n    # [bs, h/4, w/4, 128]\n    if batch_norm:\n      net = layers().BatchNormalization(\n          training=is_training, momentum=0.999, name=\"d_bn2\")(net)\n    net = lrelu(net)\n    size = height * width\n    x_shape = x.get_shape().as_list()\n    if x_shape[1] is None or x_shape[2] is None:\n      net = tf.reduce_mean(net, axis=[1, 2])\n    else:\n      net = tf.reshape(net, [batch_size, size * 8])\n    net = layers().Dense(output_size, name=\"d_fc3\")(net)\n    if batch_norm:\n      net = layers().BatchNormalization(\n          training=is_training, momentum=0.999, name=\"d_bn3\")(net)\n    net = lrelu(net)\n    return net", "response": "Discriminator architecture based on InfoGAN."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmeans and attention to reduce spatial dimensions.", "response": "def mean_with_attention(x, name, num_heads=4):\n  \"\"\"Mean and attention to reduce spatial dimensions.\"\"\"\n  with tf.variable_scope(name):\n    shape = shape_list(x)\n    m = tf.reduce_mean(x, [1, 2])\n    a = layers().Dense(num_heads, name=\"mean_attn\")(x)\n    s = tf.reshape(a, [shape[0], -1, num_heads])\n    s = tf.nn.softmax(s, axis=1)\n    s = tf.reshape(s, shape[:-1] + [1, num_heads])\n    am = tf.reduce_mean(tf.expand_dims(x, axis=-1) * s, [1, 2])\n    l = tf.concat([am, tf.expand_dims(m, axis=-1)], axis=-1)\n    return layers().Dense(2 * shape[-1], name=\"mean_attn_final\")(\n        tf.reshape(l, [shape[0], (num_heads+1) * shape[-1]]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef single_discriminator(x, filters=128, kernel_size=8,\n                         strides=4, pure_mean=False):\n  \"\"\"A simple single-layer convolutional discriminator.\"\"\"\n  with tf.variable_scope(\"discriminator\"):\n    net = layers().Conv2D(\n        filters, kernel_size, strides=strides, padding=\"SAME\", name=\"conv1\")(x)\n    if pure_mean:\n      net = tf.reduce_mean(net, [1, 2])\n    else:\n      net = mean_with_attention(net, \"mean_with_attention\")\n    return net", "response": "A simple convolutional discriminator."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef double_discriminator(x, filters1=128, filters2=None,\n                         kernel_size=8, strides=4, pure_mean=False):\n  \"\"\"A convolutional discriminator with 2 layers and concatenated output.\"\"\"\n  if filters2 is None:\n    filters2 = 4 * filters1\n  with tf.variable_scope(\"discriminator\"):\n    batch_size = shape_list(x)[0]\n    net = layers().Conv2D(\n        filters1, kernel_size, strides=strides, padding=\"SAME\", name=\"conv1\")(x)\n    if pure_mean:\n      net1 = tf.reduce_mean(net, [1, 2])\n    else:\n      net1 = mean_with_attention(net, \"mean_with_attention1\")\n      tf.reshape(net, [batch_size, -1])\n    net = tf.nn.relu(net)\n    net = layers().Conv2D(\n        filters2, kernel_size, strides=strides, padding=\"SAME\", name=\"conv2\")(x)\n    if pure_mean:\n      net2 = tf.reduce_mean(net, [1, 2])\n    else:\n      net2 = mean_with_attention(net, \"mean_with_attention2\")\n    return tf.concat([net1, net2], axis=-1)", "response": "A convolutional discriminator with 2 layers and concatenated output."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef upscale(inputs, f, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR):\n  height, width = shape_list(inputs)[1:3]  # pylint: disable=unbalanced-tuple-unpacking\n  return tf.image.resize_images(inputs, (height * f, width * f), method)", "response": "Upscaling the image by a factor of f."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cyclegan_upsample(net, num_outputs, stride, method=\"conv2d_transpose\"):\n\n  with tf.variable_scope(\"upconv\"):\n    net_shape = tf.shape(net)\n    height = net_shape[1]\n    width = net_shape[2]\n\n    # Reflection pad by 1 in spatial dimensions (axes 1, 2 = h, w) to make a\n    # 3x3 \"valid\" convolution produce an output with the same dimension as the\n    # input.\n    spatial_pad_1 = np.array([[0, 0], [1, 1], [1, 1], [0, 0]])\n\n    if method == \"nn_upsample_conv\":\n      net = tf.image.resize_nearest_neighbor(\n          net, [stride[0] * height, stride[1] * width])\n      net = tf.pad(net, spatial_pad_1, \"REFLECT\")\n      net = layers().Conv2D(\n          num_outputs, (3, 3), activation=tf.nn.relu)(net)\n    elif method == \"bilinear_upsample_conv\":\n      net = tf.image.resize_bilinear(net,\n                                     [stride[0] * height, stride[1] * width])\n      net = tf.pad(net, spatial_pad_1, \"REFLECT\")\n      net = layers().Conv2D(\n          num_outputs, (3, 3), activation=tf.nn.relu)(net)\n    elif method == \"conv2d_transpose\":\n      # This corrects 1 pixel offset for images with even width and height.\n      # conv2d is left aligned and conv2d_transpose is right aligned for even\n      # sized images (while doing \"SAME\" padding).\n      # Note: This doesn\"t reflect actual model in paper.\n      net = layers().Conv2DTranspose(\n          num_outputs, (3, 3), strides=stride, activation=tf.nn.relu)(net)\n      net = net[:, 1:, 1:, :]\n    else:\n      raise ValueError(\"Unknown method: [%s]\" % method)\n\n    return net", "response": "Upsamples the given inputs using the cyclegan convolution."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nweights - level magnitude pruning.", "response": "def weight_targeting(w, k):\n  \"\"\"Weight-level magnitude pruning.\"\"\"\n  k = tf.to_int32(k)\n  w_shape = shape_list(w)\n  size = tf.to_int32(tf.reduce_prod(w_shape[:-1]))\n  w = tf.reshape(w, [size, w_shape[-1]])\n\n  transpose_w = tf.transpose(w)\n  thres = tf.contrib.framework.sort(tf.abs(transpose_w), axis=1)[:, k]\n  mask = to_float(thres[None, :] >= tf.abs(w))\n\n  return tf.reshape(mask, w_shape)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef td_conv(inputs,\n            filters,\n            kernel_size,\n            targeting_count,\n            targeting_fn,\n            keep_prob,\n            is_training,\n            do_prune=True,\n            strides=(1, 1),\n            padding=\"valid\",\n            data_format=\"channels_last\",\n            dilation_rate=(1, 1),\n            activation=None,\n            use_bias=True,\n            kernel_initializer=None,\n            bias_initializer=tf.zeros_initializer(),\n            name=None,\n            reuse=None):\n  \"\"\"Apply targeted dropout to the weights of a convolution.\"\"\"\n  with tf.variable_scope(name, default_name=\"td_conv\", reuse=reuse):\n    nhwc = data_format == \"channels_last\"\n    in_dim = shape_list(inputs)[-1] if nhwc else shape_list(inputs)[1]\n\n    kernel_shape = [kernel_size, kernel_size, in_dim, filters]\n    w = tf.get_variable(\n        \"DW\", shape=kernel_shape, initializer=kernel_initializer)\n    if use_bias:\n      b = tf.get_variable(\"b\", shape=[filters], initializer=bias_initializer)\n\n    if keep_prob < 1.0:\n      w = targeted_dropout(\n          w,\n          targeting_count,\n          keep_prob,\n          targeting_fn,\n          is_training,\n          do_prune=do_prune)\n\n    if isinstance(strides, int):\n      strides = [strides, strides]\n    if isinstance(dilation_rate, int):\n      dilation_rate = [dilation_rate, dilation_rate]\n\n    if nhwc:\n      strides = [1, strides[0], strides[1], 1]\n      dilation_rate = [1, dilation_rate[0], dilation_rate[1], 1]\n    else:\n      strides = [1, 1, strides[0], strides[1]]\n      dilation_rate = [1, 1, dilation_rate[0], dilation_rate[1]]\n\n    y = tf.nn.conv2d(\n        inputs,\n        w,\n        strides,\n        padding,\n        data_format=\"NHWC\" if nhwc else \"NCHW\",\n        dilations=dilation_rate,\n        name=None)\n\n    if use_bias:\n      y += b\n\n    if activation:\n      y = activation(y)\n\n    return y", "response": "Applies targeted dropout to the weights of a convolution."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef targeted_dropout(inputs,\n                     k,\n                     keep_prob,\n                     targeting_fn,\n                     is_training,\n                     do_prune=False):\n  \"\"\"Applies targeted dropout.\n\n  Applies dropout at a rate of `1 - keep_prob` to only those elements of\n  `inputs` marked by `targeting_fn`. See below and paper for more detail:\n\n  \"Targeted Dropout for Posthoc Pruning\" Aidan N. Gomez, Ivan Zhang,\n    Kevin Swersky, Yarin Gal, and Geoffrey E. Hinton.\n\n  Args:\n    inputs: Tensor, inputs to apply targeted dropout to.\n    k: Scalar Tensor or python scalar, sets the number of elements to target in\n      `inputs`. Must be within `[0, tf.shape(x)[-1]]` and compatible with\n      second argument of `targeting_fn`.\n    keep_prob: Scalar Tensor, passed as `tf.nn.dropout`'s `keep_prob` argument.\n    targeting_fn: callable `fn(inputs, k) -> Boolean Tensor`, produces a\n      boolean mask the same shape as `inputs` where True indicates an element\n      will be dropped, and False not.\n    is_training: bool, indicates whether currently training.\n    do_prune: bool, indicates whether to prune the `k * (1 - keep_prob)`\n      elements of `inputs` expected to be dropped each forwards pass.\n\n  Returns:\n    Tensor, same shape and dtype as `inputs`.\n  \"\"\"\n  if not is_training and do_prune:\n    k = tf.round(to_float(k) * to_float(1. - keep_prob))\n\n  mask = targeting_fn(inputs, k)\n  mask = tf.cast(mask, inputs.dtype)\n\n  if is_training:\n    return inputs * (1 - mask) + tf.nn.dropout(inputs, keep_prob) * mask\n  elif do_prune:\n    return inputs * (1 - mask)\n  else:\n    return inputs", "response": "Applies targeted dropout to all elements of the alphabetical alphabetical"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef kl_divergence(mu, log_var, mu_p=0.0, log_var_p=0.0):\n\n  batch_size = shape_list(mu)[0]\n  prior_distribution = tfp.distributions.Normal(\n      mu_p, tf.exp(tf.multiply(0.5, log_var_p)))\n  posterior_distribution = tfp.distributions.Normal(\n      mu, tf.exp(tf.multiply(0.5, log_var)))\n  kld = tfp.distributions.kl_divergence(posterior_distribution,\n                                        prior_distribution)\n  return tf.reduce_sum(kld) / to_float(batch_size)", "response": "KL divergence of diagonal gaussian N mu exp ( log_var ) and N ( 0 1 )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating weights with normalization.", "response": "def _compute_weights(self):\n    \"\"\"Generate weights with normalization.\"\"\"\n    with tf.variable_scope(\"compute_weights\"):\n      self.layer.kernel = tf.nn.l2_normalize(\n          self.layer.v, axis=self.norm_axes) * self.layer.g"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_norm(self, weights):\n    with tf.variable_scope(\"init_norm\"):\n      flat = tf.reshape(weights, [-1, self.layer_depth])\n      return tf.reshape(tf.norm(flat, axis=0), (self.layer_depth,))", "response": "Set the norm of the weight vector."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _data_dep_init(self, inputs):\n\n    with tf.variable_scope(\"data_dep_init\"):\n      # Generate data dependent init values\n      activation = self.layer.activation\n      self.layer.activation = None\n      x_init = self.layer.call(inputs)\n      m_init, v_init = tf.moments(x_init, self.norm_axes)\n      scale_init = 1. / tf.sqrt(v_init + 1e-10)\n\n    # Assign data dependent init values\n    self.layer.g = self.layer.g * scale_init\n    self.layer.bias = (-m_init * scale_init)\n    self.layer.activation = activation\n    self.initialized = True", "response": "Data dependent initialization for eager execution."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds a WeightNorm layer.", "response": "def build(self, input_shape=None):\n    \"\"\"Build `Layer`.\"\"\"\n    input_shape = tf.TensorShape(input_shape).as_list()\n    self.input_spec = layers().InputSpec(shape=input_shape)\n\n    if not self.layer.built:\n      self.layer.build(input_shape)\n      self.layer.built = False\n\n      if not hasattr(self.layer, \"kernel\"):\n        raise ValueError(\"`WeightNorm` must wrap a layer that\"\n                         \" contains a `kernel` for weights\")\n\n      # The kernel's filter or unit dimension is -1\n      self.layer_depth = int(self.layer.kernel.shape[-1])\n      self.norm_axes = list(range(self.layer.kernel.shape.ndims - 1))\n\n      self.layer.v = self.layer.kernel\n      self.layer.g = self.layer.add_variable(\n          name=\"g\",\n          shape=(self.layer_depth,),\n          initializer=tf.ones_initializer,\n          dtype=self.layer.kernel.dtype,\n          trainable=True)\n\n      # with ops.control_dependencies([self.layer.g.assign(\n      #     self._init_norm(self.layer.v))]):\n      #   self._compute_weights()\n      self._compute_weights()\n\n      self.layer.built = True\n\n    super(WeightNorm, self).build()\n    self.built = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates mean rewards from given epoch.", "response": "def compute_mean_reward(rollouts, clipped):\n  \"\"\"Calculate mean rewards from given epoch.\"\"\"\n  reward_name = \"reward\" if clipped else \"unclipped_reward\"\n  rewards = []\n  for rollout in rollouts:\n    if rollout[-1].done:\n      rollout_reward = sum(getattr(frame, reward_name) for frame in rollout)\n      rewards.append(rollout_reward)\n  if rewards:\n    mean_rewards = np.mean(rewards)\n  else:\n    mean_rewards = 0\n  return mean_rewards"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef evaluate_single_config(\n    hparams, sampling_temp, max_num_noops, agent_model_dir,\n    eval_fn=_eval_fn_with_learner\n):\n  \"\"\"Evaluate the PPO agent in the real environment.\"\"\"\n  tf.logging.info(\"Evaluating metric %s\", get_metric_name(\n      sampling_temp, max_num_noops, clipped=False\n  ))\n  eval_hparams = trainer_lib.create_hparams(hparams.base_algo_params)\n  env = setup_env(\n      hparams, batch_size=hparams.eval_batch_size, max_num_noops=max_num_noops,\n      rl_env_max_episode_steps=hparams.eval_rl_env_max_episode_steps,\n      env_name=hparams.rl_env_name)\n  env.start_new_epoch(0)\n  eval_fn(env, hparams, eval_hparams, agent_model_dir, sampling_temp)\n  rollouts = env.current_epoch_rollouts()\n  env.close()\n\n  return tuple(\n      compute_mean_reward(rollouts, clipped) for clipped in (True, False)\n  )", "response": "Evaluate the PPO agent in the real environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nevaluating the agent with multiple eval configurations.", "response": "def evaluate_all_configs(\n    hparams, agent_model_dir, eval_fn=_eval_fn_with_learner\n):\n  \"\"\"Evaluate the agent with multiple eval configurations.\"\"\"\n  metrics = {}\n  # Iterate over all combinations of sampling temperatures and whether to do\n  # initial no-ops.\n  for sampling_temp in hparams.eval_sampling_temps:\n    # Iterate over a set so if eval_max_num_noops == 0 then it's 1 iteration.\n    for max_num_noops in set([hparams.eval_max_num_noops, 0]):\n      scores = evaluate_single_config(\n          hparams, sampling_temp, max_num_noops, agent_model_dir, eval_fn\n      )\n      for (score, clipped) in zip(scores, (True, False)):\n        metric_name = get_metric_name(sampling_temp, max_num_noops, clipped)\n        metrics[metric_name] = score\n\n  return metrics"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nevaluates the world model.", "response": "def evaluate_world_model(\n    real_env, hparams, world_model_dir, debug_video_path,\n    split=tf.estimator.ModeKeys.EVAL,\n):\n  \"\"\"Evaluate the world model (reward accuracy).\"\"\"\n  frame_stack_size = hparams.frame_stack_size\n  rollout_subsequences = []\n  def initial_frame_chooser(batch_size):\n    assert batch_size == len(rollout_subsequences)\n    return np.stack([\n        [frame.observation.decode() for frame in subsequence[:frame_stack_size]]    # pylint: disable=g-complex-comprehension\n        for subsequence in rollout_subsequences\n    ])\n\n  env_fn = rl.make_simulated_env_fn_from_hparams(\n      real_env, hparams, batch_size=hparams.wm_eval_batch_size,\n      initial_frame_chooser=initial_frame_chooser, model_dir=world_model_dir\n  )\n  sim_env = env_fn(in_graph=False)\n  subsequence_length = int(\n      max(hparams.wm_eval_rollout_ratios) * hparams.simulated_rollout_length\n  )\n  rollouts = real_env.current_epoch_rollouts(\n      split=split,\n      minimal_rollout_frames=(subsequence_length + frame_stack_size)\n  )\n\n  video_writer = common_video.WholeVideoWriter(\n      fps=10, output_path=debug_video_path, file_format=\"avi\"\n  )\n\n  reward_accuracies_by_length = {\n      int(ratio * hparams.simulated_rollout_length): []\n      for ratio in hparams.wm_eval_rollout_ratios\n  }\n  for _ in range(hparams.wm_eval_num_batches):\n    rollout_subsequences[:] = random_rollout_subsequences(\n        rollouts, hparams.wm_eval_batch_size,\n        subsequence_length + frame_stack_size\n    )\n\n    eval_subsequences = [\n        subsequence[(frame_stack_size - 1):]\n        for subsequence in rollout_subsequences\n    ]\n\n    # Check that the initial observation is the same in the real and simulated\n    # rollout.\n    sim_init_obs = sim_env.reset()\n    def decode_real_obs(index):\n      return np.stack([\n          subsequence[index].observation.decode()\n          for subsequence in eval_subsequences  # pylint: disable=cell-var-from-loop\n      ])\n    real_init_obs = decode_real_obs(0)\n    assert np.all(sim_init_obs == real_init_obs)\n\n    debug_frame_batches = []\n    def append_debug_frame_batch(sim_obs, real_obs, sim_cum_rews,\n                                 real_cum_rews, sim_rews, real_rews):\n      \"\"\"Add a debug frame.\"\"\"\n      rews = [[sim_cum_rews, sim_rews], [real_cum_rews, real_rews]]\n      headers = []\n      for j in range(len(sim_obs)):\n        local_nps = []\n        for i in range(2):\n          img = PIL_Image().new(\"RGB\", (sim_obs.shape[-2], 11),)\n          draw = PIL_ImageDraw().Draw(img)\n          draw.text((0, 0), \"c:{:3}, r:{:3}\".format(int(rews[i][0][j]),\n                                                    int(rews[i][1][j])),\n                    fill=(255, 0, 0))\n          local_nps.append(np.asarray(img))\n        local_nps.append(np.zeros_like(local_nps[0]))\n        headers.append(np.concatenate(local_nps, axis=1))\n      errs = absolute_hinge_difference(sim_obs, real_obs)\n      headers = np.stack(headers)\n      debug_frame_batches.append(  # pylint: disable=cell-var-from-loop\n          np.concatenate([headers,\n                          np.concatenate([sim_obs, real_obs, errs], axis=2)],\n                         axis=1)\n      )\n    append_debug_frame_batch(sim_init_obs, real_init_obs,\n                             np.zeros(hparams.wm_eval_batch_size),\n                             np.zeros(hparams.wm_eval_batch_size),\n                             np.zeros(hparams.wm_eval_batch_size),\n                             np.zeros(hparams.wm_eval_batch_size))\n\n    (sim_cum_rewards, real_cum_rewards) = (\n        np.zeros(hparams.wm_eval_batch_size) for _ in range(2)\n    )\n    for i in range(subsequence_length):\n      actions = [subsequence[i].action for subsequence in eval_subsequences]\n      (sim_obs, sim_rewards, _) = sim_env.step(actions)\n      sim_cum_rewards += sim_rewards\n\n      real_rewards = np.array([\n          subsequence[i + 1].reward for subsequence in eval_subsequences\n      ])\n      real_cum_rewards += real_rewards\n      for (length, reward_accuracies) in six.iteritems(\n          reward_accuracies_by_length\n      ):\n        if i + 1 == length:\n          reward_accuracies.append(\n              np.sum(sim_cum_rewards == real_cum_rewards) /\n              len(real_cum_rewards)\n          )\n\n      real_obs = decode_real_obs(i + 1)\n      append_debug_frame_batch(sim_obs, real_obs, sim_cum_rewards,\n                               real_cum_rewards, sim_rewards, real_rewards)\n\n    for debug_frames in np.stack(debug_frame_batches, axis=1):\n      debug_frame = None\n      for debug_frame in debug_frames:\n        video_writer.write(debug_frame)\n\n      if debug_frame is not None:\n        # Append two black frames for aesthetics.\n        for _ in range(2):\n          video_writer.write(np.zeros_like(debug_frame))\n\n  video_writer.finish_to_disk()\n\n  return {\n      \"reward_accuracy/at_{}\".format(length): np.mean(reward_accuracies)\n      for (length, reward_accuracies) in six.iteritems(\n          reward_accuracies_by_length\n      )\n  }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite metrics to summary.", "response": "def summarize_metrics(eval_metrics_writer, metrics, epoch):\n  \"\"\"Write metrics to summary.\"\"\"\n  for (name, value) in six.iteritems(metrics):\n    summary = tf.Summary()\n    summary.value.add(tag=name, simple_value=value)\n    eval_metrics_writer.add_summary(summary, epoch)\n  eval_metrics_writer.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef full_game_name(short_name):\n  camel_game_name = misc_utils.snakecase_to_camelcase(short_name)\n  full_name = camel_game_name + ATARI_GAME_MODE\n  return full_name", "response": "CamelCase game name with mode suffix."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncopying a subset of hparams to target_hparams.", "response": "def update_hparams_from_hparams(target_hparams, source_hparams, prefix):\n  \"\"\"Copy a subset of hparams to target_hparams.\"\"\"\n  for (param_name, param_value) in six.iteritems(source_hparams.values()):\n    if param_name.startswith(prefix):\n      target_hparams.set_hparam(param_name[len(prefix):], param_value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nchoose a random frame sequence of given length from a set of rollouts.", "response": "def random_rollout_subsequences(rollouts, num_subsequences, subsequence_length):\n  \"\"\"Chooses a random frame sequence of given length from a set of rollouts.\"\"\"\n  def choose_subsequence():\n    # TODO(koz4k): Weigh rollouts by their lengths so sampling is uniform over\n    # frames and not rollouts.\n    rollout = random.choice(rollouts)\n    try:\n      from_index = random.randrange(len(rollout) - subsequence_length + 1)\n    except ValueError:\n      # Rollout too short; repeat.\n      return choose_subsequence()\n    return rollout[from_index:(from_index + subsequence_length)]\n\n  return [choose_subsequence() for _ in range(num_subsequences)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a function to choose initial frames from a single rollout.", "response": "def make_initial_frame_chooser(\n    real_env, frame_stack_size, simulation_random_starts,\n    simulation_flip_first_random_for_beginning,\n    split=tf.estimator.ModeKeys.TRAIN,\n):\n  \"\"\"Make frame chooser.\n\n  Args:\n    real_env: T2TEnv to take initial frames from.\n    frame_stack_size (int): Number of consecutive frames to extract.\n    simulation_random_starts (bool): Whether to choose frames at random.\n    simulation_flip_first_random_for_beginning (bool): Whether to flip the first\n      frame stack in every batch for the frames at the beginning.\n    split (tf.estimator.ModeKeys or None): Data split to take the frames from,\n      None means use all frames.\n\n  Returns:\n    Function batch_size -> initial_frames.\n  \"\"\"\n  initial_frame_rollouts = real_env.current_epoch_rollouts(\n      split=split, minimal_rollout_frames=frame_stack_size,\n  )\n  def initial_frame_chooser(batch_size):\n    \"\"\"Frame chooser.\"\"\"\n\n    deterministic_initial_frames =\\\n        initial_frame_rollouts[0][:frame_stack_size]\n    if not simulation_random_starts:\n      # Deterministic starts: repeat first frames from the first rollout.\n      initial_frames = [deterministic_initial_frames] * batch_size\n    else:\n      # Random starts: choose random initial frames from random rollouts.\n      initial_frames = random_rollout_subsequences(\n          initial_frame_rollouts, batch_size, frame_stack_size\n      )\n      if simulation_flip_first_random_for_beginning:\n        # Flip first entry in the batch for deterministic initial frames.\n        initial_frames[0] = deterministic_initial_frames\n\n    return np.stack([\n        [frame.observation.decode() for frame in initial_frame_stack]  # pylint: disable=g-complex-comprehension\n        for initial_frame_stack in initial_frames\n    ])\n  return initial_frame_chooser"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef absolute_hinge_difference(arr1, arr2, min_diff=10, dtype=np.uint8):\n  diff = np.abs(arr1.astype(np.int) - arr2, dtype=np.int)\n  return np.maximum(diff - min_diff, 0).astype(dtype)", "response": "Point - wise hinge loss - like difference between arrays."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef augment_observation(\n    observation, reward, cum_reward, frame_index, bar_color=None,\n    header_height=27\n):\n  \"\"\"Augments an observation with debug info.\"\"\"\n  img = PIL_Image().new(\n      \"RGB\", (observation.shape[1], header_height,)\n  )\n  draw = PIL_ImageDraw().Draw(img)\n  draw.text(\n      (1, 0), \"c:{:3}, r:{:3}\".format(int(cum_reward), int(reward)),\n      fill=(255, 0, 0)\n  )\n  draw.text(\n      (1, 15), \"f:{:3}\".format(int(frame_index)),\n      fill=(255, 0, 0)\n  )\n  header = np.copy(np.asarray(img))\n  del img\n  if bar_color is not None:\n    header[0, :, :] = bar_color\n  return np.concatenate([header, observation], axis=0)", "response": "Augments an observation with debug info."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns a batch of rollouts from given initial observations.", "response": "def run_rollouts(\n    env, agent, initial_observations, step_limit=None, discount_factor=1.0,\n    log_every_steps=None, video_writers=(), color_bar=False,\n    many_rollouts_from_each_env=False\n):\n  \"\"\"Runs a batch of rollouts from given initial observations.\"\"\"\n  assert step_limit is not None or not many_rollouts_from_each_env, (\n      \"When collecting many rollouts from each environment, time limit must \"\n      \"be set.\"\n  )\n\n  num_dones = 0\n  first_dones = np.array([False] * env.batch_size)\n  observations = initial_observations\n  step_index = 0\n  cum_rewards = np.zeros(env.batch_size)\n\n  for (video_writer, obs_stack) in zip(video_writers, initial_observations):\n    for (i, ob) in enumerate(obs_stack):\n      debug_frame = augment_observation(\n          ob, reward=0, cum_reward=0, frame_index=(-len(obs_stack) + i + 1),\n          bar_color=((0, 255, 0) if color_bar else None)\n      )\n      video_writer.write(debug_frame)\n\n  def proceed():\n    if step_index < step_limit:\n      return num_dones < env.batch_size or many_rollouts_from_each_env\n    else:\n      return False\n\n  while proceed():\n    act_kwargs = {}\n    if agent.needs_env_state:\n      act_kwargs[\"env_state\"] = env.state\n    actions = agent.act(observations, **act_kwargs)\n    (observations, rewards, dones) = env.step(actions)\n    observations = list(observations)\n    now_done_indices = []\n    for (i, done) in enumerate(dones):\n      if done and (not first_dones[i] or many_rollouts_from_each_env):\n        now_done_indices.append(i)\n        first_dones[i] = True\n        num_dones += 1\n    if now_done_indices:\n      # Unless many_rollouts_from_each_env, reset only envs done the first time\n      # in this timestep to ensure that we collect exactly 1 rollout from each\n      # env.\n      reset_observations = env.reset(now_done_indices)\n      for (i, observation) in zip(now_done_indices, reset_observations):\n        observations[i] = observation\n    observations = np.array(observations)\n    cum_rewards[~first_dones] = (\n        cum_rewards[~first_dones] * discount_factor + rewards[~first_dones]\n    )\n    step_index += 1\n\n    for (video_writer, obs_stack, reward, cum_reward, done) in zip(\n        video_writers, observations, rewards, cum_rewards, first_dones\n    ):\n      if done:\n        continue\n      ob = obs_stack[-1]\n      debug_frame = augment_observation(\n          ob, reward=reward, cum_reward=cum_reward,\n          frame_index=step_index, bar_color=((255, 0, 0) if color_bar else None)\n      )\n      video_writer.write(debug_frame)\n\n    # TODO(afrozm): Clean this up with tf.logging.log_every_n\n    if log_every_steps is not None and step_index % log_every_steps == 0:\n      tf.logging.info(\"Step %d, mean_score: %f\", step_index, cum_rewards.mean())\n\n  return (observations, cum_rewards)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_initial_state(self, initial_state, initial_frames):\n    self.env.set_initial_state(initial_state, initial_frames)\n    self._initial_frames = initial_frames", "response": "Sets the state that will be used on next reset."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndownloads all files generated by CNN and Dailymail.", "response": "def _maybe_download_corpora(tmp_dir, dataset_split):\n  \"\"\"Download corpora if necessary and unzip them.\n\n  Args:\n    tmp_dir: directory containing dataset.\n    dataset_split: whether we're in train/dev/test mode.\n\n  Returns:\n    List of all files generated and path to file containing\n      train/dev/test split info.\n  \"\"\"\n  cnn_filename = \"cnn_stories.tgz\"\n  cnn_finalpath = os.path.join(tmp_dir, \"cnn/stories/\")\n  dailymail_filename = \"dailymail_stories.tgz\"\n  dailymail_finalpath = os.path.join(tmp_dir, \"dailymail/stories/\")\n  if not tf.gfile.Exists(cnn_finalpath):\n    cnn_file = generator_utils.maybe_download_from_drive(\n        tmp_dir, cnn_filename, _CNN_STORIES_DRIVE_URL)\n    with tarfile.open(cnn_file, \"r:gz\") as cnn_tar:\n      cnn_tar.extractall(tmp_dir)\n  if not tf.gfile.Exists(dailymail_finalpath):\n    dailymail_file = generator_utils.maybe_download_from_drive(\n        tmp_dir, dailymail_filename, _DAILYMAIL_STORIES_DRIVE_URL)\n    with tarfile.open(dailymail_file, \"r:gz\") as dailymail_tar:\n      dailymail_tar.extractall(tmp_dir)\n\n  cnn_files = tf.gfile.Glob(cnn_finalpath + \"*\")\n  dailymail_files = tf.gfile.Glob(dailymail_finalpath + \"*\")\n  all_files = cnn_files + dailymail_files\n\n  if dataset_split == problem.DatasetSplit.TRAIN:\n    urls_path = generator_utils.maybe_download(tmp_dir, \"all_train.txt\",\n                                               _TRAIN_URLS)\n  elif dataset_split == problem.DatasetSplit.EVAL:\n    urls_path = generator_utils.maybe_download(tmp_dir, \"all_val.txt\",\n                                               _DEV_URLS)\n  else:\n    urls_path = generator_utils.maybe_download(tmp_dir, \"all_test.txt\",\n                                               _TEST_URLS)\n\n  return all_files, urls_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef example_splits(url_file, all_files):\n\n  def generate_hash(inp):\n    \"\"\"Generate a sha1 hash to match the raw url to the filename extracted.\"\"\"\n    h = hashlib.sha1()\n    h.update(inp)\n    return h.hexdigest()\n\n  all_files_map = {f.split(\"/\")[-1]: f for f in all_files}\n\n  urls = [line.strip().encode(\"utf-8\") for line in tf.gfile.Open(url_file)]\n\n  filelist = []\n  for url in urls:\n    url_hash = generate_hash(url)\n    filename = url_hash + \".story\"\n    if filename not in all_files_map:\n      tf.logging.info(\"Missing file: %s\" % url)\n      continue\n    filelist.append(all_files_map[filename])\n\n  tf.logging.info(\"Found %d examples\" % len(filelist))\n\n  return filelist", "response": "Generate splits of the data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite text to files.", "response": "def write_raw_text_to_files(all_files, urls_path, dataset_split, tmp_dir):\n  \"\"\"Write text to files.\"\"\"\n\n  def write_to_file(all_files, urls_path, tmp_dir, filename):\n    \"\"\"Write text to files.\"\"\"\n    with io.open(\n        os.path.join(tmp_dir, filename + \".source\"), \"w\",\n        encoding=\"utf-8\") as fstory:\n      with io.open(\n          os.path.join(tmp_dir, filename + \".target\"), \"w\",\n          encoding=\"utf-8\") as fsummary:\n        for example in example_generator(all_files, urls_path, sum_token=True):\n          story, summary = _story_summary_split(example)\n          fstory.write(story + \"\\n\")\n          fsummary.write(summary + \"\\n\")\n\n  if dataset_split == problem.DatasetSplit.TRAIN:\n    filename = \"cnndm.train\"\n  elif dataset_split == problem.DatasetSplit.EVAL:\n    filename = \"cnndm.dev\"\n  else:\n    filename = \"cnndm.test\"\n\n  tf.logging.info(\"Writing %s\" % filename)\n  write_to_file(all_files, urls_path, tmp_dir, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef infer_last_epoch_num(data_dir):\n  names = os.listdir(data_dir)\n  epochs_str = [re.findall(pattern=r\".*\\.(-?\\d+)$\", string=name)\n                for name in names]\n  epochs_str = sum(epochs_str, [])\n  return max([int(epoch_str) for epoch_str in epochs_str])", "response": "Infer highest epoch number from file names in data_dir."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload T2TGymEnv with data from one epoch. Args: hparams: hparams. data_dir: data directory. which_epoch_data: data from which epoch to load. Returns: env.", "response": "def setup_and_load_epoch(hparams, data_dir, which_epoch_data=None):\n  \"\"\"Load T2TGymEnv with data from one epoch.\n\n  Args:\n    hparams: hparams.\n    data_dir: data directory.\n    which_epoch_data: data from which epoch to load.\n\n  Returns:\n    env.\n  \"\"\"\n  t2t_env = rl_utils.setup_env(\n      hparams, batch_size=hparams.real_batch_size,\n      max_num_noops=hparams.max_num_noops\n  )\n  # Load data.\n  if which_epoch_data is not None:\n    if which_epoch_data == \"last\":\n      which_epoch_data = infer_last_epoch_num(data_dir)\n    assert isinstance(which_epoch_data, int), \\\n      \"{}\".format(type(which_epoch_data))\n    t2t_env.start_new_epoch(which_epoch_data, data_dir)\n  else:\n    t2t_env.start_new_epoch(-999)\n  return t2t_env"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef infer_game_name_from_filenames(data_dir, snake_case=True):\n  names = os.listdir(data_dir)\n  game_names = [re.findall(pattern=r\"^Gym(.*)NoFrameskip\", string=name)\n                for name in names]\n  assert game_names, \"No data files found in {}\".format(data_dir)\n  game_names = sum(game_names, [])\n  game_name = game_names[0]\n  assert all(game_name == other for other in game_names), \\\n      \"There are multiple different game names in {}\".format(data_dir)\n  if snake_case:\n    game_name = camelcase_to_snakecase(game_name)\n  return game_name", "response": "Infer name from filenames."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wrap_with_monitor(env, video_dir):\n  env = ExtendToEvenDimentions(env)\n  env = RenderObservations(env)  # pylint: disable=redefined-variable-type\n  env = gym.wrappers.Monitor(env, video_dir, force=True,\n                             video_callable=lambda idx: True,\n                             write_upon_reset=True)\n  return env", "response": "Wrap environment with gym. Monitor.\n\n"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_simulated_env(\n    output_dir, grayscale, resize_width_factor, resize_height_factor,\n    frame_stack_size, generative_model, generative_model_params,\n    random_starts=True, which_epoch_data=\"last\", **other_hparams\n):\n  \"\"\"\"Create SimulatedEnv with minimal subset of hparams.\"\"\"\n  # We need these, to initialize T2TGymEnv, but these values (hopefully) have\n  # no effect on player.\n  a_bit_risky_defaults = {\n      \"game\": \"pong\",  # assumes that T2TGymEnv has always reward_range (-1,1)\n      \"real_batch_size\": 1,\n      \"rl_env_max_episode_steps\": -1,\n      \"max_num_noops\": 0\n  }\n\n  for key in a_bit_risky_defaults:\n    if key not in other_hparams:\n      other_hparams[key] = a_bit_risky_defaults[key]\n\n  hparams = hparam.HParams(\n      grayscale=grayscale,\n      resize_width_factor=resize_width_factor,\n      resize_height_factor=resize_height_factor,\n      frame_stack_size=frame_stack_size,\n      generative_model=generative_model,\n      generative_model_params=generative_model_params,\n      **other_hparams\n  )\n  return load_data_and_make_simulated_env(\n      output_dir, wm_dir=None, hparams=hparams,\n      which_epoch_data=which_epoch_data,\n      random_starts=random_starts)", "response": "Create SimulatedEnv with minimal subset of hparams."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef infer_paths(output_dir, **subdirs):\n  directories = {}\n  for name, path in six.iteritems(subdirs):\n    directories[name] = path if path else os.path.join(output_dir, name)\n  directories[\"output_dir\"] = output_dir\n  return directories", "response": "Infers standard paths to policy and model directories."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd new frame to initial frame stack removes last one.", "response": "def add_to_initial_stack(self, frame):\n    \"\"\"Adds new frame to (initial) frame stack, removes last one.\"\"\"\n    if not self._setable_initial_frames:\n      raise ValueError(\n          \"This instance does not allow to manually set initial frame stack.\")\n    assert_msg = \"{}, {}\".format(frame.shape, self._initial_frames.shape[:1])\n    assert frame.shape == self._initial_frames.shape[2:], assert_msg\n    initial_frames = np.roll(self._initial_frames, shift=-1, axis=1)\n    initial_frames[0, -1, ...] = frame\n    self._initial_frames = initial_frames"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd single zero row or column to observation if needed.", "response": "def observation(self, frame):\n    \"\"\"Add single zero row/column to observation if needed.\"\"\"\n    if frame.shape == self.observation_space.shape:\n      return frame\n    else:\n      extended_frame = np.zeros(self.observation_space.shape,\n                                self.observation_space.dtype)\n      assert self.HW_AXES == (0, 1)\n      extended_frame[:frame.shape[0], :frame.shape[1]] = frame\n      return extended_frame"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninferring the logits and VF of a new observation.", "response": "def infer(self, ob):\n    \"\"\"Add new observation to frame stack and infer policy.\n\n    Args:\n      ob: array of shape (height, width, channels)\n\n    Returns:\n      logits and vf.\n    \"\"\"\n    self._add_to_stack(ob)\n    logits, vf = self.infer_from_frame_stack(self._frame_stack)\n    return logits, vf"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninfers policy from stack of observations.", "response": "def infer_from_frame_stack(self, ob_stack):\n    \"\"\"Infer policy from stack of observations.\n\n    Args:\n      ob_stack: array of shape (1, frame_stack_size, height, width, channels)\n\n    Returns:\n      logits and vf.\n    \"\"\"\n    logits, vf = self.sess.run([self.logits_t, self.value_function_t],\n                               feed_dict={self.obs_t: ob_stack})\n    return logits, vf"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nnormalizing the string using tokenizer. encode.", "response": "def _normalize_string(raw_str):\n  \"\"\"Normalizes the string using tokenizer.encode.\n\n  Args:\n    raw_str: the input string\n\n  Returns:\n   A string which is ready to be tokenized using split()\n  \"\"\"\n  return \" \".join(\n      token.strip()\n      for token in tokenizer.encode(text_encoder.native_to_unicode(raw_str)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _prepare_babi_data(tmp_dir, data_dir):\n  if not tf.gfile.Exists(data_dir):\n    tf.gfile.MakeDirs(data_dir)\n\n  file_path = os.path.join(tmp_dir, _TAR)\n  headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_1) \"\n                           \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n                           \"Chrome/63.0.3239.132 Safari/537.36\"}\n  resp = requests.get(_URL, headers=headers)\n  with open(file_path, \"wb\") as f:\n    f.write(resp.content)\n\n  tar = tarfile.open(file_path)\n  tar.extractall(tmp_dir)\n  tar.close()\n\n  return tmp_dir", "response": "Downloads and extracts the dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _babi_parser(tmp_dir,\n                 babi_task_id,\n                 subset,\n                 dataset_split,\n                 joint_training=True):\n  \"\"\"Parsing the bAbi dataset (train and test).\n\n  Args:\n    tmp_dir: temp directory to download and extract the dataset\n    babi_task_id: babi task id\n    subset: babi subset\n    dataset_split: dataset split (train or eval)\n    joint_training: if training the model on all tasks.\n\n  Returns:\n     babi_instances: set of training examples, each a dict containing a story,\n     a question and an answer.\n     babi_lines: all the texts in the data separated based on their\n     appearance in the stories, questions, or answers.\n  \"\"\"\n\n  def _data_file(mode, task_id):\n    \"\"\"Generates the path to the data file for the given mode(train/test).\n\n    Args:\n      mode: either train or test for bAbi dataset\n      task_id: babi task id\n\n    Returns:\n      data file path\n    \"\"\"\n    file_name = (_TASKS[task_id] + \"_{}.txt\")\n    return os.path.join(_DIR_NAME, subset, file_name.format(mode))\n\n  def _all_task_raw_data_generator(tmp_dir, data_file, dataset_split):\n    \"\"\"Prepares raw data for all tasks to gether..\n\n    Args:\n      tmp_dir: temp directory\n      data_file: data file\n      dataset_split: dataset split\n    \"\"\"\n\n    tf.logging.info(\"Preparing dataset of all task together\")\n    globe_name = (\"*_{}.txt\")\n    mode_name = \"test\"\n    if dataset_split == problem.DatasetSplit.TRAIN:\n      mode_name = \"train\"\n    files_name = os.path.join(\n        tmp_dir, _DIR_NAME, subset,\n        globe_name.format(mode_name))\n    with tf.gfile.GFile(data_file, \"wb\") as outfile:\n      for filename in tf.gfile.Glob(files_name):\n        if filename == data_file:\n          # don\"t want to copy the output into the output\n          continue\n        with tf.gfile.GFile(filename, \"rb\") as readfile:\n          shutil.copyfileobj(readfile, outfile)\n\n  def _parse_answer(answer):\n    if (joint_training or babi_task_id in [\"qa8\", \"qa19\", \"qa0\"\n                                          ]):  # \"lists-sets\" or \"path finding\"\n      return \"\".join([d for d in answer.split(\",\")])  # as a single token!\n    else:\n      return answer\n\n  if dataset_split == problem.DatasetSplit.TRAIN:\n    babi_train_task_id = \"qa0\" if joint_training else babi_task_id\n    data_file = os.path.join(tmp_dir, _data_file(\"train\", babi_train_task_id))\n  else:\n    data_file = os.path.join(tmp_dir, _data_file(\"test\", babi_task_id))\n\n  if ((babi_task_id == \"qa0\" or joint_training) and\n      not tf.gfile.Exists(os.path.join(tmp_dir, data_file))):\n    _all_task_raw_data_generator(tmp_dir, data_file, dataset_split)\n\n  tf.logging.info(\"Parsing %s into training/testing instances...\", data_file)\n\n  babi_instances = []\n  with tf.gfile.GFile(data_file, mode=\"r\") as f:\n    story = []\n    for line in f:\n      line_num, line = line.strip().split(\" \", 1)\n      if int(line_num) == 1:\n        story = []\n      if \"\\t\" in line:\n        question, answer, _ = line.split(\"\\t\")\n        question = _normalize_string(question)\n        substories = [s for s in story if s]\n        answer = _parse_answer(answer)\n        instance = {\n            FeatureNames.STORY: substories,\n            FeatureNames.QUESTION: question,\n            FeatureNames.ANSWER: answer\n        }\n        babi_instances.append(instance)\n\n        story.append(\"\")\n      else:\n        story.append(_normalize_string(line))\n\n  return babi_instances", "response": "This function parses the bAbi dataset and returns the bAbi dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_labels_encoder(self, data_dir):\n    label_filepath = os.path.join(data_dir, self.vocab_filename)\n    return text_encoder.TokenTextEncoder(label_filepath)", "response": "Builds a encoder for the given class labels."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_encoded_samples(self, data_dir, tmp_dir, dataset_split):\n    generator = self.generate_samples(data_dir, tmp_dir, dataset_split)\n    encoder = self.get_or_create_vocab(data_dir, tmp_dir)\n    label_encoder = self.get_labels_encoder(data_dir)\n    for sample in generator:\n      inputs = encoder.encode(sample[\"inputs\"])\n      inputs.append(text_encoder.EOS_ID)\n      context = encoder.encode(sample[\"context\"])\n      context.append(text_encoder.EOS_ID)\n      targets = label_encoder.encode(sample[\"targets\"])\n      sample[\"targets\"] = targets\n      yield {\"inputs\": inputs, \"context\": context, \"targets\": targets}", "response": "A generator that generates samples that are encoded."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef feature_encoders(self, data_dir):\n    encoders = (super(BabiQa, self).feature_encoders(data_dir))\n    label_encoder = self.get_labels_encoder(data_dir)\n    encoders[\"targets\"] = label_encoder  # bAbi as a classification task\n    return encoders", "response": "Return a dict for encoding and decoding inference input and output."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hparams(self, defaults, unused_model_hparams):\n    (super(BabiQa, self).hparams(defaults, unused_model_hparams))\n    p = defaults\n    num_classes = self._encoders[\"targets\"].vocab_size\n    p.modality = {\"targets\": modalities.ModalityType.CLASS_LABEL}\n    p.vocab_size = {\"targets\": num_classes}", "response": "Returns problem_hparams.\n\n    Args:\n      defaults: default hyperparameters\n      unused_model_hparams: model hyperparameters"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsplit of data to produce and number the output shards for each.", "response": "def dataset_splits(self):\n    \"\"\"Splits of data to produce and number the output shards for each.\"\"\"\n    return [{\n        \"split\": problem.DatasetSplit.TRAIN,\n        \"shards\": self.num_train_shards,\n    }, {\n        \"split\": problem.DatasetSplit.EVAL,\n        \"shards\": self.num_eval_shards,\n    }, {\n        \"split\": problem.DatasetSplit.TEST,\n        \"shards\": self.num_test_shards,\n    }]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntraverses a directory collecting input and target files.", "response": "def _collect_data(directory, input_ext, transcription_ext):\n  \"\"\"Traverses directory collecting input and target files.\"\"\"\n  # Directory from string to tuple pair of strings\n  # key: the filepath to a datafile including the datafile's basename. Example,\n  #   if the datafile was \"/path/to/datafile.wav\" then the key would be\n  #   \"/path/to/datafile\"\n  # value: a pair of strings (media_filepath, label)\n  data_files = {}\n  for root, _, filenames in os.walk(directory):\n    transcripts = [filename for filename in filenames\n                   if transcription_ext in filename]\n    for transcript in transcripts:\n      transcript_path = os.path.join(root, transcript)\n      with open(transcript_path, \"r\") as transcript_file:\n        for transcript_line in transcript_file:\n          line_contents = transcript_line.strip().split(\" \", 1)\n          media_base, label = line_contents\n          key = os.path.join(root, media_base)\n          assert key not in data_files\n          media_name = \"%s.%s\"%(media_base, input_ext)\n          media_path = os.path.join(root, media_name)\n          data_files[key] = (media_base, media_path, label)\n  return data_files"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd to base hparams the attributes for librispeech.", "response": "def add_librispeech_hparams(hparams):\n  \"\"\"Adding to base hparams the attributes for for librispeech.\"\"\"\n  hparams.batch_size = 36\n  hparams.audio_compression = 8\n  hparams.hidden_size = 2048\n  hparams.max_input_seq_length = 600000\n  hparams.max_target_seq_length = 350\n  hparams.max_length = hparams.max_input_seq_length\n  hparams.min_length_bucket = hparams.max_input_seq_length // 2\n  hparams.learning_rate = 0.05\n  hparams.train_steps = 5000000\n  hparams.num_hidden_layers = 4\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef words_and_tags_from_wsj_tree(tree_string):\n  stack, tags, words = [], [], []\n  for tok in tree_string.strip().split():\n    if tok[0] == \"(\":\n      symbol = tok[1:]\n      tags.append(symbol)\n      stack.append(symbol)\n    else:\n      assert tok[-1] == \")\"\n      stack.pop()  # Pop the POS-tag.\n      while tok[-2] == \")\":\n        tags.append(\"/\" + stack.pop())\n        tok = tok[:-1]\n      words.append(tok[:-1])\n  return str.join(\" \", words), str.join(\" \", tags[1:-1])", "response": "Generates a list of words and tags from a wsj tree format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parsing_token_generator(data_dir, tmp_dir, train, source_vocab_size,\n                            target_vocab_size):\n  \"\"\"Generator for parsing as a sequence-to-sequence task that uses tokens.\n\n  This generator assumes the files parsing_{train,dev}.trees, which contain\n  trees in WSJ format.\n\n  Args:\n    data_dir: path to the data directory.\n    tmp_dir: path to temporary storage directory.\n    train: whether we're training or not.\n    source_vocab_size: source vocab size.\n    target_vocab_size: target vocab size.\n\n  Returns:\n    A generator to a dictionary of inputs and outputs.\n  \"\"\"\n  # TODO(lukaszkaiser): Correct these calls to generate vocabularies. No data\n  # sources are being passed.\n  del (data_dir, tmp_dir, train, source_vocab_size, target_vocab_size)\n  assert False, \"Vocabulary generation not implemented\"", "response": "Generator for parsing as a sequence - to - sequence task that uses tokens."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef aggregate_stats(stats_files):\n  all_stats = {}\n  for fname in stats_files:\n    with tf.gfile.Open(fname) as f:\n      stats = json.loads(f.read())\n      for k, v in stats.iteritems():\n        if k not in all_stats:\n          if isinstance(v, list):\n            all_stats[k] = []\n          else:\n            all_stats[k] = 0\n\n        if isinstance(v, list):\n          all_stats[k].extend(v)\n        else:\n          all_stats[k] += v\n\n  stats = all_stats\n  ref_coverage = float(stats[\"total_found_refs\"]) / stats[\"total_original_refs\"]\n  len_bounds = [0, 2, 10, 100, 1000, 5000, 10000, 20000, 50000, 100000, 1000000]\n  len_counts, len_bounds = np.histogram(stats[\"ref_lengths\"], len_bounds)\n  len_dist = len_counts.astype(np.float32) / len_counts.sum()\n  wiki_coverage = (float(stats[\"num_wikis_written\"]) /\n                   stats[\"total_original_wikis\"])\n  wikis_skipped_no_ref = (float(stats[\"wikis_skipped_no_refs\"]) /\n                          stats[\"total_original_wikis\"])\n  wikis_skipped_no_lead = (float(stats[\"wikis_skipped_short_lead\"]) /\n                           stats[\"total_original_wikis\"])\n  wiki_ref_coverage = [\n      float(found) / orig for found, orig\n      in zip(stats[\"wiki_found_refs\"], stats[\"wiki_original_refs\"]) if found\n  ]\n  coverage_bounds = np.arange(21).astype(np.float32) / 20\n  coverage_counts, coverage_bounds = np.histogram(wiki_ref_coverage,\n                                                  coverage_bounds)\n  coverage_dist = coverage_counts.astype(np.float32) / coverage_counts.sum()\n\n  agg_stats = dict(\n      total_original_wikis=stats[\"total_original_wikis\"],\n      total_original_refs=stats[\"total_original_refs\"],\n      wiki_coverage=wiki_coverage,\n      wikis_skipped_no_ref=wikis_skipped_no_ref,\n      wikis_skipped_no_lead=wikis_skipped_no_lead,\n      overall_ref_coverage=ref_coverage,\n      per_wiki_ref_coverage_dist=list((coverage_dist * 100).astype(int)),\n      per_wiki_ref_coverage_bounds=list((coverage_bounds * 100).astype(int)),\n      ref_len_dist=list((len_dist * 100).astype(int)),\n      ref_len_bounds=list(len_bounds),\n  )\n  return agg_stats", "response": "Aggregate stats in per - shard stats files."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmaps filename to the task id that created it assuming 1k tasks.", "response": "def filename_to_task_id(fname):\n  \"\"\"Map filename to the task id that created it assuming 1k tasks.\"\"\"\n  # This matches the order and size in WikisumBase.out_filepaths\n  fname = os.path.basename(fname)\n  shard_id_increment = {\n      \"train\": 0,\n      \"dev\": 800,\n      \"test\": 900,\n  }\n  parts = fname.split(\"-\")\n  split = parts[1]\n  shard_id = parts[2]\n  task_id = int(shard_id) + shard_id_increment[split]\n  return task_id"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates presence and minimum size of files.", "response": "def validate_data_files(problem, data_files, min_size):\n  \"\"\"Validate presence and minimum size of files.\"\"\"\n  # Check that all files are present\n  data_dir = os.path.split(data_files[0])[0]\n  out_filepaths = problem.out_filepaths(data_dir)\n  missing_filepaths = set(out_filepaths) - set(data_files)\n  if missing_filepaths:\n    tf.logging.error(\"Missing %d data files\", len(missing_filepaths))\n\n  # Check that each file is at least 100M\n  too_small = []\n  for data_file in data_files:\n    length = get_length(data_file)\n    if length < min_size:\n      too_small.append(data_file)\n  if too_small:\n    tf.logging.error(\"%d files too small\", len(too_small))\n\n  bad_files = too_small + list(missing_filepaths)\n  return bad_files"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets of hyperparameters for distill_resnet_32_to_15_cifar20x5.", "response": "def distill_resnet_32_to_15_cifar20x5():\n  \"\"\"Set of hyperparameters.\"\"\"\n  hparams = distill_base()\n  hparams.teacher_model = \"resnet\"\n  hparams.teacher_hparams = \"resnet_cifar_32\"\n  hparams.student_model = \"resnet\"\n  hparams.student_hparams = \"resnet_cifar_15\"\n\n  hparams.optimizer_momentum_nesterov = True\n  # (base_lr=0.1) * (batch_size=128*8 (on TPU, or 8 GPUs)=1024) / (256.)\n  hparams.teacher_learning_rate = 0.25 * 128. * 8. / 256.\n  hparams.student_learning_rate = 0.2 * 128. * 8. / 256.\n  hparams.learning_rate_decay_scheme = \"piecewise\"\n  hparams.add_hparam(\"learning_rate_boundaries\", [40000, 60000, 80000])\n  hparams.add_hparam(\"learning_rate_multiples\", [0.1, 0.01, 0.001])\n\n  hparams.task_balance = 0.28\n  hparams.distill_temperature = 2.0\n\n  hparams.num_classes = 20\n\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _prepare_lambada_data(tmp_dir, data_dir, vocab_size, vocab_filename):\n\n  if not tf.gfile.Exists(data_dir):\n    tf.gfile.MakeDirs(data_dir)\n\n  file_path = generator_utils.maybe_download(tmp_dir, _TAR, _URL)\n  tar_all = tarfile.open(file_path)\n  tar_all.extractall(tmp_dir)\n  tar_all.close()\n  tar_train = tarfile.open(os.path.join(tmp_dir, \"train-novels.tar\"))\n  tar_train.extractall(tmp_dir)\n  tar_train.close()\n\n  vocab_path = os.path.join(data_dir, vocab_filename)\n  if not tf.gfile.Exists(vocab_path):\n    with tf.gfile.GFile(os.path.join(tmp_dir, _VOCAB), \"r\") as infile:\n      reader = csv.reader(infile, delimiter=\"\\t\")\n      words = [row[0] for row in reader]\n      words = [_UNK] + words[:vocab_size]\n    with tf.gfile.GFile(vocab_path, \"w\") as outfile:\n      outfile.write(\"\\n\".join(words))", "response": "Download and prepare the dataset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_dataset_split(tmp_dir, split, use_control_set):\n  if not use_control_set:\n    dataset_split = {\n        problem.DatasetSplit.TRAIN: [\n            f for f in tf.gfile.Glob(\n                os.path.join(tmp_dir, \"train-novels/*/*.txt\"))\n        ],\n        problem.DatasetSplit.EVAL: [\n            os.path.join(tmp_dir, \"lambada_development_plain_text.txt\")\n        ],\n        problem.DatasetSplit.TEST: [\n            os.path.join(tmp_dir, \"lambada_test_plain_text.txt\")\n        ]\n    }\n\n  else:\n    dataset_split = {\n        problem.DatasetSplit.TRAIN: [\n            f for f in tf.gfile.Glob(\n                os.path.join(tmp_dir, \"train-novels/*/*.txt\"))\n        ],\n        problem.DatasetSplit.EVAL: [\n            os.path.join(tmp_dir, \"lambada_control_test_data_plain_text.txt\")\n        ],\n    }\n\n  return dataset_split[split]", "response": "Returns the file paths with regards to the given split."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef min_sequence_length(self, dataset_split):\n    return {\n        problem.DatasetSplit.TRAIN: 8,\n        problem.DatasetSplit.EVAL: 65,\n        problem.DatasetSplit.TEST: 65\n    }[dataset_split]", "response": "Determine the minimum length given a dataset_split."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetermining the maximum length given a dataset_split.", "response": "def max_sequence_length(self, dataset_split):\n    \"\"\"Determine the maximum sequence length given a dataset_split.\n\n    Args:\n      dataset_split: A problem.DatasetSplit.\n\n    Returns:\n      The maximum length that a sequence can be for this dataset_split.\n    \"\"\"\n    return {\n        problem.DatasetSplit.TRAIN: 64,\n        problem.DatasetSplit.EVAL: 128,\n        problem.DatasetSplit.TEST: 128\n    }[dataset_split]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine the number of samples for this dataset_split.", "response": "def num_samples(self, dataset_split):\n    \"\"\"Determine the dataset sized given a dataset_split.\n\n    Args:\n      dataset_split: A problem.DatasetSplit.\n\n    Returns:\n      The desired number of samples for this dataset_split.\n    \"\"\"\n    return {\n        problem.DatasetSplit.TRAIN: 1000000,\n        problem.DatasetSplit.EVAL: 10000,\n        problem.DatasetSplit.TEST: 10000\n    }[dataset_split]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef next_checkpoint(model_dir, timeout_mins=240):\n  last_ckpt = None\n  timeout_secs = None\n  if timeout_mins != -1:\n    timeout_secs = timeout_mins * 60\n  while True:\n    last_ckpt = tf.contrib.training.wait_for_new_checkpoint(\n        model_dir, last_ckpt, seconds_to_sleep=60, timeout=timeout_secs)\n\n    if last_ckpt is None:\n      tf.logging.info(\n          \"Eval timeout: no new checkpoints within %dm\" % timeout_mins)\n      break\n\n    yield last_ckpt", "response": "Yields successive checkpoints from model_dir."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nyields successive checkpoints from model_dir.", "response": "def next_undecoded_checkpoint(model_dir, timeout_mins=240):\n  \"\"\"Yields successive checkpoints from model_dir.\"\"\"\n  last_ckpt = None\n  last_step = 0\n  while True:\n    # Get the latest checkpoint.\n    last_ckpt = tf.contrib.training.wait_for_new_checkpoint(\n        model_dir, last_ckpt, seconds_to_sleep=60, timeout=60 * timeout_mins)\n    # Get all the checkpoint from the model dir.\n    ckpt_path = tf.train.get_checkpoint_state(model_dir)\n    all_model_checkpoint_paths = ckpt_path.all_model_checkpoint_paths\n    ckpt_step = np.inf\n    next_ckpt = None\n    # Find the next checkpoint to eval based on last_step.\n    for ckpt in all_model_checkpoint_paths:\n      step = int(os.path.basename(ckpt).split(\"-\")[1])\n      if step > last_step and step < ckpt_step:\n        ckpt_step = step\n        next_ckpt = ckpt\n\n    # If all the checkpoints have been evaluated.\n    if last_ckpt is None and next_ckpt is None:\n      tf.logging.info(\n          \"Eval timeout: no new checkpoints within %dm\" % timeout_mins)\n      break\n\n    if next_ckpt is not None:\n      last_step = ckpt_step\n      last_ckpt = next_ckpt\n\n    yield last_ckpt"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a TensorFlow Session config.", "response": "def create_session_config(log_device_placement=False,\n                          enable_graph_rewriter=False,\n                          gpu_mem_fraction=0.95,\n                          use_tpu=False,\n                          xla_jit_level=tf.OptimizerOptions.OFF,\n                          inter_op_parallelism_threads=0,\n                          intra_op_parallelism_threads=0):\n  \"\"\"The TensorFlow Session config to use.\"\"\"\n  if use_tpu:\n    graph_options = tf.GraphOptions()\n  else:\n    if enable_graph_rewriter:\n      rewrite_options = rewriter_config_pb2.RewriterConfig()\n      rewrite_options.layout_optimizer = rewriter_config_pb2.RewriterConfig.ON\n      graph_options = tf.GraphOptions(rewrite_options=rewrite_options)\n    else:\n      graph_options = tf.GraphOptions(\n          optimizer_options=tf.OptimizerOptions(\n              opt_level=tf.OptimizerOptions.L1,\n              do_function_inlining=False,\n              global_jit_level=xla_jit_level))\n\n  gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_mem_fraction)\n\n  config = tf.ConfigProto(\n      allow_soft_placement=True,\n      graph_options=graph_options,\n      gpu_options=gpu_options,\n      log_device_placement=log_device_placement,\n      inter_op_parallelism_threads=inter_op_parallelism_threads,\n      intra_op_parallelism_threads=intra_op_parallelism_threads,\n      isolate_session_state=True)\n  return config"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_run_config(model_name,\n                      master=\"\",\n                      model_dir=None,\n                      iterations_per_loop=1000,\n                      num_shards=8,\n                      log_device_placement=False,\n                      save_checkpoints_steps=1000,\n                      save_checkpoints_secs=None,\n                      keep_checkpoint_max=20,\n                      keep_checkpoint_every_n_hours=10000,\n                      num_gpus=1,\n                      gpu_order=\"\",\n                      num_async_replicas=1,\n                      enable_graph_rewriter=False,\n                      gpu_mem_fraction=0.95,\n                      no_data_parallelism=False,\n                      optionally_use_dist_strat=False,\n                      daisy_chain_variables=True,\n                      schedule=\"continuous_train_and_eval\",\n                      worker_job=\"/job:localhost\",\n                      worker_id=0,\n                      ps_replicas=0,\n                      ps_job=\"/job:ps\",\n                      ps_gpu=0,\n                      random_seed=None,\n                      sync=False,\n                      tpu_infeed_sleep_secs=None,\n                      use_tpu=False,\n                      use_tpu_estimator=False,\n                      xla_jit_level=tf.OptimizerOptions.OFF,\n                      inter_op_parallelism_threads=0,\n                      log_step_count_steps=100,\n                      intra_op_parallelism_threads=0,\n                      tpu_config_extra_kwargs=None,\n                      cloud_tpu_name=\"\"):\n  \"\"\"Create RunConfig, TPUConfig, and Parallelism object.\"\"\"\n  session_config = create_session_config(\n      log_device_placement=log_device_placement,\n      enable_graph_rewriter=enable_graph_rewriter,\n      gpu_mem_fraction=gpu_mem_fraction,\n      use_tpu=use_tpu,\n      xla_jit_level=xla_jit_level,\n      inter_op_parallelism_threads=inter_op_parallelism_threads,\n      intra_op_parallelism_threads=intra_op_parallelism_threads)\n  run_config_args = {\n      \"master\": master,\n      \"evaluation_master\": master,\n      \"model_dir\": model_dir,\n      \"session_config\": session_config,\n      \"save_summary_steps\": 100,\n      \"save_checkpoints_steps\": save_checkpoints_steps,\n      \"save_checkpoints_secs\": save_checkpoints_secs,\n      \"keep_checkpoint_max\": keep_checkpoint_max,\n      \"keep_checkpoint_every_n_hours\": keep_checkpoint_every_n_hours,\n      \"tf_random_seed\": random_seed,\n      \"log_step_count_steps\": log_step_count_steps\n  }\n  if save_checkpoints_secs:\n    del run_config_args[\"save_checkpoints_steps\"]\n  run_config_cls = tf.contrib.learn.RunConfig\n\n  if use_tpu or use_tpu_estimator:\n    # If using TPUEstimator, use TPU RunConfig, add TPUConfig, and add\n    # additional args.\n    tpu_config_kwargs = {\n        \"iterations_per_loop\": iterations_per_loop,\n        \"num_shards\": num_shards,\n        \"per_host_input_for_training\": True,\n        \"initial_infeed_sleep_secs\": tpu_infeed_sleep_secs,\n    }\n    if tpu_config_extra_kwargs is not None:\n      tpu_config_kwargs.update(tpu_config_extra_kwargs)\n    run_config_cls = tf.contrib.tpu.RunConfig\n    tpu_config = tf.contrib.tpu.TPUConfig(\n        **tpu_config_kwargs)\n    run_config_args[\"tpu_config\"] = tpu_config\n    if not master and \"KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS\" in os.environ:\n      # If running on TPU but no master is set and the KUBE env var is present\n      # then we're running on ML Engine. Set the master.\n      run_config_args[\"master\"] = os.environ[\n          \"KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS\"]\n      run_config_args[\"evaluation_master\"] = run_config_args[\"master\"]\n    elif not master and cloud_tpu_name:\n      # Update run_config to use cluster instead of master/evaluation_master\n      # as we need the cluster spec to use Cloud Pods\n      tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n          cloud_tpu_name)\n      run_config_args[\"cluster\"] = tpu_cluster_resolver\n      del run_config_args[\"master\"]\n      del run_config_args[\"evaluation_master\"]\n  elif is_cloud_async_distributed():\n    run_config_cls = tf.estimator.RunConfig\n    del run_config_args[\"master\"]\n    del run_config_args[\"evaluation_master\"]\n\n  config = run_config_cls(**run_config_args)\n\n  # If not using TPU, add device info for data_parallelism\n  config.use_tpu = use_tpu\n  if not use_tpu:\n    config.t2t_device_info = {\n        \"num_async_replicas\": num_async_replicas,\n    }\n    use_distribution_strategy = (\n        optionally_use_dist_strat and\n        t2t_model.T2TModel.has_symmetric_shards(model_name) and\n        not no_data_parallelism and ps_replicas == 0 and ps_gpu == 0 and\n        num_async_replicas == 1)\n\n    if use_distribution_strategy:\n      tf.logging.info(\n          \"Configuring MirroredStrategy DistributionStrategy to replicate the \"\n          \"model.\"\n      )\n      distribution = tf.contrib.distribute.MirroredStrategy()\n      config = config.replace(train_distribute=distribution)\n      config.data_parallelism = None\n    else:\n      tf.logging.info(\"Configuring DataParallelism to replicate the model.\")\n      config.data_parallelism = devices.data_parallelism(\n          daisy_chain_variables=daisy_chain_variables,\n          ps_replicas=ps_replicas,\n          ps_job=ps_job,\n          ps_gpu=ps_gpu,\n          schedule=schedule,\n          sync=sync,\n          worker_gpu=num_gpus,\n          worker_replicas=num_async_replicas,\n          worker_id=worker_id,\n          gpu_order=gpu_order,\n          worker_job=worker_job,\n          no_data_parallelism=no_data_parallelism)\n\n  return config", "response": "Create RunConfig TPUConfig and Parallelism object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_estimator(model_name,\n                     hparams,\n                     run_config,\n                     schedule=\"train_and_evaluate\",\n                     decode_hparams=None,\n                     use_tpu=False,\n                     use_tpu_estimator=False,\n                     use_xla=False):\n  \"\"\"Create a T2T Estimator.\"\"\"\n  model_fn = t2t_model.T2TModel.make_estimator_model_fn(\n      model_name, hparams, decode_hparams=decode_hparams, use_tpu=use_tpu)\n\n\n  del use_xla\n  if use_tpu or use_tpu_estimator:\n    problem = hparams.problem\n    batch_size = (\n        problem.tpu_batch_size_per_shard(hparams) *\n        run_config.tpu_config.num_shards)\n    mlperf_log.transformer_print(\n        key=mlperf_log.INPUT_BATCH_SIZE, value=batch_size)\n    if getattr(hparams, \"mtf_mode\", False):\n      batch_size = problem.tpu_batch_size_per_shard(hparams)\n    predict_batch_size = batch_size\n    if decode_hparams and decode_hparams.batch_size:\n      predict_batch_size = decode_hparams.batch_size\n    if decode_hparams and run_config.tpu_config:\n      decode_hparams.add_hparam(\"iterations_per_loop\",\n                                run_config.tpu_config.iterations_per_loop)\n    estimator = tf.contrib.tpu.TPUEstimator(\n        model_fn=model_fn,\n        model_dir=run_config.model_dir,\n        config=run_config,\n        use_tpu=use_tpu,\n        train_batch_size=batch_size,\n        eval_batch_size=batch_size if \"eval\" in schedule else None,\n        predict_batch_size=predict_batch_size,\n        experimental_export_device_assignment=True)\n  else:\n    estimator = tf.estimator.Estimator(\n        model_fn=model_fn,\n        model_dir=run_config.model_dir,\n        config=run_config,\n    )\n  return estimator", "response": "Create a T2T Estimator."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates train and eval hooks for Experiment.", "response": "def create_hooks(use_tfdbg=False,\n                 use_dbgprofile=False,\n                 dbgprofile_kwargs=None,\n                 use_validation_monitor=False,\n                 validation_monitor_kwargs=None,\n                 use_early_stopping=False,\n                 early_stopping_kwargs=None):\n  \"\"\"Create train and eval hooks for Experiment.\"\"\"\n  train_hooks = []\n  eval_hooks = []\n\n  if use_tfdbg:\n    hook = debug.LocalCLIDebugHook()\n    train_hooks.append(hook)\n    eval_hooks.append(hook)\n\n  if use_dbgprofile:\n    # Recorded traces can be visualized with chrome://tracing/\n    # The memory/tensor lifetime is also profiled\n    tf.logging.info(\"Using ProfilerHook\")\n    defaults = dict(save_steps=10, show_dataflow=True, show_memory=True)\n    defaults.update(dbgprofile_kwargs)\n    train_hooks.append(tf.train.ProfilerHook(**defaults))\n\n  if use_validation_monitor:\n    tf.logging.info(\"Using ValidationMonitor\")\n    train_hooks.append(\n        tf.contrib.learn.monitors.ValidationMonitor(\n            hooks=eval_hooks, **validation_monitor_kwargs))\n\n  if use_early_stopping:\n    tf.logging.info(\"Using EarlyStoppingHook\")\n    hook = metrics_hook.EarlyStoppingHook(**early_stopping_kwargs)\n    # Adding to both training and eval so that eval aborts as well\n    train_hooks.append(hook)\n    eval_hooks.append(hook)\n\n  return train_hooks, eval_hooks"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_experiment_fn(*args, **kwargs):\n\n  def experiment_fn(run_config, hparams):\n    return create_experiment(run_config, hparams, *args, **kwargs)\n\n  return experiment_fn", "response": "Wrapper for canonical experiment_fn. See create_experiment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrestore from a checkpoint.", "response": "def restore_checkpoint(ckpt_dir, saver, sess, must_restore=False):\n  \"\"\"Restore from a checkpoint.\"\"\"\n  ckpt = tf.train.get_checkpoint_state(ckpt_dir)\n  if must_restore and not ckpt:\n    raise ValueError(\"No checkpoint found in %s\" % ckpt_dir)\n  if not ckpt:\n    return 0\n\n  path = ckpt.model_checkpoint_path\n  tf.logging.info(\"Restoring checkpoint %s\", path)\n  saver.restore(sess, path)\n  step = int(path.split(\"-\")[-1])\n  return step"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef train_eval_and_decode(self):\n    eval_steps = self._hparams.eval_freq_in_steps\n    packed_dataset = \"_packed\" in self._hparams.problem.name\n    mlperf_log.transformer_print(key=mlperf_log.TRAIN_LOOP)\n    for i in range(0, self._train_spec.max_steps, eval_steps):\n      mlperf_log.transformer_print(\n          key=mlperf_log.TRAIN_EPOCH, value=i // eval_steps)\n      if packed_dataset and i > 0:\n        problem = registry.problem(self._hparams.problem.name + \"_packed\")\n        p_hparams = problem.get_hparams(self._hparams)\n        self._hparams.problem = problem\n        self._hparams.problem_hparams = p_hparams\n      self._estimator.train(\n          self._train_spec.input_fn,\n          steps=eval_steps,\n          hooks=self._train_spec.hooks)\n      self._set_eval_dir_name(\"eval\")\n      self._estimator.evaluate(\n          self._eval_spec.input_fn,\n          steps=self._eval_spec.steps,\n          hooks=self._eval_spec.hooks,\n          name=\"eval\")\n      if packed_dataset:\n        problem = registry.problem(\n            self._hparams.problem.name.replace(\"_packed\", \"\"))\n        p_hparams = problem.get_hparams(self._hparams)\n        self._hparams.problem = problem\n        self._hparams.problem_hparams = p_hparams\n      mlperf_log.transformer_print(key=mlperf_log.EVAL_START)\n      if self._hparams.mlperf_mode:\n        self._decode_hparams.mlperf_decode_step = i + eval_steps\n      self.decode(dataset_split=tf.estimator.ModeKeys.EVAL)\n      d_hparams = self._decode_hparams\n      if self._hparams.mlperf_mode and d_hparams.mlperf_success:\n        mlperf_log.transformer_print(\n            key=mlperf_log.RUN_STOP, value={\"success\": \"true\"})\n        break\n\n    d_hparams = self._decode_hparams\n    if self._hparams.mlperf_mode and not d_hparams.mlperf_success:\n      mlperf_log.transformer_print(\n          key=mlperf_log.RUN_STOP, value={\"success\": \"false\"})", "response": "Does eval and decode after training every eval_freq_in_steps."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef continuous_eval(self):\n    for ckpt_path in next_checkpoint(self._hparams.model_dir,\n                                     self._hparams.eval_timeout_mins):\n      # Skip zero'th step.\n      train_step = decoding.get_step_from_ckpt_path(ckpt_path)\n      if train_step == 0:\n        tf.logging.info(\"Skipping evaluation at step 0\")\n        continue\n      self.evaluate()", "response": "Evaluate until checkpoints stop being produced."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef continuous_eval_on_train_data(self):\n    for ckpt_path in next_checkpoint(self._hparams.model_dir,\n                                     self._hparams.eval_timeout_mins):\n      # Skip zero'th step.\n      train_step = decoding.get_step_from_ckpt_path(ckpt_path)\n      if train_step == 0:\n        tf.logging.info(\"Skipping evaluation at step 0\")\n        continue\n      self.evaluate_on_train_data()", "response": "Evaluate on train data until checkpoints stop being produced."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run_std_server(self):\n    config = tf.estimator.RunConfig()\n    server = tf.train.Server(\n        config.cluster_spec,\n        job_name=config.task_type,\n        task_index=config.task_id,\n        protocol=config.protocol)\n    server.join()", "response": "Starts a TensorFlow server and joins the serving thread."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndecode from dataset or file.", "response": "def decode(self,\n             dataset_split=None,\n             decode_from_file=False,\n             checkpoint_path=None):\n    \"\"\"Decodes from dataset or file.\"\"\"\n    if decode_from_file:\n      decoding.decode_from_file(self._estimator,\n                                self._decode_hparams.decode_from_file,\n                                self._hparams,\n                                self._decode_hparams,\n                                self._decode_hparams.decode_to_file)\n    else:\n      decoding.decode_from_dataset(\n          self._estimator,\n          self._hparams.problem.name,\n          self._hparams,\n          self._decode_hparams,\n          dataset_split=dataset_split,\n          checkpoint_path=checkpoint_path)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef continuous_decode(self):\n    for _ in next_checkpoint(self._hparams.model_dir,\n                             self._decode_hparams.decode_timeout_mins):\n      self.decode()", "response": "Decode from dataset on new checkpoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef continuous_decode_on_train_data(self):\n    for _ in next_checkpoint(self._hparams.model_dir,\n                             self._decode_hparams.decode_timeout_mins):\n      self.decode(dataset_split=tf.estimator.ModeKeys.TRAIN)", "response": "Decode from dataset on new checkpoint."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndecoding from dataset on new checkpoint.", "response": "def continuous_decode_on_eval_data(self):\n    \"\"\"Decode from dataset on new checkpoint.\"\"\"\n    if self._hparams.mlperf_mode:\n      ckpt_generator = next_undecoded_checkpoint(\n          self._hparams.model_dir, self._decode_hparams.decode_timeout_mins)\n    else:\n      ckpt_generator = next_checkpoint(self._hparams.model_dir,\n                                       self._decode_hparams.decode_timeout_mins)\n\n    for ckpt in ckpt_generator:\n      current_step = decoding.get_step_from_ckpt_path(ckpt)\n      tf.logging.info(\"Decoding step %d\" % current_step)\n      # Skip checkpoint 0.\n      if current_step == 0:\n        continue\n      # Decode the latest checkpoint by default.\n      checkpoint_path = None\n      if self._hparams.mlperf_mode:\n        self._decode_hparams.mlperf_decode_step = current_step\n        checkpoint_path = ckpt\n\n      mlperf_log.transformer_print(key=mlperf_log.EVAL_START)\n      self.decode(\n          dataset_split=tf.estimator.ModeKeys.EVAL,\n          checkpoint_path=checkpoint_path)\n      d_hparams = self._decode_hparams\n      if self._hparams.mlperf_mode and d_hparams.mlperf_success:\n        mlperf_log.transformer_print(\n            key=mlperf_log.RUN_STOP, value={\"success\": \"true\"})\n        break\n\n    d_hparams = self._decode_hparams\n    if self._hparams.mlperf_mode and not d_hparams.mlperf_success:\n      mlperf_log.transformer_print(\n          key=mlperf_log.RUN_STOP, value={\"success\": \"false\"})"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef continuous_decode_from_file(self):\n    for _ in next_checkpoint(self._hparams.model_dir,\n                             self._decode_hparams.decode_timeout_mins):\n      self.decode(decode_from_file=True)", "response": "Decode from file on new checkpoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _flatten_dict(original_dict):\n  flat_dict = {}\n  for key, value in original_dict.items():\n    if isinstance(value, dict):\n      for name, tensor in value.items():\n        if isinstance(tensor, dict):\n          raise ValueError(\"flatten_dict only handles 2 levels of nesting.\")\n        flat_key = \"__\" + key + \"_\" + name\n        flat_dict[flat_key] = tensor\n    else:\n      flat_dict[key] = value\n\n  return flat_dict", "response": "Flatten a dict of dicts into a single dict with appropriate prefixes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dict of dicts if any prefixes match keys in the flat dict. The function handles the case where the prefix may not be a dict. Args: flat_dict: A dict without any nesting. prefixes: A list of strings which may have been dicts in the original structure.", "response": "def _unflatten_dict(flat_dict, prefixes):\n  \"\"\"Returns a dict of dicts if any prefixes match keys in the flat dict.\n\n    The function handles the case where the prefix may not be a dict.\n\n  Args:\n    flat_dict: A dict without any nesting.\n    prefixes: A list of strings which may have been dicts in the\n      original structure.\n\n  \"\"\"\n  original_dict = {}\n  for key, value in flat_dict.items():\n    prefix_found = False\n    for prefix in prefixes:\n      full_prefix = \"__\" + prefix + \"_\"\n      if key.startswith(full_prefix):\n        # Add a dict to the original dict with key=prefix\n        if prefix not in original_dict:\n          original_dict[prefix] = {}\n        original_dict[prefix][key[len(full_prefix):]] = value\n        prefix_found = True\n        break\n    if not prefix_found:\n      # No key matched a prefix in the for loop.\n      original_dict[key] = value\n\n  return original_dict"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_tpu_eval_metrics_fn(problem, model_hparams):\n\n  metric_fns = []\n  eval_metrics = problem.eval_metric_fns(model_hparams)\n\n  tm = _create_target_modality(problem.get_hparams(model_hparams).modality)\n  if isinstance(tm, dict):\n    for k, v in six.iteritems(tm):\n      weights_fn = modalities.get_weights_fn(v)\n\n      def make_metric_fn(metric_fn):\n        def wrapped_metric_fn(logits, labels, features, weights_fn=weights_fn):\n          kwargs = {}\n          args, _, keywords, _ = inspect.getargspec(metric_fn)\n          if (\"features\" in args) or keywords:\n            kwargs[\"features\"] = features\n          num, den = metric_fn(logits, labels, weights_fn=weights_fn, **kwargs)\n          return tf.metrics.mean(num, den)\n\n        return wrapped_metric_fn\n\n      for metric, metric_fn in six.iteritems(eval_metrics):\n        if metric in TPU_METRIC_BLACKLIST:\n          log_warn(\"Skipping eval metric %s in TPU_METRIC_BLACKLIST\", metric)\n          continue\n        name = \"%s/metrics-%s/%s\" % (k, problem.name, metric)\n        metric_fns.append((name, make_metric_fn(metric_fn)))\n  else:\n    weights_fn = modalities.get_weights_fn(tm)\n\n    def make_metric_fn(metric_fn):\n      def wrapped_metric_fn(logits, labels, features):\n        kwargs = {}\n        args, _, keywords, _ = inspect.getargspec(metric_fn)\n        if (\"features\" in args) or keywords:\n          kwargs[\"features\"] = features\n        num, den = metric_fn(logits, labels, weights_fn=weights_fn, **kwargs)\n        return tf.metrics.mean(num, den)\n\n      return wrapped_metric_fn\n\n    for metric, metric_fn in six.iteritems(eval_metrics):\n      if metric in TPU_METRIC_BLACKLIST:\n        log_warn(\"Skipping eval metric %s in TPU_METRIC_BLACKLIST\", metric)\n        continue\n      name = \"metrics-%s/%s\" % (problem.name, metric)\n      metric_fns.append((name, make_metric_fn(metric_fn)))\n\n  def all_metrics_fn(**kwargs):\n    \"\"\"Construct metrics dictionary.\"\"\"\n\n    original_kwargs = _unflatten_dict(kwargs, prefixes=[\"logits\", \"features\"])\n    del kwargs\n\n    logits = original_kwargs[\"logits\"]\n    labels = original_kwargs[\"labels\"]\n    features = original_kwargs[\"features\"]\n    del original_kwargs\n\n    metrics_dict = {}\n\n    for name, fn in metric_fns:\n      if isinstance(logits, dict) and isinstance(labels, dict):\n        for k, v in six.iteritems(logits):\n          metrics_dict[\"%s/%s\" % (k, name)] = fn(v, labels[k], features)\n      elif isinstance(logits, dict):\n        tf.logging.warning(\"Logits is a dict, but labels is not; only \"\n                           \"evaluating logits['targets'] against labels.\")\n        metrics_dict[\"%s/%s\" % (\"targets\", name)] = fn(logits[\"targets\"],\n                                                       labels, features)\n      else:\n        metrics_dict[name] = fn(logits, labels, features)\n\n    return metrics_dict\n\n  return all_metrics_fn", "response": "Create the metrics_fn that TPUEstimatorSpec expects."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves summaries from the default graph.", "response": "def remove_summaries():\n  \"\"\"Remove summaries from the default graph.\"\"\"\n  g = tf.get_default_graph()\n  key = tf.GraphKeys.SUMMARIES\n  log_debug(\"Remove summaries %s\" % str(g.get_collection(key)))\n  del g.get_collection_ref(key)[:]\n  assert not g.get_collection(key)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconstructing a host_call writing scalar summaries.", "response": "def create_host_call(model_dir):\n  \"\"\"Construct a host_call writing scalar summaries.\n\n  Args:\n    model_dir: String containing path to train\n\n  Returns:\n    (fn, args) Pair to be called by TPUEstimator as the host_call.\n  \"\"\"\n  graph = tf.get_default_graph()\n  summaries = graph.get_collection(tf.GraphKeys.SUMMARIES)\n  gs_t = tf.reshape(tf.to_int32(tf.train.get_global_step()), [1])\n  summary_kwargs = collections.OrderedDict()\n  for t in summaries:\n    # TODO(aidangomez): enable ImageSummary support when we have a faster method\n    # see @shibow's comment in cl/202344570\n    if t.op.type not in [\"ScalarSummary\"]:\n      tf.logging.warn(\"Ignoring unsupported tf.Summary type %s\" % t.op.type)\n      continue\n\n    name = t.op.name\n    tensor = t.op.inputs[1]\n    if t.op.type == \"ScalarSummary\":\n      assert tensor.shape.is_compatible_with([])\n      if tensor.dtype == tf.int64:\n        tensor = tf.to_int32(tensor)\n      summary_kwargs[\"ScalarSummary\" + name] = tf.reshape(tensor, [1])\n    elif t.op.type == \"ImageSummary\":\n      # TODO(aidangomez): as we move to support more types, update\n      # common_layers.tpu_safe_image_summary\n      if tensor.dtype != tf.float32:\n        tf.logging.warn(\n            \"Currently T2T on TPU only supports ImageSummary of \"\n            \"tf.float32-type Tensors. Skipping Tensor \"\n            \"%s with dtype %s...\" % (tensor.name, tensor.dtype))\n        continue\n      # tensor = tf.to_float(tensor)\n      summary_kwargs[\"ImageSummary\" + name] = tensor\n  # When no supported summaries are found, don't create host_call. Otherwise,\n  # TPU outfeed queue would enqueue global_step while host_call doesn't dequeue\n  # it, eventually causing hang.\n  if not summary_kwargs:\n    return None\n  summary_kwargs[\"global_step\"] = gs_t\n  log_info(\"summary_kwargs %s\" % str(summary_kwargs))\n\n  def host_call_fn(**kwargs):\n    \"\"\"Training host call. Creates summaries for training metrics.\n\n    Args:\n      **kwargs: Dict of {str: Tensor} , with `Tensor` of shape `[batch]`. Must\n        contain key \"global_step\" with value of current global_step Tensor.\n\n    Returns:\n      List of summary ops to run on the CPU host.\n    \"\"\"\n    gs = tf.to_int64(kwargs.pop(\"global_step\")[0])\n    with tf.contrib.summary.create_file_writer(model_dir).as_default():\n      with tf.contrib.summary.always_record_summaries():\n        # We need to use tf.contrib.summary in order to feed the `step`.\n        for name, value in sorted(six.iteritems(kwargs)):\n          if name.startswith(\"ScalarSummary\"):\n            name = name[len(\"ScalarSummary\"):]\n            tf.contrib.summary.scalar(\n                name, tf.reduce_mean(tf.to_float(value)), step=gs)\n          elif name.startswith(\"ImageSummary\"):\n            name = name[len(\"ImageSummary\"):]\n            tf.contrib.summary.image(name, value, step=gs)\n\n        return tf.contrib.summary.all_summary_ops()\n\n  return (host_call_fn, summary_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\naverages losses across datashards.", "response": "def average_sharded_losses(sharded_losses):\n  \"\"\"Average losses across datashards.\n\n  Args:\n    sharded_losses: list<dict<str loss_name, Tensor loss>>. The loss\n      can be a single Tensor or a 2-tuple (numerator and denominator).\n\n  Returns:\n    losses: dict<str loss_name, Tensor avg_loss>\n  \"\"\"\n  losses = {}\n  for loss_name in sorted(sharded_losses[0]):\n    all_shards = [shard_losses[loss_name] for shard_losses in sharded_losses]\n    if isinstance(all_shards[0], tuple):\n      sharded_num, sharded_den = zip(*all_shards)\n      mean_loss = (\n          tf.add_n(sharded_num) / tf.maximum(\n              tf.cast(1.0, sharded_den[0].dtype), tf.add_n(sharded_den)))\n    else:\n      mean_loss = tf.reduce_mean(all_shards)\n\n    losses[loss_name] = mean_loss\n  return losses"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates summaries for features.", "response": "def summarize_features(features, num_shards=1):\n  \"\"\"Generate summaries for features.\"\"\"\n  if not common_layers.should_generate_summaries():\n    return\n\n  with tf.name_scope(\"input_stats\"):\n    for (k, v) in sorted(six.iteritems(features)):\n      if (isinstance(v, tf.Tensor) and (v.get_shape().ndims > 1) and\n          (v.dtype != tf.string)):\n        tf.summary.scalar(\"%s_batch\" % k, tf.shape(v)[0] // num_shards)\n        tf.summary.scalar(\"%s_length\" % k, tf.shape(v)[1])\n        nonpadding = tf.to_float(tf.not_equal(v, 0))\n        nonpadding_tokens = tf.reduce_sum(nonpadding)\n        tf.summary.scalar(\"%s_nonpadding_tokens\" % k, nonpadding_tokens)\n        tf.summary.scalar(\"%s_nonpadding_fraction\" % k,\n                          tf.reduce_mean(nonpadding))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _compose_custom_getters(getter_a, getter_b):\n  if not getter_a:\n    return getter_b\n  if not getter_b:\n    return getter_a\n\n  def getter_fn(getter, *args, **kwargs):\n    return getter_b(functools.partial(getter_a, getter), *args, **kwargs)\n\n  return getter_fn", "response": "Compose two custom getters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting a custom getter in the current variable scope.", "response": "def set_custom_getter_compose(custom_getter):\n  \"\"\"Set a custom getter in the current variable scope.\n\n  Do not overwrite the existing custom getter - rather compose with it.\n\n  Args:\n    custom_getter: a custom getter.\n  \"\"\"\n  tf.get_variable_scope().set_custom_getter(\n      _compose_custom_getters(tf.get_variable_scope().custom_getter,\n                              custom_getter))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing variables from given directory.", "response": "def initialize_from_ckpt(ckpt_dir, hparams):\n  \"\"\"Initialize variables from given directory.\"\"\"\n  model_dir = hparams.get(\"model_dir\", None)\n  already_has_ckpt = (\n      model_dir and tf.train.latest_checkpoint(model_dir) is not None)\n  if already_has_ckpt:\n    return\n\n  tf.logging.info(\"Checkpoint dir: %s\", ckpt_dir)\n  reader = tf.contrib.framework.load_checkpoint(ckpt_dir)\n  variable_map = {}\n  for var in tf.contrib.framework.get_trainable_variables():\n    var_name = var.name.split(\":\")[0]\n    if reader.has_tensor(var_name):\n      tf.logging.info(\"Loading variable from checkpoint: %s\", var_name)\n      variable_map[var_name] = var\n    else:\n      tf.logging.info(\"Cannot find variable in checkpoint, skipping: %s\",\n                      var_name)\n  tf.train.init_from_checkpoint(ckpt_dir, variable_map)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _target_modality_is_real(self):\n    vocab_size = self._problem_hparams.vocab_size[\"targets\"]\n    if vocab_size is not None and hasattr(self._hparams, \"vocab_divisor\"):\n      vocab_size += (-vocab_size) % self._hparams.vocab_divisor\n    modality = self._problem_hparams.modality[\"targets\"]\n    modality_name = self._hparams.name.get(\n        \"targets\",\n        modalities.get_name(modality))(self._hparams, vocab_size)\n    return modality_name.startswith(\"real\")", "response": "Whether the target modality is real - valued."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bottom(self, features):\n    if not self._problem_hparams:\n      log_warn(\"Without a Problem, T2TModel.bottom is a passthrough.\")\n      return features\n\n    transformed_features = collections.OrderedDict()\n    all_previous_modalities = []\n    target_modality = _create_target_modality(self._problem_hparams.modality)\n\n    # Transform features via its corresponding modality.\n    for feature_name, modality in sorted(\n        six.iteritems(self._problem_hparams.modality)):\n      if feature_name not in features:\n        tf.logging.warning(\"Missing feature %s - ignoring.\" % feature_name)\n        continue\n      vocab_size = self._problem_hparams.vocab_size[feature_name]\n      if vocab_size is not None and hasattr(self._hparams, \"vocab_divisor\"):\n        vocab_size += (-vocab_size) % self._hparams.vocab_divisor\n      modality_name = self._hparams.name.get(\n          feature_name,\n          modalities.get_name(modality))(self._hparams, vocab_size)\n      # Use if-else clauses to preserve behavior of previous changes: namely,\n      # the variable scope name for the targets feature if there is only one\n      # target modality; and to reuse variable scopes for only input modalities.\n      if feature_name in target_modality:\n        if len(target_modality) > 1:\n          variable_scope_name = \"%s/%s\" % (modality_name, feature_name)\n        else:\n          variable_scope_name = modality_name\n        bottom = self._hparams.bottom.get(\n            feature_name,\n            modalities.get_targets_bottom(modality))\n        # TODO(aidangomez): share variables?\n        with tf.variable_scope(variable_scope_name) as vs:\n          self._add_variable_scope(variable_scope_name, vs)\n          log_info(\"Transforming feature '%s' with %s.targets_bottom\",\n                   feature_name,\n                   modality_name)\n          transformed_features[feature_name] = bottom(features[feature_name],\n                                                      self._hparams,\n                                                      vocab_size)\n      else:\n        bottom = self._hparams.bottom.get(feature_name,\n                                          modalities.get_bottom(modality))\n        do_reuse = modality_name in all_previous_modalities\n        with tf.variable_scope(modality_name, reuse=do_reuse) as vs:\n          self._add_variable_scope(modality_name, vs)\n          log_info(\"Transforming feature '%s' with %s.bottom\",\n                   feature_name,\n                   modality_name)\n          transformed_features[feature_name] = bottom(features[feature_name],\n                                                      self._hparams,\n                                                      vocab_size)\n        all_previous_modalities.append(modality_name)\n\n    for key in features:\n      if key not in transformed_features:\n        # For features without a modality, we pass them along as is\n        transformed_features[key] = features[key]\n      else:\n        # Other features get passed along with the \"raw\" suffix\n        transformed_features[key + \"_raw\"] = features[key]\n\n    return transformed_features", "response": "Transforms features to feed into body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef top(self, body_output, features):\n    if isinstance(body_output, dict):\n      logits = {}\n      for k, v in six.iteritems(body_output):\n        # TODO(aidangomez): share variables here?\n        with tf.variable_scope(k) as top_vs:\n          self._add_variable_scope(\"top_%s\" % k, top_vs)\n          logits[k] = self._top_single(v, k, features)\n      return logits\n    else:\n      return self._top_single(body_output, \"targets\", features)", "response": "Computes logits given body output and features."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a training op minimizing loss.", "response": "def optimize(self, loss, num_async_replicas=1, use_tpu=False):\n    \"\"\"Return a training op minimizing loss.\"\"\"\n    lr = learning_rate.learning_rate_schedule(self.hparams)\n    if num_async_replicas > 1:\n      log_info(\"Dividing learning rate by num_async_replicas: %d\",\n               num_async_replicas)\n    lr /= math.sqrt(float(num_async_replicas))\n    train_op = optimize.optimize(loss, lr, self.hparams, use_tpu=use_tpu)\n    return train_op"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting hparams with the given mode.", "response": "def set_mode(self, mode):\n    \"\"\"Set hparams with the given mode.\"\"\"\n    log_info(\"Setting T2TModel mode to '%s'\", mode)\n    hparams = hparams_lib.copy_hparams(self._original_hparams)\n    hparams.add_hparam(\"mode\", mode)\n    # When not in training mode, set all forms of dropout to zero.\n    if mode != tf.estimator.ModeKeys.TRAIN:\n      for key in hparams.values():\n        if key.endswith(\"dropout\") or key == \"label_smoothing\":\n          log_info(\"Setting hparams.%s to 0.0\", key)\n          setattr(hparams, key, 0.0)\n    self._hparams = hparams"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef infer(self,\n            features=None,\n            decode_length=50,\n            beam_size=1,\n            top_beams=1,\n            alpha=0.0,\n            use_tpu=False):\n    \"\"\"A inference method.\n\n    Quadratic time in decode_length.\n\n    Args:\n      features: an map of string to `Tensor`\n      decode_length: an integer.  How many additional timesteps to decode.\n      beam_size: number of beams.\n      top_beams: an integer. How many of the beams to return.\n      alpha: Float that controls the length penalty. larger the alpha, stronger\n        the preference for longer translations.\n      use_tpu: bool, whether to build the inference graph for TPU.\n\n    Returns:\n      A dict of decoding results {\n          \"outputs\": integer `Tensor` of decoded ids of shape\n              [batch_size, <= decode_length] if beam_size == 1 or\n              [batch_size, top_beams, <= decode_length]\n          \"scores\": decoding log probs from the beam search,\n              None if using greedy decoding (beam_size=1)\n      }\n      if slow greedy decoding is used then the dict will also contain {\n          \"logits\": `Tensor` of shape [batch_size, time, 1, 1, vocab_size].\n          \"losses\": a dictionary: {loss-name (string): floating point `Scalar`\n      }\n    \"\"\"\n    set_custom_getter_compose(self._custom_getter)\n    with self._eager_var_store.as_default():\n      # TODO(rsepassi): Make decoding work with real-valued model outputs\n      # (i.e. if the target modality is RealModality).\n      self.prepare_features_for_infer(features)\n      if not self.has_input and beam_size > 1:\n        log_warn(\"Beam searching for a model with no inputs.\")\n      if not self.has_input and self.hparams.sampling_method != \"random\":\n        log_warn(\"Non-random sampling for a model with no inputs.\")\n      self._fill_problem_hparams_features(features)\n\n      if self._problem_hparams:\n        target_modality = self._problem_hparams.modality[\"targets\"]\n        if target_modality == modalities.ModalityType.CLASS_LABEL:\n          beam_size = 1  # No use to run beam-search for a single class.\n      if beam_size == 1:\n        log_info(\"Greedy Decoding\")\n        results = self._greedy_infer(features, decode_length, use_tpu)\n      else:\n        log_info(\"Beam Decoding with beam size %d\" % beam_size)\n        results = self._beam_decode(features, decode_length, beam_size,\n                                    top_beams, alpha, use_tpu)\n\n      return results", "response": "A method that performs the inference of the model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbeaming search decoding. Models should ideally implement a more efficient version of this function. Args: features: an map of string to `Tensor` decode_length: an integer. How many additional timesteps to decode. beam_size: number of beams. top_beams: an integer. How many of the beams to return. alpha: Float that controls the length penalty. larger the alpha, stronger the preference for longer translations. use_tpu: A bool, whether to do beam decode on TPU. Returns: samples: an integer `Tensor`. Top samples from the beam search", "response": "def _beam_decode(self,\n                   features,\n                   decode_length,\n                   beam_size,\n                   top_beams,\n                   alpha,\n                   use_tpu=False):\n    \"\"\"Beam search decoding.\n\n    Models should ideally implement a more efficient version of this function.\n\n    Args:\n      features: an map of string to `Tensor`\n      decode_length: an integer.  How many additional timesteps to decode.\n      beam_size: number of beams.\n      top_beams: an integer. How many of the beams to return.\n      alpha: Float that controls the length penalty. larger the alpha, stronger\n        the preference for longer translations.\n      use_tpu: A bool, whether to do beam decode on TPU.\n\n    Returns:\n       samples: an integer `Tensor`. Top samples from the beam search\n    \"\"\"\n    return self._beam_decode_slow(features, decode_length, beam_size, top_beams,\n                                  alpha, use_tpu)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nslowing version of Beam search decoding.", "response": "def _beam_decode_slow(self, features, decode_length, beam_size, top_beams,\n                        alpha, use_tpu=False):\n    \"\"\"Slow version of Beam search decoding.\n\n    Quadratic time in decode_length.\n\n    Args:\n      features: an map of string to `Tensor`\n      decode_length: an integer.  How many additional timesteps to decode.\n      beam_size: number of beams.\n      top_beams: an integer. How many of the beams to return.\n      alpha: Float that controls the length penalty. larger the alpha, stronger\n        the preference for longer translations.\n      use_tpu: A bool, whether to do slow beam decode on TPU.\n\n    Returns:\n      samples: an integer `Tensor`. Top samples from the beam search.\n\n    Raises:\n      NotImplementedError: If use_tpu is set to true.\n    \"\"\"\n    batch_size = common_layers.shape_list(features[\"inputs\"])[0]\n\n    def symbols_to_logits_fn(ids, i=None):\n      \"\"\"Go from ids to logits.\"\"\"\n      ids = tf.expand_dims(tf.expand_dims(ids, axis=2), axis=3)\n      ids = tf.pad(ids[:, 1:], [[0, 0], [0, 1], [0, 0], [0, 0]])\n      if \"partial_targets\" in features:\n        pt = features[\"partial_targets\"]\n        pt_length = common_layers.shape_list(pt)[1]\n        pt = tf.tile(pt, [1, beam_size])\n        pt = tf.reshape(pt, [batch_size * beam_size, pt_length, 1, 1])\n        ids = tf.concat([pt, ids], axis=1)\n\n      features[\"targets\"] = ids\n      if i is not None:\n        features[\"decode_loop_step\"] = i\n      self._coverage = None\n      logits, _ = self(features)  # pylint: disable=not-callable\n      # now self._coverage is a coverage tensor for the first datashard.\n      # it has shape [batch_size] and contains floats between 0 and\n      # source_length.\n      if self._problem_hparams:\n        modality = self._problem_hparams.modality[\"targets\"]\n        top = self._hparams.top.get(\"targets\", modalities.get_top(modality))\n        if getattr(top, \"pointwise\", False):\n          return tf.squeeze(logits, axis=[1, 2, 3])\n      # -1 due to the pad above.\n      current_output_position = common_layers.shape_list(ids)[1] - 1\n      logits = logits[:, current_output_position, :, :]\n      return tf.squeeze(logits, axis=[1, 2])\n\n    def _clone_examples_for_beam(old_feature, n):\n      \"\"\"Clone each example n times.\"\"\"\n      old_shape = common_layers.shape_list(old_feature)\n      assert len(old_shape) >= 1\n\n      # Expand the inputs in to the beam size.\n      feature = tf.expand_dims(old_feature, 1)\n      feature = tf.tile(feature, [1, n] + [1] * (len(old_shape) - 1))\n      new_shape = common_layers.shape_list(feature)\n      feature = tf.reshape(feature,\n                           [new_shape[0] * new_shape[1]] + new_shape[2:])\n      return feature\n\n    initial_ids = tf.zeros([batch_size], dtype=tf.int32)\n\n    # Clone select features multiple times to account for beam size.\n    old_features = {}\n    for feature_name in [\"inputs\", \"knowledge\"]:\n      if feature_name not in features:\n        continue\n      old_features[feature_name] = features[feature_name]\n      features[feature_name] = _clone_examples_for_beam(\n          features[feature_name], beam_size)\n\n    vocab_size = self._problem_hparams.vocab_size[\"targets\"]\n    if vocab_size is not None and hasattr(self._hparams, \"vocab_divisor\"):\n      vocab_size += (-vocab_size) % self._hparams.vocab_divisor\n\n    # Setting decode length to input length + decode_length\n    if \"partial_targets\" not in features:\n      inputs = features[\"inputs\"]\n      decode_length = (common_layers.shape_list(inputs)[1] +\n                       features.get(\"decode_length\", decode_length))\n    ids, scores, _ = beam_search.beam_search(\n        symbols_to_logits_fn,\n        initial_ids,\n        beam_size,\n        decode_length,\n        vocab_size,\n        alpha,\n        stop_early=(top_beams == 1),\n        use_tpu=use_tpu)\n\n    # Set features back to the unexpanded form to not to confuse the\n    # Estimator!\n    features.update(old_features)\n\n    # Return `top_beams` decodings (also remove initial id from the beam search)\n    # TODO(lukaszkaiser): make it work multi-problem.\n    if top_beams == 1:\n      samples = ids[:, 0, 1:]\n    else:\n      samples = ids[:, :top_beams, 1:]\n\n    return {\"outputs\": samples, \"scores\": scores}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _slow_greedy_infer_tpu(self, features, decode_length):\n    if not features:\n      features = {}\n    inputs_old = None\n    if \"inputs\" in features and len(features[\"inputs\"].shape) < 4:\n      inputs_old = features[\"inputs\"]\n      features[\"inputs\"] = tf.expand_dims(features[\"inputs\"], 2)\n    if not self.has_input:\n      # Prepare partial targets.\n      # In either features[\"inputs\"] or features[\"targets\"].\n      # We force the outputs to begin with these sequences.\n      partial_targets = features.get(\"inputs\")\n      if partial_targets is None:\n        partial_targets = features[\"targets\"]\n      features[\"partial_targets\"] = tf.to_int64(partial_targets)\n    # Save the targets in a var and reassign it after the tf.while loop to avoid\n    # having targets being in a 'while' frame. This ensures targets when used\n    # in metric functions stays in the same frame as other vars.\n    targets_old = features.get(\"targets\", None)\n\n    target_modality = self._problem_hparams.modality[\"targets\"]\n\n    def infer_step(i, recent_output, recent_logits, unused_loss):\n      \"\"\"Inference step.\"\"\"\n      if not tf.executing_eagerly():\n        recent_output.set_shape([None, None, None, 1])\n      padded = tf.pad(recent_output, [[0, 0], [0, 1], [0, 0], [0, 0]])\n      features[\"targets\"] = padded\n      # This is inefficient in that it generates samples at all timesteps,\n      # not just the last one, except if target_modality is pointwise.\n      features[\"decode_loop_step\"] = i\n      samples, logits, losses = self.sample(features)\n      # Concatenate the already-generated recent_output with last timestep\n      # of the newly-generated samples.z\n      top = self._hparams.top.get(\"targets\",\n                                  modalities.get_top(target_modality))\n      if getattr(top, \"pointwise\", False):\n        cur_sample = samples[:, -1, :, :]\n      else:\n        cur_sample = samples[:, i, :, :]\n      samples = tf.transpose(recent_output, perm=[1, 0, 2, 3])\n      samples = inplace_ops.alias_inplace_update(samples, i,\n                                                 tf.to_int64(cur_sample))\n      samples = tf.transpose(samples, perm=[1, 0, 2, 3])\n      if not tf.executing_eagerly():\n        samples.set_shape([None, None, None, 1])\n\n      # Assuming we have one shard for logits.\n      recent_logits = tf.transpose(recent_logits, perm=[1, 0, 2, 3, 4])\n      recent_logits = inplace_ops.alias_inplace_update(\n          recent_logits, i, tf.squeeze(logits[:, -1:], axis=1))\n      logits = tf.transpose(recent_logits, perm=[1, 0, 2, 3, 4])\n      loss = sum([l for l in losses.values() if l is not None])\n      return i + 1, samples, logits, loss\n\n    # Create an initial output tensor. This will be passed\n    # to the infer_step, which adds one timestep at every iteration.\n    if \"partial_targets\" in features:\n      initial_output = tf.to_int64(features[\"partial_targets\"])\n      while len(initial_output.get_shape().as_list()) < 4:\n        initial_output = tf.expand_dims(initial_output, 2)\n      batch_size = common_layers.shape_list(initial_output)[0]\n    else:\n      batch_size = common_layers.shape_list(features[\"inputs\"])[0]\n      initial_output = tf.zeros((batch_size, 0, 1, 1), dtype=tf.int64)\n    # Hack: foldl complains when the output shape is less specified than the\n    # input shape, so we confuse it about the input shape.\n    initial_output = tf.slice(initial_output, [0, 0, 0, 0],\n                              common_layers.shape_list(initial_output))\n    target_modality = self._problem_hparams.modality[\"targets\"]\n    if target_modality == modalities.ModalityType.CLASS_LABEL:\n      decode_length = 1\n    else:\n      if \"partial_targets\" in features:\n        prefix_length = common_layers.shape_list(features[\"partial_targets\"])[1]\n      else:\n        prefix_length = common_layers.shape_list(features[\"inputs\"])[1]\n      decode_length = prefix_length + decode_length\n\n    # Initial values of result, logits and loss.\n    result = tf.concat(\n        [initial_output,\n         tf.zeros([batch_size, decode_length, 1, 1], tf.int64)],\n        axis=1)\n    # tensor padded to [batch_size, decode_length, 1, 1, vocab_size]\n    vocab_size = self._problem_hparams.vocab_size[\"targets\"]\n    if vocab_size is not None and hasattr(self._hparams, \"vocab_divisor\"):\n      vocab_size += (-vocab_size) % self._hparams.vocab_divisor\n    logits = tf.zeros((batch_size, decode_length, 1, 1, vocab_size))\n    if not tf.executing_eagerly():\n      logits.set_shape([None, None, None, None, None])\n    loss = 0.0\n\n    def while_exit_cond(i, result, logits, loss):  # pylint: disable=unused-argument\n      \"\"\"Exit the loop either if reach decode_length or EOS.\"\"\"\n      not_overflow = i < decode_length\n\n      if self._problem_hparams.stop_at_eos:\n\n        def fn_not_eos():\n          # Check if the last predicted element is a EOS\n          return tf.reduce_any(\n              tf.not_equal(\n                  tf.squeeze(result[:, -1, :, :]), text_encoder.EOS_ID))\n\n        not_eos = tf.cond(\n            # We only check for early stopping if there is at least 1 element (\n            # otherwise not_eos will crash).\n            tf.not_equal(i, 0),\n            fn_not_eos,\n            lambda: True,\n        )\n\n        return tf.cond(\n            tf.equal(batch_size, 1),\n            # If batch_size == 1, we check EOS for early stopping.\n            lambda: tf.logical_and(not_overflow, not_eos),\n            # Else, just wait for max length\n            lambda: not_overflow)\n      return not_overflow\n\n    _, result, logits, loss = tf.while_loop(\n        while_exit_cond,\n        infer_step, [tf.constant(0), result, logits, loss],\n        shape_invariants=[\n            tf.TensorShape([]),\n            tf.TensorShape([batch_size, decode_length, 1, 1]),\n            tf.TensorShape([batch_size, decode_length, 1, 1, vocab_size]),\n            tf.TensorShape([]),\n        ],\n        back_prop=False,\n        parallel_iterations=1)\n    if inputs_old is not None:  # Restore to not confuse Estimator.\n      features[\"inputs\"] = inputs_old\n    # Reassign targets back to the previous value.\n    if targets_old is not None:\n      features[\"targets\"] = targets_old\n    losses = {\"training\": loss}\n    if \"partial_targets\" in features:\n      partial_target_length = common_layers.shape_list(\n          features[\"partial_targets\"])[1]\n      result = tf.slice(result, [0, partial_target_length, 0, 0],\n                        [-1, -1, -1, -1])\n    return {\n        \"outputs\": result,\n        \"scores\": None,\n        \"logits\": logits,\n        \"losses\": losses,\n    }", "response": "A slow greedy inference method on TPU."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun the model and extract samples.", "response": "def sample(self, features):\n    \"\"\"Run the model and extract samples.\n\n    Args:\n      features: an map of string to `Tensor`.\n\n    Returns:\n       samples: an integer `Tensor`.\n       logits: a list of `Tensor`s, one per datashard.\n       losses: a dictionary: {loss-name (string): floating point `Scalar`}.\n    \"\"\"\n    logits, losses = self(features)  # pylint: disable=not-callable\n    if self._target_modality_is_real:\n      return logits, logits, losses  # Raw numbers returned from real modality.\n    if self.hparams.sampling_method == \"argmax\":\n      samples = tf.argmax(logits, axis=-1)\n    else:\n      assert self.hparams.sampling_method == \"random\"\n\n      def multinomial_squeeze(logits, temperature=1.0):\n        logits_shape = common_layers.shape_list(logits)\n        reshaped_logits = (\n            tf.reshape(logits, [-1, logits_shape[-1]]) / temperature)\n        choices = tf.multinomial(reshaped_logits, 1)\n        choices = tf.reshape(choices, logits_shape[:-1])\n        return choices\n\n      samples = multinomial_squeeze(logits, self.hparams.sampling_temp)\n\n    return samples, logits, losses"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef estimator_model_fn(cls,\n                         hparams,\n                         features,\n                         labels,\n                         mode,\n                         config=None,\n                         params=None,\n                         decode_hparams=None,\n                         use_tpu=False):\n    \"\"\"Model fn for Estimator.\n\n    Args:\n      hparams: HParams, model hyperparameters\n      features: dict<str name, Tensor feature>\n      labels: Tensor\n      mode: tf.estimator.ModeKeys\n      config: RunConfig, possibly with data_parallelism attribute\n      params: dict, may include batch_size, use_tpu\n      decode_hparams: HParams, used when mode == PREDICT.\n      use_tpu: A bool, whether to build the inference graph for TPU.\n\n    Returns:\n      TPUEstimatorSpec if use tpu else EstimatorSpec\n    \"\"\"\n    if mode == tf.estimator.ModeKeys.TRAIN:\n      create_dummy_vars()\n    hparams = hparams_lib.copy_hparams(hparams)\n\n    # Instantiate model\n    data_parallelism = None\n    if not use_tpu and config:\n      data_parallelism = config.data_parallelism\n    reuse = tf.get_variable_scope().reuse\n    model = cls(\n        hparams,\n        mode,\n        data_parallelism=data_parallelism,\n        decode_hparams=decode_hparams,\n        _reuse=reuse)\n\n    # PREDICT mode\n    if mode == tf.estimator.ModeKeys.PREDICT:\n      if use_tpu:\n        inputs = features.get(\"inputs\")\n        if inputs is None:\n          inputs = features[\"targets\"]\n        shape = inputs.get_shape().as_list()\n        if shape[0] is None:\n          shape[0] = decode_hparams.batch_size or hparams.batch_size\n        if shape[1] is None:\n          shape[1] = hparams.max_input_seq_length or hparams.max_length\n        inputs.set_shape(shape)\n      return model.estimator_spec_predict(features, use_tpu=use_tpu)\n\n    # TRAIN and EVAL modes\n    if hparams.eval_run_autoregressive and mode == tf.estimator.ModeKeys.EVAL:\n      logits, losses_dict = model.eval_autoregressive(features)\n    else:\n      logits, losses_dict = model(features)  # pylint: disable=not-callable\n\n    # Support model-generated labels by overriding features[\"targets\"] with\n    # logits[\"self_generated_targets\"].\n    if isinstance(logits, dict) and \"self_generated_targets\" in logits:\n      # Overwrite 'features[\"targets\"]' and 'labels'\n      # by logits[\"self_generated_targets\"].\n      tf.logging.info(\"Replacing targets with model-provided targets.\")\n      features[\"targets\"] = labels = logits.pop(\"self_generated_targets\")\n      assert list(logits.keys()) == [\"logits\"], (\n          # See \"Returns\" in the \"top\" method docstring for the expected\n          # \"logits\" format when targets are generated at training time.\n          \"Expect only key 'logits' when there is 'self_generated_targets'. \"\n          \"Found {}\".format(logits.keys())\n      )\n      # Recover the original logits tensor from the logits dict.\n      logits = logits[\"logits\"]  # Can be a tf.Tensor or a dict.\n\n    # Set known shapes\n    if common_layers.is_xla_compiled():\n      if isinstance(logits, dict):\n        for k, v in sorted(six.iteritems(logits)):\n          if \"scalar/\" in k:\n            continue\n\n          shape = v.get_shape().as_list()\n          if shape[0] is None:\n            shape[0] = params[\"batch_size\"]\n          if shape[1] is None:\n            shape[1] = hparams.max_length\n          v.set_shape(shape)\n      else:\n        shape = logits.get_shape().as_list()\n        if shape[0] is None:\n          shape[0] = params[\"batch_size\"]\n        if shape[1] is None:\n          shape[1] = hparams.max_length\n        logits.set_shape(shape)\n\n    assert \"training\" in losses_dict\n\n    # Attack mode\n    if mode == \"attack\":\n      return logits\n\n    # Summarize losses\n    model._summarize_losses(losses_dict)  # pylint: disable=protected-access\n\n    # Accumulate losses\n    loss = sum(losses_dict[key] for key in sorted(losses_dict.keys()))\n\n    # EVAL mode\n    if mode == tf.estimator.ModeKeys.EVAL:\n      return model.estimator_spec_eval(features, logits, labels, loss,\n                                       losses_dict)\n\n    # TRAIN mode\n    assert mode == tf.estimator.ModeKeys.TRAIN\n    num_async_replicas = 1\n    if config and not use_tpu:\n      num_async_replicas = config.t2t_device_info[\"num_async_replicas\"]\n    return model.estimator_spec_train(\n        loss, num_async_replicas=num_async_replicas, use_tpu=use_tpu)", "response": "Model fn for training and evaluation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef estimator_spec_train(self, loss, num_async_replicas=1, use_tpu=False):\n    train_op = self.optimize(loss, num_async_replicas=num_async_replicas,\n                             use_tpu=use_tpu)\n\n    if use_tpu:\n      if self._hparams.warm_start_from:\n        def scaffold_fn():\n          self.initialize_from_ckpt(self._hparams.warm_start_from)\n          return tf.train.Scaffold()\n      else:\n        scaffold_fn = None\n\n      # Note: important to call this before remove_summaries()\n      if self.hparams.tpu_enable_host_call:\n        host_call = self.create_train_host_call()\n      else:\n        host_call = None\n\n      remove_summaries()\n\n      return tf.contrib.tpu.TPUEstimatorSpec(\n          tf.estimator.ModeKeys.TRAIN,\n          loss=loss,\n          train_op=train_op,\n          host_call=host_call,\n          scaffold_fn=scaffold_fn)\n    else:\n      if self._hparams.warm_start_from:\n        self.initialize_from_ckpt(self._hparams.warm_start_from)\n\n      # When loading weights from a pre-trained model, you want to be able to\n      # load separate weights into the encoder and decoder.\n      if self._hparams.warm_start_from_second:\n        self.initialize_from_ckpt(self._hparams.warm_start_from_second)\n\n      return tf.estimator.EstimatorSpec(\n          tf.estimator.ModeKeys.TRAIN, loss=loss, train_op=train_op)", "response": "Constructs an estimator. EstimatorSpec for training mode."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconstruct an estimator. EstimatorSpec for EVAL mode.", "response": "def estimator_spec_eval(self, features, logits, labels, loss, losses_dict):\n    \"\"\"Constructs `tf.estimator.EstimatorSpec` for EVAL (evaluation) mode.\"\"\"\n    del losses_dict\n    hparams = self.hparams\n\n    if not hasattr(hparams, \"problem\"):\n      raise NotImplementedError(_no_problem_err(\"estimator_spec_eval\"))\n\n    problem = hparams.problem\n\n    if common_layers.is_xla_compiled():\n      # Note: important to call this before remove_summaries()\n      if self.hparams.tpu_enable_host_call:\n        host_call = self.create_eval_host_call()\n      else:\n        host_call = None\n\n      remove_summaries()\n\n      eval_metrics_fn = create_tpu_eval_metrics_fn(problem, hparams)\n\n      batch_size = [feature.shape.as_list()[0] for _, feature\n                    in features.items() if feature.shape.ndims][0]\n\n      # Add batch dimension to all features since tpu requires the batch\n      # dimension on all tensors.\n      for name, feature in features.items():\n        if not feature.shape.as_list():\n          # All features must have a batch dimension\n          feature = tf.tile(tf.expand_dims(feature, 0), [batch_size])\n        features[name] = feature\n\n      eval_metrics_fn_args = dict(\n          logits=logits,  # possibly a dict\n          labels=labels,\n          features=features,  # dict\n      )\n\n      eval_metrics_fn_flat_args = _flatten_dict(eval_metrics_fn_args)\n      return tf.contrib.tpu.TPUEstimatorSpec(\n          tf.estimator.ModeKeys.EVAL,\n          eval_metrics=(eval_metrics_fn, eval_metrics_fn_flat_args),\n          host_call=host_call,\n          loss=loss)\n    else:\n      task_list = [problem]\n      if hasattr(problem, \"task_list\"):\n        task_list = problem.task_list\n\n      eval_metrics_fns = metrics.create_evaluation_metrics(task_list, hparams)\n      eval_metrics = {}\n      for metric_name, metric_fn in six.iteritems(eval_metrics_fns):\n        if isinstance(logits, dict):\n          # the key is located in the center of metric_name: \"metrics-%s/%s/%s\"\n          k = metric_name.split(\"/\")[1]\n          if k in logits:\n            eval_metrics[metric_name] = metric_fn(logits[k], features,\n                                                  features[k])\n          else:\n            # We do not make it an error because we sometimes run models that\n            # predict only parts of the targets defined by the Problem class.\n            # For example, an autoencoder or pure-video model can run on a gym\n            # problem even if another model is also predicting other things,\n            # like actions or rewards.\n            tf.logging.warning(\"No key %s in logits for evaluation.\" % k)\n        else:\n          eval_metrics[metric_name] = metric_fn(logits, features,\n                                                features[\"targets\"])\n      if isinstance(logits, dict):\n        predictions = logits\n      else:\n        predictions = {\"predictions\": logits}\n\n      evaluation_hooks = []\n      # Create a SummarySaverHook\n      eval_dir = os.path.join(\n          self.hparams.model_dir,\n          self.hparams.get(\"eval_dir_name\", \"eval\"))\n      eval_summary_hook = tf.train.SummarySaverHook(\n          save_steps=1,\n          output_dir=eval_dir,\n          summary_op=tf.summary.merge_all())\n      evaluation_hooks.append(eval_summary_hook)\n\n      evaluation_hooks += problem.eval_hooks(features, logits, hparams)\n\n      return tf.estimator.EstimatorSpec(\n          tf.estimator.ModeKeys.EVAL,\n          predictions=predictions,\n          eval_metric_ops=eval_metrics,\n          evaluation_hooks=evaluation_hooks,\n          loss=loss)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef estimator_spec_predict(self, features, use_tpu=False):\n    decode_hparams = self._decode_hparams\n    top_beams = decode_hparams.beam_size if decode_hparams.return_beams else 1\n    infer_out = self.infer(\n        features,\n        beam_size=decode_hparams.beam_size,\n        top_beams=top_beams,\n        alpha=decode_hparams.alpha,\n        decode_length=decode_hparams.extra_length,\n        use_tpu=use_tpu)\n    if isinstance(infer_out, dict):\n      outputs = infer_out[\"outputs\"]\n      scores = infer_out[\"scores\"]\n    else:\n      outputs = infer_out\n      scores = None\n\n    inputs = features.get(\"inputs\")\n    if inputs is None:\n      inputs = features[\"targets\"]\n\n    predictions = {\n        \"outputs\": outputs,\n        \"scores\": scores,\n        \"inputs\": inputs,\n        \"targets\": features.get(\"infer_targets\"),\n    }\n\n    # Pass through remaining features\n    for name, feature in features.items():\n      if name not in list(predictions.keys()) + [\"infer_targets\"]:\n        if name == \"decode_loop_step\":\n          continue\n        if not feature.shape.as_list():\n          # All features must have a batch dimension\n          batch_size = common_layers.shape_list(outputs)[0]\n          feature = tf.tile(tf.expand_dims(feature, 0), [batch_size])\n        predictions[name] = feature\n\n    _del_dict_non_tensors(predictions)\n\n    export_out = {\"outputs\": predictions[\"outputs\"]}\n    if \"scores\" in predictions:\n      export_out[\"scores\"] = predictions[\"scores\"]\n\n    # Necessary to rejoin examples in the correct order with the Cloud ML Engine\n    # batch prediction API.\n    if \"batch_prediction_key\" in predictions:\n      export_out[\"batch_prediction_key\"] = predictions[\"batch_prediction_key\"]\n\n    export_outputs = {\n        tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n            tf.estimator.export.PredictOutput(export_out)\n    }\n    if use_tpu:\n      # Note: important to call this before remove_summaries()\n      if self.hparams.tpu_enable_host_call:\n        host_call = self.create_eval_host_call()\n      else:\n        host_call = None\n\n      remove_summaries()\n\n      return tf.contrib.tpu.TPUEstimatorSpec(\n          tf.estimator.ModeKeys.PREDICT,\n          predictions=predictions,\n          host_call=host_call,\n          export_outputs=export_outputs)\n    else:\n      return tf.estimator.EstimatorSpec(\n          tf.estimator.ModeKeys.PREDICT,\n          predictions=predictions,\n          export_outputs=export_outputs)", "response": "Constructs tf. estimator. EstimatorSpec for PREDICT mode."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds tf. summary s to all terms in the losses dictionary.", "response": "def _summarize_losses(self, losses_dict):\n    \"\"\"Adds `tf.summary`s to all terms in the losses dictionary.\"\"\"\n    if common_layers.should_generate_summaries():\n      with tf.name_scope(\"losses\"):\n        for loss_name, loss_val in sorted(losses_dict.items()):\n          tf.summary.scalar(loss_name, loss_val)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nscheduling sampling. Performs forward inference again with \"targets\" feature replaced with values sampled from the model. This is the identity unless self.hparams.scheduled_sampling_prob > 0 (default). **WARNING**: This is not a faithful implementation of scheduled sampling. This implementation samples tokens for timestep t condtioned on gold tokens 1...t-1. A proper implementation must condition on a mix of gold and sampled tokens. Doing so is not efficient for models such like Transformer. Args: features: {str: Tensor}. Features sharded along batch dimension. logits: Tensor. Logits for each shard of data. losses: 0-D Tensor or (num: 0-D Tensor, denom: 0-D Tensor). Loss Tensor Returns: new_logits: Tensor. new_losses: {str: loss} where loss is one of (i) a 0-D Tensor or (ii) a (num: 0-D Tensor, denom: 0-D Tensor) pair to be used in a weighted average.", "response": "def maybe_scheduled_sampling(self, features, logits, losses):\n    \"\"\"Scheduled sampling.\n\n    Performs forward inference again with \"targets\" feature replaced with values\n    sampled from the model.\n\n    This is the identity unless self.hparams.scheduled_sampling_prob > 0\n    (default).\n\n    **WARNING**: This is not a faithful implementation of scheduled sampling.\n    This implementation samples tokens for timestep t condtioned on gold tokens\n    1...t-1. A proper implementation must condition on a mix of gold and\n    sampled tokens. Doing so is not efficient for models such like Transformer.\n\n    Args:\n      features: {str: Tensor}. Features sharded along batch dimension.\n      logits: Tensor. Logits for each shard of data.\n      losses: 0-D Tensor or (num: 0-D Tensor, denom: 0-D Tensor). Loss Tensor\n\n    Returns:\n      new_logits: Tensor.\n      new_losses: {str: loss} where loss is one of (i) a 0-D Tensor or\n        (ii) a (num: 0-D Tensor, denom: 0-D Tensor) pair to be used in a\n        weighted average.\n    \"\"\"\n    hparams = self.hparams\n    problem_hparams = self._problem_hparams\n\n    # Only do scheduled sampling if requested.\n    if hparams.scheduled_sampling_prob == 0.0:\n      return (logits, losses)\n\n    # Only do scheduled sampling on language tasks.\n    modality = problem_hparams.modality[\"targets\"]\n    if modality != modalities.ModalityType.SYMBOL:\n      assert hparams.scheduled_sampling_prob == 0, (\n          \"Scheduled sampling only applies to ModalityType.SYMBOL. Set \"\n          \"hparams.scheduled_sampling_prob == 0.0.\")\n      return (logits, losses)\n\n    # Only do scheduled sampling when training.\n    is_training = (hparams.mode == tf.estimator.ModeKeys.TRAIN)\n    if not is_training:\n      tf.logging.info(\"Running in %s mode. Not using scheduled sampling.\",\n                      hparams.mode)\n      return (logits, losses)\n\n    # Pad vocabulary if vocab size must be evenly divisible by vocab_divisor.\n    vocab_size = problem_hparams.vocab_size[\"targets\"]\n    assert vocab_size is not None\n    assert hparams.vocab_divisor == 1\n\n    def sample(x):\n      \"\"\"Multinomial sampling from a n-dimensional tensor.\"\"\"\n      samples = tf.multinomial(tf.reshape(x, [-1, vocab_size]), 1)\n      reshaped_samples = tf.reshape(samples, common_layers.shape_list(x)[:-1])\n      return tf.to_int32(reshaped_samples)\n\n    def mix_gold_sampled(gold_targets, sampled_targets, mixin_prob):\n      \"\"\"Interleave sampled and gold tokens randomly.\"\"\"\n      return tf.where(\n          tf.less(\n              tf.random_uniform(common_layers.shape_list(sampled_targets)),\n              mixin_prob),\n          sampled_targets,\n          gold_targets)\n\n    def sampled_results(features, logits, mixin_prob):\n      \"\"\"Generate scheduled sampling results.\"\"\"\n      sampled_targets = sample(logits)\n      new_targets = mix_gold_sampled(features[\"targets\"],\n                                     sampled_targets,\n                                     mixin_prob)\n      new_targets = tf.stop_gradient(new_targets)  # Treat new_targets as given.\n      new_features = copy.copy(features)\n      new_features[\"targets\"] = new_targets\n      with tf.variable_scope(tf.get_variable_scope(), reuse=True):\n        # Compute bottom() for new_targets.\n        #\n        # TODO(duckworthd): Only apply bottom to 'new_targets'.\n        new_transformed_features = self.bottom(new_features)\n\n        # Compute body.\n        with tf.variable_scope(\"body\"):\n          new_body_outputs, new_losses = self._normalize_body_output(\n              self.body(new_transformed_features))\n        assert \"training\" not in new_losses\n\n        # Compute top.\n        new_logits = self.top(new_body_outputs, new_features)\n\n        # Compute loss. Use original features (== labels).\n        if (hparams.mode != tf.estimator.ModeKeys.PREDICT and\n            hparams.mode != \"attack\"):\n          new_losses[\"training\"] = self.loss(new_logits, features)\n        else:\n          new_losses[\"training\"] = 0.0\n\n      return new_logits, new_losses\n\n    tf.logging.info(\"Using scheduled sampling.\")\n    assert hparams.scheduled_sampling_prob == 1.0, (\n        \"hparams.scheduled_sampling_prob must be 0 or 1.\")\n    # Gradually increase over a warmup period. Lower numbers mean more gold\n    # tokens.\n    mixin_prob = (\n        hparams.scheduled_sampling_gold_mixin_prob *\n        common_layers.inverse_exp_decay(\n            hparams.scheduled_sampling_warmup_steps,\n            min_value=0.001)\n    )\n\n    # Apply scheduled sampling over N passes. The logits from the (n-1)-th pass\n    # will be mixed with gold tokens for conditioning in the n-th pass.\n    scheduled_sampling_num_passes = getattr(\n        hparams, \"scheduled_sampling_num_passes\", 1)\n    assert scheduled_sampling_num_passes > 0, (\n        \"hparams.scheduled_sampling_num_passes must be > 0 if \"\n        \"hparams.scheduled_sampling_prob > 0.0\")\n    new_logits = logits\n    new_losses = losses\n    for _ in range(scheduled_sampling_num_passes):\n      new_logits, new_losses = sampled_results(features, new_logits, mixin_prob)\n    return new_logits, new_losses"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef attention_lm_moe_prepare_decoder(targets, hparams):\n  targets_pad_mask = common_attention.embedding_to_padding(targets)\n  with tf.name_scope(\"pad_remover\"):\n    # Because of the shift_right, the <eos> token will be considered as\n    # padding. In practice, it doesn't really matter, due to the triangular\n    # mask, this token should never be attended.\n    pad_remover = expert_utils.PadRemover(targets_pad_mask)\n\n  if hparams.prepend_mode == \"prepend_inputs_full_attention\":\n    decoder_self_attention_bias = (\n        common_attention.attention_bias_prepend_inputs_full_attention(\n            targets_pad_mask))\n  else:\n    decoder_self_attention_bias = (\n        common_attention.attention_bias_lower_triangle(tf.shape(targets)[1]))\n  decoder_input = common_layers.shift_right_3d(targets)\n  if hparams.pos == \"timing\":\n    decoder_input = common_attention.add_timing_signal_1d(decoder_input)\n  return (decoder_input, decoder_self_attention_bias, pad_remover)", "response": "Prepare one shard of the model for the decoder."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a flat int32 tensor of shape [ 1 batch_size length 1 ).", "response": "def get_batch_coordinate(x, axis=0):\n  \"\"\"Return a flat int32 tensor of shape [1, batch_size*length, 1].\"\"\"\n  # Compute the batch coordinate before flattening all batches\n  batch_coordinate = tf.expand_dims(\n      common_attention.coordinate_tensor(tf.shape(x)[:-1], axis=axis), axis=-1)\n  return batch_coordinate"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef expand_batch_coordinates(bc, length_factor):\n  assert bc.get_shape().as_list() == [1, None, 1]\n  # bc has shape [1, length, 1]\n  bc *= tf.constant([[1] * length_factor])\n  # bc has shape [1, length, length_factor]\n  bc = tf.reshape(bc, [1, -1, 1])\n  # bc has shape [1, length*length_factor]\n  return bc", "response": "Duplicate elements of bc by length_factor."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_pad(x, pad_remover, mode):\n  # Concatenate all tokens (without padding)\n  x = expert_utils.flatten_all_but_last(x)\n\n  # Remove padding for training and eval\n  if mode != ModeKeys.PREDICT:\n    # This is a hack to allows inference when the <go> token\n    # is detected as padding and removed. This works for now because there is\n    # no padding at inference.\n    x = pad_remover.remove(x)\n\n  x = tf.expand_dims(x, axis=0)  # Now batch_size=1\n  return x", "response": "Remove padding from the last batch of tokens."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef attention_lm_moe_base():\n  hparams = common_hparams.basic_params1()\n  hparams.hidden_size = 1024\n  hparams.batch_size = 8192\n  hparams.max_length = 256\n  hparams.dropout = 0.0\n  hparams.clip_grad_norm = 0.  # i.e. no gradient clipping\n  hparams.optimizer_adam_epsilon = 1e-9\n  hparams.learning_rate_decay_scheme = \"noam\"\n  hparams.learning_rate = 0.1\n  hparams.learning_rate_warmup_steps = 2000\n  hparams.initializer_gain = 1.0\n  hparams.num_hidden_layers = 4\n  hparams.initializer = \"uniform_unit_scaling\"\n  hparams.weight_decay = 0.0\n  hparams.optimizer_adam_beta1 = 0.9\n  hparams.optimizer_adam_beta2 = 0.98\n  hparams.num_sampled_classes = 0\n  hparams.label_smoothing = 0.0\n  hparams.shared_embedding_and_softmax_weights = False\n  hparams.add_hparam(\"filter_size\", 2048)  # Add new ones like this.\n  hparams.moe_num_experts = 32\n  # attention-related flags\n  hparams.add_hparam(\"num_heads\", 8)\n  hparams.add_hparam(\"attention_key_channels\", 0)\n  hparams.add_hparam(\"attention_value_channels\", 0)\n  # All hyperparameters ending in \"dropout\" are automatically set to 0.0\n  # when not in training mode.\n  hparams.add_hparam(\"attention_dropout\", 0.0)\n  hparams.add_hparam(\"relu_dropout\", 0.0)\n  hparams.add_hparam(\"pos\", \"timing\")  # timing, none\n  hparams.add_hparam(\"moe_layers\", \"2\")  # comma separated list of layer numbers\n  # moe params. local attention moe.\n  # If attention_layers is set, the num_hidden_layers parameter will be ignored\n  # and each caracter of the string will correspond to one attention\n  # layer type\n  hparams.add_hparam(\"attention_layers\", \"\")\n  hparams.add_hparam(\"attention_type\", AttentionType.MULTIHEAD)\n  hparams.add_hparam(\"attention_local\", False)\n  hparams.add_hparam(\"attention_moe_k\", 2)\n  hparams.add_hparam(\"attention_num_head\", 1)\n  hparams.add_hparam(\"attention_num_experts\", 16)\n  hparams.add_hparam(\"attention_split_batch\", False)\n  hparams.add_hparam(\"attention_red_factor\", 3)\n  hparams.add_hparam(\"attention_block_length\", 128)\n  hparams.add_hparam(\"attention_reduction_type\", \"conv\")\n  # Non linearity for the attention reduction. Either \"none\", or \"silu\" (\n  # Sigmoid Linear-Unit described in https://arxiv.org/abs/1710.05941)\n  hparams.add_hparam(\"attention_nonlinearity\", \"none\")\n  # If attention_exp_factor is set, each input to local_expert_attention (of\n  # dimensionality hidden size) is projected into attention_exp_factor smaller\n  # inputs, each of dimensionality attention_exp_inputdim. (otherwise\n  # attention_exp_inputdim is ignored)\n  hparams.add_hparam(\"attention_exp_factor\", 0)\n  hparams.add_hparam(\"attention_exp_inputdim\", 128)\n  # Key, query and value dimensions for the attention\n  hparams.add_hparam(\"attention_kq_size\", 128)\n  hparams.add_hparam(\"attention_v_size\", 256)\n  # Loss coef for load balancing\n  hparams.add_hparam(\"attention_load_balance\", 2e-2)\n  # Locality-sensitive hashing params\n  hparams.add_hparam(\"lsh_num_hyperplanes\", 4)\n  hparams.add_hparam(\"lsh_use_map_fn\", False)\n\n  hparams.add_hparam(\"use_sepconv\", False)\n  hparams.add_hparam(\"diet_experts\", False)\n  hparams.add_hparam(\"memory_efficient_ffn\", False)\n  # if True, we learn a non-autoregressive model from \"inputs\" to \"targets\".\n  # if False, we learn an autoregressive model to generate \"targets\"\n  hparams.add_hparam(\"use_inputs\", False)\n  return hparams", "response": "Set of hyperparameters suitable for 1 gpu."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbases model with attention expert.", "response": "def attention_lm_moe_base_ae():\n  \"\"\"Base model with attention expert.\"\"\"\n  hparams = attention_lm_moe_base_long_seq()\n  hparams.attention_type = AttentionType.LOCAL_EXPERTS\n\n  hparams.learning_rate = 0.05\n  hparams.learning_rate_warmup_steps = 10000\n  # According to noam, (\"n\", \"da\") seems better for harder-to-learn models\n  # hparams.layer_preprocess_sequence = \"n\"\n  # hparams.layer_postprocess_sequence = \"da\"\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexperimenting with the exp_factor params.", "response": "def attention_lm_ae_extended():\n  \"\"\"Experiment with the exp_factor params.\"\"\"\n  hparams = attention_lm_moe_base_long_seq()\n  hparams.attention_layers = \"eeee\"\n  hparams.attention_local = True\n  # hparams.factored_logits=1  # Necessary when the number of expert grow bigger\n  hparams.attention_moe_k = 2\n  hparams.attention_exp_factor = 4\n  # hparams.attention_exp_inputdim = 128\n\n  hparams.layer_preprocess_sequence = \"n\"\n  hparams.layer_postprocess_sequence = \"da\"\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef attention_lm_moe_base_memeff():\n  hparams = attention_lm_moe_base_long_seq()\n  hparams.use_sepconv = False\n\n  hparams.diet_experts = True\n  hparams.layer_preprocess_sequence = \"n\"\n  hparams.layer_postprocess_sequence = \"da\"\n  hparams.layer_prepostprocess_dropout = 0.0\n  hparams.memory_efficient_ffn = True\n  hparams.attention_type = AttentionType.MEMORY_EFFICIENT\n  hparams.num_heads = 8\n  hparams.factored_logits = True\n  return hparams", "response": "Base model with attention expert."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef attention_lm_attention_moe_tiny():\n  hparams = attention_lm_moe_small()\n  hparams.moe_layers = \"\"\n  hparams.attention_num_experts = 128\n  hparams.filter_size = 8192\n  hparams.attention_type = AttentionType.LOCAL_EXPERTS\n  return hparams", "response": "Cheap model for debugging."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef attention_lm_moe_24b_diet():\n  hparams = attention_lm_moe_large_diet()\n  hparams.moe_hidden_sizes = \"12288\"\n  hparams.moe_num_experts = 1024\n  hparams.batch_size = 4096\n  return hparams", "response": "Unnecessarily large model with 24B params - because we can t do it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nversion to use for seq2seq.", "response": "def attention_lm_moe_translation():\n  \"\"\"Version to use for seq2seq.\"\"\"\n  hparams = attention_lm_moe_base()\n  hparams.layer_preprocess_sequence = \"n\"\n  hparams.layer_postprocess_sequence = \"da\"\n  hparams.learning_rate = 0.4\n  hparams.prepend_mode = \"prepend_inputs_masked_attention\"\n  hparams.max_length = 512\n  hparams.label_smoothing = 0.1\n  hparams.layer_prepostprocess_dropout = 0.2\n  hparams.num_hidden_layers = 6\n  hparams.moe_layers = \"0,1,2,3,4,5\"\n  hparams.shared_embedding_and_softmax_weights = True\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef attention_lm_moe_unscramble_base():\n  hparams = attention_lm_no_moe_small()\n  hparams.use_inputs = True\n  hparams.min_length_bucket = 1024\n  hparams.max_length = 1024\n  hparams.batch_size = 5000\n  hparams.layer_prepostprocess_dropout = 0.0\n  hparams.layer_preprocess_sequence = \"n\"\n  hparams.layer_postprocess_sequence = \"da\"\n  return hparams", "response": "Version to use with languagemodel_wiki_scramble1k50."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbottoms transformation for audio.", "response": "def audio_bottom(x, model_hparams, vocab_size):\n  \"\"\"Transform input from data space to model space.\n\n  Args:\n    x: A Tensor with shape [batch, ...]\n    model_hparams: HParams, model hyperparmeters.\n    vocab_size: int, vocabulary size.\n\n  Returns:\n    body_input: A Tensor with shape [batch, ?, ?,\n      model_hparams.hidden_size].\n  \"\"\"\n  del vocab_size  # unused arg\n  inputs = x\n  with tf.variable_scope(\"audio_modality\"):\n    # TODO(aidangomez): Will need to sort out a better audio pipeline\n    def xnet_resblock(x, filters, res_relu, name):\n      \"\"\"Xception block.\"\"\"\n      with tf.variable_scope(name):\n        # Typically audio samples are >100k samples in length and have a width\n        # of 2 or 4. Mono audio has a single channel while stereo has 2.\n        y = common_layers.separable_conv_block(\n            x,\n            filters, [((1, 1), (3, 3)), ((1, 1), (3, 3))],\n            first_relu=True,\n            padding=\"SAME\",\n            force2d=True,\n            name=\"sep_conv_block\")\n        y = common_layers.pool(y, (3, 3), \"MAX\", \"SAME\", strides=(2, 2))\n        return y + common_layers.conv_block(\n            x,\n            filters, [((1, 1), (1, 1))],\n            padding=\"SAME\",\n            strides=(2, 2),\n            first_relu=res_relu,\n            force2d=True,\n            name=\"res_conv0\")\n\n    x = tf.to_float(inputs) / 255.\n    x.set_shape([None, None, None, 1])\n    for i in range(model_hparams.audio_compression):\n      x = xnet_resblock(x, 2**(i + 1), True, \"compress_block_%d\" % i)\n    return xnet_resblock(x,\n                         model_hparams.hidden_size,\n                         False,\n                         \"compress_block_final\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef image_targets_bottom(x, model_hparams, vocab_size):\n  pixel_embedding_size = 64\n  inputs = x\n  with tf.variable_scope(\"image_modality\"):\n    if not tf.executing_eagerly():\n      tf.summary.image(\n          \"targets_bottom\",\n          common_layers.tpu_safe_image_summary(inputs),\n          max_outputs=1)\n    inputs_shape = common_layers.shape_list(inputs)\n    if len(inputs_shape) != 4:\n      raise ValueError(\"Assuming images given as int tensors in the format \"\n                       \"[batch, height, width, channels] (256 values).\")\n    # We embed each of 256=vocab_size possible pixel values.\n    embedding_var = tf.get_variable(\n        \"pixel_embedding\",\n        [vocab_size, pixel_embedding_size])\n    hot_inputs = tf.one_hot(tf.to_int32(inputs), vocab_size)\n    hot_inputs = tf.reshape(hot_inputs, [-1, vocab_size])\n    embedded = tf.matmul(hot_inputs, embedding_var)\n    # Let's now merge all channels that were embedded into a single vector.\n    merged_size = pixel_embedding_size * inputs_shape[3]\n    embedded = tf.reshape(embedded, inputs_shape[:3] + [merged_size])\n    merged = tf.layers.dense(\n        embedded,\n        model_hparams.hidden_size,\n        name=\"merge_pixel_embedded_channels\")\n    return merged", "response": "Bottom transformation for target images."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _image_channel_compress_bottom(inputs, model_hparams, name=\"bottom\"):\n  num_channels = 3\n  with tf.variable_scope(name):\n    inputs = tf.to_float(inputs)\n    hp = model_hparams\n    if hp.mode != tf.estimator.ModeKeys.PREDICT:\n      tf.summary.image(\n          \"inputs\",\n          common_layers.tpu_safe_image_summary(inputs),\n          max_outputs=2)\n    inputs = common_layers.convert_rgb_to_symmetric_real(inputs)\n\n    # Reshape inputs to apply convolutions across [img_len, img_len*channels].\n    inputs_shape = common_layers.shape_list(inputs)\n    inputs = tf.reshape(\n        inputs, [-1, inputs_shape[1], inputs_shape[2] * inputs_shape[3], 1])\n\n    # Compress RGB intensities for each pixel using a convolution.\n    outputs = tf.layers.conv2d(\n        inputs,\n        model_hparams.hidden_size,\n        kernel_size=(1, num_channels),\n        padding=\"VALID\",\n        strides=(1, num_channels),\n        activation=tf.nn.relu,\n        name=\"conv_input\")\n    return outputs", "response": "Bottom image - channel compression."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef image_channel_embeddings_bottom(x, model_hparams, vocab_size):\n  del vocab_size  # unused arg\n  inputs = tf.to_int32(x)\n  io_depth = model_hparams.num_channels\n  tshape = common_layers.shape_list(inputs)\n  hidden_size = model_hparams.hidden_size\n  target_embeddings = cia.get_channel_embeddings(\n      io_depth, inputs, hidden_size, \"input_bottom\")\n  return tf.reshape(target_embeddings,\n                    [tshape[0], tshape[1], tshape[2] * io_depth, hidden_size])", "response": "Bottom transformation for image targets."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbottoming of speech recognition.", "response": "def speech_recognition_bottom(x, model_hparams, vocab_size):\n  \"\"\"Use batchnorm instead of CMVN and shorten the stft with strided convs.\n\n  Args:\n    x: float32 tensor with shape [batch_size, len, 1, freqs * channels]\n    model_hparams: HParams, model hyperparmeters.\n    vocab_size: int, vocabulary size.\n\n  Returns:\n    float32 tensor with shape [batch_size, shorter_len, 1, hidden_size]\n  \"\"\"\n  del vocab_size  # unused arg\n  inputs = x\n  p = model_hparams\n\n  num_mel_bins = p.audio_num_mel_bins\n  num_channels = 3 if p.audio_add_delta_deltas else 1\n\n  with tf.variable_scope(\"speech_recognition_modality\"):\n    if p.audio_preproc_in_bottom:\n      # Compute filterbanks\n      with tf.variable_scope(\"fbanks\"):\n        waveforms = tf.squeeze(inputs, [2, 3])\n        mel_fbanks = common_audio.compute_mel_filterbank_features(\n            waveforms,\n            sample_rate=p.audio_sample_rate,\n            dither=p.audio_dither,\n            preemphasis=p.audio_preemphasis,\n            frame_length=p.audio_frame_length,\n            frame_step=p.audio_frame_step,\n            lower_edge_hertz=p.audio_lower_edge_hertz,\n            upper_edge_hertz=p.audio_upper_edge_hertz,\n            num_mel_bins=p.audio_num_mel_bins,\n            apply_mask=True)\n        if p.audio_add_delta_deltas:\n          mel_fbanks = common_audio.add_delta_deltas(mel_fbanks)\n        x = tf.reshape(mel_fbanks,\n                       common_layers.shape_list(mel_fbanks)[:2] +\n                       [num_mel_bins, num_channels])\n\n        nonpadding_mask = 1. - common_attention.embedding_to_padding(x)\n        num_of_nonpadding_elements = tf.reduce_sum(\n            nonpadding_mask) * num_mel_bins * num_channels\n\n        # This replaces CMVN estimation on data\n        var_epsilon = 1e-09\n        mean = tf.reduce_sum(\n            x, axis=[1], keepdims=True) / num_of_nonpadding_elements\n        variance = (num_of_nonpadding_elements * mean**2. -\n                    2. * mean * tf.reduce_sum(x, axis=[1], keepdims=True) +\n                    tf.reduce_sum(x**2, axis=[1], keepdims=True)\n                   ) / num_of_nonpadding_elements\n        x = (x - mean) * tf.rsqrt(variance + var_epsilon) * tf.expand_dims(\n            nonpadding_mask, -1)\n    else:\n      x = inputs\n\n    # The convention is that the models are flattened along the spatial,\n    # dimensions, thus the speech preprocessor treats frequencies and\n    # channels as image colors (last axis)\n    x.set_shape([None, None, num_mel_bins, num_channels])\n\n    # TODO(chorowski): how to specify bottom's hparams and avoid hardcoding?\n    x = tf.pad(x, [[0, 0], [0, 8], [0, 0], [0, 0]])\n    for _ in range(2):\n      x = tf.layers.conv2d(\n          x, 128, (3, 3), (2, 2), use_bias=False)\n      x = common_layers.layer_norm(x)\n      x = tf.nn.relu(x)\n\n    xshape = common_layers.shape_list(x)\n    # apply a conv that will remove all frequencies and at the same time\n    # project the output into desired hidden_size\n    x = tf.pad(x, [[0, 0], [0, 2], [0, 0], [0, 0]])\n    x = tf.layers.conv2d(x, p.hidden_size, (3, xshape[2]), use_bias=False)\n\n    assert common_layers.shape_list(x)[2] == 1\n    x = common_layers.layer_norm(x)\n    x = tf.nn.relu(x)\n  return x"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates or get concatenated embedding or softmax variable.", "response": "def get_weights(model_hparams, vocab_size, hidden_dim=None):\n  \"\"\"Create or get concatenated embedding or softmax variable.\n\n  Args:\n    model_hparams: HParams, model hyperparmeters.\n    vocab_size: int, vocabulary size.\n    hidden_dim: dim of the variable. Defaults to _model_hparams' hidden_size\n\n  Returns:\n     a list of num_shards Tensors.\n  \"\"\"\n  if hidden_dim is None:\n    hidden_dim = model_hparams.hidden_size\n  num_shards = model_hparams.symbol_modality_num_shards\n  shards = []\n  for i in range(num_shards):\n    shard_size = (vocab_size // num_shards) + (\n        1 if i < vocab_size % num_shards else 0)\n    var_name = \"weights_%d\" % i\n    shards.append(\n        tf.get_variable(\n            var_name, [shard_size, hidden_dim],\n            initializer=tf.random_normal_initializer(0.0, hidden_dim**-0.5)))\n  if num_shards == 1:\n    ret = shards[0]\n  else:\n    ret = tf.concat(shards, 0)\n  # Convert ret to tensor.\n  if not tf.executing_eagerly():\n    ret = common_layers.convert_gradient_to_tensor(ret)\n  return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _symbol_bottom_simple(x, model_hparams, vocab_size, name, reuse):\n  with tf.variable_scope(name, reuse=reuse):\n    # Ensure the inputs are 3-D\n    if len(x.get_shape()) == 4:\n      x = tf.squeeze(x, axis=3)\n    while len(x.get_shape()) < 3:\n      x = tf.expand_dims(x, axis=-1)\n\n    var = get_weights(model_hparams, vocab_size)\n    x = common_layers.dropout_no_scaling(\n        x, 1.0 - model_hparams.symbol_dropout)\n    ret = common_layers.gather(var, x)\n    if model_hparams.multiply_embedding_mode == \"sqrt_depth\":\n      ret *= model_hparams.hidden_size**0.5\n    ret *= tf.expand_dims(\n        common_layers.cast_like(tf.not_equal(x, 0), ret), -1)\n    return ret", "response": "Bottom transformation for symbols."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef symbol_targets_bottom(x, model_hparams, vocab_size):\n  if (model_hparams.shared_embedding_and_softmax_weights or\n      model_hparams.get(\"shared_embedding\")):\n    try:\n      return _symbol_bottom_simple(\n          x, model_hparams, vocab_size, \"shared\", reuse=True)\n    except ValueError:\n      # perhaps there were no inputs, and this is a new variable.\n      return _symbol_bottom_simple(\n          x, model_hparams, vocab_size, \"shared\", reuse=None)\n  else:\n    return _symbol_bottom_simple(\n        x, model_hparams, vocab_size, \"target_emb\", reuse=None)", "response": "Bottom transformation for target symbols."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef video_bitwise_bottom(x, model_hparams, vocab_size):\n  pixel_embedding_size = 64\n  inputs = x\n  with tf.variable_scope(\"video_modality_bitwise\", reuse=tf.AUTO_REUSE):\n    common_layers.summarize_video(inputs, \"bottom\")\n    # Embed bitwise.\n    assert vocab_size == 256\n    embedded = discretization.int_to_bit_embed(inputs, 8,\n                                               pixel_embedding_size)\n    # Project.\n    return tf.layers.dense(\n        embedded,\n        model_hparams.hidden_size,\n        name=\"merge_pixel_embedded_frames\")", "response": "Bottom transformation for embedding video bitwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef video_pixel_noise_bottom(x, model_hparams, vocab_size):\n  input_noise = getattr(model_hparams, \"video_modality_input_noise\", 0.25)\n  inputs = x\n  if model_hparams.mode == tf.estimator.ModeKeys.TRAIN:\n    background = tfp.stats.percentile(inputs, 50., axis=[0, 1, 2, 3])\n    input_shape = common_layers.shape_list(inputs)\n    input_size = tf.reduce_prod(input_shape[:-1])\n    input_mask = tf.multinomial(\n        tf.log([[input_noise, 1.-input_noise]]), input_size)\n    input_mask = tf.reshape(tf.cast(input_mask, tf.int32),\n                            input_shape[:-1]+[1])\n    inputs = inputs * input_mask + background * (1 - input_mask)\n  return video_bottom(inputs, model_hparams, vocab_size)", "response": "Bottom transformation for video."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert prediction and target from rgb to real.", "response": "def convert_rgb_to_real(prediction, targets):\n  \"\"\"Convert prediction and target from rgb to real.\"\"\"\n  prediction = tf.squeeze(prediction, axis=-1)\n  prediction = common_layers.convert_rgb_to_real(prediction)\n  targets = common_layers.convert_rgb_to_real(targets)\n  return prediction, targets"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ctc_symbol_loss(top_out, targets, model_hparams, vocab_size, weight_fn):\n  del model_hparams, vocab_size  # unused arg\n  logits = top_out\n  with tf.name_scope(\"ctc_loss\", values=[logits, targets]):\n    # For CTC we assume targets are 1d, [batch, length, 1, 1] here.\n    targets_shape = targets.get_shape().as_list()\n    assert len(targets_shape) == 4\n    assert targets_shape[2] == 1\n    assert targets_shape[3] == 1\n    targets = tf.squeeze(targets, axis=[2, 3])\n    logits = tf.squeeze(logits, axis=[2, 3])\n    targets_mask = 1 - tf.to_int32(tf.equal(targets, 0))\n    targets_lengths = tf.reduce_sum(targets_mask, axis=1)\n    sparse_targets = tf.keras.backend.ctc_label_dense_to_sparse(\n        targets, targets_lengths)\n    xent = tf.nn.ctc_loss(\n        sparse_targets,\n        logits,\n        targets_lengths,\n        time_major=False,\n        preprocess_collapse_repeated=False,\n        ctc_merge_repeated=False)\n    weights = weight_fn(targets)\n    return tf.reduce_sum(xent), tf.reduce_sum(weights)", "response": "Compute the CTC loss."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute loss numerator and denominator for one shard of output.", "response": "def generic_loss(top_out, targets, model_hparams, vocab_size, weights_fn):\n  \"\"\"Compute loss numerator and denominator for one shard of output.\"\"\"\n  del vocab_size  # unused arg\n  logits = top_out\n  logits = common_attention.maybe_upcast(logits, hparams=model_hparams)\n  cutoff = getattr(model_hparams, \"video_modality_loss_cutoff\", 0.0)\n  return common_layers.padded_cross_entropy(\n      logits,\n      targets,\n      model_hparams.label_smoothing,\n      cutoff=cutoff,\n      weights_fn=weights_fn)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\naverages loss over the labels.", "response": "def multi_label_loss(top_out, targets, model_hparams, vocab_size, weights_fn):\n  \"\"\"Average loss over the labels.\"\"\"\n  del vocab_size  # unused arg\n  logits = top_out\n  num_labels = tf.shape(targets)[1]\n  logits = tf.tile(logits, [1, num_labels, 1, 1, 1])\n\n  xent, weights = common_layers.padded_cross_entropy(\n      logits,\n      targets,\n      model_hparams.label_smoothing,\n      weights_fn=weights_fn,\n      reduce_sum=False,\n  )\n  xent = tf.squeeze(xent, [2, 3])\n  weights = tf.squeeze(weights, [2, 3])\n  # average loss over all labels\n  loss = tf.reduce_sum(xent, axis=1)\n  weights = tf.reduce_sum(weights, axis=1)\n  loss /= (weights + 1e-8)\n  weights = tf.to_float(tf.greater(weights, 0.))\n\n  return tf.reduce_sum(loss*weights), tf.reduce_sum(weights)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\napplies softmax cross - entropy between outputs and targets.", "response": "def one_hot_class_label_loss(top_out,\n                             targets,\n                             model_hparams,\n                             vocab_size,\n                             weights_fn):\n  \"\"\"Apply softmax cross-entropy between outputs and targets.\n\n  Args:\n    top_out: logits Tensor with shape [batch, ?, ?, num_classes]\n    targets: one-hot encoding Tensor with shape [batch, ?, ?, num_classes]\n    model_hparams: HParams, model hyperparmeters.\n    vocab_size: int, vocabulary size.\n    weights_fn:\n\n  Returns:\n    loss_scale (cross-entropy), loss_denom\n  \"\"\"\n  del model_hparams, vocab_size  # unused arg\n  loss_scale = tf.losses.softmax_cross_entropy(\n      onehot_labels=targets, logits=top_out)\n  weights = weights_fn(targets)\n  loss_denom = tf.reduce_sum(weights)\n  return loss_scale, loss_denom"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef real_log_poisson_loss(top_out,\n                          targets,\n                          model_hparams,\n                          vocab_size,\n                          weights_fn):\n  \"\"\"Poisson loss for real.\"\"\"\n  del model_hparams, vocab_size  # unused arg\n  predictions = top_out\n  if (len(common_layers.shape_list(top_out)) != len(\n      common_layers.shape_list(targets))):\n    predictions = tf.squeeze(top_out, axis=[-1])\n  with tf.name_scope(\"log_possion\"):\n    weights = weights_fn(targets)\n    lp_loss = tf.nn.log_poisson_loss(targets, predictions)\n    return tf.reduce_sum(lp_loss * weights), tf.reduce_sum(weights)", "response": "Poisson loss for real."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef video_loss(top_out, targets, model_hparams, vocab_size, weights_fn):\n  del vocab_size  # unused arg\n  logits = top_out\n  logits = tf.reshape(logits, [-1] + common_layers.shape_list(logits)[2:])\n  targets = tf.reshape(targets, [-1] + common_layers.shape_list(targets)[2:])\n  cutoff = getattr(model_hparams, \"video_modality_loss_cutoff\", 0.01)\n  return common_layers.padded_cross_entropy(\n      logits,\n      targets,\n      model_hparams.label_smoothing,\n      cutoff=cutoff,\n      weights_fn=weights_fn)", "response": "Compute loss numerator and denominator for one shard of output."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing loss numerator and denominator for one shard of output.", "response": "def video_l1_loss(top_out, targets, model_hparams, vocab_size, weights_fn):\n  \"\"\"Compute loss numerator and denominator for one shard of output.\"\"\"\n  del vocab_size  # unused arg\n  logits = top_out\n  logits = tf.reshape(logits, [-1] + common_layers.shape_list(logits)[2:-1])\n  targets = tf.reshape(targets, [-1] + common_layers.shape_list(targets)[2:])\n  weights = weights_fn(targets)\n  # Shift targets by 0.5 so later just casting to int gives the prediction.\n  # So for int targets, say 0 and 7, we actually train to predict 0.5 and 7.5.\n  # Later (in merics or infer) this is cast to int anyway. Also, we have no\n  # loss beyond cutoff = 0.2 as these are already correct predictions.\n  targets = tf.to_float(targets) + 0.5\n  loss = video_l1_internal_loss(logits, targets, model_hparams)\n  return tf.reduce_sum(loss * weights), tf.reduce_sum(weights)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute loss numerator and denominator for one shard of output.", "response": "def video_l2_loss(top_out, targets, model_hparams, vocab_size, weights_fn):\n  \"\"\"Compute loss numerator and denominator for one shard of output.\"\"\"\n  del vocab_size  # unused arg\n  logits = top_out\n  logits = tf.reshape(logits, [-1] + common_layers.shape_list(logits)[2:-1])\n  targets = tf.reshape(targets, [-1] + common_layers.shape_list(targets)[2:])\n  weights = weights_fn(targets)\n  # Shift targets by 0.5 so later just casting to int gives the prediction.\n  # So for int targets, say 0 and 7, we actually train to predict 0.5 and 7.5.\n  # Later (in merics or infer) this is cast to int anyway. Also, we have no\n  # loss beyond cutoff = 0.2 as these are already correct predictions.\n  targets = tf.to_float(targets) + 0.5\n  loss = video_l2_internal_loss(logits, targets, model_hparams)\n  return tf.reduce_sum(loss * weights), tf.reduce_sum(weights)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntransform inputs from model space to target space.", "response": "def class_label_top(body_output, targets, model_hparams, vocab_size):\n  \"\"\"Transform inputs from model space to target space.\n\n  Average over inner dims and a linear layer to logits.\n\n  Args:\n    body_output: A Tensor with shape [batch, ?, ?, body_output_size].\n    targets:\n    model_hparams: HParams, model hyperparmeters.\n    vocab_size: int, vocabulary size.\n\n  Returns:\n    a Tensors, each with shape [batch_size, 1, 1, 1, vocab_size]\n  \"\"\"\n  del targets  # unused arg\n  with tf.variable_scope(\"class_label_modality_%d_%d\" % (\n      vocab_size, model_hparams.hidden_size)):\n    x = body_output\n    x = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n    res = tf.layers.dense(x, vocab_size)\n    return tf.expand_dims(res, 3)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef image_top(body_output, targets, model_hparams, vocab_size):\n  del targets  # unused arg\n  # TODO(lukaszkaiser): is this a universal enough way to get channels?\n  num_channels = model_hparams.problem.num_channels\n  with tf.variable_scope(\"rgb_softmax\"):\n    body_output_shape = common_layers.shape_list(body_output)\n    reshape_shape = body_output_shape[:3]\n    reshape_shape.extend([num_channels, vocab_size])\n    res = tf.layers.dense(body_output, vocab_size * num_channels)\n    res = tf.reshape(res, reshape_shape)\n    if not tf.get_variable_scope().reuse:\n      res_argmax = tf.argmax(res, axis=-1)\n      tf.summary.image(\n          \"result\",\n          common_layers.tpu_safe_image_summary(res_argmax),\n          max_outputs=1)\n    return res", "response": "Top transformation for images."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef image_channel_compress_top(body_output, targets, model_hparams, vocab_size):\n  del targets  # unused arg\n  with tf.variable_scope(\"image_channel_compress_modality\"):\n    hidden_size = model_hparams.hidden_size\n    img_len = model_hparams.img_len\n    channels = 3  # RGB\n    batch = common_layers.shape_list(body_output)[0]\n    x = tf.layers.conv2d(\n        body_output,\n        hidden_size * channels,\n        kernel_size=(1, 1),\n        strides=(1, 1),\n        padding=\"VALID\",\n        activation=tf.nn.relu,\n        name=\"decompress_conv\")\n    x = tf.reshape(x, [batch, img_len, img_len * channels, hidden_size])\n    x = common_layers.layer_preprocess(x, model_hparams)\n    x = tf.layers.dense(x,\n                        vocab_size,\n                        use_bias=True,\n                        activation=None,\n                        name=\"output_conv\")\n    x = tf.reshape(\n        x, [batch, img_len, img_len, channels, vocab_size])\n    return x", "response": "Transforms body output to return logits."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntops transformation for images.", "response": "def image_channel_embeddings_top(body_output,\n                                 targets,\n                                 model_hparams,\n                                 vocab_size):\n  \"\"\"Top transformation for images.\"\"\"\n  del targets  # unused arg\n  with tf.variable_scope(\"image_channel_embeddings_bottom\"):\n    img_len = model_hparams.img_len\n    channels = model_hparams.num_channels\n    x = tf.layers.dense(\n        body_output, 256, use_bias=True, activation=None, name=\"output_conv\")\n    x = tf.reshape(x,\n                   [-1, img_len, img_len, channels, vocab_size])\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef softmax_last_timestep_class_label_top(body_output,\n                                          targets,\n                                          model_hparams,\n                                          vocab_size):\n  \"\"\"Loss for class label.\"\"\"\n  del targets  # unused arg\n  with tf.variable_scope(\n      \"softmax_last_timestep_onehot_class_label_modality_%d_%d\" % (\n          vocab_size, model_hparams.hidden_size)):\n    x = body_output\n    x = tf.expand_dims(x[:, -1], 1)  # Pick the last timestep\n    return tf.layers.dense(x, vocab_size)", "response": "Loss for class label."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef softmax_max_pooling_class_label_top(body_output,\n                                        targets,\n                                        model_hparams,\n                                        vocab_size):\n  \"\"\"Loss for class label.\"\"\"\n  del targets  # unused arg\n  with tf.variable_scope(\n      \"softmax_max_pooling_onehot_class_label_modality_%d_%d\" % (\n          vocab_size, model_hparams.hidden_size)):\n    x = body_output\n    x = tf.reduce_max(x, axis=1, keepdims=True)\n    return tf.layers.dense(x, vocab_size)", "response": "Loss for class label."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate logits. Args: body_output: A Tensor with shape [batch, p0, p1, model_hparams.hidden_size]. targets: Unused. model_hparams: HParams, model hyperparmeters. vocab_size: int, vocabulary size. Returns: logits: A Tensor with shape [batch, p0, p1, ?, vocab_size].", "response": "def symbol_top(body_output, targets, model_hparams, vocab_size):\n  \"\"\"Generate logits.\n\n  Args:\n    body_output: A Tensor with shape\n      [batch, p0, p1, model_hparams.hidden_size].\n    targets: Unused.\n    model_hparams: HParams, model hyperparmeters.\n    vocab_size: int, vocabulary size.\n\n  Returns:\n    logits: A Tensor with shape  [batch, p0, p1, ?, vocab_size].\n  \"\"\"\n  del targets  # unused arg\n  if model_hparams.shared_embedding_and_softmax_weights:\n    scope_name = \"shared\"\n    reuse = tf.AUTO_REUSE\n  else:\n    scope_name = \"softmax\"\n    reuse = False\n  with tf.variable_scope(scope_name, reuse=reuse):\n    body_output_shape = common_layers.shape_list(body_output)\n    var = get_weights(model_hparams, vocab_size, body_output_shape[-1])\n    if (model_hparams.factored_logits and\n        model_hparams.mode == tf.estimator.ModeKeys.TRAIN):\n      # insert channels dimension\n      body_output = tf.expand_dims(body_output, 3)\n      return common_layers.FactoredTensor(body_output, var)\n    else:\n      body_output = tf.reshape(body_output, [-1, body_output_shape[-1]])\n      logits = tf.matmul(body_output, var, transpose_b=True)\n      return tf.reshape(logits,\n                        body_output_shape[:-1] + [1, vocab_size])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef video_top(body_output, targets, model_hparams, vocab_size):\n  del targets  # unused arg\n  num_channels = model_hparams.problem.num_channels\n  shape = common_layers.shape_list(body_output)\n  reshape_shape = shape[:-1] + [num_channels, vocab_size]\n  res = tf.reshape(body_output, reshape_shape)\n  # Calculate argmax so as to have a summary with the produced images.\n  x = tf.argmax(tf.reshape(res, [-1, vocab_size]), axis=-1)\n  x = tf.reshape(x, shape[:-1] + [num_channels])\n  common_video.gif_summary(\"results\", x, max_outputs=1)\n  return res", "response": "Top transformation for video."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntops transformation for video.", "response": "def video_l1_top(body_output, targets, model_hparams, vocab_size):\n  \"\"\"Top transformation for video.\"\"\"\n  del targets, vocab_size  # unused arg\n  num_channels = model_hparams.problem.num_channels\n  num_frames = model_hparams.video_num_target_frames\n  with tf.variable_scope(\"rgb\"):\n    body_output_shape = common_layers.shape_list(body_output)\n    res = tf.layers.dense(body_output, num_channels * num_frames, name=\"cast\")\n    res = tf.reshape(res, body_output_shape[:3] + [num_channels, num_frames])\n    res = tf.transpose(res, [0, 4, 1, 2, 3])  # Move frames next to batch.\n    if not tf.get_variable_scope().reuse:\n      res_argmax = res[:, -1, :, :, :]\n      tf.summary.image(\n          \"result\",\n          common_layers.tpu_safe_image_summary(res_argmax),\n          max_outputs=1)\n    return tf.expand_dims(res, axis=-1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets default bottom transformation for given modality type.", "response": "def get_bottom(modality_type, value=None):\n  \"\"\"Gets default bottom transformation; if none available, return value.\"\"\"\n  if modality_type == ModalityType.AUDIO:\n    return audio_bottom\n  elif modality_type == ModalityType.AUDIO_SPECTRAL:\n    return audio_spectral_bottom\n  elif modality_type in (ModalityType.CLASS_LABEL,\n                         ModalityType.MULTI_LABEL,\n                         ModalityType.ONE_HOT_CLASS_LABEL,\n                         ModalityType.SIGMOID_CLASS_LABEL,\n                         ModalityType.SIGMOID_MAX_POOLING_CLASS_LABEL,\n                         ModalityType.SOFTMAX_AVERAGE_POOLING_CLASS_LABEL,\n                         ModalityType.SOFTMAX_LAST_TIMESTEP_CLASS_LABEL,\n                         ModalityType.SOFTMAX_MAX_POOLING_CLASS_LABEL):\n    return class_label_bottom\n  elif modality_type in (ModalityType.CTC_SYMBOL,\n                         ModalityType.SYMBOL,\n                         ModalityType.SYMBOL_WEIGHTS_ALL):\n    return symbol_bottom\n  elif modality_type in (ModalityType.GENERIC_L2_LOSS,\n                         ModalityType.IDENTITY,\n                         ModalityType.IDENTITY_SYMBOL,\n                         ModalityType.IMAGE_CHANNEL_EMBEDDINGS_BOTTOM):\n    return identity_bottom\n  elif modality_type == ModalityType.IMAGE:\n    return image_bottom\n  elif modality_type in (ModalityType.IMAGE_CHANNEL_BOTTOM_IDENTITY,\n                         ModalityType.IMAGE_CHANNEL_COMPRESS):\n    return image_channel_compress_bottom\n  elif modality_type in (ModalityType.REAL,\n                         ModalityType.REAL_L2_LOSS,\n                         ModalityType.REAL_LOG_POISSON_LOSS):\n    return real_bottom\n  elif modality_type == ModalityType.SPEECH_RECOGNITION:\n    return speech_recognition_bottom\n  elif modality_type == ModalityType.SYMBOL_ONE_HOT:\n    return symbol_one_hot_bottom\n  elif modality_type in (ModalityType.VIDEO,\n                         ModalityType.VIDEO_L1,\n                         ModalityType.VIDEO_L2):\n    return video_bottom\n  elif modality_type == ModalityType.VIDEO_BITWISE:\n    return video_bitwise_bottom\n  elif modality_type == ModalityType.VIDEO_IDENTITY:\n    return video_identity_bottom\n  elif modality_type in (ModalityType.VIDEO_L1_RAW,\n                         ModalityType.VIDEO_L2_RAW):\n    return video_raw_bottom\n  elif modality_type == ModalityType.VIDEO_PIXEL_NOISE:\n    return video_pixel_noise_bottom\n  return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget default loss transformation for given modality type.", "response": "def get_loss(modality_type, value=None):\n  \"\"\"Gets default loss transformation; if none available, return value.\"\"\"\n  if modality_type in (ModalityType.AUDIO,\n                       ModalityType.AUDIO_SPECTRAL,\n                       ModalityType.CLASS_LABEL,\n                       ModalityType.IDENTITY,\n                       ModalityType.IDENTITY_SYMBOL,\n                       ModalityType.IMAGE,\n                       ModalityType.IMAGE_CHANNEL_BOTTOM_IDENTITY,\n                       ModalityType.IMAGE_CHANNEL_COMPRESS,\n                       ModalityType.IMAGE_CHANNEL_EMBEDDINGS_BOTTOM,\n                       ModalityType.REAL,\n                       ModalityType.SPEECH_RECOGNITION,\n                       ModalityType.SYMBOL,\n                       ModalityType.SYMBOL_WEIGHTS_ALL):\n    return generic_loss\n  elif modality_type == ModalityType.CTC_SYMBOL:\n    return ctc_symbol_loss\n  elif modality_type == ModalityType.GENERIC_L2_LOSS:\n    return generic_l2_loss\n  elif modality_type == ModalityType.MULTI_LABEL:\n    return multi_label_loss\n  elif modality_type in (ModalityType.ONE_HOT_CLASS_LABEL,\n                         ModalityType.SOFTMAX_AVERAGE_POOLING_CLASS_LABEL,\n                         ModalityType.SOFTMAX_LAST_TIMESTEP_CLASS_LABEL,\n                         ModalityType.SOFTMAX_MAX_POOLING_CLASS_LABEL):\n    return one_hot_class_label_loss\n  elif modality_type == ModalityType.REAL_L2_LOSS:\n    return real_l2_loss\n  elif modality_type == ModalityType.REAL_LOG_POISSON_LOSS:\n    return real_log_poisson_loss\n  elif modality_type == ModalityType.SIGMOID_CLASS_LABEL:\n    return sigmoid_class_label_loss\n  elif modality_type == ModalityType.SIGMOID_MAX_POOLING_CLASS_LABEL:\n    return sigmoid_max_pooling_class_label_loss\n  elif modality_type == ModalityType.SYMBOL_ONE_HOT:\n    return symbol_one_hot_loss\n  elif modality_type in (ModalityType.VIDEO,\n                         ModalityType.VIDEO_BITWISE,\n                         ModalityType.VIDEO_PIXEL_NOISE):\n    return video_loss\n  elif modality_type == ModalityType.VIDEO_IDENTITY:\n    return video_identity_loss\n  elif modality_type == ModalityType.VIDEO_L1:\n    return video_l1_loss\n  elif modality_type == ModalityType.VIDEO_L1_RAW:\n    return video_l1_raw_loss\n  elif modality_type == ModalityType.VIDEO_L2:\n    return video_l2_loss\n  elif modality_type == ModalityType.VIDEO_L2_RAW:\n    return video_l2_raw_loss\n  return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_name(modality_type, value=None):\n  # For legacy reasons, modalities vary in their naming scheme. Future plans are\n  # to remove any need for get_name. We do not recommend using it.\n  if modality_type == ModalityType.AUDIO:\n    return lambda model_hparams, vocab_size: \"audio_modality\"\n  elif modality_type == ModalityType.AUDIO_SPECTRAL:\n    return lambda model_hparams, vocab_size: \"audio_spectral_modality\"\n  elif modality_type == ModalityType.GENERIC_L2_LOSS:\n    return lambda model_hparams, vocab_size: \"generic_l2_loss_modality\"\n  elif modality_type == ModalityType.IDENTITY:\n    return lambda model_hparams, vocab_size: \"identity_modality\"\n  elif modality_type == ModalityType.IMAGE:\n    return lambda model_hparams, vocab_size: \"image_modality\"\n  elif modality_type == ModalityType.IMAGE_CHANNEL_BOTTOM_IDENTITY:\n    return (lambda model_hparams, vocab_size:  # pylint: disable=g-long-lambda\n            \"image_channel_bottom_identity_modality\")\n  elif modality_type == ModalityType.IMAGE_CHANNEL_COMPRESS:\n    return lambda model_hparams, vocab_size: \"image_channel_compress_modality\"\n  elif modality_type == ModalityType.IMAGE_CHANNEL_EMBEDDINGS_BOTTOM:\n    return lambda model_hparams, vocab_size: \"image_channel_embeddings_bottom\"\n  elif modality_type == ModalityType.REAL:\n    return lambda model_hparams, vocab_size: \"real_modality\"\n  elif modality_type == ModalityType.REAL_L2_LOSS:\n    return lambda model_hparams, vocab_size: \"real_l2_loss_modality\"\n  elif modality_type == ModalityType.REAL_LOG_POISSON_LOSS:\n    return lambda model_hparams, vocab_size: \"real_log_poisson_loss_modality\"\n  elif modality_type == ModalityType.SPEECH_RECOGNITION:\n    return lambda model_hparams, vocab_size: \"speech_recognition_modality\"\n  elif modality_type == ModalityType.VIDEO:\n    return lambda model_hparams, vocab_size: \"video_modality\"\n  elif modality_type == ModalityType.VIDEO_BITWISE:\n    return lambda model_hparams, vocab_size: \"video_modality_bitwise\"\n  elif modality_type == ModalityType.VIDEO_IDENTITY:\n    return lambda model_hparams, vocab_size: \"video_modality_identity\"\n  elif modality_type == ModalityType.VIDEO_L1:\n    return lambda model_hparams, vocab_size: \"video_modality_l1\"\n  elif modality_type == ModalityType.VIDEO_L1_RAW:\n    return lambda model_hparams, vocab_size: \"video_modality_l1_raw\"\n  elif modality_type == ModalityType.VIDEO_L2:\n    return lambda model_hparams, vocab_size: \"video_modality_l2\"\n  elif modality_type == ModalityType.VIDEO_L2_RAW:\n    return lambda model_hparams, vocab_size: \"video_modality_l2_raw\"\n  elif modality_type == ModalityType.VIDEO_PIXEL_NOISE:\n    return lambda model_hparams, vocab_size: \"video_modality_pixel_noise\"\n  elif modality_type in (ModalityType.CLASS_LABEL,\n                         ModalityType.MULTI_LABEL,\n                         ModalityType.ONE_HOT_CLASS_LABEL):\n    def name(model_hparams, vocab_size):\n      return \"class_label_modality_%d_%d\" % (vocab_size,\n                                             model_hparams.hidden_size)\n    return name\n  elif modality_type in (ModalityType.CTC_SYMBOL,\n                         ModalityType.IDENTITY_SYMBOL,\n                         ModalityType.SYMBOL,\n                         ModalityType.SYMBOL_WEIGHTS_ALL,\n                         ModalityType.SYMBOL_ONE_HOT):\n    def name(model_hparams, vocab_size):\n      return \"symbol_modality_%d_%d\" % (vocab_size, model_hparams.hidden_size)\n    return name\n  elif modality_type == ModalityType.SIGMOID_CLASS_LABEL:\n    def name(model_hparams, vocab_size):\n      return \"sigmoid_class_symbol_modality_%d_%d\" % (vocab_size,\n                                                      model_hparams.hidden_size)\n    return name\n  elif modality_type == ModalityType.SIGMOID_MAX_POOLING_CLASS_LABEL:\n    def name(model_hparams, vocab_size):\n      return \"sigmoid_max_pooling_class_symbol_modality_%d_%d\" % (\n          vocab_size, model_hparams.hidden_size)\n    return name\n  elif modality_type == ModalityType.SOFTMAX_AVERAGE_POOLING_CLASS_LABEL:\n    def name(model_hparams, vocab_size):\n      return \"softmax_average_pooling_onehot_class_label_modality_%d_%d\" % (\n          vocab_size, model_hparams.hidden_size)\n    return name\n  elif modality_type == ModalityType.SOFTMAX_LAST_TIMESTEP_CLASS_LABEL:\n    def name(model_hparams, vocab_size):\n      return \"softmax_last_timestep_onehot_class_label_modality_%d_%d\" % (\n          vocab_size, model_hparams.hidden_size)\n    return name\n  elif modality_type == ModalityType.SOFTMAX_MAX_POOLING_CLASS_LABEL:\n    def name(model_hparams, vocab_size):\n      return \"softmax_max_pooling_onehot_class_label_modality_%d_%d\" % (\n          vocab_size, model_hparams.hidden_size)\n    return name\n  return value", "response": "Gets default name for transformations ; if none available return value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting default bottom transformation for targets ; if none return value.", "response": "def get_targets_bottom(modality_type, value=None):\n  \"\"\"Gets default bottom transformation for targets; if none, return value.\"\"\"\n  if modality_type == ModalityType.AUDIO:\n    return make_targets_bottom(audio_bottom)\n  elif modality_type == ModalityType.AUDIO_SPECTRAL:\n    return make_targets_bottom(audio_spectral_bottom)\n  elif modality_type in (ModalityType.CLASS_LABEL,\n                         ModalityType.MULTI_LABEL,\n                         ModalityType.ONE_HOT_CLASS_LABEL,\n                         ModalityType.SIGMOID_CLASS_LABEL,\n                         ModalityType.SIGMOID_MAX_POOLING_CLASS_LABEL,\n                         ModalityType.SOFTMAX_AVERAGE_POOLING_CLASS_LABEL,\n                         ModalityType.SOFTMAX_LAST_TIMESTEP_CLASS_LABEL,\n                         ModalityType.SOFTMAX_MAX_POOLING_CLASS_LABEL):\n    return class_label_targets_bottom\n  elif modality_type in (ModalityType.CTC_SYMBOL,\n                         ModalityType.SYMBOL,\n                         ModalityType.SYMBOL_WEIGHTS_ALL):\n    return symbol_targets_bottom\n  elif modality_type in (ModalityType.GENERIC_L2_LOSS,\n                         ModalityType.IDENTITY_SYMBOL):\n    return identity_bottom\n  elif modality_type == ModalityType.IDENTITY:\n    return make_targets_bottom(identity_bottom)\n  elif modality_type == ModalityType.IMAGE:\n    return image_targets_bottom\n  elif modality_type in (ModalityType.IMAGE_CHANNEL_BOTTOM_IDENTITY,\n                         ModalityType.IMAGE_CHANNEL_COMPRESS):\n    return image_channel_compress_targets_bottom\n  elif modality_type == ModalityType.IMAGE_CHANNEL_EMBEDDINGS_BOTTOM:\n    return image_channel_embeddings_bottom\n  elif modality_type in (ModalityType.REAL,\n                         ModalityType.REAL_L2_LOSS,\n                         ModalityType.REAL_LOG_POISSON_LOSS):\n    return make_targets_bottom(real_bottom)\n  elif modality_type == ModalityType.SPEECH_RECOGNITION:\n    return make_targets_bottom(speech_recognition_bottom)\n  elif modality_type == ModalityType.SYMBOL_ONE_HOT:\n    return symbol_one_hot_bottom\n  elif modality_type in (ModalityType.VIDEO,\n                         ModalityType.VIDEO_L1,\n                         ModalityType.VIDEO_L2):\n    return video_targets_bottom\n  elif modality_type == ModalityType.VIDEO_BITWISE:\n    return video_bitwise_targets_bottom\n  elif modality_type == ModalityType.VIDEO_IDENTITY:\n    return video_identity_targets_bottom\n  elif modality_type in (ModalityType.VIDEO_L1_RAW,\n                         ModalityType.VIDEO_L2_RAW):\n    return video_raw_targets_bottom\n  elif modality_type == ModalityType.VIDEO_PIXEL_NOISE:\n    return make_targets_bottom(video_pixel_noise_bottom)\n  return value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_top(modality_type, value=None):\n  if modality_type in (ModalityType.AUDIO,\n                       ModalityType.AUDIO_SPECTRAL,\n                       ModalityType.GENERIC_L2_LOSS,\n                       ModalityType.IDENTITY,\n                       ModalityType.IDENTITY_SYMBOL,\n                       ModalityType.IMAGE_CHANNEL_BOTTOM_IDENTITY,\n                       ModalityType.SPEECH_RECOGNITION,\n                       ModalityType.VIDEO_IDENTITY):\n    return identity_top\n  elif modality_type in (ModalityType.CLASS_LABEL,\n                         ModalityType.MULTI_LABEL,\n                         ModalityType.ONE_HOT_CLASS_LABEL,\n                         ModalityType.SIGMOID_CLASS_LABEL):\n    return class_label_top\n  elif modality_type in (ModalityType.CTC_SYMBOL,\n                         ModalityType.SYMBOL,\n                         ModalityType.SYMBOL_WEIGHTS_ALL):\n    return symbol_top\n  elif modality_type == ModalityType.IMAGE:\n    return image_top\n  elif modality_type == ModalityType.IMAGE_CHANNEL_COMPRESS:\n    return image_channel_compress_top\n  elif modality_type == ModalityType.IMAGE_CHANNEL_EMBEDDINGS_BOTTOM:\n    return image_channel_embeddings_top\n  elif modality_type in (ModalityType.REAL,\n                         ModalityType.REAL_L2_LOSS,\n                         ModalityType.REAL_LOG_POISSON_LOSS):\n    return real_top\n  elif modality_type == ModalityType.SIGMOID_MAX_POOLING_CLASS_LABEL:\n    return sigmoid_max_pooling_class_label_top\n  elif modality_type == ModalityType.SOFTMAX_AVERAGE_POOLING_CLASS_LABEL:\n    return softmax_average_pooling_class_label_top\n  elif modality_type == ModalityType.SOFTMAX_LAST_TIMESTEP_CLASS_LABEL:\n    return softmax_last_timestep_class_label_top\n  elif modality_type == ModalityType.SOFTMAX_MAX_POOLING_CLASS_LABEL:\n    return softmax_max_pooling_class_label_top\n  elif modality_type == ModalityType.SYMBOL_ONE_HOT:\n    return symbol_one_hot_top\n  elif modality_type in (ModalityType.VIDEO,\n                         ModalityType.VIDEO_BITWISE,\n                         ModalityType.VIDEO_PIXEL_NOISE):\n    return video_top\n  elif modality_type in (ModalityType.VIDEO_L1,\n                         ModalityType.VIDEO_L2):\n    return video_l1_top\n  elif modality_type in (ModalityType.VIDEO_L1_RAW,\n                         ModalityType.VIDEO_L2_RAW):\n    return video_raw_top\n  return value", "response": "Gets default top transformation for given modality type."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget default weights function ; if none available return value.", "response": "def get_weights_fn(modality_type, value=None):\n  \"\"\"Gets default weights function; if none available, return value.\"\"\"\n  if modality_type in (ModalityType.CTC_SYMBOL,\n                       ModalityType.IDENTITY_SYMBOL,\n                       ModalityType.MULTI_LABEL,\n                       ModalityType.SYMBOL,\n                       ModalityType.SYMBOL_ONE_HOT):\n    return common_layers.weights_nonzero\n  elif modality_type in ModalityType.get_choices():\n    return common_layers.weights_all\n  return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating all possible pair combinations for the input list of sentences.", "response": "def create_combination(list_of_sentences):\n  \"\"\"Generates all possible pair combinations for the input list of sentences.\n\n  For example:\n\n  input = [\"paraphrase1\", \"paraphrase2\", \"paraphrase3\"]\n\n  output = [(\"paraphrase1\", \"paraphrase2\"),\n            (\"paraphrase1\", \"paraphrase3\"),\n            (\"paraphrase2\", \"paraphrase3\")]\n\n  Args:\n    list_of_sentences: the list of input sentences.\n  Returns:\n    the list of all possible sentence pairs.\n  \"\"\"\n  num_sentences = len(list_of_sentences) - 1\n  combinations = []\n  for i, _ in enumerate(list_of_sentences):\n    if i == num_sentences:\n      break\n    num_pairs = num_sentences - i\n    populated = num_pairs * [list_of_sentences[i]]\n    zipped = list(zip(populated, list_of_sentences[i + 1:]))\n    combinations += zipped\n  return combinations"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset of hyperparameters for 2D image transformer.", "response": "def image_transformer2d_base():\n  \"\"\"Set of hyperparameters.\"\"\"\n  hparams = common_hparams.basic_params1()\n  hparams.hidden_size = 512\n  hparams.batch_size = 1\n  hparams.max_length = 256\n  hparams.dropout = 0.0\n  hparams.clip_grad_norm = 0.  # i.e. no gradient clipping\n  hparams.optimizer_adam_epsilon = 1e-9\n  hparams.learning_rate_decay_scheme = \"noam\"\n  hparams.learning_rate = 0.1\n  hparams.learning_rate_warmup_steps = 4000\n  hparams.initializer_gain = 0.2\n  hparams.initializer = \"uniform_unit_scaling\"\n  hparams.weight_decay = 0.0\n  hparams.optimizer_adam_beta1 = 0.9\n  hparams.optimizer_adam_beta2 = 0.98\n  hparams.label_smoothing = 0.0\n  hparams.bottom[\"targets\"] = modalities.make_targets_bottom(\n      modalities.image_channel_embeddings_bottom)\n  hparams.top[\"targets\"] = modalities.identity_top\n  hparams.norm_type = \"layer\"\n  hparams.layer_prepostprocess_dropout = 0.0\n  hparams.add_hparam(\"filter_size\", 512)  # Add new ones like this.\n\n  # attention-related flags\n  hparams.add_hparam(\"num_heads\", 8)\n  hparams.add_hparam(\"attention_key_channels\", 0)\n  hparams.add_hparam(\"attention_value_channels\", 0)\n  hparams.add_hparam(\"ffn_layer\", \"conv_hidden_relu\")\n  # All hyperparameters ending in \"dropout\" are automatically set to 0.0\n  # when not in training mode.\n  hparams.add_hparam(\"attention_dropout\", 0.0)\n  hparams.add_hparam(\"relu_dropout\", 0.0)\n  hparams.add_hparam(\"pos\", \"timing\")  # timing, none\n  hparams.add_hparam(\"nbr_decoder_problems\", 1)\n  hparams.add_hparam(\"num_output_layers\", 3)\n  hparams.add_hparam(\"block_size\", 1)\n\n  # image size related flags\n  # assuming that the image has same height and width\n  hparams.add_hparam(\"img_len\", 32)\n  hparams.add_hparam(\"num_channels\", 3)\n  # Local attention params\n  hparams.add_hparam(\"local_and_global_att\", False)\n  hparams.add_hparam(\"block_length\", 256)\n  hparams.add_hparam(\"block_width\", 128)\n  # Local 2D attention params\n  hparams.add_hparam(\"query_shape\", (16, 16))\n  hparams.add_hparam(\"memory_flange\", (16, 32))\n  hparams.add_hparam(\"num_encoder_layers\", 4)\n  hparams.add_hparam(\"num_decoder_layers\", 8)\n  # attention type related params\n  hparams.add_hparam(\"enc_attention_type\", cia.AttentionType.GLOBAL)\n  hparams.add_hparam(\"dec_attention_type\", cia.AttentionType.LOCAL_2D)\n  hparams.add_hparam(\"block_raster_scan\", False)\n\n  # multipos attention params\n  hparams.add_hparam(\"q_filter_width\", 1)\n  hparams.add_hparam(\"kv_filter_width\", 1)\n\n  hparams.add_hparam(\"unconditional\", False)  # unconditional generation\n\n  # relative embedding hparams\n  hparams.add_hparam(\"shared_rel\", False)\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef imagetransformer_base_10l_8h_big_uncond_dr03_dan_64_2d():\n  hparams = image_transformer2d_base()\n  hparams.unconditional = True\n  hparams.hidden_size = 512\n  hparams.batch_size = 1\n  hparams.img_len = 64\n  hparams.num_heads = 8\n  hparams.filter_size = 2048\n  hparams.batch_size = 1\n  hparams.max_length = 3075\n  hparams.max_length = 14000\n  hparams.layer_preprocess_sequence = \"none\"\n  hparams.layer_postprocess_sequence = \"dan\"\n  hparams.layer_prepostprocess_dropout = 0.1\n  hparams.dec_attention_type = cia.AttentionType.LOCAL_2D\n  hparams.query_shape = (16, 16)\n  hparams.memory_flange = (8, 8)\n  return hparams", "response": "big 1d model for unconditional generation on imagenet."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbasing params for img2img 2d attention.", "response": "def img2img_transformer2d_base():\n  \"\"\"Base params for img2img 2d attention.\"\"\"\n  hparams = image_transformer2d_base()\n  # learning related flags\n  hparams.layer_preprocess_sequence = \"n\"\n  hparams.layer_postprocess_sequence = \"da\"\n  # This version seems to benefit from a higher learning rate.\n  hparams.learning_rate = 0.2\n  hparams.layer_prepostprocess_dropout = 0.1\n  hparams.learning_rate_warmup_steps = 12000\n  hparams.filter_size = 2048\n  hparams.num_encoder_layers = 4\n  hparams.num_decoder_layers = 8\n  hparams.bottom[\"inputs\"] = modalities.image_channel_embeddings_bottom\n  hparams.dec_attention_type = cia.AttentionType.LOCAL_2D\n  hparams.block_raster_scan = True\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef img2img_transformer2d_q3():\n  hparams = img2img_transformer2d_q1()\n  hparams.batch_size = 2\n  hparams.query_shape = (8, 16)\n  hparams.memory_flange = (8, 32)\n  return hparams", "response": "Current best hparams for local 2d."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbasing params for local1d attention.", "response": "def img2img_transformer_base():\n  \"\"\"Base params for local1d attention.\"\"\"\n  hparams = image_transformer2d_base()\n  # learning related flags\n  hparams.layer_preprocess_sequence = \"n\"\n  hparams.layer_postprocess_sequence = \"da\"\n  # This version seems to benefit from a higher learning rate.\n  hparams.learning_rate = 0.2\n  hparams.layer_prepostprocess_dropout = 0.1\n  hparams.learning_rate_warmup_steps = 12000\n  hparams.filter_size = 2048\n  hparams.num_encoder_layers = 4\n  hparams.num_decoder_layers = 8\n  hparams.block_length = 256\n  hparams.block_width = 256\n  hparams.dec_attention_type = cia.AttentionType.LOCAL_1D\n  hparams.block_raster_scan = False\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef img2img_transformer_b3():\n  hparams = img2img_transformer_base()\n  hparams.batch_size = 2\n  hparams.layer_preprocess_sequence = \"none\"\n  hparams.layer_postprocess_sequence = \"dan\"\n  hparams.block_length = 128\n  hparams.sampling_temp = 0.9\n  return hparams", "response": "Current best hparams for local 1d."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef img2img_transformer_base_tpu():\n  hparams = img2img_transformer_base()\n  update_hparams_for_tpu(hparams)\n  hparams.batch_size = 2\n  hparams.num_heads = 4   # heads are expensive on tpu\n  hparams.num_decoder_layers = 8\n  hparams.num_encoder_layers = 4\n  hparams.shared_embedding_and_softmax_weights = False\n  return hparams", "response": "Hparams for training img2img_transformer on tpu."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef TransformerEncoder(vocab_size,\n                       num_classes=10,\n                       feature_depth=512,\n                       feedforward_depth=2048,\n                       num_layers=6,\n                       num_heads=8,\n                       dropout=0.1,\n                       max_len=2048,\n                       mode='train'):\n  \"\"\"Transformer encoder.\n\n  Args:\n    vocab_size: int: vocab size\n    num_classes: how many classes on output\n    feature_depth: int:  depth of embedding\n    feedforward_depth: int: depth of feed-forward layer\n    num_layers: int: number of encoder/decoder layers\n    num_heads: int: number of attention heads\n    dropout: float: dropout rate (how much to drop out)\n    max_len: int: maximum symbol length for positional encoding\n    mode: str: 'train' or 'eval'\n\n  Returns:\n    the Transformer encoder layer.\n  \"\"\"\n  input_embedding = layers.Serial(\n      layers.Embedding(feature_depth, vocab_size),\n      layers.Dropout(rate=dropout, mode=mode),\n      layers.PositionalEncoding(max_len=max_len)\n  )\n  return layers.Serial(\n      layers.Branch(),  # Branch input to create embedding and mask.\n      layers.Parallel(input_embedding, layers.PaddingMask()),\n      layers.Serial(*[EncoderLayer(feature_depth, feedforward_depth, num_heads,\n                                   dropout, mode)\n                      for _ in range(num_layers)]),\n      layers.FirstBranch(),  # Drop the mask.\n      layers.LayerNorm(),\n      layers.Mean(axis=1),  # Average on length.\n      layers.Dense(num_classes),\n      layers.LogSoftmax()\n  )", "response": "Transformer encoder.\n\n  Args:\n    vocab_size: int: vocab size\n    num_classes: how many classes on output\n    feature_depth: int:  depth of embedding\n    feedforward_depth: int: depth of feed-forward layer\n    num_layers: int: number of encoder/decoder layers\n    num_heads: int: number of attention heads\n    dropout: float: dropout rate (how much to drop out)\n    max_len: int: maximum symbol length for positional encoding\n    mode: str: 'train' or 'eval'\n\n  Returns:\n    the Transformer encoder layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef DecoderLayer(feature_depth,\n                 feedforward_depth,\n                 num_heads,\n                 dropout,\n                 mode):\n  \"\"\"Transformer decoder layer.\n\n  Args:\n    feature_depth: int:  depth of embedding\n    feedforward_depth: int: depth of feed-forward layer\n    num_heads: int: number of attention heads\n    dropout: float: dropout rate (how much to drop out)\n    mode: str: 'train' or 'eval'\n\n  Returns:\n    the layer.\n  \"\"\"\n  return layers.Serial(\n      layers.Residual(  # Self-attention block.\n          layers.LayerNorm(),\n          layers.Branch(),\n          layers.Parallel(layers.Identity(),  # activation for (q, k, v)\n                          layers.CausalMask(axis=-2)),  # attention mask\n          layers.MultiHeadedAttention(feature_depth, num_heads=num_heads,\n                                      dropout=dropout, mode=mode),\n          layers.Dropout(rate=dropout, mode=mode)\n      ),\n      ResidualFeedForward(feature_depth, feedforward_depth, dropout, mode=mode)\n  )", "response": "Transformer decoder layer.\n\n  Args:\n    feature_depth: int:  depth of embedding\n    feedforward_depth: int: depth of feed-forward layer\n    num_heads: int: number of attention heads\n    dropout: float: dropout rate (how much to drop out)\n    mode: str: 'train' or 'eval'\n\n  Returns:\n    the layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mtf_transformer_base():\n  hparams = common_hparams.basic_params1()\n  hparams.no_data_parallelism = True\n  hparams.use_fixed_batch_size = True\n  hparams.add_hparam(\"mtf_mode\", True)\n  hparams.batch_size = 64\n  hparams.max_length = 256\n  hparams.add_hparam(\"d_model\", 512)\n  hparams.add_hparam(\"d_kv\", 128)\n  hparams.add_hparam(\"local_attention_window_size\", 128)\n  hparams.label_smoothing = 0.1\n  # 8-way model-parallelism\n  hparams.add_hparam(\"mesh_shape\", \"model:8\")\n  hparams.add_hparam(\"layout\", \"batch:batch;vocab:model;d_ff:model;heads:model\")\n  hparams.add_hparam(\"num_heads\", 8)\n  hparams.add_hparam(\"d_ff\", 2048)\n  hparams.add_hparam(\"encoder_replicate_factor\", 1)\n  hparams.add_hparam(\"decoder_replicate_factor\", 1)\n  hparams.add_hparam(\"encoder_layers\", [\"att\", \"drd\"] * 6)\n  hparams.add_hparam(\"decoder_layers\", [\"att\", \"enc_att\", \"drd\"] * 6)\n  hparams.add_hparam(\"attention_dropout\", 0.1)\n  hparams.add_hparam(\"relu_dropout\", 0.1)\n  hparams.layer_prepostprocess_dropout = 0.1\n\n  # Describes what model architecture:\n  #   \"encdec\": encoder + autoregressive decoder\n  #   \"decoder\": single-stack autoregressive sequence model.\n  #   \"encoder\": single-stack non-autoregressive model\n  #      with equal-length inputs and outputs.\n  hparams.add_hparam(\"transformer_type\", \"encdec\")\n\n  # What does the decoder do:\n  #   \"autoregressive\": Decoder left to right\n  #   \"denoising\": Fills in masked-out values simultaneously\n  hparams.add_hparam(\"decoder_type\", \"autoregressive\")\n\n  # Parameters describing the noising algorithm for denoising decoders\n  hparams.add_hparam(\"noising_spec_train\", {\"type\": \"mask\", \"prob\": 0.15})\n  hparams.add_hparam(\"noising_spec_eval\", {\"type\": \"mask\", \"prob\": 0.15})\n  # during training, we use the eval noiser with this probability\n  hparams.add_hparam(\"noising_use_eval_during_train\", 0.1)\n\n  # round up vocab sizes to be a multiple of this value\n  hparams.vocab_divisor = 128\n\n  # options are dense_relu_dense, moe, hmoe\n  hparams.add_hparam(\"feedforward_layer\", \"drd\")\n\n  # If True, then reuse targets_embedding_var * rsqrt(d_model) as softmax_var\n  # If hparams.transformer_type == \"encoder\", then there is no targets embedding\n  # so we reuse the inputs embedding instead.\n  hparams.shared_embedding_and_softmax_weights = True\n  # Reuse targets_embedding_var as inputs_embedding_var\n  # relevant only if hparams.transformer_type == \"encdec\"\n  hparams.shared_embedding = True\n  hparams.optimizer = \"Adafactor\"\n  hparams.learning_rate_schedule = \"linear_warmup*rsqrt_decay*linear_decay\"\n  hparams.learning_rate_warmup_steps = 10000\n  hparams.add_hparam(\"master_dtype\", \"bfloat16\")\n  hparams.add_hparam(\"slice_dtype\", \"float32\")\n  hparams.activation_dtype = \"bfloat16\"\n\n  # These parameters make Transformer model compatible with MtfTransformer\n  # Do not override these, as mtf_transformer does not support other options.\n  hparams.clip_grad_norm = 0.  # i.e. no gradient clipping\n  hparams.bottom = {\n      \"inputs\": modalities.identity_bottom,\n      \"targets\": modalities.identity_bottom,\n  }\n  hparams.top = {\n      \"targets\": modalities.identity_top,\n  }\n\n  # Parameters for computing the maximum decode length in beam search.\n  # Maximum decode length is:\n  #    min(max_length,\n  #        decode_length_multiplier * input_length + decode_length_constant)\n  hparams.add_hparam(\"decode_length_multiplier\", 1.5)\n  hparams.add_hparam(\"decode_length_constant\", 10.0)\n\n  # If nonzero, we split the batch across two tensor-dimensions named\n  # \"outer_batch\" and \"inner_batch\", allowing for splitting across two mesh\n  # dimensions.  This is necessary for hierarchical mixture of experts.\n  # The two tensor dimensions have sizes hparams.outer_batch_size and\n  # hparams.batch_size // hparams.outer_batch_size.\n  hparams.add_hparam(\"outer_batch_size\", 0)\n\n  # TODO(noam): file a bug\n  hparams.add_hparam(\"reshape_logits_hack\", False)\n  hparams.add_hparam(\"compression_factor\", 4)\n\n  return hparams", "response": "Set of hyperparameters for Mt - Transformer model."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mtf_transformer_paper_lm(size):\n  n = 2 ** size\n  hparams = mtf_transformer_base_lm()\n  hparams.batch_size = 256\n  hparams.d_model = 1024\n  hparams.d_ff = int(8192 * n)\n  hparams.d_kv = 256\n  hparams.num_heads = int(8 * n)\n  hparams.shared_embedding_and_softmax_weights = False\n  # one epoch for languagemodel_lm1b32k_packed = 13600 steps\n  hparams.learning_rate_decay_steps = 13600\n  return hparams", "response": "Config for language - model experiments."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngraphs attention. Args: q: a Tensor with shape [batch, heads, length_q, depth_k] k: a Tensor with shape [batch, heads, length_kv, depth_k] v: a Tensor with shape [batch, heads, length_kv, depth_v] bias: bias Tensor (see attention_bias()) dropout_rate: a floating point number image_shapes: optional tuple of integer scalars. see comments for attention_image_summary() name: an optional string make_image_summary: True if you want an image summary. save_weights_to: an optional dictionary to capture attention weights for vizualization; the weights tensor will be appended there under a string key created from the variable scope (including name). dropout_broadcast_dims: an optional list of integers less than 4 specifying in which dimensions to broadcast the dropout decisions. saves memory. adjacency_matrix: optional matrix of [batch, length, length] ids indicating edge type num_edge_types: an int indicating number of edge types Returns: A Tensor of shape [batch, length, depth(q)]", "response": "def graph_attention(q,\n                    k,\n                    v,\n                    bias,\n                    dropout_rate=0.0,\n                    image_shapes=None,\n                    name=None,\n                    make_image_summary=True,\n                    save_weights_to=None,\n                    dropout_broadcast_dims=None,\n                    adjacency_matrix=None,\n                    num_edge_types=5):\n  \"\"\"graph attention.\n\n  Args:\n    q: a Tensor with shape [batch, heads, length_q, depth_k]\n    k: a Tensor with shape [batch, heads, length_kv, depth_k]\n    v: a Tensor with shape [batch, heads, length_kv, depth_v]\n    bias: bias Tensor (see attention_bias())\n    dropout_rate: a floating point number\n    image_shapes: optional tuple of integer scalars.\n      see comments for attention_image_summary()\n    name: an optional string\n    make_image_summary: True if you want an image summary.\n    save_weights_to: an optional dictionary to capture attention weights\n      for vizualization; the weights tensor will be appended there under\n      a string key created from the variable scope (including name).\n    dropout_broadcast_dims:  an optional list of integers less than 4\n      specifying in which dimensions to broadcast the dropout decisions.\n      saves memory.\n    adjacency_matrix: optional matrix of [batch, length, length] ids indicating\n      edge type\n    num_edge_types: an int indicating number of edge types\n  Returns:\n    A Tensor of shape [batch, length, depth(q)]\n  \"\"\"\n  with tf.variable_scope(\n      name, default_name=\"dot_product_attention\", values=[q, k, v]) as scope:\n    # [batch, num_heads, query_length, memory_length]\n    logits = tf.matmul(q, k, transpose_b=True)\n    if adjacency_matrix is not None:\n      key_head_depth = common_layers.shape_list(q)[-1]\n      adjacency_vectors = make_edge_vectors(\n          adjacency_matrix,\n          num_edge_types,\n          key_head_depth,\n          name=name)\n      # transposing q to be [batch, length_q, heads, depth_k]\n      # to allow for matmul with [batch, length_q, length_q, depth_k]\n      q_t = tf.transpose(q, [0, 2, 1, 3])\n      adj_logits = tf.matmul(q_t, adjacency_vectors, transpose_b=True)\n      logits += tf.transpose(adj_logits, [0, 2, 1, 3])\n      # [batch, depth, num_nodes, num_nodes]\n    if bias is not None:\n      logits += bias\n    weights = tf.nn.softmax(logits, name=\"attention_weights\")\n    if save_weights_to is not None:\n      save_weights_to[scope.name] = weights\n    # dropping out the attention links for each of the heads\n    weights = common_layers.dropout_with_broadcast_dims(\n        weights, 1.0 - dropout_rate, broadcast_dims=dropout_broadcast_dims)\n    if common_layers.should_generate_summaries() and make_image_summary:\n      common_attention.attention_image_summary(weights, image_shapes)\n    return tf.matmul(weights, v)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compute_mpnn_qkv(node_states,\n                     total_key_depth,\n                     total_value_depth,\n                     num_transforms):\n  \"\"\"Computes query, key and value for edge matrices.\n\n  Let B be the number of batches.\n  Let N be the number of nodes in the graph.\n  Let D be the size of the node hidden states.\n  Let K be the size of the attention keys/queries (total_key_depth).\n  Let V be the size of the attention values (total_value_depth).\n  Let T be the total number of transforms (num_transforms).\n\n  Computes the queries, keys, and values for attention.\n  * For each node N_i in the graph, a query Q_i of size K is computed. This\n    query is used to determine the relative weights to give to each of the\n    node's incoming edges.\n  * For each node N_j and edge type t, a key K_jt of size K is computed. When an\n    edge of type t goes from node N_j to any other node, K_jt is the key that is\n    in the attention process.\n  * For each node N_j and edge type t, a value V_jt of size V is computed. When\n    an edge of type t goes from node N_j to node N_i, Attention(Q_i, K_jt)\n    produces a weight w_ijt. The message sent along this edge is w_ijt * V_jt.\n\n  Args:\n    node_states: A Tensor with shape [B, N, D].\n    total_key_depth: an integer (K).\n    total_value_depth: an integer (V).\n    num_transforms: a integer specifying number of transforms (T). This is\n      typically the number of edge types.\n  Returns:\n    q: The attention queries for each destination node (shape [B, N, K]).\n    k: The attention keys for each node and edge type (shape [B, N*T, K]).\n    v: The attention values for each node and edge type (shape [B, N*T, V]).\n  \"\"\"\n\n  # node_states is initially a tensor with shape [B, N, D]. The call to dense\n  # creates a D x K kernel that serves as a fully-connected layer.\n  #\n  # For each possible batch b and node n in the first two dimensions of\n  # node_states, the corresponding size-D vector (the third dimension of\n  # node_states) is the hidden state for node n in batch b. Each of these size-D\n  # vectors is multiplied by the kernel to produce an attention query of size K.\n  # The result is a tensor of size [B, N, K] containing the attention queries\n  # for each node in each batch.\n  q = common_layers.dense(\n      node_states, total_key_depth, use_bias=False, name=\"q_mpnn\")\n\n  # Creates the attention keys in a manner similar to the process of creating\n  # the attention queries. One key is created for each type of outgoing edge the\n  # corresponding node might have, meaning k will have shape [B, N, K*T].\n  k = _compute_edge_transforms(node_states,\n                               total_key_depth,\n                               num_transforms,\n                               name=\"k_mpnn\")\n  v = _compute_edge_transforms(node_states,\n                               total_value_depth,\n                               num_transforms,\n                               name=\"v_mpnn\")\n\n  return q, k, v", "response": "This function computes the query key and value for edge matrices."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef multihead_mpnn_attention(node_states,\n                             total_key_depth,\n                             total_value_depth,\n                             output_depth,\n                             num_heads,\n                             adjacency_matrix=None,\n                             num_edge_types=5,\n                             num_transforms=None,\n                             use_weighted_sum=False,\n                             name=\"mpnn_attention\"):\n  \"\"\"Multihead scaled-dot-product attention with input/output transformations.\n\n  Let B be the number of batches.\n  Let N be the number of nodes in the graph.\n  Let D be the size of the node hidden states.\n  Let K be the size of the attention keys/queries (total_key_depth).\n  Let V be the size of the attention values (total_value_depth).\n  Let O be the size of the attention output (output_depth).\n  Let H be the number of heads (num_heads).\n  Let T be the total number of transforms (num_transforms).\n\n  The key and value depths are split across all of the heads. For example, if\n  the key depth is 6 and there are three heads, then the key for each head has\n  depth 2.\n\n  Args:\n    node_states: A Tensor with shape [B, N, D]\n    total_key_depth: An integer (K).\n    total_value_depth: An integer (V).\n    output_depth: An integer (O).\n    num_heads: An integer (H).\n    adjacency_matrix: An Tensor of ints with shape [B, T, N, N]. If there is an\n      edge from node j to node i in batch b, then adjacency_matrix[b, i, j]\n      contains the type of that edge as an integer. Otherwise, it contains 0.\n    num_edge_types: An integer indicating number of edge types.\n    num_transforms: An integer indicating number of transforms (T). If None,\n      then num_transforms will be equal to num_edge_types.\n    use_weighted_sum: If False, will only use a single transform per edge type.\n      Otherwise, use a learned weighted sum of transforms per edge type.\n    name: A string.\n\n  Returns:\n    The result of the attention transformation. The output shape is [B, N, O].\n\n  Raises:\n    ValueError: if the key depth or value depth are not divisible by the\n      number of attention heads.\n  \"\"\"\n  if total_key_depth % num_heads != 0:\n    raise ValueError(\"Key depth (%d) must be divisible by the number of \"\n                     \"attention heads (%d).\" % (total_key_depth, num_heads))\n  if total_value_depth % num_heads != 0:\n    raise ValueError(\"Value depth (%d) must be divisible by the number of \"\n                     \"attention heads (%d).\" % (total_value_depth, num_heads))\n  with tf.variable_scope(\n      name, default_name=\"multihead_mpnn_attention\", values=[node_states]):\n    # If not explicitly set, use num_transforms set to num_edge_types.\n    num_transforms = (\n        num_edge_types if num_transforms is None else num_transforms)\n\n    # Create the query for each node's incoming edges.\n    # Create the keys/values for each node for each possible outgoing edge type.\n    q, k, v = compute_mpnn_qkv(\n        node_states,\n        total_key_depth,\n        total_value_depth,\n        num_transforms)\n\n    q_shape = tf.shape(q)  # As above, q_shape is [B, N, K].\n\n    # Divides each query/key/value into separate heads. Specifically, the\n    # query/key/value for each (batch, node) pair (i.e., the third dimensions\n    # of q, k, and v) are broken into H separate pieces. These pieces are used\n    # as the separate attention heads. The resulting tensors have shape\n    # [B, H, N, ?/H], where ? = K, K*T or V*T as appropriate.\n    q = common_attention.split_heads(q, num_heads)  # Shape [B, H, N, K/H].\n    k = common_attention.split_heads(k, num_heads)  # Shape [B, H, N, K*T/H].\n    v = common_attention.split_heads(v, num_heads)  # Shape [B, H, N, V*T/H].\n    key_depth_per_head = total_key_depth // num_heads\n\n    # Ensures that the logits don't have too large of a magnitude.\n    q *= key_depth_per_head**-0.5\n\n    # Rearrange the dimensions so that the head is first. This will make\n    # subsequent steps easier (we loop over the head).\n    q = tf.transpose(q, [1, 0, 2, 3])  # Shape [H, B, N, K/H].\n    k = tf.transpose(k, [1, 0, 2, 3])  # Shape [H, B, N, K*T/H].\n    v = tf.transpose(v, [1, 0, 2, 3])  # Shape [H, B, N, V*T/H].\n\n    # Split the keys and values into separate per-edge-type keys and values.\n    k = tf.reshape(k, [\n        num_heads, q_shape[0], q_shape[1], num_transforms,\n        total_key_depth // num_heads\n    ])  # Shape [H, B, N, T, K/H].\n    k = tf.transpose(k, [0, 1, 3, 2, 4])  # Shape [H, B, T, N, K/H].\n\n    v = tf.reshape(v, [\n        num_heads, q_shape[0], q_shape[1], num_transforms,\n        total_value_depth // num_heads\n    ])  # Shape [H, B, N, T, V/H].\n    v = tf.transpose(v, [0, 1, 3, 2, 4])  # Shape [H, B, T, N, V/H].\n\n    # Perform attention for each head and combine the results into a list.\n    # head_outputs stores a list of tensors, each with shape [1, B, N, V/H].\n    # The last dimension contains the values computed for each attention head.\n    # Each value was determined by computing attention over all of the\n    # incoming edges for node n, weighting the incoming values accordingly,\n    # and adding those weighted values together.\n    head_outputs = []\n    for head_id in range(num_heads):\n      output = dot_product_mpnn_attention(\n          q[head_id],\n          k[head_id],\n          v[head_id],\n          adjacency_matrix,\n          num_edge_types,\n          num_transforms=num_transforms,\n          use_weighted_sum=use_weighted_sum)\n\n      # Store this result in the list of attention results for each head.\n      # The call to expand_dims gives output shape [1, B, N, V/H], which will\n      # come in handy when we combine the heads together.\n      head_outputs.append(tf.expand_dims(output, axis=0))\n\n    # Combine the heads together into one tensor and rearrange the dimensions.\n    x = tf.concat(head_outputs, axis=0)  # Shape [H, B, N, V/H].\n    x = tf.transpose(x, [1, 0, 2, 3])  # Shape [B, H, N, V/H].\n\n    # Concatenate the values produced by each head together into one vector.\n    x = common_attention.combine_heads(x)  # Shape [B, N, V].\n\n    # A fully-connected linear layer to convert from the value vectors of size V\n    # to output vectors of length O (the appropriate output length).\n    x = common_layers.dense(\n        x, output_depth, use_bias=False, name=\"output_transform\")\n    return x", "response": "Multihead scaled - dot - product attention with input and output transformations."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndots product attention with edge vectors.", "response": "def dot_product_mpnn_attention(q,\n                               k,\n                               v,\n                               adjacency_matrix,\n                               num_edge_types,\n                               num_transforms=None,\n                               use_weighted_sum=False,\n                               name=None):\n  \"\"\"Dot product attention with edge vectors.\n\n  Let B be the number of batches.\n  Let N be the number of nodes in the graph.\n  Let K be the size of the attention keys/queries.\n  Let V be the size of the attention values.\n  Let T be the total number of transforms (num_transforms).\n\n  Args:\n    q: The query Tensor of shape [B, N, K].\n    k: The key Tensor of shape [B, T, N, K].\n    v: The value Tensor of shape [B, T, N, V].\n    adjacency_matrix: A Tensor of shape [B, N, N, T]. An entry at\n      indices b, i, j, k is the indicator of the edge\n      from node j to node i in batch b. A standard adjacency matrix will only\n      have one edge type while a mutigraph will have multiple edge types.\n    num_edge_types: An integer specifying number of edge types.\n    num_transforms: An integer indicating number of transforms (T). If None,\n      then num_transforms will be equal to num_edge_types.\n    use_weighted_sum: If False, will only use a single transform per edge type.\n      Otherwise, use a learned weighted sum of transforms per edge type.\n    name: A string.\n\n  Returns:\n    A Tensor of shape [B, N, V] storing the result of computing attention\n    weights using the queries and keys and combining the values according to\n    those weights.\n\n  Raises:\n    ValueError: if num_transforms doesn't equal num_edge_types and not using\n      weighted sum.\n  \"\"\"\n  with tf.variable_scope(\n      name,\n      default_name=\"dot_product_mpnn_attention\",\n      values=[q, k, v, adjacency_matrix, num_edge_types]):\n    # If not explicitly set, use num_transforms set to num_edge_types.\n    num_transforms = (\n        num_edge_types if num_transforms is None else num_transforms)\n\n    if not use_weighted_sum and num_transforms != num_edge_types:\n      raise ValueError(\"num_transforms must equal num_edge_types unless \"\n                       \"use_weighted_sum is True\")\n\n    # Computes the raw dot-product attention values between each query and\n    # the corresponding keys it needs to consider.\n    #\n    # This operation takes the dot product of (the query for\n    # each node) and (the key for each node for each possible edge type),\n    # creating an N x N matrix for each edge type. The entry at index (i, j)\n    # is the dot-product for the edge from node i to node j of the appropriate\n    # type. These dot products will eventually become attention weights\n    # specifying how much node i weights an edge of that type coming from node\n    # j.\n    all_edge_logits = tf.matmul(\n        tf.tile(tf.expand_dims(q, axis=1), [1, num_edge_types, 1, 1]),\n        k,\n        transpose_b=True)\n\n    # The adjacency matrix assumes there is only one directed edge (i <- j) for\n    # each pair of nodes. If such an edge exists, it contains the integer\n    # type of that edge at position (i, j) of the adjacency matrix.\n    #\n    # Construct edge_vectors of shape [B, N, N, T].\n    if use_weighted_sum:\n      # Use dense representation for edge vectors.\n      edge_vectors = make_edge_vectors(\n          adjacency_matrix,\n          num_edge_types,\n          num_transforms)\n    else:\n      # Generate one-hot vectors based on edge types.\n      # If there is an edge from node j to node i of type t, then index t of the\n      # last dimension is 1 for entry (i, j) of the second and third dimensions.\n      edge_vectors = tf.one_hot(adjacency_matrix, num_transforms)\n\n    # Rearranging the dimensions to match the shape of all_edge_logits.\n    edge_vectors = tf.transpose(edge_vectors, [0, 3, 1, 2])\n\n    # Element-wise multiplies all_edge_logits and edge_vectors.\n    #\n    # In other words: all_edge_logits contains N x N matrices of query-key\n    # products. This element-wise multiplication zeroes out entries that do not\n    # correspond to actual edges in the graph of the appropriate edge type.\n    # all_edge_logits retains shape [B, T, N, N].\n    all_edge_logits *= edge_vectors\n\n    # Since there can only be one edge from node A to node B, we can collapse\n    # the T different adjacency matrices containing key-query pairs into one\n    # adjacency matrix. logits is [B, N, N].\n    # TODO(dbieber): Use a reshape instead of reduce sum to attend over all\n    # edges instead of over all neighboring nodes to handle the multigraph case.\n    logits = tf.reduce_sum(all_edge_logits, axis=1)\n\n    # For pairs of nodes with no edges between them, add a large negative bias\n    # to each location without an edge so that the softmax of entries with the\n    # value 0 become a small negative number instead.\n    bias = 0\n    bias = tf.to_float(tf.equal(\n        tf.reduce_sum(adjacency_matrix, axis=-1), 0)) * -1e9\n    logits += bias\n\n    # Turn the raw key-query products into a probability distribution (or,\n    # in terms of attention, weights). The softmax is computed across the\n    # last dimension of logits.\n    compatibility = tf.nn.softmax(logits)  # Shape [B, N, N].\n\n    # Computes a summary showing the attention matrix as an image. Does not do\n    # any work toward actually performing attention.\n    common_attention.attention_image_summary(\n        tf.expand_dims(compatibility, axis=1), None)\n\n    # Repeats the attention matrix T times for each batch, producing\n    # a tensor with shape [B, T, N, N] where the [N, N] component is T\n    # repeats of the values found in compatibility.\n    edge_compatibility = tf.tile(\n        tf.expand_dims(compatibility, axis=1), [1, num_edge_types, 1, 1])\n\n    # Zeroes out the entries in edge_compatibility that do not correspond to\n    # actual edges.\n    edge_compatibility *= edge_vectors  # Shape [B, T, N, N].\n\n    output = compute_values(edge_compatibility, v)\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes values for ggnn. a .", "response": "def compute_values(edge_compatibility, v):\n  \"\"\"Compute values. If edge compatibilities is just adjacency, we get ggnn.\n\n  Args:\n    edge_compatibility: A tensor of shape [batch, num_transforms, length, depth]\n    v: A tensor of shape [batch, num_transforms, length, depth]\n\n  Returns:\n    output: A [batch, length, depth] tensor\n  \"\"\"\n\n  # Computes the incoming value vectors for each node by weighting them\n  # according to the attention weights. These values are still segregated by\n  # edge type.\n  # Shape = [B, T, N, V].\n  all_edge_values = tf.matmul(tf.to_float(edge_compatibility), v)\n\n  # Combines the weighted value vectors together across edge types into a\n  # single N x V matrix for each batch.\n  output = tf.reduce_sum(all_edge_values, axis=1)  # Shape [B, N, V].\n  return output"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef precompute_edge_matrices(adjacency, hparams):\n  batch_size, num_nodes, _, edge_dim = common_layers.shape_list(adjacency)\n\n  # build the edge_network for incoming edges\n  with tf.variable_scope(\"edge_network\"):\n    x = tf.reshape(\n        adjacency, [batch_size * num_nodes * num_nodes, edge_dim],\n        name=\"adj_reshape_in\")\n\n    for ip_layer in range(hparams.edge_network_layers):\n      name = \"edge_network_layer_%d\"%ip_layer\n      x = tf.layers.dense(common_layers.layer_preprocess(x, hparams),\n                          hparams.edge_network_hidden_size,\n                          activation=tf.nn.relu,\n                          name=name)\n    x = tf.layers.dense(common_layers.layer_preprocess(x, hparams),\n                        hparams.hidden_size**2,\n                        activation=None,\n                        name=\"edge_network_output\")\n\n  # x = [batch * l * l, d *d]\n  edge_matrices_flat = tf.reshape(x, [batch_size, num_nodes,\n                                      num_nodes, hparams.hidden_size,\n                                      hparams.hidden_size])\n\n  # reshape to [batch, l * d, l *d]\n  edge_matrices = tf.reshape(\n      tf.transpose(edge_matrices_flat, [0, 1, 3, 2, 4]), [\n          -1, num_nodes * hparams.hidden_size,\n          num_nodes * hparams.hidden_size\n      ],\n      name=\"edge_matrices\")\n\n  return edge_matrices", "response": "Precompute the edge_matrices for the object passing."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute a_t from h_t from node_states and edge_matrices.", "response": "def dense_message_pass(node_states, edge_matrices):\n  \"\"\"Computes a_t from h_{t-1}, see bottom of page 3 in the paper.\n\n  Args:\n    node_states: [B, L, D] tensor (h_{t-1})\n    edge_matrices (tf.float32): [B, L*D, L*D]\n\n  Returns:\n    messages (tf.float32): [B, L, D] For each pair\n      of nodes in the graph a message is sent along both the incoming and\n      outgoing edge.\n  \"\"\"\n  batch_size, num_nodes, node_dim = common_layers.shape_list(node_states)\n\n  # Stack the nodes as a big column vector.\n  h_flat = tf.reshape(\n      node_states, [batch_size, num_nodes * node_dim, 1], name=\"h_flat\")\n\n  messages = tf.reshape(\n      tf.matmul(edge_matrices, h_flat), [batch_size * num_nodes, node_dim],\n      name=\"messages_matmul\")\n\n  message_bias = tf.get_variable(\"message_bias\", shape=node_dim)\n  messages = messages + message_bias\n  messages = tf.reshape(messages, [batch_size, num_nodes, node_dim])\n  return messages"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_example(dictionary):\n  features = {}\n  for (k, v) in six.iteritems(dictionary):\n    if not v:\n      raise ValueError(\"Empty generated field: %s\" % str((k, v)))\n    if isinstance(v[0], six.integer_types):\n      features[k] = tf.train.Feature(int64_list=tf.train.Int64List(value=v))\n    elif isinstance(v[0], float):\n      features[k] = tf.train.Feature(float_list=tf.train.FloatList(value=v))\n    elif isinstance(v[0], six.string_types):\n      if not six.PY2:  # Convert in python 3.\n        v = [bytes(x, \"utf-8\") for x in v]\n      features[k] = tf.train.Feature(bytes_list=tf.train.BytesList(value=v))\n    elif isinstance(v[0], bytes):\n      features[k] = tf.train.Feature(bytes_list=tf.train.BytesList(value=v))\n    else:\n      raise ValueError(\"Value for %s is not a recognized type; v: %s type: %s\" %\n                       (k, str(v[0]), str(type(v[0]))))\n  return tf.train.Example(features=tf.train.Features(feature=features))", "response": "Helper to build tf. Example from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating files distributed with a single writer.", "response": "def generate_files_distributed(generator,\n                               output_name,\n                               output_dir,\n                               num_shards=1,\n                               max_cases=None,\n                               task_id=0):\n  \"\"\"generate_files but with a single writer writing to shard task_id.\"\"\"\n  assert task_id < num_shards\n  output_filename = sharded_name(output_name, task_id, num_shards)\n  output_file = os.path.join(output_dir, output_filename)\n  tf.logging.info(\"Writing to file %s\", output_file)\n  writer = tf.python_io.TFRecordWriter(output_file)\n\n  counter = 0\n  for case in generator:\n    if counter % 100000 == 0:\n      tf.logging.info(\"Generating case %d for %s.\" % (counter, output_name))\n    counter += 1\n    if max_cases and counter > max_cases:\n      break\n    example = to_example(case)\n    writer.write(example.SerializeToString())\n\n  writer.close()\n  return output_file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate cases from a generator and saves as TFRecord files.", "response": "def generate_files(generator, output_filenames,\n                   max_cases=None, cycle_every_n=1):\n  \"\"\"Generate cases from a generator and save as TFRecord files.\n\n  Generated cases are transformed to tf.Example protos and saved as TFRecords\n  in sharded files named output_dir/output_name-00..N-of-00..M=num_shards.\n\n  Args:\n    generator: a generator yielding (string -> int/float/str list) dictionaries.\n    output_filenames: List of output file paths.\n    max_cases: maximum number of cases to get from the generator;\n      if None (default), we use the generator until StopIteration is raised.\n    cycle_every_n: how many cases from the generator to take before\n      switching to the next shard; by default set to 1, switch every case.\n  \"\"\"\n  if outputs_exist(output_filenames):\n    tf.logging.info(\"Skipping generator because outputs files exists at {}\"\n                    .format(output_filenames))\n    return\n  tmp_filenames = [fname + \".incomplete\" for fname in output_filenames]\n  num_shards = len(output_filenames)\n  # Check if is training or eval, ref: train_data_filenames().\n  if num_shards > 0:\n    if \"-train\" in output_filenames[0]:\n      tag = \"train\"\n    elif \"-dev\" in output_filenames[0]:\n      tag = \"eval\"\n    else:\n      tag = \"other\"\n\n  writers = [tf.python_io.TFRecordWriter(fname) for fname in tmp_filenames]\n  counter, shard = 0, 0\n  for case in generator:\n    if case is None:\n      continue\n    if counter % 100000 == 0:\n      tf.logging.info(\"Generating case %d.\" % counter)\n    counter += 1\n    if max_cases and counter > max_cases:\n      break\n    example = to_example(case)\n    writers[shard].write(example.SerializeToString())\n    if counter % cycle_every_n == 0:\n      shard = (shard + 1) % num_shards\n\n  for writer in writers:\n    writer.close()\n\n  for tmp_name, final_name in zip(tmp_filenames, output_filenames):\n    tf.gfile.Rename(tmp_name, final_name)\n\n  if num_shards > 0:\n    if tag == \"train\":\n      mlperf_log.transformer_print(\n          key=mlperf_log.PREPROC_NUM_TRAIN_EXAMPLES, value=counter)\n    elif tag == \"eval\":\n      mlperf_log.transformer_print(\n          key=mlperf_log.PREPROC_NUM_EVAL_EXAMPLES, value=counter)\n\n  tf.logging.info(\"Generated %s Examples\", counter)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreports hook for download progress.", "response": "def download_report_hook(count, block_size, total_size):\n  \"\"\"Report hook for download progress.\n\n  Args:\n    count: current block number\n    block_size: block size\n    total_size: total size\n  \"\"\"\n  percent = int(count * block_size * 100 / total_size)\n  print(\"\\r%d%%\" % percent + \" completed\", end=\"\\r\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndownload filename from uri to directory.", "response": "def maybe_download(directory, filename, uri):\n  \"\"\"Download filename from uri unless it's already in directory.\n\n  Copies a remote file to local if that local file does not already exist.  If\n  the local file pre-exists this function call, it does not check that the local\n  file is a copy of the remote.\n\n  Remote filenames can be filepaths, any URI readable by tensorflow.gfile, or a\n  URL.\n\n  Args:\n    directory: path to the directory that will be used.\n    filename: name of the file to download to (do nothing if it already exists).\n    uri: URI to copy (or download) from.\n\n  Returns:\n    The path to the downloaded file.\n  \"\"\"\n  tf.gfile.MakeDirs(directory)\n  filepath = os.path.join(directory, filename)\n  if tf.gfile.Exists(filepath):\n    tf.logging.info(\"Not downloading, file already found: %s\" % filepath)\n    return filepath\n\n  tf.logging.info(\"Downloading %s to %s\" % (uri, filepath))\n  try:\n    tf.gfile.Copy(uri, filepath)\n  except tf.errors.UnimplementedError:\n    if uri.startswith(\"http\"):\n      inprogress_filepath = filepath + \".incomplete\"\n      inprogress_filepath, _ = urllib.urlretrieve(\n          uri, inprogress_filepath, reporthook=download_report_hook)\n      # Print newline to clear the carriage return from the download progress\n      print()\n      tf.gfile.Rename(inprogress_filepath, filepath)\n    else:\n      raise ValueError(\"Unrecognized URI: \" + filepath)\n  statinfo = os.stat(filepath)\n  tf.logging.info(\"Successfully downloaded %s, %s bytes.\" %\n                  (filename, statinfo.st_size))\n  return filepath"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndownloading filename from Google drive unless it s already in directory.", "response": "def maybe_download_from_drive(directory, filename, url):\n  \"\"\"Download filename from Google drive unless it's already in directory.\n\n  Args:\n    directory: path to the directory that will be used.\n    filename: name of the file to download to (do nothing if it already exists).\n    url: URL to download from.\n\n  Returns:\n    The path to the downloaded file.\n  \"\"\"\n  if not tf.gfile.Exists(directory):\n    tf.logging.info(\"Creating directory %s\" % directory)\n    tf.gfile.MakeDirs(directory)\n  filepath = os.path.join(directory, filename)\n  confirm_token = None\n  if tf.gfile.Exists(filepath):\n    tf.logging.info(\"Not downloading, file already found: %s\" % filepath)\n    return filepath\n\n  # Since the file is big, drive will scan it for virus and take it to a\n  # warning page. We find the confirm token on this page and append it to the\n  # URL to start the download process.\n  confirm_token = None\n  session = requests.Session()\n  response = session.get(url, stream=True)\n  for k, v in response.cookies.items():\n    if k.startswith(\"download_warning\"):\n      confirm_token = v\n\n  if confirm_token:\n    url = url + \"&confirm=\" + confirm_token\n  tf.logging.info(\"Downloading %s to %s\" % (url, filepath))\n\n  response = session.get(url, stream=True)\n  # Now begin the download.\n  chunk_size = 16 * 1024\n  with open(filepath, \"wb\") as f:\n    for chunk in response.iter_content(chunk_size):\n      if chunk:\n        f.write(chunk)\n\n  # Print newline to clear the carriage return from the download progress\n  print()\n  statinfo = os.stat(filepath)\n  tf.logging.info(\"Successfully downloaded %s, %s bytes.\" % (filename,\n                                                             statinfo.st_size))\n  return filepath"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nunzipping from gz_path into new_path.", "response": "def gunzip_file(gz_path, new_path):\n  \"\"\"Unzips from gz_path into new_path.\n\n  Args:\n    gz_path: path to the zipped file.\n    new_path: path to where the file will be unzipped.\n  \"\"\"\n  if tf.gfile.Exists(new_path):\n    tf.logging.info(\"File %s already exists, skipping unpacking\" % new_path)\n    return\n  tf.logging.info(\"Unpacking %s to %s\" % (gz_path, new_path))\n  # We may be unpacking into a newly created directory, add write mode.\n  mode = stat.S_IRWXU or stat.S_IXGRP or stat.S_IRGRP or stat.S_IROTH\n  os.chmod(os.path.dirname(new_path), mode)\n  with gzip.open(gz_path, \"rb\") as gz_file:\n    with tf.gfile.GFile(new_path, mode=\"wb\") as new_file:\n      for line in gz_file:\n        new_file.write(line)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_or_generate_vocab_inner(data_dir, vocab_filename, vocab_size,\n                                generator, max_subtoken_length=None,\n                                reserved_tokens=None):\n  \"\"\"Inner implementation for vocab generators.\n\n  Args:\n    data_dir: The base directory where data and vocab files are stored. If None,\n      then do not save the vocab even if it doesn't exist.\n    vocab_filename: relative filename where vocab file is stored\n    vocab_size: target size of the vocabulary constructed by SubwordTextEncoder\n    generator: a generator that produces tokens from the vocabulary\n    max_subtoken_length: an optional integer.  Set this to a finite value to\n      avoid quadratic costs during vocab building.\n    reserved_tokens: List of reserved tokens. `text_encoder.RESERVED_TOKENS`\n      should be a prefix of `reserved_tokens`. If `None`, defaults to\n      `RESERVED_TOKENS`.\n\n  Returns:\n    A SubwordTextEncoder vocabulary object.\n  \"\"\"\n  if data_dir and vocab_filename:\n    vocab_filepath = os.path.join(data_dir, vocab_filename)\n    if tf.gfile.Exists(vocab_filepath):\n      tf.logging.info(\"Found vocab file: %s\", vocab_filepath)\n      return text_encoder.SubwordTextEncoder(vocab_filepath)\n  else:\n    vocab_filepath = None\n\n  tf.logging.info(\"Generating vocab file: %s\", vocab_filepath)\n  vocab = text_encoder.SubwordTextEncoder.build_from_generator(\n      generator, vocab_size, max_subtoken_length=max_subtoken_length,\n      reserved_tokens=reserved_tokens)\n\n  if vocab_filepath:\n    tf.gfile.MakeDirs(data_dir)\n    vocab.store_to_file(vocab_filepath)\n\n  return vocab", "response": "Inner implementation for vocab generators."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_or_generate_vocab(data_dir, tmp_dir, vocab_filename, vocab_size,\n                          sources, file_byte_budget=1e6,\n                          max_subtoken_length=None):\n  \"\"\"Generate a vocabulary from the datasets in sources.\"\"\"\n\n  vocab_generator = generate_lines_for_vocab(tmp_dir, sources, file_byte_budget)\n  return get_or_generate_vocab_inner(data_dir, vocab_filename, vocab_size,\n                                     vocab_generator, max_subtoken_length)", "response": "Generate a vocabulary from the datasets in sources."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_lines_for_vocab(tmp_dir, sources, file_byte_budget=1e6):\n  tf.logging.info(\"Generating vocab from: %s\", str(sources))\n  for source in sources:\n    url = source[0]\n    filename = os.path.basename(url)\n    compressed_file = maybe_download(tmp_dir, filename, url)\n\n    for lang_file in source[1]:\n      tf.logging.info(\"Reading file: %s\" % lang_file)\n      filepath = os.path.join(tmp_dir, lang_file)\n\n      # Extract from tar if needed.\n      if not tf.gfile.Exists(filepath):\n        read_type = \"r:gz\" if filename.endswith(\"tgz\") else \"r\"\n        with tarfile.open(compressed_file, read_type) as corpus_tar:\n          corpus_tar.extractall(tmp_dir)\n\n      # For some datasets a second extraction is necessary.\n      if lang_file.endswith(\".gz\"):\n        new_filepath = os.path.join(tmp_dir, lang_file[:-3])\n        if tf.gfile.Exists(new_filepath):\n          tf.logging.info(\n              \"Subdirectory %s already exists, skipping unpacking\" % filepath)\n        else:\n          tf.logging.info(\"Unpacking subdirectory %s\" % filepath)\n          gunzip_file(filepath, new_filepath)\n        filepath = new_filepath\n\n      with tf.gfile.GFile(filepath, mode=\"r\") as source_file:\n        file_byte_budget_ = file_byte_budget\n        counter = 0\n        countermax = int(source_file.size() / file_byte_budget_ / 2)\n        for line in source_file:\n          if counter < countermax:\n            counter += 1\n          else:\n            if file_byte_budget_ <= 0:\n              break\n            line = line.strip()\n            file_byte_budget_ -= len(line)\n            counter = 0\n            yield line", "response": "Generate lines for vocabulary generation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a vocabulary from txt files with example - per - line.", "response": "def get_or_generate_txt_vocab(data_dir, vocab_filename, vocab_size,\n                              filepatterns):\n  \"\"\"Generate a vocabulary from txt files with example-per-line.\"\"\"\n  if isinstance(filepatterns, str):\n    filepatterns = [filepatterns]\n\n  def generate():\n    tf.logging.info(\"Generating vocab from %s\", filepatterns)\n    for filepattern in filepatterns:\n      for filename in tf.gfile.Glob(filepattern):\n        with tf.gfile.GFile(filename, mode=\"r\") as source_file:\n          for line in source_file:\n            yield line.strip()\n\n  return get_or_generate_vocab_inner(data_dir, vocab_filename, vocab_size,\n                                     generate())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _shuffle_single(fname, extra_fn=None):\n  records = read_records(fname)\n  random.shuffle(records)\n  if extra_fn is not None:\n    records = extra_fn(records)\n  out_fname = fname.replace(UNSHUFFLED_SUFFIX, \"\")\n  write_records(records, out_fname)\n  tf.gfile.Remove(fname)", "response": "Shuffle a single file of records."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef shuffle_dataset(filenames, extra_fn=None):\n  if outputs_exist(filenames):\n    tf.logging.info(\"Skipping shuffle because output files exist\")\n    return\n  tf.logging.info(\"Shuffling data...\")\n  for filename in filenames:\n    _shuffle_single(filename, extra_fn=extra_fn)\n  tf.logging.info(\"Data shuffled.\")", "response": "Shuffles the dataset.\n\n  Args:\n    filenames: a list of strings\n    extra_fn: an optional function from list of records to list of records\n      to be called after shuffling a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pack_examples(examples,\n                  has_inputs,\n                  packed_length=256,\n                  spacing=2,\n                  queue_size=10,\n                  chop_long_sequences=False):\n  \"\"\"Pack examples into longer examples.\n\n  If has_inputs=False, we are packing single-sequence examples with\n  targets only and no inputs.\n\n  In this case, we concatenate the targets from several examples to form\n  each new example.  We insert a number of zeros for spacing between the\n  original sequences.  This is to help the sequences stay separate\n  under convolutions.  If chop_long_sequences is set, then any input sequence\n  longer than packed_length gets chopped up into multiple examples.  Otherwise,\n  long sequences are emitted as singletons.\n\n  If has_inputs=True, then we are packing sequence-to-sequence\n  examples.  We combine several examples by concatenating the inputs\n  (as above) and concatenating the targets (as above).  Chopping of\n  long sequences is not supported.\n\n  The packed examples are represented as dictionaries containing:\n    \"inputs\", \"targets\": the packed sequences described above\n    \"inputs_segmentation\", \"targets_segmentation\":\n       Sequences aligned with \"inputs\", \"targets\" specifying to which original\n       sequence each position belongs.  Numbering starts from 1, and 0 is used\n       for spacing.  This information is useful for preventing attention across\n       segments.\n       e.g. [1 1 1 1 1 1 0 0 2 2 2 0 0 3 3 3 3 3 0 0 4 4 4]\n     \"inputs_position\", \"targets_position\":\n       Sequences aligned with \"inputs\", \"targets\" specifying position within\n       the original sequence.  This is useful for positional encodings.\n       e.g. [0 1 2 3 4 5 0 0 0 1 2 0 0 0 1 2 3 4 0 0 0 1 2]\n\n  Args:\n    examples: a generator returning feature dictionaries.\n    has_inputs: a boolean\n    packed_length: an integer\n    spacing: an integer\n    queue_size: an integer\n    chop_long_sequences: a boolean\n\n  Yields:\n    feature dictionaries.\n  \"\"\"\n  packer = SequencePairPacker if has_inputs else SequencePacker\n  combined = []\n  for example in examples:\n    x = ((example[\"inputs\"], example[\"targets\"])\n         if has_inputs else example[\"targets\"])\n    if chop_long_sequences and len(x) > packed_length:\n      assert not has_inputs\n      num_fragments = len(x) // packed_length\n      for i in range(num_fragments):\n        yield packer(\n            x[packed_length * i:packed_length * (i + 1)], spacing).to_dict()\n      x = x[packed_length * num_fragments:]\n    added = False\n    for c in combined:\n      if c.can_fit(x, packed_length):\n        c.add(x)\n        added = True\n        break\n    if not added:\n      if len(combined) == queue_size:\n        yield combined[0].to_dict()\n        combined = combined[1:]\n      combined.append(packer(x, spacing))\n  for c in combined:\n    yield c.to_dict()", "response": "Packs examples into longer examples."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking a temporary directory.", "response": "def make_tmp_dir(suffix=\"\", prefix=\"tmp\", dir=None):  # pylint: disable=redefined-builtin\n  \"\"\"Make a temporary directory.\"\"\"\n  if dir is None:\n    return tempfile.mkdtemp(suffix, prefix, dir)\n  else:\n    while True:\n      rand_term = random.randint(1, 9999)\n      tmp_dir = os.path.join(dir, \"%s%d%s\" % (prefix, rand_term, suffix))\n      if tf.gfile.Exists(tmp_dir):\n        continue\n      tf.gfile.MakeDirs(tmp_dir)\n      break\n    return tmp_dir"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\niterates over the records on disk for the problem.", "response": "def tfrecord_iterator_for_problem(problem, data_dir,\n                                  dataset_split=tf.estimator.ModeKeys.TRAIN):\n  \"\"\"Iterate over the records on disk for the Problem.\"\"\"\n  filenames = tf.gfile.Glob(problem.filepattern(data_dir, mode=dataset_split))\n  example_spec = problem.example_reading_spec()[0]\n  return tfrecord_iterator(filenames, example_spec=example_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an iterator over all records in the list of TFRecord files.", "response": "def tfrecord_iterator(filenames, gzipped=False, example_spec=None):\n  \"\"\"Yields records from TFRecord files.\n\n  Args:\n    filenames: list<str>, list of TFRecord filenames to read from.\n    gzipped: bool, whether the TFRecord files are gzip-encoded.\n    example_spec: dict<str feature name, tf.VarLenFeature/tf.FixedLenFeature>,\n      if provided, will parse each record as a tensorflow.Example proto.\n\n  Yields:\n    Records (or parsed Examples, if example_spec is provided) from files.\n  \"\"\"\n  with tf.Graph().as_default():\n    dataset = tf.data.Dataset.from_tensor_slices(filenames)\n\n    def _load_records(filename):\n      return tf.data.TFRecordDataset(\n          filename,\n          compression_type=tf.constant(\"GZIP\") if gzipped else None,\n          buffer_size=16 * 1000 * 1000)\n\n    dataset = dataset.flat_map(_load_records)\n\n    def _parse_example(ex_ser):\n      return tf.parse_single_example(ex_ser, example_spec)\n\n    if example_spec:\n      dataset = dataset.map(_parse_example, num_parallel_calls=32)\n    dataset = dataset.prefetch(100)\n    record_it = dataset.make_one_shot_iterator().get_next()\n\n    with tf.Session() as sess:\n      while True:\n        try:\n          ex = sess.run(record_it)\n          yield ex\n        except tf.errors.OutOfRangeError:\n          break"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef random_deinterleave(text, separator_symbol=\"X\"):\n  words = text.strip().split(\" \")\n  n = len(words)\n  if n <= 1:\n    return text, \"\"\n  cut = [False] * n\n  cut[0] = True\n  num_cuts = int(math.exp(random.uniform(0, math.log(n))))\n  for _ in range(num_cuts):\n    cut[random.randint(1, n -1)] = True\n  out = [[], []]\n  part = random.randint(0, 1)\n  for i in range(n):\n    if cut[i]:\n      out[part].append(separator_symbol)\n      part = 1 - part\n    out[part].append(words[i])\n  return \" \".join(out[0]), \" \".join(out[1])", "response": "Create a fill - in - the - blanks training example from text."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef neural_gpu_body(inputs, hparams, name=None):\n  with tf.variable_scope(name, \"neural_gpu\"):\n\n    def step(state, inp):  # pylint: disable=missing-docstring\n      x = tf.nn.dropout(state, 1.0 - hparams.dropout)\n      for layer in range(hparams.num_hidden_layers):\n        x = common_layers.conv_gru(\n            x, (hparams.kernel_height, hparams.kernel_width),\n            hparams.hidden_size,\n            name=\"cgru_%d\" % layer)\n      # Padding input is zeroed-out in the modality, we check this by summing.\n      padding_inp = tf.less(tf.reduce_sum(tf.abs(inp), axis=[1, 2]), 0.00001)\n      new_state = tf.where(padding_inp, state, x)  # No-op where inp is padding.\n      return new_state\n\n    return tf.foldl(\n        step,\n        tf.transpose(inputs, [1, 0, 2, 3]),\n        initializer=inputs,\n        parallel_iterations=1,\n        swap_memory=True)", "response": "The core Neural GPU."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimproves Neural GPU as in https://arxiv.org/abs/1702.08727.", "response": "def diagonal_neural_gpu(inputs, hparams, name=None):\n  \"\"\"Improved Neural GPU as in https://arxiv.org/abs/1702.08727.\"\"\"\n  with tf.variable_scope(name, \"diagonal_neural_gpu\"):\n\n    def step(state_tup, inp):\n      \"\"\"Single step of the improved Neural GPU.\"\"\"\n      state, _ = state_tup\n      x = state\n      for layer in range(hparams.num_hidden_layers):\n        x, new_loss = common_layers.diagonal_conv_gru(\n            x, (hparams.kernel_height, hparams.kernel_width),\n            hparams.hidden_size,\n            dropout=hparams.dropout,\n            name=\"dcgru_%d\" % layer)\n      # Padding input is zeroed-out in the modality, we check this by summing.\n      padding_inp = tf.less(tf.reduce_sum(tf.abs(inp), axis=[1, 2]), 0.00001)\n      new_state = tf.where(padding_inp, state, x)  # No-op where inp is padding.\n      return new_state, new_loss\n\n    final_state, losses = tf.scan(\n        step,\n        tf.transpose(inputs, [1, 0, 2, 3]),\n        initializer=(inputs, tf.constant(0.0)),\n        parallel_iterations=1,\n        swap_memory=True)\n    return final_state[0, :, :, :, :], 2.0 * tf.reduce_mean(losses)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _reorder_shape(input_shape, output=None):  # pylint: disable=invalid-name\n  if output is None:\n    return input_shape\n  return base.nested_map(output, lambda i: input_shape[i])", "response": "Helper to determine the shape of reorder output."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreordering a tuple into another tuple.", "response": "def Reorder(x, params, output=None, **kwargs):\n  \"\"\"Reorder a tuple into another tuple.\n\n  For example, we can re-order (x, y) into (y, x) or even (y, (x, y), y).\n  The output argument specifies how to re-order, using integers that refer\n  to indices in the input tuple. For example, if\n\n    input = (x, y, z)\n\n  then\n\n    Reorder(input, output=(1, 0, 2))   = (y, x, z)\n    Reorder(input, output=(0, 0))      = (x, x)\n    Reorder(input, output=(0, (1, 1))) = (x, (y, y))\n    Reorder(input, output=((2, 0), (1, 1))) = ((z, x), (y, y))\n\n  By default (if no output is given) Reorder does nothing (Identity).\n\n  Args:\n    x: the input tuple to re-order.\n    params: layer parameters (unused).\n    output: the specification of the output tuple: a nested tuple of ints.\n    **kwargs: other arguments (unused).\n\n  Returns:\n    The re-ordered tuple with the same shape as output.\n  \"\"\"\n  del params, kwargs\n  if output is None:\n    return x\n  return base.nested_map(output, lambda i: x[i])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _nested_op(inputs, op):  # pylint: disable=invalid-name\n  # First the simple non-nested case.\n  if not isinstance(inputs[0], (list, tuple)):\n    return op(inputs)\n  # In the nested case, sum on each axis separately.\n  result_list = []\n  for i in range(len(inputs[0])):\n    result_list.append(_nested_op([x[i] for x in inputs], op=op))\n  if isinstance(inputs[0], list):\n    return result_list\n  return tuple(result_list)", "response": "Helper function for sum a list of arrays or nested arrays."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GateBranches(x, **unused_kwargs):\n  assert len(x) == 3, x\n  state, gate, candidate = x\n  return gate * state + (1.0 - gate) * candidate", "response": "Implements a gating function on a tuple of memory gates and candidate gates."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconstructing a residual version of layers summing input to layers output.", "response": "def Residual(*layers, **kwargs):\n  \"\"\"Constructs a residual version of layers, summing input to layers output.\"\"\"\n  shortcut = kwargs.get('shortcut', Identity())  # pylint: disable=no-value-for-parameter\n  if len(layers) > 1:\n    return Serial(\n        Branch(),  # pylint: disable=no-value-for-parameter\n        Parallel(Serial(*layers), shortcut),\n        SumBranches()  # pylint: disable=no-value-for-parameter\n    )\n  elif len(layers) == 1:\n    return Serial(\n        Branch(),  # pylint: disable=no-value-for-parameter\n        Parallel(layers[0], shortcut),\n        SumBranches()  # pylint: disable=no-value-for-parameter\n    )\n  else:\n    raise ValueError('Empty residual combinator.')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_hparams_for_universal_transformer(hparams):\n  hparams.daisy_chain_variables = False  # Breaks multi-gpu in while loops.\n\n  # If not None, mixes vanilla transformer with Universal Transformer.\n  # Options: None, \"before_ut\", and \"after_ut\".\n  hparams.add_hparam(\"mix_with_transformer\", None)\n\n  # Number of vanilla transformer layers used to be mixed with u-transofmer.\n  hparams.add_hparam(\"num_mixedin_layers\", 2)\n  # Number of transformer layers within the recurrent block (default is 1).\n  hparams.add_hparam(\"num_inrecurrence_layers\", 1)\n\n  # Type of recurrency:\n  # basic, highway, skip, dwa, act, rnn, gru, lstm.\n  hparams.add_hparam(\"recurrence_type\", \"basic\")\n\n  # Number of steps (which is equivalent to num layer in transformer).\n  hparams.add_hparam(\"num_rec_steps\", hparams.num_hidden_layers)\n\n  # Add the positional mebedding at each step(horisontal timing)\n  hparams.add_hparam(\"add_position_timing_signal\", True)\n  if hparams.add_position_timing_signal:\n    hparams.pos = None\n  # Logic of position shifting when using timing signal:\n  # None, \"random\", \"step\"\n  hparams.add_hparam(\"position_start_index\", None)\n\n  # Add an step embedding at each step (vertical timing)\n  hparams.add_hparam(\"add_step_timing_signal\", True)\n  # Either \"learned\" or \"sinusoid\"\n  hparams.add_hparam(\"step_timing_signal_type\", \"learned\")\n\n  # Add or concat the timing signal (applied both on position and step timing).\n  # Options: \"add\" and \"concat\".\n  hparams.add_hparam(\"add_or_concat_timing_signal\", \"add\")\n\n  # Add SRU at the beginning of each Universal Transformer step.\n  # This can be considered as a position timing signal\n  hparams.add_hparam(\"add_sru\", False)\n\n  # Default ffn layer is separable convolution.\n  # Options: \"fc\" and \"sepconv\".\n  hparams.add_hparam(\"transformer_ffn_type\", \"fc\")\n\n  # Transform bias (in models with highway or skip connection).\n  hparams.add_hparam(\"transform_bias_init\", -1.0)\n  hparams.add_hparam(\"couple_carry_transform_gates\", True)\n\n  # Depth-wise attention (grid-transformer!) hparams:\n  # Adds depth embedding, if true.\n  hparams.add_hparam(\"depth_embedding\", True)\n  # Learns attention weights for elements (instead of positions), if true.\n  hparams.add_hparam(\"dwa_elements\", True)\n\n  # Type of ffn_layer used for gate in skip, highway, etc.\n  # \"dense\" or \"dense_dropconnect\".\n  # With dense_relu_dense, the bias/kernel initializations will not be applied.\n  hparams.add_hparam(\"gate_ffn_layer\", \"dense\")\n\n  # LSTM forget bias for lstm style recurrence.\n  hparams.add_hparam(\"lstm_forget_bias\", 1.0)\n  # Uses the memory at the last step as the final output, if true.\n  hparams.add_hparam(\"use_memory_as_final_state\", False)\n  # if also add a ffn unit to the transition function when using gru/lstm\n  hparams.add_hparam(\"add_ffn_unit_to_the_transition_function\", False)\n\n  # Type of act: basic/accumulated/global (instead of position-wise!)/random.\n  hparams.add_hparam(\"act_type\", \"basic\")\n  # Max number of steps (forces halting at this step).\n  hparams.add_hparam(\"act_max_steps\", 2 * hparams.num_hidden_layers)\n  hparams.add_hparam(\"act_halting_bias_init\", 1.0)\n  hparams.add_hparam(\"act_epsilon\", 0.01)\n  hparams.add_hparam(\"act_loss_weight\", 0.01)\n\n  return hparams", "response": "Updates hparams with default values for all of the variants of Universal Transformer."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbase parameters for Universal Transformer.", "response": "def universal_transformer_base():\n  \"\"\"Base parameters for Universal Transformer.\"\"\"\n  hparams = transformer.transformer_base()\n  # To have a similar capacity to the transformer_base with 6 layers,\n  # we need to increase the size of the UT's layer\n  # since, in fact, UT has a single layer repeating multiple times.\n  hparams.hidden_size = 1024\n  hparams.filter_size = 4096\n  hparams.num_heads = 16\n  hparams.layer_prepostprocess_dropout = 0.3\n  hparams = update_hparams_for_universal_transformer(hparams)\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef adaptive_universal_transformer_multilayer_hard():\n  hparams = adaptive_universal_transformer_multilayer_tpu()\n  hparams.batch_size = 256\n  hparams.hard_attention_k = 8\n  hparams.add_step_timing_signal = True\n  # hparams.add_sru = True  # This is very slow on GPUs, does it help?\n  hparams.self_attention_type = \"dot_product_relative_v2\"\n  hparams.max_relative_position = 256\n  return hparams", "response": "Multi - layer config for adaptive Transformer with hard attention."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nranges of hyperparameters for universal transformer base.", "response": "def universal_transformer_base_range(rhp):\n  \"\"\"Range of hyperparameters.\"\"\"\n  # After starting from base, set intervals for some parameters.\n  rhp.set_discrete(\"num_rec_steps\", [6, 8, 10])\n  rhp.set_discrete(\"hidden_size\", [1024, 2048, 4096])\n  rhp.set_discrete(\"filter_size\", [2048, 4096, 8192])\n  rhp.set_discrete(\"num_heads\", [8, 16, 32])\n  rhp.set_discrete(\"transformer_ffn_type\", [\"sepconv\", \"fc\"])\n  rhp.set_float(\"learning_rate\", 0.3, 3.0, scale=rhp.LOG_SCALE)\n  rhp.set_float(\"weight_decay\", 0.0, 2.0)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef adaptive_universal_transformer_base_range(rhp):\n  # After starting from base, set intervals for some parameters.\n  rhp.set_discrete(\"act_max_steps\", [8, 16, 32])\n  rhp.set_float(\"act_loss_weight\", 0.0, 0.5)\n  rhp.set_discrete(\"hidden_size\", [1024, 2048, 4096])\n  rhp.set_discrete(\"filter_size\", [2048, 4096, 8192])\n  rhp.set_discrete(\"num_heads\", [8, 16, 32])\n  rhp.set_discrete(\"transformer_ffn_type\", [\"sepconv\", \"fc\"])\n  rhp.set_float(\"learning_rate\", 0.3, 3.0, scale=rhp.LOG_SCALE)\n  rhp.set_float(\"weight_decay\", 0.0, 2.0)", "response": "Range of hyperparameters for adaptive Transformer base."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsplitting channels in 3 parts. Shifts 1st and 3rd sections to left / right.", "response": "def DiagonalGate(x, params, **kwargs):\n  \"\"\"Split channels in 3 parts. Shifts 1st and 3rd sections to left/right.\"\"\"\n  del params\n  del kwargs\n  # x : [batch, 1, length, depth]\n  x = np.pad(\n      x, [(0, 0), (0, 0), (1, 1), (0, 0)], mode='constant', constant_values=0.0)\n  depth = x.shape[-1] // 3\n  assert 3 * depth == x.shape[-1], ('Depth must be divisible by 3', depth,\n                                    x.shape)\n  xs = [\n      x[:, :, :-2, :depth], x[:, :, 1:-1, depth:2 * depth],\n      x[:, :, 2:, 2 * depth:3 * depth]\n  ]\n  return np.concatenate(xs, axis=3)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds convolutional GRU with diagonal gating as in ImprovedNGPU.", "response": "def ConvDiagonalGRU(units, kernel_size=(3, 3)):\n  \"\"\"Build convolutional GRU with diagonal gating as in ImprovedNGPU.\"\"\"\n\n  def BuildConv():\n    return layers.Conv(filters=units, kernel_size=kernel_size, padding='SAME')\n\n  return layers.GeneralGRUCell(\n      candidate_transform=BuildConv,\n      memory_transform=DiagonalGate,\n      gate_nonlinearity=layers.HardSigmoid,\n      candidate_nonlinearity=layers.HardTanh)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstrip ids_to_strip from the end ids.", "response": "def strip_ids(ids, ids_to_strip):\n  \"\"\"Strip ids_to_strip from the end ids.\"\"\"\n  ids = list(ids)\n  while ids and ids[-1] in ids_to_strip:\n    ids.pop()\n  return ids"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _escape_token(token, alphabet):\n  if not isinstance(token, six.text_type):\n    raise ValueError(\"Expected string type for token, got %s\" % type(token))\n\n  token = token.replace(u\"\\\\\", u\"\\\\\\\\\").replace(u\"_\", u\"\\\\u\")\n  ret = [c if c in alphabet and c != u\"\\n\" else r\"\\%d;\" % ord(c) for c in token]\n  return u\"\".join(ret) + \"_\"", "response": "Escape away underscores and OOV characters and append _."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encode(self, s):\n    return [int(w) + self._num_reserved_ids for w in s.split()]", "response": "Transform a human - readable string into a sequence of int ids."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decode(self, ids, strip_extraneous=False):\n    if strip_extraneous:\n      ids = strip_ids(ids, list(range(self._num_reserved_ids or 0)))\n    return \" \".join(self.decode_list(ids))", "response": "Transform a sequence of int ids into a human - readable string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntransform a sequence of int ids into a list of their string versions.", "response": "def decode_list(self, ids):\n    \"\"\"Transform a sequence of int ids into a their string versions.\n\n    This method supports transforming individual input/output ids to their\n    string versions so that sequence to/from text conversions can be visualized\n    in a human readable format.\n\n    Args:\n      ids: list of integers to be converted.\n\n    Returns:\n      strs: list of human-readable string.\n    \"\"\"\n    decoded_ids = []\n    for id_ in ids:\n      if 0 <= id_ < self._num_reserved_ids:\n        decoded_ids.append(RESERVED_TOKENS[int(id_)])\n      else:\n        decoded_ids.append(id_ - self._num_reserved_ids)\n    return [str(d) for d in decoded_ids]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a space - separated string of tokens to a list of ids.", "response": "def encode(self, s):\n    \"\"\"Converts a space-separated string of tokens to a list of ids.\"\"\"\n    sentence = s\n    tokens = sentence.strip().split()\n    if self._replace_oov is not None:\n      tokens = [t if t in self._token_to_id else self._replace_oov\n                for t in tokens]\n    ret = [self._token_to_id[tok] for tok in tokens]\n    return ret[::-1] if self._reverse else ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload a vocabulary from a file.", "response": "def _init_vocab_from_file(self, filename):\n    \"\"\"Load vocab from a file.\n\n    Args:\n      filename: The file to load vocabulary from.\n    \"\"\"\n    with tf.gfile.Open(filename) as f:\n      tokens = [token.strip() for token in f.readlines()]\n\n    def token_gen():\n      for token in tokens:\n        yield token\n\n    self._init_vocab(token_gen(), add_reserved_tokens=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _init_vocab_from_list(self, vocab_list):\n    def token_gen():\n      for token in vocab_list:\n        if token not in RESERVED_TOKENS:\n          yield token\n\n    self._init_vocab(token_gen())", "response": "Initialize tokens from a list of tokens."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _init_vocab(self, token_generator, add_reserved_tokens=True):\n\n    self._id_to_token = {}\n    non_reserved_start_index = 0\n\n    if add_reserved_tokens:\n      self._id_to_token.update(enumerate(RESERVED_TOKENS))\n      non_reserved_start_index = len(RESERVED_TOKENS)\n\n    self._id_to_token.update(\n        enumerate(token_generator, start=non_reserved_start_index))\n\n    # _token_to_id is the reverse of _id_to_token\n    self._token_to_id = dict((v, k)\n                             for k, v in six.iteritems(self._id_to_token))", "response": "Initialize vocabulary with tokens from token_generator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef store_to_file(self, filename):\n    with tf.gfile.Open(filename, \"w\") as f:\n      for i in range(len(self._id_to_token)):\n        f.write(self._id_to_token[i] + \"\\n\")", "response": "Writes the reserved vocabulary to disk."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a sequence of subtoken ids to a native string.", "response": "def decode(self, ids, strip_extraneous=False):\n    \"\"\"Converts a sequence of subtoken ids to a native string.\n\n    Args:\n      ids: a list of integers in the range [0, vocab_size)\n      strip_extraneous: bool, whether to strip off extraneous tokens\n        (EOS and PAD).\n\n    Returns:\n      a native string\n    \"\"\"\n    if strip_extraneous:\n      ids = strip_ids(ids, list(range(self._num_reserved_ids or 0)))\n    return unicode_to_native(\n        tokenizer.decode(self._subtoken_ids_to_tokens(ids)))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _tokens_to_subtoken_ids(self, tokens):\n    ret = []\n    for token in tokens:\n      ret.extend(self._token_to_subtoken_ids(token))\n    return ret", "response": "Converts a list of tokens to a list of subtoken ids."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a token to a list of subtoken ids.", "response": "def _token_to_subtoken_ids(self, token):\n    \"\"\"Converts token to a list of subtoken ids.\n\n    Args:\n      token: a string.\n    Returns:\n      a list of integers in the range [0, vocab_size)\n    \"\"\"\n    cache_location = hash(token) % self._cache_size\n    cache_key, cache_value = self._cache[cache_location]\n    if cache_key == token:\n      return cache_value\n    ret = self._escaped_token_to_subtoken_ids(\n        _escape_token(token, self._alphabet))\n    self._cache[cache_location] = (token, ret)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _subtoken_ids_to_tokens(self, subtokens):\n    concatenated = \"\".join(\n        [self._subtoken_id_to_subtoken_string(s) for s in subtokens])\n    split = concatenated.split(\"_\")\n    ret = []\n    for t in split:\n      if t:\n        unescaped = _unescape_token(t + \"_\")\n        if unescaped:\n          ret.append(unescaped)\n    return ret", "response": "Converts a list of subtoken ids to a list of tokens."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _subtoken_id_to_subtoken_string(self, subtoken):\n    if 0 <= subtoken < self.vocab_size:\n      return self._all_subtoken_strings[subtoken]\n    return u\"\"", "response": "Converts a subtoken integer ID to a subtoken string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting an escaped token string to a list of subtoken strings.", "response": "def _escaped_token_to_subtoken_strings(self, escaped_token):\n    \"\"\"Converts an escaped token string to a list of subtoken strings.\n\n    Args:\n      escaped_token: An escaped token as a unicode string.\n    Returns:\n      A list of subtokens as unicode strings.\n    \"\"\"\n    # NOTE: This algorithm is greedy; it won't necessarily produce the \"best\"\n    # list of subtokens.\n    ret = []\n    start = 0\n    token_len = len(escaped_token)\n    while start < token_len:\n      for end in range(\n          min(token_len, start + self._max_subtoken_len), start, -1):\n        subtoken = escaped_token[start:end]\n        if subtoken in self._subtoken_string_to_id:\n          ret.append(subtoken)\n          start = end\n          break\n\n      else:  # Did not break\n        # If there is no possible encoding of the escaped token then one of the\n        # characters in the token is not in the alphabet. This should be\n        # impossible and would be indicative of a bug.\n        assert False, \"Token substring not found in subtoken vocabulary.\"\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _escaped_token_to_subtoken_ids(self, escaped_token):\n    return [\n        self._subtoken_string_to_id[subtoken]\n        for subtoken in self._escaped_token_to_subtoken_strings(escaped_token)\n    ]", "response": "Converts an escaped token string to a list of subtoken IDs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_from_generator(cls,\n                           generator,\n                           target_size,\n                           max_subtoken_length=None,\n                           reserved_tokens=None):\n    \"\"\"Builds a SubwordTextEncoder from the generated text.\n\n    Args:\n      generator: yields text.\n      target_size: int, approximate vocabulary size to create.\n      max_subtoken_length: Maximum length of a subtoken. If this is not set,\n        then the runtime and memory use of creating the vocab is quadratic in\n        the length of the longest token. If this is set, then it is instead\n        O(max_subtoken_length * length of longest token).\n      reserved_tokens: List of reserved tokens. The global variable\n        `RESERVED_TOKENS` must be a prefix of `reserved_tokens`. If this\n        argument is `None`, it will use `RESERVED_TOKENS`.\n\n    Returns:\n      SubwordTextEncoder with `vocab_size` approximately `target_size`.\n    \"\"\"\n    token_counts = collections.defaultdict(int)\n    for item in generator:\n      for tok in tokenizer.encode(native_to_unicode(item)):\n        token_counts[tok] += 1\n    encoder = cls.build_to_target_size(\n        target_size, token_counts, 1, 1e3,\n        max_subtoken_length=max_subtoken_length,\n        reserved_tokens=reserved_tokens)\n    return encoder", "response": "Builds a SubwordTextEncoder from a generator."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a SubwordTextEncoder that has vocab_size near target_size.", "response": "def build_to_target_size(cls,\n                           target_size,\n                           token_counts,\n                           min_val,\n                           max_val,\n                           max_subtoken_length=None,\n                           reserved_tokens=None,\n                           num_iterations=4):\n    \"\"\"Builds a SubwordTextEncoder that has `vocab_size` near `target_size`.\n\n    Uses simple recursive binary search to find a minimum token count that most\n    closely matches the `target_size`.\n\n    Args:\n      target_size: Desired vocab_size to approximate.\n      token_counts: A dictionary of token counts, mapping string to int.\n      min_val: An integer; lower bound for the minimum token count.\n      max_val: An integer; upper bound for the minimum token count.\n      max_subtoken_length: Maximum length of a subtoken. If this is not set,\n        then the runtime and memory use of creating the vocab is quadratic in\n        the length of the longest token. If this is set, then it is instead\n        O(max_subtoken_length * length of longest token).\n      reserved_tokens: List of reserved tokens. The global variable\n        `RESERVED_TOKENS` must be a prefix of `reserved_tokens`. If this\n        argument is `None`, it will use `RESERVED_TOKENS`.\n      num_iterations: An integer; how many iterations of refinement.\n\n    Returns:\n      A SubwordTextEncoder instance.\n\n    Raises:\n      ValueError: If `min_val` is greater than `max_val`.\n    \"\"\"\n    if min_val > max_val:\n      raise ValueError(\"Lower bound for the minimum token count \"\n                       \"is greater than the upper bound.\")\n    if target_size < 1:\n      raise ValueError(\"Target size must be positive.\")\n\n    if reserved_tokens is None:\n      reserved_tokens = RESERVED_TOKENS\n\n    def bisect(min_val, max_val):\n      \"\"\"Bisection to find the right size.\"\"\"\n      present_count = (max_val + min_val) // 2\n      tf.logging.info(\"Trying min_count %d\" % present_count)\n      subtokenizer = cls()\n      subtokenizer.build_from_token_counts(\n          token_counts, present_count, num_iterations,\n          max_subtoken_length=max_subtoken_length,\n          reserved_tokens=reserved_tokens)\n\n      # Being within 1% of the target size is ok.\n      is_ok = abs(subtokenizer.vocab_size - target_size) * 100 < target_size\n      # If min_val == max_val, we can't do any better than this.\n      if is_ok or min_val >= max_val or present_count < 2:\n        return subtokenizer\n\n      if subtokenizer.vocab_size > target_size:\n        other_subtokenizer = bisect(present_count + 1, max_val)\n      else:\n        other_subtokenizer = bisect(min_val, present_count - 1)\n\n      if other_subtokenizer is None:\n        return subtokenizer\n\n      if (abs(other_subtokenizer.vocab_size - target_size) <\n          abs(subtokenizer.vocab_size - target_size)):\n        return other_subtokenizer\n      return subtokenizer\n\n    return bisect(min_val, max_val)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntrain a SubwordTextEncoder based on a dictionary of word counts.", "response": "def build_from_token_counts(self,\n                              token_counts,\n                              min_count,\n                              num_iterations=4,\n                              reserved_tokens=None,\n                              max_subtoken_length=None):\n    \"\"\"Train a SubwordTextEncoder based on a dictionary of word counts.\n\n    Args:\n      token_counts: a dictionary of Unicode strings to int.\n      min_count: an integer - discard subtokens with lower counts.\n      num_iterations: an integer.  how many iterations of refinement.\n      reserved_tokens: List of reserved tokens. The global variable\n        `RESERVED_TOKENS` must be a prefix of `reserved_tokens`. If this\n        argument is `None`, it will use `RESERVED_TOKENS`.\n      max_subtoken_length: Maximum length of a subtoken. If this is not set,\n        then the runtime and memory use of creating the vocab is quadratic in\n        the length of the longest token. If this is set, then it is instead\n        O(max_subtoken_length * length of longest token).\n\n    Raises:\n      ValueError: if reserved is not 0 or len(RESERVED_TOKENS). In this case, it\n        is not clear what the space is being reserved for, or when it will be\n        filled in.\n    \"\"\"\n    if reserved_tokens is None:\n      reserved_tokens = RESERVED_TOKENS\n    else:\n      # There is not complete freedom in replacing RESERVED_TOKENS.\n      for default, proposed in zip(RESERVED_TOKENS, reserved_tokens):\n        if default != proposed:\n          raise ValueError(\"RESERVED_TOKENS must be a prefix of \"\n                           \"reserved_tokens.\")\n\n    # Initialize the alphabet. Note, this must include reserved tokens or it can\n    # result in encoding failures.\n    alphabet_tokens = chain(six.iterkeys(token_counts),\n                            [native_to_unicode(t) for t in reserved_tokens])\n\n    self._init_alphabet_from_tokens(alphabet_tokens)\n\n    # Bootstrap the initial list of subtokens with the characters from the\n    # alphabet plus the escaping characters.\n    self._init_subtokens_from_list(list(self._alphabet),\n                                   reserved_tokens=reserved_tokens)\n\n    # We build iteratively.  On each iteration, we segment all the words,\n    # then count the resulting potential subtokens, keeping the ones\n    # with high enough counts for our new vocabulary.\n    if min_count < 1:\n      min_count = 1\n    for i in range(num_iterations):\n      tf.logging.info(\"Iteration {0}\".format(i))\n\n      # Collect all substrings of the encoded token that break along current\n      # subtoken boundaries.\n      subtoken_counts = collections.defaultdict(int)\n      for token, count in six.iteritems(token_counts):\n        iter_start_time = time.time()\n        escaped_token = _escape_token(token, self._alphabet)\n        subtokens = self._escaped_token_to_subtoken_strings(escaped_token)\n        start = 0\n        for subtoken in subtokens:\n          last_position = len(escaped_token) + 1\n          if max_subtoken_length is not None:\n            last_position = min(last_position, start + max_subtoken_length)\n\n          for end in range(start + 1, last_position):\n            new_subtoken = escaped_token[start:end]\n            subtoken_counts[new_subtoken] += count\n          start += len(subtoken)\n        iter_time_secs = time.time() - iter_start_time\n        if iter_time_secs > 0.1:\n          tf.logging.info(u\"Processing token [{0}] took {1} seconds, consider \"\n                          \"setting Text2TextProblem.max_subtoken_length to a \"\n                          \"smaller value.\".format(token, iter_time_secs))\n\n      # Array of sets of candidate subtoken strings, by length.\n      len_to_subtoken_strings = []\n      for subtoken_string, count in six.iteritems(subtoken_counts):\n        lsub = len(subtoken_string)\n        if count >= min_count:\n          while len(len_to_subtoken_strings) <= lsub:\n            len_to_subtoken_strings.append(set())\n          len_to_subtoken_strings[lsub].add(subtoken_string)\n\n      # Consider the candidates longest to shortest, so that if we accept\n      # a longer subtoken string, we can decrement the counts of its prefixes.\n      new_subtoken_strings = []\n      for lsub in range(len(len_to_subtoken_strings) - 1, 0, -1):\n        subtoken_strings = len_to_subtoken_strings[lsub]\n        for subtoken_string in subtoken_strings:\n          count = subtoken_counts[subtoken_string]\n          if count >= min_count:\n            # Exclude alphabet tokens here, as they must be included later,\n            # explicitly, regardless of count.\n            if subtoken_string not in self._alphabet:\n              new_subtoken_strings.append((count, subtoken_string))\n            for l in range(1, lsub):\n              subtoken_counts[subtoken_string[:l]] -= count\n\n      # Include the alphabet explicitly to guarantee all strings are encodable.\n      new_subtoken_strings.extend((subtoken_counts.get(a, 0), a)\n                                  for a in self._alphabet)\n      new_subtoken_strings.sort(reverse=True)\n\n      # Reinitialize to the candidate vocabulary.\n      new_subtoken_strings = [subtoken for _, subtoken in new_subtoken_strings]\n      if reserved_tokens:\n        escaped_reserved_tokens = [\n            _escape_token(native_to_unicode(t), self._alphabet)\n            for t in reserved_tokens\n        ]\n        new_subtoken_strings = escaped_reserved_tokens + new_subtoken_strings\n\n      self._init_subtokens_from_list(new_subtoken_strings)\n      tf.logging.info(\"vocab_size = %d\" % self.vocab_size)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndebug dump of the current subtoken vocabulary.", "response": "def dump(self):\n    \"\"\"Debugging dump of the current subtoken vocabulary.\"\"\"\n    subtoken_strings = [(i, s)\n                        for s, i in six.iteritems(self._subtoken_string_to_id)]\n    print(u\", \".join(u\"{0} : '{1}'\".format(i, s)\n                     for i, s in sorted(subtoken_strings)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _load_from_file_object(self, f):\n    subtoken_strings = []\n    for line in f:\n      s = line.strip()\n      # Some vocab files wrap words in single quotes, but others don't\n      if ((s.startswith(\"'\") and s.endswith(\"'\")) or\n          (s.startswith(\"\\\"\") and s.endswith(\"\\\"\"))):\n        s = s[1:-1]\n      subtoken_strings.append(native_to_unicode(s))\n    self._init_subtokens_from_list(subtoken_strings)\n    self._init_alphabet_from_tokens(subtoken_strings)", "response": "Loads a vocabulary from a file object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _load_from_file(self, filename):\n    if not tf.gfile.Exists(filename):\n      raise ValueError(\"File %s not found\" % filename)\n    with tf.gfile.Open(filename) as f:\n      self._load_from_file_object(f)", "response": "Load from a vocab file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntransform a string with a filename into a list of RGB integers.", "response": "def encode(self, s):\n    \"\"\"Transform a string with a filename into a list of RGB integers.\n\n    Args:\n      s: path to the file with an image.\n\n    Returns:\n      ids: list of integers\n    \"\"\"\n    try:\n      import matplotlib.image as im  # pylint: disable=g-import-not-at-top\n    except ImportError as e:\n      tf.logging.warning(\n          \"Reading an image requires matplotlib to be installed: %s\", e)\n      raise NotImplementedError(\"Image reading not implemented.\")\n    return im.imread(s)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntransforms a sequence of int ids into an image file.", "response": "def decode(self, ids, strip_extraneous=False):\n    \"\"\"Transform a sequence of int ids into an image file.\n\n    Args:\n      ids: list of integers to be converted.\n      strip_extraneous: unused\n\n    Returns:\n      Path to the temporary file where the image was saved.\n\n    Raises:\n      ValueError: if the ids are not of the appropriate size.\n    \"\"\"\n    del strip_extraneous\n    _, tmp_file_path = tempfile.mkstemp(\"_decode.png\")\n    if self._height is None or self._width is None:\n      size = int(math.sqrt(len(ids) / self._channels))\n      length = size * size * self._channels\n    else:\n      size = None\n      length = self._height * self._width * self._channels\n    if len(ids) != length:\n      raise ValueError(\"Length of ids (%d) must be height (%d) x width (%d) x \"\n                       \"channels (%d); %d != %d.\\n Ids: %s\"\n                       % (len(ids), self._height, self._width, self._channels,\n                          len(ids), length, \" \".join([str(i) for i in ids])))\n    with tf.Graph().as_default():\n      raw = tf.constant(ids, dtype=tf.uint8)\n      if size is None:\n        img = tf.reshape(raw, [self._height, self._width, self._channels])\n      else:\n        img = tf.reshape(raw, [size, size, self._channels])\n      png = tf.image.encode_png(img)\n      op = tf.write_file(tmp_file_path, png)\n      with tf.Session() as sess:\n        sess.run(op)\n    return tmp_file_path"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntransforming sequence of float values into string.", "response": "def decode(self, ids, strip_extraneous=False):\n    \"\"\"Transform sequence of float values into string (float values).\n\n    Args:\n      ids: array of floats to be converted.\n      strip_extraneous: unused\n\n    Returns:\n      String having space separated float values.\n\n    Raises:\n      ValueError: if the ids are not of the appropriate size.\n    \"\"\"\n    del strip_extraneous\n    return \" \".join([str(i) for i in ids])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef markdownify_operative_config_str(string):\n\n  # TODO(b/37527917): Total hack below. Implement more principled formatting.\n  def process(line):\n    \"\"\"Convert a single line to markdown format.\"\"\"\n    if not line.startswith('#'):\n      return '    ' + line\n\n    line = line[2:]\n    if line.startswith('===='):\n      return ''\n    if line.startswith('None'):\n      return '    # None.'\n    if line.endswith(':'):\n      return '#### ' + line\n    return line\n\n  output_lines = []\n  for line in string.splitlines():\n    procd_line = process(line)\n    if procd_line is not None:\n      output_lines.append(procd_line)\n\n  return '\\n'.join(output_lines)", "response": "Convert an operative config string to markdown format."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncloses the summary writer. Final!", "response": "def close(self):\n    \"\"\"Close SummaryWriter. Final!\"\"\"\n    if not self._closed:\n      self._event_writer.close()\n      self._closed = True\n      del self._event_writer"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef scalar(self, tag, value, step=None):\n    value = float(onp.array(value))\n    if step is None:\n      step = self._step\n    else:\n      self._step = step\n    summary = Summary(value=[Summary.Value(tag=tag, simple_value=value)])\n    self.add_summary(summary, step)", "response": "Saves scalar value.\n\n    Args:\n      tag: str: label for this data\n      value: int/float: number to log\n      step: int: training step"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave RGB image summary from onp. ndarray [ H W 1 or HW 3 or 1 or 3.", "response": "def image(self, tag, image, step=None):\n    \"\"\"Saves RGB image summary from onp.ndarray [H,W], [H,W,1], or [H,W,3].\n\n    Args:\n      tag: str: label for this data\n      image: ndarray: [H,W], [H,W,1], [H,W,3] save image in greyscale or colors/\n      step: int: training step\n    \"\"\"\n    image = onp.array(image)\n    if step is None:\n      step = self._step\n    else:\n      self._step = step\n    if len(onp.shape(image)) == 2:\n      image = image[:, :, onp.newaxis]\n    if onp.shape(image)[-1] == 1:\n      image = onp.repeat(image, 3, axis=-1)\n    image_strio = io.BytesIO()\n    plt.imsave(image_strio, image, format='png')\n    image_summary = Summary.Image(\n        encoded_image_string=image_strio.getvalue(),\n        colorspace=3,\n        height=image.shape[0],\n        width=image.shape[1])\n    summary = Summary(value=[Summary.Value(tag=tag, image=image_summary)])\n    self.add_summary(summary, step)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving images from onp. ndarray.", "response": "def images(self, tag, images, step=None, rows=None, cols=None):\n    \"\"\"Saves (rows, cols) tiled images from onp.ndarray.\n\n    If either rows or cols aren't given, they are determined automatically\n    from the size of the image batch, if neither are given a long column\n    of images is produced. This truncates the image batch rather than padding\n    if it doesn't fill the final row.\n\n    Args:\n      tag: str: label for this data\n      images: ndarray: [N,H,W,1] or [N,H,W,3] to tile in 2d\n      step: int: training step\n      rows: int: number of rows in tile\n      cols: int: number of columns in tile\n    \"\"\"\n    images = onp.array(images)\n    if step is None:\n      step = self._step\n    else:\n      self._step = step\n    n_images = onp.shape(images)[0]\n    if rows is None and cols is None:\n      rows = 1\n      cols = n_images\n    elif rows is None:\n      rows = n_images // cols\n    elif cols is None:\n      cols = n_images // rows\n    tiled_images = _pack_images(images, rows, cols)\n    self.image(tag, tiled_images, step=step)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves matplotlib plot output to summary image.", "response": "def plot(self, tag, mpl_plt, step=None, close_plot=True):\n    \"\"\"Saves matplotlib plot output to summary image.\n\n    Args:\n      tag: str: label for this data\n      mpl_plt: matplotlib stateful pyplot object with prepared plotting state\n      step: int: training step\n      close_plot: bool: automatically closes plot\n    \"\"\"\n    if step is None:\n      step = self._step\n    else:\n      self._step = step\n    fig = mpl_plt.get_current_fig_manager()\n    img_w, img_h = fig.canvas.get_width_height()\n    image_buf = io.BytesIO()\n    mpl_plt.savefig(image_buf, format='png')\n    image_summary = Summary.Image(\n        encoded_image_string=image_buf.getvalue(),\n        colorspace=4,  # RGBA\n        height=img_h,\n        width=img_w)\n    summary = Summary(value=[Summary.Value(tag=tag, image=image_summary)])\n    self.add_summary(summary, step)\n    if close_plot:\n      mpl_plt.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef audio(self, tag, audiodata, step=None, sample_rate=44100):\n    audiodata = onp.array(audiodata)\n    if step is None:\n      step = self._step\n    else:\n      self._step = step\n    audiodata = onp.clip(onp.squeeze(audiodata), -1, 1)\n    if audiodata.ndim != 1:\n      raise ValueError('Audio data must be 1D.')\n    sample_list = (32767.0 * audiodata).astype(int).tolist()\n    wio = io.BytesIO()\n    wav_buf = wave.open(wio, 'wb')\n    wav_buf.setnchannels(1)\n    wav_buf.setsampwidth(2)\n    wav_buf.setframerate(sample_rate)\n    enc = b''.join([struct.pack('<h', v) for v in sample_list])\n    wav_buf.writeframes(enc)\n    wav_buf.close()\n    encoded_audio_bytes = wio.getvalue()\n    wio.close()\n    audio = Summary.Audio(\n        sample_rate=sample_rate,\n        num_channels=1,\n        length_frames=len(sample_list),\n        encoded_audio_string=encoded_audio_bytes,\n        content_type='audio/wav')\n    summary = Summary(value=[Summary.Value(tag=tag, audio=audio)])\n    self.add_summary(summary, step)", "response": "Saves audio data to a new file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves histogram of values.", "response": "def histogram(self, tag, values, bins, step=None):\n    \"\"\"Saves histogram of values.\n\n    Args:\n      tag: str: label for this data\n      values: ndarray: will be flattened by this routine\n      bins: number of bins in histogram, or array of bins for onp.histogram\n      step: int: training step\n    \"\"\"\n    if step is None:\n      step = self._step\n    else:\n      self._step = step\n    values = onp.array(values)\n    bins = onp.array(bins)\n    values = onp.reshape(values, -1)\n    counts, limits = onp.histogram(values, bins=bins)\n    # boundary logic\n    cum_counts = onp.cumsum(onp.greater(counts, 0, dtype=onp.int32))\n    start, end = onp.searchsorted(\n        cum_counts, [0, cum_counts[-1] - 1], side='right')\n    start, end = int(start), int(end) + 1\n    counts = (\n        counts[start -\n               1:end] if start > 0 else onp.concatenate([[0], counts[:end]]))\n    limits = limits[start:end + 1]\n    sum_sq = values.dot(values)\n    histo = HistogramProto(\n        min=values.min(),\n        max=values.max(),\n        num=len(values),\n        sum=values.sum(),\n        sum_squares=sum_sq,\n        bucket_limit=limits.tolist(),\n        bucket=counts.tolist())\n    summary = Summary(value=[Summary.Value(tag=tag, histo=histo)])\n    self.add_summary(summary, step)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef text(self, tag, textdata, step=None):\n    if step is None:\n      step = self._step\n    else:\n      self._step = step\n    smd = SummaryMetadata(\n        plugin_data=SummaryMetadata.PluginData(plugin_name='text'))\n    if isinstance(textdata, (str, bytes)):\n      tensor = tf.make_tensor_proto(\n          values=[textdata.encode(encoding='utf_8')], shape=(1,))\n    else:\n      textdata = onp.array(textdata)  # convert lists, jax arrays, etc.\n      datashape = onp.shape(textdata)\n      if len(datashape) == 1:\n        tensor = tf.make_tensor_proto(\n            values=[td.encode(encoding='utf_8') for td in textdata],\n            shape=(datashape[0],))\n      elif len(datashape) == 2:\n        tensor = tf.make_tensor_proto(\n            values=[\n                td.encode(encoding='utf_8') for td in onp.reshape(textdata, -1)\n            ],\n            shape=(datashape[0], datashape[1]))\n    summary = Summary(\n        value=[Summary.Value(tag=tag, metadata=smd, tensor=tensor)])\n    self.add_summary(summary, step)", "response": "Saves a text summary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nimport module at usr_dir if provided.", "response": "def import_usr_dir(usr_dir):\n  \"\"\"Import module at usr_dir, if provided.\"\"\"\n  if not usr_dir:\n    return\n  if usr_dir == INTERNAL_USR_DIR_PACKAGE:\n    # The package has been installed with pip under this name for Cloud ML\n    # Engine so just import it.\n    importlib.import_module(INTERNAL_USR_DIR_PACKAGE)\n    return\n\n  dir_path = os.path.abspath(os.path.expanduser(usr_dir).rstrip(\"/\"))\n  containing_dir, module_name = os.path.split(dir_path)\n  tf.logging.info(\"Importing user module %s from path %s\", module_name,\n                  containing_dir)\n  sys.path.insert(0, containing_dir)\n  importlib.import_module(module_name)\n  sys.path.pop(0)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_reset_and_type_change(self, name, orig_ctr):\n    # Resetting a hyperparameter\n    if name in orig_ctr:\n      tf.logging.warning(\"Overwriting hparam %s\", name)\n\n    ctr_names = [\n        (self._categorical_params, \"categorical\"),\n        (self._discrete_params, \"discrete\"),\n        (self._float_params, \"float\"),\n        (self._int_params, \"int\"),\n    ]\n    ctrs, names = list(zip(*ctr_names))\n    orig_name = names[ctrs.index(orig_ctr)]\n\n    for ctr, ctr_name in ctr_names:\n      if ctr is orig_ctr:\n        continue\n\n      # Using a different type for the same hyperparameter name\n      if name in ctr:\n        raise ValueError(\"Setting hyperparameter %s as type %s, but a \"\n                         \"hyperparemeter of the same name was originally \"\n                         \"registered as type %s\" % (name, ctr_name, orig_name))", "response": "Check if name is in orig_ctr and if it is in one of the other type containers."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate and register a problem for a game.", "response": "def register_game(game_name, game_mode=\"NoFrameskip-v4\"):\n  \"\"\"Create and register problems for the game.\n\n  Args:\n    game_name: str, one of the games in ATARI_GAMES, e.g. \"bank_heist\".\n    game_mode: the frame skip and sticky keys config.\n\n  Raises:\n    ValueError: if game_name or game_mode are wrong.\n  \"\"\"\n  if game_name not in ATARI_GAMES:\n    raise ValueError(\"Game %s not in ATARI_GAMES\" % game_name)\n  if game_mode not in ATARI_GAME_MODES:\n    raise ValueError(\"Unknown ATARI game mode: %s.\" % game_mode)\n  camel_game_name = misc_utils.snakecase_to_camelcase(game_name) + game_mode\n  # Create and register the Problem\n  cls = type(\"Gym%sRandom\" % camel_game_name,\n             (T2TGymEnv,), {\"base_env_name\": camel_game_name})\n  registry.register_problem(cls)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _decode_png(self, encoded_observation):\n    return self._session.obj.run(\n        self._decoded_image_t.obj,\n        feed_dict={self._encoded_image_p.obj: encoded_observation}\n    )", "response": "Decodes a single observation from PNG."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _encode_observations(self, observations):\n    return [\n        Observation(\n            self._session.obj.run(\n                self._encoded_image_t.obj,\n                feed_dict={self._decoded_image_p.obj: observation}\n            ),\n            self._decode_png\n        )\n        for observation in observations\n    ]", "response": "Encodes observations as PNG."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef step(self, actions):\n    if self._store_rollouts and \\\n        self._rollouts_by_epoch_and_split[self.current_epoch]:\n      raise ValueError(\n          \"Data for current epoch has already been loaded from disk.\"\n      )\n    (obs, unclipped_rewards, dones) = self._step(actions)\n    obs = self._preprocess_observations(obs)\n    (min_reward, max_reward) = self.reward_range\n    rewards = np.around(np.clip(unclipped_rewards, min_reward, max_reward))\n    if self._store_rollouts:\n      unclipped_rewards = unclipped_rewards.astype(np.float64)\n      encoded_obs = self._encode_observations(obs)\n      for (rollout, frame, action) in zip(\n          self._current_batch_rollouts, self._current_batch_frames, actions\n      ):\n        rollout.append(frame._replace(action=action))\n\n      # orud = (observation, reward, unclipped_reward, done)\n      self._current_batch_frames = [\n          Frame(*orud, action=None)\n          for orud in zip(encoded_obs, rewards, unclipped_rewards, dones)\n      ]\n    return (obs, rewards, dones)", "response": "Makes a step in all environments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nresetting the environment at given indices.", "response": "def reset(self, indices=None):\n    \"\"\"Resets environments at given indices.\n\n    Does any preprocessing and adds rollouts to history.\n\n    Args:\n      indices: Indices of environments to reset.\n\n    Returns:\n      Batch of initial observations of reset environments.\n\n    Raises:\n      ValueError: when there's no current epoch.\n    \"\"\"\n    if self._store_rollouts and self.current_epoch is None:\n      raise ValueError(\n          \"No current epoch. start_new_epoch() should first be called.\"\n      )\n\n    if indices is None:\n      indices = np.arange(self.batch_size)\n    new_obs = self._reset(indices)\n    if self._should_preprocess_on_reset:\n      new_obs = self._preprocess_observations(new_obs)\n    if self._store_rollouts:\n      encoded_obs = self._encode_observations(new_obs)\n      for (index, ob) in zip(indices, encoded_obs):\n        frame = self._current_batch_frames[index]\n        if frame is not None:\n          rollout = self._current_batch_rollouts[index]\n          rollout.append(frame._replace(action=0))\n          self._current_epoch_rollouts.append(rollout)\n          self._current_batch_rollouts[index] = []\n        self._current_batch_frames[index] = Frame(\n            observation=ob, reward=0, unclipped_reward=0, done=False,\n            action=None\n        )\n    return new_obs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _split_current_epoch(self):\n    num_frames = self._calc_num_frames(self._current_epoch_rollouts)\n    num_shards = sum(split[\"shards\"] for split in self.dataset_splits)\n    shard_size = num_frames // num_shards\n\n    splits = self.dataset_splits\n    num_saved_frames = 0\n    split_index = 0\n    split_begin_index = 0\n    rollouts_by_split = collections.defaultdict(list)\n\n    def split_size(split_index):\n      return splits[split_index][\"shards\"] * shard_size\n\n    for rollout in self._current_epoch_rollouts:\n      num_saved_frames_current_rollout = 0\n      # Split the rollout into chunks corresponding to dataset splits. In most\n      # cases there should be only one chunk. On dataset split boundary there\n      # will be two. If a rollout is longer then the size of a dataset split,\n      # there might be more.\n      while num_saved_frames_current_rollout < len(rollout):\n        max_chunk_length = (\n            split_begin_index + split_size(split_index) - num_saved_frames\n        )\n        if split_index == len(splits) - 1:\n          # Put the remainder in the last split to preserve the ordering.\n          max_chunk_length = len(rollout)\n        rollout_chunk = rollout[\n            num_saved_frames_current_rollout:\n            (num_saved_frames_current_rollout + max_chunk_length)\n        ]\n        rollouts_by_split[splits[split_index][\"split\"]].append(rollout_chunk)\n        num_saved_frames_current_rollout += len(rollout_chunk)\n        num_saved_frames += len(rollout_chunk)\n\n        if num_saved_frames == split_begin_index + split_size(split_index):\n          split_begin_index += split_size(split_index)\n          split_index = min(split_index + 1, len(splits) - 1)\n\n    self._rollouts_by_epoch_and_split[self.current_epoch] = rollouts_by_split\n    self._current_epoch_rollouts = []", "response": "Splits the current epoch according to self. dataset_splits."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists of pairs ( split paths ) for the current epoch.", "response": "def splits_and_paths(self, data_dir):\n    \"\"\"List of pairs (split, paths) for the current epoch.\"\"\"\n    filepath_fns = {\n        problem.DatasetSplit.TRAIN: self.training_filepaths,\n        problem.DatasetSplit.EVAL: self.dev_filepaths,\n        problem.DatasetSplit.TEST: self.test_filepaths,\n    }\n\n    def append_epoch(paths):\n      return [\n          \"{}.{}\".format(path, self.current_epoch)\n          for path in paths\n      ]\n\n    # We set shuffled=True as we don't want to shuffle on disk later.\n    return [\n        (split[\"split\"], append_epoch(filepath_fns[split[\"split\"]](\n            data_dir, split[\"shards\"], shuffled=True\n        )))\n        for split in self.dataset_splits\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_data(self, data_dir, tmp_dir=None, task_id=-1):\n    if not self._rollouts_by_epoch_and_split[self.current_epoch]:\n      # Data not loaded from disk.\n      self._split_current_epoch()\n\n    rollouts_by_split = self._rollouts_by_epoch_and_split[self.current_epoch]\n    splits_and_paths = self.splits_and_paths(data_dir)\n\n    for (split, paths) in splits_and_paths:\n      rollouts = rollouts_by_split[split]\n      num_frames = self._calc_num_frames(rollouts)\n      shard_size = num_frames // len(paths)\n\n      frame_gen = self._generate_frames(rollouts)\n      for (path_index, path) in enumerate(paths):\n        limit = shard_size\n        # Put the remainder in the last shard to preserve the ordering.\n        if path_index == len(paths) - 1:\n          limit = None\n        generator_utils.generate_files(\n            itertools.islice(frame_gen, limit), [path],\n            cycle_every_n=float(\"inf\")\n        )", "response": "Saves the current epoch rollouts to disk split into train set."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_initial_state(self, initial_state, initial_frames):\n    self._initial_state = initial_state\n    self._initial_frames = initial_frames[:, -1, ...]\n    self._should_preprocess_on_reset = False", "response": "Sets the initial state that will be used on next reset."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a NumPy image to a tf. Summary. Value object.", "response": "def image_to_tf_summary_value(image, tag):\n  \"\"\"Converts a NumPy image to a tf.Summary.Value object.\n\n  Args:\n    image: 3-D NumPy array.\n    tag: name for tf.Summary.Value for display in tensorboard.\n  Returns:\n    image_summary: A tf.Summary.Value object.\n  \"\"\"\n  curr_image = np.asarray(image, dtype=np.uint8)\n  height, width, n_channels = curr_image.shape\n  # If monochrome image, then reshape to [height, width]\n  if n_channels == 1:\n    curr_image = np.reshape(curr_image, [height, width])\n  s = io.BytesIO()\n  matplotlib_pyplot().imsave(s, curr_image, format=\"png\")\n  img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),\n                             height=height, width=width,\n                             colorspace=n_channels)\n  return tf.Summary.Value(tag=tag, image=img_sum)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert_predictions_to_image_summaries(hook_args):\n  decode_hparams = hook_args.decode_hparams\n  if not decode_hparams.display_decoded_images:\n    return []\n  predictions = hook_args.predictions[0]\n\n  # Display ten random inputs and outputs so that tensorboard does not hang.\n  all_summaries = []\n  rand_predictions = np.random.choice(predictions, size=10)\n  for ind, prediction in enumerate(rand_predictions):\n    output_summary = image_to_tf_summary_value(\n        prediction[\"outputs\"], tag=\"%d_output\" % ind)\n    input_summary = image_to_tf_summary_value(\n        prediction[\"inputs\"], tag=\"%d_input\" % ind)\n    all_summaries.append(input_summary)\n    all_summaries.append(output_summary)\n  return all_summaries", "response": "Optionally converts images from hooks_args to image summaries."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nimage resize function used by quite a few image problems.", "response": "def resize_by_area(img, size):\n  \"\"\"image resize function used by quite a few image problems.\"\"\"\n  return tf.to_int64(\n      tf.image.resize_images(img, [size, size], tf.image.ResizeMethod.AREA))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_multiscale(image, resolutions,\n                    resize_method=tf.image.ResizeMethod.BICUBIC,\n                    num_channels=3):\n  \"\"\"Returns list of scaled images, one for each resolution.\n\n  Args:\n    image: Tensor of shape [height, height, num_channels].\n    resolutions: List of heights that image's height is resized to.\n    resize_method: tf.image.ResizeMethod.\n    num_channels: Number of channels in image.\n\n  Returns:\n    List of Tensors, one for each resolution with shape given by\n    [resolutions[i], resolutions[i], num_channels].\n  \"\"\"\n  scaled_images = []\n  for height in resolutions:\n    scaled_image = tf.image.resize_images(\n        image,\n        size=[height, height],  # assuming that height = width\n        method=resize_method)\n    scaled_image = tf.to_int64(scaled_image)\n    scaled_image.set_shape([height, height, num_channels])\n    scaled_images.append(scaled_image)\n\n  return scaled_images", "response": "Returns list of images scaled to multiple resolution."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_multiscale_dilated(image, resolutions, num_channels=3):\n  image_height = common_layers.shape_list(image)[0]\n  scaled_images = []\n  for height in resolutions:\n    dilation_rate = image_height // height  # assuming height = width\n    scaled_image = image[::dilation_rate, ::dilation_rate]\n    scaled_image = tf.to_int64(scaled_image)\n    scaled_image.set_shape([None, None, num_channels])\n    scaled_images.append(scaled_image)\n  return scaled_images", "response": "Returns list of images scaled by skipping every nth pixel."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef encode_images_as_png(images):\n  if tf.executing_eagerly():\n    for image in images:\n      yield tf.image.encode_png(image).numpy()\n  else:\n    (height, width, channels) = images[0].shape\n    with tf.Graph().as_default():\n      image_t = tf.placeholder(dtype=tf.uint8, shape=(height, width, channels))\n      encoded_image_t = tf.image.encode_png(image_t)\n      with tf.Session() as sess:\n        for image in images:\n          enc_string = sess.run(encoded_image_t, feed_dict={image_t: image})\n          yield enc_string", "response": "Yield images encoded as pngs."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimages augmentation: cropping, flipping, and color transforms.", "response": "def image_augmentation(images, do_colors=False, crop_size=None):\n  \"\"\"Image augmentation: cropping, flipping, and color transforms.\"\"\"\n  if crop_size is None:\n    crop_size = [299, 299]\n  images = tf.random_crop(images, crop_size + [3])\n  images = tf.image.random_flip_left_right(images)\n  if do_colors:  # More augmentation, but might be slow.\n    images = tf.image.random_brightness(images, max_delta=32. / 255.)\n    images = tf.image.random_saturation(images, lower=0.5, upper=1.5)\n    images = tf.image.random_hue(images, max_delta=0.2)\n    images = tf.image.random_contrast(images, lower=0.5, upper=1.5)\n  return images"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nimage augmentation suitable for CIFAR - 10 and 100.", "response": "def cifar_image_augmentation(images):\n  \"\"\"Image augmentation suitable for CIFAR-10/100.\n\n  As described in https://arxiv.org/pdf/1608.06993v3.pdf (page 5).\n\n  Args:\n    images: a Tensor.\n  Returns:\n    Tensor of the same shape as images.\n  \"\"\"\n  images = tf.image.resize_image_with_crop_or_pad(images, 40, 40)\n  images = tf.random_crop(images, [32, 32, 3])\n  images = tf.image.random_flip_left_right(images)\n  return images"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef random_shift(image, wsr=0.1, hsr=0.1):\n  height, width, _ = common_layers.shape_list(image)\n  width_range, height_range = wsr*width, hsr*height\n  height_translations = tf.random_uniform((1,), -height_range, height_range)\n  width_translations = tf.random_uniform((1,), -width_range, width_range)\n  translations = tf.concat((height_translations, width_translations), axis=0)\n  return tf.contrib.image.translate(image, translations=translations)", "response": "Apply random horizontal and vertical shift to images."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the common attention and feed - forward layers.", "response": "def get_standardized_layers(hparams, dp=None):\n  \"\"\"Get the common attention and feed-forward layers.\n\n  The returned layer functions will have the following signature:\n\n    y, extra_loss = fct(x)\n\n  extra_loss is set to 0.0 if the layer doesn't have extra loss.\n  If dp is provided, the layers will be distributed within the devices.\n  If moe wants to be used, both dp and model need to be set.\n\n  Args:\n    hparams (tf.HParams): the model hparameters\n    dp (expert_utils.Parallelism): A data parallelism object. If not given,\n      the dp calls are simply ignored.\n\n  Returns:\n    dict[str:fct]: A dictionary containing the standardized functions\n  \"\"\"\n\n  def partial(fct, *args, **kwargs):\n    \"\"\"Same as functools.partial but with functools.wraps.\"\"\"\n    return functools.wraps(fct)(functools.partial(fct, *args, **kwargs))\n\n  def register_layer(\n      fct_in,\n      default_args=None,\n      default_kwargs=None,\n      use_dp=True,\n      recompute_grad=False,\n  ):\n    \"\"\"Turn a function into its standardized version.\n\n    Args:\n      fct_in (fct): The function to register\n      default_args (list): The default parameters to add to the function.\n      default_kwargs (dict): The default parameters to add to the function.\n        Those arguments can be overwritten when calling the function.\n      use_dp (bool): Wrap the function call within a dataparallelism object if\n        dp is available. Some layers (like MOE) must be called without dp.\n      recompute_grad (bool): If True, recompute the function during the\n        backward pass to save memory\n\n    Returns:\n      fct: the standardized layer function.\n    \"\"\"\n    # The kwargs given when calling the function overwrite the default ones\n    fct_in = partial(fct_in, *(default_args or []), **(default_kwargs or {}))\n\n    @functools.wraps(fct_in)\n    def decorator(x, *args, **kwargs):\n      \"\"\"Call the layer function.\"\"\"\n      fct = fct_in  # For closure. Could use nonlocal with Python 3\n      # Eventually create the memory optimized version of the function\n      if recompute_grad:\n        fct = partial(fct, **kwargs)  # recompute_grad only accept args\n        fct = common_layers.recompute_grad(fct)\n        kwargs = {}\n\n      # Eventually use dp (if given and not MoE)\n      if use_dp and dp is not None:\n        y = dp(fct, x, *args, **kwargs)\n      else:\n        y = fct(x, *args, **kwargs)\n\n      # Eventually capture the extra loss\n      extra_loss = 0.0\n      if isinstance(y, tuple):\n        y, extra_loss = y\n\n      return y, extra_loss\n\n    return decorator\n\n  total_key_depth = hparams.attention_key_channels or hparams.hidden_size\n  total_value_depth = hparams.attention_value_channels or hparams.hidden_size\n\n  # Attention layers:\n\n  # === Multi-head full attention layer ===\n  multihead_attention_fn = register_layer(\n      multihead_attention,\n      default_kwargs=dict(\n          memory_antecedent=None,  # Self-attention by default\n          bias=None,\n          total_key_depth=total_key_depth,\n          total_value_depth=total_value_depth,\n          output_depth=hparams.hidden_size,\n          num_heads=hparams.num_heads,\n          dropout_rate=hparams.attention_dropout,\n      ))\n\n  # === Memory efficient full-attention layer ===\n  # Save memory by not storing the activations and\n  # recomputing them during the backward pass\n  memeff_attention_base_fn = register_layer(\n      multihead_attention,\n      default_kwargs=dict(\n          total_key_depth=total_key_depth,\n          total_value_depth=total_value_depth,\n          output_depth=hparams.hidden_size,\n          num_heads=hparams.num_heads,\n          dropout_rate=hparams.attention_dropout,\n      ),\n      recompute_grad=True,\n  )\n\n  def memeff_attention_fn(*args, **kwargs):\n    \"\"\"Modify args/kwargs for compatibility with recompute_grad.\"\"\"\n    kwargs = kwargs.copy()\n    assert len(args) == 1\n    x = args[0]\n    memory_antecedent = kwargs.pop(\"memory_antecedent\", x)  # Same as x if None\n    if kwargs.get(\"bias\", None) is not None:  # Case where bias has been set\n      args = (x, memory_antecedent, kwargs.pop(\"bias\"))\n    else:\n      # Otherwise, only 2 args. This is necessary as recompute_grad does not\n      # support None values.\n      args = (x, memory_antecedent)\n    return memeff_attention_base_fn(*args, **kwargs)\n\n  # === Local attention (unmasked) layer ===\n  # Reuse same parameters as multihead_attention\n  # Don't mask the future\n  local_attention_fn = partial(\n      multihead_attention_fn,\n      block_length=hparams.attention_loc_block_length,\n      block_width=hparams.attention_loc_block_width,\n      attention_type=\"local_unmasked\",\n  )\n\n  # === Local attention (masked) layer ===\n  # Reuse same parameters as multihead_attention\n  # Only works for self attention. Always mask the future.\n  local_attention_masked_fn = partial(\n      multihead_attention_fn,\n      block_length=hparams.attention_loc_block_length,\n      attention_type=\"local_mask_right\",\n  )\n\n  # === Masked memory-compressed multihead self attention layer ===\n  # Only works for self attention. Always mask the future.\n  compressed_attention_masked_fn = register_layer(\n      multihead_self_attention_reduced,\n      default_kwargs=dict(\n          factor=hparams.attention_red_factor,\n          nonlinearity=hparams.attention_red_nonlinearity,\n          reduction_type=hparams.attention_red_type,\n          multihead_params=dict(\n              total_key_depth=total_key_depth,\n              total_value_depth=total_value_depth,\n              num_heads=hparams.num_heads,\n              dropout_rate=hparams.attention_dropout,\n          ),\n      ),\n  )\n\n  # === Unmasked memory-compressed multihead self attention layer ===\n  # Only works for self attention. Never mask the future. Bias never added\n  compressed_attention_fn = partial(\n      compressed_attention_masked_fn,\n      add_mask=False,\n  )\n\n  # Feed-forwards layers:\n\n  # === FC layer ===\n  conv_hidden_relu = register_layer(\n      common_layers.conv_hidden_relu,\n      default_kwargs=dict(\n          hidden_size=hparams.filter_size,\n          output_size=hparams.hidden_size,\n          dropout=hparams.relu_dropout,\n      ),\n  )\n\n  # === Separable convolution layer ===\n  # No mask applied\n  sep_conv_relu = partial(\n      conv_hidden_relu,\n      padding=\"SAME\",\n      # Parameters copied from the transformer model, could add hparams\n      kernel_size=(3, 1),\n      second_kernel_size=(31, 1),\n  )\n\n  # === Separable convolution layer (masked version) ===\n  # Mask the future\n  sep_conv_relu_masked = partial(\n      sep_conv_relu,\n      padding=\"LEFT\",  # Mask future for decoder\n  )\n\n  # Define all available layers\n\n  cur_layers = dict(\n      # Attention layers:\n      a=multihead_attention_fn,  # Multihead full attention\n      loc=local_attention_fn,  # Local attention\n      locm=local_attention_masked_fn,  # Local attention (masked)\n      red=compressed_attention_fn,  # Memory-compressed attention\n      redm=compressed_attention_masked_fn,  # Memory-compressed att (masked)\n      mem=memeff_attention_fn,  # Memory efficient\n      # Feed-forward layers:\n      fc=conv_hidden_relu,  # Fully connected\n      sep=sep_conv_relu,  # Separable convolution (unmasked)\n      sepm=sep_conv_relu_masked,  # Separable convolution (masked)\n  )\n  return cur_layers"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_standard_attention_hparams(hparams):\n  # All hyperparameters ending in \"dropout\" are automatically set to 0.0\n  # when not in training mode.\n\n  # hparams used and which should have been defined outside (in\n  # common_hparams):\n  # Global flags\n  # hparams.mode\n  # hparams.hidden_size\n  # Pre-post processing flags\n  # hparams.layer_preprocess_sequence\n  # hparams.layer_postprocess_sequence\n  # hparams.layer_prepostprocess_dropout\n  # hparams.norm_type\n  # hparams.norm_epsilon\n  # Mixture-of-Expert flags\n  # hparams.moe_hidden_sizes\n  # hparams.moe_num_experts\n  # hparams.moe_k\n  # hparams.moe_loss_coef\n\n  # Attention layers flags\n  hparams.add_hparam(\"num_heads\", 8)\n  hparams.add_hparam(\"attention_key_channels\", 0)\n  hparams.add_hparam(\"attention_value_channels\", 0)\n  hparams.add_hparam(\"attention_dropout\", 0.0)\n  # Attention: Local\n  hparams.add_hparam(\"attention_loc_block_length\", 256)\n  # Attention: Local (unmasked only): How much to look left.\n  hparams.add_hparam(\"attention_loc_block_width\", 128)\n  # Attention: Memory-compressed\n  hparams.add_hparam(\"attention_red_factor\", 3)\n  hparams.add_hparam(\"attention_red_type\", \"conv\")\n  hparams.add_hparam(\"attention_red_nonlinearity\", \"none\")\n\n  # Fully connected layers flags\n  # To be more consistent, should use filter_size to also control the MOE\n  # size if moe_hidden_sizes not set.\n  hparams.add_hparam(\"filter_size\", 2048)\n  hparams.add_hparam(\"relu_dropout\", 0.0)\n\n  return hparams", "response": "Adds the hparams used by get_standardized_layers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing encdec attention loss between the expected and actual attentions.", "response": "def encoder_decoder_attention_loss(expected_attention_logits,\n                                   actual_attentions,\n                                   loss_type=\"kl_divergence\",\n                                   loss_multiplier=1.0):\n  \"\"\"Computes encdec attention loss between expected and actual attentions.\n\n  Args:\n    expected_attention_logits: Tensor storing the expected encoder-decoder\n      attention logits with shape [batch_size, target_length, input_length].\n    actual_attentions: Dictionary with actual attention logits for different\n      attention types and hidden layers.\n    loss_type: type of the loss function.\n    loss_multiplier: multiplier for the attention loss.\n\n  Returns:\n    KL_divergence loss between the actual and expected attention logits.\n  \"\"\"\n\n  def combine_attentions(attention_list):\n    \"\"\"Combine different layer attentions and then average over layers/heads.\"\"\"\n    # Stack all hidden layer attention tensors to get a tensor with shape\n    # [num_hidden_layers, batch_size, num_heads, target_length, input_length].\n    attentions = tf.stack(attention_list)\n    # Reduce mean across all layers (axis=0) and all heads (axis=2) to get a\n    # tensor with shape [batch_size, target_length, input_length].\n    return tf.reduce_mean(attentions, [0, 2])\n\n  def kl_divergence_loss(expected_logits, actual_logits):\n    p = tfp.distributions.Categorical(logits=expected_logits)\n    q = tfp.distributions.Categorical(logits=actual_logits)\n    return tfp.distributions.kl_divergence(p, q)\n\n  def mse_loss(expected_logits, actual_weights):\n    expected_weights = tf.nn.softmax(expected_logits)\n    return tf.losses.mean_squared_error(expected_weights, actual_weights)\n\n  # For each hidden layer, we have attention-logit and attention-weight tensors\n  # with shape [batch_size, num_heads, target_length, input_length].\n  loss = 0.0\n  if loss_type == \"mse\":\n    actual_encdec_attention_weights = [\n        t for layer_key, t in actual_attentions.items()\n        if \"encdec_attention\" in layer_key and not layer_key.endswith(\"/logits\")\n    ]\n    actual_attention_weights = combine_attentions(\n        actual_encdec_attention_weights)\n    loss = mse_loss(expected_attention_logits, actual_attention_weights)\n  else:\n    actual_encdec_attention_logits = [\n        t for layer_key, t in actual_attentions.items()\n        if \"encdec_attention\" in layer_key and layer_key.endswith(\"/logits\")\n    ]\n    actual_attention_logits = combine_attentions(actual_encdec_attention_logits)\n    loss = kl_divergence_loss(expected_attention_logits,\n                              actual_attention_logits)\n  return loss * loss_multiplier"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_timing_signal_1d(length,\n                         channels,\n                         min_timescale=1.0,\n                         max_timescale=1.0e4,\n                         start_index=0):\n  \"\"\"Gets a bunch of sinusoids of different frequencies.\n\n  Each channel of the input Tensor is incremented by a sinusoid of a different\n  frequency and phase.\n\n  This allows attention to learn to use absolute and relative positions.\n  Timing signals should be added to some precursors of both the query and the\n  memory inputs to attention.\n\n  The use of relative position is possible because sin(x+y) and cos(x+y) can be\n  expressed in terms of y, sin(x) and cos(x).\n\n  In particular, we use a geometric sequence of timescales starting with\n  min_timescale and ending with max_timescale.  The number of different\n  timescales is equal to channels / 2. For each timescale, we\n  generate the two sinusoidal signals sin(timestep/timescale) and\n  cos(timestep/timescale).  All of these sinusoids are concatenated in\n  the channels dimension.\n\n  Args:\n    length: scalar, length of timing signal sequence.\n    channels: scalar, size of timing embeddings to create. The number of\n        different timescales is equal to channels / 2.\n    min_timescale: a float\n    max_timescale: a float\n    start_index: index of first position\n\n  Returns:\n    a Tensor of timing signals [1, length, channels]\n  \"\"\"\n  position = tf.to_float(tf.range(length) + start_index)\n  num_timescales = channels // 2\n  log_timescale_increment = (\n      math.log(float(max_timescale) / float(min_timescale)) /\n      tf.maximum(tf.to_float(num_timescales) - 1, 1))\n  inv_timescales = min_timescale * tf.exp(\n      tf.to_float(tf.range(num_timescales)) * -log_timescale_increment)\n  scaled_time = tf.expand_dims(position, 1) * tf.expand_dims(inv_timescales, 0)\n  signal = tf.concat([tf.sin(scaled_time), tf.cos(scaled_time)], axis=1)\n  signal = tf.pad(signal, [[0, 0], [0, tf.mod(channels, 2)]])\n  signal = tf.reshape(signal, [1, length, channels])\n  return signal", "response": "This function returns a Tensor of the timing signals for a given length and channels."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_timing_signal_1d(x,\n                         min_timescale=1.0,\n                         max_timescale=1.0e4,\n                         start_index=0):\n  \"\"\"Adds a bunch of sinusoids of different frequencies to a Tensor.\n\n  Each channel of the input Tensor is incremented by a sinusoid of a different\n  frequency and phase.\n\n  This allows attention to learn to use absolute and relative positions.\n  Timing signals should be added to some precursors of both the query and the\n  memory inputs to attention.\n\n  The use of relative position is possible because sin(x+y) and cos(x+y) can be\n  expressed in terms of y, sin(x) and cos(x).\n\n  In particular, we use a geometric sequence of timescales starting with\n  min_timescale and ending with max_timescale.  The number of different\n  timescales is equal to channels / 2. For each timescale, we\n  generate the two sinusoidal signals sin(timestep/timescale) and\n  cos(timestep/timescale).  All of these sinusoids are concatenated in\n  the channels dimension.\n\n  Args:\n    x: a Tensor with shape [batch, length, channels]\n    min_timescale: a float\n    max_timescale: a float\n    start_index: index of first position\n\n  Returns:\n    a Tensor the same shape as x.\n  \"\"\"\n  length = common_layers.shape_list(x)[1]\n  channels = common_layers.shape_list(x)[2]\n  signal = get_timing_signal_1d(length, channels, min_timescale, max_timescale,\n                                start_index)\n  return x + common_layers.cast_like(signal, x)", "response": "Adds a bunch of sinusoids of different frequencies to a Tensor."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget n - dimensional embedding as the layer vertical timing signal.", "response": "def get_layer_timing_signal_learned_1d(channels, layer, num_layers):\n  \"\"\"get n-dimensional embedding as the layer (vertical) timing signal.\n\n  Adds embeddings to represent the position of the layer in the tower.\n\n  Args:\n    channels: dimension of the timing signal\n    layer: layer num\n    num_layers: total number of layers\n\n  Returns:\n    a Tensor of timing signals [1, 1, channels].\n  \"\"\"\n  shape = [num_layers, 1, 1, channels]\n  layer_embedding = (\n      tf.get_variable(\n          \"layer_embedding\",\n          shape,\n          initializer=tf.random_normal_initializer(0, channels**-0.5)) *\n      (channels**0.5))\n  return layer_embedding[layer, :, :, :]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds n - dimensional embedding as the layer ( vertical ) timing signal.", "response": "def add_layer_timing_signal_learned_1d(x, layer, num_layers):\n  \"\"\"Add n-dimensional embedding as the layer (vertical) timing signal.\n\n  Adds embeddings to represent the position of the layer in the tower.\n\n  Args:\n    x: a tensor with shape [batch, length, depth]\n    layer: layer num\n    num_layers: total number of layers\n\n  Returns:\n    a Tensor the same shape as x.\n  \"\"\"\n  channels = common_layers.shape_list(x)[-1]\n  signal = get_layer_timing_signal_learned_1d(channels, layer, num_layers)\n  x += signal\n  return x"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding sinusoids of different frequencies as layer ( vertical ) timing signal.", "response": "def get_layer_timing_signal_sinusoid_1d(channels, layer, num_layers):\n  \"\"\"Add sinusoids of different frequencies as layer (vertical) timing signal.\n\n  Args:\n    channels: dimension of the timing signal\n    layer: layer num\n    num_layers: total number of layers\n\n  Returns:\n    a Tensor of timing signals [1, 1, channels].\n  \"\"\"\n\n  signal = get_timing_signal_1d(num_layers, channels)\n  layer_signal = tf.expand_dims(signal[:, layer, :], axis=1)\n\n  return layer_signal"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding sinusoids of different frequencies as layer vertical timing signal.", "response": "def add_layer_timing_signal_sinusoid_1d(x, layer, num_layers):\n  \"\"\"Add sinusoids of different frequencies as layer (vertical) timing signal.\n\n  Args:\n    x: a Tensor with shape [batch, length, channels]\n    layer: layer num\n    num_layers: total number of layers\n\n  Returns:\n    a Tensor the same shape as x.\n  \"\"\"\n\n  channels = common_layers.shape_list(x)[-1]\n  signal = get_layer_timing_signal_sinusoid_1d(channels, layer, num_layers)\n\n  return x + signal"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd sinusoids of diff frequencies given a given timing position.", "response": "def add_timing_signal_1d_given_position(x,\n                                        position,\n                                        min_timescale=1.0,\n                                        max_timescale=1.0e4):\n  \"\"\"Adds sinusoids of diff frequencies to a Tensor, with timing position given.\n\n  Args:\n    x: a Tensor with shape [batch, length, channels]\n    position: a Tensor with shape [batch, length]\n    min_timescale: a float\n    max_timescale: a float\n\n  Returns:\n    a Tensor the same shape as x.\n  \"\"\"\n  channels = common_layers.shape_list(x)[2]\n  num_timescales = channels // 2\n  log_timescale_increment = (\n      math.log(float(max_timescale) / float(min_timescale)) /\n      (tf.to_float(num_timescales) - 1))\n  inv_timescales = min_timescale * tf.exp(\n      tf.to_float(tf.range(num_timescales)) * -log_timescale_increment)\n  scaled_time = (\n      tf.expand_dims(tf.to_float(position), 2) * tf.expand_dims(\n          tf.expand_dims(inv_timescales, 0), 0))\n  signal = tf.concat([tf.sin(scaled_time), tf.cos(scaled_time)], axis=2)\n  signal = tf.pad(signal, [[0, 0], [0, 0], [0, tf.mod(channels, 2)]])\n  signal = common_layers.cast_like(signal, x)\n  return x + signal"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_timing_signal_nd(x, min_timescale=1.0, max_timescale=1.0e4):\n  num_dims = len(x.get_shape().as_list()) - 2\n  channels = common_layers.shape_list(x)[-1]\n  num_timescales = channels // (num_dims * 2)\n  log_timescale_increment = (\n      math.log(float(max_timescale) / float(min_timescale)) /\n      (tf.to_float(num_timescales) - 1))\n  inv_timescales = min_timescale * tf.exp(\n      tf.to_float(tf.range(num_timescales)) * -log_timescale_increment)\n  for dim in range(num_dims):\n    length = common_layers.shape_list(x)[dim + 1]\n    position = tf.to_float(tf.range(length))\n    scaled_time = tf.expand_dims(position, 1) * tf.expand_dims(\n        inv_timescales, 0)\n    signal = tf.concat([tf.sin(scaled_time), tf.cos(scaled_time)], axis=1)\n    prepad = dim * 2 * num_timescales\n    postpad = channels - (dim + 1) * 2 * num_timescales\n    signal = tf.pad(signal, [[0, 0], [prepad, postpad]])\n    for _ in range(1 + dim):\n      signal = tf.expand_dims(signal, 0)\n    for _ in range(num_dims - 1 - dim):\n      signal = tf.expand_dims(signal, -2)\n    x += signal\n  return x", "response": "Adds a bunch of sinusoids of different frequencies and phase in a different_timescale."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_positional_embedding(x, max_length, name=None, positions=None):\n  with tf.name_scope(\"add_positional_embedding\"):\n    _, length, depth = common_layers.shape_list(x)\n    var = tf.cast(tf.get_variable(name, [max_length, depth]), x.dtype)\n    if positions is None:\n      pad_length = tf.maximum(0, length - max_length)\n      sliced = tf.cond(\n          tf.less(length, max_length),\n          lambda: tf.slice(var, [0, 0], [length, -1]),\n          lambda: tf.pad(var, [[0, pad_length], [0, 0]]))\n      return x + tf.expand_dims(sliced, 0)\n    else:\n      return x + tf.gather(var, tf.to_int32(positions))", "response": "Adds positional embedding to the graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding n - dimensional positional embedding.", "response": "def add_positional_embedding_nd(x, max_length, name=None):\n  \"\"\"Adds n-dimensional positional embedding.\n\n  The embeddings add to all positional dimensions of the tensor.\n\n  Args:\n    x: Tensor with shape [batch, p1 ... pn, depth]. It has n positional\n      dimensions, i.e., 1 for text, 2 for images, 3 for video, etc.\n    max_length: int representing static maximum size of any dimension.\n    name: str representing name of the embedding tf.Variable.\n\n  Returns:\n    Tensor of same shape as x.\n  \"\"\"\n  with tf.name_scope(\"add_positional_embedding_nd\"):\n    x_shape = common_layers.shape_list(x)\n    num_dims = len(x_shape) - 2\n    depth = x_shape[-1]\n    base_shape = [1] * (num_dims + 1) + [depth]\n    base_start = [0] * (num_dims + 2)\n    base_size = [-1] + [1] * num_dims + [depth]\n    for i in range(num_dims):\n      shape = base_shape[:]\n      start = base_start[:]\n      size = base_size[:]\n      shape[i + 1] = max_length\n      size[i + 1] = x_shape[i + 1]\n      var = tf.get_variable(\n          name + \"_%d\" % i,\n          shape,\n          initializer=tf.random_normal_initializer(0, depth**-0.5))\n      var = var * depth**0.5\n      x += tf.slice(var, start, size)\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating the edge vectors for the edge types in the adjacency matrix.", "response": "def make_edge_vectors(adjacency_matrix, num_edge_types, depth, name=None):\n  \"\"\"Gets edge vectors for the edge types in the adjacency matrix.\n\n  Args:\n    adjacency_matrix: A [batch, num_nodes, num_nodes] tensor of ints.\n    num_edge_types: Number of different edge types\n    depth: Number of channels\n    name: a string\n  Returns:\n    A [batch, num_nodes, num_nodes, depth] vector of tensors\n  \"\"\"\n  with tf.variable_scope(name, default_name=\"edge_vectors\"):\n    att_adj_vectors_shape = [num_edge_types, depth]\n    adjacency_matrix_shape = common_layers.shape_list(adjacency_matrix)\n    adj_vectors = (\n        tf.get_variable(\n            \"adj_vectors\",\n            att_adj_vectors_shape,\n            initializer=tf.random_normal_initializer(0, depth**-0.5)) *\n        (depth**0.5))\n    # Avoiding gathers so that it works on TPUs\n    # adjacency_matrix_one_hot has shape\n    # [batch, num_nodes, num_nodes, num_edge_types]\n\n    adjacency_matrix_one_hot = tf.one_hot(adjacency_matrix, num_edge_types)\n\n    att_adj_vectors = tf.matmul(\n        tf.reshape(tf.to_float(adjacency_matrix_one_hot), [-1, num_edge_types]),\n        adj_vectors)\n    return tf.reshape(att_adj_vectors,\n                      [adjacency_matrix_shape[0], adjacency_matrix_shape[1],\n                       adjacency_matrix_shape[2], depth])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the length of a mask based on padding.", "response": "def padding_to_length(padding):\n  \"\"\"Calculate the length of mask based on padding.\n\n  Args:\n    padding: a Tensor with shape [..., length].\n  Returns:\n    a Tensor with shape [...].\n  \"\"\"\n  non_padding = 1.0 - padding\n  return tf.to_int32(tf.reduce_sum(non_padding, axis=-1))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a bias tensor to be added to attention logits.", "response": "def attention_bias_local(length, max_backward, max_forward):\n  \"\"\"Create an bias tensor to be added to attention logits.\n\n  A position may attend to positions at most max_distance from it,\n  forward and backwards.\n\n  This does not actually save any computation.\n\n  Args:\n    length: int\n    max_backward: int, maximum distance backward to attend. Negative values\n      indicate unlimited.\n    max_forward: int, maximum distance forward to attend. Negative values\n      indicate unlimited.\n\n  Returns:\n    a `Tensor` with shape [1, 1, length, length].\n  \"\"\"\n  band = common_layers.ones_matrix_band_part(\n      length,\n      length,\n      max_backward,\n      max_forward,\n      out_shape=[1, 1, length, length])\n  return -1e9 * (1.0 - band)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef attention_bias_same_segment(query_segment_id, memory_segment_id):\n  ret = (tf.to_float(\n      tf.not_equal(\n          tf.expand_dims(query_segment_id, 2),\n          tf.expand_dims(memory_segment_id, 1))) *\n         large_compatible_negative(memory_segment_id.dtype))\n  return tf.expand_dims(ret, axis=1)", "response": "Create an attention bias tensor to be added to attention logits."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an bias tensor to be added to attention logits.", "response": "def attention_bias_ignore_padding(memory_padding):\n  \"\"\"Create an bias tensor to be added to attention logits.\n\n  Args:\n    memory_padding: a float `Tensor` with shape [batch, memory_length].\n\n  Returns:\n    a `Tensor` with shape [batch, 1, 1, memory_length].\n  \"\"\"\n  ret = memory_padding * large_compatible_negative(memory_padding.dtype)\n  return tf.expand_dims(tf.expand_dims(ret, axis=1), axis=1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef attention_bias_to_padding(attention_bias, cast_fn=tf.to_float):\n  # `attention_bias` is a large negative number in padding positions and 0.0\n  # elsewhere.\n  return tf.squeeze(cast_fn(tf.less(attention_bias, -1)), axis=[1, 2])", "response": "Inverse of attention_bias_ignore_padding().\n\n  Args:\n    attention_bias: a `Tensor` with shape [batch, 1, 1, memory_length], as\n      returned by attention_bias_ignore_padding().\n    cast_fn: function used to cast to output type.\n\n  Returns:\n    a Tensor with shape [batch, memory_length] with 1.0 in padding positions\n    and 0.0 in non-padding positions. Type is determined by cast_fn."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef attention_bias_prepend_inputs_full_attention(padding):\n  # Everything past the first padding position is part of the target.\n  # This Tensor has zeros for the source portion and separator,\n  # and ones for the target portion.\n  in_target = tf.cumsum(padding, axis=1, exclusive=True)\n  # The position within the target, or 0 if part of the source.\n  target_pos = tf.cumsum(in_target, axis=1)\n  # A position with a lesser target_pos cannot see a position with greater\n  # target_pos.\n  illegal_connections = tf.greater(\n      tf.expand_dims(target_pos, 1), tf.expand_dims(target_pos, 2))\n  bias = tf.to_float(illegal_connections) * -1e9\n  bias = tf.expand_dims(bias, 1)\n  return bias", "response": "Create a bias tensor for self - attention."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbiasing for self - attention to encourage attention to close positions.", "response": "def attention_bias_proximal(length):\n  \"\"\"Bias for self-attention to encourage attention to close positions.\n\n  Args:\n    length: an integer scalar.\n\n  Returns:\n    a Tensor with shape [1, 1, length, length]\n  \"\"\"\n  r = tf.to_float(tf.range(length))\n  diff = tf.expand_dims(r, 0) - tf.expand_dims(r, 1)\n  return tf.expand_dims(tf.expand_dims(-tf.log1p(tf.abs(diff)), 0), 0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef attention_bias_batch(batch_coordinates_q,\n                         batch_coordinates_k=None,\n                         condition_fn=None):\n  \"\"\"Generate a mask to prevent the batch to attend to each others.\n\n  Args:\n    batch_coordinates_q: Int-like Tensor of shape [length_q, 1] containing the\n      coordinates of the batches\n    batch_coordinates_k: Int-like Tensor of shape [length_k, 1] containing the\n      coordinates of the batches. If None, do self-attention.\n    condition_fn: Callable defining the attention mask.\n\n  Returns:\n    Float-like Tensor of shape [length_q, length_k] containing either 0 or\n    -infinity (-1e9).\n  \"\"\"\n  if batch_coordinates_k is None:\n    batch_coordinates_k = batch_coordinates_q\n\n  # Convert to float first because of b/25387198.\n  def to_float(bc):\n    bc = tf.squeeze(bc, 1)\n    bc = tf.to_float(bc)\n    return bc\n\n  # Broadcast to create [length_q, length_k] mask.\n  bc_v = tf.expand_dims(to_float(batch_coordinates_q), 1)\n  bc_h = tf.expand_dims(to_float(batch_coordinates_k), 0)\n  bias_batch = bc_h - bc_v\n  bias_batch = condition_fn(bias_batch)\n  bias_batch *= -1e9\n  return bias_batch", "response": "Generate a bias batch for the attention."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef split_last_dimension(x, n):\n  x_shape = common_layers.shape_list(x)\n  m = x_shape[-1]\n  if isinstance(m, int) and isinstance(n, int):\n    assert m % n == 0\n  return tf.reshape(x, x_shape[:-1] + [n, m // n])", "response": "Reshape x so that the last dimension becomes two dimensions."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef combine_last_two_dimensions(x):\n  x_shape = common_layers.shape_list(x)\n  a, b = x_shape[-2:]\n  return tf.reshape(x, x_shape[:-2] + [a * b])", "response": "Reshape x so that the last two dimension become one."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes color image summary.", "response": "def attention_image_summary(attn, image_shapes=None):\n  \"\"\"Compute color image summary.\n\n  Args:\n    attn: a Tensor with shape [batch, num_heads, query_length, memory_length]\n    image_shapes: optional tuple of integer scalars.\n      If the query positions and memory positions represent the\n      pixels of flattened images, then pass in their dimensions:\n        (query_rows, query_cols, memory_rows, memory_cols).\n      If the query positions and memory positions represent the\n      pixels x channels of flattened images, then pass in their dimensions:\n        (query_rows, query_cols, query_channels,\n         memory_rows, memory_cols, memory_channels).\n  \"\"\"\n  attn = tf.cast(attn, tf.float32)\n  num_heads = common_layers.shape_list(attn)[1]\n  # [batch, query_length, memory_length, num_heads]\n  image = tf.transpose(attn, [0, 2, 3, 1])\n  image = tf.pow(image, 0.2)  # for high-dynamic-range\n  # Each head will correspond to one of RGB.\n  # pad the heads to be a multiple of 3\n  image = tf.pad(image, [[0, 0], [0, 0], [0, 0], [0, tf.mod(-num_heads, 3)]])\n  image = split_last_dimension(image, 3)\n  image = tf.reduce_max(image, 4)\n  if image_shapes is not None:\n    if len(image_shapes) == 4:\n      q_rows, q_cols, m_rows, m_cols = list(image_shapes)\n      image = tf.reshape(image, [-1, q_rows, q_cols, m_rows, m_cols, 3])\n      image = tf.transpose(image, [0, 1, 3, 2, 4, 5])\n      image = tf.reshape(image, [-1, q_rows * m_rows, q_cols * m_cols, 3])\n    else:\n      assert len(image_shapes) == 6\n      q_rows, q_cols, q_channnels, m_rows, m_cols, m_channels = list(\n          image_shapes)\n      image = tf.reshape(\n          image,\n          [-1, q_rows, q_cols, q_channnels, m_rows, m_cols, m_channels, 3])\n      image = tf.transpose(image, [0, 1, 4, 3, 2, 5, 6, 7])\n      image = tf.reshape(\n          image,\n          [-1, q_rows * m_rows * q_channnels, q_cols * m_cols * m_channels, 3])\n  tf.summary.image(\"attention\", image, max_outputs=1)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef grouped_attention_multihead(query_antecedent,\n                                memory_antecedent,\n                                total_key_depth,\n                                total_value_depth,\n                                output_depth,\n                                num_heads,\n                                num_groups,\n                                memory_target_density=2.0,\n                                multiplicative_overhead=1.25,\n                                additive_overhead=8.0,\n                                mask_right=False,\n                                make_image_summary=True,\n                                name=None):\n  \"\"\"Multi-head dot-product attention with sparsity.\n\n  For each attention head, the queries are partitioned into groups.\n  For each group, only a subset of the key-value pairs are considered.\n\n  The choices of groups are selected based on trained predictors of\n  the total attention given the group inclusion.\n\n  memory_target_density indicates the average how many groups in which\n  a key-value pair should participate.\n\n  We use auxiliary losses to ensure that each group contains roughly\n  the same number of queries and the same number of key-value pairs.\n  If for a given sequence, the actual number of queries/pairs sent to\n  an expert exceeds this target by a factor of more than\n  multiplicative_overhead, then the last ones are dropped.  We use\n  this drop-last policy to avoid bleeding information backwards, which\n  is necessary when using this function with autoregressive\n  prediction.\n\n  Args:\n    query_antecedent: a Tensor with shape [batch, length_q, channels]\n    memory_antecedent: a Tensor with shape [batch, length_m, channels]\n    total_key_depth: an integer\n    total_value_depth: an integer\n    output_depth: an integer\n    num_heads: an integer dividing total_key_depth and total_value_depth\n    num_groups: an integer\n    memory_target_density: a floating point scalar\n    multiplicative_overhead: a floating point scalar\n    additive_overhead: a floating point scalar\n    mask_right: a boolean\n    make_image_summary: a boolean\n    name: an optional string\n\n  Returns:\n    A Tensor with shape [batch, length_q, output_depth]\n\n  Raises:\n    ValueError: if the key depth or value depth are not divisible by the\n      number of attention heads.\n  \"\"\"\n  batch = common_layers.shape_list(query_antecedent)[0]\n  length_q = common_layers.shape_list(query_antecedent)[1]\n  length_kv = common_layers.shape_list(memory_antecedent)[1]\n\n  if total_key_depth % num_heads != 0:\n    raise ValueError(\"Key depth (%d) must be divisible by the number of \"\n                     \"attention heads (%d).\" % (total_key_depth, num_heads))\n  depth_qk = total_key_depth // num_heads\n  if total_value_depth % num_heads != 0:\n    raise ValueError(\"Value depth (%d) must be divisible by the number of \"\n                     \"attention heads (%d).\" % (total_value_depth, num_heads))\n  depth_v = total_value_depth // num_heads\n  with tf.variable_scope(\n      name, default_name=\"multihead_attention_sparse\",\n      values=[query_antecedent, memory_antecedent]):\n    q = common_layers.dense(\n        query_antecedent, total_key_depth, use_bias=False, name=\"q_transform\")\n    kv = common_layers.dense(\n        memory_antecedent,\n        total_key_depth + total_value_depth,\n        use_bias=False,\n        name=\"kv_transform\")\n    q = split_heads(q, num_heads)\n    kv = split_heads(kv, num_heads)\n    # Make predictions about q_total and m_total.\n    # These are used to determine group inclusion.\n    # We will train these by auxiliary losses.  We use stop_gradient here\n    # to keep these losses from back-propagating to the rest of the model.\n    # We add biases that help balance the usage of the experts.\n    q_pred = common_layers.dense(\n        tf.stop_gradient(query_antecedent),\n        num_heads * num_groups,\n        use_bias=False,\n        name=\"q_pred\")\n    q_pred = split_heads(q_pred, num_heads)\n    q_bias = tf.get_variable(\"q_bias\", [1, num_heads, 1, num_groups])\n    q_pred_biased = q_pred + q_bias\n    m_pred = common_layers.dense(\n        tf.stop_gradient(memory_antecedent),\n        num_heads * num_groups,\n        use_bias=False,\n        name=\"m_pred\")\n    m_pred = split_heads(m_pred, num_heads)\n    m_bias = tf.get_variable(\"m_bias\", [1, num_heads, 1, num_groups])\n    m_pred_biased = m_pred + m_bias\n    q *= depth_qk**-0.5\n    # q, kv, q_pred, m_pred are all [batch, heads, length_[q/m], ?]\n    # now reshape them all to [batch * heads, length, ?]\n    q = combine_first_two_dimensions(q)\n    kv = combine_first_two_dimensions(kv)\n    q_pred = combine_first_two_dimensions(q_pred)\n    m_pred = combine_first_two_dimensions(m_pred)\n    q_pred_biased = combine_first_two_dimensions(q_pred_biased)\n    m_pred_biased = combine_first_two_dimensions(m_pred_biased)\n    q_group = tf.argmax(q_pred_biased, axis=2)\n    q_requests = tf.one_hot(q_group, num_groups, axis=-1)\n    m_requests = tf.to_float(tf.greater(m_pred_biased, 0.0))\n    # include first memory position in all groups, to avoid division by zero.\n    m_requests = tf.maximum(\n        m_requests, tf.reshape(tf.one_hot([0], length_kv), [1, length_kv, 1]))\n    q_group_size = tf.reduce_sum(q_requests, 1)\n    m_group_size = tf.reduce_sum(m_requests, 1)\n    q_group_target_size = tf.to_float(length_q) / tf.to_float(num_groups)\n    m_group_target_size = (\n        tf.to_float(length_kv) * memory_target_density /\n        tf.to_float(num_groups))\n    capacity_q = tf.minimum(\n        length_q,\n        tf.to_int32(q_group_target_size * multiplicative_overhead +\n                    additive_overhead))\n    capacity_m = tf.minimum(\n        length_kv,\n        tf.to_int32(m_group_target_size * multiplicative_overhead +\n                    additive_overhead))\n    q_dispatcher = expert_utils.TruncatingDispatcher(q_requests, capacity_q)\n    m_dispatcher = expert_utils.TruncatingDispatcher(m_requests, capacity_m)\n    q_gates = q_dispatcher.gates()\n    m_gates = m_dispatcher.gates()\n    dispatched_q = q_dispatcher.dispatch(q)\n    dispatched_kv = m_dispatcher.dispatch(kv)\n    # dispatched_q: [batch * num_heads, num_groups, capacity_q, depth_qk]\n    # dispatched_kv:\n    #   [batch * num_heads, num_groups, capacity_m, depth_qk + depth_v]\n    k, v = tf.split(dispatched_kv, [depth_qk, depth_v], axis=3)\n    logits = tf.matmul(dispatched_q, k, transpose_b=True)\n    bias = tf.expand_dims((m_dispatcher.nonpadding() - 1.0) * 1e9, 2)\n    if mask_right:\n      q_coordinate = tf.to_float(\n          tf.expand_dims(q_dispatcher.length_coordinate(), 3))\n      m_coordinate = tf.to_float(\n          tf.expand_dims(m_dispatcher.length_coordinate(), 2))\n      bias += tf.to_float(tf.greater(m_coordinate, q_coordinate)) * -1e9\n    logits += bias\n    log_weights = tf.nn.log_softmax(logits)\n    weights = tf.exp(log_weights)\n    # For each query, this is the log of the sum of the unnormalized weights.\n    q_total = tf.stop_gradient(logits[:, :, :, :1] - log_weights[:, :, :, :1])\n    # For each key, this is the sum of the normalized weights.\n    m_total = tf.expand_dims(\n        tf.reduce_sum(tf.stop_gradient(weights), axis=2), -1)\n    o = tf.matmul(weights, v)\n    o = q_dispatcher.combine(o)\n\n    o = tf.reshape(o, [batch, num_heads, length_q, depth_v])\n    o = combine_heads(o)\n    o = common_layers.dense(\n        o, output_depth, use_bias=False, name=\"output_transform\")\n\n    m_total = m_dispatcher.combine(m_total)\n    q_total = q_dispatcher.combine(q_total)\n    q_total = tf.squeeze(q_total, -1)\n    m_total = tf.squeeze(m_total, -1)\n    # Compute summed m predictions for all groups\n    m_pred_used = tf.reduce_sum(tf.exp(m_pred) * m_dispatcher.gates(), axis=2)\n    q_pred_used = tf.reduce_sum(q_pred * q_dispatcher.gates(), axis=2)\n    epsilon = 1e-3\n    m_pred_used = tf.log(m_pred_used + epsilon)\n    m_total = tf.log(m_total + epsilon)\n    m_loss = tf.nn.l2_loss(m_total - m_pred_used)\n    q_loss = tf.nn.l2_loss(\n        (q_total - q_pred_used) * tf.reduce_sum(q_gates, axis=2))\n\n    q_loss /= tf.to_float(batch * length_q)\n    m_loss /= tf.to_float(batch * length_kv)\n\n    # We would like the query groups to be equal sized.  The group\n    # size is discrete, so we need some trick here.  We add a loss\n    # proportional to the product of the group size and the\n    # predictions for that group.  This encourages the predictions to\n    # decrease for groups that are too big.\n    q_group_deviation = (q_group_size / q_group_target_size) - 1.0\n    q_balance_loss = tf.reduce_sum(\n        tf.reduce_mean(q_pred_biased, axis=1) *\n        q_group_deviation) / tf.to_float(batch)\n    m_group_deviation = (m_group_size / m_group_target_size) - 1.0\n    m_balance_loss = tf.reduce_sum(\n        tf.reduce_mean(m_pred_biased, axis=1) *\n        m_group_deviation) / tf.to_float(batch)\n\n    # The losses in this function only propagate back to variables\n    # defined in this function, and the losses outside of this\n    # function only propagate back to variables outside of this\n    # function.  Assuming some kind of adaptive learning algorithm,\n    # it should not matter how much we scale the losses in this function.\n    # Still we scale them down a lot so that they should not show up\n    # much in the overall loss for the model.\n    extra_loss_multiplier = 1e-3\n    extra_loss = q_loss + m_loss + q_balance_loss + m_balance_loss\n    extra_loss *= extra_loss_multiplier\n\n    # Show a bunch of summaries.\n    if common_layers.should_generate_summaries() and make_image_summary:\n      tf.summary.histogram(\"q_group_size\", q_group_size)\n      tf.summary.histogram(\"m_group_size\", m_group_size)\n      tf.summary.scalar(\"q_loss\", q_loss)\n      tf.summary.scalar(\"m_loss\", m_loss)\n      tf.summary.scalar(\"q_balance_loss\", q_balance_loss)\n      tf.summary.scalar(\"m_balance_loss\", m_balance_loss)\n      tf.summary.histogram(\"m_pred_used\", m_pred_used)\n      tf.summary.histogram(\"m_total\", m_total)\n      tf.summary.histogram(\"q_pred_used\", q_pred_used)\n      tf.summary.histogram(\"q_total\", q_total)\n      if make_image_summary:\n        # image summaries are expensive.\n        # So we restrict them to head_num<4, query_position<512, batch_index=0.\n        trunc_heads = min(4, num_heads)\n        trunc_length_q = tf.minimum(length_q, 512)\n        # We recompute the attention for the first example, in an inefficient\n        # way - masking.  This lets us show pretty pictures.\n        # [trunc_heads, length_q, group]\n        q_gates_trunc = q_gates[:trunc_heads, :trunc_length_q, :]\n        # [trunc_heads, length_kv, group]\n        m_gates_trunc = m_gates[:trunc_heads, :, :]\n        grouping_mask = tf.matmul(\n            q_gates_trunc, m_gates_trunc, transpose_b=True)\n        q_trunc = q[:trunc_heads, :trunc_length_q, :]\n        k_trunc = kv[:trunc_heads, :, :depth_qk]\n        logits_trunc = tf.matmul(q_trunc, k_trunc, transpose_b=True)\n        if mask_right:\n          band = common_layers.ones_matrix_band_part(trunc_length_q, length_kv,\n                                                     -1, 0)\n          trunc_bias = tf.expand_dims((1.0 - band) * -1e9, 0)\n          logits_trunc += trunc_bias\n        att_trunc = tf.nn.softmax(logits_trunc)\n        mask_coverage = tf.reduce_sum(grouping_mask * att_trunc) / (\n            tf.to_float(trunc_length_q) * trunc_heads)\n        tf.summary.scalar(\"coverage\", mask_coverage)\n        att_trunc_hdr = tf.pow(att_trunc, 0.2)  # for high-dynamic-range\n        mask_channel = grouping_mask * tf.maximum(att_trunc_hdr, 0.3)\n        image = tf.stack([att_trunc_hdr, mask_channel, mask_channel], axis=3)\n        tf.summary.image(\"att\", image, max_outputs=trunc_heads)\n        # show one group for each head.\n        att_per_group = tf.expand_dims(weights[:trunc_heads, 0, :, :], -1)\n        tf.summary.image(\n            \"att_per_group_%d\",\n            tf.pow(att_per_group, 0.2),\n            max_outputs=trunc_heads)\n    return o, extra_loss", "response": "Multi - head dot - product attention with sparsity."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes attention weights non - zero only on the top - hard_attention_k ones.", "response": "def harden_attention_weights(weights, hard_attention_k):\n  \"\"\"Make attention weights non-0 only on the top-hard_attention_k ones.\"\"\"\n  # Subtract the top-kth weight and zero-out all lower ones.\n  # Note that currently in case of numerical ties it will retain more\n  # than k elements. In the future, we may want to avoid this.\n  weights -= common_layers.top_kth_iterative(weights, hard_attention_k)\n  weights = tf.nn.relu(weights)\n  # Re-normalize the weights.\n  weights_sum = tf.reduce_sum(weights, axis=-1, keep_dims=True)\n  weights_sum = tf.maximum(weights_sum, 1e-6)  # Avoid division by 0.\n  weights /= weights_sum\n  return weights"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndotting - product attention.", "response": "def dot_product_attention(q,\n                          k,\n                          v,\n                          bias,\n                          dropout_rate=0.0,\n                          image_shapes=None,\n                          name=None,\n                          make_image_summary=True,\n                          save_weights_to=None,\n                          dropout_broadcast_dims=None,\n                          activation_dtype=None,\n                          weight_dtype=None,\n                          hard_attention_k=0):\n  \"\"\"Dot-product attention.\n\n  Args:\n    q: Tensor with shape [..., length_q, depth_k].\n    k: Tensor with shape [..., length_kv, depth_k]. Leading dimensions must\n      match with q.\n    v: Tensor with shape [..., length_kv, depth_v] Leading dimensions must\n      match with q.\n    bias: bias Tensor (see attention_bias())\n    dropout_rate: a float.\n    image_shapes: optional tuple of integer scalars.\n      see comments for attention_image_summary()\n    name: an optional string\n    make_image_summary: True if you want an image summary.\n    save_weights_to: an optional dictionary to capture attention weights\n      for visualization; the weights tensor will be appended there under\n      a string key created from the variable scope (including name).\n    dropout_broadcast_dims: an optional list of integers less than rank of q.\n      Specifies in which dimensions to broadcast the dropout decisions.\n    activation_dtype: Used to define function activation dtype when using\n      mixed precision.\n    weight_dtype: The dtype weights are stored in when using mixed precision\n    hard_attention_k: integer, if > 0 triggers hard attention (picking top-k)\n\n  Returns:\n    Tensor with shape [..., length_q, depth_v].\n  \"\"\"\n  with tf.variable_scope(\n      name, default_name=\"dot_product_attention\", values=[q, k, v]) as scope:\n    logits = tf.matmul(q, k, transpose_b=True)  # [..., length_q, length_kv]\n    if bias is not None:\n      bias = common_layers.cast_like(bias, logits)\n      logits += bias\n    # If logits are fp16, upcast before softmax\n    logits = maybe_upcast(logits, activation_dtype, weight_dtype)\n    weights = tf.nn.softmax(logits, name=\"attention_weights\")\n    if hard_attention_k > 0:\n      weights = harden_attention_weights(weights, hard_attention_k)\n    weights = common_layers.cast_like(weights, q)\n    if save_weights_to is not None:\n      save_weights_to[scope.name] = weights\n      save_weights_to[scope.name + \"/logits\"] = logits\n    # Drop out attention links for each head.\n    weights = common_layers.dropout_with_broadcast_dims(\n        weights, 1.0 - dropout_rate, broadcast_dims=dropout_broadcast_dims)\n    if common_layers.should_generate_summaries() and make_image_summary:\n      attention_image_summary(weights, image_shapes)\n    return tf.matmul(weights, v)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _generate_relative_positions_matrix(length_q, length_k,\n                                        max_relative_position,\n                                        cache=False):\n  \"\"\"Generates matrix of relative positions between inputs.\"\"\"\n  if not cache:\n    if length_q == length_k:\n      range_vec_q = range_vec_k = tf.range(length_q)\n    else:\n      range_vec_k = tf.range(length_k)\n      range_vec_q = range_vec_k[-length_q:]\n    distance_mat = range_vec_k[None, :] - range_vec_q[:, None]\n  else:\n    distance_mat = tf.expand_dims(tf.range(-length_k+1, 1, 1), 0)\n  distance_mat_clipped = tf.clip_by_value(distance_mat, -max_relative_position,\n                                          max_relative_position)\n  # Shift values to be >= 0. Each integer still uniquely identifies a relative\n  # position difference.\n  final_mat = distance_mat_clipped + max_relative_position\n  return final_mat", "response": "Generates matrix of relative positions between inputs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate the embeddings for each relative position of dimension depth.", "response": "def _generate_relative_positions_embeddings(length_q, length_k, depth,\n                                            max_relative_position, name,\n                                            cache=False):\n  \"\"\"Generates tensor of size [1 if cache else length_q, length_k, depth].\"\"\"\n  with tf.variable_scope(name):\n    relative_positions_matrix = _generate_relative_positions_matrix(\n        length_q, length_k, max_relative_position, cache=cache)\n    vocab_size = max_relative_position * 2 + 1\n    # Generates embedding for each relative position of dimension depth.\n    embeddings_table = tf.get_variable(\"embeddings\", [vocab_size, depth])\n    embeddings = tf.gather(embeddings_table, relative_positions_matrix)\n    return embeddings"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _relative_attention_inner(x, y, z, transpose):\n  batch_size = tf.shape(x)[0]\n  heads = x.get_shape().as_list()[1]\n  length = tf.shape(x)[2]\n\n  # xy_matmul is [batch_size, heads, length or 1, length or depth]\n  xy_matmul = tf.matmul(x, y, transpose_b=transpose)\n  # x_t is [length or 1, batch_size, heads, length or depth]\n  x_t = tf.transpose(x, [2, 0, 1, 3])\n  # x_t_r is [length or 1, batch_size * heads, length or depth]\n  x_t_r = tf.reshape(x_t, [length, heads * batch_size, -1])\n  # x_tz_matmul is [length or 1, batch_size * heads, length or depth]\n  x_tz_matmul = tf.matmul(x_t_r, z, transpose_b=transpose)\n  # x_tz_matmul_r is [length or 1, batch_size, heads, length or depth]\n  x_tz_matmul_r = tf.reshape(x_tz_matmul, [length, batch_size, heads, -1])\n  # x_tz_matmul_r_t is [batch_size, heads, length or 1, length or depth]\n  x_tz_matmul_r_t = tf.transpose(x_tz_matmul_r, [1, 2, 0, 3])\n  return xy_matmul + x_tz_matmul_r_t", "response": "Relative position - aware dot - product attention inner calculation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dot_product_attention_relative(q,\n                                   k,\n                                   v,\n                                   bias,\n                                   max_relative_position,\n                                   dropout_rate=0.0,\n                                   image_shapes=None,\n                                   save_weights_to=None,\n                                   name=None,\n                                   make_image_summary=True,\n                                   cache=False,\n                                   allow_memory=False,\n                                   hard_attention_k=0):\n  \"\"\"Calculate relative position-aware dot-product self-attention.\n\n  The attention calculation is augmented with learned representations for the\n  relative position between each element in q and each element in k and v.\n\n  Args:\n    q: a Tensor with shape [batch, heads, length, depth].\n    k: a Tensor with shape [batch, heads, length, depth].\n    v: a Tensor with shape [batch, heads, length, depth].\n    bias: bias Tensor.\n    max_relative_position: an integer specifying the maximum distance between\n        inputs that unique position embeddings should be learned for.\n    dropout_rate: a floating point number.\n    image_shapes: optional tuple of integer scalars.\n    save_weights_to: an optional dictionary to capture attention weights\n      for visualization; the weights tensor will be appended there under\n      a string key created from the variable scope (including name).\n    name: an optional string.\n    make_image_summary: Whether to make an attention image summary.\n    cache: whether use cache mode\n    allow_memory: whether to assume that recurrent memory is in use. If True,\n      the length dimension of k/v/bias may be longer than the queries, and it is\n      assumed that the extra memory entries precede the non-memory entries.\n    hard_attention_k: integer, if > 0 triggers hard attention (picking top-k)\n\n  Returns:\n    A Tensor.\n\n  Raises:\n    ValueError: if max_relative_position is not > 0.\n  \"\"\"\n  if not max_relative_position:\n    raise ValueError(\"Max relative position (%s) should be > 0 when using \"\n                     \"relative self attention.\" % (max_relative_position))\n  with tf.variable_scope(\n      name, default_name=\"dot_product_attention_relative\",\n      values=[q, k, v]) as scope:\n\n    # This calculation only works for self attention.\n    # q, k and v must therefore have the same shape, unless memory is enabled.\n    if not cache and not allow_memory:\n      q.get_shape().assert_is_compatible_with(k.get_shape())\n      q.get_shape().assert_is_compatible_with(v.get_shape())\n\n    # Use separate embeddings suitable for keys and values.\n    depth = k.get_shape().as_list()[3]\n    length_k = common_layers.shape_list(k)[2]\n    length_q = common_layers.shape_list(q)[2] if allow_memory else length_k\n    relations_keys = _generate_relative_positions_embeddings(\n        length_q, length_k, depth, max_relative_position,\n        \"relative_positions_keys\", cache=cache)\n    relations_values = _generate_relative_positions_embeddings(\n        length_q, length_k, depth, max_relative_position,\n        \"relative_positions_values\", cache=cache)\n\n    # Compute self attention considering the relative position embeddings.\n    logits = _relative_attention_inner(q, k, relations_keys, True)\n    if bias is not None:\n      logits += bias\n    weights = tf.nn.softmax(logits, name=\"attention_weights\")\n    if hard_attention_k > 0:\n      weights = harden_attention_weights(weights, hard_attention_k)\n    if save_weights_to is not None:\n      save_weights_to[scope.name] = weights\n      save_weights_to[scope.name + \"/logits\"] = logits\n    weights = tf.nn.dropout(weights, 1.0 - dropout_rate)\n    if not tf.get_variable_scope().reuse and make_image_summary:\n      attention_image_summary(weights, image_shapes)\n    return _relative_attention_inner(weights, v, relations_values, False)", "response": "Calculate relative position - aware dot - product self - attention."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _relative_position_to_absolute_position_masked(x):\n  batch, heads, length, _ = common_layers.shape_list(x)\n  x = tf.pad(x, [[0, 0], [0, 0], [0, 0], [1, 0]])\n  x = tf.reshape(x, [batch, heads, 1 + length, length])\n  x = tf.slice(x, [0, 0, 1, 0], [-1, -1, -1, -1])\n  return x", "response": "Helper to dot_product_self_attention_relative_v2.\n\n  Rearrange an attention logits or weights Tensor.\n\n  The dimensions of the input represent:\n  [batch, heads, query_position, memory_position - query_position + length - 1]\n\n  The dimensions of the output represent:\n  [batch, heads, query_position, memory_position]\n\n  Only works with masked_attention.  Undefined behavior for regions of the\n  input where memory_position > query_position.\n\n  Args:\n    x: a Tensor with shape [batch, heads, length, length]\n\n  Returns:\n    a Tensor with shape [batch, heads, length, length]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating relative position - aware dot - product self - attention.", "response": "def dot_product_self_attention_relative_v2(q,\n                                           k,\n                                           v,\n                                           bias,\n                                           max_relative_position=None,\n                                           dropout_rate=0.0,\n                                           image_shapes=None,\n                                           name=None,\n                                           make_image_summary=True,\n                                           dropout_broadcast_dims=None,\n                                           heads_share_relative_embedding=False,\n                                           add_relative_to_values=False):\n  \"\"\"Calculate relative position-aware dot-product self-attention.\n\n  Only works for masked self-attention (no looking forward).\n\n  The attention calculation is augmented with learned representations for the\n  relative position between each element in q and each element in k and v.\n\n  Args:\n    q: a Tensor with shape [batch, heads, length, depth].\n    k: a Tensor with shape [batch, heads, length, depth].\n    v: a Tensor with shape [batch, heads, length, depth].\n    bias: bias Tensor.\n    max_relative_position: an integer indicating the maximum relative distance\n      to look back - changing this invalidates checkpoints\n    dropout_rate: a floating point number.\n    image_shapes: optional tuple of integer scalars.\n    name: an optional string.\n    make_image_summary: Whether to make an attention image summary.\n    dropout_broadcast_dims:  an optional list of integers less than 4\n      specifying in which dimensions to broadcast the dropout decisions.\n      saves memory.\n    heads_share_relative_embedding: a boolean indicating wheather to share\n      relative embeddings between attention heads.\n    add_relative_to_values: a boolean for whether to add relative component to\n      values.\n\n  Returns:\n    A Tensor.\n\n  Raises:\n    ValueError: if max_relative_position is not > 0.\n  \"\"\"\n  if not max_relative_position:\n    raise ValueError(\"Max relative position (%s) should be > 0 when using \"\n                     \"relative self attention.\" % (max_relative_position))\n  with tf.variable_scope(\n      name,\n      default_name=\"dot_product_self_attention_relative_v2\",\n      values=[q, k, v]):\n\n    # This calculation only works for self attention.\n    # q, k and v must therefore have the same shape.\n    q.get_shape().assert_is_compatible_with(k.get_shape())\n    q.get_shape().assert_is_compatible_with(v.get_shape())\n\n    # Use separate embeddings suitable for keys and values.\n    _, num_heads, length, depth_k = common_layers.shape_list(k)\n\n    # [batch, num_heads, query_length, memory_length]\n    logits = tf.matmul(q, k, transpose_b=True)\n    key_relative_embeddings = get_relative_embeddings_left(\n        max_relative_position, length, depth_k, num_heads,\n        heads_share_relative_embedding, \"key_relative_embeddings\")\n\n    rel_logits = matmul_with_relative_keys(q, key_relative_embeddings,\n                                           heads_share_relative_embedding)\n    rel_logits = _relative_position_to_absolute_position_masked(rel_logits)\n    logits += rel_logits\n    if bias is not None:\n      logits += bias\n\n    weights = tf.nn.softmax(logits, name=\"attention_weights\")\n    # Dropping out the attention links for each of the heads.\n    weights = common_layers.dropout_with_broadcast_dims(\n        weights, 1.0 - dropout_rate, broadcast_dims=dropout_broadcast_dims)\n    if common_layers.should_generate_summaries() and make_image_summary:\n      attention_image_summary(weights, image_shapes)\n    output = tf.matmul(weights, v)\n    if add_relative_to_values:\n      # [batch, num_heads, query_length, memory_length]\n      relative_weights = _absolute_position_to_relative_position_masked(weights)\n      depth_v = common_layers.shape_list(v)[3]\n      value_relative_embeddings = get_relative_embeddings_left(\n          max_relative_position, length, depth_v, num_heads,\n          heads_share_relative_embedding, \"value_relative_embeddings\")\n      output += matmul_with_relative_values(\n          relative_weights, value_relative_embeddings,\n          heads_share_relative_embedding)\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _absolute_position_to_relative_position_unmasked(x):\n  batch, heads, length, _ = common_layers.shape_list(x)\n  # padd along column\n  x = tf.pad(x, [[0, 0], [0, 0], [0, 0], [0, length-1]])\n  x_flat = tf.reshape(x, [batch, heads, length**2 + length*(length -1)])\n  # add 0's in the beginning that will skew the elements after reshape\n  x_flat = tf.pad(x_flat, [[0, 0], [0, 0], [length, 0]])\n  x = tf.reshape(x_flat, [batch, heads, length, 2*length])\n  x = tf.slice(x, [0, 0, 0, 1], [batch, heads, length,\n                                 2*length -1])\n  return x", "response": "Helper function for dot_product_unmasked_self_attention_relative_v2."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_relative_embeddings_left_right(max_relative_position, length, depth,\n                                       num_heads,\n                                       heads_share_relative_embedding,\n                                       name):\n  \"\"\"Instantiate or retrieve relative embeddings, sliced according to length.\n\n  Use for unmasked case where the relative attention looks both left and right.\n\n  Args:\n    max_relative_position: an Integer for the number of entries in the relative\n      embedding, which corresponds to the max relative distance that is\n      considered.\n    length: an Integer, specifies the length of the input sequence for which\n      this relative embedding is retrieved for.\n    depth: an Integer, specifies the depth for relative embeddings.\n    num_heads: an Integer, specifies the number of heads.\n    heads_share_relative_embedding: a Boolean specifying if the relative\n      embedding is shared across heads.\n    name: a string giving the name of the embedding variables.\n\n  Returns:\n    a Tensor with shape [length, depth]\n  \"\"\"\n  initializer_stddev = depth**-0.5\n  max_relative_position_unmasked = 2 * max_relative_position - 1\n  if heads_share_relative_embedding:\n    embedding_shape = (max_relative_position_unmasked, depth)\n  else:\n    embedding_shape = (num_heads, max_relative_position_unmasked, depth)\n  relative_embeddings = tf.get_variable(\n      name=name, shape=embedding_shape,\n      initializer=tf.random_normal_initializer(stddev=initializer_stddev))\n  # Pad first before slice to avoid using tf.cond.\n  pad_length = tf.maximum(length - max_relative_position, 0)\n  slice_start_position = tf.maximum(max_relative_position-length, 0)\n  if heads_share_relative_embedding:\n    padded_relative_embeddings = tf.pad(\n        relative_embeddings,\n        [[pad_length, pad_length], [0, 0]])\n    used_relative_embeddings = tf.slice(\n        padded_relative_embeddings,\n        [slice_start_position, 0], [2 * length - 1, -1])\n  else:\n    padded_relative_embeddings = tf.pad(\n        relative_embeddings,\n        [[0, 0], [pad_length, pad_length], [0, 0]])\n    used_relative_embeddings = tf.slice(\n        padded_relative_embeddings,\n        [0, slice_start_position, 0], [-1, 2 * length - 1, -1])\n  return used_relative_embeddings", "response": "Instantiate or retrieve relative embeddings for the given max relative distance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dot_product_unmasked_self_attention_relative_v2(\n    q, k, v, bias, max_relative_position=None, dropout_rate=0.0,\n    image_shapes=None, name=None, make_image_summary=True,\n    dropout_broadcast_dims=None, heads_share_relative_embedding=False,\n    add_relative_to_values=False):\n  \"\"\"Calculate relative position-aware dot-product self-attention.\n\n  The attention calculation is augmented with learned representations for the\n  relative position between each element in q and each element in k and v.\n\n  Args:\n    q: a Tensor with shape [batch, heads, length, depth].\n    k: a Tensor with shape [batch, heads, length, depth].\n    v: a Tensor with shape [batch, heads, length, depth].\n    bias: bias Tensor.\n    max_relative_position: an integer the max relative embedding considered.\n      Changing this invalidates checkpoints.\n    dropout_rate: a floating point number.\n    image_shapes: optional tuple of integer scalars.\n    name: an optional string.\n    make_image_summary: Whether to make an attention image summary.\n    dropout_broadcast_dims:  an optional list of integers less than 4\n      specifying in which dimensions to broadcast the dropout decisions.\n      saves memory.\n    heads_share_relative_embedding: a boolean indicating wheather to share\n      relative embeddings between attention heads.\n    add_relative_to_values: a boolean for whether to add relative component to\n      values.\n\n  Returns:\n    A Tensor.\n\n  Raises:\n    ValueError: if max_relative_position is not > 0.\n  \"\"\"\n  if not max_relative_position:\n    raise ValueError(\"Max relative position (%s) should be > 0 when using \"\n                     \"relative self attention.\" % (max_relative_position))\n\n  with tf.variable_scope(\n      name,\n      default_name=\"dot_product_unmasked_self_attention_relative_v2\",\n      values=[q, k, v]):\n\n    # This calculation only works for self attention.\n    # q, k and v must therefore have the same shape.\n    q.get_shape().assert_is_compatible_with(k.get_shape())\n    q.get_shape().assert_is_compatible_with(v.get_shape())\n\n    # [batch, num_heads, query_length, memory_length]\n    logits = tf.matmul(q, k, transpose_b=True)\n\n    length = common_layers.shape_list(q)[2]\n    k_shape = common_layers.shape_list(k)\n    num_heads = k_shape[1]\n    depth_k = k_shape[-1]\n\n    key_relative_embeddings = get_relative_embeddings_left_right(\n        max_relative_position, length, depth_k, num_heads,\n        heads_share_relative_embedding,\n        \"key_relative_embeddings\")\n    unmasked_rel_logits = matmul_with_relative_keys(\n        q, key_relative_embeddings, heads_share_relative_embedding)\n    unmasked_rel_logits = _relative_position_to_absolute_position_unmasked(\n        unmasked_rel_logits)\n    logits += unmasked_rel_logits\n\n    if bias is not None:\n      logits += bias\n    weights = tf.nn.softmax(logits, name=\"attention_weights\")\n    # dropping out the attention links for each of the heads\n    weights = common_layers.dropout_with_broadcast_dims(\n        weights, 1.0 - dropout_rate, broadcast_dims=dropout_broadcast_dims)\n    # relative_weights.set_shape([None, None, None, max_length])\n    if common_layers.should_generate_summaries() and make_image_summary:\n      attention_image_summary(weights, image_shapes)\n    ret = tf.matmul(weights, v)\n    if add_relative_to_values:\n      # Adds the contribution of the weighted relative embeddings to the values.\n      # [batch, num_heads, query_length, 2*memory_length-1]\n      relative_weights = _absolute_position_to_relative_position_unmasked(\n          weights)\n      depth_v = common_layers.shape_list(v)[3]\n      value_relative_embeddings = get_relative_embeddings_left_right(\n          max_relative_position, length, depth_v, num_heads,\n          heads_share_relative_embedding, \"value_relative_embeddings\")\n      ret += matmul_with_relative_values(\n          relative_weights, value_relative_embeddings,\n          heads_share_relative_embedding)\n    return ret", "response": "Calculate relative position - aware dot - product self - attention."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating relative position unmasked dot - product self - attention for a given set of relative positions.", "response": "def dot_product_unmasked_self_attention_relative_2d(\n    q, k, v, bias, max_relative_position=None, dropout_rate=0.0,\n    image_shapes=None, name=None, make_image_summary=True,\n    dropout_broadcast_dims=None, heads_share_relative_embedding=False,\n    add_relative_to_values=False):\n  \"\"\"Calculate relative position unmasked dot-product self-attention 2d.\n\n\n  The attention calculation is augmented with learned representations for the\n  relative position between each element in q and each element in k and v in\n  height and width dimensions. for query index (i,j) and key index (l, m),\n  the logit is q_i k_j^T + q_i rh_{l-i}^T + q_i rw_{m-j}^T, where rh and ry are\n  the set of relative embeddings in height and width spatial dimensions,\n  respectively.\n\n  Args:\n    q: a Tensor with shape [batch, heads, height, width, depth].\n    k: a Tensor with shape [batch, heads, height, width, depth].\n    v: a Tensor with shape [batch, heads, height, width, depth].\n    bias: bias Tensor.\n    max_relative_position: an integer the max relative embedding considered.\n      Changing this invalidates checkpoints.\n    dropout_rate: a floating point number.\n    image_shapes: optional tuple of integer scalars.\n    name: an optional string.\n    make_image_summary: Whether to make an attention image summary.\n    dropout_broadcast_dims:  an optional list of integers less than 4\n      specifying in which dimensions to broadcast the dropout decisions.\n      saves memory.\n    heads_share_relative_embedding: a boolean indicating wheather to share\n      relative embeddings between attention heads.\n    add_relative_to_values: a boolean for adding relative embeddings to values.\n\n  Returns:\n    [batch, heads, height, width, depth] tensor, the output of attention.\n    height_key_relative_embeddings: a 3d or 2d tensor, depending on head sharing\n      settings, which are the relative embeddings for height.\n    width_key_relative_embeddings: a 3d or 2d tensor, depending on head sharing\n      settings, which are the relative embeddings for width.\n\n  Raises:\n    ValueError: if max_relative_position is not > 0.\n  \"\"\"\n  if not max_relative_position:\n    raise ValueError(\"Max relative position (%s) should be > 0 when using \"\n                     \"relative self attention.\" % (max_relative_position))\n\n  if add_relative_to_values:\n    raise ValueError(\"Adding relative embeddings to values is not implemented\")\n\n  with tf.variable_scope(\n      name,\n      default_name=\"dot_product_self_attention_relative_v2\",\n      values=[q, k, v]):\n\n    # This calculation only works for self attention.\n    # q, k and v must therefore have the same shape.\n    q.get_shape().assert_is_compatible_with(k.get_shape())\n    q.get_shape()[:-1].assert_is_compatible_with(v.get_shape()[:-1])\n\n    (height, width) = (common_layers.shape_list(q)[2],\n                       common_layers.shape_list(q)[3])\n    k_shape = common_layers.shape_list(k)\n    num_heads = k_shape[1]\n    depth_k = k_shape[-1]\n    depth_v = common_layers.shape_list(v)[-1]\n    # flatten height width\n    flatten_hw = lambda x, d: tf.reshape(x, [-1, num_heads, height*width, d])\n    # [batch, num_heads, query_length, memory_length]\n    logits = tf.matmul(flatten_hw(q, depth_k), flatten_hw(k, depth_k),\n                       transpose_b=True)\n\n    def _compute_2d_relative_logits(\n        query, key_relative_embeddings, height, width,\n        heads_share_relative_embedding, transpose_mask):\n      \"\"\"compute relative logits.\"\"\"\n      unmasked_rel_logits = _matmul_with_relative_keys_2d(\n          query, key_relative_embeddings, heads_share_relative_embedding)\n      # collapse height and heads\n      unmasked_rel_logits = tf.reshape(unmasked_rel_logits,\n                                       [-1, num_heads*height, width,\n                                        2*width-1])\n      unmasked_rel_logits = (\n          _relative_position_to_absolute_position_unmasked(\n              unmasked_rel_logits))\n      # shape it back for tiling\n      unmasked_rel_logits = tf.reshape(\n          unmasked_rel_logits, [-1, num_heads, height, width, width])\n      # tiling it height times\n      unmasked_rel_logits = tf.expand_dims(\n          unmasked_rel_logits, axis=3)\n      unmasked_rel_logits = tf.tile(unmasked_rel_logits,\n                                    [1, 1, 1, height, 1, 1])\n      # bringing it to the right shape for adding to the logits.\n      unmasked_rel_logits = tf.transpose(unmasked_rel_logits, transpose_mask)\n      unmasked_rel_logits = tf.reshape(unmasked_rel_logits,\n                                       [-1, num_heads, height*width,\n                                        height*width])\n      return unmasked_rel_logits\n\n    # Relative logits in width dimension first.\n    width_key_relative_embeddings = get_relative_embeddings_left_right(\n        max_relative_position, width, depth_k, num_heads,\n        heads_share_relative_embedding,\n        \"width_key_relative_embeddings\")\n    # [batch, heads, height, 2*width-1, 2*width-1]\n    width_unmasked_rel_logits = _compute_2d_relative_logits(\n        q, width_key_relative_embeddings, height, width,\n        heads_share_relative_embedding, [0, 1, 2, 4, 3, 5])\n    logits += width_unmasked_rel_logits\n    # Relative logits in height dimension next. For ease, we transpose\n    # height and width and repeat the above steps, and transpose to eventually\n    # put the logits in their right positions.\n    # [batch, heads, height, 2*height-1, 2*width-1]\n    height_key_relative_embeddings = get_relative_embeddings_left_right(\n        max_relative_position, height, depth_k, num_heads,\n        heads_share_relative_embedding,\n        \"height_key_relative_embeddings\")\n\n    height_unmasked_rel_logits = _compute_2d_relative_logits(\n        tf.transpose(q, [0, 1, 3, 2, 4]),\n        height_key_relative_embeddings,\n        width,\n        height,\n        heads_share_relative_embedding, [0, 1, 4, 2, 5, 3])\n    logits += height_unmasked_rel_logits\n    if bias is not None:\n      logits += bias\n    weights = tf.nn.softmax(logits, name=\"attention_weights\")\n    # dropping out the attention links for each of the heads\n    weights = common_layers.dropout_with_broadcast_dims(\n        weights, 1.0 - dropout_rate, broadcast_dims=dropout_broadcast_dims)\n    if common_layers.should_generate_summaries() and make_image_summary:\n      attention_image_summary(weights, image_shapes)\n    ret = tf.matmul(weights, flatten_hw(v, depth_v))\n    # reshape back the same spatial dimensions as q\n    return (\n        tf.reshape(ret, [-1, num_heads, height, width, depth_v]),\n        height_key_relative_embeddings,\n        width_key_relative_embeddings)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_2d_local_memory(x, query_shape, memory_flange):\n  (_, height, width, depth_x) = common_layers.shape_list(x)\n  x_center_blocks = _extract_blocks(x, query_shape[0], query_shape[1])\n  # add extra padding to x so that we can extract the memory region\n  # around the center\n  paddings = [[0, 0], [memory_flange[0], memory_flange[0]],\n              [memory_flange[1], memory_flange[1]], [0, 0]]\n  padded_x = tf.pad(x, paddings)\n  padded_x.set_shape([None, height+2*memory_flange[0],\n                      width+2*memory_flange[1], depth_x])\n  x_outer_memory_blocks = _extract_blocks(padded_x,\n                                          memory_flange[0], memory_flange[1])\n  # We'll extract left and right memory blocks, top and bottom memory blocks,\n  # and then the corner memory blocks\n\n  # Each of these after  will have shape\n  # [batch, num_h_blocks, num_w_blocks, query_shape[0],\n  # memory_flange[1], depth]\n  x_left_blocks, x_right_blocks = _get_left_right_blocks(\n      x_outer_memory_blocks)\n  t_hw_block = lambda x: tf.transpose(x, [0, 2, 1, 4, 3, 5])\n  # now to get top and bottom blocks, we should just transpose the outer\n  # blocks, call the same function and transpose back to get shape\n  # [batch, num_h_blocks, num_w_blocks, memory_flange[0],\n  # query_shape[1], depth]\n  x_top_center_blocks, x_bottom_center_blocks = (\n      map(t_hw_block, _get_left_right_blocks(\n          t_hw_block(x_outer_memory_blocks))))\n\n  # now to get the corner blocks\n  x_left_corner_blocks, x_right_corner_blocks = _split_along_width(\n      x_outer_memory_blocks)\n  # now to extract top and bottom for both k and v\n  # we need to transpose because _split_along_width separates along\n  # the width\n  # each of these should have shape [batch, num_h_blocks,\n  # num_w_blocks, memory_flange[0], memory_flange[1], depth]\n\n  t_hw = lambda x: tf.transpose(x, [0, 2, 1, 3, 4, 5])\n  x_top_left_corner_blocks, x_bottom_left_corner_blocks = (\n      map(t_hw, _split_along_width(t_hw(x_left_corner_blocks))))\n  x_top_right_corner_blocks, x_bottom_right_corner_blocks = (\n      map(t_hw, _split_along_width(t_hw(x_right_corner_blocks))))\n\n  # The memory is top_left     top_center    top_right\n  #               left_center  middle        right_center\n  #               bottom_left  bottom_center bottom_right\n  # Assembling the above row by row\n  # first [x_top_left, x_top, x_top_right]\n  # to get [batch, num_h_blocks, num_w_blocks, memory_flange[0],\n  # query_shape[1]+2*memory_flange[1], depth]\n  # then [x_left, x_center, x_right]\n  # then [x_bottom_left, x_bottom, x_bottom_right]\n  x_top_memory = tf.concat(\n      [x_top_left_corner_blocks,\n       x_top_center_blocks,\n       x_top_right_corner_blocks], axis=4)\n  x_middle_memory = tf.concat(\n      [x_left_blocks, x_center_blocks, x_right_blocks], axis=4)\n  x_bottom_memory = tf.concat(\n      [x_bottom_left_corner_blocks,\n       x_bottom_center_blocks,\n       x_bottom_right_corner_blocks], axis=4)\n\n  # concat along height\n  x = tf.concat([x_top_memory, x_middle_memory, x_bottom_memory], axis=3)\n  return x", "response": "Stitches together the local 2d memory blocks."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngathers 2 - D local memory blocks around query blocks.", "response": "def get_2d_local_memory_v2(x, query_shape, memory_flange):\n  \"\"\"Gathering memory blocks around query blocks. flange is half of query .\n\n    Only works if memory flanges are half of query sizes.\n\n  Args:\n    x: a [batch, height, width, depth tensor]\n    query_shape: 2-d integer list of query shape\n    memory_flange: 2-d integer list of memory flanges\n\n  Returns:\n    x: A [batch, num_h_blocks, num_w_blocks,\n          query_shape[0]+2*memory_flange[0],query_shape[1]+2*memory_flange[1]]\n          tensor.\n  \"\"\"\n  (_, height, width, depth_x) = common_layers.shape_list(x)\n  # add extra padding to x so that we can extract the memory region\n  # around the center\n  paddings = [[0, 0], [memory_flange[0], memory_flange[0]],\n              [memory_flange[1], memory_flange[1]], [0, 0]]\n  padded_x = tf.pad(x, paddings)\n  padded_x.set_shape([None, height+2*memory_flange[0],\n                      width+2*memory_flange[1], depth_x])\n  num_h_memory_blocks = height//query_shape[0] + 1\n  num_w_memory_blocks = width//query_shape[1] + 1\n  x_memory_blocks = _extract_blocks(padded_x,\n                                    query_shape[0], query_shape[1])\n  x_width_blocks = tf.split(x_memory_blocks, num_w_memory_blocks,\n                            2)\n  x_left_width = tf.concat(x_width_blocks[:num_w_memory_blocks - 1], axis=2)\n  x_right_width = tf.concat(x_width_blocks[1:], axis=2)\n  x_memory_blocks = tf.concat([x_left_width, x_right_width], axis=4)\n\n  x_height_blocks = tf.split(x_memory_blocks, num_h_memory_blocks, 1)\n  x_top_height = tf.concat(x_height_blocks[:num_h_memory_blocks - 1], axis=1)\n  x_bottom_height = tf.concat(x_height_blocks[1:], axis=1)\n  x = tf.concat([x_top_height, x_bottom_height], axis=3)\n\n  return x"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dot_product_unmasked_attention_local_2d_tpu(\n    q, k, v, bias, max_relative_position=None, query_shape=(8, 8),\n    dropout_rate=0.0, image_shapes=None, name=None, make_image_summary=False,\n    dropout_broadcast_dims=None):\n  \"\"\"Calculate unmasked dot-product local self-attention 2d on tpu.\n\n  Args:\n    q: a Tensor with shape [batch, heads, height, width, depth].\n    k: a Tensor with shape [batch, heads, height, width, depth].\n    v: a Tensor with shape [batch, heads, height, width, depth].\n    bias: bias Tensor.\n    max_relative_position: an integer the max relative embedding considered.\n      Changing this invalidates checkpoints.\n    query_shape: a two tuple indicating query shape\n    dropout_rate: a floating point number.\n    image_shapes: optional tuple of integer scalars.\n    name: an optional string.\n    make_image_summary: Whether to make an attention image summary.\n    dropout_broadcast_dims:  an optional list of integers less than 4\n      specifying in which dimensions to broadcast the dropout decisions.\n      saves memory.\n\n  Returns:\n    [batch, heads, height, width, depth] tensor, the output of attention.\n\n  \"\"\"\n  if max_relative_position:\n    raise ValueError(\"Relative local 2d attention not implemented\")\n\n  with tf.variable_scope(\n      name,\n      default_name=\"dot_product_unmasked_attention_local_2d_tpu\",\n      values=[q, k, v]):\n\n    # This calculation only works for self attention.\n    # q, k and v must therefore have the same shape.\n    q.get_shape().assert_is_compatible_with(k.get_shape())\n    q.get_shape().assert_is_compatible_with(v.get_shape())\n    orig_q_shape = common_layers.shape_list(q)\n    # Pad query, key, value to ensure multiple of corresponding lengths.\n    memory_flange = [int(query_shape[0]//2), int(query_shape[1]//2)]\n    q = pad_to_multiple_2d(q, query_shape)\n    k = pad_to_multiple_2d(k, query_shape)\n    v = pad_to_multiple_2d(v, query_shape)\n    q_shape = common_layers.shape_list(q)\n    (height, width) = (q_shape[2],\n                       q_shape[3])\n    _, num_heads, height, width, depth_k = common_layers.shape_list(k)\n    depth_v = common_layers.shape_list(v)[-1]\n    num_h_blocks = height//query_shape[0]\n    num_w_blocks = width//query_shape[1]\n    # Extract center queries, keys, and values\n    q = tf.reshape(q, [-1, height, width, depth_k])\n    queries = _extract_blocks(\n        q, query_shape[0], query_shape[1])\n    k = tf.reshape(k, [-1, height, width, depth_k])\n    keys = get_2d_local_memory_v2(\n        k, query_shape, memory_flange)\n    v = tf.reshape(v, [-1, height, width, depth_v])\n    values = get_2d_local_memory_v2(\n        v, query_shape, memory_flange)\n    memory_h = query_shape[0] + 2*memory_flange[0]\n    memory_w = query_shape[1] + 2*memory_flange[1]\n    queries = tf.reshape(queries, [-1, num_heads, num_h_blocks, num_w_blocks,\n                                   query_shape[0]*query_shape[1], depth_k])\n    keys = tf.reshape(keys, [-1, num_heads, num_h_blocks, num_w_blocks,\n                             memory_h*memory_w, depth_k])\n    values = tf.reshape(values, [-1, num_heads, num_h_blocks, num_w_blocks,\n                                 memory_h*memory_w, depth_v])\n    logits = tf.matmul(queries, keys, transpose_b=True)\n    if bias is not None:\n      logits += bias\n\n    weights = tf.nn.softmax(logits, name=\"attention_weights\")\n    # Dropping out the attention links for each of the heads\n    weights = common_layers.dropout_with_broadcast_dims(\n        weights, 1.0 - dropout_rate, broadcast_dims=dropout_broadcast_dims)\n    if common_layers.should_generate_summaries() and make_image_summary:\n      attention_image_summary(weights, image_shapes)\n    ret = tf.matmul(weights, values)\n    # we need to get it back to shape [batch, heads, height, width]\n    ret = tf.reshape(ret, [-1, num_heads, num_h_blocks, num_w_blocks,\n                           query_shape[0], query_shape[1], depth_v])\n    ret = tf.transpose(ret, [0, 1, 2, 4, 3, 5, 6])\n    ret = tf.reshape(ret, [-1, num_heads, num_h_blocks*query_shape[0],\n                           num_w_blocks*query_shape[1], depth_v])\n    # slice if padding was introduced\n    ret = tf.slice(ret, [0, 0, 0, 0, 0], [-1, -1, orig_q_shape[2],\n                                          orig_q_shape[3], -1])\n    return ret", "response": "Unmasked dot - product local self - attention on tpu."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates simple unmasked dot-product local self-attention 2d on tpu. The query, key, and value blocks are the same. We do not do a second linear transformation after computing the values Args: x: a Tensor with shape [batch, height, width, depth]. bias: bias Tensor. total_key_depth: the dimensions of the keys total_value_depth: the dimensions of the values num_heads: number of heads query_shape: a two tuple indicating query shape dropout_rate: a floating point number. image_shapes: optional tuple of integer scalars. make_image_summary: Whether to make an attention image summary. dropout_broadcast_dims: an optional list of integers less than 4 specifying in which dimensions to broadcast the dropout decisions. saves memory. Returns: ret: [batch, height, width, total_value_depth] tensor, the output of attention. q: [batch, height, width, total_key_depth] query tensor k: [batch, height, width, total_key_depth] key tensor v: [batch, height, width, total_value_depth] value tensor", "response": "def dot_product_unmasked_attention_local_2d_tpu_simple(\n    x, bias, total_key_depth, total_value_depth, num_heads,\n    query_shape=(8, 8),\n    dropout_rate=0.0, image_shapes=None, make_image_summary=False,\n    dropout_broadcast_dims=None):\n\n  \"\"\"Calculate simple unmasked dot-product local self-attention 2d on tpu.\n\n  The query, key, and value blocks are the same. We do not do a second linear\n  transformation after computing the values\n\n  Args:\n    x: a Tensor with shape [batch, height, width, depth].\n    bias: bias Tensor.\n    total_key_depth: the dimensions of the keys\n    total_value_depth: the dimensions of the values\n    num_heads: number of heads\n    query_shape: a two tuple indicating query shape\n    dropout_rate: a floating point number.\n    image_shapes: optional tuple of integer scalars.\n    make_image_summary: Whether to make an attention image summary.\n    dropout_broadcast_dims:  an optional list of integers less than 4\n      specifying in which dimensions to broadcast the dropout decisions.\n      saves memory.\n\n  Returns:\n    ret: [batch, height, width, total_value_depth] tensor,\n      the output of attention.\n    q: [batch, height, width, total_key_depth] query tensor\n    k: [batch, height, width, total_key_depth] key tensor\n    v: [batch, height, width, total_value_depth] value tensor\n\n  \"\"\"\n  # This calculation only works for self attention.\n  # q, k and v must therefore have the same shape.\n  orig_x_shape = common_layers.shape_list(x)\n  # Pad query, key, value to ensure multiple of corresponding lengths if\n  # necessary\n  is_padded = False\n  if (orig_x_shape[1]%query_shape[0]) != 0 or (\n      orig_x_shape[2]%query_shape[1]) != 0:\n    x = pad_to_multiple_2d(x, query_shape)\n    is_padded = True\n  _, height, width, depth = common_layers.shape_list(x)\n  assert depth%num_heads == 0\n  num_h_blocks = height//query_shape[0]\n  num_w_blocks = width//query_shape[1]\n  # Extract center queries, keys, and values\n  x_blocks = _extract_blocks(x, query_shape[0], query_shape[1])\n  x_blocks = tf.reshape(x_blocks, [-1, query_shape[0]*query_shape[1], depth])\n  q, k, v = compute_qkv(x_blocks, None, total_key_depth, total_value_depth)\n  hsplit = lambda x: split_heads(x, num_heads)\n  q, k, v = map(hsplit, [q, k, v])\n  logits = tf.matmul(q, k, transpose_b=True)\n  if bias is not None:\n    logits += bias\n  weights = tf.nn.softmax(logits, name=\"attention_weights\")\n  # Dropping out the attention links for each of the heads\n  weights = common_layers.dropout_with_broadcast_dims(\n      weights, 1.0 - dropout_rate, broadcast_dims=dropout_broadcast_dims)\n  if common_layers.should_generate_summaries() and make_image_summary:\n    attention_image_summary(weights, image_shapes)\n  output = tf.matmul(weights, v)\n  output = combine_heads(output)\n  # we need to get it back to shape [batch, height, width]\n  ret = tf.reshape(output, [-1, num_h_blocks, num_w_blocks,\n                            query_shape[0], query_shape[1], total_value_depth])\n\n  ret = tf.transpose(ret, [0, 1, 3, 2, 4, 5])\n  ret = tf.reshape(ret, [-1, num_h_blocks*query_shape[0],\n                         num_w_blocks*query_shape[1], total_value_depth])\n  # slice if padding was introduced\n  if is_padded:\n    ret = tf.slice(ret, [0, 0, 0, 0], [-1, orig_x_shape[1],\n                                       orig_x_shape[2], -1])\n  return ret, q, k, v"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef masked_within_block_local_attention_1d(q, k, v, block_length=64, name=None):\n  with tf.variable_scope(\n      name, default_name=\"within_local_attention_1d\", values=[q, k, v]):\n    batch, heads, length, depth_k = common_layers.shape_list(q)\n    depth_v = common_layers.shape_list(v)[-1]\n    if isinstance(block_length, tf.Tensor):\n      const = tf.contrib.util.constant_value(block_length)\n      if const is not None:\n        block_length = int(const)\n\n    # Pad query, key, value to ensure multiple of block length.\n    original_length = length\n    padding_size = tf.mod(-length, block_length)\n    length += padding_size\n    padding = [[0, 0], [0, 0], [0, padding_size], [0, 0]]\n    q = tf.pad(q, padding)\n    k = tf.pad(k, padding)\n    v = tf.pad(v, padding)\n\n    # Compute attention for all subsequent query blocks.\n    num_blocks = tf.div(length, block_length)\n    q = tf.reshape(q, [batch, heads, num_blocks, block_length, depth_k])\n    k = tf.reshape(k, [batch, heads, num_blocks, block_length, depth_k])\n    v = tf.reshape(v, [batch, heads, num_blocks, block_length, depth_v])\n    # [batch, heads, num_blocks, block_length, block_length]\n    attention = tf.matmul(q, k, transpose_b=True)\n    attention += tf.reshape(attention_bias_lower_triangle(block_length),\n                            [1, 1, 1, block_length, block_length])\n    attention = tf.nn.softmax(attention)\n    # [batch, heads, num_blocks, block_length, depth_v]\n    output = tf.matmul(attention, v)\n    output = tf.reshape(output, [batch, heads, -1, depth_v])\n\n    # Remove the padding if introduced.\n    output = tf.slice(output, [0, 0, 0, 0], [-1, -1, original_length, -1])\n    output.set_shape([None if isinstance(dim, tf.Tensor) else dim for dim in\n                      (batch, heads, length, depth_v)])\n    return output", "response": "Attention to the source and a neighborhood to the left within a block."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _relative_position_to_absolute_position_unmasked(x):\n  x_shape = common_layers.shape_list(x)\n  batch = x_shape[0]\n  heads = x_shape[1]\n  length = x_shape[2]\n  # Concat columns of pad to shift from relative to absolute indexing.\n  col_pad = tf.zeros((batch, heads, length, 1))\n  x = tf.concat([x, col_pad], axis=3)\n\n  # Concat extra elements so to add up to shape (len+1, 2*len-1).\n  flat_x = tf.reshape(x, [batch, heads, length * 2 * length])\n  flat_pad = tf.zeros((batch, heads, length-1))\n  flat_x_padded = tf.concat([flat_x, flat_pad], axis=2)\n\n  # Reshape and slice out the padded elements.\n  final_x = tf.reshape(flat_x_padded, [batch, heads, length+1, 2*length-1])\n  final_x = final_x[:, :, :, length-1:]\n  final_x = final_x[:, :, :length, :]\n  return final_x", "response": "Converts tensor from relative to absolute indexing for local attention."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef masked_relative_local_attention_1d(q,\n                                       k,\n                                       v,\n                                       block_length=128,\n                                       make_image_summary=False,\n                                       dropout_rate=0.,\n                                       heads_share_relative_embedding=False,\n                                       add_relative_to_values=False,\n                                       name=None):\n  \"\"\"Masked local 1d attention with relative positions.\n\n  The sequence is divided into blocks of length block_size.\n  Attention for a given query position can only see memory positions\n  less than or equal to the query position, in the corresponding block\n  and the previous block.\n\n  If mask_right is True, then a target position cannot see greater source\n  positions.\n\n  Args:\n    q: a Tensor with shape [batch, heads, length, depth_k]\n    k: a Tensor with shape [batch, heads, length, depth_k]\n    v: a Tensor with shape [batch, heads, length, depth_v]\n    block_length: an integer\n    make_image_summary: a boolean, whether to make an attention image summary.\n    dropout_rate: Dropout rate for attention dropout\n    heads_share_relative_embedding: a boolean for sharing relative embeddings.\n    add_relative_to_values: a boolean for whether to add relative component to\n        values.\n    name: an optional string\n\n  Returns:\n    a Tensor of shape [batch, heads, length, depth_v]\n\n  Raises:\n    ValueError: wwhen the name for the variable scope is not passed.\n  \"\"\"\n  if not name:\n    raise ValueError(\"Name must be assigned since reuse for variable scope is \"\n                     \"set to tf.AUTO_REUSE, in order to reuse relative \"\n                     \"embeddings of keys and values.\")\n\n  # Reuse flag is set to auto_reuse to reuse relative embeddings of keys and\n  # values across blocks (first and tail blocks).\n  with tf.variable_scope(\n      name, default_name=\"masked_relative_local_attention_1d\",\n      values=[q, k, v], reuse=tf.AUTO_REUSE):\n\n    default_block_length = block_length\n    batch = common_layers.shape_list(q)[0]\n    heads = common_layers.shape_list(q)[1]\n    length = common_layers.shape_list(q)[2]\n    # If (length < 2 * block_length), then we use only one block.\n    if isinstance(length, int) and isinstance(block_length, int):\n      block_length = length if length < block_length * 2 else block_length\n    else:\n      block_length = tf.where(\n          tf.less(length, block_length * 2), length, block_length)\n    depth_k = common_layers.shape_list(k)[3]\n    depth_v = common_layers.shape_list(v)[3]\n    original_length = length\n    padding_size = tf.mod(-length, block_length)\n    length += padding_size\n    padding = [[0, 0], [0, 0], [0, padding_size], [0, 0]]\n    q = tf.pad(q, padding)\n    k = tf.pad(k, padding)\n    v = tf.pad(v, padding)\n\n    num_blocks = length // block_length\n    # compute attention for the first query block.\n    first_q = tf.slice(q, [0, 0, 0, 0], [-1, -1, block_length, -1])\n    first_k = tf.slice(k, [0, 0, 0, 0], [-1, -1, block_length, -1])\n    first_v = tf.slice(v, [0, 0, 0, 0], [-1, -1, block_length, -1])\n    # Relative embeddings will be used later as well.\n    # TODO(avaswani,annahuang): check why 2*bl was breaking for music\n    # Needs to be known at static shape inference time, hence cannot be\n    # 2 * block_length.\n    rel_embed_length = 4 * default_block_length\n    # We only multiply with the needed embeddings as we slice them out.\n    first_rel_embeddings = get_relative_embeddings_left(\n        rel_embed_length, block_length, depth_k, heads,\n        heads_share_relative_embedding, \"relative_embeddings\")\n    first_rel_logits = matmul_with_relative_keys(\n        first_q, first_rel_embeddings, heads_share_relative_embedding)\n    first_logits = tf.matmul(first_q, first_k, transpose_b=True)\n    first_logits += (\n        _relative_position_to_absolute_position_masked(first_rel_logits))\n    # adding a mask\n    first_logits += (\n        common_layers.cast_like(attention_bias_lower_triangle(block_length),\n                                first_logits))\n    first_att = tf.nn.softmax(first_logits,\n                              name=\"first_attention_weights\")\n    # dropping out the attention links for each of the heads\n    first_att = common_layers.dropout_with_broadcast_dims(\n        first_att, 1.0 - dropout_rate,\n        broadcast_dims=None)\n    # only call image summary for the first block\n    if common_layers.should_generate_summaries() and make_image_summary:\n      attention_image_summary(first_att, None)\n    first_output = tf.matmul(first_att, first_v)\n\n    # compute attention for all subsequent query blocks.\n    q = tf.reshape(q, [batch, heads, num_blocks, block_length, depth_k])\n    k = tf.reshape(k, [batch, heads, num_blocks, block_length, depth_k])\n    v = tf.reshape(v, [batch, heads, num_blocks, block_length, depth_v])\n    local_k = _make_local_block(k, depth_k, batch, heads, num_blocks,\n                                block_length)\n    local_v = _make_local_block(v, depth_v, batch, heads, num_blocks,\n                                block_length)\n    tail_q = tf.slice(q, [0, 0, 1, 0, 0], [-1, -1, -1, -1, -1])\n    tail_q = tf.reshape(tail_q,\n                        [batch, heads, num_blocks - 1, block_length, depth_k])\n    local_length = common_layers.shape_list(local_k)[3]\n\n    # collapsing num blocks and batch size so that we can reuse\n    # functions\n    def _reshape_for_relative(x):\n      x_shape = common_layers.shape_list(x)\n      # [batch, num_blocks, heads, length, depth]\n      x = tf.transpose(x, [0, 2, 1, 3, 4])\n      x = tf.reshape(x, [batch*x_shape[2], heads, x_shape[3],\n                         x_shape[4]])\n      return x\n    rel_tail_q = _reshape_for_relative(tail_q)\n    rel_k = _reshape_for_relative(local_k)\n    rel_v = _reshape_for_relative(local_v)\n    rel_embeddings = get_relative_embeddings_left(\n        rel_embed_length, 2 * block_length, depth_k, heads,\n        heads_share_relative_embedding, \"relative_embeddings\")\n    rel_logits = matmul_with_relative_keys(\n        rel_tail_q, rel_embeddings, heads_share_relative_embedding)\n    # Computing relative logits separately for the masked and unmasked parts\n    # because the reshaping logic is different for both\n    masked_rel_logits = tf.slice(rel_logits, [0, 0, 0, block_length],\n                                 [-1, -1, -1, -1])\n    masked_rel_logits = _relative_position_to_absolute_position_masked(\n        masked_rel_logits)\n    unmasked_rel_logits = tf.slice(rel_logits, [0, 0, 0, 0],\n                                   [-1, -1, -1, 2*block_length-1])\n    unmasked_rel_logits = _relative_position_to_absolute_position_unmasked(\n        unmasked_rel_logits)\n    all_rel_logits = tf.concat([unmasked_rel_logits, masked_rel_logits],\n                               axis=3)\n    all_logits = (\n        tf.matmul(rel_tail_q, rel_k, transpose_b=True) + all_rel_logits)\n    # make sure source_pos <= target_pos\n    good_part = common_layers.ones_matrix_band_part(block_length,\n                                                    local_length,\n                                                    -1, block_length)\n    mask = (1.0 - good_part) * -1e9\n    mask = common_layers.cast_like(mask, all_logits)\n    all_logits += tf.reshape(mask, [1, 1, block_length, local_length])\n    weights = tf.nn.softmax(all_logits, name=\"attention_weights\")\n    # [batch (* num_blocks), heads, query_length (=block_length),\n    # key_length (=2*block_length)]\n    weights = common_layers.dropout_with_broadcast_dims(\n        weights, 1.0 - dropout_rate,\n        broadcast_dims=None)\n\n    output = tf.matmul(weights, rel_v)\n    if add_relative_to_values:\n      # Adds the contribution of the weighted relative embeddings to the values.\n      weights_for_unmasked, weights_for_masked = (\n          tf.split(weights, 2, axis=3))\n      rel_weights_unmasked = _absolute_position_to_relative_position_unmasked(\n          weights_for_unmasked)\n      rel_weights_masked = _absolute_position_to_relative_position_masked(\n          weights_for_masked)\n\n      value_rel_embeddings_unmasked = get_relative_embeddings_left(\n          rel_embed_length, 2 * block_length, depth_v,\n          heads, heads_share_relative_embedding,\n          \"value_relative_embeddings\")\n      # The unmasked part starts with index -1 as opposed 0 has take uptil last.\n      if heads_share_relative_embedding:\n        value_rel_embeddings_unmasked = value_rel_embeddings_unmasked[:-1, :]\n      else:\n        value_rel_embeddings_unmasked = value_rel_embeddings_unmasked[:, :-1, :]\n      value_rel_embeddings_masked = get_relative_embeddings_left(\n          rel_embed_length, block_length, depth_v,\n          heads, heads_share_relative_embedding,\n          \"value_relative_embeddings\")\n\n      # [batch (*num_blocks), heads, query length, key length]\n      rel_weights = tf.concat(\n          [rel_weights_unmasked, rel_weights_masked], axis=3)\n      if heads_share_relative_embedding:\n        value_rel_embeddings_concat_axis = 0\n      else:\n        value_rel_embeddings_concat_axis = 1\n      value_rel_embeddings = tf.concat(\n          [value_rel_embeddings_unmasked, value_rel_embeddings_masked],\n          axis=value_rel_embeddings_concat_axis)\n      output_rel = matmul_with_relative_values(\n          rel_weights, value_rel_embeddings, heads_share_relative_embedding)\n      output += output_rel\n\n    # bring to [batch, heads, num_blocks-1, block_length, depth]\n    output = tf.reshape(output,\n                        [batch, num_blocks-1, heads, block_length, depth_v])\n    output = tf.transpose(output, [0, 2, 1, 3, 4])\n\n    output = tf.reshape(\n        output, [batch, heads, (num_blocks - 1) * block_length, depth_v])\n    output = tf.concat([first_output, output], axis=2)\n    output = tf.slice(output, [0, 0, 0, 0], [-1, -1, original_length, -1])\n    output = tf.reshape(output, [batch, heads, original_length, depth_v])\n    return output", "response": "Mask local 1d attention with relative positions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstride block local self - attention.", "response": "def local_attention_1d(q, k, v, block_length=128, filter_width=100, name=None):\n  \"\"\"Strided block local self-attention.\n\n  The sequence is divided into blocks of length block_length. Attention for a\n  given query position can see all memory positions in the corresponding block\n  and filter_width many positions to the left and right of the block.\n\n  Args:\n    q: a Tensor with shape [batch, heads, length, depth_k]\n    k: a Tensor with shape [batch, heads, length, depth_k]\n    v: a Tensor with shape [batch, heads, length, depth_v]\n    block_length: an integer\n    filter_width: an integer indicating how much to look left and right of the\n      block.\n    name: an optional string\n\n  Returns:\n    a Tensor of shape [batch, heads, length, depth_v]\n  \"\"\"\n  with tf.variable_scope(\n      name, default_name=\"local_self_attention_1d\", values=[q, k, v]):\n    # Check that q, k, v have the same shape except in their depth dimension.\n    q.get_shape()[:-1].assert_is_compatible_with(k.get_shape()[:-1])\n    q.get_shape()[:-1].assert_is_compatible_with(v.get_shape()[:-1])\n\n    batch_size, num_heads, original_length, _ = common_layers.shape_list(q)\n\n    # Pad query, key, value to ensure multiple of corresponding lengths.\n    def pad_to_multiple(x, pad_length):\n      x_length = common_layers.shape_list(x)[2]\n      return tf.pad(x, [[0, 0], [0, 0], [0, -x_length % pad_length], [0, 0]])\n\n    def pad_l_and_r(x, pad_length):\n      return tf.pad(x, [[0, 0], [0, 0], [pad_length, pad_length], [0, 0]])\n\n    # Set up query blocks.\n    # [batch, heads, blocks_q, block_length, depth_k]\n    q = pad_to_multiple(q, block_length)\n    q = reshape_by_blocks(q, common_layers.shape_list(q), block_length)\n    total_query_blocks = common_layers.shape_list(q)[2]\n\n    # Set up key and value blocks.\n    # [batch, heads, blocks_k, block_length, depth_k]\n    blocks_per_filter_width = filter_width // block_length\n    remaining_items = filter_width % block_length\n    k = pad_to_multiple(k, block_length)\n    v = pad_to_multiple(v, block_length)\n    k = pad_l_and_r(k, filter_width + block_length - remaining_items)\n    v = pad_l_and_r(v, filter_width + block_length - remaining_items)\n    k = reshape_by_blocks(k, common_layers.shape_list(k), block_length)\n    v = reshape_by_blocks(v, common_layers.shape_list(v), block_length)\n\n    total_kv_blocks = common_layers.shape_list(k)[2]\n\n    slices = []\n    # prepare the left-most and right-most partial blocks if needed\n    if remaining_items:\n      first_partial_block_k = tf.slice(\n          k, [0, 0, 0, block_length - remaining_items, 0],\n          [-1, -1, total_query_blocks, -1, -1])\n      first_partial_block_v = tf.slice(\n          v, [0, 0, 0, block_length - remaining_items, 0],\n          [-1, -1, total_query_blocks, -1, -1])\n      last_partial_block_k = tf.slice(\n          k, [0, 0, total_kv_blocks - total_query_blocks, 0, 0],\n          [-1, -1, -1, remaining_items, -1])\n      last_partial_block_v = tf.slice(\n          v, [0, 0, total_kv_blocks - total_query_blocks, 0, 0],\n          [-1, -1, -1, remaining_items, -1])\n      slices.append((first_partial_block_k, first_partial_block_v))\n      slices.append((last_partial_block_k, last_partial_block_v))\n\n    # Prepare the rest of the blocks\n    first_block_index = 1 if remaining_items else 0\n    attention_blocks = 2 * blocks_per_filter_width + 1\n    for i in range(first_block_index, attention_blocks + first_block_index):\n      block_k = tf.slice(k, [0, 0, i, 0, 0],\n                         [-1, -1, total_query_blocks, -1, -1])\n      block_v = tf.slice(v, [0, 0, i, 0, 0],\n                         [-1, -1, total_query_blocks, -1, -1])\n      slices.append((block_k, block_v))\n    # [batch, heads, blocks_q, block_length + 2 * filter_width, depth_k]\n    k = tf.concat([s[0] for s in slices], axis=3)\n    v = tf.concat([s[1] for s in slices], axis=3)\n\n    attention_bias = tf.expand_dims(embedding_to_padding(k) * -1e9, axis=-2)\n    depth_v = common_layers.shape_list(v)[-1]\n\n    output = dot_product_attention(\n        q,\n        k,\n        v,\n        attention_bias,\n        dropout_rate=0.,\n        name=\"local_1d\",\n        make_image_summary=False)\n    output = tf.reshape(output, [batch_size, num_heads, -1, depth_v])\n\n    # Remove the padding if introduced.\n    output = tf.slice(output, [0, 0, 0, 0], [-1, -1, original_length, -1])\n    output.set_shape([None if isinstance(dim, tf.Tensor) else dim for dim in\n                      (batch_size, num_heads, original_length, depth_v)])\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reshape_by_blocks(x, x_shape, memory_block_size):\n  x = tf.reshape(x, [\n      x_shape[0], x_shape[1], x_shape[2] // memory_block_size,\n      memory_block_size, x_shape[3]\n  ])\n  return x", "response": "Reshapes input by splitting its length over blocks of memory_block_size."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dilated_self_attention_1d(q,\n                              k,\n                              v,\n                              query_block_size=128,\n                              memory_block_size=128,\n                              gap_size=2,\n                              num_memory_blocks=2,\n                              name=None):\n  \"\"\"Dilated self-attention.\n\n  Args:\n    q: a Tensor with shape [batch, heads, length, depth]\n    k: a Tensor with shape [batch, heads, length, depth]\n    v: a Tensor with shape [batch, heads, length, depth]\n    query_block_size: an integer indicating size of query block\n    memory_block_size: an integer indicating the size of a memory block.\n    gap_size: an integer indicating the gap size\n    num_memory_blocks: how many memory blocks to look at to the left and right.\n      Each will be separated by gap_size.\n    name: an optional string\n\n  Returns:\n    a Tensor of shape [batch, heads, length, depth]\n  \"\"\"\n  with tf.variable_scope(\n      name, default_name=\"dilated_self_attention_1d\", values=[q, k, v]):\n    v_list_shape = v.get_shape().as_list()\n    assert v_list_shape == k.shape.as_list(), \"K and V depths must be equal\"\n    v_shape = common_layers.shape_list(v)\n    depth_v = v_shape[3]\n    batch_size = v_shape[0]\n    num_heads = v_shape[1]\n    original_length = common_layers.shape_list(q)[2]\n\n    # Pad query, key, value to ensure multiple of corresponding lengths.\n    def pad_to_multiple(x, pad_length):\n      x_length = common_layers.shape_list(x)[2]\n      return tf.pad(x, [[0, 0], [0, 0], [0, -x_length % pad_length], [0, 0]])\n\n    def pad_l_and_r(x, pad_length):\n      return tf.pad(x, [[0, 0], [0, 0], [pad_length, pad_length], [0, 0]])\n\n    q = pad_to_multiple(q, query_block_size)\n    v = pad_to_multiple(v, query_block_size)\n    k = pad_to_multiple(k, query_block_size)\n\n    # Set up query blocks.\n    new_q_shape = common_layers.shape_list(q)\n    q = reshape_by_blocks(q, new_q_shape, query_block_size)\n    self_k_part = reshape_by_blocks(k, new_q_shape, query_block_size)\n    self_v_part = reshape_by_blocks(v, new_q_shape, query_block_size)\n\n    # Set up key and value windows.\n    k_v_padding = (gap_size + memory_block_size) * num_memory_blocks\n    k = pad_l_and_r(k, k_v_padding)\n    v = pad_l_and_r(v, k_v_padding)\n\n    # Get gather indices.\n    index_length = (new_q_shape[2] - query_block_size + memory_block_size)\n    indices = tf.range(0, index_length, delta=1, name=\"index_range\")\n    indices = tf.reshape(indices, [1, -1, 1])  # [1, length, 1] for convs\n    kernel = tf.expand_dims(tf.eye(memory_block_size), axis=1)\n    gather_indices = tf.nn.conv1d(\n        tf.cast(indices, tf.float32),\n        kernel,\n        query_block_size,\n        padding=\"VALID\",\n        name=\"gather_conv\")\n\n    gather_indices = tf.squeeze(tf.cast(gather_indices, tf.int32), axis=0)\n\n    # Get left and right memory blocks for each query.\n    # [length, batch, heads, dim]\n    k_t = tf.transpose(k, [2, 0, 1, 3])\n    v_t = tf.transpose(v, [2, 0, 1, 3])\n    left_k = gather_dilated_memory_blocks(\n        k_t[:-k_v_padding, :, :, :], num_memory_blocks, gap_size,\n        query_block_size, memory_block_size, gather_indices)\n    left_v = gather_dilated_memory_blocks(\n        v_t[:-k_v_padding, :, :, :], num_memory_blocks, gap_size,\n        query_block_size, memory_block_size, gather_indices)\n\n    right_k = gather_dilated_memory_blocks(\n        k_t[k_v_padding:, :, :, :],\n        num_memory_blocks,\n        gap_size,\n        query_block_size,\n        memory_block_size,\n        gather_indices,\n        direction=\"right\")\n    right_v = gather_dilated_memory_blocks(\n        v_t[k_v_padding:, :, :, :],\n        num_memory_blocks,\n        gap_size,\n        query_block_size,\n        memory_block_size,\n        gather_indices,\n        direction=\"right\")\n\n    k_windows = tf.concat([left_k, self_k_part, right_k], axis=3)\n    v_windows = tf.concat([left_v, self_v_part, right_v], axis=3)\n    attention_bias = tf.expand_dims(\n        embedding_to_padding(k_windows) * -1e9, axis=-2)\n\n    output = dot_product_attention(\n        q,\n        k_windows,\n        v_windows,\n        attention_bias,\n        dropout_rate=0.,\n        name=\"dilated_1d\",\n        make_image_summary=False)\n    output = tf.reshape(output, [batch_size, num_heads, -1, depth_v])\n\n    # Remove the padding if introduced.\n    output = tf.slice(output, [0, 0, 0, 0], [-1, -1, original_length, -1])\n    output.set_shape(v_list_shape)\n    return output", "response": "Dilated self - attention."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngather blocks with gaps in between.", "response": "def gather_dilated_memory_blocks(x,\n                                 num_memory_blocks,\n                                 gap_size,\n                                 query_block_size,\n                                 memory_block_size,\n                                 gather_indices,\n                                 direction=\"left\"):\n  \"\"\"Gathers blocks with gaps in between.\n\n  Args:\n    x: Tensor of shape [length, batch, heads, depth]\n    num_memory_blocks: how many memory blocks to look in \"direction\". Each will\n      be separated by gap_size.\n    gap_size: an integer indicating the gap size\n    query_block_size: an integer indicating size of query block\n    memory_block_size: an integer indicating the size of a memory block.\n    gather_indices: The indices to gather from.\n    direction: left or right\n\n  Returns:\n    Tensor of shape [batch, heads, blocks, block_length, depth]\n  \"\"\"\n  gathered_blocks = []\n  # gathering memory blocks\n  for block_id in range(num_memory_blocks):\n    block_end_index = -(query_block_size + gap_size *\n                        (block_id + 1) + memory_block_size * block_id)\n    block_start_index = (\n        (memory_block_size + gap_size) * (num_memory_blocks - (block_id + 1)))\n    if direction != \"left\":\n      [block_end_index,\n       block_start_index] = [-block_start_index, -block_end_index]\n    if block_end_index == 0:\n      x_block = x[block_start_index:]\n    else:\n      x_block = x[block_start_index:block_end_index]\n\n    def gather_dilated_1d_blocks(x, gather_indices):\n      x_new = tf.gather(x, gather_indices)\n      # [batch, heads, blocks, block_length, dim]\n      return tf.transpose(x_new, [2, 3, 0, 1, 4])\n\n    gathered_blocks.append(gather_dilated_1d_blocks(x_block, gather_indices))\n  return tf.concat(gathered_blocks, 3)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef masked_dilated_self_attention_1d(q,\n                                     k,\n                                     v,\n                                     query_block_size=64,\n                                     memory_block_size=64,\n                                     gap_size=2,\n                                     num_memory_blocks=2,\n                                     name=None):\n  \"\"\"Dilated self-attention. TODO(avaswani): Try it and write a paper on it.\n\n  Args:\n    q: a Tensor with shape [batch, heads, length, depth]\n    k: a Tensor with shape [batch, heads, length, depth]\n    v: a Tensor with shape [batch, heads, length, depth]\n    query_block_size: an integer\n    memory_block_size: an integer indicating how much to look left.\n    gap_size: an integer indicating the gap size\n    num_memory_blocks: how many memory blocks to look at to the left. Each will\n      be separated by gap_size.\n    name: an optional string\n\n  Returns:\n    a Tensor of shape [batch, heads, length, depth]\n  \"\"\"\n  with tf.variable_scope(\n      name, default_name=\"masked_dilated_self_attention_1d\", values=[q, k, v]):\n    v_list_shape = v.get_shape().as_list()\n    assert v_list_shape == k.shape.as_list(), \"K and V depths must be equal\"\n    v_shape = common_layers.shape_list(v)\n    depth_v = v_shape[3]\n    batch_size = v_shape[0]\n    num_heads = v_shape[1]\n    original_length = common_layers.shape_list(q)[2]\n\n    # Pad query, key, value to ensure multiple of corresponding lengths.\n    def pad_to_multiple(x, pad_length):\n      x_length = common_layers.shape_list(x)[2]\n      return tf.pad(x, [[0, 0], [0, 0], [0, -x_length % pad_length], [0, 0]])\n\n    def pad_l(x, left_pad_length):\n      return tf.pad(x, [[0, 0], [0, 0], [left_pad_length, 0], [0, 0]])\n\n    q = pad_to_multiple(q, query_block_size)\n    v = pad_to_multiple(v, query_block_size)\n    k = pad_to_multiple(k, query_block_size)\n\n    # Set up query blocks.\n    new_q_shape = common_layers.shape_list(q)\n    q = reshape_by_blocks(q, new_q_shape, query_block_size)\n\n    # Set up key and value windows.\n    self_k_part = reshape_by_blocks(k, new_q_shape, query_block_size)\n    self_v_part = reshape_by_blocks(v, new_q_shape, query_block_size)\n    k_v_padding = (gap_size + memory_block_size) * num_memory_blocks\n    k = pad_l(k, k_v_padding)\n    v = pad_l(v, k_v_padding)\n\n    # Get gather indices.\n    index_length = (new_q_shape[2] - query_block_size + memory_block_size)\n\n    indices = tf.range(0, index_length, delta=1, name=\"index_range\")\n    indices = tf.reshape(indices, [1, -1, 1])  # [1, length, 1] for convs\n    kernel = tf.expand_dims(tf.eye(memory_block_size), axis=1)\n    gather_indices = tf.nn.conv1d(\n        tf.cast(indices, tf.float32),\n        kernel,\n        query_block_size,\n        padding=\"VALID\",\n        name=\"gather_conv\")\n    gather_indices = tf.squeeze(tf.cast(gather_indices, tf.int32), axis=0)\n\n    # Get left and right memory blocks for each query.\n    # [length, batch, heads, dim]\n    k_t = tf.transpose(k, [2, 0, 1, 3])\n    v_t = tf.transpose(v, [2, 0, 1, 3])\n\n    k_unmasked_windows = gather_dilated_memory_blocks(\n        k_t, num_memory_blocks, gap_size, query_block_size, memory_block_size,\n        gather_indices)\n    v_unmasked_windows = gather_dilated_memory_blocks(\n        v_t, num_memory_blocks, gap_size, query_block_size, memory_block_size,\n        gather_indices)\n\n    # Combine memory windows.\n    block_q_shape = common_layers.shape_list(q)\n    masked_attention_bias = tf.tile(\n        tf.expand_dims(attention_bias_lower_triangle(query_block_size), axis=0),\n        [block_q_shape[0], block_q_shape[1], block_q_shape[2], 1, 1])\n    padding_attention_bias = tf.expand_dims(\n        embedding_to_padding(k_unmasked_windows) * -1e9, axis=-2)\n    padding_attention_bias = tf.tile(padding_attention_bias,\n                                     [1, 1, 1, query_block_size, 1])\n    attention_bias = tf.concat(\n        [masked_attention_bias, padding_attention_bias], axis=-1)\n    # combine memory windows\n    k_windows = tf.concat([self_k_part, k_unmasked_windows], 3)\n    v_windows = tf.concat([self_v_part, v_unmasked_windows], 3)\n    output = dot_product_attention(\n        q,\n        k_windows,\n        v_windows,\n        attention_bias,\n        dropout_rate=0.,\n        name=\"dilated_1d\",\n        make_image_summary=False)\n    output = tf.reshape(output, [batch_size, num_heads, -1, depth_v])\n\n    # Remove the padding if introduced.\n    output = tf.slice(output, [0, 0, 0, 0], [-1, -1, original_length, -1])\n    output.set_shape(v_list_shape)\n    return output", "response": "Dilated self - attention."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef local_attention_2d(q,\n                       k,\n                       v,\n                       query_shape=(8, 16),\n                       memory_flange=(8, 16),\n                       name=None):\n  \"\"\"Strided block local self-attention.\n\n  The 2-D sequence is divided into 2-D blocks of shape query_shape. Attention\n  for a given query position can only see memory positions less than or equal to\n  the query position. The memory positions are the corresponding block with\n  memory_flange many positions to add to the height and width of the block\n  (namely, left, top, and right).\n\n  Args:\n    q: a Tensor with shape [batch, heads, h, w, depth_k]\n    k: a Tensor with shape [batch, heads, h, w, depth_k]\n    v: a Tensor with shape [batch, heads, h, w, depth_v]. In the current\n      implementation, depth_v must be equal to depth_k.\n    query_shape: an tuple indicating the height and width of each query block.\n    memory_flange: an integer indicating how much to look in height and width\n      from each query block.\n    name: an optional string\n\n  Returns:\n    a Tensor of shape [batch, heads, h, w, depth_v]\n  \"\"\"\n  with tf.variable_scope(\n      name, default_name=\"local_self_attention_2d\", values=[q, k, v]):\n    v_shape = common_layers.shape_list(v)\n\n    # Pad query, key, value to ensure multiple of corresponding lengths.\n    q = pad_to_multiple_2d(q, query_shape)\n    k = pad_to_multiple_2d(k, query_shape)\n    v = pad_to_multiple_2d(v, query_shape)\n    paddings = [[0, 0], [0, 0], [memory_flange[0], memory_flange[1]],\n                [memory_flange[0], memory_flange[1]], [0, 0]]\n    k = tf.pad(k, paddings)\n    v = tf.pad(v, paddings)\n\n    # Set up query blocks.\n    q_indices = gather_indices_2d(q, query_shape, query_shape)\n    q_new = gather_blocks_2d(q, q_indices)\n\n    # Set up key and value blocks.\n    memory_shape = (query_shape[0] + 2 * memory_flange[0],\n                    query_shape[1] + 2 * memory_flange[1])\n    k_and_v_indices = gather_indices_2d(k, memory_shape, query_shape)\n    k_new = gather_blocks_2d(k, k_and_v_indices)\n    v_new = gather_blocks_2d(v, k_and_v_indices)\n\n    attention_bias = tf.expand_dims(\n        tf.to_float(embedding_to_padding(k_new)) * -1e9, axis=-2)\n    output = dot_product_attention(\n        q_new,\n        k_new,\n        v_new,\n        attention_bias,\n        dropout_rate=0.,\n        name=\"local_2d\",\n        make_image_summary=False)\n    # Put representations back into original shapes.\n    padded_q_shape = common_layers.shape_list(q)\n    output = scatter_blocks_2d(output, q_indices, padded_q_shape)\n\n    # Remove the padding if introduced.\n    output = tf.slice(output, [0, 0, 0, 0, 0],\n                      [-1, -1, v_shape[2], v_shape[3], -1])\n    return output", "response": "Strided block local self - attention."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking sure x is a multiple of shape.", "response": "def pad_to_multiple_2d(x, block_shape):\n  \"\"\"Making sure x is a multiple of shape.\n\n  Args:\n    x: a [batch, heads, h, w, depth] or [batch, h, w, depth] tensor\n    block_shape: a 2-d list of integer shapes\n\n  Returns:\n    padded_x: a [batch, heads, h, w, depth] or [batch, h, w, depth] tensor\n  \"\"\"\n  old_shape = x.get_shape().dims\n  last = old_shape[-1]\n  if len(old_shape) == 4:\n    height_padding = -common_layers.shape_list(x)[1] % block_shape[0]\n    width_padding = -common_layers.shape_list(x)[2] % block_shape[1]\n    paddings = [[0, 0], [0, height_padding], [0, width_padding], [0, 0]]\n  elif len(old_shape) == 5:\n    height_padding = -common_layers.shape_list(x)[2] % block_shape[0]\n    width_padding = -common_layers.shape_list(x)[3] % block_shape[1]\n    paddings = [[0, 0], [0, 0], [0, height_padding], [0, width_padding], [0, 0]]\n\n  padded_x = tf.pad(x, paddings)\n  padded_shape = padded_x.get_shape().as_list()\n  padded_shape = padded_shape[:-1] + [last]\n  padded_x.set_shape(padded_shape)\n  return padded_x"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reshape_range(tensor, i, j, shape):\n  t_shape = common_layers.shape_list(tensor)\n  target_shape = t_shape[:i] + shape + t_shape[j:]\n  return tf.reshape(tensor, target_shape)", "response": "Reshapes a tensor between dimensions i and j."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngather flattened blocks from x.", "response": "def gather_blocks_2d(x, indices):\n  \"\"\"Gathers flattened blocks from x.\"\"\"\n  x_shape = common_layers.shape_list(x)\n  x = reshape_range(x, 2, 4, [tf.reduce_prod(x_shape[2:4])])\n  # [length, batch, heads, dim]\n  x_t = tf.transpose(x, [2, 0, 1, 3])\n  x_new = tf.gather(x_t, indices)\n  # returns [batch, heads, num_blocks, block_length ** 2, dim]\n  return tf.transpose(x_new, [2, 3, 0, 1, 4])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nscattering blocks from x into shape with indices.", "response": "def scatter_blocks_2d(x, indices, shape):\n  \"\"\"scatters blocks from x into shape with indices.\"\"\"\n  x_shape = common_layers.shape_list(x)\n  # [length, batch, heads, dim]\n  x_t = tf.transpose(\n      tf.reshape(x, [x_shape[0], x_shape[1], -1, x_shape[-1]]), [2, 0, 1, 3])\n  x_t_shape = common_layers.shape_list(x_t)\n  indices = tf.reshape(indices, [-1, 1])\n  scattered_x = tf.scatter_nd(indices, x_t, x_t_shape)\n  scattered_x = tf.transpose(scattered_x, [1, 2, 0, 3])\n  return tf.reshape(scattered_x, shape)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a mask for 2d block raster scan.", "response": "def make_2d_block_raster_mask(query_shape, memory_flange):\n  \"\"\"Creates a mask for 2d block raster scan.\n\n  The query mask can look to the left, top left, top, and top right, but\n  not to the right. Inside the query, we have the standard raster scan\n  masking.\n  Args:\n    query_shape: A tuple of ints (query_height, query_width)\n    memory_flange: A tuple of ints\n      (memory_flange_height, memory_flange_width)\n\n  Returns:\n    A tensor of shape query_size, memory_size\n  \"\"\"\n  # mask inside the query block\n  query_triangle = common_layers.ones_matrix_band_part(\n      np.prod(query_shape), np.prod(query_shape), -1, 0)\n  split_query_masks = tf.split(query_triangle, query_shape[0], axis=1)\n  # adding mask for left and right\n  mask_pieces = [\n      tf.concat(  # pylint: disable=g-complex-comprehension\n          [tf.ones([np.prod(query_shape), memory_flange[1]]),\n           split_query_masks[i],\n           tf.zeros([np.prod(query_shape), memory_flange[1]])],\n          axis=1) for i in range(query_shape[0])\n  ]\n  # adding mask for top\n  final_mask = tf.concat(\n      [\n          tf.ones([\n              np.prod(query_shape),\n              (query_shape[1] + 2 * memory_flange[1]) * memory_flange[0]\n          ]),\n          tf.concat(mask_pieces, axis=1)\n      ],\n      axis=1)\n  # 0.0 is visible location, 1.0 is masked.\n  return 1. - final_mask"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the memory regions that surround a 2d query.", "response": "def get_memory_region(x, query_block_shape, memory_flange, q_indices):\n  \"\"\"Get the memory regions that surround a 2d query.\n\n    The memory regions will be the left and top right.\n\n  Args:\n    x: A tensor with shape [batch, heads, height, width, depth]\n    query_block_shape: a 2-d tuple of integers\n    memory_flange: a 2-d tuple of integers\n    q_indices: a tensor of indices for each of the center blocks.\n      [num_blocks, block_length]\n  Returns:\n    x_flange: A tensor of shape [batch, heads, #blocks, block_length, depth]\n  \"\"\"\n  # Padding x to be multiple of query_shape and then\n  # extracting the memory blocks from the same regions as the query blocks\n  x_query_padded = pad_to_multiple_2d(x, query_block_shape)\n  x_center = gather_blocks_2d(x_query_padded, q_indices)\n  # Then padding the flange region\n  paddings = [[0, 0], [0, 0], [memory_flange[0], 0],\n              [memory_flange[1], memory_flange[1]], [0, 0]]\n  x_memory_padded = tf.pad(x_query_padded, paddings)\n  left_x = None\n  top_x = None\n  # Extracting the memory regions around the query block. left_x_region extends\n  # to the left and the top_x_region is the combination of top left, top, and\n  # top right of the query block\n  # if no left region\n  if memory_flange[1] > 0:\n    left_x_region = x_memory_padded[:, :, memory_flange[\n        0]:, :-(query_block_shape[1] + memory_flange[1]), :]\n    left_memory_shape = (query_block_shape[0], memory_flange[1])\n    left_indices = gather_indices_2d(left_x_region, left_memory_shape,\n                                     query_block_shape)\n    left_x = gather_blocks_2d(left_x_region, left_indices)\n  # if no top region\n  if memory_flange[0] > 0:\n    top_x_region = x_memory_padded[:, :, :-query_block_shape[0], :, :]\n\n    top_memory_shape = (memory_flange[0],\n                        query_block_shape[1] + 2 * memory_flange[1])\n\n    top_indices = gather_indices_2d(top_x_region, top_memory_shape,\n                                    query_block_shape)\n\n    top_x = gather_blocks_2d(top_x_region, top_indices)\n  x_flange = None\n  if top_x is not None and left_x is not None:\n    x_flange = tf.concat([top_x, left_x], axis=3)\n  else:\n    x_flange = top_x if top_x is not None else left_x\n  return x_flange, x_center"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_shifted_center_blocks(x, indices):\n  center_x = gather_blocks_2d(x, indices)\n\n  # Shift right along the length dimension\n  def shift_right_2d_blocks(x):\n    \"\"\"Shift the second to last dimension of x right by one.\"\"\"\n    shifted_targets = (\n        tf.pad(x, [[0, 0], [0, 0], [0, 0], [1, 0], [0, 0]])[:, :, :, :-1, :])\n    return shifted_targets\n\n  x_shifted = shift_right_2d_blocks(center_x)\n  return x_shifted", "response": "Get right shifted blocks for masked local attention 2d."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nright shifts once in every block.", "response": "def right_shift_blockwise(x, query_shape, name=None):\n  \"\"\"Right shifts once in every block.\n\n  Args:\n    x: a tensor of shape [batch, height, width, depth]\n    query_shape: A 2d tuple of ints\n    name: a string\n\n  Returns:\n    output: a tensor of the same shape as x\n  \"\"\"\n  with tf.variable_scope(\n      name, default_name=\"right_shift_blockwise\", values=[x]):\n    x_list_shape = x.get_shape().as_list()\n    x_shape = common_layers.shape_list(x)\n    # Add a dummy dimension for heads.\n    x = tf.expand_dims(x, axis=1)\n    x = pad_to_multiple_2d(x, query_shape)\n    padded_x_shape = common_layers.shape_list(x)\n    # Set up q blocks.\n    x_indices = gather_indices_2d(x, query_shape, query_shape)\n    x_new = get_shifted_center_blocks(x, x_indices)\n\n    # Put representations back into original shapes.\n    output = scatter_blocks_2d(x_new, x_indices, padded_x_shape)\n    # Remove the dummy head dimension.\n    output = tf.squeeze(output, axis=1)\n    # Remove the padding if introduced.\n    output = tf.slice(output, [0, 0, 0, 0], [-1, x_shape[1], x_shape[2], -1])\n    output.set_shape(x_list_shape)\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstrides block local self - attention.", "response": "def masked_local_attention_2d(q,\n                              k,\n                              v,\n                              query_shape=(8, 16),\n                              memory_flange=(8, 16),\n                              name=None):\n  \"\"\"Strided block local self-attention.\n\n  Each position in a query block can attend to all the generated queries in\n  the query block, which are generated in raster scan, and positions that are\n  generated to the left and top. The shapes are specified by query shape and\n  memory flange. Note that if you're using this function, you do not need to\n  right shift. Right shifting happens inside this function separately for each\n  block.\n\n  Args:\n    q: a Tensor with shape [batch, heads, h, w, depth_k]\n    k: a Tensor with shape [batch, heads, h, w, depth_k]\n    v: a Tensor with shape [batch, heads, h, w, depth_v]. In the current\n      implementation, depth_v must be equal to depth_k.\n    query_shape: an tuple indicating the height and width of each query block.\n      query_shape = block_shape\n    memory_flange: an integer indicating how much to look in height and width\n      from each query block.\n      memory shape = query_shape + (block_flange[0], 2*block_flange[1])\n    name: an optional string\n\n  Returns:\n    a Tensor of shape [batch, heads, h, w, depth_v]\n  \"\"\"\n  with tf.variable_scope(\n      name, default_name=\"local_masked_self_attention_2d\", values=[q, k, v]):\n    v_shape = common_layers.shape_list(v)\n\n    # Pad query to ensure multiple of corresponding lengths.\n    q = pad_to_multiple_2d(q, query_shape)\n\n    # Set up query blocks.\n    q_indices = gather_indices_2d(q, query_shape, query_shape)\n    q_new = gather_blocks_2d(q, q_indices)\n\n    # Set up key and value blocks.\n    k_flange, k_center = get_memory_region(k, query_shape, memory_flange,\n                                           q_indices)\n    v_flange, v_center = get_memory_region(v, query_shape, memory_flange,\n                                           q_indices)\n    if k_flange is not None:\n      k_new = tf.concat([k_flange, k_center], axis=3)\n      v_new = tf.concat([v_flange, v_center], axis=3)\n    else:\n      k_new = k_center\n      v_new = v_center\n\n    # Set up the masks.\n    query_elements = np.prod(query_shape)\n    padding_mask = None\n    if k_flange is not None:\n      padding_mask = tf.expand_dims(\n          embedding_to_padding(k_flange) * -1e9, axis=-2)\n      padding_mask = tf.tile(padding_mask, [1, 1, 1, query_elements, 1])\n\n    center_attention_bias = attention_bias_lower_triangle(\n        np.prod(query_elements))\n    center_attention_bias = tf.reshape(\n        center_attention_bias, [1, 1, 1, query_elements, query_elements])\n    v_center_shape = common_layers.shape_list(v_center)\n    center_attention_bias = tf.tile(\n        center_attention_bias,\n        [v_center_shape[0], v_center_shape[1], v_center_shape[2], 1, 1])\n    if padding_mask is not None:\n      # Combine the mask for padding and visible region.\n      attention_bias = tf.concat([padding_mask, center_attention_bias], axis=4)\n    else:\n      attention_bias = center_attention_bias\n\n    output = dot_product_attention(\n        q_new,\n        k_new,\n        v_new,\n        attention_bias,\n        dropout_rate=0.,\n        name=\"masked_local_2d\",\n        make_image_summary=False)\n    # Put representations back into original shapes.\n    padded_q_shape = common_layers.shape_list(q)\n    output = scatter_blocks_2d(output, q_indices, padded_q_shape)\n\n    # Remove the padding if introduced.\n    output = tf.slice(output, [0, 0, 0, 0, 0],\n                      [-1, -1, v_shape[2], v_shape[3], -1])\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compute_attention_component(antecedent,\n                                total_depth,\n                                filter_width=1,\n                                padding=\"VALID\",\n                                name=\"c\",\n                                vars_3d_num_heads=0,\n                                layer_collection=None):\n  \"\"\"Computes attention compoenent (query, key or value).\n\n  Args:\n    antecedent: a Tensor with shape [batch, length, channels]\n    total_depth: an integer\n    filter_width: An integer specifying how wide you want the attention\n      component to be.\n    padding: One of \"VALID\", \"SAME\" or \"LEFT\". Default is VALID: No padding.\n    name: a string specifying scope name.\n    vars_3d_num_heads: an optional integer (if we want to use 3d variables)\n    layer_collection: A tensorflow_kfac.LayerCollection. Only used by the\n      KFAC optimizer. Default is None.\n\n  Returns:\n    c : [batch, length, depth] tensor\n  \"\"\"\n  if layer_collection is not None:\n    if filter_width != 1 or vars_3d_num_heads != 0:\n      raise ValueError(\n          \"KFAC implementation only supports filter_width=1 (actual: {}) and \"\n          \"vars_3d_num_heads=0 (actual: {}).\".format(\n              filter_width, vars_3d_num_heads))\n  if vars_3d_num_heads > 0:\n    assert filter_width == 1\n    input_depth = antecedent.get_shape().as_list()[-1]\n    depth_per_head = total_depth // vars_3d_num_heads\n    initializer_stddev = input_depth ** -0.5\n    if \"q\" in name:\n      initializer_stddev *= depth_per_head ** -0.5\n    var = tf.get_variable(\n        name, [input_depth,\n               vars_3d_num_heads,\n               total_depth // vars_3d_num_heads],\n        initializer=tf.random_normal_initializer(stddev=initializer_stddev))\n    var = tf.cast(var, antecedent.dtype)\n    var = tf.reshape(var, [input_depth, total_depth])\n    return tf.tensordot(antecedent, var, axes=1)\n  if filter_width == 1:\n    return common_layers.dense(\n        antecedent, total_depth, use_bias=False, name=name,\n        layer_collection=layer_collection)\n  else:\n    return common_layers.conv1d(\n        antecedent, total_depth, filter_width, padding=padding, name=name)", "response": "Computes attention component of an antecedent."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute_qkv(query_antecedent,\n                memory_antecedent,\n                total_key_depth,\n                total_value_depth,\n                q_filter_width=1,\n                kv_filter_width=1,\n                q_padding=\"VALID\",\n                kv_padding=\"VALID\",\n                vars_3d_num_heads=0,\n                layer_collection=None):\n  \"\"\"Computes query, key and value.\n\n  Args:\n    query_antecedent: a Tensor with shape [batch, length_q, channels]\n    memory_antecedent: a Tensor with shape [batch, length_m, channels]\n    total_key_depth: an integer\n    total_value_depth: an integer\n    q_filter_width: An integer specifying how wide you want the query to be.\n    kv_filter_width: An integer specifying how wide you want the keys and values\n    to be.\n    q_padding: One of \"VALID\", \"SAME\" or \"LEFT\". Default is VALID: No padding.\n    kv_padding: One of \"VALID\", \"SAME\" or \"LEFT\". Default is VALID: No padding.\n    vars_3d_num_heads: an optional (if we want to use 3d variables)\n    layer_collection: A tensorflow_kfac.LayerCollection. Only used by the\n      KFAC optimizer. Default is None.\n\n  Returns:\n    q, k, v : [batch, length, depth] tensors\n  \"\"\"\n  if memory_antecedent is None:\n    memory_antecedent = query_antecedent\n  q = compute_attention_component(\n      query_antecedent,\n      total_key_depth,\n      q_filter_width,\n      q_padding,\n      \"q\",\n      vars_3d_num_heads=vars_3d_num_heads,\n      layer_collection=layer_collection)\n  k = compute_attention_component(\n      memory_antecedent,\n      total_key_depth,\n      kv_filter_width,\n      kv_padding,\n      \"k\",\n      vars_3d_num_heads=vars_3d_num_heads,\n      layer_collection=layer_collection)\n  v = compute_attention_component(\n      memory_antecedent,\n      total_value_depth,\n      kv_filter_width,\n      kv_padding,\n      \"v\",\n      vars_3d_num_heads=vars_3d_num_heads,\n      layer_collection=layer_collection)\n  return q, k, v", "response": "Computes the query key and value of a KFAC."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef multihead_attention(query_antecedent,\n                        memory_antecedent,\n                        bias,\n                        total_key_depth,\n                        total_value_depth,\n                        output_depth,\n                        num_heads,\n                        dropout_rate,\n                        attention_type=\"dot_product\",\n                        max_relative_position=None,\n                        heads_share_relative_embedding=False,\n                        add_relative_to_values=False,\n                        image_shapes=None,\n                        block_length=128,\n                        block_width=128,\n                        q_filter_width=1,\n                        kv_filter_width=1,\n                        q_padding=\"VALID\",\n                        kv_padding=\"VALID\",\n                        cache=None,\n                        gap_size=0,\n                        num_memory_blocks=2,\n                        name=\"multihead_attention\",\n                        save_weights_to=None,\n                        make_image_summary=True,\n                        dropout_broadcast_dims=None,\n                        vars_3d=False,\n                        layer_collection=None,\n                        recurrent_memory=None,\n                        chunk_number=None,\n                        hard_attention_k=0,\n                        max_area_width=1,\n                        max_area_height=1,\n                        memory_height=1,\n                        area_key_mode=\"mean\",\n                        area_value_mode=\"sum\",\n                        training=True,\n                        **kwargs):\n  \"\"\"Multihead scaled-dot-product attention with input/output transformations.\n\n  Args:\n    query_antecedent: a Tensor with shape [batch, length_q, channels]\n    memory_antecedent: a Tensor with shape [batch, length_m, channels] or None\n    bias: bias Tensor (see attention_bias())\n    total_key_depth: an integer\n    total_value_depth: an integer\n    output_depth: an integer\n    num_heads: an integer dividing total_key_depth and total_value_depth\n    dropout_rate: a floating point number\n    attention_type: a string, either \"dot_product\", \"dot_product_relative\",\n                    \"local_mask_right\", \"local_unmasked\", \"masked_dilated_1d\",\n                    \"unmasked_dilated_1d\", graph, or any attention function\n                    with the signature (query, key, value, **kwargs)\n    max_relative_position: Maximum distance between inputs to generate\n                           unique relation embeddings for. Only relevant\n                           when using \"dot_product_relative\" attention.\n    heads_share_relative_embedding: boolean to share relative embeddings\n    add_relative_to_values: a boolean for whether to add relative component to\n                            values.\n    image_shapes: optional tuple of integer scalars.\n                  see comments for attention_image_summary()\n    block_length: an integer - relevant for \"local_mask_right\"\n    block_width: an integer - relevant for \"local_unmasked\"\n    q_filter_width: An integer specifying how wide you want the query to be.\n    kv_filter_width: An integer specifying how wide you want the keys and values\n                     to be.\n    q_padding: One of \"VALID\", \"SAME\" or \"LEFT\". Default is VALID: No padding.\n               kv_padding: One of \"VALID\", \"SAME\" or \"LEFT\". Default is \"VALID\":\n               no padding.\n    cache: dict containing Tensors which are the results of previous\n           attentions, used for fast decoding. Expects the dict to contrain two\n           keys ('k' and 'v'), for the initial call the values for these keys\n           should be empty Tensors of the appropriate shape.\n               'k' [batch_size, 0, key_channels]\n               'v' [batch_size, 0, value_channels]\n    gap_size: Integer option for dilated attention to indicate spacing between\n              memory blocks.\n    num_memory_blocks: Integer option to indicate how many memory blocks to look\n                       at.\n    name: an optional string.\n    save_weights_to: an optional dictionary to capture attention weights\n      for vizualization; the weights tensor will be appended there under\n      a string key created from the variable scope (including name).\n    make_image_summary: Whether to make an attention image summary.\n    dropout_broadcast_dims:  an optional list of integers less than 4\n      specifying in which dimensions to broadcast the dropout decisions.\n      saves memory.\n    vars_3d: use 3-dimensional variables for input/output transformations\n    layer_collection: A tensorflow_kfac.LayerCollection. Only used by the\n      KFAC optimizer. Default is None.\n    recurrent_memory: An optional transformer_memory.RecurrentMemory, which\n      retains state across chunks. Default is None.\n    chunk_number: an optional integer Tensor with shape [batch] used to operate\n      the recurrent_memory.\n    hard_attention_k: integer, if > 0 triggers hard attention (picking top-k).\n    max_area_width: the max width allowed for an area.\n    max_area_height: the max height allowed for an area.\n    memory_height: the height of the memory.\n    area_key_mode: the mode for computing area keys, which can be \"mean\",\n      \"concat\", \"sum\", \"sample_concat\", and \"sample_sum\".\n    area_value_mode: the mode for computing area values, which can be either\n      \"mean\", or \"sum\".\n    training: indicating if it is in the training mode.\n    **kwargs (dict): Parameters for the attention function.\n\n  Caching:\n    WARNING: For decoder self-attention, i.e. when memory_antecedent == None,\n    the caching assumes that the bias contains future masking.\n\n    The caching works by saving all the previous key and value values so that\n    you are able to send just the last query location to this attention\n    function. I.e. if the cache dict is provided it assumes the query is of the\n    shape [batch_size, 1, hidden_dim] rather than the full memory.\n\n  Returns:\n    The result of the attention transformation. The output shape is\n        [batch_size, length_q, hidden_dim]\n    unless the cache dict is provided in which case only the last memory\n    position is calculated and the output shape is [batch_size, 1, hidden_dim]\n    Optionally returns an additional loss parameters (ex: load balance loss for\n    the experts) returned by the attention_type function.\n\n  Raises:\n    ValueError: if the key depth or value depth are not divisible by the\n      number of attention heads.\n  \"\"\"\n  if total_key_depth % num_heads != 0:\n    raise ValueError(\"Key depth (%d) must be divisible by the number of \"\n                     \"attention heads (%d).\" % (total_key_depth, num_heads))\n  if total_value_depth % num_heads != 0:\n    raise ValueError(\"Value depth (%d) must be divisible by the number of \"\n                     \"attention heads (%d).\" % (total_value_depth, num_heads))\n  vars_3d_num_heads = num_heads if vars_3d else 0\n\n  if layer_collection is not None:\n    if cache is not None:\n      raise ValueError(\"KFAC implementation only supports cache is None.\")\n    if vars_3d:\n      raise ValueError(\"KFAC implementation does not support 3d vars.\")\n\n  if recurrent_memory is not None:\n    if memory_antecedent is not None:\n      raise ValueError(\"Recurrent memory requires memory_antecedent is None.\")\n    if cache is not None:\n      raise ValueError(\"Cache is not supported when using recurrent memory.\")\n    if vars_3d:\n      raise ValueError(\"3d vars are not supported when using recurrent memory.\")\n    if layer_collection is not None:\n      raise ValueError(\"KFAC is not supported when using recurrent memory.\")\n    if chunk_number is None:\n      raise ValueError(\"chunk_number is required when using recurrent memory.\")\n\n  with tf.variable_scope(name, default_name=\"multihead_attention\",\n                         values=[query_antecedent, memory_antecedent]):\n\n    if recurrent_memory is not None:\n      (\n          recurrent_memory_transaction,\n          query_antecedent, memory_antecedent, bias,\n      ) = recurrent_memory.pre_attention(\n          chunk_number,\n          query_antecedent, memory_antecedent, bias,\n      )\n\n    if cache is None or memory_antecedent is None:\n      q, k, v = compute_qkv(query_antecedent, memory_antecedent,\n                            total_key_depth, total_value_depth, q_filter_width,\n                            kv_filter_width, q_padding, kv_padding,\n                            vars_3d_num_heads=vars_3d_num_heads,\n                            layer_collection=layer_collection)\n    if cache is not None:\n      if attention_type not in [\"dot_product\", \"dot_product_relative\"]:\n        # TODO(petershaw): Support caching when using relative position\n        # representations, i.e. \"dot_product_relative\" attention.\n        raise NotImplementedError(\n            \"Caching is not guaranteed to work with attention types other than\"\n            \" dot_product.\")\n      if bias is None:\n        raise ValueError(\"Bias required for caching. See function docstring \"\n                         \"for details.\")\n\n      if memory_antecedent is not None:\n        # Encoder-Decoder Attention Cache\n        q = compute_attention_component(query_antecedent, total_key_depth,\n                                        q_filter_width, q_padding, \"q\",\n                                        vars_3d_num_heads=vars_3d_num_heads)\n        k = cache[\"k_encdec\"]\n        v = cache[\"v_encdec\"]\n      else:\n        k = split_heads(k, num_heads)\n        v = split_heads(v, num_heads)\n        decode_loop_step = kwargs.get(\"decode_loop_step\")\n        if decode_loop_step is None:\n          k = cache[\"k\"] = tf.concat([cache[\"k\"], k], axis=2)\n          v = cache[\"v\"] = tf.concat([cache[\"v\"], v], axis=2)\n        else:\n          # Inplace update is required for inference on TPU.\n          # Inplace_ops only supports inplace_update on the first dimension.\n          # The performance of current implementation is better than updating\n          # the tensor by adding the result of matmul(one_hot,\n          # update_in_current_step)\n          tmp_k = tf.transpose(cache[\"k\"], perm=[2, 0, 1, 3])\n          tmp_k = inplace_ops.alias_inplace_update(\n              tmp_k, decode_loop_step, tf.squeeze(k, axis=2))\n          k = cache[\"k\"] = tf.transpose(tmp_k, perm=[1, 2, 0, 3])\n          tmp_v = tf.transpose(cache[\"v\"], perm=[2, 0, 1, 3])\n          tmp_v = inplace_ops.alias_inplace_update(\n              tmp_v, decode_loop_step, tf.squeeze(v, axis=2))\n          v = cache[\"v\"] = tf.transpose(tmp_v, perm=[1, 2, 0, 3])\n\n    q = split_heads(q, num_heads)\n    if cache is None:\n      k = split_heads(k, num_heads)\n      v = split_heads(v, num_heads)\n\n    key_depth_per_head = total_key_depth // num_heads\n    if not vars_3d:\n      q *= key_depth_per_head**-0.5\n\n    additional_returned_value = None\n    if callable(attention_type):  # Generic way to extend multihead_attention\n      x = attention_type(q, k, v, **kwargs)\n      if isinstance(x, tuple):\n        x, additional_returned_value = x  # Unpack\n    elif attention_type == \"dot_product\":\n      if max_area_width > 1 or max_area_height > 1:\n        x = area_attention.dot_product_area_attention(\n            q, k, v, bias, dropout_rate, image_shapes,\n            save_weights_to=save_weights_to,\n            dropout_broadcast_dims=dropout_broadcast_dims,\n            max_area_width=max_area_width,\n            max_area_height=max_area_height,\n            memory_height=memory_height,\n            area_key_mode=area_key_mode,\n            area_value_mode=area_value_mode,\n            training=training)\n      else:\n        x = dot_product_attention(q, k, v, bias, dropout_rate, image_shapes,\n                                  save_weights_to=save_weights_to,\n                                  make_image_summary=make_image_summary,\n                                  dropout_broadcast_dims=dropout_broadcast_dims,\n                                  activation_dtype=kwargs.get(\n                                      \"activation_dtype\"),\n                                  hard_attention_k=hard_attention_k)\n    elif attention_type == \"dot_product_relative\":\n      x = dot_product_attention_relative(\n          q,\n          k,\n          v,\n          bias,\n          max_relative_position,\n          dropout_rate,\n          image_shapes,\n          save_weights_to=save_weights_to,\n          make_image_summary=make_image_summary,\n          cache=cache is not None,\n          allow_memory=recurrent_memory is not None,\n          hard_attention_k=hard_attention_k)\n    elif attention_type == \"dot_product_unmasked_relative_v2\":\n      x = dot_product_unmasked_self_attention_relative_v2(\n          q,\n          k,\n          v,\n          bias,\n          max_relative_position,\n          dropout_rate,\n          image_shapes,\n          make_image_summary=make_image_summary,\n          dropout_broadcast_dims=dropout_broadcast_dims,\n          heads_share_relative_embedding=heads_share_relative_embedding,\n          add_relative_to_values=add_relative_to_values)\n    elif attention_type == \"dot_product_relative_v2\":\n      x = dot_product_self_attention_relative_v2(\n          q,\n          k,\n          v,\n          bias,\n          max_relative_position,\n          dropout_rate,\n          image_shapes,\n          make_image_summary=make_image_summary,\n          dropout_broadcast_dims=dropout_broadcast_dims,\n          heads_share_relative_embedding=heads_share_relative_embedding,\n          add_relative_to_values=add_relative_to_values)\n    elif attention_type == \"local_within_block_mask_right\":\n      x = masked_within_block_local_attention_1d(\n          q, k, v, block_length=block_length)\n    elif attention_type == \"local_relative_mask_right\":\n      x = masked_relative_local_attention_1d(\n          q,\n          k,\n          v,\n          block_length=block_length,\n          make_image_summary=make_image_summary,\n          dropout_rate=dropout_rate,\n          heads_share_relative_embedding=heads_share_relative_embedding,\n          add_relative_to_values=add_relative_to_values,\n          name=\"masked_relative_local_attention_1d\")\n    elif attention_type == \"local_mask_right\":\n      x = masked_local_attention_1d(\n          q,\n          k,\n          v,\n          block_length=block_length,\n          make_image_summary=make_image_summary)\n    elif attention_type == \"local_unmasked\":\n      x = local_attention_1d(\n          q, k, v, block_length=block_length, filter_width=block_width)\n    elif attention_type == \"masked_dilated_1d\":\n      x = masked_dilated_self_attention_1d(q, k, v, block_length, block_width,\n                                           gap_size, num_memory_blocks)\n    else:\n      assert attention_type == \"unmasked_dilated_1d\"\n      x = dilated_self_attention_1d(q, k, v, block_length, block_width,\n                                    gap_size, num_memory_blocks)\n    x = combine_heads(x)\n\n    # Set last dim specifically.\n    x.set_shape(x.shape.as_list()[:-1] + [total_value_depth])\n\n    if vars_3d:\n      o_var = tf.get_variable(\n          \"o\", [num_heads, total_value_depth // num_heads, output_depth])\n      o_var = tf.cast(o_var, x.dtype)\n      o_var = tf.reshape(o_var, [total_value_depth, output_depth])\n      x = tf.tensordot(x, o_var, axes=1)\n    else:\n      x = common_layers.dense(\n          x, output_depth, use_bias=False, name=\"output_transform\",\n          layer_collection=layer_collection)\n\n    if recurrent_memory is not None:\n      x = recurrent_memory.post_attention(recurrent_memory_transaction, x)\n    if additional_returned_value is not None:\n      return x, additional_returned_value\n    return x", "response": "Multihead scaled - dot - product attention with input and output transformations."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef multihead_attention_2d(query_antecedent,\n                           memory_antecedent,\n                           total_key_depth,\n                           total_value_depth,\n                           output_depth,\n                           num_heads,\n                           attention_type=\"local_attention_2d\",\n                           query_shape=(8, 16),\n                           memory_flange=(8, 16),\n                           name=None):\n  \"\"\"2d Multihead scaled-dot-product attention with inp/output transformations.\n\n  Args:\n    query_antecedent: a Tensor with shape [batch, h, w, depth_k]\n    memory_antecedent: a Tensor with shape [batch, h, w, depth_k]\n    total_key_depth: an integer\n    total_value_depth: an integer\n    output_depth: an integer\n    num_heads: an integer dividing total_key_depth and total_value_depth\n    attention_type: String, type of attention function to use.\n    query_shape: an tuple indicating the height and width of each query block.\n    memory_flange: an integer indicating how much to look in height and width\n    name: an optional string\n\n  Returns:\n    A Tensor of shape [batch, h, w, output_depth]\n\n  Raises:\n    ValueError: if the key depth or value depth are not divisible by the\n      number of attention heads.\n  \"\"\"\n  if total_key_depth % num_heads != 0:\n    raise ValueError(\"Key depth (%d) must be divisible by the number of \"\n                     \"attention heads (%d).\" % (total_key_depth, num_heads))\n  if total_value_depth % num_heads != 0:\n    raise ValueError(\"Value depth (%d) must be divisible by the number of \"\n                     \"attention heads (%d).\" % (total_value_depth, num_heads))\n  with tf.variable_scope(\n      name,\n      default_name=\"multihead_attention_2d\",\n      values=[query_antecedent, memory_antecedent]):\n    q, k, v = compute_qkv(query_antecedent, memory_antecedent, total_key_depth,\n                          total_value_depth)\n    # after splitting, shape is [batch, heads, h, w, depth]\n    q = split_heads_2d(q, num_heads)\n    k = split_heads_2d(k, num_heads)\n    v = split_heads_2d(v, num_heads)\n    key_depth_per_head = total_key_depth // num_heads\n    q *= key_depth_per_head**-0.5\n    if attention_type == \"local_attention_2d\":\n      x = local_attention_2d(\n          q, k, v, query_shape=query_shape, memory_flange=memory_flange)\n    elif attention_type == \"masked_local_attention_2d\":\n      assert attention_type == \"masked_local_attention_2d\"\n      x = masked_local_attention_2d(\n          q, k, v, query_shape=query_shape, memory_flange=memory_flange)\n    else:\n      assert attention_type == \"unmasked_local_attention_2d_tpu\"\n      x = dot_product_unmasked_attention_local_2d_tpu(\n          q, k, v, None, max_relative_position=None, query_shape=query_shape)\n    x = combine_heads_2d(x)\n    x = common_layers.dense(\n        x, output_depth, use_bias=False, name=\"output_transform\")\n    return x", "response": "2d Multihead scaled - dot - product attention with inp and output transformations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nself - attention layer.", "response": "def ffn_self_attention_layer(x,\n                             filter_depth,\n                             output_depth,\n                             num_parts,\n                             dropout_rate,\n                             share_kv=False,\n                             name=None):\n  \"\"\"Self-attention feedforward layer.\n\n  We use self-attention to do feedforward computations. We apply this function\n  positionwise where for each position, we linearly transform the output to have\n  depth filter_depth, and break up the result depth-wise into num_parts\n  contiguous parts. The parts self-attend, we concatenate the results\n  depth-wise, and we linearly transform to a depth of output_depth. The goal is\n  to get multiplicative interactions between components of a representation.\n\n  Args:\n    x: a Tensor with shape [batch, length, channels]\n    filter_depth: an integer\n    output_depth: an integer\n    num_parts: an integer dividing filter depth\n    dropout_rate: a floating point number\n    share_kv: Share the key value transform\n    name: an optional string\n\n  Returns:\n    A Tensor with shape [batch, length, output_depth].\n  \"\"\"\n  with tf.variable_scope(\n      name, default_name=\"feedforward_self_attention\", values=[x]):\n    x_shape = common_layers.shape_list(x)\n    part_depth = filter_depth // num_parts\n    if not share_kv:\n      combined = common_layers.dense(\n          x, filter_depth * 3, use_bias=False, name=\"qkv_transform\")\n      combined = tf.expand_dims(combined, axis=2)\n      q, k, v = tf.split(combined, 3, axis=3)\n    else:\n      q = tf.expand_dims(\n          common_layers.dense(\n              x, filter_depth, use_bias=False, name=\"q_transform\"),\n          axis=2)\n      kv_combined = tf.expand_dims(\n          common_layers.dense(\n              tf.concat([x, x], axis=1),\n              filter_depth,\n              use_bias=False,\n              name=\"kv_transform\"),\n          axis=2)\n      k, v = tf.split(kv_combined, [x_shape[1], x_shape[1]], axis=1)\n\n    batch_q = tf.reshape(q, [-1, 1, num_parts, part_depth])\n    batch_k = tf.reshape(k, [-1, 1, num_parts, part_depth])\n    batch_v = tf.reshape(v, [-1, 1, num_parts, part_depth])\n\n    batch_q *= part_depth**-0.5\n    # non-masked bias\n    bias = None\n    x = dot_product_attention(batch_q, batch_k, batch_v, bias, dropout_rate)\n    x = tf.reshape(x, [x_shape[0], x_shape[1], filter_depth])\n    x = common_layers.dense(\n        x, output_depth, use_bias=False, name=\"output_transform\")\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parameter_attention(x,\n                        total_key_depth,\n                        total_value_depth,\n                        output_depth,\n                        memory_rows,\n                        num_heads,\n                        dropout_rate,\n                        name=None):\n  \"\"\"Attention over parameters.\n\n  We use the same multi-headed attention as in the other layers, but the memory\n  keys and values are model parameters. There are no linear transformation on\n  the keys or values.\n\n  We are also a bit more careful about memory usage, since the number of\n  memory positions may be very large.\n\n  Args:\n    x: a Tensor with shape [batch, length_q, channels]\n    total_key_depth: an integer\n    total_value_depth: an integer\n    output_depth: an integer\n    memory_rows: an integer\n    num_heads: an integer dividing total_key_depth and total_value_depth\n    dropout_rate: a floating point number\n    name: an optional string\n\n  Returns:\n    A Tensor with shape [batch, length_q, output_depth].\n  \"\"\"\n  with tf.variable_scope(name, default_name=\"parameter_attention\", values=[x]):\n    head_size_k = total_key_depth // num_heads\n    head_size_v = total_value_depth // num_heads\n    var_shape_k = [num_heads, memory_rows, head_size_k]\n    var_shape_v = [num_heads, memory_rows, head_size_v]\n    k = tf.get_variable(\n        \"k\",\n        var_shape_k,\n        initializer=tf.random_normal_initializer(\n            0, output_depth**-0.5 * (num_heads**0.5)))\n    v = tf.get_variable(\n        \"v\",\n        var_shape_v,\n        initializer=tf.random_normal_initializer(\n            0, output_depth**-0.5 * (output_depth**0.5)))\n    batch_size = common_layers.shape_list(x)[0]\n    length = common_layers.shape_list(x)[1]\n    q = common_layers.dense(\n        x, total_key_depth, use_bias=False, name=\"q_transform\")\n    if dropout_rate:\n      # This is a cheaper form of attention dropout where we use to use\n      # the same dropout decisions across batch elements and query positions,\n      # but different decisions across heads and memory positions.\n      v = tf.nn.dropout(\n          v, 1.0 - dropout_rate, noise_shape=[num_heads, memory_rows, 1])\n    # query is [batch, length, hidden_size]\n    # reshape and transpose it to [heads, batch * length, head_size]\n    q = tf.reshape(q, [batch_size, length, num_heads, head_size_k])\n    q = tf.transpose(q, [2, 0, 1, 3])\n    q = tf.reshape(q, [num_heads, batch_size * length, head_size_k])\n    weights = tf.matmul(q, k, transpose_b=True)\n    weights = tf.nn.softmax(weights)\n    y = tf.matmul(weights, v)\n    y = tf.reshape(y, [num_heads, batch_size, length, head_size_v])\n    y = tf.transpose(y, [1, 2, 0, 3])\n    y = tf.reshape(y, [batch_size, length, total_value_depth])\n    y.set_shape([None, None, total_value_depth])\n    y = common_layers.dense(\n        y, output_depth, use_bias=False, name=\"output_transform\")\n    return y", "response": "Attention over parameters.\n\n  We use the same multi-headed attention as in the other layers, but the memory\n  keys and values are model parameters. There are no linear transformation on\n  the keys or values.\n\n  We are also a bit more careful about memory usage, since the number of\n  memory positions may be very large.\n\n  Args:\n    x: a Tensor with shape [batch, length_q, channels]\n    total_key_depth: an integer\n    total_value_depth: an integer\n    output_depth: an integer\n    memory_rows: an integer\n    num_heads: an integer dividing total_key_depth and total_value_depth\n    dropout_rate: a floating point number\n    name: an optional string\n\n  Returns:\n    A Tensor with shape [batch, length_q, output_depth]."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef coordinate_tensor(shape, axis):\n  if axis < 0:\n    axis = tf.size(shape) + axis  # Convert to positive for the one_hot indice\n\n  r = tf.range(shape[axis])\n  r_shape = tf.one_hot(\n      axis, tf.size(shape), on_value=-1, off_value=1, dtype=tf.int32)\n  return tf.zeros(shape, dtype=tf.int32) + tf.reshape(r, r_shape)", "response": "Returns a tensor with given shape containing coordinate along given axis."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimplements attention that runs inside each expert.", "response": "def self_attention_expert(x,\n                          batch_coordinate,\n                          mask_right=True,\n                          split_batch=False,\n                          attention_num_head=1,\n                          attention_kq_size=None,\n                          attention_v_size=None):\n  \"\"\"Implementing attention that runs inside each expert.\n\n  Args:\n    x: A tensor of shape[batch, depth]. Contains representations from\n      different positions, which are lexicographically ordered.\n    batch_coordinate: A tensor of shape [batch, 1] containing the batch\n      coordinate of each element in x. This is needed to make sure that\n      positions from different sequences don't attend to each other.\n    mask_right: A bool. If true, we will not attend to positions on the right,\n      just as decoder self attention.\n    split_batch (bool): If True, each sequence of the batch is processed\n      individually on a loop. If False, the sequences are processed all at\n      once and a mask is applied to isolate the sequences from each others\n    attention_num_head (int): number of attention heads\n    attention_kq_size (int): dimension used for the attention key, and query\n    attention_v_size (int): dimension used for the attention value\n\n  Returns:\n    out: A tensor of shape [batch, depth].\n  example use:\n  expert_utils.local_moe(\n     ...\n     expert_fn=functools.partial(self_attention_expert, mask_right=)\n     )\n  \"\"\"\n\n  depth = x.get_shape().as_list()[-1]\n  length = common_layers.shape_list(batch_coordinate)[0]\n\n  # Print a warning message if one of the expert isn't used (useful at\n  # inference where summaries aren't used and the gating function don't add\n  # noise)\n  global _expert_count  # Hack to make each expert have a unique id\n  _expert_count += 1\n  length = tf.cond(\n      tf.equal(length, 0),\n      lambda: tf.Print(  # pylint: disable=g-long-lambda\n          length, [length], \"Expert {} empty: \".format(_expert_count)),\n      lambda: length,\n  )\n\n  tf.summary.scalar(\"batch_size\", length, family=\"experts_stats_batch_size\")\n\n  attention_kq_size = attention_kq_size or depth\n  attention_v_size = attention_v_size or depth\n\n  def length_not_null(x, batch_coordinate):\n    \"\"\"Branch of the graph only evaluated when length isn't null.\"\"\"\n\n    # Mask between the sequences (not used if map_ids is used)\n    bias_batch = attention_bias_coordinates(batch_coordinate)\n\n    def add_or_set_if(prev_bias, new_bias, condition):\n      \"\"\"Add the bias together while considering the None case.\"\"\"\n      if not condition:\n        return prev_bias\n      if prev_bias is None:\n        return new_bias\n      return prev_bias + new_bias\n\n    def mask_and_call_attention(x):\n      \"\"\"Function applied once for each sequence of the batch.\"\"\"\n\n      # Mask to prevent sequences of attending to the future\n      length = common_layers.shape_list(x)[1]  # x has shape [1, length,...]\n      bias_past = tf.reshape(\n          attention_bias_lower_triangle(length), [length, length])\n      # bias has shape [length, length]\n\n      bias = None\n      bias = add_or_set_if(bias, bias_past, mask_right)\n      bias = add_or_set_if(bias, bias_batch, not split_batch)\n      bias = tf.reshape(bias, [1, 1, length, length])\n\n      return multihead_attention(\n          x,\n          None,\n          bias,\n          total_key_depth=attention_kq_size,\n          total_value_depth=attention_v_size,\n          output_depth=depth,\n          num_heads=attention_num_head,\n          dropout_rate=0.0)\n\n    if split_batch:\n      out = expert_utils.map_ids(x, batch_coordinate, mask_and_call_attention)\n    else:\n      x = tf.reshape(x, [1, length, depth])\n      out = mask_and_call_attention(x)\n      out = tf.squeeze(out, 0)\n    return out\n\n  # If the length is empty, just forward an empty tensor (avoid having to\n  # evaluate multihead_attention with tensor having dim equal to zeros)\n  out = tf.cond(\n      tf.equal(length, 0),\n      lambda: tf.zeros(shape=[0, depth], dtype=tf.float32, name=\"empty_out\"),\n      lambda: length_not_null(x, batch_coordinate),\n  )\n  return out"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef expert_dot_product(q, k, v, info_q, info_k):\n\n  length_q = common_layers.shape_list(q)[0]\n  length_k = common_layers.shape_list(k)[0]\n  depth_v = v.get_shape().as_list()[-1]\n\n  # Create the mask\n  bias = attention_bias_coordinates(info_q.coordinates, info_k.coordinates)\n  if info_k.order is not None:\n    bias += attention_bias_future(info_q.order, info_k.order)\n\n  # Restore batch and head dimension\n  q, k, v = [tf.expand_dims(tf.expand_dims(t, 0), 0) for t in (q, k, v)]\n\n  def is_zero():\n    zeros = tf.zeros(shape=[1, 1, length_q, depth_v], dtype=tf.float32)\n    zeros = tf.Print(zeros, [length_k, length_q], \"length_k/length_q: \")\n    return zeros\n\n  def is_not_zero():\n    return dot_product_attention(\n        q,\n        k,\n        v,\n        bias=bias,\n        # No image summary to avoid \"Retval[0] does not have value\" (because\n        # inside a condition)\n        make_image_summary=False,\n    )\n\n  # TODO(epot): Should make sure a query gets at least one key. Because the\n  # different sequences of a batch are merged, it's possible that a\n  # query from a sequence only receive memory from another sequence, so\n  # with the mask, the query will perform a softmax on -infinity values.\n  # A hack could be to add at least one sequence of each batch on each group so\n  # the query can attend to at least one element.\n  # Softmax(Q.K)*V\n  v_out = tf.cond(\n      tf.logical_or(tf.equal(length_q, 0), tf.equal(length_k, 0)),\n      is_zero,\n      is_not_zero,\n  )\n\n  # Remove batch and head dimension\n  v_out = tf.squeeze(v_out, axis=0)\n  v_out = tf.squeeze(v_out, axis=0)\n  return v_out", "response": "Perform dot product on a subset of the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nperform a dot product attention on a single sequence.", "response": "def dot_product_single_head(q, k, v, gates_q, gates_k, bi):\n  \"\"\"Perform a dot product attention on a single sequence on a single head.\n\n  This function dispatch the q, k, v and loop over the buckets to compute the\n  attention dot product on each subsequences.\n\n  Args:\n    q (tf.Tensor): [length_q, depth_q]\n    k (tf.Tensor): [length_k, depth_q]\n    v (tf.Tensor): [length_k, depth_v]\n    gates_q (tf.Tensor): One-hot vector of shape [length_q, nb_buckets]\n    gates_k (tf.Tensor): One-hot vector of shape [length_k, nb_buckets]\n    bi (BatchInfo): Contains the batch coordinates and sequence order\n\n  Returns:\n    tf.Tensor: [length_q, depth_v]\n  \"\"\"\n\n  nb_buckets = gates_q.get_shape().as_list()[-1]\n\n  q_dispatcher = expert_utils.SparseDispatcher(nb_buckets, gates_q)\n  k_dispatcher = expert_utils.SparseDispatcher(nb_buckets, gates_k)\n\n  def eventually_dispatch(dispatcher, value):\n    if value is not None:\n      return dispatcher.dispatch(value)\n    return [None] * nb_buckets\n\n  # Iterate over every dispatched group\n  list_v_out = []\n  for (\n      q_i,\n      k_i,\n      v_i,\n      qbc,\n      qbo,\n      kbc,\n      kbo,\n  ) in zip(\n      # Dispatch queries, keys and values\n      q_dispatcher.dispatch(q),\n      k_dispatcher.dispatch(k),\n      k_dispatcher.dispatch(v),\n      # Also dispatch the sequence positions and batch coordinates\n      eventually_dispatch(q_dispatcher, bi.coordinates),\n      eventually_dispatch(q_dispatcher, bi.order),\n      eventually_dispatch(k_dispatcher, bi.coordinates),\n      eventually_dispatch(k_dispatcher, bi.order),\n  ):\n    list_v_out.append(\n        expert_dot_product(\n            q_i,\n            k_i,\n            v_i,\n            info_q=BatchInfo(coordinates=qbc, order=qbo),\n            info_k=BatchInfo(coordinates=kbc, order=kbo)))\n\n  # Combine all buckets together to restore the original length\n  return q_dispatcher.combine(list_v_out)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef map_fn_switch(fn, elems, use_map_fn=True, **kwargs):\n  if use_map_fn:\n    return tf.map_fn(fn, elems, **kwargs)\n  elems_unpacked = (tf.unstack(e) for e in elems)\n  out_unpacked = [fn(e) for e in zip(*elems_unpacked)]\n  out = tf.stack(out_unpacked)\n  return out", "response": "This function is used to construct a tf. Graph that maps the given function to the given elements."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dot_product_batched_head(q, k, v, gates_q, gates_k, mask_right=False):\n  nb_buckets = common_layers.shape_list(gates_q)[-1]\n\n  @expert_utils.add_name_scope()\n  def get_dispatcher(gates):\n    \"\"\"Construct dispatcher for gates.\"\"\"\n    length = common_layers.shape_list(gates)[1]\n    # Count the number of ones per batch (and keep the max value)\n    nb_elems_to_dispatch = tf.reduce_sum(gates, axis=[1, 2])\n    nb_elems_to_dispatch = tf.reduce_max(nb_elems_to_dispatch)\n    nb_elems_to_dispatch = tf.to_int32(nb_elems_to_dispatch)\n    capacity = nb_elems_to_dispatch // nb_buckets * 2  # Capacity is hardcoded\n    capacity = tf.minimum(length, capacity)\n    tf.summary.scalar(\"dispatch_capacity\", capacity, family=\"lsh\")\n    return expert_utils.TruncatingDispatcher(gates, capacity)\n\n  def add_summary_capacity(x, prefix):\n    # Monitor if capacity overflow\n    x = x[0, ...]  # Take first batch/head\n    x = tf.reduce_sum(x, axis=0)\n    tf.summary.scalar(prefix + \"_min\", tf.reduce_min(x), family=\"lsh\")\n    tf.summary.scalar(prefix + \"_max\", tf.reduce_max(x), family=\"lsh\")\n    tf.summary.histogram(prefix + \"capacity_distribution\", x, family=\"lsh\")\n    for i in range(3):  # Show the first 3 buckets\n      tf.summary.scalar(\"{}_{}\".format(prefix, i), x[i], family=\"lsh\")\n\n  add_summary_capacity(gates_q, \"q\")\n  add_summary_capacity(gates_k, \"k\")\n\n  q_dispatcher = get_dispatcher(gates_q)\n  k_dispatcher = get_dispatcher(gates_k)\n\n  q = q_dispatcher.dispatch(q)\n  k = k_dispatcher.dispatch(k)\n  v = k_dispatcher.dispatch(v)\n\n  # Bias of shape [batch*heads, nb_buckets, 1, capacity] broadcasted to every\n  # queries\n  bias = tf.expand_dims((k_dispatcher.nonpadding() - 1.0) * 1e9, 2)\n  if mask_right:\n    q_coordinate = tf.to_float(\n        tf.expand_dims(q_dispatcher.length_coordinate(), 3))\n    k_coordinate = tf.to_float(\n        tf.expand_dims(k_dispatcher.length_coordinate(), 2))\n    bias += tf.to_float(tf.greater(k_coordinate, q_coordinate)) * -1e9\n  # The sequence padding is not masked but is ignored on the next layers\n\n  # q, k, v now have shape [batch*heads, nb_bucket, capacity, depth]\n  # The buckets can be seen as different heads\n  v_out = dot_product_attention(q, k, v, bias=bias)\n\n  # Combine all buckets together to restore the original length\n  return q_dispatcher.combine(v_out)", "response": "This function dispatches the q k v and computes the dot product on each subsequence."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deconv_elems_1d(x, factor, out_depth=None):\n  out_depth = out_depth or x.get_shape().as_list()[-1]\n  x = tf.expand_dims(x, 1)  # [batch_size, 1, length, depth]\n  x = layers().Conv2DTranspose(\n      filters=out_depth,\n      kernel_size=(1, factor),\n      strides=(1, factor),\n      padding=\"valid\",\n      data_format=\"channels_last\",\n  )(x)  # [batch_size, 1, length*factor, out_depth]\n  x = tf.squeeze(x, 1)  # [batch_size, length*factor, depth]\n  return x", "response": "Increase the length and change the dimensionality."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndecreases the length and change the dimensionality.", "response": "def conv_elems_1d(x, factor, out_depth=None):\n  \"\"\"Decrease the length and change the dimensionality.\n\n  Merge/restore/compress factors positions of dim depth of the input into\n  a single position of dim out_depth.\n  This is basically just a strided convolution without overlap\n  between each strides. The original length has to be divided by factor.\n\n  Args:\n    x (tf.Tensor): shape [batch_size, length, depth]\n    factor (int): Length compression factor.\n    out_depth (int): Output depth\n\n  Returns:\n    tf.Tensor: shape [batch_size, length//factor, out_depth]\n  \"\"\"\n  out_depth = out_depth or x.get_shape().as_list()[-1]\n  # with tf.control_dependencies(  # Dynamic assertion\n  #     [tf.assert_equal(tf.shape(x)[1] % factor, 0)]):\n  x = tf.expand_dims(x, 1)  # [batch_size, 1, length, depth]\n  x = layers().Conv2D(\n      filters=out_depth,\n      kernel_size=(1, factor),\n      strides=(1, factor),\n      padding=\"valid\",\n      data_format=\"channels_last\",\n  )(x)  # [batch_size, 1, length//factor, out_depth]\n  x = tf.squeeze(x, 1)  # [batch_size, length//factor, depth]\n  return x"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef local_reduction_attention(x, block_length, multihead_params):\n\n  @expert_utils.add_name_scope()\n  def dot_product_self_local_attention_flattened(q, k, v):\n    \"\"\"Strided block local self-attention.\n\n    No overlap between the blocks.\n\n    Args:\n      q (tf.Tensor): shape [batch, heads, length, depth_k]\n      k (tf.Tensor): shape [batch, heads, length, depth_k]\n      v (tf.Tensor): shape [batch, heads, length, depth_v]\n\n    Returns:\n      tf.Tensor: shape [batch, heads, length, depth_v]\n    \"\"\"\n    _, num_head, _, depth = q.get_shape().as_list()\n\n    # Extract the blocks\n    def pad_and_reshape(x):\n      \"\"\"Split the length dim into [num_block, block_length].\"\"\"\n      length_x = common_layers.shape_list(x)[2]\n      # Add some padding, but won't matter as the last block will never be\n      # attended by the query (after compression)\n      x = tf.pad(x, [[0, 0], [0, 0], [0, -length_x % block_length], [0, 0]])\n      x = tf.reshape(\n          x,\n          [\n              common_layers.shape_list(x)[0],  # Batch\n              num_head,  # Head\n              common_layers.shape_list(x)[2] // block_length,  # Num blocks\n              block_length,  # Block length\n              depth,  # Depth\n          ])\n      return x\n\n    q, k, v = [pad_and_reshape(t) for t in (q, k, v)]\n\n    # Perform attention on the flattened dot product\n    logits = tf.matmul(q, k, transpose_b=True)\n    logits = tf.reshape(\n        logits,\n        [\n            common_layers.shape_list(logits)[0],  # Batch\n            num_head,  # Head\n            common_layers.shape_list(logits)[2],  # Num blocks\n            block_length**2,  # Flatten last dimension\n        ])\n    weights = tf.nn.softmax(logits)\n    weights = tf.reshape(\n        weights,\n        [\n            common_layers.shape_list(weights)[0],  # Batch\n            num_head,  # Head\n            common_layers.shape_list(weights)[2],  # Num blocks\n            block_length,\n            block_length,  # Restore the block length dimension\n        ])\n    weights = tf.reduce_sum(weights, axis=3, keep_dims=True)  # Compress block\n    v_out = tf.matmul(weights, v)  # [1, block_length] @ [block_length, depth]\n    v_out = tf.squeeze(v_out, axis=3)\n    return v_out\n\n  return multihead_attention(\n      x,\n      None,\n      bias=None,\n      output_depth=x.get_shape().as_list()[-1],\n      attention_type=dot_product_self_local_attention_flattened,\n      **multihead_params)", "response": "Reduces the length dimension using self - attention."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreducing the length dimension by compressing with self - attention.", "response": "def multihead_self_attention_reduced(\n    x,\n    memory_antecedent=None,\n    bias=None,\n    factor=None,\n    multihead_params=None,\n    nonlinearity=\"none\",\n    reduction_type=\"conv\",\n    add_mask=True,\n):\n  \"\"\"Reduce the length dimension by compressing with conv.\n\n  Args:\n    x (tf.Tensor): float32 of shape [batch, length, depth]\n    memory_antecedent (tf.Tensor): Unsupported for now\n    bias (tf.Tensor): Ignored\n    factor (int): compression factor for the memory sequence\n    multihead_params (dict): parameters for multihead attention\n    nonlinearity (str): Add some non-linearity after the memory block\n    reduction_type (str): type of compression\n    add_mask (bool): If True, add the bias to prevent attention to the future\n\n  Returns:\n    (tf.Tensor): float32 of shape [batch, length, depth]\n\n  Raises:\n    ValueError: If reduction_type or nonlinearity is invalid\n  \"\"\"\n  if not factor or not multihead_params:\n    raise ValueError(\"factor and multihead_params should be set\")\n  if memory_antecedent is not None:\n    raise NotImplementedError(\n        \"multihead_self_attention_reduced only works with self-attention\")\n\n  depth = x.get_shape().as_list()[-1]\n\n  # Could try to have some overlap between the blocks but that would\n  # create conv artifacts, would make it difficult to not attend to the future\n  # within one group and the padding should be handled specially.\n\n  # Reduce the memory dimension\n  if reduction_type == \"attention\":\n    memory_x = local_reduction_attention(x, factor, multihead_params)\n  elif reduction_type == \"conv\":\n    # With valid padding, the last block won't be computed (not attended anyway)\n    memory_x = conv_elems_1d(x, factor)\n  else:\n    raise ValueError(\"Unknown reduction type {}\".format(reduction_type))\n\n  if nonlinearity == \"silu\":\n    memory_x *= tf.nn.sigmoid(memory_x)\n  elif nonlinearity != \"none\":\n    raise ValueError(\"Unknown non linearity {}\".format(nonlinearity))\n\n  memory_x = tf.concat(\n      # Add the first elem to make it attendable by everyone (otherwise the\n      # first block cannot attend to anything)\n      [x[:, :1, :], memory_x],\n      axis=1,\n  )\n\n  # Construct the bias\n  @expert_utils.add_name_scope()\n  def construct_bias_vectors(t, axis):\n    length = tf.to_float(common_layers.shape_list(t)[1])\n    length_coordinates = tf.range(length, dtype=tf.float32)\n    length_coordinates = tf.expand_dims(length_coordinates, axis=axis)\n    # [1, length_k] or [length_q, 1]\n    return length_coordinates\n\n  if add_mask:  # Create mask to prevent attention to the future\n    bias = tf.to_float(\n        tf.greater(\n            # Because we add the first elem to the memory block and it can be\n            # attended by anyone,we don't need to add +1 anymore to prevent self\n            # attention Use * factor to make sure the last tokens  of a block\n            # cannot attend the block\n            construct_bias_vectors(memory_x, 0) * factor,\n            # +epsilon to avoid float equality\n            construct_bias_vectors(x, 1) + 1e-3,\n        )) * -1e9\n    bias = tf.expand_dims(bias, axis=0)\n    bias = tf.expand_dims(bias, axis=0)  # [1, 1, length_k, length_q]\n  else:\n    bias = None\n\n  return multihead_attention(\n      query_antecedent=x,\n      memory_antecedent=memory_x,\n      bias=bias,\n      output_depth=depth,\n      **multihead_params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nscale dot - product attention. One head. One spatial dimension.", "response": "def scaled_dot_product_attention_simple(q, k, v, bias, name=None):\n  \"\"\"Scaled dot-product attention. One head. One spatial dimension.\n\n  Args:\n    q: a Tensor with shape [batch, length_q, depth_k]\n    k: a Tensor with shape [batch, length_kv, depth_k]\n    v: a Tensor with shape [batch, length_kv, depth_v]\n    bias: optional Tensor broadcastable to [batch, length_q, length_kv]\n    name: an optional string\n\n  Returns:\n    A Tensor.\n  \"\"\"\n  with tf.variable_scope(\n      name, default_name=\"scaled_dot_product_attention_simple\"):\n    scalar = tf.rsqrt(tf.to_float(common_layers.shape_list(q)[2]))\n    logits = tf.matmul(q * scalar, k, transpose_b=True)\n    if bias is not None:\n      logits += bias\n    weights = tf.nn.softmax(logits, name=\"attention_weights\")\n    if common_layers.should_generate_summaries():\n      tf.summary.image(\n          \"attention\", tf.expand_dims(tf.pow(weights, 0.2), 3), max_outputs=1)\n    return tf.matmul(weights, v)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _idx_to_bits(self, i):\n    bits = bin(i)[2:].zfill(self.nb_hyperplanes)  # Pad the bits str with 0\n    return [-1.0 if b == \"0\" else 1.0 for b in bits]", "response": "Convert an index to its bit representation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_gates(self, x):\n\n    # The balance loss don't propagate to the rest of the network\n    x = tf.stop_gradient(x)\n    # [length, depth] * [depth, nb_vectors * replicat]\n    x = tf.matmul(x, self.t_vectors)\n    # [length, nb_vector * replicat]\n    x = tf.sign(x)  # Get on which side of the hyperplane the keys are.\n\n    # x = tf.reshape(x, [-1, nb_replicat, nb_vector])\n    # [length, replicat, nb_vector] * [nb_vector, 2^nb_vector - 1]\n\n    x = tf.matmul(x, self.t_group, transpose_b=True) / self.nb_hyperplanes\n    # We get a similarity score for each of the group between [-1, 1]\n    # [length, (replicat,) 2^nb_vector - 1]\n    # Do an argmax to get the most likely group for each replicat\n    x = tf.argmax(x, axis=-1)\n    # [length(, replicat)]\n    # One-hot for compatibility with the sparse dispatcher\n    x = tf.one_hot(x, self.nb_buckets)\n    # TODO(epot): Use a loss to force an even distribution\n    return x", "response": "Returns the bucket id of the given tensor."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef van_enc_2d(x, first_depth, reuse=False):\n  with tf.variable_scope('van_enc', reuse=reuse):\n    a = 4  # depends on the inputs size\n    b = 4\n    # a, b = 4,4\n    enc = tf.nn.relu(x)\n    enc = tf.layers.dense(enc, first_depth * a * b, tf.nn.relu)\n    enc = tf.contrib.layers.layer_norm(enc)\n\n    enc = tf.reshape(enc, [-1, a, b, first_depth])\n\n    enc = tf.layers.conv2d_transpose(\n        enc, first_depth, 3, padding='same', activation=tf.nn.relu, strides=1)\n    enc = tf.contrib.layers.layer_norm(enc)\n    enc = tf.layers.conv2d_transpose(\n        enc,\n        first_depth * 2,\n        3,\n        padding='same',\n        activation=tf.nn.relu,\n        strides=2)\n    van_higher_level_2 = tf.reshape(enc, [-1, a * 2 * b * 2 * first_depth * 2])\n\n    enc = tf.layers.conv2d_transpose(\n        enc,\n        first_depth * 2,\n        3,\n        padding='same',\n        activation=tf.nn.relu,\n        strides=1)\n    enc = tf.contrib.layers.layer_norm(enc)\n    enc = tf.layers.conv2d_transpose(\n        enc,\n        first_depth * 4,\n        3,\n        padding='same',\n        activation=tf.nn.relu,\n        strides=1)\n    van_higher_level_4 = tf.reshape(enc, [-1, a * 2 * b * 2 * first_depth * 4])\n\n    van_higher_level = tf.concat([x, van_higher_level_2, van_higher_level_4], 1)\n\n    return enc, van_higher_level", "response": "The VAN encoder for the VAN."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef van_dec_2d(x, skip_connections, output_shape, first_depth, hparams=None):\n  with tf.variable_scope('van_dec'):\n    dec = tf.layers.conv2d_transpose(\n        x, first_depth * 4, 3, padding='same', activation=tf.nn.relu, strides=2)\n    dec = tf.nn.dropout(dec, hparams.van_keep_prob)\n    dec = tf.contrib.layers.layer_norm(dec)\n    dec = tf.layers.conv2d_transpose(\n        dec,\n        first_depth * 4,\n        3,\n        padding='same',\n        activation=tf.nn.relu,\n        strides=1)\n    dec = tf.nn.dropout(dec, hparams.van_keep_prob)\n    dec = tf.layers.conv2d_transpose(\n        dec,\n        first_depth * 2,\n        3,\n        padding='same',\n        activation=tf.nn.relu,\n        strides=1)\n    dec = tf.nn.dropout(dec, hparams.van_keep_prob)\n    dec = tf.contrib.layers.layer_norm(dec)\n\n    dec = tf.layers.conv2d_transpose(\n        dec,\n        first_depth * 2,\n        3,\n        padding='same',\n        activation=tf.nn.relu,\n        strides=2)\n    dec = tf.nn.dropout(dec, hparams.van_keep_prob)\n    dec = tf.layers.conv2d_transpose(\n        dec, first_depth, 3, padding='same', activation=tf.nn.relu, strides=1)\n    dec = tf.nn.dropout(dec, hparams.van_keep_prob)\n    dec = tf.contrib.layers.layer_norm(dec)\n\n    dec = tf.layers.conv2d_transpose(\n        dec,\n        output_shape[3] + 1,\n        3,\n        padding='same',\n        activation=tf.nn.relu,\n        strides=2)\n    dec = tf.nn.dropout(dec, hparams.van_keep_prob)\n\n    out_mask = tf.layers.conv2d_transpose(\n        dec, output_shape[3] + 1, 3, strides=1, padding='same', activation=None)\n\n    mask = tf.nn.sigmoid(out_mask[:, :, :, 3:4])\n    out = out_mask[:, :, :, :3]\n\n    return out * mask + skip_connections[0] * (1 - mask)", "response": "The VAN decoder.\n\n  Args:\n    x: The analogy information to decode.\n    skip_connections: The encoder layers which can be used as skip connections.\n    output_shape: The shape of the desired output image.\n    first_depth: The depth of the first layer of the van image encoder.\n    hparams: The python hparams.\n\n  Returns:\n    The decoded image prediction."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nimplementing the deep analogy computation.", "response": "def analogy_computation_2d(f_first_enc,\n                           f_first_frame,\n                           f_current_enc,\n                           first_depth):\n  \"\"\"Implements the deep analogy computation.\"\"\"\n  with tf.variable_scope('analogy_computation'):\n\n    frame_enc_diff = f_first_frame - f_first_enc\n\n    frame_enc_diff_enc = tf.layers.conv2d(\n        frame_enc_diff,\n        first_depth * 4,\n        3,\n        padding='same',\n        activation=tf.nn.relu,\n        strides=1)\n    f_current_enc_enc = tf.layers.conv2d(\n        f_current_enc,\n        first_depth * 4,\n        3,\n        padding='same',\n        activation=tf.nn.relu,\n        strides=1)\n\n    analogy = tf.concat([frame_enc_diff_enc, f_current_enc_enc], 3)\n    analogy = tf.layers.conv2d(\n        analogy,\n        first_depth * 4,\n        3,\n        padding='same',\n        activation=tf.nn.relu,\n        strides=1)\n    analogy = tf.contrib.layers.layer_norm(analogy)\n    analogy = tf.layers.conv2d(\n        analogy,\n        first_depth * 4,\n        3,\n        padding='same',\n        activation=tf.nn.relu,\n        strides=1)\n    return tf.layers.conv2d(\n        analogy,\n        first_depth * 4,\n        3,\n        padding='same',\n        activation=tf.nn.relu,\n        strides=1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimplements a VAN. Args: first_enc: The first encoding. first_frame: The first ground truth frame. current_enc: The encoding of the frame to generate. gt_image: The ground truth image, only used for regularization. reuse: To reuse in variable scope or not. scope_prefix: The prefix before the scope name. hparams: The python hparams. Returns: The generated image.", "response": "def van(first_enc,\n        first_frame,\n        current_enc,\n        gt_image,\n        reuse=False,\n        scope_prefix='',\n        hparams=None):\n  \"\"\"Implements a VAN.\n\n  Args:\n    first_enc: The first encoding.\n    first_frame: The first ground truth frame.\n    current_enc: The encoding of the frame to generate.\n    gt_image: The ground truth image, only used for regularization.\n    reuse: To reuse in variable scope or not.\n    scope_prefix: The prefix before the scope name.\n    hparams: The python hparams.\n\n  Returns:\n    The generated image.\n  \"\"\"\n  with tf.variable_scope(scope_prefix + 'van', reuse=reuse):\n    output_shape = first_frame.get_shape().as_list()\n    output_shape[0] = -1\n\n    first_depth = 64\n\n    f_first_enc, _ = van_enc_2d(first_enc, first_depth)\n    f_first_frame, image_enc_history = van_image_enc_2d(\n        first_frame, first_depth, hparams=hparams)\n    f_current_enc, van_higher_level = van_enc_2d(\n        current_enc, first_depth, reuse=True)\n    f_gt_image, _ = van_image_enc_2d(gt_image, first_depth, True,\n                                     hparams=hparams)\n\n    analogy_t = analogy_computation_2d(\n        f_first_enc, f_first_frame, f_current_enc, first_depth)\n    enc_img = f_current_enc + analogy_t\n\n    img = van_dec_2d(\n        enc_img, image_enc_history, output_shape, first_depth, hparams=hparams)\n\n    batch_size = tf.to_float(tf.shape(first_enc)[0])\n    r_loss = tf.nn.l2_loss(f_gt_image - f_current_enc - analogy_t) / batch_size\n\n    return img, r_loss, van_higher_level"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encoder_vgg(x, enc_final_size, reuse=False, scope_prefix='', hparams=None,\n                is_training=True):\n  \"\"\"VGG network to use as encoder without the top few layers.\n\n  Can be pretrained.\n\n  Args:\n    x: The image to encode. In the range 0 to 1.\n    enc_final_size: The desired size of the encoding.\n    reuse: To reuse in variable scope or not.\n    scope_prefix: The prefix before the scope name.\n    hparams: The python hparams.\n    is_training: boolean value indicating if training is happening.\n\n  Returns:\n    The generated image.\n  \"\"\"\n  with tf.variable_scope(scope_prefix + 'encoder', reuse=reuse):\n\n    # Preprocess input\n    x *= 256\n    x = x - COLOR_NORMALIZATION_VECTOR\n\n    with arg_scope(vgg.vgg_arg_scope()):\n      # Padding because vgg_16 accepts images of size at least VGG_IMAGE_SIZE.\n      x = tf.pad(x, [[0, 0], [0, VGG_IMAGE_SIZE - IMG_WIDTH],\n                     [0, VGG_IMAGE_SIZE - IMG_HEIGHT], [0, 0]])\n      _, end_points = vgg.vgg_16(\n          x,\n          num_classes=enc_final_size,\n          is_training=is_training)\n      pool5_key = [key for key in end_points.keys() if 'pool5' in key]\n      assert len(pool5_key) == 1\n      enc = end_points[pool5_key[0]]\n      # Undoing padding.\n      enc = tf.slice(enc, [0, 0, 0, 0], [-1, 2, 2, -1])\n\n    enc_shape = enc.get_shape().as_list()\n    enc_shape[0] = -1\n    enc_size = enc_shape[1] * enc_shape[2] * enc_shape[3]\n\n    enc_flat = tf.reshape(enc, (-1, enc_size))\n    enc_flat = tf.nn.dropout(enc_flat, hparams.enc_keep_prob)\n\n    enc_flat = tf.layers.dense(\n        enc_flat,\n        enc_final_size,\n        kernel_initializer=tf.truncated_normal_initializer(stddev=1e-4,))\n\n    if hparams.enc_pred_use_l2norm:\n      enc_flat = tf.nn.l2_normalize(enc_flat, 1)\n\n  return enc_flat", "response": "VGG network to use as encoder."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef construct_model(images,\n                    actions=None,\n                    context_frames=2,\n                    hparams=None,\n                    is_training=True):\n  \"\"\"Constructs the tensorflow graph of the hierarchical model.\"\"\"\n\n  pred_depth = 20\n\n  enc_out_all, pred_out_all, van_out_all, van_on_enc_all = [], [], [], []\n\n  lstm_states = [None] * (pred_depth + 2)\n\n  enc_out = encoder_vgg(\n      images[0], hparams.enc_size, False, scope_prefix='timestep/',\n      hparams=hparams, is_training=is_training)\n  enc_out = tf.identity(enc_out, 'enc_out')\n  enc_out_all.append(enc_out)\n\n  num_timesteps = len(actions) - 1\n  sum_freq = int(num_timesteps / 4 + 1)\n\n  reuse = False\n  for timestep, action in zip(range(len(actions) - 1), actions[:-1]):\n    done_warm_start = timestep > context_frames - 1\n\n    with tf.variable_scope('timestep', reuse=reuse):\n      if done_warm_start:\n        pred_input = pred_out_all[-1]\n      else:\n        pred_input = enc_out_all[-1]\n      pred_out = predictor(\n          pred_input, action, lstm_states, pred_depth, False, hparams=hparams)\n      pred_out = tf.identity(pred_out, 'pred_out')\n      if timestep % sum_freq == 0:  # and not hparams.use_tpu:\n        tf.summary.histogram('pred_out', pred_out)\n      pred_out_all.append(pred_out)\n\n      if timestep % sum_freq == 0:  # and not hparams.use_tpu:\n        tf.summary.histogram('lstm_state', lstm_states[0])\n      van_out, _, _ = van(\n          enc_out_all[0],\n          images[0],\n          pred_out,\n          images[timestep + 1],\n          tf.AUTO_REUSE,\n          hparams=hparams)\n      van_out = tf.identity(van_out, 'van_out')\n      van_out_all.append(van_out)\n\n      enc_out = encoder_vgg(\n          images[timestep + 1], hparams.enc_size, True, hparams=hparams,\n          is_training=is_training)\n      enc_out = tf.identity(enc_out, 'enc_out')\n      if timestep % sum_freq == 0:  # and not hparams.use_tpu:\n        tf.summary.histogram('enc_out', enc_out)\n      enc_out_all.append(enc_out)\n\n      van_input = images[0]\n      enc_noise = tf.zeros_like(enc_out)\n      if timestep % sum_freq == 0:  # and not hparams.use_tpu:\n        tf.summary.histogram('enc_noise', enc_noise)\n      van_on_enc, _, _ = van(\n          enc_out_all[0],\n          van_input,\n          enc_out + enc_noise,\n          images[timestep + 1],\n          tf.AUTO_REUSE,\n          hparams=hparams)\n      van_on_enc = tf.identity(van_on_enc, 'van_on_enc')\n      van_on_enc_all.append(van_on_enc)\n\n      reuse = True\n\n  return enc_out_all, pred_out_all, van_out_all, van_on_enc_all", "response": "Constructs the tensorflow graph of the hierarchical model."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef peak_signal_to_noise_ratio(true, pred):\n  return 10.0 * tf.log(1.0 / mean_squared_error(true, pred)) / tf.log(10.0)", "response": "Image quality metric based on maximal signal power vs. power of the noise."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef l1_error(true, pred):\n  return tf.reduce_sum(tf.abs(true - pred)) / tf.to_float(tf.size(pred))", "response": "L1 error between tensors true and pred."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate loss and psnr for predictions over multiple timesteps.", "response": "def calc_loss_psnr(gen_images, images, name, hparams=None, use_l1_loss=False):\n  \"\"\"Calculates loss and psnr for predictions over multiple timesteps.\"\"\"\n  del hparams\n  with tf.name_scope(name):\n    loss, error, psnr_all = 0.0, 0.0, 0.0\n    for _, x, gx in zip(range(len(gen_images)), images, gen_images):\n      recon_cost = mean_squared_error(x, gx)\n      if use_l1_loss:\n        recon_cost = l1_error(x, gx)\n\n      error_i = l1_error(x, gx)\n      psnr_i = peak_signal_to_noise_ratio(x, gx)\n      psnr_all += psnr_i\n      error += error_i\n      loss += recon_cost\n\n    psnr_all /= tf.to_float(len(gen_images))\n    loss /= tf.to_float(len(gen_images))\n    error /= tf.to_float(len(gen_images))\n\n    # if not hparams.use_tpu:\n    tf.summary.scalar('psnr_all', psnr_all)\n    tf.summary.scalar('loss', loss)\n\n    return loss, psnr_all"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef next_frame_sv2p_atari_softmax():\n  hparams = next_frame_sv2p_atari()\n  hparams.bottom = {}\n  hparams.loss = {}\n  hparams.top = {}\n  hparams.internal_loss = True\n  return hparams", "response": "SV2P model for atari with softmax."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_mscoco(directory):\n  for url in _MSCOCO_URLS:\n    filename = os.path.basename(url)\n    download_url = os.path.join(_MSCOCO_ROOT_URL, url)\n    path = generator_utils.maybe_download(directory, filename, download_url)\n    unzip_dir = os.path.join(directory, filename.strip(\".zip\"))\n    if not tf.gfile.Exists(unzip_dir):\n      zipfile.ZipFile(path, \"r\").extractall(directory)", "response": "Download and extract MSCOCO datasets to directory unless it is there."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimages generator for MSCOCO captioning problem with token - wise captions.", "response": "def mscoco_generator(data_dir,\n                     tmp_dir,\n                     training,\n                     how_many,\n                     start_from=0,\n                     eos_list=None,\n                     vocab_filename=None):\n  \"\"\"Image generator for MSCOCO captioning problem with token-wise captions.\n\n  Args:\n    data_dir: path to the data directory.\n    tmp_dir: path to temporary storage directory.\n    training: a Boolean; if true, we use the train set, otherwise the test set.\n    how_many: how many images and labels to generate.\n    start_from: from which image to start.\n    eos_list: optional list of end of sentence tokens, otherwise use default\n      value `1`.\n    vocab_filename: file within `tmp_dir` to read vocabulary from.\n\n  Yields:\n    A dictionary representing the images with the following fields:\n    * image/encoded: the string encoding the image as JPEG,\n    * image/format: the string \"jpeg\" representing image format,\n    * image/class/label: a list of integers representing the caption,\n    * image/height: an integer representing the height,\n    * image/width: an integer representing the width.\n    Every field is actually a list of the corresponding type.\n  \"\"\"\n  eos_list = [1] if eos_list is None else eos_list\n  def get_vocab():\n    \"\"\"Get vocab for caption text encoder.\"\"\"\n    if data_dir is not None and vocab_filename is not None:\n      vocab_filepath = os.path.join(data_dir, vocab_filename)\n      if tf.gfile.Exists(vocab_filepath):\n        tf.logging.info(\"Found vocab file: %s\", vocab_filepath)\n        vocab_symbolizer = text_encoder.SubwordTextEncoder(vocab_filepath)\n        return vocab_symbolizer\n      else:\n        raise ValueError(\"Vocab file does not exist: %s\" % vocab_filepath)\n    return None\n\n  vocab_symbolizer = get_vocab()\n  _get_mscoco(tmp_dir)\n  caption_filepath = (\n      _MSCOCO_TRAIN_CAPTION_FILE if training else _MSCOCO_EVAL_CAPTION_FILE)\n  caption_filepath = os.path.join(tmp_dir, caption_filepath)\n  prefix = _MSCOCO_TRAIN_PREFIX if training else _MSCOCO_EVAL_PREFIX\n  caption_file = io.open(caption_filepath)\n  caption_json = json.load(caption_file)\n  # Dictionary from image_id to ((filename, height, width), captions).\n  image_dict = {}\n  for image in caption_json[\"images\"]:\n    image_dict[image[\"id\"]] = [(image[\"file_name\"], image[\"height\"],\n                                image[\"width\"]), []]\n  annotations = caption_json[\"annotations\"]\n  annotation_count = len(annotations)\n  image_count = len(image_dict)\n  tf.logging.info(\"Processing %d images and %d labels\\n\" % (image_count,\n                                                            annotation_count))\n  for annotation in annotations:\n    image_id = annotation[\"image_id\"]\n    image_dict[image_id][1].append(annotation[\"caption\"])\n\n  data = list(image_dict.values())[start_from:start_from + how_many]\n  random.shuffle(data)\n  for image_info, labels in data:\n    image_filename = image_info[0]\n    image_filepath = os.path.join(tmp_dir, prefix, image_filename)\n    with tf.gfile.Open(image_filepath, \"rb\") as f:\n      encoded_image_data = f.read()\n      height, width = image_info[1], image_info[2]\n      for label in labels:\n        if vocab_filename is None or vocab_symbolizer is None:\n          label = [ord(c) for c in label] + eos_list\n        else:\n          label = vocab_symbolizer.encode(label) + eos_list\n        yield {\n            \"image/encoded\": [encoded_image_data],\n            \"image/format\": [\"jpeg\"],\n            \"image/class/label\": label,\n            \"image/height\": [height],\n            \"image/width\": [width]\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting FLAGS to list of args suitable for passing on cmd line.", "response": "def flags_as_args():\n  \"\"\"Convert FLAGS to list of args suitable for passing on cmd line.\"\"\"\n  if hasattr(FLAGS, \"flag_values_dict\"):\n    args_dict = FLAGS.flag_values_dict()\n  else:\n    args_dict = dict(FLAGS.__dict__[\"__flags\"])\n  del args_dict[\"cloud_mlengine\"]\n  # Configured later\n  del args_dict[\"t2t_usr_dir\"]\n  args_dict.pop(\"h\", None)\n  args_dict.pop(\"helpfull\", None)\n  args_dict.pop(\"helpshort\", None)\n  args_dict.pop(\"help\", None)\n  args = []\n  for name, val in args_dict.items():\n    if val is None:\n      continue\n    if name.startswith(\"autotune\"):\n      continue\n    args.extend([\"--%s=%s\" % (name, str(val))])\n  return args"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_default_master_type(num_gpus=1):\n  gpus_to_master_map = {\n      0: \"standard\",\n      1: \"standard_p100\",\n      4: \"complex_model_m_p100\",\n      8: \"complex_model_l_gpu\",\n  }\n  if num_gpus not in gpus_to_master_map:\n    raise ValueError(\"Num gpus must be in %s\" %\n                     str(sorted(list(gpus_to_master_map.keys()))))\n  return gpus_to_master_map[num_gpus]", "response": "Returns master_type for trainingInput."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconstruct jobSpec for ML Engine job.", "response": "def configure_job():\n  \"\"\"Construct jobSpec for ML Engine job.\"\"\"\n  # See documentation:\n  # https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs#traininginput\n  training_input = {\n      \"pythonModule\": \"tensor2tensor.bin.t2t_trainer\",\n      \"args\": flags_as_args(),\n      \"region\": text_encoder.native_to_unicode(default_region()),\n      \"runtimeVersion\": RUNTIME_VERSION,\n      \"pythonVersion\": \"3.5\" if sys.version_info.major == 3 else \"2.7\",\n      \"jobDir\": FLAGS.output_dir,\n      \"scaleTier\": \"CUSTOM\",\n      \"masterType\": FLAGS.cloud_mlengine_master_type or get_default_master_type(\n          num_gpus=FLAGS.worker_gpu)\n  }\n  if FLAGS.use_tpu:\n    training_input[\"masterType\"] = (FLAGS.cloud_mlengine_master_type or\n                                    \"standard\")\n    training_input[\"workerType\"] = \"cloud_tpu\"\n    training_input[\"workerCount\"] = 1\n  if FLAGS.hparams_range:\n    tf.logging.info(\"Configuring hyperparameter tuning.\")\n    training_input[\"hyperparameters\"] = configure_autotune(\n        FLAGS.hparams_range,\n        FLAGS.autotune_objective,\n        FLAGS.autotune_maximize,\n        FLAGS.autotune_max_trials,\n        FLAGS.autotune_parallel_trials,\n    )\n\n  timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n  job_spec = {\n      \"jobId\": \"%s_%s_t2t_%s\" % (FLAGS.model, FLAGS.problem, timestamp),\n      \"labels\": {\n          \"model\": FLAGS.model,\n          \"problem\": FLAGS.problem,\n          \"hparams\": FLAGS.hparams_set\n      },\n      \"trainingInput\": training_input,\n  }\n  return job_spec"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlaunching job on ML Engine.", "response": "def launch_job(job_spec):\n  \"\"\"Launch job on ML Engine.\"\"\"\n  project_id = \"projects/{}\".format(\n      text_encoder.native_to_unicode(default_project()))\n  credentials = GoogleCredentials.get_application_default()\n  cloudml = discovery.build(\"ml\", \"v1\", credentials=credentials,\n                            cache_discovery=False)\n  request = cloudml.projects().jobs().create(body=job_spec, parent=project_id)\n  request.execute()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntaring and gzip src_dir and copy to GCS target_dir.", "response": "def _tar_and_copy(src_dir, target_dir):\n  \"\"\"Tar and gzip src_dir and copy to GCS target_dir.\"\"\"\n  src_dir = src_dir.rstrip(\"/\")\n  target_dir = target_dir.rstrip(\"/\")\n  tmp_dir = tempfile.gettempdir().rstrip(\"/\")\n  src_base = os.path.basename(src_dir)\n  shell_run(\n      \"tar --exclude=.git -zcf {tmp_dir}/{src_base}.tar.gz -C {src_dir} .\",\n      src_dir=src_dir,\n      src_base=src_base,\n      tmp_dir=tmp_dir)\n  final_destination = \"%s/%s.tar.gz\" % (target_dir, src_base)\n  shell_run(\n      (\"gsutil cp {tmp_dir}/{src_base}.tar.gz \"\n       \"{final_destination}\"),\n      tmp_dir=tmp_dir,\n      src_base=src_base,\n      final_destination=final_destination)\n  return final_destination"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntars Tensor2Tensor and cp to train_dir.", "response": "def tar_and_copy_t2t(train_dir):\n  \"\"\"Tar Tensor2Tensor and cp to train_dir.\"\"\"\n  tf.logging.info(\"Tarring and pushing local Tensor2Tensor package.\")\n\n  output = text_encoder.native_to_unicode(shell_output(\n      \"pip show tensor2tensor\")).split(\"\\n\")\n  assert output[1].startswith(\"Version\")\n  assert output[7].startswith(\"Location\")\n  t2t_version = output[1].split(\":\")[1].strip()\n  t2t_dir = output[7].split(\":\")[1].strip()\n\n  # A local installation cloned from GitHub will have a setup.py file and a docs\n  # folder\n  is_local_t2t = all([\n      tf.gfile.Exists(os.path.join(t2t_dir, fname))\n      for fname in [\"setup.py\", \"docs/cloud_mlengine.md\"]\n  ])\n\n  if is_local_t2t:\n    tf.logging.info(\"Found local T2T installation. Tarring directory %s\",\n                    t2t_dir)\n  else:\n    # PyPI installation\n    # Create a folder with just a setup.py file pointing to the right version\n    tf.logging.info(\"Found PyPI T2T installation. Launching tensor2tensor==%s\",\n                    t2t_version)\n    t2t_dir = os.path.join(tempfile.gettempdir(), \"tensor2tensor_tmp\")\n    shutil.rmtree(t2t_dir, ignore_errors=True)\n    os.mkdir(t2t_dir)\n    setup_fname = os.path.join(t2t_dir, \"setup.py\")\n    setup_file_str = get_setup_file(\n        name=\"DummyT2TPackage\",\n        packages=[\"tensor2tensor==%s\" % t2t_version]\n    )\n    with tf.gfile.Open(setup_fname, \"w\") as f:\n      f.write(setup_file_str)\n  t2t_tar = _tar_and_copy(t2t_dir, train_dir)\n  return t2t_tar"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npackages tar and copy usr_dir to GCS train_dir.", "response": "def tar_and_copy_usr_dir(usr_dir, train_dir):\n  \"\"\"Package, tar, and copy usr_dir to GCS train_dir.\"\"\"\n  tf.logging.info(\"Tarring and pushing t2t_usr_dir.\")\n  usr_dir = os.path.abspath(os.path.expanduser(usr_dir))\n  # Copy usr dir to a temp location\n  top_dir = os.path.join(tempfile.gettempdir(), \"t2t_usr_container\")\n  tmp_usr_dir = os.path.join(top_dir, usr_dir_lib.INTERNAL_USR_DIR_PACKAGE)\n  shutil.rmtree(top_dir, ignore_errors=True)\n  shutil.copytree(usr_dir, tmp_usr_dir)\n  # Insert setup.py if one does not exist\n  top_setup_fname = os.path.join(top_dir, \"setup.py\")\n  setup_file_str = get_setup_file(\n      name=\"DummyUsrDirPackage\",\n      packages=get_requirements(usr_dir)\n  )\n  with tf.gfile.Open(top_setup_fname, \"w\") as f:\n    f.write(setup_file_str)\n  usr_tar = _tar_and_copy(top_dir, train_dir)\n  return usr_tar"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_flags():\n  assert not job_dir()\n  assert FLAGS.output_dir.startswith(\"gs://\")\n  assert FLAGS.data_dir.startswith(\"gs://\")\n  assert FLAGS.worker_replicas <= 1\n  assert FLAGS.ps_replicas <= 0\n  if FLAGS.hparams_range:\n    assert FLAGS.autotune_objective\n  if FLAGS.worker_gpu:\n    assert FLAGS.worker_gpu in [1, 4, 8]\n  if FLAGS.cloud_mlengine_master_type:\n    if FLAGS.worker_gpu:\n      if FLAGS.worker_gpu == 1:\n        assert FLAGS.cloud_mlengine_master_type in [\"standard_gpu\",\n                                                    \"standard_p100\"]\n      elif FLAGS.worker_gpu == 4:\n        assert FLAGS.cloud_mlengine_master_type in [\"complex_model_m_gpu\",\n                                                    \"complex_model_m_p100\"]\n      else:\n        assert FLAGS.cloud_mlengine_master_type == \"complex_model_l_gpu\"\n    else:\n      assert FLAGS.cloud_mlengine_master_type in [\"standard\", \"large_model\",\n                                                  \"complex_model_s\",\n                                                  \"complex_model_m\",\n                                                  \"complex_model_l\"]", "response": "Validates flags are set to acceptable values for CloudML Engine runs."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlaunches t2t_trainer on Cloud ML Engine.", "response": "def launch():\n  \"\"\"Launch t2t_trainer on Cloud ML Engine.\"\"\"\n  validate_flags()\n  job_spec = configure_job()\n  job_name = job_spec[\"jobId\"]\n  tf.logging.info(\"Launching job %s with ML Engine spec:\\n%s\", job_name,\n                  pprint.pformat(job_spec))\n  assert confirm()\n  train_dir = FLAGS.output_dir\n  t2t_tar = tar_and_copy_t2t(train_dir)\n  configure_trainer_package(job_spec, t2t_tar)\n  if FLAGS.t2t_usr_dir:\n    usr_tar = tar_and_copy_usr_dir(FLAGS.t2t_usr_dir, train_dir)\n    configure_usr_dir(job_spec, usr_tar)\n  launch_job(job_spec)\n  tf.logging.info(\"Launched %s. See console to track: %s.\", job_name,\n                  CONSOLE_URL)\n  tf.logging.info(\"Interact with the training job from the command line:\")\n  tf.logging.info(\"Abort job: gcloud ml-engine jobs cancel %s\", job_name)\n  tf.logging.info(\"Stream logs: gcloud ml-engine jobs stream-logs %s\", job_name)\n  tf.logging.info(\"Open tensorboard: tensorboard --logdir %s\", train_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_weight(cls):\n  @functools.wraps(cls.add_weight)\n  def _add_weight(self,\n                  name=None,\n                  shape=None,\n                  dtype=None,\n                  initializer=None,\n                  regularizer=None,\n                  **kwargs):\n    \"\"\"Adds weight.\"\"\"\n    if isinstance(initializer, tf.keras.layers.Layer):\n      weight = initializer(shape, dtype)\n      self._trainable_weights.extend(initializer.trainable_weights)  # pylint: disable=protected-access\n      self._non_trainable_weights.extend(initializer.non_trainable_weights)  # pylint: disable=protected-access\n      if regularizer is not None:\n        # TODO(trandustin): Replace need for this with\n        # Layer._handle_weight_regularization. For Eager compatibility, random\n        # variable __init__s cannot apply TF ops (cl/220898007).\n        def loss_fn():\n          \"\"\"Creates a regularization loss `Tensor`.\"\"\"\n          with tf.name_scope(name + '/Regularizer'):\n            return regularizer(initializer(shape, dtype))\n        self.add_loss(loss_fn)\n      return weight\n    return super(cls, self).add_weight(name=name,\n                                       shape=shape,\n                                       dtype=dtype,\n                                       initializer=initializer,\n                                       regularizer=regularizer,\n                                       **kwargs)\n  cls.add_weight = _add_weight\n  return cls", "response": "Decorator for Layer subclasses overriding add_weight for non - trainable initializers."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_beta(self, kl_loss=0.0):\n    if self.hparams.latent_loss_multiplier_dynamic:\n      beta = tf.Variable(self.hparams.latent_loss_multiplier,\n                         trainable=False, dtype=tf.float32)\n      alpha = self.hparams.latent_loss_multiplier_alpha\n      epsilon = self.hparams.latent_loss_multiplier_epsilon\n      shadow_beta = beta + alpha * (kl_loss - epsilon)\n      # Caping the beta between 0 and 1. May need to change this later on.\n      shadow_beta = tf.maximum(shadow_beta, 0.0)\n      shadow_beta = tf.minimum(shadow_beta, 1.0)\n      update_op = tf.assign(beta, shadow_beta)\n    else:\n      beta = common_video.beta_schedule(\n          schedule=self.hparams.latent_loss_multiplier_schedule,\n          global_step=self.get_iteration_num(),\n          final_beta=self.hparams.latent_loss_multiplier,\n          decay_start=(self.hparams.num_iterations_1st_stage +\n                       self.hparams.num_iterations_2nd_stage),\n          decay_end=self.hparams.anneal_end)\n      update_op = tf.identity(beta)  # fake update for regular beta.\n    with tf.control_dependencies([update_op]):\n      tf.summary.scalar(\"beta\", beta)\n      return beta", "response": "Get the KL multiplier."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets KL loss for all predicted Gaussians.", "response": "def get_kl_loss(self, means, log_vars, means_p=None, log_vars_p=None):\n    \"\"\"Get KL loss for all the predicted Gaussians.\"\"\"\n    kl_loss = 0.0\n    if means_p is None:\n      means_p = tf.unstack(tf.zeros_like(means))\n    if log_vars_p is None:\n      log_vars_p = tf.unstack(tf.zeros_like(log_vars))\n    enumerated_inputs = enumerate(zip(means, log_vars, means_p, log_vars_p))\n    if self.is_training and self.hparams.stochastic_model:\n      for i, (mean, log_var, mean_p, log_var_p) in enumerated_inputs:\n        kl_loss += common_layers.kl_divergence(mean, log_var, mean_p, log_var_p)\n        tf.summary.histogram(\"posterior_mean_%d\" % i, mean)\n        tf.summary.histogram(\"posterior_log_var_%d\" % i, log_var)\n        tf.summary.histogram(\"prior_mean_%d\" % i, mean_p)\n        tf.summary.histogram(\"prior_log_var_%d\" % i, log_var_p)\n      tf.summary.scalar(\"kl_raw\", tf.reduce_mean(kl_loss))\n\n    beta = self.get_beta(kl_loss)\n    # information capacity from \"Understanding disentangling in beta-VAE\"\n    if self.hparams.information_capacity > 0.0:\n      kl_loss = tf.abs(kl_loss - self.hparams.information_capacity)\n    return beta * kl_loss"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconstructing the latent tower.", "response": "def construct_latent_tower(self, images, time_axis):\n    \"\"\"Create the latent tower.\"\"\"\n    # No latent in the first phase\n    first_phase = tf.less(\n        self.get_iteration_num(), self.hparams.num_iterations_1st_stage)\n\n    # use all frames by default but this allows more\n    # predicted frames at inference time\n    latent_num_frames = self.hparams.latent_num_frames\n    tf.logging.info(\"Creating latent tower with %d frames.\" % latent_num_frames)\n    if latent_num_frames > 0:\n      images = images[:, :latent_num_frames]\n\n    return common_video.conv_latent_tower(\n        images=images,\n        time_axis=time_axis,\n        latent_channels=self.hparams.latent_channels,\n        min_logvar=self.hparams.latent_std_min,\n        is_training=self.is_training,\n        random_latent=first_phase,\n        tiny_mode=self.hparams.tiny_mode,\n        small_mode=self.hparams.small_mode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transformer_encode(encoder_function, inputs, target_space, hparams,\n                       attention_weights=None, features=None, losses=None,\n                       **kwargs):\n  \"\"\"Encode transformer inputs.\n\n  Args:\n    encoder_function: the encoder function\n    inputs: Transformer inputs [batch_size, input_length, 1, hidden_dim] which\n      will be flattened along the two spatial dimensions.\n    target_space: scalar, target space ID.\n    hparams: hyperparameters for model.\n    attention_weights: weight to store attention to.\n    features: optionally pass the entire features dictionary as well. This is\n      needed now for \"packed\" datasets.\n    losses: optional list onto which to append extra training losses\n    **kwargs: additional arguments to pass to encoder_function\n\n  Returns:\n    Tuple of:\n        encoder_output: Encoder representation.\n            [batch_size, input_length, hidden_dim]\n        encoder_decoder_attention_bias: Bias and mask weights for\n            encoder-decoder attention. [batch_size, input_length]\n  \"\"\"\n  inputs = common_layers.flatten4d3d(inputs)\n\n  encoder_input, self_attention_bias, encoder_decoder_attention_bias = (\n      transformer_prepare_encoder(\n          inputs, target_space, hparams, features=features))\n\n  mlperf_log.transformer_print(\n      key=mlperf_log.MODEL_HP_LAYER_POSTPROCESS_DROPOUT,\n      value=hparams.layer_prepostprocess_dropout,\n      hparams=hparams)\n\n  encoder_input = tf.nn.dropout(encoder_input,\n                                1.0 - hparams.layer_prepostprocess_dropout)\n\n  attn_bias_for_padding = None\n  # Otherwise the encoder will just use encoder_self_attention_bias.\n  if hparams.unidirectional_encoder:\n    attn_bias_for_padding = encoder_decoder_attention_bias\n\n  encoder_output = encoder_function(\n      encoder_input,\n      self_attention_bias,\n      hparams,\n      nonpadding=features_to_nonpadding(features, \"inputs\"),\n      save_weights_to=attention_weights,\n      make_image_summary=not common_layers.is_xla_compiled(),\n      losses=losses,\n      attn_bias_for_padding=attn_bias_for_padding,\n      **kwargs)\n\n  return encoder_output, encoder_decoder_attention_bias", "response": "Encode transformer inputs.\n\n  Args:\n    encoder_function: the encoder function\n    inputs: Transformer inputs [batch_size, input_length, 1, hidden_dim] which\n      will be flattened along the two spatial dimensions.\n    target_space: scalar, target space ID.\n    hparams: hyperparameters for model.\n    attention_weights: weight to store attention to.\n    features: optionally pass the entire features dictionary as well. This is\n      needed now for \"packed\" datasets.\n    losses: optional list onto which to append extra training losses\n    **kwargs: additional arguments to pass to encoder_function\n\n  Returns:\n    Tuple of:\n        encoder_output: Encoder representation.\n            [batch_size, input_length, hidden_dim]\n        encoder_decoder_attention_bias: Bias and mask weights for\n            encoder-decoder attention. [batch_size, input_length]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef transformer_decode(decoder_function,\n                       decoder_input,\n                       encoder_output,\n                       encoder_decoder_attention_bias,\n                       decoder_self_attention_bias,\n                       hparams,\n                       attention_weights=None,\n                       cache=None,\n                       decode_loop_step=None,\n                       nonpadding=None,\n                       losses=None,\n                       **kwargs):\n  \"\"\"Decode Transformer outputs from encoder representation.\n\n  Args:\n    decoder_function: the decoder function\n    decoder_input: inputs to bottom of the model. [batch_size, decoder_length,\n      hidden_dim]\n    encoder_output: Encoder representation. [batch_size, input_length,\n      hidden_dim]\n    encoder_decoder_attention_bias: Bias and mask weights for encoder-decoder\n      attention. [batch_size, input_length]\n    decoder_self_attention_bias: Bias and mask weights for decoder\n      self-attention. [batch_size, decoder_length]\n    hparams: hyperparameters for model.\n    attention_weights: weight to store attention to.\n    cache: dict, containing tensors which are the results of previous\n      attentions, used for fast decoding.\n    decode_loop_step: An integer, step number of the decoding loop. Only used\n      for inference on TPU.\n    nonpadding: optional Tensor with shape [batch_size, decoder_length]\n    losses: optional list onto which to append extra training losses\n    **kwargs: additional arguments to pass to decoder_function\n\n  Returns:\n    Final decoder representation. [batch_size, decoder_length, hidden_dim]\n  \"\"\"\n  mlperf_log.transformer_print(\n      key=mlperf_log.MODEL_HP_LAYER_POSTPROCESS_DROPOUT,\n      value=hparams.layer_prepostprocess_dropout,\n      hparams=hparams)\n  decoder_input = tf.nn.dropout(decoder_input,\n                                1.0 - hparams.layer_prepostprocess_dropout)\n\n  decoder_output = decoder_function(\n      decoder_input,\n      encoder_output,\n      decoder_self_attention_bias,\n      encoder_decoder_attention_bias,\n      hparams,\n      cache=cache,\n      decode_loop_step=decode_loop_step,\n      nonpadding=nonpadding,\n      save_weights_to=attention_weights,\n      losses=losses,\n      **kwargs)\n\n  if (common_layers.is_xla_compiled() and\n      hparams.mode == tf.estimator.ModeKeys.TRAIN):\n    # TPU does not react kindly to extra dimensions.\n    # TODO(noam): remove this once TPU is more forgiving of extra dims.\n    return decoder_output\n  else:\n    # Expand since t2t expects 4d tensors.\n    return tf.expand_dims(decoder_output, axis=2)", "response": "Decode Transformer outputs from encoder representation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _init_transformer_cache(cache, hparams, batch_size, attention_init_length,\n                            encoder_output, encoder_decoder_attention_bias,\n                            scope_prefix):\n  \"\"\"Create the initial cache for Transformer fast decoding.\"\"\"\n  key_channels = hparams.attention_key_channels or hparams.hidden_size\n  value_channels = hparams.attention_value_channels or hparams.hidden_size\n  num_layers = hparams.num_decoder_layers or hparams.num_hidden_layers\n  vars_3d_num_heads = (\n      hparams.num_heads if hparams.get(\"attention_variables_3d\") else 0)\n\n  if cache is None:\n    cache = {}\n  cache.update({\n      \"layer_%d\" % layer: {  # pylint: disable=g-complex-comprehension\n          \"k\":\n              common_attention.split_heads(\n                  tf.zeros([batch_size,\n                            attention_init_length,\n                            key_channels]), hparams.num_heads),\n          \"v\":\n              common_attention.split_heads(\n                  tf.zeros([batch_size,\n                            attention_init_length,\n                            value_channels]), hparams.num_heads),\n      } for layer in range(num_layers)\n  })\n\n  # If `ffn_layer` is in `[\"dense_relu_dense\" or \"conv_hidden_relu\"]`, then the\n  # cache key \"f\" won't be used, which means that the` shape of cache[\"f\"]`\n  # won't be changed to\n  # `[beamsize*batch_size, decode_length, hparams.hidden_size]` and may cause\n  # error when applying `nest.map reshape function` on it.\n  if hparams.ffn_layer not in [\"dense_relu_dense\", \"conv_hidden_relu\"]:\n    for layer in range(num_layers):\n      cache[\"layer_%d\" % layer][\"f\"] = tf.zeros(\n          [batch_size, 0, hparams.hidden_size])\n\n  if encoder_output is not None:\n    for layer in range(num_layers):\n      layer_name = \"layer_%d\" % layer\n      with tf.variable_scope(\n          \"%sdecoder/%s/encdec_attention/multihead_attention\" %\n          (scope_prefix, layer_name)):\n        k_encdec = common_attention.compute_attention_component(\n            encoder_output,\n            key_channels,\n            name=\"k\",\n            vars_3d_num_heads=vars_3d_num_heads)\n        k_encdec = common_attention.split_heads(k_encdec, hparams.num_heads)\n        v_encdec = common_attention.compute_attention_component(\n            encoder_output,\n            value_channels,\n            name=\"v\",\n            vars_3d_num_heads=vars_3d_num_heads)\n        v_encdec = common_attention.split_heads(v_encdec, hparams.num_heads)\n      cache[layer_name][\"k_encdec\"] = k_encdec\n      cache[layer_name][\"v_encdec\"] = v_encdec\n\n    cache[\"encoder_output\"] = encoder_output\n    cache[\"encoder_decoder_attention_bias\"] = encoder_decoder_attention_bias\n  return cache", "response": "Create the initial cache for Transformer fast decoding."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives encoder output and a symbols to logits function, does fast decoding. Implements both greedy and beam search decoding for TPU, uses beam search iff beam_size > 1, otherwise beam search related arguments are ignored. Args: encoder_output: A tensor, output from encoder. encoder_decoder_attention_bias: A tensor, bias for use in encoder-decoder attention. symbols_to_logits_fn: Incremental decoding, function mapping triple `(ids, step, cache)` to symbol logits. hparams: Run hyperparameters. decode_length: An integer, how many additional timesteps to decode. vocab_size: Output vocabulary size. init_cache_fn: Function that returns the initial cache dict. beam_size: An integer, number of beams. top_beams: An integer, how many of the beams to return. alpha: A float that controls the length penalty. Larger the alpha, stronger the preference for longer translations. sos_id: Start-of-sequence symbol. eos_id: End-of-sequence symbol. batch_size: An integer, must be passed if there is no input. force_decode_length: A bool, whether to force the full decode length, or if False, stop when all beams hit eos_id. scope_prefix: str, prefix for decoder layer variable scopes. use_top_k_with_unique: bool, whether to use a fast (but decreased precision) top_k during beam search. Returns: A dict of decoding results { \"outputs\": integer `Tensor` of decoded ids of shape [batch_size, <= decode_length] if top_beams == 1 or [batch_size, top_beams, <= decode_length] otherwise \"scores\": decoding log probs from the beam search, None if using greedy decoding (beam_size=1) }. Raises: NotImplementedError: If beam size > 1 with partial targets.", "response": "def fast_decode_tpu(encoder_output,\n                    encoder_decoder_attention_bias,\n                    symbols_to_logits_fn,\n                    hparams,\n                    decode_length,\n                    vocab_size,\n                    init_cache_fn=_init_transformer_cache,\n                    beam_size=1,\n                    top_beams=1,\n                    alpha=1.0,\n                    sos_id=0,\n                    eos_id=beam_search.EOS_ID,\n                    batch_size=None,\n                    force_decode_length=False,\n                    scope_prefix=\"body/\",\n                    use_top_k_with_unique=True):\n  \"\"\"Given encoder output and a symbols to logits function, does fast decoding.\n\n  Implements both greedy and beam search decoding for TPU, uses beam search iff\n  beam_size > 1, otherwise beam search related arguments are ignored.\n\n  Args:\n    encoder_output: A tensor, output from encoder.\n    encoder_decoder_attention_bias: A tensor, bias for use in encoder-decoder\n      attention.\n    symbols_to_logits_fn: Incremental decoding, function mapping triple `(ids,\n      step, cache)` to symbol logits.\n    hparams: Run hyperparameters.\n    decode_length: An integer, how many additional timesteps to decode.\n    vocab_size: Output vocabulary size.\n    init_cache_fn: Function that returns the initial cache dict.\n    beam_size: An integer, number of beams.\n    top_beams: An integer, how many of the beams to return.\n    alpha: A float that controls the length penalty. Larger the alpha, stronger\n      the preference for longer translations.\n    sos_id: Start-of-sequence symbol.\n    eos_id: End-of-sequence symbol.\n    batch_size: An integer, must be passed if there is no input.\n    force_decode_length: A bool, whether to force the full decode length, or if\n      False, stop when all beams hit eos_id.\n    scope_prefix: str, prefix for decoder layer variable scopes.\n    use_top_k_with_unique: bool, whether to use a fast (but decreased precision)\n      top_k during beam search.\n\n  Returns:\n    A dict of decoding results {\n        \"outputs\": integer `Tensor` of decoded ids of shape\n            [batch_size, <= decode_length] if top_beams == 1 or\n            [batch_size, top_beams, <= decode_length] otherwise\n        \"scores\": decoding log probs from the beam search,\n            None if using greedy decoding (beam_size=1)\n    }.\n\n  Raises:\n    NotImplementedError: If beam size > 1 with partial targets.\n  \"\"\"\n  if encoder_output is not None:\n    batch_size = common_layers.shape_list(encoder_output)[0]\n\n  cache = init_cache_fn(None, hparams, batch_size, decode_length,\n                        encoder_output, encoder_decoder_attention_bias,\n                        scope_prefix)\n\n  mlperf_log.transformer_print(\n      key=mlperf_log.MODEL_HP_SEQ_BEAM_SEARCH,\n      value={\n          \"vocab_size\": vocab_size,\n          \"batch_size\": batch_size,\n          \"beam_size\": beam_size,\n          \"alpha\": alpha,\n          \"max_decode_length\": decode_length\n      },\n      hparams=hparams)\n  if beam_size > 1:  # Beam Search\n    initial_ids = sos_id * tf.ones([batch_size], dtype=tf.int32)\n    decoded_ids, scores, _ = beam_search.beam_search(\n        symbols_to_logits_fn,\n        initial_ids,\n        beam_size,\n        decode_length,\n        vocab_size,\n        alpha,\n        states=cache,\n        eos_id=eos_id,\n        stop_early=(top_beams == 1),\n        use_tpu=True,\n        use_top_k_with_unique=use_top_k_with_unique)\n\n    if top_beams == 1:\n      decoded_ids = decoded_ids[:, 0, 1:]\n      scores = scores[:, 0]\n    else:\n      decoded_ids = decoded_ids[:, :top_beams, 1:]\n      scores = scores[:, :top_beams]\n  else:  # Greedy\n\n    def inner_loop(i, hit_eos, next_id, decoded_ids, cache, log_prob):\n      \"\"\"One step of greedy decoding.\"\"\"\n      logits, cache = symbols_to_logits_fn(next_id, i, cache)\n      log_probs = common_layers.log_prob_from_logits(logits)\n      temperature = getattr(hparams, \"sampling_temp\", 0.0)\n      keep_top = getattr(hparams, \"sampling_keep_top_k\", -1)\n      if hparams.sampling_method == \"argmax\":\n        temperature = 0.0\n      next_id = common_layers.sample_with_temperature(\n          logits, temperature, keep_top)\n\n      hit_eos |= tf.equal(next_id, eos_id)\n\n      log_prob_indices = tf.stack([tf.range(tf.to_int64(batch_size)), next_id],\n                                  axis=1)\n      log_prob += tf.gather_nd(log_probs, log_prob_indices)\n\n      next_id = tf.expand_dims(next_id, axis=1)\n      decoded_ids = tf.transpose(decoded_ids)\n      decoded_ids = inplace_ops.alias_inplace_update(\n          decoded_ids, i, tf.squeeze(next_id, axis=1))\n      decoded_ids = tf.transpose(decoded_ids)\n      return i + 1, hit_eos, next_id, decoded_ids, cache, log_prob\n\n    def is_not_finished(i, hit_eos, *_):\n      finished = i >= decode_length\n      if not force_decode_length:\n        finished |= tf.reduce_all(hit_eos)\n      return tf.logical_not(finished)\n\n    decoded_ids = tf.zeros([batch_size, decode_length], dtype=tf.int64)\n    hit_eos = tf.fill([batch_size], False)\n    next_id = sos_id * tf.ones([batch_size, 1], dtype=tf.int64)\n    initial_log_prob = tf.zeros([batch_size], dtype=tf.float32)\n\n    def compute_cache_shape_invariants(tensor):\n      return tf.TensorShape(tensor.shape.as_list())\n\n    _, _, _, decoded_ids, _, log_prob = tf.while_loop(\n        is_not_finished,\n        inner_loop, [\n            tf.constant(0), hit_eos, next_id, decoded_ids, cache,\n            initial_log_prob\n        ],\n        shape_invariants=[\n            tf.TensorShape([]),\n            tf.TensorShape([batch_size]),\n            tf.TensorShape([batch_size, 1]),\n            tf.TensorShape([batch_size, decode_length]),\n            nest.map_structure(compute_cache_shape_invariants, cache),\n            tf.TensorShape([batch_size]),\n        ])\n    scores = log_prob\n\n  return {\"outputs\": decoded_ids, \"scores\": scores}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive encoder output and a symbols to logits function, does fast decoding. Implements both greedy and beam search decoding, uses beam search iff beam_size > 1, otherwise beam search related arguments are ignored. Args: encoder_output: Output from encoder. encoder_decoder_attention_bias: a bias tensor for use in encoder-decoder attention symbols_to_logits_fn: Incremental decoding; function mapping triple `(ids, step, cache)` to symbol logits. hparams: run hyperparameters decode_length: an integer. How many additional timesteps to decode. vocab_size: Output vocabulary size. init_cache_fn: Function that returns the initial cache dict. beam_size: number of beams. top_beams: an integer. How many of the beams to return. alpha: Float that controls the length penalty. larger the alpha, stronger the preference for longer translations. sos_id: End-of-sequence symbol in beam search. eos_id: End-of-sequence symbol in beam search. batch_size: an integer scalar - must be passed if there is no input force_decode_length: bool, whether to force the full decode length, or if False, stop when all beams hit eos_id. scope_prefix: str, prefix for decoder layer variable scopes. cache: cache dictionary for additional predictions. Returns: A dict of decoding results { \"outputs\": integer `Tensor` of decoded ids of shape [batch_size, <= decode_length] if top_beams == 1 or [batch_size, top_beams, <= decode_length] otherwise \"scores\": decoding log probs from the beam search, None if using greedy decoding (beam_size=1) } Raises: NotImplementedError: If beam size > 1 with partial targets.", "response": "def fast_decode(encoder_output,\n                encoder_decoder_attention_bias,\n                symbols_to_logits_fn,\n                hparams,\n                decode_length,\n                vocab_size,\n                init_cache_fn=_init_transformer_cache,\n                beam_size=1,\n                top_beams=1,\n                alpha=1.0,\n                sos_id=0,\n                eos_id=beam_search.EOS_ID,\n                batch_size=None,\n                force_decode_length=False,\n                scope_prefix=\"body/\",\n                cache=None):\n  \"\"\"Given encoder output and a symbols to logits function, does fast decoding.\n\n  Implements both greedy and beam search decoding, uses beam search iff\n  beam_size > 1, otherwise beam search related arguments are ignored.\n\n  Args:\n    encoder_output: Output from encoder.\n    encoder_decoder_attention_bias: a bias tensor for use in encoder-decoder\n      attention\n    symbols_to_logits_fn: Incremental decoding; function mapping triple `(ids,\n      step, cache)` to symbol logits.\n    hparams: run hyperparameters\n    decode_length: an integer.  How many additional timesteps to decode.\n    vocab_size: Output vocabulary size.\n    init_cache_fn: Function that returns the initial cache dict.\n    beam_size: number of beams.\n    top_beams: an integer. How many of the beams to return.\n    alpha: Float that controls the length penalty. larger the alpha, stronger\n      the preference for longer translations.\n    sos_id: End-of-sequence symbol in beam search.\n    eos_id: End-of-sequence symbol in beam search.\n    batch_size: an integer scalar - must be passed if there is no input\n    force_decode_length: bool, whether to force the full decode length, or if\n      False, stop when all beams hit eos_id.\n    scope_prefix: str, prefix for decoder layer variable scopes.\n    cache: cache dictionary for additional predictions.\n\n  Returns:\n      A dict of decoding results {\n          \"outputs\": integer `Tensor` of decoded ids of shape\n              [batch_size, <= decode_length] if top_beams == 1 or\n              [batch_size, top_beams, <= decode_length] otherwise\n          \"scores\": decoding log probs from the beam search,\n              None if using greedy decoding (beam_size=1)\n      }\n\n    Raises:\n      NotImplementedError: If beam size > 1 with partial targets.\n  \"\"\"\n  if encoder_output is not None:\n    batch_size = common_layers.shape_list(encoder_output)[0]\n\n  cache = init_cache_fn(\n      cache=cache,\n      hparams=hparams,\n      batch_size=batch_size,\n      attention_init_length=0,\n      encoder_output=encoder_output,\n      encoder_decoder_attention_bias=encoder_decoder_attention_bias,\n      scope_prefix=scope_prefix)\n\n  if beam_size > 1:  # Beam Search\n    initial_ids = sos_id * tf.ones([batch_size], dtype=tf.int32)\n    decoded_ids, scores, cache = beam_search.beam_search(\n        symbols_to_logits_fn,\n        initial_ids,\n        beam_size,\n        decode_length,\n        vocab_size,\n        alpha,\n        states=cache,\n        eos_id=eos_id,\n        stop_early=(top_beams == 1))\n\n    if top_beams == 1:\n      decoded_ids = decoded_ids[:, 0, 1:]\n      scores = scores[:, 0]\n    else:\n      decoded_ids = decoded_ids[:, :top_beams, 1:]\n      scores = scores[:, :top_beams]\n  else:  # Greedy\n\n    def inner_loop(i, hit_eos, next_id, decoded_ids, cache, log_prob):\n      \"\"\"One step of greedy decoding.\"\"\"\n      logits, cache = symbols_to_logits_fn(next_id, i, cache)\n      log_probs = common_layers.log_prob_from_logits(logits)\n      temperature = getattr(hparams, \"sampling_temp\", 0.0)\n      keep_top = getattr(hparams, \"sampling_keep_top_k\", -1)\n      if hparams.sampling_method == \"argmax\":\n        temperature = 0.0\n      next_id = common_layers.sample_with_temperature(\n          logits, temperature, keep_top)\n      hit_eos |= tf.equal(next_id, eos_id)\n\n      log_prob_indices = tf.stack([tf.range(tf.to_int64(batch_size)), next_id],\n                                  axis=1)\n      log_prob += tf.gather_nd(log_probs, log_prob_indices)\n\n      next_id = tf.expand_dims(next_id, axis=1)\n      decoded_ids = tf.concat([decoded_ids, next_id], axis=1)\n      return i + 1, hit_eos, next_id, decoded_ids, cache, log_prob\n\n    def is_not_finished(i, hit_eos, *_):\n      finished = i >= decode_length\n      if not force_decode_length:\n        finished |= tf.reduce_all(hit_eos)\n      return tf.logical_not(finished)\n\n    decoded_ids = tf.zeros([batch_size, 0], dtype=tf.int64)\n    hit_eos = tf.fill([batch_size], False)\n    next_id = sos_id * tf.ones([batch_size, 1], dtype=tf.int64)\n    initial_log_prob = tf.zeros([batch_size], dtype=tf.float32)\n    _, _, _, decoded_ids, cache, log_prob = tf.while_loop(\n        is_not_finished,\n        inner_loop, [\n            tf.constant(0), hit_eos, next_id, decoded_ids, cache,\n            initial_log_prob\n        ],\n        shape_invariants=[\n            tf.TensorShape([]),\n            tf.TensorShape([None]),\n            tf.TensorShape([None, None]),\n            tf.TensorShape([None, None]),\n            nest.map_structure(beam_search.get_state_shape_invariants, cache),\n            tf.TensorShape([None]),\n        ])\n    scores = log_prob\n\n  return {\"outputs\": decoded_ids, \"scores\": scores, \"cache\": cache}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transformer_prepare_decoder(targets, hparams, features=None):\n  if hparams.causal_decoder_self_attention:\n    # Causal attention.\n    if hparams.prepend_mode == \"prepend_inputs_full_attention\":\n      decoder_self_attention_bias = (\n          common_attention.attention_bias_prepend_inputs_full_attention(\n              common_attention.embedding_to_padding(targets)))\n    else:\n      decoder_self_attention_bias = (\n          common_attention.attention_bias_lower_triangle(\n              common_layers.shape_list(targets)[1]))\n  else:\n    # Full attention.\n    decoder_padding = common_attention.embedding_to_padding(targets)\n    decoder_self_attention_bias = (\n        common_attention.attention_bias_ignore_padding(decoder_padding))\n\n  if features and \"targets_segmentation\" in features:\n    # \"Packed\" dataset - keep the examples from seeing each other.\n    targets_segmentation = features[\"targets_segmentation\"]\n    targets_position = features[\"targets_position\"]\n    decoder_self_attention_bias += common_attention.attention_bias_same_segment(\n        targets_segmentation, targets_segmentation)\n  else:\n    targets_position = None\n  if hparams.proximity_bias:\n    decoder_self_attention_bias += common_attention.attention_bias_proximal(\n        common_layers.shape_list(targets)[1])\n  decoder_input = common_layers.shift_right_3d(targets)\n  if hparams.pos == \"timing\":\n    if targets_position is not None:\n      decoder_input = common_attention.add_timing_signal_1d_given_position(\n          decoder_input, targets_position)\n    else:\n      decoder_input = common_attention.add_timing_signal_1d(decoder_input)\n  elif hparams.pos == \"emb\":\n    decoder_input = common_attention.add_positional_embedding(\n        decoder_input, hparams.max_length, \"targets_positional_embedding\",\n        targets_position)\n\n  if hparams.activation_dtype == \"bfloat16\":\n    decoder_self_attention_bias = tf.cast(decoder_self_attention_bias,\n                                          tf.bfloat16)\n  return (decoder_input, decoder_self_attention_bias)", "response": "Prepare one shard of the model for the decoder."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transformer_decoder(decoder_input,\n                        encoder_output,\n                        decoder_self_attention_bias,\n                        encoder_decoder_attention_bias,\n                        hparams,\n                        cache=None,\n                        decode_loop_step=None,\n                        name=\"decoder\",\n                        nonpadding=None,\n                        save_weights_to=None,\n                        make_image_summary=True,\n                        losses=None,\n                        layer_collection=None,\n                        recurrent_memory_by_layer=None,\n                        chunk_number=None,\n                        ):\n  \"\"\"A stack of transformer layers.\n\n  Args:\n    decoder_input: a Tensor\n    encoder_output: a Tensor\n    decoder_self_attention_bias: bias Tensor for self-attention (see\n      common_attention.attention_bias())\n    encoder_decoder_attention_bias: bias Tensor for encoder-decoder attention\n      (see common_attention.attention_bias())\n    hparams: hyperparameters for model\n    cache: dict, containing tensors which are the results of previous\n      attentions, used for fast decoding.\n    decode_loop_step: An integer, step number of the decoding loop. Only used\n      for inference on TPU.\n    name: a string\n    nonpadding: optional Tensor with shape [batch_size, encoder_length]\n      indicating what positions are not padding.  This is used to mask out\n      padding in convolutional layers.  We generally only need this mask for\n      \"packed\" datasets, because for ordinary datasets, no padding is ever\n      followed by nonpadding.\n    save_weights_to: an optional dictionary to capture attention weights for\n      visualization; the weights tensor will be appended there under a string\n      key created from the variable scope (including name).\n    make_image_summary: Whether to make an attention image summary.\n    losses: optional list onto which to append extra training losses\n    layer_collection: A tensorflow_kfac.LayerCollection. Only used by the\n      KFAC optimizer. Default is None.\n    recurrent_memory_by_layer: Optional dict, mapping layer names to instances\n      of transformer_memory.RecurrentMemory. Default is None.\n    chunk_number: an optional integer Tensor with shape [batch] used to operate\n      the recurrent_memory.\n\n  Returns:\n    y: a Tensors\n  \"\"\"\n  x = decoder_input\n  attention_dropout_broadcast_dims = (\n      common_layers.comma_separated_string_to_integer_list(\n          getattr(hparams, \"attention_dropout_broadcast_dims\", \"\")))\n\n  mlperf_log.transformer_print(\n      key=mlperf_log.MODEL_HP_NUM_HIDDEN_LAYERS,\n      value=hparams.num_decoder_layers or hparams.num_hidden_layers,\n      hparams=hparams)\n  mlperf_log.transformer_print(\n      key=mlperf_log.MODEL_HP_ATTENTION_DROPOUT,\n      value=hparams.attention_dropout,\n      hparams=hparams)\n  mlperf_log.transformer_print(\n      key=mlperf_log.MODEL_HP_ATTENTION_DENSE,\n      value={\n          \"use_bias\": \"false\",\n          \"num_heads\": hparams.num_heads,\n          \"hidden_size\": hparams.hidden_size\n      },\n      hparams=hparams)\n\n  with tf.variable_scope(name):\n    for layer in range(hparams.num_decoder_layers or hparams.num_hidden_layers):\n      layer_name = \"layer_%d\" % layer\n      layer_cache = cache[layer_name] if cache is not None else None\n      if recurrent_memory_by_layer is not None:\n        recurrent_memory = recurrent_memory_by_layer[layer_name]\n      else:\n        recurrent_memory = None\n\n      if layer < hparams.get(\"num_area_layers\", 0):\n        max_area_width = hparams.get(\"max_area_width\", 1)\n        max_area_height = hparams.get(\"max_area_height\", 1)\n        memory_height = hparams.get(\"max_area_height\", 1)\n      else:\n        max_area_width = 1\n        max_area_height = 1\n        memory_height = 1\n      with tf.variable_scope(layer_name):\n        with tf.variable_scope(\"self_attention\"):\n          y = common_attention.multihead_attention(\n              common_layers.layer_preprocess(\n                  x, hparams, layer_collection=layer_collection),\n              None,\n              decoder_self_attention_bias,\n              hparams.attention_key_channels or hparams.hidden_size,\n              hparams.attention_value_channels or hparams.hidden_size,\n              hparams.hidden_size,\n              hparams.num_heads,\n              hparams.attention_dropout,\n              attention_type=hparams.self_attention_type,\n              max_relative_position=hparams.max_relative_position,\n              heads_share_relative_embedding=(\n                  hparams.heads_share_relative_embedding),\n              add_relative_to_values=hparams.add_relative_to_values,\n              save_weights_to=save_weights_to,\n              cache=layer_cache,\n              make_image_summary=make_image_summary,\n              dropout_broadcast_dims=attention_dropout_broadcast_dims,\n              max_length=hparams.get(\"max_length\"),\n              decode_loop_step=decode_loop_step,\n              vars_3d=hparams.get(\"attention_variables_3d\"),\n              activation_dtype=hparams.get(\"activation_dtype\", \"float32\"),\n              weight_dtype=hparams.get(\"weight_dtype\", \"float32\"),\n              layer_collection=layer_collection,\n              recurrent_memory=recurrent_memory,\n              chunk_number=chunk_number,\n              hard_attention_k=hparams.get(\"hard_attention_k\", 0),\n              max_area_width=max_area_width,\n              max_area_height=max_area_height,\n              memory_height=memory_height,\n              area_key_mode=hparams.get(\"area_key_mode\", \"none\"),\n              area_value_mode=hparams.get(\"area_value_mode\", \"none\"),\n              training=(hparams.get(\"mode\", tf.estimator.ModeKeys.TRAIN)\n                        == tf.estimator.ModeKeys.TRAIN))\n          x = common_layers.layer_postprocess(x, y, hparams)\n        if encoder_output is not None:\n          with tf.variable_scope(\"encdec_attention\"):\n            y = common_attention.multihead_attention(\n                common_layers.layer_preprocess(\n                    x, hparams, layer_collection=layer_collection),\n                encoder_output,\n                encoder_decoder_attention_bias,\n                hparams.attention_key_channels or hparams.hidden_size,\n                hparams.attention_value_channels or hparams.hidden_size,\n                hparams.hidden_size,\n                hparams.num_heads,\n                hparams.attention_dropout,\n                max_relative_position=hparams.max_relative_position,\n                heads_share_relative_embedding=(\n                    hparams.heads_share_relative_embedding),\n                add_relative_to_values=hparams.add_relative_to_values,\n                save_weights_to=save_weights_to,\n                cache=layer_cache,\n                make_image_summary=make_image_summary,\n                dropout_broadcast_dims=attention_dropout_broadcast_dims,\n                max_length=hparams.get(\"max_length\"),\n                vars_3d=hparams.get(\"attention_variables_3d\"),\n                activation_dtype=hparams.get(\"activation_dtype\", \"float32\"),\n                weight_dtype=hparams.get(\"weight_dtype\", \"float32\"),\n                layer_collection=layer_collection,\n                hard_attention_k=hparams.get(\"hard_attention_k\", 0),\n                max_area_width=max_area_width,\n                max_area_height=max_area_height,\n                memory_height=memory_height,\n                area_key_mode=hparams.get(\"area_key_mode\", \"none\"),\n                area_value_mode=hparams.get(\"area_value_mode\", \"none\"),\n                training=(hparams.get(\"mode\", tf.estimator.ModeKeys.TRAIN)\n                          == tf.estimator.ModeKeys.TRAIN))\n            x = common_layers.layer_postprocess(x, y, hparams)\n        with tf.variable_scope(\"ffn\"):\n          y = transformer_ffn_layer(\n              common_layers.layer_preprocess(\n                  x, hparams, layer_collection=layer_collection),\n              hparams,\n              conv_padding=\"LEFT\",\n              nonpadding_mask=nonpadding,\n              losses=losses,\n              cache=layer_cache,\n              decode_loop_step=decode_loop_step,\n              layer_collection=layer_collection)\n          x = common_layers.layer_postprocess(x, y, hparams)\n    # if normalization is done in layer_preprocess, then it should also be done\n    # on the output, since the output can grow very large, being the sum of\n    # a whole stack of unnormalized layer outputs.\n    mlperf_log.transformer_print(\n        key=mlperf_log.MODEL_HP_NORM,\n        value={\"hidden_size\": hparams.hidden_size})\n    return common_layers.layer_preprocess(\n        x, hparams, layer_collection=layer_collection)", "response": "A function to create a stack of transformer layers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transformer_base_v1():\n  hparams = common_hparams.basic_params1()\n  hparams.norm_type = \"layer\"\n  hparams.hidden_size = 512\n  hparams.batch_size = 4096\n  hparams.max_length = 256\n  hparams.clip_grad_norm = 0.  # i.e. no gradient clipping\n  hparams.optimizer_adam_epsilon = 1e-9\n  hparams.learning_rate_schedule = \"legacy\"\n  hparams.learning_rate_decay_scheme = \"noam\"\n  hparams.learning_rate = 0.1\n  hparams.learning_rate_warmup_steps = 4000\n  hparams.initializer_gain = 1.0\n  hparams.num_hidden_layers = 6\n  hparams.initializer = \"uniform_unit_scaling\"\n  hparams.weight_decay = 0.0\n  hparams.optimizer_adam_beta1 = 0.9\n  hparams.optimizer_adam_beta2 = 0.98\n  hparams.num_sampled_classes = 0\n  hparams.label_smoothing = 0.1\n  hparams.shared_embedding_and_softmax_weights = True\n  hparams.symbol_modality_num_shards = 16\n\n  # Add new ones like this.\n  hparams.add_hparam(\"filter_size\", 2048)\n  # Layer-related flags. If zero, these fall back on hparams.num_hidden_layers.\n  hparams.add_hparam(\"num_encoder_layers\", 0)\n  hparams.add_hparam(\"num_decoder_layers\", 0)\n  # Attention-related flags.\n  hparams.add_hparam(\"num_heads\", 8)\n  hparams.add_hparam(\"attention_key_channels\", 0)\n  hparams.add_hparam(\"attention_value_channels\", 0)\n  hparams.add_hparam(\"ffn_layer\", \"dense_relu_dense\")\n  hparams.add_hparam(\"parameter_attention_key_channels\", 0)\n  hparams.add_hparam(\"parameter_attention_value_channels\", 0)\n  # All hyperparameters ending in \"dropout\" are automatically set to 0.0\n  # when not in training mode.\n  hparams.add_hparam(\"attention_dropout\", 0.0)\n  hparams.add_hparam(\"attention_dropout_broadcast_dims\", \"\")\n  hparams.add_hparam(\"relu_dropout\", 0.0)\n  hparams.add_hparam(\"relu_dropout_broadcast_dims\", \"\")\n  hparams.add_hparam(\"pos\", \"timing\")  # timing, none\n  hparams.add_hparam(\"nbr_decoder_problems\", 1)\n  hparams.add_hparam(\"proximity_bias\", False)\n  hparams.add_hparam(\"causal_decoder_self_attention\", True)\n  hparams.add_hparam(\"use_pad_remover\", True)\n  hparams.add_hparam(\"self_attention_type\", \"dot_product\")\n  hparams.add_hparam(\"conv_first_kernel\", 3)\n  hparams.add_hparam(\"attention_variables_3d\", False)\n  hparams.add_hparam(\"use_target_space_embedding\", True)\n  # These parameters are only used when ffn_layer==\"local_moe_tpu\"\n  hparams.add_hparam(\"moe_overhead_train\", 1.0)\n  hparams.add_hparam(\"moe_overhead_eval\", 2.0)\n  hparams.moe_num_experts = 16\n  hparams.moe_loss_coef = 1e-3\n  # If specified, use this value instead of problem name in metrics.py.\n  # This is useful for programs that can automatically compare experiments side\n  #   by side based on the same metric names.\n  hparams.add_hparam(\"overload_eval_metric_name\", \"\")\n  # For making a transformer encoder unidirectional by using masked\n  # attention.\n  hparams.add_hparam(\"unidirectional_encoder\", False)\n  # For hard attention.\n  hparams.add_hparam(\"hard_attention_k\", 0)\n  return hparams", "response": "Hparams for training base_v1."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transformer_base_vq_ada_32ex_packed():\n  hparams = transformer_base_v2()\n  expert_utils.update_hparams_for_vq_gating(hparams)\n  hparams.moe_num_experts = 32\n  hparams.gating_type = \"vq\"\n  # this gives us a batch size of 16 because each seq is len 256\n  hparams.batch_size = 5072\n  hparams.ffn_layer = \"local_moe\"\n  hparams.shared_embedding_and_softmax_weights = False\n  hparams.learning_rate_warmup_steps = 10000\n  # one epoch for languagemodel_lm1b32k_packed = 27200 steps w/ bsize 128\n  hparams.learning_rate_decay_steps = 27200\n  hparams.num_heads = 4\n  hparams.num_blocks = 1\n  hparams.moe_k = 1\n  hparams.num_decoder_layers = 6\n  hparams.label_smoothing = 0.\n  hparams.layer_prepostprocess_dropout = 0.1\n  hparams.layer_postprocess_sequence = \"dan\"\n  hparams.layer_preprocess_sequence = \"none\"\n  hparams.weight_decay = 1e-06\n  hparams.attention_dropout = 0.1\n  hparams.optimizer = \"Adafactor\"\n  hparams.learning_rate_schedule = \"linear_warmup*rsqrt_decay*linear_decay\"\n  hparams.activation_dtype = \"float32\"\n  hparams.learning_rate = 0.1\n  hparams.learning_rate_constant = 1.0\n  return hparams", "response": "Set of hyperparameters for lm1b packed following tpu params."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transformer_base_v3():\n  # Update parameters here, then occasionally cut a versioned set, e.g.\n  # transformer_base_v2.\n  hparams = transformer_base_v2()\n  hparams.optimizer_adam_beta2 = 0.997\n  # New way of specifying learning rate schedule.\n  # Equivalent to previous version.\n  hparams.learning_rate_schedule = (\n      \"constant*linear_warmup*rsqrt_decay*rsqrt_hidden_size\")\n  hparams.learning_rate_constant = 2.0\n  return hparams", "response": "Base parameters for Transformer model."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nties means fine - tune CNN or DM summarization as LM.", "response": "def transformer_tall_finetune_tied():\n  \"\"\"Tied means fine-tune CNN/DM summarization as LM.\"\"\"\n  hparams = transformer_tall()\n  hparams.multiproblem_max_input_length = 750\n  hparams.multiproblem_max_target_length = 100\n  hparams.multiproblem_schedule_max_examples = 0\n  hparams.learning_rate_schedule = (\"linear_warmup*constant*cosdecay\")\n  hparams.learning_rate_constant = 5e-5\n  hparams.learning_rate_warmup_steps = 100\n  # Set train steps to learning_rate_decay_steps or less\n  hparams.learning_rate_decay_steps = 80000\n  hparams.multiproblem_target_eval_only = True\n  hparams.multiproblem_reweight_label_loss = True\n  hparams.multiproblem_label_weight = 1.0\n  hparams.optimizer = \"true_adam\"\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transformer_tall_finetune_uniencdec():\n  hparams = transformer_tall()\n  hparams.max_input_seq_length = 750\n  hparams.max_target_seq_length = 100\n  hparams.optimizer = \"true_adam\"\n  hparams.learning_rate_schedule = (\"linear_warmup*constant*cosdecay\")\n  hparams.learning_rate_decay_steps = 80000\n  hparams.learning_rate_constant = 5e-5\n  hparams.learning_rate_warmup_steps = 100\n  hparams.unidirectional_encoder = True\n  return hparams", "response": "Fine - tune CNN / DM with a unidirectional encoder and decoder."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transformer_tall_train_uniencdec():\n  hparams = transformer_tall()\n  hparams.max_input_seq_length = 750\n  hparams.max_target_seq_length = 100\n  hparams.optimizer = \"true_adam\"\n  hparams.learning_rate_schedule = (\"linear_warmup*constant*cosdecay\")\n  hparams.learning_rate_decay_steps = 150000\n  hparams.learning_rate_constant = 2e-4\n  hparams.unidirectional_encoder = True\n  return hparams", "response": "Train CNN and DM with a unidirectional encoder and decoder."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transformer_tall_pretrain_lm_tpu_adafactor():\n  hparams = transformer_tall_pretrain_lm()\n  update_hparams_for_tpu(hparams)\n  hparams.max_length = 1024\n  # For multi-problem on TPU we need it in absolute examples.\n  hparams.batch_size = 8\n  hparams.multiproblem_vocab_size = 2**16\n  return hparams", "response": "Hparams for transformer on LM pretraining on TPU."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nuse relative position embeddings instead of absolute position encodings.", "response": "def transformer_relative():\n  \"\"\"Use relative position embeddings instead of absolute position encodings.\"\"\"\n  hparams = transformer_base()\n  hparams.pos = None\n  hparams.self_attention_type = \"dot_product_relative\"\n  hparams.max_relative_position = 20\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_hparams_for_tpu(hparams):\n\n  # Adafactor uses less memory than Adam.\n  # switch to Adafactor with its recommended learning rate scheme.\n  hparams.optimizer = \"Adafactor\"\n  hparams.learning_rate_schedule = \"rsqrt_decay\"\n  hparams.learning_rate_warmup_steps = 10000\n\n  # Avoid an expensive concat on TPU.\n  # >1 shards helps with faster parameter distribution on multi-GPU machines\n  hparams.symbol_modality_num_shards = 1\n\n  # Adaptive batch sizes and sequence lengths are not supported on TPU.\n  # Instead, every batch has the same sequence length and the same batch size.\n  # Longer sequences are dropped and shorter ones are padded.\n  #\n  # It is therefore suggested to use a problem where examples have been combined\n  # to a longer length, e.g. the \"_packed\" problems.\n  #\n  # For problems with variable sequence lengths, this parameter controls the\n  # maximum sequence length.  Shorter sequences are dropped and longer ones\n  # are padded.\n  #\n  # For problems with fixed sequence lengths - e.g. the \"_packed\" problems,\n  # this hyperparameter is ignored.\n  hparams.max_length = 64\n\n  # TPUs have less memory than GPUs, so decrease the batch size\n  hparams.batch_size = 2048\n\n  # Using noise broadcast in the dropout layers saves memory during training.\n  hparams.attention_dropout_broadcast_dims = \"0,1\"  # batch, heads\n  hparams.relu_dropout_broadcast_dims = \"1\"  # length\n  hparams.layer_prepostprocess_dropout_broadcast_dims = \"1\"  # length\n  return hparams", "response": "Change hparams to be compatible with TPU training."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transformer_tpu_range(rhp):\n  # After starting from base, set intervals for some parameters.\n  rhp.set_float(\"learning_rate\", 0.3, 3.0, scale=rhp.LOG_SCALE)\n  rhp.set_discrete(\"learning_rate_warmup_steps\",\n                   [1000, 2000, 4000, 8000, 16000])\n  rhp.set_float(\"initializer_gain\", 0.5, 2.0)\n  rhp.set_float(\"optimizer_adam_beta1\", 0.85, 0.95)\n  rhp.set_float(\"optimizer_adam_beta2\", 0.97, 0.99)\n  rhp.set_float(\"weight_decay\", 0.0, 2.0)", "response": "Small range of hyperparameters for TPU."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef transformer_clean():\n  hparams = transformer_base_v2()\n  hparams.label_smoothing = 0.0\n  hparams.layer_prepostprocess_dropout = 0.0\n  hparams.attention_dropout = 0.0\n  hparams.relu_dropout = 0.0\n  hparams.max_length = 0\n  return hparams", "response": "No dropout label smoothing max_length."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transformer_lm_tpu_0():\n  hparams = transformer_clean_big()\n  update_hparams_for_tpu(hparams)\n  hparams.num_heads = 4  # Heads are expensive on TPUs.\n  hparams.batch_size = 4096\n  hparams.shared_embedding_and_softmax_weights = False\n  hparams.layer_prepostprocess_dropout = 0.1\n  return hparams", "response": "HParams for training languagemodel_lm1b8k on tpu. 92M Params."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transformer_librispeech_v1():\n  hparams = transformer_base()\n\n  hparams.num_heads = 4\n  hparams.filter_size = 1024\n  hparams.hidden_size = 256\n  hparams.num_encoder_layers = 5\n  hparams.num_decoder_layers = 3\n  hparams.learning_rate = 0.15\n  hparams.batch_size = 6000000\n\n  librispeech.set_librispeech_length_hparams(hparams)\n  return hparams", "response": "HParams for training ASR model on LibriSpeech V1."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transformer_librispeech_tpu_v1():\n  hparams = transformer_librispeech_v1()\n  update_hparams_for_tpu(hparams)\n\n  hparams.batch_size = 16\n  librispeech.set_librispeech_length_hparams(hparams)\n  return hparams", "response": "HParams for training ASR model on Librispeech on TPU v1."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transformer_librispeech_tpu_v2():\n  hparams = transformer_librispeech_v2()\n  update_hparams_for_tpu(hparams)\n\n  hparams.batch_size = 16\n  librispeech.set_librispeech_length_hparams(hparams)\n  return hparams", "response": "HParams for training ASR model on Librispeech on TPU v2."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transformer_tpu_1b():\n  hparams = transformer_tpu()\n  hparams.hidden_size = 2048\n  hparams.filter_size = 8192\n  hparams.num_hidden_layers = 8\n  # smaller batch size to avoid OOM\n  hparams.batch_size = 1024\n  hparams.activation_dtype = \"bfloat16\"\n  hparams.weight_dtype = \"bfloat16\"\n  # maximize number of parameters relative to computation by not sharing.\n  hparams.shared_embedding_and_softmax_weights = False\n  return hparams", "response": "Hparams for machine translation with ~1. 1B parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transformer_wikitext103_l16k_memory_v0():\n  hparams = transformer_wikitext103_l4k_memory_v0()\n\n  hparams.max_length = 16384\n  hparams.split_targets_chunk_length = 64\n  hparams.split_targets_max_chunks = int(\n      hparams.max_length / hparams.split_targets_chunk_length)\n\n  # The hparams specify batch size *before* chunking, but we want to have a\n  # consistent 4K batch size *after* chunking to fully utilize the hardware.\n  target_tokens_per_batch = 4096\n  hparams.batch_size = int(target_tokens_per_batch * (\n      hparams.max_length / hparams.split_targets_chunk_length))\n\n  hparams.max_relative_position = 2 * hparams.split_targets_chunk_length\n\n  return hparams", "response": "HParams for training languagemodel_wikitext103_l16k with memory."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transformer_cifar10_memory_v0():\n  hparams = transformer_wikitext103_l4k_memory_v0()\n\n  hparams.num_hidden_layers = 6\n\n  hparams.max_length = 32 * 32 * 3\n  hparams.split_targets_chunk_length = 64 * 3\n  hparams.split_targets_max_chunks = int(\n      hparams.max_length / hparams.split_targets_chunk_length)\n  hparams.num_memory_items = 128 * 3\n\n  # Since this is an image problem, batch size refers to examples (not tokens)\n  target_images_per_batch = 4\n  hparams.batch_size = int(target_images_per_batch * (\n      hparams.max_length / hparams.split_targets_chunk_length))\n\n  # The recurrent memory needs to know the actual batch size (in sequences)\n  hparams.recurrent_memory_batch_size = hparams.batch_size\n\n  hparams.max_relative_position = (\n      hparams.num_memory_items + hparams.split_targets_chunk_length)\n\n  return hparams", "response": "HParams for training image_cifar10_plain_gen_flat_rev with memory."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndilating attention with a masking strategy.", "response": "def get_dilated_1d_attention_mask(\n    num_heads, block_size,\n    num_blocks, memory_size, gap_size,\n    name=\"dilated_mask\"):\n  \"\"\"Dilated attention with a masking strategy.\"\"\"\n  mask = np.ones((num_heads, block_size, 2*block_size), np.bool)\n\n  # now going over every row to do the right assignment of\n  # memory blocks\n  for i in range(block_size):\n    visible = 2*block_size  - (block_size-i)\n    # You always attend to yourself, set the mask for that\n    mask[:, i, -(block_size - i)] = 0\n    # Maybe num_blocks can be automatically calculated?\n    for j in range(num_blocks):\n      for k in range(memory_size):\n        index = ((gap_size + memory_size)*j) + k\n        if index >= visible:\n          break\n        mask[:, i, -(index + block_size - i + 1)] = 0  # Verify\n\n  # adding a num blocks dimension\n  mask = np.expand_dims(mask, axis=1)\n  return tf.constant(mask, dtype=tf.int32, name=name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndilate 1d self - attention.", "response": "def dilated_attention_1d(x,\n                         hparams,\n                         attention_type=\"masked_dilated_1d\",\n                         q_padding=\"VALID\",\n                         kv_padding=\"VALID\",\n                         gap_size=2):\n  \"\"\"Dilated 1d self attention.\"\"\"\n  # self-attention\n  x, x_shape, is_4d = maybe_reshape_4d_to_3d(x)\n  with tf.variable_scope(\"masked_dilated_1d\"):\n    y = common_attention.multihead_attention(\n        x,\n        None,\n        None,\n        hparams.attention_key_channels or hparams.hidden_size,\n        hparams.attention_value_channels or hparams.hidden_size,\n        hparams.hidden_size,\n        hparams.num_heads,\n        hparams.attention_dropout,\n        attention_type=attention_type,\n        block_width=hparams.block_width,\n        block_length=hparams.block_length,\n        q_padding=q_padding,\n        kv_padding=kv_padding,\n        q_filter_width=hparams.q_filter_width,\n        kv_filter_width=hparams.kv_filter_width,\n        gap_size=gap_size,\n        num_memory_blocks=hparams.num_memory_blocks,\n        name=\"self_attention\")\n    if is_4d:\n      y = tf.reshape(y, x_shape)\n      y.set_shape([None, None, None, hparams.hidden_size])\n    return y"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef local_global_attention(x,\n                           self_attention_bias,\n                           hparams,\n                           q_padding=\"LEFT\",\n                           kv_padding=\"LEFT\"):\n  \"\"\"Local and global 1d self attention.\"\"\"\n  with tf.variable_scope(\"self_local_global_att\"):\n    [x_global, x_local] = tf.split(x, 2, axis=-1)\n    split_hidden_size = int(hparams.hidden_size / 2)\n    split_heads = int(hparams.num_heads / 2)\n    if self_attention_bias is not None:\n      self_attention_bias = get_self_attention_bias(x)\n    y_global = common_attention.multihead_attention(\n        x_global,\n        None,\n        self_attention_bias,\n        hparams.attention_key_channels or split_hidden_size,\n        hparams.attention_value_channels or split_hidden_size,\n        split_hidden_size,\n        split_heads,\n        hparams.attention_dropout,\n        q_filter_width=hparams.q_filter_width,\n        kv_filter_width=hparams.kv_filter_width,\n        q_padding=q_padding,\n        kv_padding=kv_padding,\n        name=\"global_self_att\")\n    y_local = common_attention.multihead_attention(\n        x_local,\n        None,\n        None,\n        hparams.attention_key_channels or split_hidden_size,\n        hparams.attention_value_channels or split_hidden_size,\n        split_hidden_size,\n        split_heads,\n        hparams.attention_dropout,\n        attention_type=\"local_masked\",\n        block_length=hparams.block_length,\n        block_width=hparams.block_width,\n        q_filter_width=hparams.q_filter_width,\n        kv_filter_width=hparams.kv_filter_width,\n        q_padding=q_padding,\n        kv_padding=kv_padding,\n        name=\"local_self_att\")\n    y = tf.concat([y_global, y_local], axis=-1)\n    return y", "response": "Local 1d self attention."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfull self - attention layer.", "response": "def full_self_attention(x,\n                        self_attention_bias,\n                        hparams,\n                        q_padding=\"LEFT\",\n                        kv_padding=\"LEFT\"):\n  \"\"\"Full self-attention layer.\"\"\"\n  x, x_shape, is_4d = maybe_reshape_4d_to_3d(x)\n  if self_attention_bias is not None:\n    self_attention_bias = get_self_attention_bias(x)\n  with tf.variable_scope(\"self_att\"):\n    y = common_attention.multihead_attention(\n        x,\n        None,\n        self_attention_bias,\n        hparams.attention_key_channels or hparams.hidden_size,\n        hparams.attention_value_channels or hparams.hidden_size,\n        hparams.hidden_size,\n        hparams.num_heads,\n        hparams.attention_dropout,\n        q_filter_width=hparams.q_filter_width,\n        kv_filter_width=hparams.kv_filter_width,\n        q_padding=q_padding,\n        kv_padding=kv_padding,\n        name=\"self_att\")\n    if is_4d:\n      y = tf.reshape(y, [x_shape[0], x_shape[1], x_shape[2], x_shape[3]])\n      y.set_shape([None, None, None, hparams.hidden_size])\n    return y"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef encdec_attention_1d(x,\n                        encoder_output,\n                        encoder_decoder_attention_bias,\n                        hparams):\n  \"\"\"Local 1d self attention.\"\"\"\n  x, x_shape, is_4d = maybe_reshape_4d_to_3d(x)\n  encoder_output, _, _ = maybe_reshape_4d_to_3d(encoder_output)\n  with tf.variable_scope(\"encdec_attention\"):\n    # Encoder Decoder attention\n    y = common_attention.multihead_attention(\n        x,\n        encoder_output,\n        encoder_decoder_attention_bias,\n        hparams.attention_key_channels or hparams.hidden_size,\n        hparams.attention_value_channels or hparams.hidden_size,\n        hparams.hidden_size,\n        hparams.num_heads,\n        hparams.attention_dropout,\n        name=\"encdec_attention\")\n  if is_4d:\n    y = tf.reshape(y, x_shape)\n    y.set_shape([None, None, None, hparams.hidden_size])\n  return y", "response": "Local 1d self attention."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_self_attention_bias(x):\n\n  x_shape = common_layers.shape_list(x)\n  self_attention_bias = common_attention.attention_bias_lower_triangle(\n      x_shape[1])\n  return self_attention_bias", "response": "Creates masked self attention bias."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprepares encoder for images.", "response": "def prepare_encoder(inputs, hparams, attention_type=\"local_1d\"):\n  \"\"\"Prepare encoder for images.\"\"\"\n  x = prepare_image(inputs, hparams, name=\"enc_channels\")\n  # Add position signals.\n  x = add_pos_signals(x, hparams, \"enc_pos\")\n  x_shape = common_layers.shape_list(x)\n  if attention_type == \"local_1d\":\n    x = tf.reshape(x, [x_shape[0], x_shape[1]*x_shape[2], hparams.hidden_size])\n    x.set_shape([None, None, hparams.hidden_size])\n  elif attention_type == \"local_2d\":\n    x.set_shape([None, None, None, hparams.hidden_size])\n  return x"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npreparing decoder for images.", "response": "def prepare_decoder(targets, hparams):\n  \"\"\"Prepare decoder for images.\"\"\"\n  targets_shape = common_layers.shape_list(targets)\n  channels = hparams.num_channels\n  curr_infer_length = None\n\n  # during training, images are [batch, IMG_LEN, IMG_LEN, 3].\n  # At inference, they are [batch, curr_infer_length, 1, 1]\n  if hparams.mode == tf.estimator.ModeKeys.PREDICT:\n    curr_infer_length = targets_shape[1]\n    if hparams.block_raster_scan:\n      assert hparams.img_len*channels % hparams.query_shape[1] == 0\n      assert hparams.img_len % hparams.query_shape[0] == 0\n      total_block_width = hparams.img_len*channels\n      # Decoding is in block raster scan order. We divide the image into\n      # hparams.query_shape blocks and then decode each block in raster scan.\n      # To make that compatible with our inference pipeline, pad the target so\n      # that rows is a multiple of query_shape and columns is a multiple of\n      # hparams.img_len*channels\n      curr_infer_length = targets_shape[1]\n      block_padding_factor = total_block_width * hparams.query_shape[0]\n      targets = tf.pad(targets, [\n          [0, 0], [0, -curr_infer_length % block_padding_factor],\n          [0, 0], [0, 0]])\n\n      num_blocks = total_block_width // hparams.query_shape[1]\n      # Reshape the image to represent blocks\n      target_blocks = tf.reshape(\n          targets, [targets_shape[0], -1, num_blocks, hparams.query_shape[0],\n                    hparams.query_shape[1]])\n      # Transpose to read the image in 2D fashion.\n      targets = tf.transpose(target_blocks, [0, 1, 3, 2, 4])\n    else:\n      # add padding to make sure the size of targets is a multiple of img_height\n      # times number of channels. This is  needed for positional encodings and\n      # for doing the RGB lookup.\n      padding_factor = channels * hparams.img_len\n      targets = tf.pad(targets, [\n          [0, 0], [0, -curr_infer_length % padding_factor], [0, 0], [0, 0]])\n    targets = tf.reshape(targets,\n                         [targets_shape[0], -1, hparams.img_len, channels])\n  # Preprocess image\n  x = prepare_image(targets, hparams, name=\"dec_channels\")\n  x_shape = common_layers.shape_list(x)\n  if (hparams.dec_attention_type == AttentionType.LOCAL_2D or\n      hparams.dec_attention_type == AttentionType.LOCAL_BLOCK):\n    x = common_attention.right_shift_blockwise(x, hparams.query_shape)\n    x = add_pos_signals(x, hparams, \"dec_pos\")\n  else:\n    # Add position signals\n    x = tf.reshape(x, [targets_shape[0],\n                       x_shape[1]*x_shape[2], hparams.hidden_size])\n    x = common_layers.shift_right_3d(x)\n    x = tf.reshape(x, [targets_shape[0],\n                       x_shape[1], x_shape[2], hparams.hidden_size])\n    x = add_pos_signals(x, hparams, \"dec_pos\")\n  x = common_layers.cast_like(x, targets)\n  return x, x_shape[1], x_shape[2]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate output from decoder output and vars.", "response": "def create_output(decoder_output, rows, cols, targets, hparams):\n  \"\"\"Creates output from decoder output and vars.\n\n  Args:\n    decoder_output: Tensor of shape [batch, ...], where ... can be any rank such\n      that the number of elements is batch * rows * cols * hparams.hidden_size.\n    rows: Integer representing number of rows in a 2-D data point.\n    cols: Integer representing number of columns in a 2-D data point.\n    targets: Tensor of shape [batch, hparams.img_len, hparams.img_len,\n      hparams.num_channels].\n    hparams: HParams set.\n\n  Returns:\n    Tensor of shape [batch, hparams.img_len, hparams.img_len,\n    hparams.num_mixtures * 10] if hparams.likelihood is DMOL, otherwise\n    [batch, hparams.img_len, hparams.img_len, hparams.num_channels, 256].\n    In the special case of predict mode, it is a Tensor of rank 5.\n  \"\"\"\n  del targets  # unused arg\n  decoded_image = postprocess_image(decoder_output, rows, cols, hparams)\n  batch = common_layers.shape_list(decoded_image)[0]\n  depth = common_layers.shape_list(decoded_image)[-1]\n  likelihood = getattr(hparams, \"likelihood\", DistributionType.CAT)\n  if hparams.mode == tf.estimator.ModeKeys.PREDICT:\n    y = tf.reshape(decoded_image, [batch, -1, 1, 1, depth])\n    output = y[:, :rows, :, :, :]\n  elif likelihood == DistributionType.CAT:\n    # Unpack the cols dimension of the Categorical.\n    channels = hparams.num_channels\n    output = tf.reshape(decoded_image,\n                        [batch, rows, cols // channels, channels, depth])\n  else:\n    output = decoded_image\n  return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_channel_embeddings(io_depth, targets, hidden_size, name=\"channel\"):\n  targets_split = tf.split(targets, io_depth, axis=3)\n  rgb_embedding_var = tf.get_variable(\"rgb_target_emb_%s\" % name,\n                                      [256 * io_depth, hidden_size])\n  rgb_embedding_var = tf.identity(rgb_embedding_var)\n  rgb_embedding_var *= float(hidden_size)**0.5\n  channel_target_embs = []\n  for i in range(io_depth):\n    # Adding the channel offsets to get the right embedding since the\n    # embedding tensor has shape 256 * io_depth, hidden_size\n    target_ids = tf.squeeze(targets_split[i], axis=3) + i * 256\n    target_embs = common_layers.gather(rgb_embedding_var, target_ids)\n    channel_target_embs.append(target_embs)\n\n  return tf.concat(channel_target_embs, axis=-1)", "response": "Get the channel embedding for each of the channels."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef simulate(self, action):\n    with tf.name_scope(\"environment/simulate\"):\n      if action.dtype in (tf.float16, tf.float32, tf.float64):\n        action = tf.check_numerics(action, \"action\")\n      def step(action):\n        step_response = self._batch_env.step(action)\n        # Current env doesn't return `info`, but EnvProblem does.\n        # TODO(afrozm): The proper way to do this is to make T2TGymEnv return\n        # an empty info return value.\n        if len(step_response) == 3:\n          (observ, reward, done) = step_response\n        else:\n          (observ, reward, done, _) = step_response\n        return (observ, reward.astype(np.float32), done)\n      observ, reward, done = tf.py_func(\n          step, [action],\n          [self.observ_dtype, tf.float32, tf.bool], name=\"step\")\n      reward = tf.check_numerics(reward, \"reward\")\n      reward.set_shape((len(self),))\n      done.set_shape((len(self),))\n      with tf.control_dependencies([self._observ.assign(observ)]):\n        return tf.identity(reward), tf.identity(done)", "response": "Step the batch of environments.\n\n    The results of the step can be accessed from the variables defined below.\n\n    Args:\n      action: Tensor holding the batch of actions to apply.\n\n    Returns:\n      Operation."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreset the batch of environments to empty.", "response": "def _reset_non_empty(self, indices):\n    \"\"\"Reset the batch of environments.\n\n    Args:\n      indices: The batch indices of the environments to reset; defaults to all.\n\n    Returns:\n      Batch tensor of the new observations.\n    \"\"\"\n    observ = tf.py_func(\n        self._batch_env.reset, [indices], self.observ_dtype, name=\"reset\")\n    observ.set_shape(indices.get_shape().concatenate(self.observ_shape))\n    with tf.control_dependencies([\n        tf.scatter_update(self._observ, indices, observ)]):\n      return tf.identity(observ)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndecides whether to include a revision.", "response": "def include_revision(revision_num, skip_factor=1.1):\n  \"\"\"Decide whether to include a revision.\n\n  If the number of revisions is large, we exclude some revisions to avoid\n  a quadratic blowup in runtime, since the article is likely also large.\n\n  We make the ratio between consecutive included revision numbers\n  appproximately equal to \"factor\".\n\n  Args:\n    revision_num: an integer\n    skip_factor: a floating point number >= 1.0\n\n  Returns:\n    a boolean\n  \"\"\"\n  if skip_factor <= 1.0:\n    return True\n  return (int(math.log1p(revision_num) / math.log(skip_factor)) != int(\n      math.log(revision_num + 2.0) / math.log(skip_factor)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads wikipedia pages from a history dump. Since some pages can be terabytes in size (with all the revisions), we limit page size to max_page_size bytes. Args: my_file: an open file object. max_page_size: an integer Yields: strings", "response": "def file_page_generator(my_file, max_page_size=2**28):\n  \"\"\"Read wikipedia pages from a history dump.\n\n  Since some pages can be terabytes in size (with all the revisions),\n  we limit page size to max_page_size bytes.\n\n  Args:\n    my_file: an open file object.\n    max_page_size: an integer\n\n  Yields:\n    strings\n  \"\"\"\n  page_start = \"  <page>\\n\"\n  page_end = \"  </page>\\n\"\n  chunk_size = max_page_size\n  page_start = \"  <page>\\n\"\n  page_end = \"  </page>\\n\"\n  leftovers = \"\"\n  while True:\n    chunk = my_file.read(chunk_size)\n    if not chunk:\n      break\n    chunk = leftovers + chunk\n    current_pos = 0\n    while True:\n      start_pos = chunk.find(page_start, current_pos)\n      if start_pos == -1:\n        break\n      end_pos = chunk.find(page_end, start_pos)\n      if end_pos == -1:\n        if len(chunk) - start_pos > max_page_size:\n          leftovers = \"\"\n        else:\n          leftovers = chunk[start_pos:]\n        break\n      raw_page = chunk[start_pos + len(page_start):end_pos]\n      if len(raw_page) < max_page_size:\n        ret = parse_page(raw_page)\n        if ret:\n          yield ret\n      current_pos = end_pos + len(page_end)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_title(page):\n  start_pos = page.find(\"<title>\")\n  end_pos = page.find(\"</title>\")\n  assert start_pos != -1\n  assert end_pos != -1\n  start_pos += len(\"<title>\")\n  return text_encoder.to_unicode_utf8(page[start_pos:end_pos])", "response": "Extract the title from a page."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_id(page):\n  start_pos = page.find(\"<id>\")\n  end_pos = page.find(\"</id>\")\n  assert start_pos != -1\n  assert end_pos != -1\n  start_pos += len(\"<id>\")\n  return int(page[start_pos:end_pos])", "response": "Extract the id from a page.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_revisions(page):\n  start_string = \"    <revision>\\n\"\n  end_string = \"    </revision>\\n\"\n  ret = []\n  current_pos = 0\n  while True:\n    start_pos = page.find(start_string, current_pos)\n    if start_pos == -1:\n      break\n    end_pos = page.find(end_string, start_pos)\n    assert end_pos != -1\n    ret.append(page[start_pos + len(start_string):end_pos])\n    current_pos = end_pos + len(end_string)\n  return ret", "response": "Extract the revisions of a page."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a page into a dictionary with title id and list of revisions.", "response": "def parse_page(raw_page):\n  \"\"\"Create a dictionary with title, id, and list of revisions.\n\n  The dictionary contains:\n  \"title\": a string\n  \"id\": an integer\n  \"revisions\": a list of strings\n\n  Args:\n    raw_page: a string\n\n  Returns:\n    a dictionary, or None in the case of an error.\n  \"\"\"\n  ret = {\"title\": get_title(raw_page), \"id\": get_id(raw_page)}\n  if \":\" in ret[\"title\"]:\n    return None\n  ret[\"revisions\"] = get_revisions(raw_page)\n  return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef maybe_copy_file_to_directory(source_filepath, target_directory):\n  if not tf.gfile.Exists(target_directory):\n    tf.logging.info(\"Creating directory %s\" % target_directory)\n    os.mkdir(target_directory)\n  target_filepath = os.path.join(target_directory,\n                                 os.path.basename(source_filepath))\n  if not tf.gfile.Exists(target_filepath):\n    tf.logging.info(\"Copying %s to %s\" % (source_filepath, target_filepath))\n    tf.gfile.Copy(source_filepath, target_filepath)\n    statinfo = os.stat(target_filepath)\n    tf.logging.info(\"Successfully copied %s, %s bytes.\" % (target_filepath,\n                                                           statinfo.st_size))\n  else:\n    tf.logging.info(\"Not copying, file already found: %s\" % target_filepath)\n  return target_filepath", "response": "Copy a file to a directory if it is not already there."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating pages from a list of .7z encoded history dumps. Args: corpus_files: a list of strings tmp_dir: a string max_page_size_exp: an integer Yields: strings", "response": "def corpus_page_generator(corpus_files, tmp_dir, max_page_size_exp):\n  \"\"\"Generate pages from a list of .7z encoded history dumps.\n\n  Args:\n    corpus_files: a list of strings\n    tmp_dir: a string\n    max_page_size_exp: an integer\n\n  Yields:\n    strings\n  \"\"\"\n  for remote_filepath in corpus_files:\n\n    filepath = maybe_copy_file_to_directory(remote_filepath, tmp_dir)\n    tf.logging.info(\"Reading from \" + filepath)\n\n    command = [\"7z\", \"x\", \"-so\", filepath]\n    tf.logging.info(\"Running command: %s\", command)\n\n    p = subprocess.Popen(command, stdout=subprocess.PIPE, bufsize=-1)\n\n    for page in file_page_generator(p.stdout, 2**max_page_size_exp):\n      yield page"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts the text from a revision.", "response": "def get_text(revision, strip=True):\n  \"\"\"Extract the text from a revision.\n\n  Args:\n    revision: a string\n    strip: a boolean\n\n  Returns:\n    a string\n  \"\"\"\n  # text start tag looks like \"<text ..otherstuff>\"\n  start_pos = revision.find(\"<text\")\n  assert start_pos != -1\n  end_tag_pos = revision.find(\">\", start_pos)\n  assert end_tag_pos != -1\n  end_tag_pos += len(\">\")\n  end_pos = revision.find(\"</text>\")\n  if end_pos == -1:\n    ret = \"\"\n  else:\n    ret = revision[end_tag_pos:end_pos]\n  if strip:\n    ret = strip_text(ret)\n  ret = text_encoder.to_unicode_utf8(ret)\n  return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves all curly braces from a string.", "response": "def _remove_curly_braces(text):\n  \"\"\"Remove everything in curly braces.\n\n  Curly braces may be nested, so we keep track of depth.\n\n  Args:\n    text: a string\n  Returns:\n    a string\n  \"\"\"\n  current_pos = 0\n  depth = 0\n  ret = \"\"\n  for match in re.finditer(\"[{}]\", text):\n    if depth == 0:\n      ret += text[current_pos:match.start()]\n    depth += 1 if text[match.start()] == \"{\" else -1\n    current_pos = match.end()\n  if depth != 0:\n    # Many articles have mismatched braces, but it still seems better to remove\n    # them than not.\n    pass\n  else:\n    ret += text[current_pos:]\n  return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _remove_double_brackets(text):\n\n  def replacement_fn(s):\n    if \":\" in s:\n      # this is probably a category or something like that.\n      return \"\"\n    # keep the part after the bar.\n    bar_pos = s.find(\"|\")\n    if bar_pos == -1:\n      return s\n    return s[bar_pos + 1:]\n\n  return _find_and_replace(text, \"[[\", \"]]\", replacement_fn)", "response": "Remove double brackets but leave the viewable text."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _remove_boring_lines(text):\n  lines = text.split(\"\\n\")\n  filtered = [line for line in lines if re.match(\"[a-zA-z\\\"\\']\", line)]\n  return \"\\n\".join(filtered)", "response": "Remove lines that start with a letter or a quote."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget or generate the vocabulary.", "response": "def get_or_generate_vocabulary(data_dir,\n                               tmp_dir,\n                               data_prefix,\n                               max_page_size_exp,\n                               approx_vocab_size=32768,\n                               strip=True):\n  \"\"\"Get or generate the vocabulary.\n\n  Args:\n    data_dir: a string\n    tmp_dir: a string\n    data_prefix: a string\n    max_page_size_exp: an integer\n    approx_vocab_size: an integer\n    strip: a boolean\n\n  Returns:\n    a TextEncoder\n  \"\"\"\n  num_pages_for_vocab_generation = approx_vocab_size // 3\n  vocab_file = vocab_filename(approx_vocab_size, strip)\n\n  def my_generator(data_prefix):\n    \"\"\"Line generator for vocab.\"\"\"\n    count = 0\n    for page in corpus_page_generator(\n        all_corpus_files(data_prefix)[::-1], tmp_dir, max_page_size_exp):\n      revisions = page[\"revisions\"]\n      if revisions:\n        text = get_text(revisions[-1], strip=strip)\n        yield text\n        count += 1\n        if count % 100 == 0:\n          tf.logging.info(\"reading pages for vocab %d\" % count)\n        if count > num_pages_for_vocab_generation:\n          break\n\n  return generator_utils.get_or_generate_vocab_inner(data_dir, vocab_file,\n                                                     approx_vocab_size,\n                                                     my_generator(data_prefix))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget encoder from vocab file.", "response": "def get_encoder_from_vocab(vocab_filepath):\n  \"\"\"Get encoder from vocab file.\n\n  If vocab is not found in output dir, it will be copied there by\n  copy_vocab_to_output_dir to clarify the vocab used to generate the data.\n\n  Args:\n    vocab_filepath: path to vocab, either local or cns\n\n  Returns:\n    A SubwordTextEncoder vocabulary object. None if the output_parallel_text\n    is set.\n  \"\"\"\n  if not tf.gfile.Exists(vocab_filepath):\n    raise ValueError(\"Vocab file does not exist: {}.\".format(vocab_filepath))\n\n  tf.logging.info(\"Found vocab file: %s\", vocab_filepath)\n  encoder = text_encoder.SubwordTextEncoder(vocab_filepath)\n  return encoder"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef edit_distance_filter(source_target_input, max_equal_to_diff_ratio=0):\n  thrown_out_count = 0\n  source_target_output = []\n\n  if not max_equal_to_diff_ratio:\n    return source_target_input, thrown_out_count\n\n  for src_tgt in source_target_input:\n    opcodes = fast_match_sequences(*src_tgt)\n    diff_char_count = 0\n    equal_char_count = 0\n    for tag, i1, i2, j1, j2 in opcodes:\n      if tag == \"diff\":\n        # max() prevents double-counting substitutions.\n        diff_char_count += max(i2 - i1, j2 - j1)\n      else:\n        equal_char_count += i2 - i1\n    if diff_char_count <= max_equal_to_diff_ratio * equal_char_count:\n      source_target_output.append(src_tgt)\n    else:\n      thrown_out_count += 1\n  return source_target_output, thrown_out_count", "response": "Filter out examples that exceed max_edit_ratio between source and target."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute diffs between two sequences. This function is similar in functionality and spirit to difflib.SequenceMatcher.get_opcodes, but it seems to run faster. if a_start, a_end, b_start, b_end are specified, then we compute diffs of the segments a[a_start:a_end] and b[b_start:b_end]. Returned indices are relative to the full sequence. We try to match the longest matching segments first, but due to heuristics in finding the matches, this is not guaranteed. Matching segments shorter than min_match_length are counted as part of the surrounding differing segments, unless they are at the beginning or end of both sequences. This helps eliminate junk matches. Args: a: a sequence b: a sequence a_start: an optional integer a_end: an optional integer b_start: an optional integer b_end: an optional integer min_match_length: an integer max_recursion_depth: an integer - avoids crashes in weird corner cases involving pairs of long repetitive sequences. Returns: a list of 5-tuples (tag, i1, i2, j1, j2). Each tuple represents the alignment of segment a[i1:i2] with b[j1:j2]. tag is either \"equal\" or \"diff\". Note that the tags differ from those returned by difflib.SequenceMatcher.get_opcodes.", "response": "def fast_match_sequences(a,\n                         b,\n                         a_start=0,\n                         a_end=None,\n                         b_start=0,\n                         b_end=None,\n                         min_match_length=3,\n                         max_recursion_depth=128):\n  \"\"\"Compute diffs between two sequences.\n\n  This function is similar in functionality and spirit to\n  difflib.SequenceMatcher.get_opcodes, but it seems to run faster.\n\n  if a_start, a_end, b_start, b_end are specified, then we compute diffs of\n  the segments a[a_start:a_end] and b[b_start:b_end].  Returned indices\n  are relative to the full sequence.\n\n  We try to match the longest matching segments first, but due to heuristics\n  in finding the matches, this is not guaranteed.\n\n  Matching segments shorter than min_match_length are counted as part of the\n  surrounding differing segments, unless they are at the beginning or end of\n  both sequences.  This helps eliminate junk matches.\n\n  Args:\n    a: a sequence\n    b: a sequence\n    a_start: an optional integer\n    a_end: an optional integer\n    b_start: an optional integer\n    b_end: an optional integer\n    min_match_length: an integer\n    max_recursion_depth: an integer - avoids crashes in weird corner cases\n      involving pairs of long repetitive sequences.\n\n  Returns:\n    a list of 5-tuples (tag, i1, i2, j1, j2).\n    Each tuple represents the alignment of segment a[i1:i2] with b[j1:j2].\n      tag is either \"equal\" or \"diff\".  Note that the tags differ from those\n      returned by difflib.SequenceMatcher.get_opcodes.\n  \"\"\"\n  if a_end is None:\n    a_end = len(a)\n  if b_end is None:\n    b_end = len(b)\n  if a_start == a_end and b_start == b_end:\n    return []\n  if a_start == a_end or b_start == b_end:\n    return [(\"diff\", a_start, a_end, b_start, b_end)]\n  # Compute an index from value to first occurrence in the b segment.\n  # Technically, we should index and explore all occurrences of a value,\n  # but that might be much slower.\n  b_index = {}\n  for j in range(b_end - 1, b_start - 1, -1):\n    b_index[b[j]] = j\n  # we will look for the longest match we can find.\n  max_match_length = 0\n  a_pos = a_start\n  while a_pos < a_end:\n    val = a[a_pos]\n    b_pos = b_index.get(val)\n    if b_pos is None:\n      a_pos += 1\n      continue\n    else:\n      a_match_start = a_pos\n      a_match_end = a_pos + 1\n      b_match_start = b_pos\n      b_match_end = b_pos + 1\n      while (a_match_start > a_start and b_match_start > b_start and\n             a[a_match_start - 1] == b[b_match_start - 1]):\n        a_match_start -= 1\n        b_match_start -= 1\n      while (a_match_end < a_end and b_match_end < b_end and\n             a[a_match_end] == b[b_match_end]):\n        a_match_end += 1\n        b_match_end += 1\n      # Compute the length of the matching segment.  We prefer the longest.\n      match_length = a_match_end - a_match_start\n      # Extra credit for matching at the beginning or end of the sequence.\n      if a_match_start == 0 and b_match_start == 0:\n        match_length += min_match_length\n      if a_match_end == len(a) and b_match_end == len(b):\n        match_length += min_match_length\n      if match_length > max_match_length:\n        max_match_length = match_length\n        best_match = (a_match_start, a_match_end, b_match_start, b_match_end)\n      # advance a_pos to the end of this match to avoid wasting time\n      # rediscovering this match.\n      a_pos = a_match_end\n  if max_match_length < min_match_length or max_recursion_depth == 0:\n    return [(\"diff\", a_start, a_end, b_start, b_end)]\n  a_match_start, a_match_end, b_match_start, b_match_end = best_match\n  return (fast_match_sequences(\n      a, b, a_start, a_match_start, b_start, b_match_start, min_match_length,\n      max_recursion_depth - 1) + [\n          (\"equal\", a_match_start, a_match_end, b_match_start, b_match_end)\n      ] + fast_match_sequences(a, b, a_match_end, a_end, b_match_end, b_end,\n                               min_match_length, max_recursion_depth - 1))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef begin(self):\n    variables_to_restore = tf.contrib.framework.get_variables_to_restore(\n        include=self._include, exclude=self._exclude)\n    # remove new_model_scope from variable name prefix\n    assignment_map = {variable.name[len(self._new_model_scope):]: variable\n                      for variable in variables_to_restore\n                      if variable.name.startswith(self._new_model_scope)}\n    # remove :0 from variable name suffix\n    assignment_map = {name.split(\":\")[0]: variable\n                      for name, variable in six.iteritems(assignment_map)\n                      if name.startswith(self._old_model_scope)}\n    self._assignment_map = assignment_map\n\n    tf.logging.info(\"restoring %d variables from checkpoint %s\"%(\n        len(assignment_map), self._checkpoint_path))\n    tf.train.init_from_checkpoint(self._checkpoint_path, self._assignment_map)", "response": "Load variables from checkpoint."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_time_step(cls,\n                       observation=None,\n                       done=False,\n                       raw_reward=None,\n                       processed_reward=None,\n                       action=None):\n    \"\"\"Creates a TimeStep with both rewards and actions as optional.\"\"\"\n\n    return cls(observation, done, raw_reward, processed_reward, action)", "response": "Creates a TimeStep with both rewards and actions as optional."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncompletes attention layer with preprocessing.", "response": "def attention(targets_shifted, inputs_encoded, norm_fn, hparams, bias=None):\n  \"\"\"Complete attention layer with preprocessing.\"\"\"\n  separabilities = [hparams.separability, hparams.separability]\n  if hparams.separability < 0:\n    separabilities = [hparams.separability - 1, hparams.separability]\n  targets_timed = common_layers.subseparable_conv_block(\n      common_layers.add_timing_signal(targets_shifted),\n      hparams.hidden_size, [((1, 1), (5, 1)), ((4, 1), (5, 1))],\n      normalizer_fn=norm_fn,\n      padding=\"LEFT\",\n      separabilities=separabilities,\n      name=\"targets_time\")\n  if hparams.attention_type == \"transformer\":\n    targets_timed = tf.squeeze(targets_timed, 2)\n    target_shape = tf.shape(targets_timed)\n    targets_segment = tf.zeros([target_shape[0], target_shape[1]])\n    target_attention_bias = common_attention.attention_bias(\n        targets_segment, targets_segment, lower_triangular=True)\n    inputs_attention_bias = tf.zeros([\n        tf.shape(inputs_encoded)[0], hparams.num_heads,\n        tf.shape(targets_segment)[1],\n        tf.shape(inputs_encoded)[1]\n    ])\n\n    qv = common_attention.multihead_attention(\n        targets_timed,\n        None,\n        target_attention_bias,\n        hparams.hidden_size,\n        hparams.hidden_size,\n        hparams.hidden_size,\n        hparams.num_heads,\n        hparams.attention_dropout,\n        name=\"self_attention\")\n    qv = common_attention.multihead_attention(\n        qv,\n        inputs_encoded,\n        inputs_attention_bias,\n        hparams.hidden_size,\n        hparams.hidden_size,\n        hparams.hidden_size,\n        hparams.num_heads,\n        hparams.attention_dropout,\n        name=\"encdec_attention\")\n    return tf.expand_dims(qv, 2)\n  elif hparams.attention_type == \"simple\":\n    targets_with_attention = common_layers.simple_attention(\n        targets_timed, inputs_encoded, bias=bias)\n    return norm_fn(targets_shifted + targets_with_attention, name=\"attn_norm\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef similarity_cost(inputs_encoded, targets_encoded):\n  # This is a first very simple version: handle variable-length by padding\n  # to same length and putting everything into batch. In need of a better way.\n  x, y = common_layers.pad_to_same_length(inputs_encoded, targets_encoded)\n  depth = tf.shape(inputs_encoded)[3]\n  x, y = tf.reshape(x, [-1, depth]), tf.reshape(y, [-1, depth])\n  return rank_loss(x, y)", "response": "Loss telling to be more similar to your own targets than to others."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmiddle part of slicenet connecting encoder and decoder.", "response": "def slicenet_middle(inputs_encoded, targets, target_space_emb, mask, hparams):\n  \"\"\"Middle part of slicenet, connecting encoder and decoder.\"\"\"\n\n  def norm_fn(x, name):\n    with tf.variable_scope(name, default_name=\"norm\"):\n      return common_layers.apply_norm(x, hparams.norm_type, hparams.hidden_size,\n                                      hparams.norm_epsilon)\n\n  # Flatten targets and embed target_space_id.\n  targets_flat = tf.expand_dims(common_layers.flatten4d3d(targets), axis=2)\n  target_space_emb = tf.tile(target_space_emb,\n                             [tf.shape(targets_flat)[0], 1, 1, 1])\n\n  # Use attention from each target to look at input and retrieve.\n  targets_shifted = common_layers.shift_right(\n      targets_flat, pad_value=target_space_emb)\n  if hparams.attention_type == \"none\":\n    targets_with_attention = tf.zeros_like(targets_shifted)\n  else:\n    inputs_padding_bias = (1.0 - mask) * -1e9  # Bias to not attend to padding.\n    targets_with_attention = attention(\n        targets_shifted,\n        inputs_encoded,\n        norm_fn,\n        hparams,\n        bias=inputs_padding_bias)\n\n  # Positional targets: merge attention and raw.\n  kernel = (hparams.kernel_height, hparams.kernel_width)\n  targets_merged = common_layers.subseparable_conv_block(\n      tf.concat([targets_with_attention, targets_shifted], axis=3),\n      hparams.hidden_size, [((1, 1), kernel)],\n      normalizer_fn=norm_fn,\n      padding=\"LEFT\",\n      separability=4,\n      name=\"targets_merge\")\n\n  return targets_merged, 0.0"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninput embeddings -> is_padding.", "response": "def embedding_to_padding(emb):\n  \"\"\"Input embeddings -> is_padding.\"\"\"\n  emb_sum = tf.reduce_sum(tf.abs(emb), axis=-1, keep_dims=True)\n  return tf.to_float(tf.equal(emb_sum, 0.0))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef slicenet_internal(inputs, targets, target_space, hparams, run_decoder=True):\n  with tf.variable_scope(\"slicenet\"):\n    # Project to hidden size if necessary\n    if inputs.get_shape().as_list()[-1] != hparams.hidden_size:\n      inputs = common_layers.conv_block(\n          inputs,\n          hparams.hidden_size, [((1, 1), (3, 3))],\n          first_relu=False,\n          padding=\"SAME\",\n          force2d=True)\n\n    # Flatten inputs and encode.\n    inputs = tf.expand_dims(common_layers.flatten4d3d(inputs), axis=2)\n    inputs_mask = 1.0 - embedding_to_padding(inputs)\n    inputs = common_layers.add_timing_signal(inputs)  # Add position info.\n    target_space_emb = embed_target_space(target_space, hparams.hidden_size)\n    extra_layers = int(hparams.num_hidden_layers * 1.5)\n    inputs_encoded = multi_conv_res(\n        inputs, \"SAME\", \"encoder\", extra_layers, hparams, mask=inputs_mask)\n    if not run_decoder:\n      return inputs_encoded\n    # Do the middle part.\n    decoder_start, similarity_loss = slicenet_middle(\n        inputs_encoded, targets, target_space_emb, inputs_mask, hparams)\n    # Decode.\n    decoder_final = multi_conv_res(\n        decoder_start,\n        \"LEFT\",\n        \"decoder\",\n        hparams.num_hidden_layers,\n        hparams,\n        mask=inputs_mask,\n        source=inputs_encoded)\n    return decoder_final, tf.reduce_mean(similarity_loss)", "response": "The slicenet model main step used for training."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nversioning with Noam s decay scheme.", "response": "def slicenet_params1_noam():\n  \"\"\"Version with Noam's decay scheme.\"\"\"\n  hparams = slicenet_params1()\n  hparams.learning_rate_decay_scheme = \"noam\"\n  hparams.learning_rate = 1.0\n  hparams.learning_rate_warmup_steps = 4000\n  hparams.initializer = \"uniform_unit_scaling\"\n  hparams.optimizer_adam_epsilon = 1e-9\n  hparams.optimizer_adam_beta1 = 0.9\n  hparams.optimizer_adam_beta2 = 0.98\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nversions for fast local runs.", "response": "def slicenet_params1_tiny():\n  \"\"\"Version for fast local runs.\"\"\"\n  hparams = slicenet_params1()\n  hparams.attention_type = \"simple\"\n  hparams.separability = 0\n  hparams.hidden_size = 128\n  hparams.num_hidden_layers = 2\n  hparams.batch_size = 512\n  hparams.learning_rate_warmup_steps = 200\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef slicenet_range1(ranged_hparams):\n  rhp = ranged_hparams\n  rhp.set_float(\"clip_grad_norm\", 1.0, 10.0, scale=rhp.LOG_SCALE)\n  rhp.set_float(\"learning_rate\", 0.02, 1.0, scale=rhp.LOG_SCALE)\n  rhp.set_float(\"optimizer_adam_beta2\", 0.995, 0.998)\n  rhp.set_float(\"weight_decay\", 1.0, 5.0)", "response": "Small range of hyperparameters."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef encode(self, s):\n    sentence = s\n    tokens = sentence.strip().split()\n    ids = []\n    ids_extend = []\n    oovs = {}\n    for t in tokens:\n      if t in self._token_to_id:\n        ids.append(self._token_to_id[t])\n        ids_extend.append(self._token_to_id[t])\n      else:\n        next_oov_id = len(oovs)\n        oov_num = oovs.get(t, next_oov_id)\n        if oov_num == next_oov_id:\n          oovs[t] = oov_num\n        ids_extend.append(self.vocab_size + oov_num)\n        ids.append(self._token_to_id[self._replace_oov])\n    source_oov_id_to_token = [\"\"] * len(oovs)\n    for oov in oovs:\n      source_oov_id_to_token[oovs[oov]] = oov\n    if self._reverse:\n      return ids[::-1], ids_extend[::-1], oovs, source_oov_id_to_token\n    else:\n      return ids, ids_extend, oovs, source_oov_id_to_token", "response": "Converts a space - separated string of tokens to lists of ids."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef encode_target(self, target, source_oovs):\n    tokens = target.strip().split()\n    ids = []\n    ids_extend = []\n    for t in tokens:\n      if t in self._token_to_id:\n        i = self._token_to_id[t]\n        ids.append(i)\n        ids_extend.append(i)\n      else:\n        ids.append(self._token_to_id[self._replace_oov])\n        if t in source_oovs:\n          vocab_idx = self.vocab_size + source_oovs[t]\n          ids_extend.append(vocab_idx)\n        else:\n          ids_extend.append(self._token_to_id[self._replace_oov])\n    if self._reverse:\n      return ids[::-1], ids_extend[::-1]\n    else:\n      return ids, ids_extend", "response": "Converts a space - separated string of tokens to lists of ids."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decode_list_oov(self, ids, source_oov_id_to_token):\n    seq = reversed(ids) if self._reverse else ids\n    tokens = []\n    for cur_id in seq:\n      if cur_id in self._id_to_token:\n        tokens.append(self._id_to_token[cur_id])\n      else:\n        tokens.append(source_oov_id_to_token[cur_id - self.vocab_size])\n    return tokens", "response": "decode ids back to tokens considering OOVs temporary IDs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _smallest_size_at_least(height, width, smallest_side):\n  smallest_side = tf.convert_to_tensor(smallest_side, dtype=tf.int32)\n\n  height = tf.to_float(height)\n  width = tf.to_float(width)\n  smallest_side = tf.to_float(smallest_side)\n\n  scale = tf.cond(\n      tf.greater(height, width), lambda: smallest_side / width,\n      lambda: smallest_side / height)\n  new_height = tf.to_int32(height * scale)\n  new_width = tf.to_int32(width * scale)\n  return new_height, new_width", "response": "Computes new shape with the smallest side equal to smallest_side."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndistort the color of a Tensor image.", "response": "def _distort_color(image, color_ordering=0, scope=None):\n  \"\"\"Distort the color of a Tensor image.\n\n  Each color distortion is non-commutative and thus ordering of the color ops\n  matters. Ideally we would randomly permute the ordering of the color ops.\n  Rather then adding that level of complication, we select a distinct ordering\n  of color ops for each preprocessing thread.\n\n  Args:\n    image: 3-D Tensor containing single image in [0, 1].\n    color_ordering: Python int, a type of distortion (valid values: 0-3).\n    scope: Optional scope for name_scope.\n  Returns:\n    3-D Tensor color-distorted image on range [0, 1]\n  Raises:\n    ValueError: if color_ordering not in [0, 3]\n  \"\"\"\n  with tf.name_scope(scope, \"distort_color\", [image]):\n    if color_ordering == 0:\n      image = tf.image.random_brightness(image, max_delta=32. / 255.)\n      image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n      image = tf.image.random_hue(image, max_delta=0.2)\n      image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n    elif color_ordering == 1:\n      image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n      image = tf.image.random_brightness(image, max_delta=32. / 255.)\n      image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n      image = tf.image.random_hue(image, max_delta=0.2)\n    elif color_ordering == 2:\n      image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n      image = tf.image.random_hue(image, max_delta=0.2)\n      image = tf.image.random_brightness(image, max_delta=32. / 255.)\n      image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n    elif color_ordering == 3:\n      image = tf.image.random_hue(image, max_delta=0.2)\n      image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n      image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n      image = tf.image.random_brightness(image, max_delta=32. / 255.)\n    else:\n      raise ValueError(\"color_ordering must be in [0, 3]\")\n\n    # The random_* ops do not necessarily clamp.\n    return tf.clip_by_value(image, 0.0, 1.0)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\napply func to x with random selector.", "response": "def _apply_with_random_selector(x, func, num_cases):\n  \"\"\"Computes func(x, sel), with sel sampled from [0...num_cases-1].\n\n  Args:\n    x: input Tensor.\n    func: Python function to apply.\n    num_cases: Python int32, number of cases to sample sel from.\n\n  Returns:\n    The result of func(x, sel), where func receives the value of the\n    selector as a python integer, but sel is sampled dynamically.\n  \"\"\"\n  sel = tf.random_uniform([], maxval=num_cases, dtype=tf.int32)\n  # Pass the real x only to one of the func calls.\n  return control_flow_ops.merge([\n      func(control_flow_ops.switch(x, tf.equal(sel, case))[1], case)\n      for case in range(num_cases)\n  ])[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _mean_image_subtraction(image, means):\n  if image.get_shape().ndims != 3:\n    raise ValueError(\"Input must be of size [height, width, C>0]\")\n  num_channels = image.get_shape().as_list()[-1]\n  if len(means) != num_channels:\n    raise ValueError(\"len(means) must match the number of channels\")\n\n  channels = tf.split(axis=2, num_or_size_splits=num_channels, value=image)\n  for i in range(num_channels):\n    channels[i] -= means[i]\n  return tf.concat(axis=2, values=channels)", "response": "Subtracts the given means from each image channel."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef vqa_v2_preprocess_image(\n    image,\n    height,\n    width,\n    mode,\n    resize_side=512,\n    distort=True,\n    image_model_fn=\"resnet_v1_152\",\n):\n  \"\"\"vqa v2 preprocess image.\"\"\"\n\n  image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n  assert resize_side > 0\n  if resize_side:\n    image = _aspect_preserving_resize(image, resize_side)\n  if mode == tf.estimator.ModeKeys.TRAIN:\n    image = tf.random_crop(image, [height, width, 3])\n  else:\n    # Central crop, assuming resize_height > height, resize_width > width.\n    image = tf.image.resize_image_with_crop_or_pad(image, height, width)\n\n  image = tf.clip_by_value(image, 0.0, 1.0)\n\n  if mode == tf.estimator.ModeKeys.TRAIN and distort:\n    image = _flip(image)\n    num_distort_cases = 4\n    # pylint: disable=unnecessary-lambda\n    image = _apply_with_random_selector(\n        image, lambda x, ordering: _distort_color(x, ordering),\n        num_cases=num_distort_cases)\n\n  if image_model_fn.startswith(\"resnet_v1\"):\n    # resnet_v1 uses vgg preprocessing\n    image = image * 255.\n    image = _mean_image_subtraction(image, [_R_MEAN, _G_MEAN, _B_MEAN])\n  elif image_model_fn.startswith(\"resnet_v2\"):\n    # resnet v2 uses inception preprocessing\n    image = tf.subtract(image, 0.5)\n    image = tf.multiply(image, 2.0)\n\n  return image", "response": "vqa v2 preprocess image."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npreparing one shard of the model for the encoder.", "response": "def transformer_prepare_encoder(inputs, target_space, hparams, features=None):\n  \"\"\"Prepare one shard of the model for the encoder.\n\n  Args:\n    inputs: a Tensor.\n    target_space: a Tensor.\n    hparams: run hyperparameters\n    features: optionally pass the entire features dictionary as well.\n      This is needed now for \"packed\" datasets.\n\n  Returns:\n    encoder_input: a Tensor, bottom of encoder stack\n    encoder_self_attention_bias: a bias tensor for use in encoder self-attention\n    encoder_decoder_attention_bias: a bias tensor for use in encoder-decoder\n      attention\n  \"\"\"\n  ishape_static = inputs.shape.as_list()\n  encoder_input = inputs\n  if features and \"inputs_segmentation\" in features:\n    # Packed dataset.  Keep the examples from seeing each other.\n    inputs_segmentation = features[\"inputs_segmentation\"]\n    inputs_position = features[\"inputs_position\"]\n    targets_segmentation = features[\"targets_segmentation\"]\n    if (hasattr(hparams, \"unidirectional_encoder\") and\n        hparams.unidirectional_encoder):\n      tf.logging.info(\"Using unidirectional encoder\")\n      encoder_self_attention_bias = (\n          common_attention.attention_bias_lower_triangle(\n              common_layers.shape_list(inputs)[1]))\n    else:\n      encoder_self_attention_bias = (\n          common_attention.attention_bias_same_segment(\n              inputs_segmentation, inputs_segmentation))\n    encoder_decoder_attention_bias = (\n        common_attention.attention_bias_same_segment(targets_segmentation,\n                                                     inputs_segmentation))\n  else:\n    encoder_padding = common_attention.embedding_to_padding(encoder_input)\n    ignore_padding = common_attention.attention_bias_ignore_padding(\n        encoder_padding)\n    if (hasattr(hparams, \"unidirectional_encoder\") and\n        hparams.unidirectional_encoder):\n      tf.logging.info(\"Using unidirectional encoder\")\n      encoder_self_attention_bias = (\n          common_attention.attention_bias_lower_triangle(\n              common_layers.shape_list(inputs)[1]))\n    else:\n      # Usual case - not a packed dataset.\n      encoder_self_attention_bias = ignore_padding\n    encoder_decoder_attention_bias = ignore_padding\n    inputs_position = None\n  if hparams.proximity_bias:\n    encoder_self_attention_bias += common_attention.attention_bias_proximal(\n        common_layers.shape_list(inputs)[1])\n  if target_space is not None and hparams.get(\"use_target_space_embedding\",\n                                              True):\n    # Append target_space_id embedding to inputs.\n    emb_target_space = common_layers.embedding(\n        target_space,\n        32,\n        ishape_static[-1],\n        name=\"target_space_embedding\",\n        dtype=hparams.get(\"activation_dtype\", \"float32\"))\n    emb_target_space = tf.reshape(emb_target_space, [1, 1, -1])\n    encoder_input += emb_target_space\n  if hparams.pos == \"timing\":\n    if inputs_position is not None:\n      encoder_input = common_attention.add_timing_signal_1d_given_position(\n          encoder_input, inputs_position)\n    else:\n      encoder_input = common_attention.add_timing_signal_1d(encoder_input)\n  elif hparams.pos == \"emb\":\n    encoder_input = common_attention.add_positional_embedding(\n        encoder_input, hparams.max_length, \"inputs_positional_embedding\",\n        inputs_position)\n\n  encoder_self_attention_bias = common_layers.cast_like(\n      encoder_self_attention_bias, encoder_input)\n  encoder_decoder_attention_bias = common_layers.cast_like(\n      encoder_decoder_attention_bias, encoder_input)\n  return (encoder_input, encoder_self_attention_bias,\n          encoder_decoder_attention_bias)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfeeding - forward layer in the transformer.", "response": "def transformer_ffn_layer(x,\n                          hparams,\n                          pad_remover=None,\n                          conv_padding=\"LEFT\",\n                          nonpadding_mask=None,\n                          losses=None,\n                          cache=None,\n                          decode_loop_step=None,\n                          readout_filter_size=0,\n                          layer_collection=None):\n  \"\"\"Feed-forward layer in the transformer.\n\n  Args:\n    x: a Tensor of shape [batch_size, length, hparams.hidden_size]\n    hparams: hyperparameters for model\n    pad_remover: an expert_utils.PadRemover object tracking the padding\n      positions. If provided, when using convolutional settings, the padding\n      is removed before applying the convolution, and restored afterward. This\n      can give a significant speedup.\n    conv_padding: a string - either \"LEFT\" or \"SAME\".\n    nonpadding_mask: an optional Tensor with shape [batch_size, length].\n      needed for convolutional layers with \"SAME\" padding.\n      Contains 1.0 in positions corresponding to nonpadding.\n    losses: optional list onto which to append extra training losses\n    cache: dict, containing tensors which are the results of previous\n        attentions, used for fast decoding.\n    decode_loop_step: An integer, step number of the decoding loop.\n        Only used for inference on TPU.\n    readout_filter_size: if it's greater than 0, then it will be used instead of\n      filter_size\n    layer_collection: A tensorflow_kfac.LayerCollection. Only used by the\n      KFAC optimizer. Default is None.\n\n\n  Returns:\n    a Tensor of shape [batch_size, length, hparams.hidden_size]\n\n  Raises:\n    ValueError: If losses arg is None, but layer generates extra losses.\n  \"\"\"\n  ffn_layer = hparams.ffn_layer\n  relu_dropout_broadcast_dims = (\n      common_layers.comma_separated_string_to_integer_list(\n          getattr(hparams, \"relu_dropout_broadcast_dims\", \"\")))\n  if ffn_layer == \"conv_hidden_relu\":\n    # Backwards compatibility\n    ffn_layer = \"dense_relu_dense\"\n  if ffn_layer == \"dense_relu_dense\":\n    # In simple convolution mode, use `pad_remover` to speed up processing.\n    mlperf_log.transformer_print(\n        key=mlperf_log.MODEL_HP_FFN_FILTER_DENSE,\n        value={\n            \"filter_size\": hparams.filter_size,\n            \"use_bias\": \"True\",\n            \"activation\": mlperf_log.RELU\n        })\n    mlperf_log.transformer_print(\n        key=mlperf_log.MODEL_HP_FFN_OUTPUT_DENSE,\n        value={\n            \"hidden_size\": hparams.hidden_size,\n            \"use_bias\": \"True\",\n        })\n    mlperf_log.transformer_print(\n        key=mlperf_log.MODEL_HP_RELU_DROPOUT, value=hparams.relu_dropout)\n    if pad_remover:\n      original_shape = common_layers.shape_list(x)\n      # Collapse `x` across examples, and remove padding positions.\n      x = tf.reshape(x, tf.concat([[-1], original_shape[2:]], axis=0))\n      x = tf.expand_dims(pad_remover.remove(x), axis=0)\n    conv_output = common_layers.dense_relu_dense(\n        x,\n        hparams.filter_size,\n        hparams.hidden_size,\n        dropout=hparams.relu_dropout,\n        dropout_broadcast_dims=relu_dropout_broadcast_dims,\n        layer_collection=layer_collection)\n    if pad_remover:\n      # Restore `conv_output` to the original shape of `x`, including padding.\n      conv_output = tf.reshape(\n          pad_remover.restore(tf.squeeze(conv_output, axis=0)), original_shape)\n    return conv_output\n  elif ffn_layer == \"conv_relu_conv\":\n    return common_layers.conv_relu_conv(\n        x,\n        readout_filter_size or hparams.filter_size,\n        hparams.hidden_size,\n        first_kernel_size=hparams.conv_first_kernel,\n        second_kernel_size=1,\n        padding=conv_padding,\n        nonpadding_mask=nonpadding_mask,\n        dropout=hparams.relu_dropout,\n        cache=cache,\n        decode_loop_step=decode_loop_step)\n  elif ffn_layer == \"parameter_attention\":\n    return common_attention.parameter_attention(\n        x, hparams.parameter_attention_key_channels or hparams.hidden_size,\n        hparams.parameter_attention_value_channels or hparams.hidden_size,\n        hparams.hidden_size, readout_filter_size or hparams.filter_size,\n        hparams.num_heads,\n        hparams.attention_dropout)\n  elif ffn_layer == \"conv_hidden_relu_with_sepconv\":\n    return common_layers.conv_hidden_relu(\n        x,\n        readout_filter_size or hparams.filter_size,\n        hparams.hidden_size,\n        kernel_size=(3, 1),\n        second_kernel_size=(31, 1),\n        padding=\"LEFT\",\n        dropout=hparams.relu_dropout)\n  elif ffn_layer == \"sru\":\n    return common_layers.sru(x)\n  elif ffn_layer == \"local_moe_tpu\":\n    overhead = hparams.moe_overhead_eval\n    if hparams.mode == tf.estimator.ModeKeys.TRAIN:\n      overhead = hparams.moe_overhead_train\n    ret, loss = expert_utils.local_moe_tpu(\n        x,\n        hparams.filter_size // 2,\n        hparams.hidden_size,\n        hparams.moe_num_experts,\n        overhead=overhead,\n        loss_coef=hparams.moe_loss_coef)\n  elif ffn_layer == \"local_moe\":\n    overhead = hparams.moe_overhead_eval\n    if hparams.mode == tf.estimator.ModeKeys.TRAIN:\n      overhead = hparams.moe_overhead_train\n    ret, loss = expert_utils.local_moe(\n        x,\n        True,\n        expert_utils.ffn_expert_fn(hparams.hidden_size, [hparams.filter_size],\n                                   hparams.hidden_size),\n        hparams.moe_num_experts,\n        k=hparams.moe_k,\n        hparams=hparams)\n    losses.append(loss)\n    return ret\n  else:\n    assert ffn_layer == \"none\"\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lmx_base():\n  hparams = transformer.transformer_tpu()\n  # sharing is counterproductive when underparameterized\n  hparams.shared_embedding_and_softmax_weights = False\n  # we judge by log-ppl, so label smoothing hurts.\n  hparams.label_smoothing = 0.0\n  # This makes the batch size on GPU the same as on TPU for a packed problem\n  # with sequence length 256.\n  # TODO(noam): fix the mess that is the data reading pipeline.\n  hparams.max_length = 256\n  # larger batch since we only have a decoder\n  hparams.batch_size = 4096\n  # save some memory so we can have a larger model\n  hparams.activation_dtype = \"bfloat16\"\n  return hparams", "response": "Transformer on languagemodel_lm1b32k_packed. 50M Params."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lmx_h4k_f16k():\n  hparams = lmx_base()\n  hparams.hidden_size = 4096\n  hparams.filter_size = 16384\n  hparams.batch_size = 1024\n  hparams.weight_dtype = \"bfloat16\"\n  return hparams", "response": "HParams for training languagemodel_lm1b32k_packed. 1470M Params."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef lmx_relative():\n  hparams = lmx_base()\n  hparams.self_attention_type = \"dot_product_relative_v2\"\n  hparams.activation_dtype = \"float32\"\n  hparams.weight_dtype = \"float32\"\n  return hparams", "response": "Language model using relative attention."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lmx_moe_h1k_f4k_x32():\n  hparams = lmx_h1k_f4k()\n  hparams.ffn_layer = \"local_moe_tpu\"\n  hparams.moe_num_experts = 32\n  hparams.weight_dtype = \"bfloat16\"\n  hparams.batch_size = 8192\n  return hparams", "response": "Transformer with mixture of experts. 890M Params."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef lmx_moe_h1k_f8k_x16():\n  hparams = lmx_h1k_f4k()\n  hparams.filter_size = 8192\n  hparams.ffn_layer = \"local_moe_tpu\"\n  hparams.moe_num_experts = 16\n  hparams.weight_dtype = \"bfloat16\"\n  hparams.batch_size = 8192\n  return hparams", "response": "Transformer with mixture of experts. 890M Params."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreset the batch of environments.", "response": "def _reset_non_empty(self, indices):\n    \"\"\"Reset the batch of environments.\n\n    Args:\n      indices: The batch indices of the environments to reset; defaults to all.\n\n    Returns:\n      Batch tensor of the new observations.\n    \"\"\"\n    reset_video_op = tf.cond(\n        self._video_condition,\n        lambda: tf.py_func(self._video_reset_writer, [], []),\n        tf.no_op)\n    with tf.control_dependencies([reset_video_op]):\n      inc_op = tf.assign_add(self._episode_counter, 1)\n      with tf.control_dependencies([self.history_buffer.reset(indices),\n                                    inc_op]):\n        initial_frame_dump_op = tf.cond(\n            self._video_condition,\n            lambda: tf.py_func(self._video_dump_frames,  # pylint: disable=g-long-lambda\n                               [self.history_buffer.get_all_elements()], []),\n            tf.no_op)\n        observ_assign_op = self._observ.assign(\n            self.history_buffer.get_all_elements()[:, -1, ...])\n        with tf.control_dependencies([observ_assign_op, initial_frame_dump_op]):\n          reset_model_op = tf.assign(self._reset_model, tf.constant(1.0))\n          with tf.control_dependencies([reset_model_op]):\n            return tf.gather(self._observ.read_value(), indices)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the random seed from flag everywhere.", "response": "def set_random_seed():\n  \"\"\"Set the random seed from flag everywhere.\"\"\"\n  tf.set_random_seed(FLAGS.random_seed)\n  random.seed(FLAGS.random_seed)\n  np.random.seed(FLAGS.random_seed)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating data for a problem in _SUPPORTED_PROBLEM_GENERATORS.", "response": "def generate_data_for_problem(problem):\n  \"\"\"Generate data for a problem in _SUPPORTED_PROBLEM_GENERATORS.\"\"\"\n  training_gen, dev_gen, test_gen = _SUPPORTED_PROBLEM_GENERATORS[problem]\n\n  num_train_shards = FLAGS.num_shards or 10\n  tf.logging.info(\"Generating training data for %s.\", problem)\n  train_output_files = generator_utils.train_data_filenames(\n      problem + generator_utils.UNSHUFFLED_SUFFIX, FLAGS.data_dir,\n      num_train_shards)\n  generator_utils.generate_files(training_gen(), train_output_files,\n                                 FLAGS.max_cases)\n  num_dev_shards = int(num_train_shards * 0.1)\n  tf.logging.info(\"Generating development data for %s.\", problem)\n  dev_output_files = generator_utils.dev_data_filenames(\n      problem + generator_utils.UNSHUFFLED_SUFFIX, FLAGS.data_dir,\n      num_dev_shards)\n  generator_utils.generate_files(dev_gen(), dev_output_files)\n  num_test_shards = int(num_train_shards * 0.1)\n  test_output_files = []\n  test_gen_data = test_gen()\n  if test_gen_data is not None:\n    tf.logging.info(\"Generating test data for %s.\", problem)\n    test_output_files = generator_utils.test_data_filenames(\n        problem + generator_utils.UNSHUFFLED_SUFFIX, FLAGS.data_dir,\n        num_test_shards)\n    generator_utils.generate_files(test_gen_data, test_output_files)\n  all_output_files = train_output_files + dev_output_files + test_output_files\n  generator_utils.shuffle_dataset(all_output_files)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating data for a specific EnvProblem.", "response": "def generate_data_for_env_problem(problem_name):\n  \"\"\"Generate data for `EnvProblem`s.\"\"\"\n  assert FLAGS.env_problem_max_env_steps > 0, (\"--env_problem_max_env_steps \"\n                                               \"should be greater than zero\")\n  assert FLAGS.env_problem_batch_size > 0, (\"--env_problem_batch_size should be\"\n                                            \" greather than zero\")\n  problem = registry.env_problem(problem_name)\n  task_id = None if FLAGS.task_id < 0 else FLAGS.task_id\n  data_dir = os.path.expanduser(FLAGS.data_dir)\n  tmp_dir = os.path.expanduser(FLAGS.tmp_dir)\n  # TODO(msaffar): Handle large values for env_problem_batch_size where we\n  #  cannot create that many environments within the same process.\n  problem.initialize(batch_size=FLAGS.env_problem_batch_size)\n  env_problem_utils.play_env_problem_randomly(\n      problem, num_steps=FLAGS.env_problem_max_env_steps)\n  problem.generate_data(data_dir=data_dir, tmp_dir=tmp_dir, task_id=task_id)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating data for a registered problem.", "response": "def generate_data_for_registered_problem(problem_name):\n  \"\"\"Generate data for a registered problem.\"\"\"\n  tf.logging.info(\"Generating data for %s.\", problem_name)\n  if FLAGS.num_shards:\n    raise ValueError(\"--num_shards should not be set for registered Problem.\")\n  problem = registry.problem(problem_name)\n  task_id = None if FLAGS.task_id < 0 else FLAGS.task_id\n  data_dir = os.path.expanduser(FLAGS.data_dir)\n  tmp_dir = os.path.expanduser(FLAGS.tmp_dir)\n  if task_id is None and problem.multiprocess_generate:\n    if FLAGS.task_id_start != -1:\n      assert FLAGS.task_id_end != -1\n      task_id_start = FLAGS.task_id_start\n      task_id_end = FLAGS.task_id_end\n    else:\n      task_id_start = 0\n      task_id_end = problem.num_generate_tasks\n    pool = multiprocessing.Pool(processes=FLAGS.num_concurrent_processes)\n    problem.prepare_to_generate(data_dir, tmp_dir)\n    args = [(problem_name, data_dir, tmp_dir, task_id)\n            for task_id in range(task_id_start, task_id_end)]\n    pool.map(generate_data_in_process, args)\n  else:\n    problem.generate_data(data_dir, tmp_dir, task_id)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntraverses directory collecting input and target files.", "response": "def _collect_data(directory):\n  \"\"\"Traverses directory collecting input and target files.\n\n  Args:\n   directory: base path to extracted audio and transcripts.\n  Returns:\n   list of (media_base, media_filepath, label) tuples\n  \"\"\"\n  # Returns:\n  data_files = []\n  transcripts = [\n      filename for filename in os.listdir(directory)\n      if filename.endswith(\".csv\")\n  ]\n  for transcript in transcripts:\n    transcript_path = os.path.join(directory, transcript)\n    with open(transcript_path, \"r\") as transcript_file:\n      transcript_reader = csv.reader(transcript_file)\n      # skip header\n      _ = next(transcript_reader)\n      for transcript_line in transcript_reader:\n        media_name, label = transcript_line[0:2]\n        filename = os.path.join(directory, media_name)\n        data_files.append((media_name, filename, label))\n  return data_files"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if the filename exists under the path.", "response": "def _file_exists(path, filename):\n  \"\"\"Checks if the filename exists under the path.\"\"\"\n  return os.path.isfile(os.path.join(path, filename))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _is_relative(path, filename):\n  return os.path.abspath(os.path.join(path, filename)).startswith(path)", "response": "Checks if the filename is relative."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef define_ppo_epoch(memory, hparams, action_space, batch_size):\n  observation, reward, done, action, old_pdf, value = memory\n\n  # This is to avoid propagating gradients through simulated environment.\n  observation = tf.stop_gradient(observation)\n  action = tf.stop_gradient(action)\n  reward = tf.stop_gradient(reward)\n  if hasattr(hparams, \"rewards_preprocessing_fun\"):\n    reward = hparams.rewards_preprocessing_fun(reward)\n  done = tf.stop_gradient(done)\n  value = tf.stop_gradient(value)\n  old_pdf = tf.stop_gradient(old_pdf)\n\n  advantage = calculate_generalized_advantage_estimator(\n      reward, value, done, hparams.gae_gamma, hparams.gae_lambda)\n\n  discounted_reward = tf.stop_gradient(advantage + value[:-1])\n\n  advantage_mean, advantage_variance = tf.nn.moments(advantage, axes=[0, 1],\n                                                     keep_dims=True)\n  advantage_normalized = tf.stop_gradient(\n      (advantage - advantage_mean)/(tf.sqrt(advantage_variance) + 1e-8))\n\n  add_lists_elementwise = lambda l1, l2: [x + y for x, y in zip(l1, l2)]\n\n  number_of_batches = ((hparams.epoch_length-1) * hparams.optimization_epochs\n                       // hparams.optimization_batch_size)\n  epoch_length = hparams.epoch_length\n  if hparams.effective_num_agents is not None:\n    number_of_batches *= batch_size\n    number_of_batches //= hparams.effective_num_agents\n    epoch_length //= hparams.effective_num_agents\n\n  assert number_of_batches > 0, \"Set the paremeters so that number_of_batches>0\"\n  lr = learning_rate.learning_rate_schedule(hparams)\n\n  shuffled_indices = [tf.random.shuffle(tf.range(epoch_length - 1))\n                      for _ in range(hparams.optimization_epochs)]\n  shuffled_indices = tf.concat(shuffled_indices, axis=0)\n  shuffled_indices = shuffled_indices[:number_of_batches *\n                                      hparams.optimization_batch_size]\n  indices_of_batches = tf.reshape(shuffled_indices,\n                                  shape=(-1, hparams.optimization_batch_size))\n  input_tensors = [observation, action, discounted_reward,\n                   advantage_normalized, old_pdf]\n\n  ppo_step_rets = tf.scan(\n      lambda a, i: add_lists_elementwise(  # pylint: disable=g-long-lambda\n          a, define_ppo_step([tf.gather(t, indices_of_batches[i, :])\n                              for t in input_tensors],\n                             hparams, action_space, lr\n                            )),\n      tf.range(number_of_batches),\n      [0., 0., 0.],\n      parallel_iterations=1)\n\n  ppo_summaries = [tf.reduce_mean(ret) / number_of_batches\n                   for ret in ppo_step_rets]\n  ppo_summaries.append(lr)\n  summaries_names = [\n      \"policy_loss\", \"value_loss\", \"entropy_loss\", \"learning_rate\"\n  ]\n\n  summaries = [tf.summary.scalar(summary_name, summary)\n               for summary_name, summary in zip(summaries_names, ppo_summaries)]\n  losses_summary = tf.summary.merge(summaries)\n\n  for summary_name, summary in zip(summaries_names, ppo_summaries):\n    losses_summary = tf.Print(losses_summary, [summary], summary_name + \": \")\n\n  return losses_summary", "response": "Define the PPO epoch."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calculate_generalized_advantage_estimator(\n    reward, value, done, gae_gamma, gae_lambda):\n  # pylint: disable=g-doc-args\n  \"\"\"Generalized advantage estimator.\n\n  Returns:\n    GAE estimator. It will be one element shorter than the input; this is\n    because to compute GAE for [0, ..., N-1] one needs V for [1, ..., N].\n  \"\"\"\n  # pylint: enable=g-doc-args\n\n  next_value = value[1:, :]\n  next_not_done = 1 - tf.cast(done[1:, :], tf.float32)\n  delta = (reward[:-1, :] + gae_gamma * next_value * next_not_done\n           - value[:-1, :])\n\n  return_ = tf.reverse(tf.scan(\n      lambda agg, cur: cur[0] + cur[1] * gae_gamma * gae_lambda * agg,\n      [tf.reverse(delta, [0]), tf.reverse(next_not_done, [0])],\n      tf.zeros_like(delta[0, :]),\n      parallel_iterations=1), [0])\n  return tf.check_numerics(return_, \"return\")", "response": "Generalized advantage estimator.\n\n  Returns:\n    GAE estimator. It will be one element shorter than the input; this is\n    because to compute GAE for [0, ..., N-1] one needs V for [1, ..., N]."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gym_space_spec(gym_space):\n  # First try to determine the type.\n  try:\n    tf_dtype = tf.as_dtype(gym_space.dtype)\n  except TypeError as e:\n    tf.logging.error(\"Cannot convert space's type [%s] to tf.dtype\",\n                     gym_space.dtype)\n    raise e\n\n  # Now hand it over to the specialized functions.\n  if isinstance(gym_space, Box):\n    return box_space_spec(gym_space, tf_dtype)\n  elif isinstance(gym_space, Discrete):\n    return discrete_space_spec(gym_space, tf_dtype)\n  else:\n    raise NotImplementedError", "response": "Returns a reading spec of a gym space."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the number of elements that can be represented by the gym space.", "response": "def cardinality(gym_space):\n  \"\"\"Number of elements that can be represented by the space.\n\n  Makes the most sense for Discrete or Box type with integral dtype, ex: number\n  of actions in an action space.\n\n  Args:\n    gym_space: The gym space.\n\n  Returns:\n    np.int64 number of observations that can be represented by this space, or\n    returns None when this doesn't make sense, i.e. float boxes etc.\n\n  Raises:\n    NotImplementedError when a space's cardinality makes sense but we haven't\n    implemented it.\n  \"\"\"\n\n  if (gym_space.dtype == np.float32) or (gym_space.dtype == np.float64):\n    tf.logging.error(\"Returning None for a float gym space's cardinality: \",\n                     gym_space)\n    return None\n\n  if isinstance(gym_space, Discrete):\n    return gym_space.n\n\n  if isinstance(gym_space, Box):\n    # Construct a box with all possible values in this box and take a product.\n    return np.prod(gym_space.high - gym_space.low + 1)\n\n  raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef abs_error(predictions, labels, weights_fn=None):\n  del weights_fn  # Unused\n  targets = tf.squeeze(labels, axis=[2, 3])\n  batch_abs_error = tf.abs(predictions - targets)\n  den = tf.ones(tf.shape(batch_abs_error), dtype=tf.float32)\n  return (batch_abs_error, den)", "response": "Computes mean absolute error."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexplaining variance also known as R^2.", "response": "def padded_variance_explained(predictions,\n                              labels,\n                              weights_fn=common_layers.weights_all):\n  \"\"\"Explained variance, also known as R^2.\"\"\"\n  predictions, labels = common_layers.pad_with_zeros(predictions, labels)\n  targets = labels\n  weights = weights_fn(targets)\n\n  y_bar = tf.reduce_mean(weights * targets)\n  tot_ss = tf.reduce_sum(weights * tf.pow(targets - y_bar, 2))\n  res_ss = tf.reduce_sum(weights * tf.pow(targets - predictions, 2))\n  r2 = 1. - res_ss / tot_ss\n  return r2, tf.reduce_sum(weights)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rounding_sequence_accuracy(predictions,\n                               labels,\n                               weights_fn=common_layers.weights_nonzero):\n  \"\"\"Sequence accuracy for L1/L2 losses: round down the predictions to ints.\"\"\"\n  outputs = tf.squeeze(tf.to_int32(predictions), axis=-1)\n  weights = weights_fn(labels)\n  labels = tf.to_int32(labels)\n  not_correct = tf.to_float(tf.not_equal(outputs, labels)) * weights\n  axis = list(range(1, len(outputs.get_shape())))\n  correct_seq = 1.0 - tf.minimum(1.0, tf.reduce_sum(not_correct, axis=axis))\n  return correct_seq, tf.constant(1.0)", "response": "Sequence accuracy for L1 and L2 losses."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sequence_edit_distance(predictions,\n                           labels,\n                           weights_fn=common_layers.weights_nonzero):\n  \"\"\"Average edit distance, ignoring padding 0s.\n\n  The score returned is the edit distance divided by the total length of\n  reference truth and the weight returned is the total length of the truth.\n\n  Args:\n    predictions: Tensor of shape [`batch_size`, `length`, 1, `num_classes`] and\n        type tf.float32 representing the logits, 0-padded.\n    labels: Tensor of shape [`batch_size`, `length`, 1, 1] and type tf.int32\n        representing the labels of same length as logits and 0-padded.\n    weights_fn: ignored. The weights returned are the total length of the ground\n        truth labels, excluding 0-paddings.\n\n  Returns:\n    (edit distance / reference length, reference length)\n\n  Raises:\n    ValueError: if weights_fn is not common_layers.weights_nonzero.\n  \"\"\"\n  if weights_fn is not common_layers.weights_nonzero:\n    raise ValueError(\"Only weights_nonzero can be used for this metric.\")\n\n  with tf.variable_scope(\"edit_distance\", values=[predictions, labels]):\n    # Transform logits into sequence classes by taking max at every step.\n    predictions = tf.to_int32(\n        tf.squeeze(tf.argmax(predictions, axis=-1), axis=(2, 3)))\n    nonzero_idx = tf.where(tf.not_equal(predictions, 0))\n    sparse_outputs = tf.SparseTensor(nonzero_idx,\n                                     tf.gather_nd(predictions, nonzero_idx),\n                                     tf.shape(predictions, out_type=tf.int64))\n    labels = tf.squeeze(labels, axis=(2, 3))\n    nonzero_idx = tf.where(tf.not_equal(labels, 0))\n    label_sparse_outputs = tf.SparseTensor(nonzero_idx,\n                                           tf.gather_nd(labels, nonzero_idx),\n                                           tf.shape(labels, out_type=tf.int64))\n    distance = tf.reduce_sum(\n        tf.edit_distance(sparse_outputs, label_sparse_outputs, normalize=False))\n    reference_length = tf.to_float(common_layers.shape_list(nonzero_idx)[0])\n    return distance / reference_length, reference_length", "response": "Average edit distance between two sequences."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef padded_neg_log_perplexity(predictions,\n                              labels,\n                              weights_fn=common_layers.weights_nonzero):\n  \"\"\"Average log-perplexity exluding padding 0s. No smoothing.\"\"\"\n  num, den = common_layers.padded_cross_entropy(\n      predictions, labels, 0.0, weights_fn=weights_fn, reduce_sum=False)\n  return (-num, den)", "response": "Average log - perplexity exluding padding 0s. No smoothing."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\naverages log - perplexity with custom targets_mask.", "response": "def padded_neg_log_perplexity_with_masking(\n    predictions,\n    labels,\n    features,\n    weights_fn=None):\n  \"\"\"Average log-perplexity with custom targets_mask.\"\"\"\n  del weights_fn\n  if \"targets_mask\" not in features:\n    raise ValueError(\"masked_neg_log_perplexity requires targets_mask feature\")\n\n  # Features are 4 dimensional, so we need to reshape the targets_mask to match\n  # the shape of the labels. A lot of models rely on these features being 4D,\n  # so it's best to update the shape of the mask.\n  extended_targets_mask_shape = common_layers.shape_list(\n      features[\"targets_mask\"])\n  extended_targets_mask_shape.extend([1, 1])\n  features[\"targets_mask\"] = tf.reshape(features[\"targets_mask\"],\n                                        shape=extended_targets_mask_shape)\n\n  mask_fn = lambda labels: features[\"targets_mask\"]\n  return padded_neg_log_perplexity(predictions, labels, mask_fn)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dmol_neg_log_perplexity(predictions,\n                            labels,\n                            weights_fn=None):\n  \"\"\"Average log-perplexity excluding padding 0s. No smoothing.\"\"\"\n  del weights_fn  # Unused\n  num, den = common_layers.dml_loss(\n      predictions, labels, reduce_sum=False)\n  return (-num, den)", "response": "Average log - perplexity excluding padding 0s. No smoothing."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rounding_accuracy(predictions,\n                      labels,\n                      weights_fn=common_layers.weights_nonzero):\n  \"\"\"Rounding accuracy for L1/L2 losses: round down the predictions to ints.\"\"\"\n  outputs = tf.squeeze(tf.to_int32(predictions))\n  labels = tf.squeeze(labels)\n  weights = weights_fn(labels)\n  labels = tf.to_int32(labels)\n  return tf.to_float(tf.equal(outputs, labels)), weights", "response": "Rounding accuracy for L1 and L2 losses."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef multilabel_accuracy_matchk(predictions,\n                               labels,\n                               k,\n                               weights_fn=common_layers.weights_nonzero):\n  \"\"\"Used to evaluate the VQA accuracy.\n\n  Let n be the times that predictions appear in labels, then final score\n  is min(n/k, 1).\n  Refer to https://arxiv.org/pdf/1505.00468.pdf.\n\n  Args:\n    predictions: A tensor with shape [batch_size, 1, 1, 1, vocab_size].\n    labels: A tensor with shape [batch_size, length, 1, 1].\n    k: A tensor constant.\n    weights_fn: weight function.\n  Returns:\n    scores: min(n/k, 1).\n    weights: returns all ones.\n\n  \"\"\"\n  predictions = tf.to_int32(tf.argmax(predictions, axis=-1))\n  scores = tf.to_float(tf.equal(predictions, labels))\n  # those label == 0 do not count\n  weights = weights_fn(labels)\n  scores *= weights\n  scores = tf.reduce_sum(scores, axis=[1, 2, 3])\n  scores = tf.minimum(scores / tf.to_float(k), 1)\n  # every sample count\n  weights = tf.ones(tf.shape(scores), dtype=tf.float32)\n\n  return scores, weights", "response": "Used to evaluate the VQA accuracy."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef image_summary(predictions, targets, hparams):\n  del hparams\n  results = tf.cast(tf.argmax(predictions, axis=-1), tf.uint8)\n  gold = tf.cast(targets, tf.uint8)\n  summary1 = tf.summary.image(\"prediction\", results, max_outputs=2)\n  summary2 = tf.summary.image(\"data\", gold, max_outputs=2)\n  summary = tf.summary.merge([summary1, summary2])\n  return summary, tf.zeros_like(predictions)", "response": "Reshapes predictions and passes it to tensorboard.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef softmax_cross_entropy_one_hot(logits, labels, weights_fn=None):\n  with tf.variable_scope(\"softmax_cross_entropy_one_hot\",\n                         values=[logits, labels]):\n    del weights_fn\n    cross_entropy = tf.losses.softmax_cross_entropy(\n        onehot_labels=labels, logits=logits)\n    return cross_entropy, tf.constant(1.0)", "response": "Calculate softmax cross entropy given one - hot labels and logits."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate accuracy for a set given one - hot labels and logits.", "response": "def sigmoid_accuracy_one_hot(logits, labels, weights_fn=None):\n  \"\"\"Calculate accuracy for a set, given one-hot labels and logits.\n\n  Args:\n    logits: Tensor of size [batch-size, o=1, p=1, num-classes]\n    labels: Tensor of size [batch-size, o=1, p=1, num-classes]\n    weights_fn: Function that takes in labels and weighs examples (unused)\n  Returns:\n    accuracy (scalar), weights\n  \"\"\"\n  with tf.variable_scope(\"sigmoid_accuracy_one_hot\", values=[logits, labels]):\n    del weights_fn\n    predictions = tf.nn.sigmoid(logits)\n    labels = tf.argmax(labels, -1)\n    predictions = tf.argmax(predictions, -1)\n    _, accuracy = tf.metrics.accuracy(labels=labels, predictions=predictions)\n    return accuracy, tf.constant(1.0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates recall for a set given one - hot labels and logits.", "response": "def sigmoid_recall_one_hot(logits, labels, weights_fn=None):\n  \"\"\"Calculate recall for a set, given one-hot labels and logits.\n\n  Predictions are converted to one-hot,\n  as predictions[example][arg-max(example)] = 1\n\n  Args:\n    logits: Tensor of size [batch-size, o=1, p=1, num-classes]\n    labels: Tensor of size [batch-size, o=1, p=1, num-classes]\n    weights_fn: Function that takes in labels and weighs examples (unused)\n  Returns:\n    recall (scalar), weights\n  \"\"\"\n  with tf.variable_scope(\"sigmoid_recall_one_hot\", values=[logits, labels]):\n    del weights_fn\n    num_classes = logits.shape[-1]\n    predictions = tf.nn.sigmoid(logits)\n    predictions = tf.argmax(predictions, -1)\n    predictions = tf.one_hot(predictions, num_classes)\n    _, recall = tf.metrics.recall(labels=labels, predictions=predictions)\n    return recall, tf.constant(1.0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sigmoid_cross_entropy_one_hot(logits, labels, weights_fn=None):\n  with tf.variable_scope(\"sigmoid_cross_entropy_one_hot\",\n                         values=[logits, labels]):\n    del weights_fn\n    cross_entropy = tf.losses.sigmoid_cross_entropy(\n        multi_class_labels=labels, logits=logits)\n    return cross_entropy, tf.constant(1.0)", "response": "Calculate sigmoid cross entropy for one - hot lanels and logits."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate ROC AUC. Requires binary classes. Args: logits: Tensor of size [batch_size, 1, 1, num_classes] labels: Tensor of size [batch_size, 1, 1, num_classes] weights_fn: Function that takes in labels and weighs examples (unused) Returns: ROC AUC (scalar), weights", "response": "def roc_auc(logits, labels, weights_fn=None):\n  \"\"\"Calculate ROC AUC.\n\n  Requires binary classes.\n\n  Args:\n    logits: Tensor of size [batch_size, 1, 1, num_classes]\n    labels: Tensor of size [batch_size, 1, 1, num_classes]\n    weights_fn: Function that takes in labels and weighs examples (unused)\n  Returns:\n    ROC AUC (scalar), weights\n  \"\"\"\n  del weights_fn\n  with tf.variable_scope(\"roc_auc\", values=[logits, labels]):\n    predictions = tf.argmax(logits, axis=-1)\n    _, auc = tf.metrics.auc(labels, predictions, curve=\"ROC\")\n    return auc, tf.constant(1.0)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_evaluation_metrics(problems, model_hparams):\n  def reduce_dimensions(predictions, labels):\n    \"\"\"Reduce dimensions for high-dimensional predictions and labels.\"\"\"\n    # We will treat first dimensions as batch. One example are video frames.\n    if len(predictions.get_shape()) > 5:\n      predictions_shape = common_layers.shape_list(predictions)\n      predictions = tf.reshape(\n          predictions, [predictions_shape[0], predictions_shape[1], -1,\n                        predictions_shape[-1]])\n      labels_shape = common_layers.shape_list(labels)\n      labels = tf.reshape(\n          labels, [labels_shape[0], labels_shape[1], -1])\n    return predictions, labels\n\n  def make_problem_specific_metric_fn(metric_fn, weights_fn):\n    \"\"\"Create a metric fn.\"\"\"\n\n    def problem_metric_fn(predictions, features, labels):\n      \"\"\"Metric fn.\"\"\"\n      # Send along the entire features dict if the metric fn has the kwarg\n      # \"features\".\n      kwargs = {}\n      args, _, keywords, _ = inspect.getargspec(metric_fn)\n      if (\"features\" in args) or keywords:\n        kwargs[\"features\"] = features\n\n      predictions, labels = reduce_dimensions(predictions, labels)\n\n      scores, weights = metric_fn(predictions, labels,\n                                  weights_fn=weights_fn, **kwargs)\n      return tf.metrics.mean(scores, weights)\n\n    return problem_metric_fn\n\n  def make_image_wrapped_metric_fn(metric_fn):\n    \"\"\"Metric fn without tf.metrics.mean.\"\"\"\n\n    def image_wrapped_metric_fn(predictions,\n                                features,\n                                labels,\n                                weights_fn=common_layers.weights_all):\n      del weights_fn\n      del features\n      predictions, labels = reduce_dimensions(predictions, labels)\n      return metric_fn(predictions, labels, model_hparams)\n\n    return image_wrapped_metric_fn\n\n  def weights_fn_for_mp(problem_task_id):\n    return lambda x: common_layers.weights_multi_problem(x, problem_task_id)\n\n  eval_metrics = {}\n  for problem_instance in problems:\n    problem_name = problem_instance.name\n    if problem_instance.was_reversed:\n      problem_name += \"_rev\"\n    metrics = problem_instance.eval_metric_fns(model_hparams)\n    if hasattr(model_hparams.problem, \"task_list\"):\n      metrics = model_hparams.problem.eval_metric_fns(model_hparams)\n\n    tm = problem_instance.get_hparams(model_hparams).modality[\"targets\"]\n    if not isinstance(tm, dict):\n      tm = {\"targets\": tm}\n\n    for target_name, modality in six.iteritems(tm):\n      weights_fn = model_hparams.weights_fn.get(\n          \"targets\",\n          modalities.get_weights_fn(modality))\n      if hasattr(model_hparams.problem, \"task_list\"):\n        ptid = problem_instance.task_id  # pylint: disable=cell-var-from-loop\n        weights_fn = weights_fn_for_mp(ptid)\n\n      for metric, metric_fn in six.iteritems(metrics):\n        overload_eval_metric_name = getattr(\n            model_hparams, \"overload_eval_metric_name\", None)\n        if len(problems) == 1 and overload_eval_metric_name:\n          metric_name = \"metrics-%s/%s/%s\" % (\n              overload_eval_metric_name, target_name, metric)\n        else:\n          metric_name = \"metrics-%s/%s/%s\" % (problem_name, target_name, metric)\n        if metric == Metrics.IMAGE_SUMMARY:\n          eval_metrics[metric_name] = make_image_wrapped_metric_fn(metric_fn)\n        else:\n          eval_metrics[metric_name] = make_problem_specific_metric_fn(\n              metric_fn, weights_fn)\n\n  return eval_metrics", "response": "Creates the evaluation metrics for the model."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_eager_metrics_for_problem(problem, model_hparams):\n  metric_fns = problem.eval_metric_fns(model_hparams)\n  problem_hparams = problem.get_hparams(model_hparams)\n  target_modality = problem_hparams.modality[\"targets\"]\n  weights_fn = model_hparams.weights_fn.get(\n      \"targets\",\n      modalities.get_weights_fn(target_modality))\n  return create_eager_metrics_internal(metric_fns, weights_fn=weights_fn)", "response": "Create eager metrics for a problem."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_eager_metrics(metric_names, weights_fn=common_layers.weights_all):\n  metric_fns = dict(\n      [(name, METRICS_FNS[name]) for name in metric_names])\n  return create_eager_metrics_internal(metric_fns, weights_fn)", "response": "Create metrics accumulators and averager for Eager mode."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating metrics accumulators and averager for Eager mode.", "response": "def create_eager_metrics_internal(metric_fns,\n                                  weights_fn=common_layers.weights_all):\n  \"\"\"Create metrics accumulators and averager for Eager mode.\n\n  Args:\n    metric_fns: dict<metric name, metric function>\n    weights_fn: function that takes labels and returns a weights mask. Defaults\n      to weights of all 1, i.e. common_layers.weights_all. Use\n      common_layers.weights_nonzero if labels have 0-padding.\n\n  Returns:\n    (accum_fn(predictions, targets) => None,\n     result_fn() => dict<str metric_name, float avg_val>\n  \"\"\"\n  tfe_metrics = {}\n\n  for name in metric_fns:\n    tfe_metrics[name] = tfe.metrics.Mean(name=name)\n\n  def metric_accum(predictions, targets):\n    for name, metric_fn in metric_fns.items():\n      val, weight = metric_fn(predictions, targets,\n                              weights_fn=weights_fn)\n      tfe_metrics[name](np.squeeze(val), np.squeeze(weight))\n\n  def metric_means():\n    avgs = {}\n    for name in metric_fns:\n      avgs[name] = tfe_metrics[name].result().numpy()\n    return avgs\n\n  return metric_accum, metric_means"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef word_error_rate(raw_predictions,\n                    labels,\n                    lookup=None,\n                    weights_fn=common_layers.weights_nonzero):\n  \"\"\"Calculate word error rate.\n\n  Args:\n    raw_predictions: The raw predictions.\n    labels: The actual labels.\n    lookup: A tf.constant mapping indices to output tokens.\n    weights_fn: Weighting function.\n\n  Returns:\n    The word error rate.\n  \"\"\"\n\n  def from_tokens(raw, lookup_):\n    gathered = tf.gather(lookup_, tf.cast(raw, tf.int32))\n    joined = tf.regex_replace(tf.reduce_join(gathered, axis=1), b\"<EOS>.*\", b\"\")\n    cleaned = tf.regex_replace(joined, b\"_\", b\" \")\n    tokens = tf.string_split(cleaned, \" \")\n    return tokens\n\n  def from_characters(raw, lookup_):\n    \"\"\"Convert ascii+2 encoded codes to string-tokens.\"\"\"\n    corrected = tf.bitcast(\n        tf.clip_by_value(tf.subtract(raw, 2), 0, 255), tf.uint8)\n\n    gathered = tf.gather(lookup_, tf.cast(corrected, tf.int32))[:, :, 0]\n    joined = tf.reduce_join(gathered, axis=1)\n    cleaned = tf.regex_replace(joined, b\"\\0\", b\"\")\n    tokens = tf.string_split(cleaned, \" \")\n    return tokens\n\n  if lookup is None:\n    lookup = tf.constant([chr(i) for i in range(256)])\n    convert_fn = from_characters\n  else:\n    convert_fn = from_tokens\n\n  if weights_fn is not common_layers.weights_nonzero:\n    raise ValueError(\"Only weights_nonzero can be used for this metric.\")\n\n  with tf.variable_scope(\"word_error_rate\", values=[raw_predictions, labels]):\n\n    raw_predictions = tf.squeeze(\n        tf.argmax(raw_predictions, axis=-1), axis=(2, 3))\n    labels = tf.squeeze(labels, axis=(2, 3))\n\n    reference = convert_fn(labels, lookup)\n    predictions = convert_fn(raw_predictions, lookup)\n\n    distance = tf.reduce_sum(\n        tf.edit_distance(predictions, reference, normalize=False))\n    reference_length = tf.cast(\n        tf.size(reference.values, out_type=tf.int32), dtype=tf.float32)\n\n    return distance / reference_length, reference_length", "response": "Calculate word error rate."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the pearson correlation coefficient.", "response": "def pearson_correlation_coefficient(predictions, labels, weights_fn=None):\n  \"\"\"Calculate pearson correlation coefficient.\n\n  Args:\n    predictions: The raw predictions.\n    labels: The actual labels.\n    weights_fn: Weighting function.\n\n  Returns:\n    The pearson correlation coefficient.\n  \"\"\"\n  del weights_fn\n  _, pearson = tf.contrib.metrics.streaming_pearson_correlation(predictions,\n                                                                labels)\n  return pearson, tf.constant(1.0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef attention_lm_prepare_decoder(targets, hparams):\n  if hparams.prepend_mode == \"prepend_inputs_full_attention\":\n    decoder_self_attention_bias = (\n        common_attention.attention_bias_prepend_inputs_full_attention(\n            common_attention.embedding_to_padding(targets)))\n  else:\n    decoder_self_attention_bias = (\n        common_attention.attention_bias_lower_triangle(\n            common_layers.shape_list(targets)[1]))\n  decoder_input = common_layers.shift_right_3d(targets)\n  if hparams.pos == \"timing\":\n    decoder_input = common_attention.add_timing_signal_1d(decoder_input)\n  return (decoder_input, decoder_self_attention_bias)", "response": "Prepare one shard of the model for the decoder."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef attention_lm_decoder(decoder_input,\n                         decoder_self_attention_bias,\n                         hparams,\n                         name=\"decoder\"):\n  \"\"\"A stack of attention_lm layers.\n\n  Args:\n    decoder_input: a Tensor\n    decoder_self_attention_bias: bias Tensor for self-attention\n      (see common_attention.attention_bias())\n    hparams: hyperparameters for model\n    name: a string\n\n  Returns:\n    y: a Tensors\n  \"\"\"\n  x = decoder_input\n  with tf.variable_scope(name):\n    for layer in range(hparams.num_hidden_layers):\n      with tf.variable_scope(\"layer_%d\" % layer):\n        with tf.variable_scope(\"self_attention\"):\n          y = common_attention.multihead_attention(\n              common_layers.layer_preprocess(\n                  x, hparams), None, decoder_self_attention_bias,\n              hparams.attention_key_channels or hparams.hidden_size,\n              hparams.attention_value_channels or hparams.hidden_size,\n              hparams.hidden_size, hparams.num_heads, hparams.attention_dropout)\n          x = common_layers.layer_postprocess(x, y, hparams)\n        with tf.variable_scope(\"ffn\"):\n          y = common_layers.conv_hidden_relu(\n              common_layers.layer_preprocess(x, hparams),\n              hparams.filter_size,\n              hparams.hidden_size,\n              dropout=hparams.relu_dropout)\n          x = common_layers.layer_postprocess(x, y, hparams)\n    return common_layers.layer_preprocess(x, hparams)", "response": "A stack of attention_lm layers."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef attention_lm_small():\n  hparams = attention_lm_base()\n  hparams.num_hidden_layers = 4\n  hparams.hidden_size = 512\n  hparams.filter_size = 2048\n  hparams.layer_prepostprocess_dropout = 0.5\n  return hparams", "response": "Cheap model.\n on lm1b_32k."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nversion to use for seq2seq.", "response": "def attention_lm_translation():\n  \"\"\"Version to use for seq2seq.\"\"\"\n  hparams = attention_lm_base()\n  hparams.layer_preprocess_sequence = \"n\"\n  hparams.layer_postprocess_sequence = \"da\"\n  hparams.learning_rate = 0.4\n  hparams.prepend_mode = \"prepend_inputs_masked_attention\"\n  hparams.max_length = 512\n  hparams.label_smoothing = 0.1\n  hparams.shared_embedding_and_softmax_weights = True\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract all n - grams from a given text segment.", "response": "def _get_ngrams(segment, max_order):\n  \"\"\"Extracts all n-grams up to a given maximum order from an input segment.\n\n  Args:\n    segment: text segment from which n-grams will be extracted.\n    max_order: maximum length in tokens of the n-grams returned by this\n        methods.\n\n  Returns:\n    The Counter containing all n-grams up to max_order in segment\n    with a count of how many times each n-gram occurred.\n  \"\"\"\n  ngram_counts = collections.Counter()\n  for order in range(1, max_order + 1):\n    for i in range(0, len(segment) - order + 1):\n      ngram = tuple(segment[i:i + order])\n      ngram_counts[ngram] += 1\n  return ngram_counts"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bleu_score(predictions, labels, **unused_kwargs):\n  outputs = tf.to_int32(tf.argmax(predictions, axis=-1))\n  # Convert the outputs and labels to a [batch_size, input_length] tensor.\n  outputs = tf.squeeze(outputs, axis=[-1, -2])\n  labels = tf.squeeze(labels, axis=[-1, -2])\n\n  bleu = tf.py_func(compute_bleu, (labels, outputs), tf.float32)\n  return bleu, tf.constant(1.0)", "response": "BLEU score computation between labels and predictions."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bleu_tokenize(string):\n  string = uregex.nondigit_punct_re.sub(r\"\\1 \\2 \", string)\n  string = uregex.punct_nondigit_re.sub(r\" \\1 \\2\", string)\n  string = uregex.symbol_re.sub(r\" \\1 \", string)\n  return string.split()", "response": "Tokenize a string following the official BLEU implementation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bleu_wrapper(ref_filename, hyp_filename, case_sensitive=False):\n  ref_lines = text_encoder.native_to_unicode(\n      tf.gfile.Open(ref_filename, \"r\").read()).split(\"\\n\")\n  hyp_lines = text_encoder.native_to_unicode(\n      tf.gfile.Open(hyp_filename, \"r\").read()).split(\"\\n\")\n  assert len(ref_lines) == len(hyp_lines), (\"{} != {}\".format(\n      len(ref_lines), len(hyp_lines)))\n  if not case_sensitive:\n    ref_lines = [x.lower() for x in ref_lines]\n    hyp_lines = [x.lower() for x in hyp_lines]\n  ref_tokens = [bleu_tokenize(x) for x in ref_lines]\n  hyp_tokens = [bleu_tokenize(x) for x in hyp_lines]\n  return compute_bleu(ref_tokens, hyp_tokens)", "response": "Compute BLEU for two files."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _try_twice_tf_glob(pattern):\n  try:\n    return tf.gfile.Glob(pattern)\n  except tf.errors.NotFoundError:\n    return tf.gfile.Glob(pattern)", "response": "Try twice tf. gfile. Glob."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _read_stepfiles_list(path_prefix, path_suffix=\".index\", min_steps=0):\n  stepfiles = []\n  for filename in _try_twice_tf_glob(path_prefix + \"*-[0-9]*\" + path_suffix):\n    basename = filename[:-len(path_suffix)] if path_suffix else filename\n    try:\n      steps = int(basename.rsplit(\"-\")[-1])\n    except ValueError:  # The -[0-9]* part is not an integer.\n      continue\n    if steps < min_steps:\n      continue\n    if not os.path.exists(filename):\n      tf.logging.info(filename + \" was deleted, so skipping it\")\n      continue\n    stepfiles.append(StepFile(basename, os.path.getmtime(filename),\n                              os.path.getctime(filename), steps))\n  return sorted(stepfiles, key=lambda x: -x.steps)", "response": "Return list of StepFiles sorted by step from files at path_prefix."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts the VQA V2 annotation files to directory unless it s there.", "response": "def _get_vqa_v2_annotations(directory,\n                            annotation_url,\n                            annotation_filename=\"vqa_v2.tar.gz\"):\n  \"\"\"Extract the VQA V2 annotation files to directory unless it's there.\"\"\"\n  annotation_file = generator_utils.maybe_download_from_drive(\n      directory, annotation_filename, annotation_url)\n  with tarfile.open(annotation_file, \"r:gz\") as annotation_tar:\n    annotation_tar.extractall(directory)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_vqa_v2_image_raw_dataset(directory, image_root_url, image_urls):\n  for url in image_urls:\n    filename = os.path.basename(url)\n    download_url = os.path.join(image_root_url, url)\n    path = generator_utils.maybe_download(directory, filename, download_url)\n    unzip_dir = os.path.join(directory, filename.strip(\".zip\"))\n    if not tf.gfile.Exists(unzip_dir):\n      zipfile.ZipFile(path, \"r\").extractall(directory)", "response": "Extract the VQA V2 image data set to directory unless it s there."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_vqa_v2_image_feature_dataset(\n    directory, feature_url, feature_filename=\"mscoco_feat.tar.gz\"):\n  \"\"\"Extract the VQA V2 feature data set to directory unless it's there.\"\"\"\n  feature_file = generator_utils.maybe_download_from_drive(\n      directory, feature_filename, feature_url)\n  with tarfile.open(feature_file, \"r:gz\") as feature_tar:\n    feature_tar.extractall(directory)", "response": "Extract the VQA V2 feature data set to directory unless it s there."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _process_scalar_value(name, parse_fn, var_type, m_dict, values,\n                          results_dictionary):\n  \"\"\"Update results_dictionary with a scalar value.\n\n  Used to update the results_dictionary to be returned by parse_values when\n  encountering a clause with a scalar RHS (e.g.  \"s=5\" or \"arr[0]=5\".)\n\n  Mutates results_dictionary.\n\n  Args:\n    name: Name of variable in assignment (\"s\" or \"arr\").\n    parse_fn: Function for parsing the actual value.\n    var_type: Type of named variable.\n    m_dict: Dictionary constructed from regex parsing.\n      m_dict['val']: RHS value (scalar)\n      m_dict['index']: List index value (or None)\n    values: Full expression being parsed\n    results_dictionary: The dictionary being updated for return by the parsing\n      function.\n\n  Raises:\n    ValueError: If the name has already been used.\n  \"\"\"\n  try:\n    parsed_value = parse_fn(m_dict['val'])\n  except ValueError:\n    _parse_fail(name, var_type, m_dict['val'], values)\n\n  # If no index is provided\n  if not m_dict['index']:\n    if name in results_dictionary:\n      _reuse_fail(name, values)\n    results_dictionary[name] = parsed_value\n  else:\n    if name in results_dictionary:\n      # The name has already been used as a scalar, then it\n      # will be in this dictionary and map to a non-dictionary.\n      if not isinstance(results_dictionary.get(name), dict):\n        _reuse_fail(name, values)\n    else:\n      results_dictionary[name] = {}\n\n    index = int(m_dict['index'])\n    # Make sure the index position hasn't already been assigned a value.\n    if index in results_dictionary[name]:\n      _reuse_fail('{}[{}]'.format(name, index), values)\n    results_dictionary[name][index] = parsed_value", "response": "Process a scalar value in the results_dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _process_list_value(name, parse_fn, var_type, m_dict, values,\n                        results_dictionary):\n  \"\"\"Update results_dictionary from a list of values.\n\n  Used to update results_dictionary to be returned by parse_values when\n  encountering a clause with a list RHS (e.g.  \"arr=[1,2,3]\".)\n\n  Mutates results_dictionary.\n\n  Args:\n    name: Name of variable in assignment (\"arr\").\n    parse_fn: Function for parsing individual values.\n    var_type: Type of named variable.\n    m_dict: Dictionary constructed from regex parsing.\n      m_dict['val']: RHS value (scalar)\n    values: Full expression being parsed\n    results_dictionary: The dictionary being updated for return by the parsing\n      function.\n\n  Raises:\n    ValueError: If the name has an index or the values cannot be parsed.\n  \"\"\"\n  if m_dict['index'] is not None:\n    raise ValueError('Assignment of a list to a list index.')\n  elements = filter(None, re.split('[ ,]', m_dict['vals']))\n  # Make sure the name hasn't already been assigned a value\n  if name in results_dictionary:\n    raise _reuse_fail(name, values)\n  try:\n    results_dictionary[name] = [parse_fn(e) for e in elements]\n  except ValueError:\n    _parse_fail(name, var_type, m_dict['vals'], values)", "response": "Process a list value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncast the value of a hparam to the provided type if compatible with the param_type.", "response": "def _cast_to_type_if_compatible(name, param_type, value):\n  \"\"\"Cast hparam to the provided type, if compatible.\n\n  Args:\n    name: Name of the hparam to be cast.\n    param_type: The type of the hparam.\n    value: The value to be cast, if compatible.\n\n  Returns:\n    The result of casting `value` to `param_type`.\n\n  Raises:\n    ValueError: If the type of `value` is not compatible with param_type.\n      * If `param_type` is a string type, but `value` is not.\n      * If `param_type` is a boolean, but `value` is not, or vice versa.\n      * If `param_type` is an integer type, but `value` is not.\n      * If `param_type` is a float type, but `value` is not a numeric type.\n  \"\"\"\n  fail_msg = (\n      \"Could not cast hparam '%s' of type '%s' from value %r\" %\n      (name, param_type, value))\n\n  # Some callers use None, for which we can't do any casting/checking. :(\n  if issubclass(param_type, type(None)):\n    return value\n\n  # Avoid converting a non-string type to a string.\n  if (issubclass(param_type, (six.string_types, six.binary_type)) and\n      not isinstance(value, (six.string_types, six.binary_type))):\n    raise ValueError(fail_msg)\n\n  # Avoid converting a number or string type to a boolean or vice versa.\n  if issubclass(param_type, bool) != isinstance(value, bool):\n    raise ValueError(fail_msg)\n\n  # Avoid converting float to an integer (the reverse is fine).\n  if (issubclass(param_type, numbers.Integral) and\n      not isinstance(value, numbers.Integral)):\n    raise ValueError(fail_msg)\n\n  # Avoid converting a non-numeric type to a numeric type.\n  if (issubclass(param_type, numbers.Number) and\n      not isinstance(value, numbers.Number)):\n    raise ValueError(fail_msg)\n\n  return param_type(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a string containing comma - separated name = value pairs into a python map.", "response": "def parse_values(values, type_map, ignore_unknown=False):\n  \"\"\"Parses hyperparameter values from a string into a python map.\n\n  `values` is a string containing comma-separated `name=value` pairs.\n  For each pair, the value of the hyperparameter named `name` is set to\n  `value`.\n\n  If a hyperparameter name appears multiple times in `values`, a ValueError\n  is raised (e.g. 'a=1,a=2', 'a[1]=1,a[1]=2').\n\n  If a hyperparameter name in both an index assignment and scalar assignment,\n  a ValueError is raised.  (e.g. 'a=[1,2,3],a[0] = 1').\n\n  The hyperparameter name may contain '.' symbols, which will result in an\n  attribute name that is only accessible through the getattr and setattr\n  functions.  (And must be first explicit added through add_hparam.)\n\n  WARNING: Use of '.' in your variable names is allowed, but is not well\n  supported and not recommended.\n\n  The `value` in `name=value` must follows the syntax according to the\n  type of the parameter:\n\n  *  Scalar integer: A Python-parsable integer point value.  E.g.: 1,\n     100, -12.\n  *  Scalar float: A Python-parsable floating point value.  E.g.: 1.0,\n     -.54e89.\n  *  Boolean: Either true or false.\n  *  Scalar string: A non-empty sequence of characters, excluding comma,\n     spaces, and square brackets.  E.g.: foo, bar_1.\n  *  List: A comma separated list of scalar values of the parameter type\n     enclosed in square brackets.  E.g.: [1,2,3], [1.0,1e-12], [high,low].\n\n  When index assignment is used, the corresponding type_map key should be the\n  list name.  E.g. for \"arr[1]=0\" the type_map must have the key \"arr\" (not\n  \"arr[1]\").\n\n  Args:\n    values: String.  Comma separated list of `name=value` pairs where\n      'value' must follow the syntax described above.\n    type_map: A dictionary mapping hyperparameter names to types.  Note every\n      parameter name in values must be a key in type_map.  The values must\n      conform to the types indicated, where a value V is said to conform to a\n      type T if either V has type T, or V is a list of elements of type T.\n      Hence, for a multidimensional parameter 'x' taking float values,\n      'x=[0.1,0.2]' will parse successfully if type_map['x'] = float.\n    ignore_unknown: Bool. Whether values that are missing a type in type_map\n      should be ignored. If set to True, a ValueError will not be raised for\n      unknown hyperparameter type.\n\n  Returns:\n    A python map mapping each name to either:\n    * A scalar value.\n    * A list of scalar values.\n    * A dictionary mapping index numbers to scalar values.\n    (e.g. \"x=5,L=[1,2],arr[1]=3\" results in {'x':5,'L':[1,2],'arr':{1:3}}\")\n\n  Raises:\n    ValueError: If there is a problem with input.\n    * If `values` cannot be parsed.\n    * If a list is assigned to a list index (e.g. 'a[1] = [1,2,3]').\n    * If the same rvalue is assigned two different values (e.g. 'a=1,a=2',\n      'a[1]=1,a[1]=2', or 'a=1,a=[1]')\n  \"\"\"\n  results_dictionary = {}\n  pos = 0\n  while pos < len(values):\n    m = PARAM_RE.match(values, pos)\n    if not m:\n      raise ValueError('Malformed hyperparameter value: %s' % values[pos:])\n    # Check that there is a comma between parameters and move past it.\n    pos = m.end()\n    # Parse the values.\n    m_dict = m.groupdict()\n    name = m_dict['name']\n    if name not in type_map:\n      if ignore_unknown:\n        continue\n      raise ValueError('Unknown hyperparameter type for %s' % name)\n    type_ = type_map[name]\n\n    # Set up correct parsing function (depending on whether type_ is a bool)\n    if type_ == bool:\n\n      def parse_bool(value):\n        if value in ['true', 'True']:\n          return True\n        elif value in ['false', 'False']:\n          return False\n        else:\n          try:\n            return bool(int(value))\n          except ValueError:\n            _parse_fail(name, type_, value, values)\n\n      parse = parse_bool\n    else:\n      parse = type_\n\n    # If a singe value is provided\n    if m_dict['val'] is not None:\n      _process_scalar_value(name, parse, type_, m_dict, values,\n                            results_dictionary)\n\n    # If the assigned value is a list:\n    elif m_dict['vals'] is not None:\n      _process_list_value(name, parse, type_, m_dict, values,\n                          results_dictionary)\n\n    else:  # Not assigned a list or value\n      _parse_fail(name, type_, '', values)\n\n  return results_dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_hparam(self, name, value):\n    # Keys in kwargs are unique, but 'name' could the name of a pre-existing\n    # attribute of this object.  In that case we refuse to use it as a\n    # hyperparameter name.\n    if getattr(self, name, None) is not None:\n      raise ValueError('Hyperparameter name is reserved: %s' % name)\n    if isinstance(value, (list, tuple)):\n      if not value:\n        raise ValueError(\n            'Multi-valued hyperparameters cannot be empty: %s' % name)\n      self._hparam_types[name] = (type(value[0]), True)\n    else:\n      self._hparam_types[name] = (type(value), False)\n    setattr(self, name, value)", "response": "Adds a { name value pair to the internal list of hyperparameters."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_hparam(self, name, value):\n    param_type, is_list = self._hparam_types[name]\n    if isinstance(value, list):\n      if not is_list:\n        raise ValueError(\n            'Must not pass a list for single-valued parameter: %s' % name)\n      setattr(self, name, [\n          _cast_to_type_if_compatible(name, param_type, v) for v in value])\n    else:\n      if is_list:\n        raise ValueError(\n            'Must pass a list for multi-valued parameter: %s.' % name)\n      setattr(self, name, _cast_to_type_if_compatible(name, param_type, value))", "response": "Sets the value of an existing hyperparameter."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving the hyperparameter with key name.", "response": "def del_hparam(self, name):\n    \"\"\"Removes the hyperparameter with key 'name'.\n\n    Does nothing if it isn't present.\n\n    Args:\n      name: Name of the hyperparameter.\n    \"\"\"\n    if hasattr(self, name):\n      delattr(self, name)\n      del self._hparam_types[name]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse(self, values):\n    type_map = {}\n    for name, t in self._hparam_types.items():\n      param_type, _ = t\n      type_map[name] = param_type\n\n    values_map = parse_values(values, type_map)\n    return self.override_from_dict(values_map)", "response": "Override existing hyperparameter values parsing new values from a string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\noverride existing hyperparameter values parsing new values from a dictionary.", "response": "def override_from_dict(self, values_dict):\n    \"\"\"Override existing hyperparameter values, parsing new values from a dictionary.\n\n    Args:\n      values_dict: Dictionary of name:value pairs.\n\n    Returns:\n      The `HParams` instance.\n\n    Raises:\n      KeyError: If a hyperparameter in `values_dict` doesn't exist.\n      ValueError: If `values_dict` cannot be parsed.\n    \"\"\"\n    for name, value in values_dict.items():\n      self.set_hparam(name, value)\n    return self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nserialize the hyperparameters into JSON.", "response": "def to_json(self, indent=None, separators=None, sort_keys=False):\n    \"\"\"Serializes the hyperparameters into JSON.\n\n    Args:\n      indent: If a non-negative integer, JSON array elements and object members\n        will be pretty-printed with that indent level. An indent level of 0, or\n        negative, will only insert newlines. `None` (the default) selects the\n        most compact representation.\n      separators: Optional `(item_separator, key_separator)` tuple. Default is\n        `(', ', ': ')`.\n      sort_keys: If `True`, the output dictionaries will be sorted by key.\n\n    Returns:\n      A JSON string.\n    \"\"\"\n    def remove_callables(x):\n      \"\"\"Omit callable elements from input with arbitrary nesting.\"\"\"\n      if isinstance(x, dict):\n        return {k: remove_callables(v) for k, v in six.iteritems(x)\n                if not callable(v)}\n      elif isinstance(x, list):\n        return [remove_callables(i) for i in x if not callable(i)]\n      return x\n    return json.dumps(\n        remove_callables(self.values()),\n        indent=indent,\n        separators=separators,\n        sort_keys=sort_keys)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\noverride existing hyperparameter values parsing new values from a json object.", "response": "def parse_json(self, values_json):\n    \"\"\"Override existing hyperparameter values, parsing new values from a json object.\n\n    Args:\n      values_json: String containing a json object of name:value pairs.\n\n    Returns:\n      The `HParams` instance.\n\n    Raises:\n      KeyError: If a hyperparameter in `values_json` doesn't exist.\n      ValueError: If `values_json` cannot be parsed.\n    \"\"\"\n    values_map = json.loads(values_json)\n    return self.override_from_dict(values_map)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef values(self):\n    return {n: getattr(self, n) for n in self._hparam_types.keys()}", "response": "Return the hyperparameter values as a Python dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, key, default=None):\n    if key in self._hparam_types:\n      # Ensure that default is compatible with the parameter type.\n      if default is not None:\n        param_type, is_param_list = self._hparam_types[key]\n        type_str = 'list<%s>' % param_type if is_param_list else str(param_type)\n        fail_msg = (\"Hparam '%s' of type '%s' is incompatible with \"\n                    'default=%s' % (key, type_str, default))\n\n        is_default_list = isinstance(default, list)\n        if is_param_list != is_default_list:\n          raise ValueError(fail_msg)\n\n        try:\n          if is_default_list:\n            for value in default:\n              _cast_to_type_if_compatible(key, param_type, value)\n          else:\n            _cast_to_type_if_compatible(key, param_type, default)\n        except ValueError as e:\n          raise ValueError('%s. %s' % (fail_msg, e))\n\n      return getattr(self, key)\n\n    return default", "response": "Returns the value of key if it exists else default."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the field name given the parameter type and is_list.", "response": "def _get_kind_name(param_type, is_list):\n    \"\"\"Returns the field name given parameter type and is_list.\n\n    Args:\n      param_type: Data type of the hparam.\n      is_list: Whether this is a list.\n\n    Returns:\n      A string representation of the field name.\n\n    Raises:\n      ValueError: If parameter type is not recognized.\n    \"\"\"\n    if issubclass(param_type, bool):\n      # This check must happen before issubclass(param_type, six.integer_types),\n      # since Python considers bool to be a subclass of int.\n      typename = 'bool'\n    elif issubclass(param_type, six.integer_types):\n      # Setting 'int' and 'long' types to be 'int64' to ensure the type is\n      # compatible with both Python2 and Python3.\n      typename = 'int64'\n    elif issubclass(param_type, (six.string_types, six.binary_type)):\n      # Setting 'string' and 'bytes' types to be 'bytes' to ensure the type is\n      # compatible with both Python2 and Python3.\n      typename = 'bytes'\n    elif issubclass(param_type, float):\n      typename = 'float'\n    else:\n      raise ValueError('Unsupported parameter type: %s' % str(param_type))\n\n    suffix = 'list' if is_list else 'value'\n    return '_'.join([typename, suffix])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process(self, query):\n    tf.logging.info(\"Processing new query [%s]\" %query)\n\n    # Create the new TFDBG hook directory.\n    hook_dir = \"/tmp/t2t_server_dump/request_%d\" %int(time.time())\n    os.makedirs(hook_dir)\n    hooks = [tfdbg.DumpingDebugHook(hook_dir, watch_fn=topk_watch_fn)]\n\n    # TODO(kstevens): This is extremely hacky and slow for responding to\n    # queries.  Figure out a reasonable way to pre-load the model weights before\n    # forking and run queries through the estimator quickly.\n    def server_input_fn():\n      \"\"\"Generator that returns just the current query.\"\"\"\n      for _ in range(1):\n        input_ids = self.source_vocab.encode(query)\n        input_ids.append(text_encoder.EOS_ID)\n        x = [1, 100, len(input_ids)] + input_ids\n        x += [0] * (self.const_array_size - len(x))\n        d = {\n            \"inputs\": np.array(x).astype(np.int32),\n        }\n        yield d\n\n    def input_fn():\n      \"\"\"Generator that returns just the current query.\"\"\"\n      gen_fn = decoding.make_input_fn_from_generator(server_input_fn())\n      example = gen_fn()\n      # TODO(kstevens): Make this method public\n      # pylint: disable=protected-access\n      return decoding._interactive_input_tensor_to_features_dict(\n          example, self.hparams)\n\n    # Make the prediction for the current query.\n    result_iter = self.estimator.predict(input_fn, hooks=hooks)\n    result = None\n    for result in result_iter:\n      break\n\n    # Extract the beam search information by reading the dumped TFDBG event\n    # tensors.  We first read and record the per step beam sequences then record\n    # the beam scores.  Afterwards we align the two sets of values to create the\n    # full graph vertices and edges.\n    decoding_graph = graph.Graph()\n    run_dirs = sorted(glob.glob(os.path.join(hook_dir, \"run_*\")))\n    for run_dir in run_dirs:\n      # Record the different completed and active beam sequence ids.\n      alive_sequences = deque()\n      finished_sequences = deque()\n\n      # Make the root vertex since it always needs to exist.\n      decoding_graph.get_vertex(sequence_key([0]))\n\n      # Create the initial vertices and edges for the active and finished\n      # sequences.  We uniquely define each vertex using it's full sequence path\n      # as a string to ensure there's no collisions when the same step has two\n      # instances of an output id.\n      dump_dir = tfdbg.DebugDumpDir(run_dir, validate=False)\n      seq_datums = dump_dir.find(predicate=seq_filter)\n      for seq_datum in seq_datums:\n        sequences = np.array(seq_datum.get_tensor()).astype(int)[0]\n        if \"alive\" in seq_datum.node_name:\n          alive_sequences.append(sequences)\n        if \"finished\" in seq_datum.node_name:\n          finished_sequences.append(sequences)\n\n        for sequence in sequences:\n          pieces = self.targets_vocab.decode_list(sequence)\n          index = sequence[-1]\n          if index == 0:\n            continue\n\n          parent = decoding_graph.get_vertex(sequence_key(sequence[:-1]))\n          current = decoding_graph.get_vertex(sequence_key(sequence))\n\n          edge = decoding_graph.add_edge(parent, current)\n          edge.data[\"label\"] = pieces[-1]\n          edge.data[\"label_id\"] = index\n          # Coerce the type to be a python bool.  Numpy bools can't be easily\n          # converted to JSON.\n          edge.data[\"completed\"] = bool(index == 1)\n\n      # Examine the score results and store the scores with the associated edges\n      # in the graph.  We fetch the vertices (and relevant edges) by looking\n      # into the saved beam sequences stored above.\n      score_datums = dump_dir.find(predicate=scores_filter)\n      for score_datum in score_datums:\n        if \"alive\" in score_datum.node_name:\n          sequences = alive_sequences.popleft()\n\n        if \"finished\" in score_datum.node_name:\n          sequences = finished_sequences.popleft()\n\n        scores = np.array(score_datum.get_tensor()).astype(float)[0]\n        for i, score in enumerate(scores):\n          sequence = sequences[i]\n          if sequence[-1] == 0:\n            continue\n\n          vertex = decoding_graph.get_vertex(sequence_key(sequence))\n          edge = decoding_graph.edges[vertex.in_edges[0]]\n          edge.data[\"score\"] = score\n          edge.data[\"log_probability\"] = score\n          edge.data[\"total_log_probability\"] = score\n\n    # Delete the hook dir to save disk space\n    shutil.rmtree(hook_dir)\n\n    # Create the graph visualization data structure.\n    graph_vis = {\n        \"visualization_name\": \"graph\",\n        \"title\": \"Graph\",\n        \"name\": \"graph\",\n        \"search_graph\": decoding_graph.to_dict(),\n    }\n\n    # Create the processing visualization data structure.\n    # TODO(kstevens): Make this method public\n    # pylint: disable=protected-access\n    output_ids = decoding._save_until_eos(result[\"outputs\"].flatten(), False)\n    output_pieces = self.targets_vocab.decode_list(output_ids)\n    output_token = [{\"text\": piece} for piece in output_pieces]\n    output = self.targets_vocab.decode(output_ids)\n\n    source_steps = [{\n        \"step_name\": \"Initial\",\n        \"segment\": [{\n            \"text\": query\n        }],\n    }]\n\n    target_steps = [{\n        \"step_name\": \"Initial\",\n        \"segment\": output_token,\n    }, {\n        \"step_name\": \"Final\",\n        \"segment\": [{\n            \"text\": output\n        }],\n    }]\n\n    processing_vis = {\n        \"visualization_name\": \"processing\",\n        \"title\": \"Processing\",\n        \"name\": \"processing\",\n        \"query_processing\": {\n            \"source_processing\": source_steps,\n            \"target_processing\": target_steps,\n        },\n    }\n\n    return {\n        \"result\": [processing_vis, graph_vis],\n    }", "response": "Returns the visualizations for the current query."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns train and evaluation datasets for the specified dataset.", "response": "def train_and_eval_dataset(dataset_name, data_dir):\n  \"\"\"Return train and evaluation datasets, feature info and supervised keys.\n\n  Args:\n    dataset_name: a string, the name of the dataset; if it starts with \"v1_\"\n      then we'll search T2T Problem registry for it, otherwise we assume it\n      is a dataset from TFDS and load it from there.\n    data_dir: directory where the data is located.\n\n  Returns:\n    a 4-tuple consisting of:\n     * the train tf.data.Dataset\n     * the eval tf.data.Dataset\n     * information about features: a python dictionary with feature names\n         as keys and an object as value that provides .shape and .num_classes.\n     * supervised_keys: information what's the input and what's the target,\n         ie., a pair of lists with input and target feature names.\n  \"\"\"\n  if dataset_name.startswith(\"v1_\"):\n    return _train_and_eval_dataset_v1(dataset_name[3:], data_dir)\n  dataset_builder = tfds.builder(dataset_name, data_dir=data_dir)\n  info = dataset_builder.info\n  splits = dataset_builder.info.splits\n  if tfds.Split.TRAIN not in splits:\n    raise ValueError(\"To train we require a train split in the dataset.\")\n  if tfds.Split.VALIDATION not in splits and \"test\" not in splits:\n    raise ValueError(\"We require a validation or test split in the dataset.\")\n  eval_split = tfds.Split.VALIDATION\n  if tfds.Split.VALIDATION not in splits:\n    eval_split = tfds.Split.TEST\n  train, valid = tfds.load(\n      name=dataset_name, split=[tfds.Split.TRAIN, eval_split])\n  keys = None\n  if info.supervised_keys:\n    keys = ([info.supervised_keys[0]], [info.supervised_keys[1]])\n  return train, valid, info.features, keys"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates an info - like tuple for feature given some shapes and vocab size.", "response": "def _make_info(shape_list, num_classes):\n  \"\"\"Create an info-like tuple for feature given some shapes and vocab size.\"\"\"\n  feature_info = collections.namedtuple(\"FeatureInfo\", [\"shape\", \"num_classes\"])\n  cur_shape = list(shape_list[0])\n  # We need to merge the provided shapes, put None where they disagree.\n  for shape in shape_list:\n    if len(shape) != len(cur_shape):\n      raise ValueError(\"Shapes need to have the same number of dimensions.\")\n    for i in range(len(shape)):\n      if cur_shape[i] is not None:\n        if shape[i] != cur_shape[i]:\n          cur_shape[i] = None\n  return feature_info(cur_shape, num_classes)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _select_features(example, feature_list=None):\n  feature_list = feature_list or [\"inputs\", \"targets\"]\n  return {f: example[f] for f in feature_list}", "response": "Select a subset of features from the example dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn train and evaluation datasets feature info and supervised keys.", "response": "def _train_and_eval_dataset_v1(problem_name, data_dir):\n  \"\"\"Return train and evaluation datasets, feature info and supervised keys.\"\"\"\n  problem = problems.problem(problem_name)\n  train_dataset = problem.dataset(tf.estimator.ModeKeys.TRAIN, data_dir)\n  train_dataset = train_dataset.map(_select_features)\n  eval_dataset = problem.dataset(tf.estimator.ModeKeys.EVAL, data_dir)\n  eval_dataset = eval_dataset.map(_select_features)\n  supervised_keys = ([\"inputs\"], [\"targets\"])\n  hparams = problem.get_hparams()\n  # We take a few training examples to guess the shapes.\n  input_shapes, target_shapes = [], []\n  for example in train_dataset.take(3):\n    input_shapes.append(example[\"inputs\"].shape.as_list())\n    target_shapes.append(example[\"targets\"].shape.as_list())\n  input_vocab_size = hparams.vocab_size[\"inputs\"]\n  target_vocab_size = hparams.vocab_size[\"targets\"]\n  input_info = _make_info(input_shapes, input_vocab_size)\n  target_info = _make_info(target_shapes, target_vocab_size)\n  info = {\"inputs\": input_info, \"targets\": target_info}\n  return train_dataset, eval_dataset, info, supervised_keys"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nshuffling and batch the given dataset.", "response": "def shuffle_and_batch_data(dataset, target_names, features_info, training):\n  \"\"\"Shuffle and batch the given dataset.\"\"\"\n  def append_targets(example):\n    \"\"\"Append targets to the example dictionary. Needed for Keras.\"\"\"\n    if len(target_names) == 1:\n      return (example, example[target_names[0]])\n    targets = {}\n    for name in target_names:\n      targets[name] = example[name]\n    return (example, targets)\n  dataset = dataset.map(append_targets)\n  if training:\n    dataset = dataset.repeat()\n  shapes = {k: features_info[k].shape for k in features_info}\n  shapes = (shapes, shapes[target_names[0]])\n  dataset = dataset.shuffle(128)\n  dataset = preprocess_fn(dataset, training)\n  dataset = batch_fn(dataset, training, shapes, target_names)\n  return dataset.prefetch(8)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncompiles the model in Keras.", "response": "def optimize_fn(model,\n                optimizer=None,\n                learning_rate_schedule=None,\n                loss=None,\n                metrics=None):\n  \"\"\"Compile the model in Keras.\"\"\"\n  learning_rate_schedule = learning_rate_schedule or T2TLearningRateSchedule()\n  if optimizer:\n    optimizer = optimizer(learning_rate=learning_rate_schedule)\n  else:  # We use Adam by default with adjusted parameters.\n    optimizer = tf.keras.optimizers.Adam(\n        learning_rate=learning_rate_schedule,\n        beta_1=0.9, beta_2=0.997, epsilon=1e-9)\n  metrics = metrics or [tf.keras.metrics.sparse_categorical_accuracy]\n  def xent_loss(y, x):\n    return tf.keras.backend.sparse_categorical_crossentropy(\n        y, x, from_logits=True)\n  loss = loss or xent_loss\n  return model.compile(optimizer=optimizer,\n                       loss=loss,\n                       metrics=metrics)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef train_fn(data_dir=None, output_dir=None,\n             model_class=gin.REQUIRED, dataset=gin.REQUIRED,\n             input_names=None, target_names=None,\n             train_steps=1000, eval_steps=1, eval_frequency=100):\n  \"\"\"Train the given model on the given dataset.\n\n  Args:\n    data_dir: Directory where the data is located.\n    output_dir: Directory where to put the logs and checkpoints.\n    model_class: The model class to train.\n    dataset: The name of the dataset to train on.\n    input_names: List of strings with the names of the features on input.\n    target_names: List of strings with the names of the target features.\n    train_steps: for how many steps to train.\n    eval_steps: for how many steps to do evaluation.\n    eval_frequency: how often (every this many steps) to run evaluation.\n  \"\"\"\n  train_data, eval_data, features_info, keys = train_and_eval_dataset(\n      dataset, data_dir)\n  if input_names is None:\n    input_names = keys[0]\n  if target_names is None:\n    target_names = keys[1]\n  # TODO(lukaszkaiser): The use of distribution strategy below fails like this:\n  #   .../keras/models.py\", line 93, in _clone_functional_model\n  #      for layer in model._input_layers:\n  #   AttributeError: 'BasicFcRelu' object has no attribute '_input_layers'\n  # strategy = tf.distribute.MirroredStrategy()\n  # with strategy.scope():\n  model = model_class(features_info=features_info,\n                      input_names=input_names, target_names=target_names)\n  optimize_fn(model)\n  train_batches = shuffle_and_batch_data(\n      train_data, target_names, features_info, training=True)\n  eval_batches = shuffle_and_batch_data(\n      eval_data, target_names, features_info, training=False)\n  # Need to run one training step just to get optimizer variables to load.\n  model.fit(train_batches, epochs=1, steps_per_epoch=1)\n\n  # Training loop.\n  callbacks = []\n  callbacks.append(tf.keras.callbacks.History())\n  callbacks.append(tf.keras.callbacks.BaseLogger())\n  last_epoch = 0\n  if output_dir is not None:\n    callbacks.append(tf.keras.callbacks.TensorBoard(log_dir=output_dir))\n    output_format = os.path.join(output_dir, \"model-{epoch:05d}\")\n    callbacks.append(tf.keras.callbacks.ModelCheckpoint(\n        filepath=output_format, save_weights_only=True))\n    checkpoints = tf.gfile.Glob(os.path.join(output_dir, \"model-*\"))\n    # Take basenames and strip the \"model-\" prefix.\n    checkpoints = [os.path.basename(ckpt)[6:] for ckpt in checkpoints]\n    # Get epoch numbers from the filenames and sort to obtain last epoch.\n    epoch_numbers = [int(ckpt[:5]) for ckpt in checkpoints if len(ckpt) > 4]\n    epoch_numbers.sort()\n    if epoch_numbers:\n      last_epoch = epoch_numbers[-1]\n      saved_path = os.path.join(output_dir, \"model-%05d\" % last_epoch)\n      model.load_weights(saved_path)\n  model.fit(train_batches,\n            epochs=train_steps // eval_frequency,\n            steps_per_epoch=eval_frequency,\n            validation_data=eval_batches,\n            validation_steps=eval_steps,\n            initial_epoch=last_epoch,\n            callbacks=callbacks)", "response": "Train the given model on the given dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef decode(estimator, hparams, decode_hp):\n  if FLAGS.decode_interactive:\n    if estimator.config.use_tpu:\n      raise ValueError(\"TPU can only decode from dataset.\")\n    decoding.decode_interactively(estimator, hparams, decode_hp,\n                                  checkpoint_path=FLAGS.checkpoint_path)\n  elif FLAGS.decode_from_file:\n    decoding.decode_from_file(estimator, FLAGS.decode_from_file, hparams,\n                              decode_hp, FLAGS.decode_to_file,\n                              checkpoint_path=FLAGS.checkpoint_path)\n    if FLAGS.checkpoint_path and FLAGS.keep_timestamp:\n      ckpt_time = os.path.getmtime(FLAGS.checkpoint_path + \".index\")\n      os.utime(FLAGS.decode_to_file, (ckpt_time, ckpt_time))\n  else:\n    decoding.decode_from_dataset(\n        estimator,\n        FLAGS.problem,\n        hparams,\n        decode_hp,\n        decode_to_file=FLAGS.decode_to_file,\n        dataset_split=\"test\" if FLAGS.eval_use_test_set else None,\n        checkpoint_path=FLAGS.checkpoint_path)", "response": "Decode from estimator. Interactive from file or from dataset."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef score_file(filename):\n  # Prepare model.\n  hparams = create_hparams()\n  encoders = registry.problem(FLAGS.problem).feature_encoders(FLAGS.data_dir)\n  has_inputs = \"inputs\" in encoders\n\n  # Prepare features for feeding into the model.\n  if has_inputs:\n    inputs_ph = tf.placeholder(dtype=tf.int32)  # Just length dimension.\n    batch_inputs = tf.reshape(inputs_ph, [1, -1, 1, 1])  # Make it 4D.\n  targets_ph = tf.placeholder(dtype=tf.int32)  # Just length dimension.\n  batch_targets = tf.reshape(targets_ph, [1, -1, 1, 1])  # Make it 4D.\n  if has_inputs:\n    features = {\"inputs\": batch_inputs, \"targets\": batch_targets}\n  else:\n    features = {\"targets\": batch_targets}\n\n  # Prepare the model and the graph when model runs on features.\n  model = registry.model(FLAGS.model)(hparams, tf.estimator.ModeKeys.EVAL)\n  _, losses = model(features)\n  saver = tf.train.Saver()\n\n  with tf.Session() as sess:\n    # Load weights from checkpoint.\n    if FLAGS.checkpoint_path is None:\n      ckpts = tf.train.get_checkpoint_state(FLAGS.output_dir)\n      ckpt = ckpts.model_checkpoint_path\n    else:\n      ckpt = FLAGS.checkpoint_path\n    saver.restore(sess, ckpt)\n    # Run on each line.\n    with tf.gfile.Open(filename) as f:\n      lines = f.readlines()\n    results = []\n    for line in lines:\n      tab_split = line.split(\"\\t\")\n      if len(tab_split) > 2:\n        raise ValueError(\"Each line must have at most one tab separator.\")\n      if len(tab_split) == 1:\n        targets = tab_split[0].strip()\n      else:\n        targets = tab_split[1].strip()\n        inputs = tab_split[0].strip()\n      # Run encoders and append EOS symbol.\n      targets_numpy = encoders[\"targets\"].encode(\n          targets) + [text_encoder.EOS_ID]\n      if has_inputs:\n        inputs_numpy = encoders[\"inputs\"].encode(inputs) + [text_encoder.EOS_ID]\n      # Prepare the feed.\n      if has_inputs:\n        feed = {inputs_ph: inputs_numpy, targets_ph: targets_numpy}\n      else:\n        feed = {targets_ph: targets_numpy}\n      # Get the score.\n      np_loss = sess.run(losses[\"training\"], feed)\n      results.append(np_loss)\n  return results", "response": "Score each line in a file and return the scores."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef time_to_channels(embedded_video):\n  video_shape = common_layers.shape_list(embedded_video)\n  if len(video_shape) != 5:\n    raise ValueError(\"Assuming videos given as tensors in the format \"\n                     \"[batch, time, height, width, channels] but got one \"\n                     \"of shape: %s\" % str(video_shape))\n  transposed = tf.transpose(embedded_video, [0, 2, 3, 1, 4])\n  return tf.reshape(transposed, [\n      video_shape[0], video_shape[2], video_shape[3],\n      video_shape[1] * video_shape[4]\n  ])", "response": "Put time dimension on channels in an embedded video."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef autoencoder_residual_text():\n  hparams = autoencoder_residual()\n  hparams.bottleneck_bits = 32\n  hparams.batch_size = 1024\n  hparams.hidden_size = 64\n  hparams.max_hidden_size = 512\n  hparams.bottleneck_noise = 0.0\n  hparams.bottom = {\n      \"inputs\": modalities.identity_bottom,\n      \"targets\": modalities.identity_bottom,\n  }\n  hparams.top = {\n      \"targets\": modalities.identity_top,\n  }\n  hparams.autoregressive_mode = \"none\"\n  hparams.sample_width = 1\n  return hparams", "response": "Residual autoencoder model for text."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\norders discrete autoencoder model.", "response": "def autoencoder_ordered_discrete():\n  \"\"\"Ordered discrete autoencoder model.\"\"\"\n  hparams = autoencoder_residual_discrete()\n  hparams.bottleneck_noise = 0.05  # Use 0.8 for ordered.\n  hparams.gan_loss_factor = 0.05\n  hparams.add_hparam(\"unordered\", True)\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef autoencoder_ordered_discrete_image64():\n  hparams = autoencoder_ordered_discrete()\n  hparams.batch_size = 32\n  hparams.num_hidden_layers = 6\n  hparams.bottleneck_warmup_steps *= 2\n  hparams.gan_codes_warmup_steps *= 2\n\n  return hparams", "response": "Ordered discrete autoencoder model."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef autoencoder_ordered_text():\n  hparams = autoencoder_ordered_discrete()\n  hparams.bottleneck_bits = 1024\n  hparams.bottleneck_shared_bits = 1024-64\n  hparams.bottleneck_shared_bits_start_warmup = 75000\n  hparams.bottleneck_shared_bits_stop_warmup = 275000\n  hparams.num_hidden_layers = 7\n  hparams.batch_size = 1024\n  hparams.autoregressive_mode = \"conv5\"\n  hparams.max_hidden_size = 1024\n  hparams.bottom = {\n      \"inputs\": modalities.identity_bottom,\n      \"targets\": modalities.identity_bottom,\n  }\n  hparams.top = {\n      \"targets\": modalities.identity_top,\n  }\n  hparams.sample_height = 128\n  hparams.sample_width = 1\n  return hparams", "response": "Ordered discrete autoencoder model for text."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef autoencoder_ordered_text_small():\n  hparams = autoencoder_ordered_text()\n  hparams.bottleneck_bits = 32\n  hparams.num_hidden_layers = 3\n  hparams.hidden_size = 64\n  hparams.max_hidden_size = 512\n  hparams.bottleneck_noise = 0.0\n  hparams.autoregressive_mode = \"conv5\"\n  hparams.sample_height = 4\n  return hparams", "response": "Ordered discrete autoencoder model for text small version."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef autoencoder_discrete_pong():\n  hparams = autoencoder_ordered_discrete()\n  hparams.num_hidden_layers = 3\n  hparams.bottleneck_bits = 24\n  hparams.batch_size = 2\n  hparams.gan_loss_factor = 0.01\n  hparams.bottleneck_l2_factor = 0.001\n  hparams.add_hparam(\"video_modality_loss_cutoff\", 0.02)\n  return hparams", "response": "Discrete autoencoder model for compressing pong frames."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef autoencoder_discrete_tiny():\n  hparams = autoencoder_ordered_discrete()\n  hparams.num_hidden_layers = 2\n  hparams.bottleneck_bits = 24\n  hparams.batch_size = 2\n  hparams.gan_loss_factor = 0.\n  hparams.bottleneck_l2_factor = 0.001\n  hparams.add_hparam(\"video_modality_loss_cutoff\", 0.02)\n  hparams.num_residual_layers = 1\n  hparams.hidden_size = 32\n  hparams.max_hidden_size = 64\n  return hparams", "response": "Discrete autoencoder model for compressing pong frames for testing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntuning grid of the main autoencoder params.", "response": "def autoencoder_range(rhp):\n  \"\"\"Tuning grid of the main autoencoder params.\"\"\"\n  rhp.set_float(\"dropout\", 0.01, 0.3)\n  rhp.set_float(\"gan_loss_factor\", 0.01, 0.1)\n  rhp.set_float(\"bottleneck_l2_factor\", 0.001, 0.1, scale=rhp.LOG_SCALE)\n  rhp.set_discrete(\"bottleneck_warmup_steps\", [200, 2000])\n  rhp.set_float(\"gumbel_temperature\", 0, 1)\n  rhp.set_float(\"gumbel_noise_factor\", 0, 0.5)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef image_encoder(image_feat,\n                  hparams,\n                  name=\"image_encoder\",\n                  save_weights_to=None,\n                  make_image_summary=True):\n  \"\"\"A stack of self attention layers.\"\"\"\n\n  x = image_feat\n  with tf.variable_scope(name):\n    for layer in range(hparams.num_encoder_layers or hparams.num_hidden_layers):\n      with tf.variable_scope(\"layer_%d\" % layer):\n        with tf.variable_scope(\"self_attention\"):\n          y = vqa_layers.multihead_attention(\n              common_layers.layer_preprocess(x, hparams),\n              None,\n              None,\n              hparams.attention_key_channels or hparams.image_hidden_size,\n              hparams.attention_value_channels or hparams.image_hidden_size,\n              hparams.image_hidden_size,\n              hparams.num_heads,\n              hparams.attention_dropout,\n              attention_type=hparams.self_attention_type,\n              save_weights_to=save_weights_to,\n              max_relative_position=None,\n              make_image_summary=make_image_summary,\n              dropout_broadcast_dims=None,\n              max_length=None,\n              vars_3d=False,\n              scale_otproduct=hparams.scale_dotproduct)\n          utils.collect_named_outputs(\"norms\", \"image_feat_self_attention\",\n                                      tf.norm(y, axis=-1))\n          x = common_layers.layer_postprocess(x, y, hparams)\n          utils.collect_named_outputs(\n              \"norms\", \"image_feat_self_attention_zero_add\",\n              tf.norm(x, axis=-1))\n        with tf.variable_scope(\"ffn\"):\n          y = common_layers.dense_relu_dense(\n              common_layers.layer_preprocess(x, hparams),\n              hparams.image_filter_size,\n              hparams.image_hidden_size,\n              dropout=hparams.relu_dropout,\n              dropout_broadcast_dims=None)\n          utils.collect_named_outputs(\"norms\", \"image_feat_ffn\",\n                                      tf.norm(y, axis=-1))\n          x = common_layers.layer_postprocess(x, y, hparams)\n          utils.collect_named_outputs(\"norms\", \"image_feat_ffn_zero_add\",\n                                      tf.norm(x, axis=-1))\n    # if normalization is done in layer_preprocess, then it should also be done\n    # on the output, since the output can grow very large, being the sum of\n    # a whole stack of unnormalized layer outputs.\n    return common_layers.layer_preprocess(x, hparams)", "response": "A stack of self - attention and fermipy - dense image encoder layers."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nquestions encoder, run LSTM encoder and get the last output as encoding.", "response": "def question_encoder(question, hparams, name=\"encoder\"):\n  \"\"\"Question encoder, run LSTM encoder and get the last output as encoding.\"\"\"\n  with tf.variable_scope(name, \"encoder\", values=[question]):\n    question = common_layers.flatten4d3d(question)\n    padding = common_attention.embedding_to_padding(question)\n    length = common_attention.padding_to_length(padding)\n\n    max_question_length = hparams.max_question_length\n    question = question[:, :max_question_length, :]\n    actual_question_length = common_layers.shape_list(question)[1]\n    length = tf.minimum(length, max_question_length)\n    padding = [[0, 0],\n               [0, max_question_length-actual_question_length],\n               [0, 0]]\n    question = tf.pad(question, padding)\n    question_shape = question.get_shape().as_list()\n    question_shape[1] = max_question_length\n    question.set_shape(question_shape)\n\n    # apply tanh dropout on question embedding\n    question = tf.tanh(question)\n    question = tf.nn.dropout(question, keep_prob=1.-hparams.dropout)\n\n    question = [question[:, i, :] for i in range(max_question_length)]\n\n    # rnn_layers = [_get_rnn_cell(hparams)\n    #               for _ in range(hparams.num_rnn_layers)]\n    # rnn_multi_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n    rnn_cell = _get_rnn_cell(hparams)\n    # outputs, _ = tf.nn.dynamic_rnn(\n    #     rnn_cell, question, length, dtype=tf.float32)\n    _, state = tf.nn.static_rnn(rnn_cell, question, sequence_length=length,\n                                dtype=tf.float32)\n    # outputs = [tf.expand_dims(output, axis=1) for output in outputs]\n    # outputs = tf.concat(outputs, axis=1)\n\n    # utils.collect_named_outputs(\"vqa_attention_debug\", \"question_output\",\n    #                             outputs)\n    # utils.collect_named_outputs(\"vqa_attention_debug\", \"question_state\",\n    #                             state.h)\n\n    # batch_size = common_layers.shape_list(outputs)[0]\n    # row_indices = tf.range(batch_size)\n    # # length - 1 as index\n    # indices = tf.transpose([row_indices, tf.maximum(length-1, 0)])\n    # last_output = tf.gather_nd(outputs, indices)\n\n    # utils.collect_named_outputs(\"vqa_attention_debug\",\n    #                             \"question_final_output\", last_output)\n\n  return state.h"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mlp(feature, hparams, name=\"mlp\"):\n  with tf.variable_scope(name, \"mlp\", values=[feature]):\n    num_mlp_layers = hparams.num_mlp_layers\n    mlp_dim = hparams.mlp_dim\n    for _ in range(num_mlp_layers):\n      feature = common_layers.dense(feature, mlp_dim, activation=tf.nn.relu)\n      feature = tf.nn.dropout(feature, keep_prob=1.-hparams.dropout)\n    return feature", "response": "Multi layer perceptron with dropout and relu activation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef vqa_attention_base():\n  hparams = common_hparams.basic_params1()\n  hparams.batch_size = 128\n  hparams.use_fixed_batch_size = True,\n  hparams.optimizer = \"adam\"\n  hparams.optimizer_adam_beta1 = 0.9\n  hparams.optimizer_adam_beta2 = 0.999\n  hparams.optimizer_adam_epsilon = 1e-8\n  hparams.weight_decay = 0.\n  hparams.clip_grad_norm = 0.\n  hparams.initializer = \"xavier\"\n  hparams.learning_rate = 0.5\n  hparams.learning_rate_schedule = \"legacy\"\n  hparams.learning_rate_warmup_steps = 0\n  hparams.learning_rate_decay_scheme = \"exp\"\n  hparams.learning_rate_decay_rate = 0.5\n  hparams.learning_rate_decay_steps = 50000\n  hparams.dropout = 0.5\n  hparams.summarize_grads = True\n  hparams.summarize_vars = True\n\n  # not used hparams\n  hparams.label_smoothing = 0.\n  hparams.multiply_embedding_mode = \"\"\n\n  # add new hparams\n  # preprocess\n  hparams.add_hparam(\"resize_side\", 512)\n  hparams.add_hparam(\"height\", 448)\n  hparams.add_hparam(\"width\", 448)\n  hparams.add_hparam(\"distort\", True)\n\n  hparams.add_hparam(\"train_resnet\", False)\n  hparams.add_hparam(\"rnn_type\", \"lstm\")\n  hparams.add_hparam(\"num_rnn_layers\", 1)\n  hparams.add_hparam(\"max_question_length\", 15)\n  # lstm hidden size\n  hparams.hidden_size = 512\n\n  hparams.add_hparam(\"attn_dim\", 512)\n  hparams.add_hparam(\"num_glimps\", 2)\n\n  hparams.add_hparam(\"num_mlp_layers\", 1)\n  hparams.add_hparam(\"mlp_dim\", 1024)\n\n  hparams.add_hparam(\"image_input_type\", \"image\")\n  hparams.add_hparam(\"image_model_fn\", \"resnet_v1_152\")\n  hparams.add_hparam(\"image_feat_size\", 0)\n\n  # self attention parts\n  hparams.norm_type = \"layer\"\n  hparams.layer_preprocess_sequence = \"n\"\n  hparams.layer_postprocess_sequence = \"da\"\n  hparams.layer_prepostprocess_dropout = 0.3\n  hparams.attention_dropout = 0.1\n  hparams.relu_dropout = 0.1\n  hparams.image_hidden_size = 2048\n  hparams.add_hparam(\"num_encoder_layers\", 1)\n  # Attention-related flags.\n  hparams.add_hparam(\"num_heads\", 8)\n  hparams.add_hparam(\"attention_key_channels\", 0)\n  hparams.add_hparam(\"attention_value_channels\", 0)\n  hparams.add_hparam(\"image_filter_size\", 1024)\n  hparams.add_hparam(\"self_attention_type\", \"dot_product\")\n  hparams.add_hparam(\"scale_dotproduct\", True)\n\n  return hparams", "response": "VQA attention base hparams."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef vqa_attention_base_range(rhp):\n  # After starting from base, set intervals for some parameters.\n  rhp.set_float(\"learning_rate\", 0.1, 1.0, scale=rhp.LOG_SCALE)\n  rhp.set_float(\"clip_grad_norm\", 0.1, 10, scale=rhp.LOG_SCALE)\n  rhp.set_discrete(\"batch_size\", [128, 256, 512, 1024])\n  rhp.set_float(\"weight_decay\", 0.0, 1e-4)\n  rhp.set_categorical(\"rnn_type\", [\"lstm\", \"lstm_layernorm\"])", "response": "Small range of hyperparameters for attention base."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nappending a pair to the history for the given mode and metric.", "response": "def append(self, mode, metric, step, value):\n    \"\"\"Append (step, value) pair to history for the given mode and metric.\"\"\"\n    if mode not in self._values:\n      self._values[mode] = collections.defaultdict(list)\n    self._values[mode][metric].append((step, value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the history for the given metric and mode.", "response": "def get(self, mode, metric):\n    \"\"\"Get the history for the given metric and mode.\"\"\"\n    if mode not in self._values:\n      logging.info(\"Metric %s not found for mode %s\", metric, mode)\n      return []\n    return list(self._values[mode][metric])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef metrics_for_mode(self, mode):\n    if mode not in self._values:\n      logging.info(\"Mode %s not found\", mode)\n      return []\n    return sorted(list(self._values[mode].keys()))", "response": "Returns a list of metrics available for a given mode."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming a batch normalization followed by a ReLU.", "response": "def batch_norm_relu(inputs,\n                    is_training,\n                    relu=True,\n                    init_zero=False,\n                    data_format=\"channels_first\"):\n  \"\"\"Performs a batch normalization followed by a ReLU.\n\n  Args:\n    inputs: `Tensor` of shape `[batch, channels, ...]`.\n    is_training: `bool` for whether the model is training.\n    relu: `bool` if False, omits the ReLU operation.\n    init_zero: `bool` if True, initializes scale parameter of batch\n        normalization with 0 instead of 1 (default).\n    data_format: `str` either \"channels_first\" for `[batch, channels, height,\n        width]` or \"channels_last for `[batch, height, width, channels]`.\n\n  Returns:\n    A normalized `Tensor` with the same `data_format`.\n  \"\"\"\n  if init_zero:\n    gamma_initializer = tf.zeros_initializer()\n  else:\n    gamma_initializer = tf.ones_initializer()\n\n  if data_format == \"channels_first\":\n    axis = 1\n  else:\n    axis = 3\n\n  inputs = layers().BatchNormalization(\n      axis=axis,\n      momentum=BATCH_NORM_DECAY,\n      epsilon=BATCH_NORM_EPSILON,\n      center=True,\n      scale=True,\n      fused=True,\n      gamma_initializer=gamma_initializer)(inputs, training=is_training)\n\n  if relu:\n    inputs = tf.nn.relu(inputs)\n  return inputs"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstrides 2 - D convolution with explicit padding.", "response": "def conv2d_fixed_padding(inputs,\n                         filters,\n                         kernel_size,\n                         strides,\n                         data_format=\"channels_first\",\n                         use_td=False,\n                         targeting_rate=None,\n                         keep_prob=None,\n                         is_training=None):\n  \"\"\"Strided 2-D convolution with explicit padding.\n\n  The padding is consistent and is based only on `kernel_size`, not on the\n  dimensions of `inputs` (as opposed to using `tf.layers.conv2d` alone).\n\n  Args:\n    inputs: `Tensor` of size `[batch, channels, height_in, width_in]`.\n    filters: `int` number of filters in the convolution.\n    kernel_size: `int` size of the kernel to be used in the convolution.\n    strides: `int` strides of the convolution.\n    data_format: `str` either \"channels_first\" for `[batch, channels, height,\n        width]` or \"channels_last for `[batch, height, width, channels]`.\n    use_td: `str` one of \"weight\" or \"unit\". Set to False or \"\" to disable\n      targeted dropout.\n    targeting_rate: `float` proportion of weights to target with targeted\n      dropout.\n    keep_prob: `float` keep probability for targeted dropout.\n    is_training: `bool` for whether the model is in training.\n\n  Returns:\n    A `Tensor` of shape `[batch, filters, height_out, width_out]`.\n\n  Raises:\n    Exception: if use_td is not valid.\n  \"\"\"\n  if strides > 1:\n    inputs = fixed_padding(inputs, kernel_size, data_format=data_format)\n\n  if use_td:\n    inputs_shape = common_layers.shape_list(inputs)\n    if use_td == \"weight\":\n      if data_format == \"channels_last\":\n        size = kernel_size * kernel_size * inputs_shape[-1]\n      else:\n        size = kernel_size * kernel_size * inputs_shape[1]\n      targeting_count = targeting_rate * tf.to_float(size)\n      targeting_fn = common_layers.weight_targeting\n    elif use_td == \"unit\":\n      targeting_count = targeting_rate * filters\n      targeting_fn = common_layers.unit_targeting\n    else:\n      raise Exception(\"Unrecognized targeted dropout type: %s\" % use_td)\n\n    y = common_layers.td_conv(\n        inputs,\n        filters,\n        kernel_size,\n        targeting_count,\n        targeting_fn,\n        keep_prob,\n        is_training,\n        do_prune=True,\n        strides=strides,\n        padding=(\"SAME\" if strides == 1 else \"VALID\"),\n        data_format=data_format,\n        use_bias=False,\n        kernel_initializer=tf.variance_scaling_initializer())\n  else:\n    y = layers().Conv2D(\n        filters=filters,\n        kernel_size=kernel_size,\n        strides=strides,\n        padding=(\"SAME\" if strides == 1 else \"VALID\"),\n        use_bias=False,\n        kernel_initializer=tf.variance_scaling_initializer(),\n        data_format=data_format)(inputs)\n\n  return y"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef residual_block(inputs,\n                   filters,\n                   is_training,\n                   projection_shortcut,\n                   strides,\n                   final_block,\n                   data_format=\"channels_first\",\n                   use_td=False,\n                   targeting_rate=None,\n                   keep_prob=None):\n  \"\"\"Standard building block for residual networks with BN before convolutions.\n\n  Args:\n    inputs: `Tensor` of size `[batch, channels, height, width]`.\n    filters: `int` number of filters for the first two convolutions. Note that\n        the third and final convolution will use 4 times as many filters.\n    is_training: `bool` for whether the model is in training.\n    projection_shortcut: `function` to use for projection shortcuts (typically\n        a 1x1 convolution to match the filter dimensions). If None, no\n        projection is used and the input is passed as unchanged through the\n        shortcut connection.\n    strides: `int` block stride. If greater than 1, this block will ultimately\n        downsample the input.\n    final_block: unused parameter to keep the same function signature as\n        `bottleneck_block`.\n    data_format: `str` either \"channels_first\" for `[batch, channels, height,\n        width]` or \"channels_last for `[batch, height, width, channels]`.\n    use_td: `str` one of \"weight\" or \"unit\". Set to False or \"\" to disable\n      targeted dropout.\n    targeting_rate: `float` proportion of weights to target with targeted\n      dropout.\n    keep_prob: `float` keep probability for targeted dropout.\n\n  Returns:\n    The output `Tensor` of the block.\n  \"\"\"\n  del final_block\n  shortcut = inputs\n  inputs = batch_norm_relu(inputs, is_training, data_format=data_format)\n\n  if projection_shortcut is not None:\n    shortcut = projection_shortcut(inputs)\n\n  inputs = conv2d_fixed_padding(\n      inputs=inputs,\n      filters=filters,\n      kernel_size=3,\n      strides=strides,\n      data_format=data_format,\n      use_td=use_td,\n      targeting_rate=targeting_rate,\n      keep_prob=keep_prob,\n      is_training=is_training)\n\n  inputs = batch_norm_relu(inputs, is_training, data_format=data_format)\n  inputs = conv2d_fixed_padding(\n      inputs=inputs,\n      filters=filters,\n      kernel_size=3,\n      strides=1,\n      data_format=data_format,\n      use_td=use_td,\n      targeting_rate=targeting_rate,\n      keep_prob=keep_prob,\n      is_training=is_training)\n\n  return inputs + shortcut", "response": "Standard build block for residual networks with BN before convolutions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbottlenecking block variant for residual networks with BN after convolutions.", "response": "def bottleneck_block(inputs,\n                     filters,\n                     is_training,\n                     projection_shortcut,\n                     strides,\n                     final_block,\n                     data_format=\"channels_first\",\n                     use_td=False,\n                     targeting_rate=None,\n                     keep_prob=None):\n  \"\"\"Bottleneck block variant for residual networks with BN after convolutions.\n\n  Args:\n    inputs: `Tensor` of size `[batch, channels, height, width]`.\n    filters: `int` number of filters for the first two convolutions. Note that\n        the third and final convolution will use 4 times as many filters.\n    is_training: `bool` for whether the model is in training.\n    projection_shortcut: `function` to use for projection shortcuts (typically\n        a 1x1 convolution to match the filter dimensions). If None, no\n        projection is used and the input is passed as unchanged through the\n        shortcut connection.\n    strides: `int` block stride. If greater than 1, this block will ultimately\n        downsample the input.\n    final_block: `bool` set to True if it is this the final block in the group.\n        This is changes the behavior of batch normalization initialization for\n        the final batch norm in a block.\n    data_format: `str` either \"channels_first\" for `[batch, channels, height,\n        width]` or \"channels_last for `[batch, height, width, channels]`.\n    use_td: `str` one of \"weight\" or \"unit\". Set to False or \"\" to disable\n      targeted dropout.\n    targeting_rate: `float` proportion of weights to target with targeted\n      dropout.\n    keep_prob: `float` keep probability for targeted dropout.\n\n  Returns:\n    The output `Tensor` of the block.\n  \"\"\"\n  # TODO(chrisying): this block is technically the post-activation resnet-v1\n  # bottleneck unit. Test with v2 (pre-activation) and replace if there is no\n  # difference for consistency.\n  shortcut = inputs\n  if projection_shortcut is not None:\n    shortcut = projection_shortcut(inputs)\n\n  inputs = conv2d_fixed_padding(\n      inputs=inputs,\n      filters=filters,\n      kernel_size=1,\n      strides=1,\n      data_format=data_format,\n      use_td=use_td,\n      targeting_rate=targeting_rate,\n      keep_prob=keep_prob,\n      is_training=is_training)\n\n  inputs = batch_norm_relu(inputs, is_training, data_format=data_format)\n  inputs = conv2d_fixed_padding(\n      inputs=inputs,\n      filters=filters,\n      kernel_size=3,\n      strides=strides,\n      data_format=data_format,\n      use_td=use_td,\n      targeting_rate=targeting_rate,\n      keep_prob=keep_prob,\n      is_training=is_training)\n\n  inputs = batch_norm_relu(inputs, is_training, data_format=data_format)\n  inputs = conv2d_fixed_padding(\n      inputs=inputs,\n      filters=4 * filters,\n      kernel_size=1,\n      strides=1,\n      data_format=data_format,\n      use_td=use_td,\n      targeting_rate=targeting_rate,\n      keep_prob=keep_prob,\n      is_training=is_training)\n  inputs = batch_norm_relu(\n      inputs,\n      is_training,\n      relu=False,\n      init_zero=final_block,\n      data_format=data_format)\n\n  return tf.nn.relu(inputs + shortcut)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef block_layer(inputs,\n                filters,\n                block_fn,\n                blocks,\n                strides,\n                is_training,\n                name,\n                data_format=\"channels_first\",\n                use_td=False,\n                targeting_rate=None,\n                keep_prob=None):\n  \"\"\"Creates one layer of blocks for the ResNet model.\n\n  Args:\n    inputs: `Tensor` of size `[batch, channels, height, width]`.\n    filters: `int` number of filters for the first convolution of the layer.\n    block_fn: `function` for the block to use within the model\n    blocks: `int` number of blocks contained in the layer.\n    strides: `int` stride to use for the first convolution of the layer. If\n        greater than 1, this layer will downsample the input.\n    is_training: `bool` for whether the model is training.\n    name: `str`name for the Tensor output of the block layer.\n    data_format: `str` either \"channels_first\" for `[batch, channels, height,\n        width]` or \"channels_last for `[batch, height, width, channels]`.\n    use_td: `str` one of \"weight\" or \"unit\". Set to False or \"\" to disable\n      targeted dropout.\n    targeting_rate: `float` proportion of weights to target with targeted\n      dropout.\n    keep_prob: `float` keep probability for targeted dropout.\n\n  Returns:\n    The output `Tensor` of the block layer.\n  \"\"\"\n  # Bottleneck blocks end with 4x the number of filters as they start with\n  filters_out = 4 * filters if block_fn is bottleneck_block else filters\n\n  def projection_shortcut(inputs):\n    \"\"\"Project identity branch.\"\"\"\n    inputs = conv2d_fixed_padding(\n        inputs=inputs,\n        filters=filters_out,\n        kernel_size=1,\n        strides=strides,\n        data_format=data_format,\n        use_td=use_td,\n        targeting_rate=targeting_rate,\n        keep_prob=keep_prob,\n        is_training=is_training)\n    return batch_norm_relu(\n        inputs, is_training, relu=False, data_format=data_format)\n\n  # Only the first block per block_layer uses projection_shortcut and strides\n  inputs = block_fn(\n      inputs,\n      filters,\n      is_training,\n      projection_shortcut,\n      strides,\n      False,\n      data_format,\n      use_td=use_td,\n      targeting_rate=targeting_rate,\n      keep_prob=keep_prob)\n\n  for i in range(1, blocks):\n    inputs = block_fn(\n        inputs,\n        filters,\n        is_training,\n        None,\n        1, (i + 1 == blocks),\n        data_format,\n        use_td=use_td,\n        targeting_rate=targeting_rate,\n        keep_prob=keep_prob)\n\n  return tf.identity(inputs, name)", "response": "Creates a block layer for the ResNet model."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resnet_v2(inputs,\n              block_fn,\n              layer_blocks,\n              filters,\n              data_format=\"channels_first\",\n              is_training=False,\n              is_cifar=False,\n              use_td=False,\n              targeting_rate=None,\n              keep_prob=None):\n  \"\"\"Resnet model.\n\n  Args:\n    inputs: `Tensor` images.\n    block_fn: `function` for the block to use within the model. Either\n        `residual_block` or `bottleneck_block`.\n    layer_blocks: list of 3 or 4 `int`s denoting the number of blocks to include\n      in each of the 3 or 4 block groups. Each group consists of blocks that\n      take inputs of the same resolution.\n    filters: list of 4 or 5 `int`s denoting the number of filter to include in\n      block.\n    data_format: `str`, \"channels_first\" `[batch, channels, height,\n        width]` or \"channels_last\" `[batch, height, width, channels]`.\n    is_training: bool, build in training mode or not.\n    is_cifar: bool, whether the data is CIFAR or not.\n    use_td: `str` one of \"weight\" or \"unit\". Set to False or \"\" to disable\n      targeted dropout.\n    targeting_rate: `float` proportion of weights to target with targeted\n      dropout.\n    keep_prob: `float` keep probability for targeted dropout.\n\n  Returns:\n    Pre-logit activations.\n  \"\"\"\n  inputs = block_layer(\n      inputs=inputs,\n      filters=filters[1],\n      block_fn=block_fn,\n      blocks=layer_blocks[0],\n      strides=1,\n      is_training=is_training,\n      name=\"block_layer1\",\n      data_format=data_format,\n      use_td=use_td,\n      targeting_rate=targeting_rate,\n      keep_prob=keep_prob)\n  inputs = block_layer(\n      inputs=inputs,\n      filters=filters[2],\n      block_fn=block_fn,\n      blocks=layer_blocks[1],\n      strides=2,\n      is_training=is_training,\n      name=\"block_layer2\",\n      data_format=data_format,\n      use_td=use_td,\n      targeting_rate=targeting_rate,\n      keep_prob=keep_prob)\n  inputs = block_layer(\n      inputs=inputs,\n      filters=filters[3],\n      block_fn=block_fn,\n      blocks=layer_blocks[2],\n      strides=2,\n      is_training=is_training,\n      name=\"block_layer3\",\n      data_format=data_format,\n      use_td=use_td,\n      targeting_rate=targeting_rate,\n      keep_prob=keep_prob)\n  if not is_cifar:\n    inputs = block_layer(\n        inputs=inputs,\n        filters=filters[4],\n        block_fn=block_fn,\n        blocks=layer_blocks[3],\n        strides=2,\n        is_training=is_training,\n        name=\"block_layer4\",\n        data_format=data_format,\n        use_td=use_td,\n        targeting_rate=targeting_rate,\n        keep_prob=keep_prob)\n\n  return inputs", "response": "Resnet model for v2."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting of hyperparameters for Theta - Weight 5. 5.", "response": "def resnet_imagenet_34_td_weight_05_05():\n  \"\"\"Set of hyperparameters.\"\"\"\n  hp = resnet_imagenet_34()\n  hp.use_td = \"weight\"\n  hp.targeting_rate = 0.5\n  hp.keep_prob = 0.5\n\n  return hp"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets of hyperparameters for Theta Unit 5. 5.", "response": "def resnet_imagenet_34_td_unit_05_05():\n  \"\"\"Set of hyperparameters.\"\"\"\n  hp = resnet_imagenet_34()\n  hp.use_td = \"unit\"\n  hp.targeting_rate = 0.5\n  hp.keep_prob = 0.5\n\n  return hp"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resnet_imagenet_34_td_unit_no_drop():\n  hp = resnet_imagenet_34()\n  hp.use_td = \"unit\"\n  hp.targeting_rate = 0.0\n  hp.keep_prob = 1.0\n\n  return hp", "response": "Set of hyperparameters for unit use."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets of hyperparameters for CIFAR 15.", "response": "def resnet_cifar_15():\n  \"\"\"Set of hyperparameters.\"\"\"\n  hp = resnet_base()\n  hp.block_fn = \"residual\"\n  hp.is_cifar = True\n  hp.layer_sizes = [2, 2, 2]\n  hp.filter_sizes = [16, 32, 64, 128]\n\n  return hp"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the length of the Longest Common Subsequence between two sequences.", "response": "def _len_lcs(x, y):\n  \"\"\"Returns the length of the Longest Common Subsequence between two seqs.\n\n  Source: http://www.algorithmist.com/index.php/Longest_Common_Subsequence\n\n  Args:\n    x: sequence of words\n    y: sequence of words\n\n  Returns\n    integer: Length of LCS between x and y\n  \"\"\"\n  table = _lcs(x, y)\n  n, m = len(x), len(y)\n  return table[n, m]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the length of the LCS between two sequences.", "response": "def _lcs(x, y):\n  \"\"\"Computes the length of the LCS between two seqs.\n\n  The implementation below uses a DP programming algorithm and runs\n  in O(nm) time where n = len(x) and m = len(y).\n  Source: http://www.algorithmist.com/index.php/Longest_Common_Subsequence\n\n  Args:\n    x: collection of words\n    y: collection of words\n\n  Returns:\n    Table of dictionary of coord and len lcs\n  \"\"\"\n  n, m = len(x), len(y)\n  table = {}\n  for i in range(n + 1):\n    for j in range(m + 1):\n      if i == 0 or j == 0:\n        table[i, j] = 0\n      elif x[i - 1] == y[j - 1]:\n        table[i, j] = table[i - 1, j - 1] + 1\n      else:\n        table[i, j] = max(table[i - 1, j], table[i, j - 1])\n  return table"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rouge_l_sentence_level(eval_sentences, ref_sentences):\n\n  f1_scores = []\n  for eval_sentence, ref_sentence in zip(eval_sentences, ref_sentences):\n    m = len(ref_sentence)\n    n = len(eval_sentence)\n    lcs = _len_lcs(eval_sentence, ref_sentence)\n    f1_scores.append(_f_lcs(lcs, m, n))\n  return np.mean(f1_scores, dtype=np.float32)", "response": "Calculates ROUGE - L sentence level of two collections of sentences."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrouges scores computation between labels and predictions.", "response": "def rouge_l_fscore(predictions, labels, **unused_kwargs):\n  \"\"\"ROUGE scores computation between labels and predictions.\n\n  This is an approximate ROUGE scoring method since we do not glue word pieces\n  or decode the ids and tokenize the output.\n\n  Args:\n    predictions: tensor, model predictions\n    labels: tensor, gold output.\n\n  Returns:\n    rouge_l_fscore: approx rouge-l f1 score.\n  \"\"\"\n  outputs = tf.to_int32(tf.argmax(predictions, axis=-1))\n  # Convert the outputs and labels to a [batch_size, input_length] tensor.\n  outputs = tf.squeeze(outputs, axis=[-1, -2])\n  labels = tf.squeeze(labels, axis=[-1, -2])\n  rouge_l_f_score = tf.py_func(rouge_l_sentence_level, (outputs, labels),\n                               tf.float32)\n  return rouge_l_f_score, tf.constant(1.0)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_ngrams(n, text):\n  ngram_set = set()\n  text_length = len(text)\n  max_index_ngram_start = text_length - n\n  for i in range(max_index_ngram_start + 1):\n    ngram_set.add(tuple(text[i:i + n]))\n  return ngram_set", "response": "Calculates n - grams in a set of tokens."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rouge_2_fscore(predictions, labels, **unused_kwargs):\n\n  outputs = tf.to_int32(tf.argmax(predictions, axis=-1))\n  # Convert the outputs and labels to a [batch_size, input_length] tensor.\n  outputs = tf.squeeze(outputs, axis=[-1, -2])\n  labels = tf.squeeze(labels, axis=[-1, -2])\n  rouge_2_f_score = tf.py_func(rouge_n, (outputs, labels), tf.float32)\n  return rouge_2_f_score, tf.constant(1.0)", "response": "ROUGE - 2 F1 score computation between labels and predictions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nnormalizing the examples from different tasks so they can be merged. This function is specific to NLP tasks and normalizes them so that in the end the example only has \"targets\" and \"task_id\". For tasks that originally have inputs, this is done by appending task_id to the inputs and prepending targets, so normalized_targets = inputs task_id targets. For classification tasks, targets are constructed by spelling out the class. Args: task: the Problem class of the task we are normalizing. example: a dictionary of tensors, the example to normalize. is_infer: bool, whether we are performing inference or not. vocab_type: the type of vocabulary in use. vocab_offset: integer, offset index for subword vocabularies. max_input_length: maximum length to cut inputs to. max_target_length: maximum length to cut targets to. fixed_train_length: set length to this size if > 0. Returns: a dictionary of tensors, like example, after normalizing, which in this case means that it only has \"targets\" and \"task_id\" as feature.", "response": "def normalize_example_nlp(task, example, is_infer, vocab_type, vocab_offset,\n                          max_input_length, max_target_length,\n                          fixed_train_length):\n  \"\"\"Normalize the examples from different tasks so they can be merged.\n\n  This function is specific to NLP tasks and normalizes them so that in the\n  end the example only has \"targets\" and \"task_id\". For tasks that originally\n  have inputs, this is done by appending task_id to the inputs and prepending\n  targets, so normalized_targets = inputs task_id targets. For classification\n  tasks, targets are constructed by spelling out the class.\n\n  Args:\n    task: the Problem class of the task we are normalizing.\n    example: a dictionary of tensors, the example to normalize.\n    is_infer: bool, whether we are performing inference or not.\n    vocab_type: the type of vocabulary in use.\n    vocab_offset: integer, offset index for subword vocabularies.\n    max_input_length: maximum length to cut inputs to.\n    max_target_length: maximum length to cut targets to.\n    fixed_train_length: set length to this size if > 0.\n\n  Returns:\n    a dictionary of tensors, like example, after normalizing, which in this\n    case means that it only has \"targets\" and \"task_id\" as feature.\n  \"\"\"\n  if task.has_inputs:\n    example[\"inputs\"] = example[\"inputs\"][:-1]  # remove EOS token\n\n  if hasattr(task, \"class_labels\"):\n    if vocab_type == text_problems.VocabType.CHARACTER:\n      # TODO(urvashik): handle the case where num_labels > 9\n      example[\"targets\"] = tf.cast(discretization.int_to_bit(\n          example[\"targets\"], 1, base=10) + 50, tf.int64)\n      example[\"targets\"] = tf.squeeze(example[\"targets\"], axis=[-1])\n    elif vocab_type == text_problems.VocabType.SUBWORD:\n      example[\"targets\"] = vocab_offset + example[\"targets\"]\n  else:\n    # sequence with inputs and targets eg: summarization\n    if task.has_inputs:\n      if max_input_length > 0:\n        example[\"inputs\"] = example[\"inputs\"][:max_input_length]\n      # Do not truncate targets during inference with beam decoding.\n      if max_target_length > 0 and not is_infer:\n        example[\"targets\"] = example[\"targets\"][:max_target_length]\n\n  def make_constant_shape(x, size):\n    x = x[:size]\n    xlen = tf.shape(x)[0]\n    x = tf.pad(x, [[0, size - xlen]])\n    return tf.reshape(x, [size])\n\n  if task.has_inputs:\n    if is_infer:\n      concat_list = [example[\"inputs\"], [task.task_id]]\n      example[\"inputs\"] = tf.concat(concat_list, axis=0)\n    else:\n      inputs = example.pop(\"inputs\")\n      concat_list = [inputs, [task.task_id], example[\"targets\"]]\n      example[\"targets\"] = tf.concat(concat_list, axis=0)\n      if fixed_train_length > 0:\n        example[\"targets\"] = make_constant_shape(\n            example[\"targets\"], fixed_train_length)\n  else:\n    concat_list = [[task.task_id], example[\"targets\"]]\n    example[\"targets\"] = tf.concat(concat_list, axis=0)\n    if not is_infer and fixed_train_length > 0:\n      example[\"targets\"] = make_constant_shape(\n          example[\"targets\"], fixed_train_length)\n\n  example[\"task_id\"] = tf.constant([task.task_id], dtype=tf.int64)\n  return example"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef flatten_zip_dataset(*args):\n  flattened = tf.data.Dataset.from_tensors(args[0])\n  for ex in args[1:]:\n    flattened = flattened.concatenate(tf.data.Dataset.from_tensors(ex))\n  return flattened", "response": "A list of examples to a dataset containing mixed examples."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef aggregate_task_lm_losses(hparams,\n                             problem_hparams,\n                             logits,\n                             feature_name,\n                             feature):\n  \"\"\"LM loss for multiproblems.\"\"\"\n  summaries = []\n  vocab_size = problem_hparams.vocab_size[feature_name]\n  if vocab_size is not None and hasattr(hparams, \"vocab_divisor\"):\n    vocab_size += (-vocab_size) % hparams.vocab_divisor\n  modality = problem_hparams.modality[feature_name]\n  loss = hparams.loss.get(feature_name, modalities.get_loss(modality))\n  weights_fn = hparams.weights_fn.get(\n      feature_name, modalities.get_weights_fn(modality))\n  loss_num = 0.\n  loss_den = 0.\n  for task in hparams.problem.task_list:\n    loss_num_, loss_den_ = loss(\n        logits, feature,\n        lambda x: common_layers.weights_multi_problem_all(x, task.task_id),  # pylint: disable=cell-var-from-loop\n        hparams, vocab_size, weights_fn)\n\n    loss_num += loss_num_\n    loss_den += loss_den_\n\n    loss_val = loss_num_ / tf.maximum(1.0, loss_den_)\n    summaries.append([task.name+\"_loss\", loss_val])\n\n  return loss_num, loss_den, summaries", "response": "Aggregate LM loss for multiproblems."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef normalize_example(self, task, example, encoder, hparams, is_infer):\n    # Here we use the default function for NLP tasks that makes everything\n    # a part of \"targets\" feature. Override in your subclasses for other uses.\n    vocab_offset = encoder.vocab_size + len(self.task_list)\n    return normalize_example_nlp(\n        task, example, is_infer, self.vocab_type, vocab_offset,\n        hparams.multiproblem_max_input_length,\n        hparams.multiproblem_max_target_length,\n        hparams.multiproblem_fixed_train_length)", "response": "Normalize the examples from different tasks so they can be merged."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_task_ids(self, encoder_vocab_size):\n    for idx, task in enumerate(self.task_list):\n      task.set_task_id(idx + encoder_vocab_size)\n      tf.logging.info(\"Task %d (%s) has id %d.\" %\n                      (idx, task.name, task.task_id))", "response": "Generate task_ids for each problem."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_max_num_classes(self):\n    num = 0\n    for task in self.task_list:\n      if hasattr(task, \"num_classes\"):\n        if num < task.num_classes:\n          num = task.num_classes\n\n    return num", "response": "Compute the maximum number of classes any subtask has."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling prior to self - attention to incorporate memory items.", "response": "def pre_attention(self, segment, query_antecedent, memory_antecedent, bias):\n    \"\"\"Called prior to self-attention, to incorporate memory items.\n\n    Args:\n      segment: an integer Tensor with shape [batch]\n      query_antecedent: a Tensor with shape [batch, length_q, channels]\n      memory_antecedent: must be None. Attention normally allows this to be a\n        Tensor with shape [batch, length_m, channels], but we currently only\n        support memory for decoder-side self-attention.\n      bias: bias Tensor (see attention_bias())\n    Returns:\n      (data, new_query_antecedent, new_memory_antecedent, new_bias)\n    \"\"\"\n    del segment\n    return None, query_antecedent, memory_antecedent, bias"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pre_attention(self, segment, query_antecedent, memory_antecedent, bias):\n    assert memory_antecedent is None, \"We only support language modeling\"\n\n    # In eval mode, batch size may be variable\n    memory_batch_size = tf.shape(self.previous_vals)[0]\n    current_batch_size = tf.shape(query_antecedent)[0]\n    amount_to_pad = memory_batch_size - current_batch_size\n\n    # If segment id is zero, don't attend back to the memory\n    previous_bias = self.previous_bias[:current_batch_size, :, :, :] + tf.cast(\n        tf.equal(segment[:, None, None, None], 0), tf.float32) * -1e9\n\n    sliced_previous_vals = self.previous_vals[:current_batch_size, :, :]\n\n    new_memory_antecedent = tf.concat(\n        [tf.stop_gradient(sliced_previous_vals), query_antecedent], 1)\n    new_bias = tf.concat([\n        tf.tile(tf.stop_gradient(previous_bias), [1, 1, self.chunk_length, 1]),\n        tf.tile(bias, [current_batch_size, 1, 1, 1]),\n    ], -1)\n\n    remember_segment = tf.pad(segment, [[0, amount_to_pad]])\n    # TODO(kitaev): The code assumes that we always either increment the chunk\n    # number or reset it to zero. This assumption will not hold if we re-run the\n    # model for each token, e.g. for autoregressive greedy/beam/sampling decode.\n    remember_vals = tf.pad(query_antecedent,\n                           [[0, amount_to_pad], [0, 0], [0, 0]])\n    # Query position is on axis -2 for bias: as long as a token can be attended\n    # to from at least one query position (i.e. it's not padding), memorize it.\n    remember_bias = tf.tile(\n        tf.reduce_max(bias, -2, keepdims=True), [memory_batch_size, 1, 1, 1])\n    # Assume that query_antecedent is always a full chunk (i.e. not truncated)\n    if self.chunk_length < self.tokens_to_cache:\n      remember_vals = tf.concat([self.previous_vals, remember_vals], 1)\n      remember_bias = tf.concat([\n          self.previous_bias - 1e9 * tf.cast(\n              tf.equal(\n                  tf.pad(segment, [[0, amount_to_pad]])[:, None, None, None],\n                  0), tf.float32),\n          remember_bias\n      ], -1)\n    if self.chunk_length != self.tokens_to_cache:\n      remember_vals = remember_vals[:, -self.tokens_to_cache:, :]\n      remember_bias = remember_bias[:, :, :, -self.tokens_to_cache:]\n    token = (remember_segment, remember_vals, remember_bias)\n\n    return token, query_antecedent, new_memory_antecedent, new_bias", "response": "Called before self - attention to incorporate memory items."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef post_attention(self, token, x):\n    with tf.control_dependencies([\n        self.previous_segment.assign(token[0]),\n        self.previous_vals.assign(token[1]),\n        self.previous_bias.assign(token[2]),\n        ]):\n      return tf.identity(x)", "response": "Called after self - attention."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the safe norm.", "response": "def _norm(self, x):\n    \"\"\"Compute the safe norm.\"\"\"\n    return tf.sqrt(tf.reduce_sum(tf.square(x), keepdims=True, axis=-1) + 1e-7)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _address_content(self, x):\n    mem_keys = tf.layers.dense(self.mem_vals, self.key_depth,\n                               bias_initializer=tf.constant_initializer(1.0),\n                               name=\"mem_key\")\n    mem_query = tf.layers.dense(x, self.key_depth,\n                                bias_initializer=tf.constant_initializer(1.0),\n                                name=\"mem_query\")\n    norm = tf.matmul(self._norm(mem_query), self._norm(mem_keys),\n                     transpose_b=True)\n    dot_product = tf.matmul(mem_query, mem_keys, transpose_b=True)\n    cos_dist = tf.div(dot_product, norm + 1e-7, name=\"cos_dist\")\n    access_logits = self.sharpen_factor * cos_dist\n    return access_logits", "response": "Address the memory based on content similarity."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(self, x):\n    access_logits = self._address_content(x)\n    weights = tf.nn.softmax(access_logits)\n    retrieved_mem = tf.reduce_sum(\n        tf.multiply(tf.expand_dims(weights, 3),\n                    tf.expand_dims(self.mem_vals, axis=1)), axis=2)\n    return access_logits, retrieved_mem", "response": "Read from the memory."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write(self, x, access_logits):\n    gamma = tf.layers.dense(x, 1, activation=tf.sigmoid, name=\"gamma\")\n    write_logits = access_logits - gamma * tf.expand_dims(self.mean_logits, 1)\n    candidate_value = tf.layers.dense(x, self.val_depth,\n                                      activation=tf.nn.relu,\n                                      name=\"candidate_value\")\n    erase_gates = tf.layers.dense(x, self.memory_size,\n                                  activation=tf.nn.sigmoid,\n                                  name=\"erase\")\n    write_weights = tf.nn.softmax(write_logits)\n    erase_weights = tf.expand_dims(1 - erase_gates * write_weights, 3)\n    erase = tf.multiply(erase_weights,\n                        tf.expand_dims(self.mem_vals, 1))\n    addition = tf.multiply(\n        tf.expand_dims(write_weights, 3),\n        tf.expand_dims(candidate_value, 2))\n    update_value_op = self.mem_vals.assign(\n        tf.reduce_mean(erase + addition, axis=1))\n    with tf.control_dependencies([update_value_op]):\n      write_op = self.mean_logits.assign(\n          self.mean_logits * 0.1 + tf.reduce_mean(write_logits * 0.9, axis=1))\n      return write_op", "response": "Writes to the memory based on a combination of similarity and least used."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreset the entries in the memory.", "response": "def reset(self, entries_to_reset):\n    \"\"\"Reset the entries in the memory.\n\n    Args:\n      entries_to_reset: a 1D tensor.\n    Returns:\n      the reset op.\n    \"\"\"\n    num_updates = tf.size(entries_to_reset)\n    update_vals = tf.scatter_update(\n        self.mem_vals, entries_to_reset,\n        tf.tile(tf.expand_dims(\n            tf.fill([self.memory_size, self.val_depth], .0), 0),\n                [num_updates, 1, 1]))\n    update_logits = tf.scatter_update(\n        self.mean_logits, entries_to_reset,\n        tf.tile(tf.expand_dims(\n            tf.fill([self.memory_size], .0), 0),\n                [num_updates, 1]))\n    reset_op = tf.group([update_vals, update_logits])\n    return reset_op"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pre_attention(self, segment_number, query_antecedent,\n                    memory_antecedent, bias):\n    \"\"\"Called prior to self-attention, to incorporate memory items.\n\n    Args:\n      segment_number: an integer Tensor with shape [batch]\n      query_antecedent: a Tensor with shape [batch, length_q, channels]\n      memory_antecedent: must be None. Attention normally allows this to be a\n        Tensor with shape [batch, length_m, channels], but we currently only\n        support memory for decoder-side self-attention.\n      bias: bias Tensor (see attention_bias())\n    Returns:\n      (data, new_query_antecedent, new_memory_antecedent, new_bias)\n    \"\"\"\n    with tf.variable_scope(self.name + \"/pre_attention\", reuse=tf.AUTO_REUSE):\n      assert memory_antecedent is None, \"We only support language modeling\"\n      with tf.control_dependencies([\n          tf.assert_greater_equal(self.batch_size, tf.size(segment_number))]):\n        difference = self.batch_size - tf.size(segment_number)\n        segment_number = tf.pad(segment_number, [[0, difference]])\n        reset_op = self.reset(tf.reshape(tf.where(\n            tf.less(segment_number, self.segment_number)), [-1]))\n      memory_results = {}\n      with tf.control_dependencies([reset_op]):\n        with tf.control_dependencies([\n            self.update_segment_number(segment_number)]):\n          x = tf.pad(query_antecedent, [\n              [0, difference], [0, 0], [0, 0]])\n          access_logits, retrieved_mem = self.read(x)\n      memory_results[\"x\"] = x\n      memory_results[\"access_logits\"] = access_logits\n      memory_results[\"retrieved_mem\"] = retrieved_mem\n      return memory_results, query_antecedent, memory_antecedent, bias", "response": "Called prior to self - attention to incorporate memory items."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall after self - attention.", "response": "def post_attention(self, token, x):\n    \"\"\"Called after self-attention. The memory can be updated here.\n\n    Args:\n      token: Data returned by pre_attention, which can be used to carry over\n        state related to the current memory operation.\n      x: a Tensor of data after self-attention and feed-forward\n    Returns:\n      a (possibly modified) version of the input x\n    \"\"\"\n    with tf.variable_scope(self.name + \"/post_attention\", reuse=tf.AUTO_REUSE):\n      depth = common_layers.shape_list(x)[-1]\n      actual_batch_size = common_layers.shape_list(x)[0]\n      memory_output = tf.gather(token[\"retrieved_mem\"],\n                                tf.range(actual_batch_size))\n      output = tf.add(tf.layers.dense(x, depth, use_bias=False),\n                      tf.layers.dense(memory_output, depth))\n      with tf.control_dependencies([output]):\n        with tf.control_dependencies([\n            self.write(token[\"x\"], token[\"access_logits\"])]):\n          return tf.identity(output)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndefining the training setup.", "response": "def _define_train(\n    train_env,\n    ppo_hparams,\n    eval_env_fn=None,\n    sampling_temp=1.0,\n    **collect_kwargs\n):\n  \"\"\"Define the training setup.\"\"\"\n  memory, collect_summary, train_initialization = (\n      _define_collect(\n          train_env,\n          ppo_hparams,\n          \"ppo_train\",\n          eval_phase=False,\n          sampling_temp=sampling_temp,\n          **collect_kwargs))\n  ppo_summary = ppo.define_ppo_epoch(\n      memory, ppo_hparams, train_env.action_space, train_env.batch_size)\n  train_summary = tf.summary.merge([collect_summary, ppo_summary])\n\n  if ppo_hparams.eval_every_epochs:\n    # TODO(koz4k): Do we need this at all?\n    assert eval_env_fn is not None\n    eval_env = eval_env_fn(in_graph=True)\n    (_, eval_collect_summary, eval_initialization) = (\n        _define_collect(\n            eval_env,\n            ppo_hparams,\n            \"ppo_eval\",\n            eval_phase=True,\n            sampling_temp=0.0,\n            **collect_kwargs))\n    return (train_summary, eval_collect_summary, (train_initialization,\n                                                  eval_initialization))\n  else:\n    return (train_summary, None, (train_initialization,))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _define_collect(batch_env, ppo_hparams, scope, frame_stack_size, eval_phase,\n                    sampling_temp, force_beginning_resets):\n  \"\"\"Collect trajectories.\n\n  Args:\n    batch_env: Batch environment.\n    ppo_hparams: PPO hparams, defined in tensor2tensor.models.research.rl.\n    scope: var scope.\n    frame_stack_size: Number of last observations to feed into the policy.\n    eval_phase: TODO(koz4k): Write docstring.\n    sampling_temp: Sampling temperature for the policy.\n    force_beginning_resets: Whether to reset at the beginning of each episode.\n\n  Returns:\n    Returns memory (observations, rewards, dones, actions,\n    pdfs, values_functions)\n    containing a rollout of environment from nested wrapped structure.\n  \"\"\"\n  epoch_length = ppo_hparams.epoch_length\n\n  to_initialize = []\n  with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n    num_agents = batch_env.batch_size\n\n    to_initialize.append(batch_env)\n    wrappers = [(StackWrapper, {\n        \"history\": frame_stack_size\n    }), (_MemoryWrapper, {})]\n    rollout_metadata = None\n    speculum = None\n    for w in wrappers:\n      tf.logging.info(\"Applying wrapper %s(%s) to env %s.\" % (str(\n          w[0]), str(w[1]), str(batch_env)))\n      batch_env = w[0](batch_env, **w[1])\n      to_initialize.append(batch_env)\n\n    rollout_metadata = _rollout_metadata(batch_env)\n    speculum = batch_env.speculum\n\n    def initialization_lambda(sess):\n      for batch_env in to_initialize:\n        batch_env.initialize(sess)\n\n    memory = [\n        tf.get_variable(  # pylint: disable=g-complex-comprehension\n            \"collect_memory_%d_%s\" % (epoch_length, name),\n            shape=[epoch_length] + shape,\n            dtype=dtype,\n            initializer=tf.zeros_initializer(),\n            trainable=False) for (shape, dtype, name) in rollout_metadata\n    ]\n\n    cumulative_rewards = tf.get_variable(\n        \"cumulative_rewards\", len(batch_env), trainable=False)\n\n    eval_phase_t = tf.convert_to_tensor(eval_phase)\n    should_reset_var = tf.Variable(True, trainable=False)\n    zeros_tensor = tf.zeros(len(batch_env))\n\n  force_beginning_resets = tf.convert_to_tensor(force_beginning_resets)\n\n  def reset_ops_group():\n    return tf.group(\n        batch_env.reset(tf.range(len(batch_env))),\n        tf.assign(cumulative_rewards, zeros_tensor))\n\n  reset_op = tf.cond(\n      tf.logical_or(should_reset_var.read_value(), force_beginning_resets),\n      reset_ops_group, tf.no_op)\n\n  with tf.control_dependencies([reset_op]):\n    reset_once_op = tf.assign(should_reset_var, False)\n\n  with tf.control_dependencies([reset_once_op]):\n\n    def step(index, scores_sum, scores_num):\n      \"\"\"Single step.\"\"\"\n      index %= epoch_length  # Only needed in eval runs.\n      # Note - the only way to ensure making a copy of tensor is to run simple\n      # operation. We are waiting for tf.copy:\n      # https://github.com/tensorflow/tensorflow/issues/11186\n      obs_copy = batch_env.observ + 0\n\n      def env_step(arg1, arg2, arg3):  # pylint: disable=unused-argument\n        \"\"\"Step of the environment.\"\"\"\n\n        (logits, value_function) = get_policy(\n            obs_copy, ppo_hparams, batch_env.action_space\n        )\n        action = common_layers.sample_with_temperature(logits, sampling_temp)\n        action = tf.cast(action, tf.int32)\n        action = tf.reshape(action, shape=(num_agents,))\n\n        reward, done = batch_env.simulate(action)\n\n        pdf = tfp.distributions.Categorical(logits=logits).prob(action)\n        pdf = tf.reshape(pdf, shape=(num_agents,))\n        value_function = tf.reshape(value_function, shape=(num_agents,))\n        done = tf.reshape(done, shape=(num_agents,))\n\n        with tf.control_dependencies([reward, done]):\n          return tf.identity(pdf), tf.identity(value_function), \\\n                 tf.identity(done)\n\n      # TODO(piotrmilos): while_body is executed at most once,\n      # thus should be replaced with tf.cond\n      pdf, value_function, top_level_done = tf.while_loop(\n          lambda _1, _2, _3: tf.equal(speculum.size(), 0),\n          env_step,\n          [\n              tf.constant(0.0, shape=(num_agents,)),\n              tf.constant(0.0, shape=(num_agents,)),\n              tf.constant(False, shape=(num_agents,))\n          ],\n          parallel_iterations=1,\n          back_prop=False,\n      )\n\n      with tf.control_dependencies([pdf, value_function]):\n        obs, reward, done, action = speculum.dequeue()\n\n        to_save = [obs, reward, done, action, pdf, value_function]\n        save_ops = [\n            tf.scatter_update(memory_slot, index, value)\n            for memory_slot, value in zip(memory, to_save)\n        ]\n        cumulate_rewards_op = cumulative_rewards.assign_add(reward)\n\n        agent_indices_to_reset = tf.where(top_level_done)[:, 0]\n      with tf.control_dependencies([cumulate_rewards_op]):\n        # TODO(piotrmilos): possibly we need cumulative_rewards.read_value()\n        scores_sum_delta = tf.reduce_sum(\n            tf.gather(cumulative_rewards.read_value(), agent_indices_to_reset))\n        scores_num_delta = tf.count_nonzero(done, dtype=tf.int32)\n      with tf.control_dependencies(save_ops +\n                                   [scores_sum_delta, scores_num_delta]):\n        reset_env_op = batch_env.reset(agent_indices_to_reset)\n        reset_cumulative_rewards_op = tf.scatter_update(\n            cumulative_rewards, agent_indices_to_reset,\n            tf.gather(zeros_tensor, agent_indices_to_reset))\n      with tf.control_dependencies([reset_env_op, reset_cumulative_rewards_op]):\n        return [\n            index + 1, scores_sum + scores_sum_delta,\n            scores_num + scores_num_delta\n        ]\n\n    def stop_condition(i, _, resets):\n      return tf.cond(eval_phase_t, lambda: resets < num_agents,\n                     lambda: i < epoch_length)\n\n    init = [tf.constant(0), tf.constant(0.0), tf.constant(0)]\n    index, scores_sum, scores_num = tf.while_loop(\n        stop_condition, step, init, parallel_iterations=1, back_prop=False)\n\n  # We handle force_beginning_resets differently. We assume that all envs are\n  # reseted at the end of episod (though it happens at the beginning of the\n  # next one\n  scores_num = tf.cond(force_beginning_resets,\n                       lambda: scores_num + len(batch_env), lambda: scores_num)\n\n  with tf.control_dependencies([scores_sum]):\n    scores_sum = tf.cond(\n        force_beginning_resets,\n        lambda: scores_sum + tf.reduce_sum(cumulative_rewards.read_value()),\n        lambda: scores_sum)\n\n  mean_score = tf.cond(\n      tf.greater(scores_num, 0),\n      lambda: scores_sum / tf.cast(scores_num, tf.float32), lambda: 0.)\n  printing = tf.Print(0, [mean_score, scores_sum, scores_num], \"mean_score: \")\n  with tf.control_dependencies([index, printing]):\n    memory = [mem.read_value() for mem in memory]\n    # When generating real data together with PPO training we must use single\n    # agent. For PPO to work we reshape the history, as if it was generated\n    # by real_ppo_effective_num_agents.\n    if ppo_hparams.effective_num_agents is not None and not eval_phase:\n      new_memory = []\n      effective_num_agents = ppo_hparams.effective_num_agents\n      assert epoch_length % ppo_hparams.effective_num_agents == 0, (\n          \"The rollout of ppo_hparams.epoch_length will be distributed amongst\"\n          \"effective_num_agents of agents\")\n      new_epoch_length = int(epoch_length / effective_num_agents)\n      for mem, info in zip(memory, rollout_metadata):\n        shape, _, name = info\n        new_shape = [effective_num_agents, new_epoch_length] + shape[1:]\n        perm = list(range(len(shape) + 1))\n        perm[0] = 1\n        perm[1] = 0\n        mem = tf.transpose(mem, perm=perm)\n        mem = tf.reshape(mem, shape=new_shape)\n        mem = tf.transpose(\n            mem,\n            perm=perm,\n            name=\"collect_memory_%d_%s\" % (new_epoch_length, name))\n        new_memory.append(mem)\n      memory = new_memory\n\n    with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n      mean_score_summary = tf.cond(\n          tf.greater(scores_num, 0),\n          lambda: tf.summary.scalar(\"mean_score_this_iter\", mean_score), str)\n      summaries = tf.summary.merge([\n          mean_score_summary,\n          tf.summary.scalar(\"episodes_finished_this_iter\", scores_num)\n      ])\n      return memory, summaries, initialization_lambda", "response": "Define the collect trajectories."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sliced_gan():\n  hparams = common_hparams.basic_params1()\n  hparams.optimizer = \"adam\"\n  hparams.learning_rate_constant = 0.0002\n  hparams.learning_rate_warmup_steps = 500\n  hparams.learning_rate_schedule = \"constant * linear_warmup\"\n  hparams.label_smoothing = 0.0\n  hparams.batch_size = 128\n  hparams.hidden_size = 128\n  hparams.initializer = \"uniform_unit_scaling\"\n  hparams.initializer_gain = 1.0\n  hparams.weight_decay = 1e-6\n  hparams.kernel_height = 4\n  hparams.kernel_width = 4\n  hparams.bottleneck_bits = 128\n  hparams.add_hparam(\"discriminator_batchnorm\", True)\n  hparams.add_hparam(\"num_sliced_vecs\", 4096)\n  return hparams", "response": "Basic parameters for a vanilla_gan."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef discriminator(self, x, is_training, reuse=False):\n    hparams = self.hparams\n    with tf.variable_scope(\n        \"discriminator\", reuse=reuse,\n        initializer=tf.random_normal_initializer(stddev=0.02)):\n      batch_size, height, width = common_layers.shape_list(x)[:3]\n      # Mapping x from [bs, h, w, c] to [bs, 1]\n      net = tf.layers.conv2d(x, 64, (4, 4), strides=(2, 2),\n                             padding=\"SAME\", name=\"d_conv1\")\n      # [bs, h/2, w/2, 64]\n      net = lrelu(net)\n      net = tf.layers.conv2d(net, 128, (4, 4), strides=(2, 2),\n                             padding=\"SAME\", name=\"d_conv2\")\n      # [bs, h/4, w/4, 128]\n      if hparams.discriminator_batchnorm:\n        net = tf.layers.batch_normalization(net, training=is_training,\n                                            momentum=0.999, name=\"d_bn2\")\n      net = lrelu(net)\n      size = height * width\n      net = tf.reshape(net, [batch_size, size * 8])  # [bs, h * w * 8]\n      net = tf.layers.dense(net, 1024, name=\"d_fc3\")  # [bs, 1024]\n      if hparams.discriminator_batchnorm:\n        net = tf.layers.batch_normalization(net, training=is_training,\n                                            momentum=0.999, name=\"d_bn3\")\n      net = lrelu(net)\n      return net", "response": "Discriminator architecture based on InfoGAN."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef body(self, features):\n    features[\"targets\"] = features[\"inputs\"]\n    is_training = self.hparams.mode == tf.estimator.ModeKeys.TRAIN\n\n    # Input images.\n    inputs = tf.to_float(features[\"targets_raw\"])\n\n    # Noise vector.\n    z = tf.random_uniform([self.hparams.batch_size,\n                           self.hparams.bottleneck_bits],\n                          minval=-1, maxval=1, name=\"z\")\n\n    # Generator output: fake images.\n    out_shape = common_layers.shape_list(inputs)[1:4]\n    g = self.generator(z, is_training, out_shape)\n\n    losses = self.losses(inputs, g)  # pylint: disable=not-callable\n\n    summary_g_image = tf.reshape(\n        g[0, :], [1] + common_layers.shape_list(inputs)[1:])\n    tf.summary.image(\"generated\", summary_g_image, max_outputs=1)\n\n    if is_training:  # Returns an dummy output and the losses dictionary.\n      return tf.zeros_like(inputs), losses\n    return tf.reshape(g, tf.shape(inputs)), losses", "response": "The body of the model."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates Inputs for built - in datasets.", "response": "def inputs(num_devices, dataset_name, data_dir=None, input_name=None,\n           num_chunks=0, append_targets=False):\n  \"\"\"Make Inputs for built-in datasets.\n\n  Args:\n    num_devices: how many devices to build the inputs for.\n    dataset_name: a TFDS or T2T dataset name. If it's a T2T dataset name, prefix\n      with \"t2t_\".\n    data_dir: data directory.\n    input_name: optional, name of the inputs from the dictionary.\n    num_chunks: optional, into how many pieces should we chunk (large inputs).\n    append_targets: optional, instead of inputs return a pair (inputs, targets)\n      which is useful for autoregressive models.\n\n  Returns:\n    trax.inputs.Inputs\n  \"\"\"\n  assert data_dir, \"Must provide a data directory\"\n  data_dir = os.path.expanduser(data_dir)\n\n  (train_batches, train_eval_batches, eval_batches,\n   input_name, input_shape) = _train_and_eval_batches(\n       dataset_name, data_dir, input_name, num_devices)\n\n  def numpy_stream(dataset):\n    return dataset_to_stream(\n        dataset, input_name,\n        num_chunks=num_chunks, append_targets=append_targets)\n\n  if num_chunks > 0:\n    length = input_shape[0]\n    input_shape = tuple(\n        [tuple([length // num_chunks] + list(input_shape)[1:])] * num_chunks)\n\n  return Inputs(train_stream=lambda: numpy_stream(train_batches),\n                train_eval_stream=lambda: numpy_stream(train_eval_batches),\n                eval_stream=lambda: numpy_stream(eval_batches),\n                input_shape=input_shape)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef random_inputs(\n    num_devices,\n    input_shape=gin.REQUIRED, input_dtype=np.int32, input_range=(0, 255),\n    output_shape=gin.REQUIRED, output_dtype=np.int32, output_range=(0, 9)):\n  \"\"\"Make random Inputs for debugging.\n\n  Args:\n    num_devices: how many devices to build the inputs for.\n    input_shape: the shape of inputs (including batch dimension).\n    input_dtype: the type of the inputs (int32 by default).\n    input_range: the range of inputs (defaults to (0, 255)).\n    output_shape: the shape of outputs (including batch dimension).\n    output_dtype: the type of the outputs (int32 by default).\n    output_range: the range of outputs (defaults to (0, 9)).\n\n  Returns:\n    trax.inputs.Inputs\n  \"\"\"\n  if input_shape[0] % num_devices != 0:\n    tf.logging.fatal(\n        \"num_devices[%d] should divide the first dimension of input_shape[%s]\",\n        num_devices, input_shape)\n  if output_shape[0] % num_devices != 0:\n    tf.logging.fatal(\n        \"num_devices[%d] should divide the first dimension of output_shape[%s]\",\n        num_devices, output_shape)\n\n  def random_minibatches():\n    \"\"\"Generate a stream of random mini-batches.\"\"\"\n    if input_dtype in [np.float16, np.float32, np.float64]:\n      rand = np.random.uniform\n    else:\n      rand = np.random.random_integers\n    while True:\n      inp = rand(input_range[0], input_range[1], input_shape)\n      inp = inp.astype(input_dtype)\n      out = rand(output_range[0], output_range[1], output_shape)\n      out = out.astype(output_dtype)\n      yield inp, out\n\n  input_shape_without_batch = list(input_shape)[1:]\n  return Inputs(train_stream=random_minibatches,\n                train_eval_stream=random_minibatches,\n                eval_stream=random_minibatches,\n                input_shape=input_shape_without_batch)", "response": "Generate random inputs for debugging."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dataset_to_stream(dataset, input_name, num_chunks=0, append_targets=False):\n  for example in tfds.as_numpy(dataset):\n    inp, out = example[0][input_name], example[1]\n    if len(out.shape) > 1 and out.shape[-1] == 1:\n      out = np.squeeze(out, axis=-1)\n    if num_chunks > 0:\n      inp = np.split(inp, num_chunks, axis=1)\n      out = np.split(out, num_chunks, axis=1)\n    if append_targets:\n      inp = (inp, out)\n    yield inp, out", "response": "Takes a tf. Dataset and creates a numpy stream of ready batches."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _train_and_eval_dataset_v1(problem_name, data_dir):\n  assert not tf.executing_eagerly(), \"tf.eager mode must be turned off.\"\n  problem = t2t_problems.problem(problem_name)\n  train_dataset = problem.dataset(tf.estimator.ModeKeys.TRAIN, data_dir)\n  train_dataset = train_dataset.map(_select_features)\n  eval_dataset = problem.dataset(tf.estimator.ModeKeys.EVAL, data_dir)\n  eval_dataset = eval_dataset.map(_select_features)\n  hparams = problem.get_hparams()\n  # We take a few training examples to guess the shapes.\n  input_shapes, target_shapes = [], []\n  example_tensor = train_dataset.make_one_shot_iterator().get_next()\n  sess = tf.Session()\n  example1 = sess.run(example_tensor)\n  example2 = sess.run(example_tensor)\n  example3 = sess.run(example_tensor)\n  # We use \"inputs\" as input except for purely auto-regressive tasks like\n  # language models where \"targets\" are used as input_key.\n  input_key = \"inputs\" if \"inputs\" in example1 else \"targets\"\n  supervised_keys = ([input_key], [\"targets\"])\n  for example in [example1, example2, example3]:\n    input_shapes.append(list(example[input_key].shape))\n    target_shapes.append(list(example[\"targets\"].shape))\n  input_vocab_size = hparams.vocab_size[input_key]\n  target_vocab_size = hparams.vocab_size[\"targets\"]\n  input_info = _make_info(input_shapes, input_vocab_size)\n  target_info = _make_info(target_shapes, target_vocab_size)\n  info = {input_key: input_info, \"targets\": target_info}\n  return train_dataset, eval_dataset, info, supervised_keys", "response": "Return train and evaluation datasets feature info and supervised keys."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nshuffles and batch the given dataset.", "response": "def shuffle_and_batch_data(dataset,\n                           target_names,\n                           features_info,\n                           training,\n                           num_devices,\n                           shuffle_buffer_size=1024,\n                           preprocess_fun=no_preprocess):\n  \"\"\"Shuffle and batch the given dataset.\"\"\"\n  def append_targets(example):\n    \"\"\"Append targets to the example dictionary. Needed for Keras.\"\"\"\n    if len(target_names) == 1:\n      return (example, example[target_names[0]])\n    targets = {}\n    for name in target_names:\n      targets[name] = example[name]\n    return (example, targets)\n  dataset = dataset.map(append_targets)\n  if training:\n    dataset = dataset.repeat()\n    # Skip a random fraction at the beginning of the stream.  The skip is\n    # essential for synchronous highly-parallel training to avoid multiple\n    # replicas reading the same data in lock-step.\n    dataset = dataset.skip(random.randint(0, _MAX_SKIP_EXAMPLES))\n  dataset = preprocess_fun(dataset, training)\n  shapes = {k: features_info[k].shape for k in features_info}\n  shapes = (shapes, shapes[target_names[0]])\n  dataset = dataset.shuffle(shuffle_buffer_size)\n  dataset = batch_fun(dataset, training, shapes, target_names, num_devices)\n  return dataset.prefetch(2)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _train_and_eval_batches(dataset, data_dir, input_name, num_devices):\n  (train_data, eval_data, features_info, keys) = train_and_eval_dataset(\n      dataset, data_dir)\n  input_names, target_names = keys[0], keys[1]\n  train_batches = shuffle_and_batch_data(\n      train_data, target_names, features_info, training=True,\n      num_devices=num_devices)\n  train_eval_batches = shuffle_and_batch_data(  # Data for eval-on-train.\n      train_data, target_names, features_info, training=False,\n      num_devices=num_devices)\n  eval_batches = shuffle_and_batch_data(\n      eval_data, target_names, features_info, training=False,\n      num_devices=num_devices)\n  input_name = input_name or input_names[0]\n  input_shape = features_info[input_name].shape\n  return (train_batches, train_eval_batches, eval_batches,\n          input_name, list(input_shape))", "response": "Return train and eval batches with input name and shape."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_multi_dataset(datasets, pmf=None):\n  pmf = tf.fill([len(datasets)], 1.0 / len(datasets)) if pmf is None else pmf\n  samplers = [d.repeat().make_one_shot_iterator().get_next for d in datasets]\n  sample = lambda _: categorical_case(pmf, samplers)\n  return tf.data.Dataset.from_tensors([]).repeat().map(sample)", "response": "Returns a Dataset that samples records from one or more Datasets."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_schedule_distribution(schedule, global_step=None):\n  interpolation, steps, pmfs = schedule\n  if len(pmfs) == 1:\n    # py_func doesn't seem to work on TPU - at least get the constant case to\n    # run.\n    # TODO(noam): get the general case working.\n    return pmfs[0]\n  if global_step is None:\n    global_step = tf.train.get_or_create_global_step()\n  if interpolation == 'step':\n    interpolation_fn = step_interpolation\n  elif interpolation == 'linear':\n    interpolation_fn = linear_interpolation\n  else:\n    raise ValueError('Invalid interpolation strategy: %s' % interpolation)\n  return tf.reshape(\n      tf.py_func(\n          func=lambda x: interpolation_fn(x, np.array(steps), np.array(pmfs)),\n          inp=[global_step], Tout=tf.float32), [len(pmfs[0])])", "response": "Computes the pmf of a schedule given the global_step."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the outputs of fns with probability pmf.", "response": "def categorical_case(pmf, fns, rand=None):\n  \"\"\"Returns the outputs of fns[i] with probability pmf[i].\n\n  Args:\n    pmf: A 1-D tensor of probabilities, the probability mass function.\n    fns: A list of callables that return tensors, same length as pmf.\n    rand: An optional scalar between 0.0 and 1.0, the output of an RNG.\n\n  Returns:\n    A tensor, the output of fns[i] with probability pmf[i].\n  \"\"\"\n  rand = tf.random_uniform([]) if rand is None else rand\n  cmf = tf.pad(tf.cumsum(pmf), [(1, 0)])\n  cmf = [cmf[i] for i in range(len(fns) + 1)]\n  preds = [(rand >= a) & (rand < b) for a, b in zip(cmf[:-1], cmf[1:])]\n  return tf.case(list(zip(preds, fns)), exclusive=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef step_interpolation(x, xp, fp, **kwargs):\n  del kwargs  # Unused.\n  xp = np.expand_dims(xp, -1)\n  lower, upper = xp[:-1], xp[1:]\n  conditions = (x >= lower) & (x < upper)\n  # Underflow and overflow conditions and values. Values default to fp[0] and\n  # fp[-1] respectively.\n  conditions = np.concatenate([[x < xp[0]], conditions, [x >= xp[-1]]])\n  values = np.concatenate([[fp[0]], fp])\n  assert np.all(np.sum(conditions, 0) == 1), 'xp must be increasing.'\n  indices = np.argmax(conditions, 0)\n  return values[indices].astype(np.float32)", "response": "Multi - dimensional step interpolation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a probability - mass - function based on relative epoch rates.", "response": "def epoch_rates_to_pmf(problems, epoch_rates=None):\n  \"\"\"Create a probability-mass-function based on relative epoch rates.\n\n  if epoch_rates=None, then we use uniform epoch rates [1.0] * len(problems)\n  i.e. it takes each problem the same time to go through one epoch.\n\n  If epoch_rates is given, then these are the relative numbers of epochs\n  of each problem to go through in a given amount of time.\n\n  Each must have problem.num_training_examples implemented.\n\n  Args:\n    problems: a list of Problem instances.\n    epoch_rates: an optional list of float\n\n  Returns:\n    a list of floating point values.\n  \"\"\"\n  if epoch_rates is None:\n    epoch_rates = [1.0] * len(problems)\n  example_rates = [epoch_rate * p.num_training_examples\n                   for p, epoch_rate in zip(problems, epoch_rates)]\n  return example_rates_to_pmf(example_rates)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encode_schedule(schedule):\n  interpolation, steps, pmfs = schedule\n  return interpolation + ' ' + ' '.join(\n      '@' + str(s) + ' ' + ' '.join(map(str, p)) for s, p in zip(steps, pmfs))", "response": "Encodes a schedule tuple into a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decode_schedule(string):\n  splits = string.split()\n  steps = [int(x[1:]) for x in splits[1:] if x[0] == '@']\n  pmfs = np.reshape(\n      [float(x) for x in splits[1:] if x[0] != '@'], [len(steps), -1])\n  return splits[0], tuplize(steps), tuplize(pmfs)", "response": "Decodes a string into a schedule tuple."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tuplize(nested):\n  if isinstance(nested, str):\n    return nested\n  try:\n    return tuple(map(tuplize, nested))\n  except TypeError:\n    return nested", "response": "Recursively converts iterables into tuples."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filepattern(self, *args, **kwargs):\n    return [p.filepattern(*args, **kwargs) for p in self.problems]", "response": "Returns a list of filepatterns one for each problem."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_data(self, *args, **kwargs):\n    for p in self.problems:\n      p.generate_data(*args, **kwargs)", "response": "Generates data for each problem."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dataset containing examples from multiple problems.", "response": "def dataset(self, mode, hparams=None, global_step=None, **kwargs):\n    \"\"\"Returns a dataset containing examples from multiple problems.\n\n    Args:\n      mode: A member of problem.DatasetSplit.\n      hparams: A tf.HParams object, the model hparams.\n      global_step: A scalar tensor used to compute the sampling distribution.\n        If global_step is None, we call tf.train.get_or_create_global_step by\n        default.\n      **kwargs: Keywords for problem.Problem.Dataset.\n\n    Returns:\n      A dataset containing examples from multiple problems.\n    \"\"\"\n    datasets = [p.dataset(mode, **kwargs) for p in self.problems]\n    datasets = [\n        d.map(lambda x, i=j: self.normalize_example(  # pylint: disable=g-long-lambda\n            dict(x, problem_id=tf.constant([i])), hparams))\n        for j, d in enumerate(datasets)  # Tag examples with a problem_id.\n    ]\n    if mode is problem.DatasetSplit.TRAIN:\n      if global_step is None:\n        global_step = tf.train.get_or_create_global_step()\n      pmf = get_schedule_distribution(self.schedule, global_step)\n      return get_multi_dataset(datasets, pmf)\n    elif self.only_eval_first_problem:\n      return datasets[0]\n    else:\n      datasets = [d.repeat() for d in datasets]\n      return tf.data.Dataset.zip(tuple(datasets)).flat_map(\n          lambda *x: functools.reduce(  # pylint: disable=g-long-lambda\n              tf.data.Dataset.concatenate,\n              map(tf.data.Dataset.from_tensors, x)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normalize_example(self, example, hparams):\n\n    length = self.max_length(hparams)\n    def _to_constant_shape(tensor):\n      tensor = tensor[:length]\n      tensor = tf.pad(tensor, [(0, length - tf.shape(tensor)[0])])\n      return tf.reshape(tensor, [length])\n\n    if self.has_inputs:\n      example['inputs'] = _to_constant_shape(example['inputs'])\n      example['targets'] = _to_constant_shape(example['targets'])\n    elif 'inputs' in example:\n      if self.packed_length:\n        raise ValueError('cannot concatenate packed examples on the fly.')\n      inputs = example.pop('inputs')[:-1]  # Remove EOS token.\n      targets = tf.concat([inputs, example['targets']], 0)\n      example['targets'] = _to_constant_shape(targets)\n    else:\n      example['targets'] = _to_constant_shape(example['targets'])\n    if self.packed_length:\n      if self.has_inputs:\n        if 'inputs_segmentation' in example:\n          example['inputs_segmentation'] = _to_constant_shape(\n              example['inputs_segmentation'])\n          example['inputs_position'] = _to_constant_shape(\n              example['inputs_position'])\n        else:\n          example['inputs_segmentation'] = tf.to_int64(\n              tf.not_equal(example['inputs'], 0))\n          example['inputs_position'] = (\n              example['inputs_segmentation'] * tf.range(length, dtype=tf.int64))\n      if 'targets_segmentation' in example:\n        example['targets_segmentation'] = _to_constant_shape(\n            example['targets_segmentation'])\n        example['targets_position'] = _to_constant_shape(\n            example['targets_position'])\n      else:\n        example['targets_segmentation'] = tf.to_int64(\n            tf.not_equal(example['targets'], 0))\n        example['targets_position'] = (\n            example['targets_segmentation'] * tf.range(length, dtype=tf.int64))\n    return example", "response": "Assumes that example contains both inputs and targets."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_data_with_shared_vocab(self, data_dir, tmp_dir, task_id=-1):\n    global_vocab_filename = os.path.join(data_dir, self.vocab_filename)\n    if not tf.gfile.Exists(global_vocab_filename):\n      raise ValueError(\n          'Global vocabulary file: %s does not exist, '\n          'please create one using build_vocab.py' % global_vocab_filename)\n    # Before generating data, we copy the global vocabulary file to the children\n    # locations. Although this is not the most disk efficient strategy, it\n    # imposes the fewest changes to the text-to-text API.\n    for p in self.problems:\n      local_vocab_filename = os.path.join(data_dir, p.vocab_filename)\n      if not tf.gfile.Exists(local_vocab_filename):\n        tf.gfile.Copy(global_vocab_filename, local_vocab_filename)\n      p.generate_data(data_dir, tmp_dir, task_id)", "response": "Generates TF - Records for problems using a global vocabulary file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a non - padding mask for areas based on lengths.", "response": "def lengths_to_area_mask(feature_length, length, max_area_size):\n  \"\"\"Generates a non-padding mask for areas based on lengths.\n\n  Args:\n    feature_length: a tensor of [batch_size]\n    length: the length of the batch\n    max_area_size: the maximum area size considered\n  Returns:\n    mask: a tensor in shape of [batch_size, num_areas]\n  \"\"\"\n\n  paddings = tf.cast(tf.expand_dims(\n      tf.logical_not(\n          tf.sequence_mask(feature_length, maxlen=length)), 2), tf.float32)\n  _, _, area_sum, _, _ = compute_area_features(paddings,\n                                               max_area_width=max_area_size)\n  mask = tf.squeeze(tf.logical_not(tf.cast(area_sum, tf.bool)), [2])\n  return mask"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npool for an area in features_2d.", "response": "def _pool_one_shape(features_2d, area_width, area_height, batch_size,\n                    width, height, depth, fn=tf.reduce_max, name=None):\n  \"\"\"Pools for an area in features_2d.\n\n  Args:\n    features_2d: a Tensor in a shape of [batch_size, height, width, depth].\n    area_width: the max width allowed for an area.\n    area_height: the max height allowed for an area.\n    batch_size: the batch size.\n    width: the width of the memory.\n    height: the height of the memory.\n    depth: the depth of the features.\n    fn: the TF function for the pooling.\n    name: the op name.\n  Returns:\n    pool_tensor: A Tensor of shape [batch_size, num_areas, depth]\n  \"\"\"\n  with tf.name_scope(name, default_name=\"pool_one_shape\"):\n    images = []\n    for y_shift in range(area_height):\n      image_height = tf.maximum(height - area_height + 1 + y_shift, 0)\n      for x_shift in range(area_width):\n        image_width = tf.maximum(width - area_width + 1 + x_shift, 0)\n        area = features_2d[:, y_shift:image_height, x_shift:image_width, :]\n        flatten_area = tf.reshape(area, [batch_size, -1, depth, 1])\n        images.append(flatten_area)\n    image_tensor = tf.concat(images, axis=3)\n    max_tensor = fn(image_tensor, axis=3)\n  return max_tensor"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef basic_pool(features, max_area_width, max_area_height=1, height=1,\n               fn=tf.reduce_max, name=None):\n  \"\"\"Pools for each area based on a given pooling function (fn).\n\n  Args:\n    features: a Tensor in a shape of [batch_size, height * width, depth].\n    max_area_width: the max width allowed for an area.\n    max_area_height: the max height allowed for an area.\n    height: the height of the image.\n    fn: the TF function for the pooling.\n    name: the namescope.\n  Returns:\n    pool_results: A Tensor of shape [batch_size, num_areas, depth]\n    area_heights: A Tensor of shape [batch_size, num_areas, 1]\n    area_widths: A Tensor of shape [batch_size, num_areas, 1]\n  \"\"\"\n  with tf.name_scope(name, default_name=\"basic_pool\"):\n    feature_shape = common_layers.shape_list(features)\n    batch_size = feature_shape[0]\n    length = feature_shape[-2]\n    depth = feature_shape[-1]\n    width = length // height\n    features_2d = tf.reshape(features, [batch_size, height, width, depth])\n    height_list = []\n    width_list = []\n    pool_list = []\n    size_tensor = tf.ones_like(features_2d[:, :, :, 0], dtype=tf.int32)\n    for area_height in range(max_area_height):\n      for area_width in range(max_area_width):\n        pool_tensor = _pool_one_shape(features_2d,\n                                      area_width=area_width + 1,\n                                      area_height=area_height + 1,\n                                      batch_size=batch_size,\n                                      width=width,\n                                      height=height,\n                                      depth=depth,\n                                      fn=fn)\n        pool_list.append(\n            tf.reshape(pool_tensor, [batch_size, -1, depth]))\n        height_list.append(\n            tf.reshape(\n                size_tensor[:, area_height:, area_width:] *\\\n                (area_height + 1), [batch_size, -1]))\n        width_list.append(\n            tf.reshape(\n                size_tensor[:, area_height:, area_width:] *\\\n                (area_width + 1), [batch_size, -1]))\n    pool_results = tf.concat(pool_list, axis=1)\n    area_heights = tf.expand_dims(tf.concat(height_list, axis=1), 2)\n    area_widths = tf.expand_dims(tf.concat(width_list, axis=1), 2)\n  return pool_results, area_heights, area_widths", "response": "Pools for each area based on a given pooling function (fn).\n\n  Args:\n    features: a Tensor in a shape of [batch_size, height * width, depth].\n    max_area_width: the max width allowed for an area.\n    max_area_height: the max height allowed for an area.\n    height: the height of the image.\n    fn: the TF function for the pooling.\n    name: the namescope.\n  Returns:\n    pool_results: A Tensor of shape [batch_size, num_areas, depth]\n    area_heights: A Tensor of shape [batch_size, num_areas, 1]\n    area_widths: A Tensor of shape [batch_size, num_areas, 1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute area sums for features.", "response": "def _compute_sum_image(features, max_area_width, max_area_height=1, height=1,\n                       name=None):\n  \"\"\"Computes area sums for features.\n\n  Args:\n    features: a Tensor in a shape of [batch_size, height * width, depth].\n    max_area_width: the max width allowed for an area.\n    max_area_height: the max height allowed for an area.\n    height: the height of the image.\n    name: the namescope.\n  Returns:\n    sum_image: A Tensor of shape [batch_size, num_areas, depth]\n    area_heights: A Tensor of shape [batch_size, num_areas, 1]\n    area_widths: A Tensor of shape [batch_size, num_areas, 1]\n  \"\"\"\n  with tf.name_scope(name, default_name=\"compute_sum_image\"):\n    feature_shape = common_layers.shape_list(features)\n    batch_size = feature_shape[0]\n    length = feature_shape[-2]\n    depth = feature_shape[-1]\n    width = length // height\n    features_2d = tf.reshape(features, [batch_size, height, width, depth])\n    width_cum = tf.cumsum(features_2d, axis=-2, name=\"compute_integral_h\")\n    integral_image = tf.cumsum(width_cum, axis=-3, name=\"compute_integral_v\")\n    padded_image = tf.pad(\n        integral_image, [[0, 0], [1, 0], [1, 0], [0, 0]], constant_values=0)\n    height_list = []\n    width_list = []\n    dst_images = []\n    src_images_diag = []\n    src_images_h = []\n    src_images_v = []\n    size_tensor = tf.ones_like(padded_image[:, :, :, 0],\n                               dtype=tf.int32)\n    for area_height in range(max_area_height):\n      for area_width in range(max_area_width):\n        dst_images.append(\n            tf.reshape(\n                padded_image[:, area_height + 1:, area_width + 1:, :],\n                [batch_size, -1, depth]))\n        src_images_diag.append(\n            tf.reshape(\n                padded_image[:, :-area_height - 1, :-area_width - 1, :],\n                [batch_size, -1, depth]))\n        src_images_h.append(\n            tf.reshape(\n                padded_image[:, area_height + 1:, :-area_width - 1, :],\n                [batch_size, -1, depth]))\n        src_images_v.append(\n            tf.reshape(\n                padded_image[:, :-area_height - 1, area_width + 1:, :],\n                [batch_size, -1, depth]))\n        height_list.append(\n            tf.reshape(\n                size_tensor[:, area_height + 1:, area_width + 1:] *\\\n                (area_height + 1), [batch_size, -1]))\n        width_list.append(\n            tf.reshape(\n                size_tensor[:, area_height + 1:, area_width + 1:] *\\\n                (area_width + 1), [batch_size, -1]))\n    sum_image = tf.subtract(\n        tf.concat(dst_images, axis=1) + tf.concat(src_images_diag, axis=1),\n        tf.concat(src_images_v, axis=1) + tf.concat(src_images_h, axis=1))\n    area_heights = tf.expand_dims(tf.concat(height_list, axis=1), 2)\n    area_widths = tf.expand_dims(tf.concat(width_list, axis=1), 2)\n  return sum_image, area_heights, area_widths"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing features for each area.", "response": "def compute_area_features(features, max_area_width, max_area_height=1, height=1,\n                          epsilon=1e-6):\n  \"\"\"Computes features for each area.\n\n  Args:\n    features: a Tensor in a shape of [batch_size, height * width, depth].\n    max_area_width: the max width allowed for an area.\n    max_area_height: the max height allowed for an area.\n    height: the height of the image.\n    epsilon: the epsilon added to the variance for computing standard deviation.\n  Returns:\n    area_mean: A Tensor of shape [batch_size, num_areas, depth]\n    area_std: A Tensor of shape [batch_size, num_areas, depth]\n    area_sum: A Tensor of shape [batch_size, num_areas, depth]\n    area_heights: A Tensor of shape [batch_size, num_areas, 1]\n    area_widths: A Tensor of shape [batch_size, num_areas, 1]\n  \"\"\"\n  with tf.name_scope(\"compute_area_features\"):\n    tf.logging.info(\"area_attention compute_area_features: %d x %d\",\n                    max_area_height, max_area_width)\n    area_sum, area_heights, area_widths = _compute_sum_image(\n        features, max_area_width=max_area_width,\n        max_area_height=max_area_height, height=height)\n    area_squared_sum, _, _ = _compute_sum_image(\n        tf.pow(features, 2), max_area_width=max_area_width,\n        max_area_height=max_area_height, height=height)\n    sizes = tf.multiply(area_heights, area_widths)\n    float_area_sizes = tf.to_float(sizes)\n    area_mean = tf.div(area_sum, float_area_sizes)\n    s2_n = tf.div(area_squared_sum, float_area_sizes)\n    area_variance = tf.subtract(s2_n, tf.pow(area_mean, 2))\n    area_std = tf.sqrt(tf.abs(area_variance) + epsilon)\n    return area_mean, area_std, area_sum, area_heights, area_widths"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the key for each area.", "response": "def compute_area_key(features, max_area_width, max_area_height=1, height=1,\n                     mode=\"mean\", training=True, name=None):\n  \"\"\"Computes the key for each area.\n\n  Args:\n    features: a Tensor in a shape of [batch_size, height * width, depth].\n    max_area_width: the max width allowed for an area.\n    max_area_height: the max height allowed for an area.\n    height: the height of the image.\n    mode: whether to combine different area features or only use\n        the vector mean of each area, which can be \"mean\", \"concat\", \"sum\",\n        \"sample_concat\", and \"sample_sum\".\n    training: indicating if it is in the training mode.\n    name: the name for setting the variable scope.\n  Returns:\n    area_key: a Tensor in the shape of [batch_size, num_areas, depth]\n  \"\"\"\n\n  tf.logging.info(\"area_attention mode=%s\", mode)\n  area_mean, area_std, _, area_heights, area_widths =\\\n      compute_area_features(features, max_area_width=max_area_width,\n                            max_area_height=max_area_height, height=height)\n  if mode == \"mean\":\n    return area_mean\n  elif mode == \"max\":\n    area_max, _, _ = basic_pool(features, max_area_width=max_area_width,\n                                max_area_height=max_area_height, height=height)\n    return area_max\n  elif mode == \"sample\":\n    if training:\n      area_mean += (area_std * tf.random_normal(tf.shape(area_std)))\n    return area_mean\n  with tf.variable_scope(\n      name, default_name=\"combine_area_features\",\n      values=[area_mean, area_std, area_heights, area_widths]):\n    depth = common_layers.shape_list(area_mean)[-1]\n    height_embed = tf.nn.embedding_lookup(\n        params=tf.get_variable(\"area_height_emb\",\n                               [max_area_height, depth // 2]),\n        ids=area_heights[:, :, 0] - 1)\n    width_embed = tf.nn.embedding_lookup(\n        params=tf.get_variable(\"area_width_emb\",\n                               [max_area_width, depth // 2]),\n        ids=area_widths[:, :, 0] - 1)\n    size_embed = tf.concat([height_embed, width_embed], -1)\n    if mode == \"concat\":\n      feature_concat = tf.concat([area_mean, area_std, size_embed], -1)\n    elif mode == \"max_concat\":\n      area_max, _, _ = basic_pool(features, max_area_width=max_area_width,\n                                  max_area_height=max_area_height,\n                                  height=height)\n      feature_concat = tf.concat([area_max, size_embed], -1)\n    elif mode == \"sum\":\n      feature_concat = size_embed + area_mean + area_std\n    elif mode == \"sample_concat\":\n      if training:\n        area_mean += (area_std * tf.random_normal(tf.shape(area_std)))\n      feature_concat = tf.concat([area_mean, size_embed], -1)\n    elif mode == \"sample_sum\":\n      if training:\n        area_mean += (area_std * tf.random_normal(tf.shape(area_std)))\n      feature_concat = area_mean + size_embed\n    else:\n      raise ValueError(\"Unsupported area key mode=%s\" % mode)\n    feature_hidden = tf.layers.dense(inputs=feature_concat,\n                                     units=depth,\n                                     activation=tf.nn.relu)\n    area_key = tf.layers.dense(feature_hidden, units=depth)\n    return area_key"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dot_product_area_attention(q,\n                               k,\n                               v,\n                               bias,\n                               dropout_rate=0.0,\n                               image_shapes=None,\n                               name=None,\n                               attention_image_summary=None,\n                               save_weights_to=None,\n                               dropout_broadcast_dims=None,\n                               max_area_width=1,\n                               max_area_height=1,\n                               memory_height=1,\n                               area_key_mode=\"mean\",\n                               area_value_mode=\"sum\",\n                               top_k_areas=0,\n                               area_temperature=1.0,\n                               training=True):\n  \"\"\"Dot-product area attention.\n\n  Args:\n    q: Tensor with shape [..., length_q, depth_k].\n    k: Tensor with shape [..., length_kv, depth_k]. Leading dimensions must\n      match with q.\n    v: Tensor with shape [..., length_kv, depth_v] Leading dimensions must\n      match with q.\n    bias: bias Tensor (see attention_bias())\n    dropout_rate: a float.\n    image_shapes: optional tuple of integer scalars.\n      see comments for attention_image_summary()\n    name: an optional string\n    attention_image_summary: the callback for making image summary of attention.\n    save_weights_to: an optional dictionary to capture attention weights\n      for visualization; the weights tensor will be appended there under\n      a string key created from the variable scope (including name).\n    dropout_broadcast_dims: an optional list of integers less than rank of q.\n      Specifies in which dimensions to broadcast the dropout decisions.\n    max_area_width: the max width allowed for an area.\n    max_area_height: the max height allowed for an area.\n    memory_height: the height of the memory.\n    area_key_mode: the mode for computing area keys, which can be \"mean\",\n      \"concat\", \"sum\", \"sample_concat\", and \"sample_sum\".\n    area_value_mode: the mode for computing area values, which can be either\n      \"mean\", or \"sum\".\n    top_k_areas: Use the top key areas for attention.\n    area_temperature: the temperature for attention softmax.\n    training: indicating if it is in the training mode.\n  Returns:\n    Tensor with shape [..., length_q, depth_v].\n  \"\"\"\n\n  tf.logging.info(\"dot_product_area_attention: \"\n                  \"area_h=%d, area_w=%d, mem_h=%d, \"\n                  \"area_key_mode=%s, area_value_mode=%s, \"\n                  \"area_temperature=%f\",\n                  max_area_height, max_area_width, memory_height,\n                  area_key_mode, area_value_mode,\n                  area_temperature)\n  with tf.variable_scope(\n      name, default_name=\"dot_product_area_attention\",\n      values=[q, k, v]) as scope:\n    mem_shape = common_layers.shape_list(k)\n    batch_size = mem_shape[0]\n    head_size = mem_shape[1]\n    length = mem_shape[2]\n    depth = mem_shape[3]\n    k_area = compute_area_key(\n        tf.reshape(k, [-1, length, depth]),\n        max_area_width=max_area_width,\n        max_area_height=max_area_height,\n        height=memory_height,\n        mode=area_key_mode,\n        training=training)\n    if area_value_mode == \"mean\":\n      v_area, _, _, _, _ = compute_area_features(\n          tf.reshape(v, [-1, length, depth]), max_area_width=max_area_width,\n          max_area_height=max_area_height, height=memory_height)\n    elif area_value_mode == \"max\":\n      v_area, _, _ = basic_pool(tf.reshape(v, [-1, length, depth]),\n                                max_area_width=max_area_width,\n                                max_area_height=max_area_height,\n                                height=memory_height,\n                                fn=tf.reduce_max)\n    elif area_value_mode == \"sum\":\n      _, _, v_area, _, _ = compute_area_features(\n          tf.reshape(v, [-1, length, depth]), max_area_width=max_area_width,\n          max_area_height=max_area_height, height=memory_height)\n    else:\n      raise ValueError(\"Unsupported area value mode=%s\" % area_value_mode)\n    k = tf.reshape(k_area, [batch_size, head_size, -1, depth])\n    v = tf.reshape(v_area, [batch_size, head_size, -1, depth])\n    logits = tf.matmul(q, k, transpose_b=True)  # [..., length_q, length_kv]\n    if bias is not None:\n      bias = common_layers.cast_like(bias, logits)\n      with tf.name_scope(\"compute_area_att_bias\", values=[bias]):\n        bias_shape = common_layers.shape_list(bias)\n        mem_length = bias_shape[-1]\n        bias_values = tf.reshape(\n            tf.to_float(tf.less(bias, -1)), [-1, mem_length, 1])\n        _, _, padding_sum, _, _ = compute_area_features(\n            bias_values, max_area_width=max_area_width,\n            max_area_height=max_area_height, height=memory_height)\n        bias = tf.where(\n            tf.cast(tf.to_int32(padding_sum), tf.bool),\n            tf.fill(tf.shape(padding_sum), -np.inf),\n            tf.zeros_like(padding_sum, dtype=tf.float32))\n        bias = tf.reshape(bias,\n                          [bias_shape[0], bias_shape[1],\n                           bias_shape[2], -1])\n      logits += bias\n    logits = logits / area_temperature\n    weights = tf.nn.softmax(logits, name=\"attention_weights\")\n    if top_k_areas > 0:\n      tf.logging.info(\"area_attention top_k_areas=%d\", top_k_areas)\n      top_k = tf.minimum(common_layers.shape_list(weights)[-1], top_k_areas)\n      top_weights, _ = tf.nn.top_k(weights, k=top_k)\n      min_values = tf.reduce_min(top_weights, -1, keepdims=True)\n      weights = tf.where(tf.greater_equal(weights, min_values),\n                         weights, tf.zeros_like(weights))\n      weights = tf.div(weights, tf.reduce_sum(weights, -1, keepdims=True))\n    if save_weights_to is not None:\n      save_weights_to[scope.name] = weights\n      save_weights_to[scope.name + \"/logits\"] = logits\n    # Drop out attention links for each head.\n    weights = common_layers.dropout_with_broadcast_dims(\n        weights, 1.0 - dropout_rate, broadcast_dims=dropout_broadcast_dims)\n    if common_layers.should_generate_summaries() and attention_image_summary:\n      attention_image_summary(weights, image_shapes)\n    return tf.matmul(weights, v)", "response": "Dot - product area attention."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_relative_timing_fn():\n  start_time = time.time()\n\n  def format_relative_time():\n    time_delta = time.time() - start_time\n    return str(datetime.timedelta(seconds=time_delta))\n\n  def log_relative_time():\n    tf.logging.info(\"Timing: %s\", format_relative_time())\n\n  return log_relative_time", "response": "Make a function that logs the duration since it was made."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntrain the PPO agent in the simulated environment.", "response": "def train_agent(real_env, learner, world_model_dir, hparams, epoch):\n  \"\"\"Train the PPO agent in the simulated environment.\"\"\"\n  initial_frame_chooser = rl_utils.make_initial_frame_chooser(\n      real_env, hparams.frame_stack_size, hparams.simulation_random_starts,\n      hparams.simulation_flip_first_random_for_beginning\n  )\n  env_fn = rl.make_simulated_env_fn_from_hparams(\n      real_env, hparams, batch_size=hparams.simulated_batch_size,\n      initial_frame_chooser=initial_frame_chooser, model_dir=world_model_dir,\n      sim_video_dir=os.path.join(\n          learner.agent_model_dir, \"sim_videos_{}\".format(epoch)\n      )\n  )\n  base_algo_str = hparams.base_algo\n  train_hparams = trainer_lib.create_hparams(hparams.base_algo_params)\n  if hparams.wm_policy_param_sharing:\n    train_hparams.optimizer_zero_grads = True\n\n  rl_utils.update_hparams_from_hparams(\n      train_hparams, hparams, base_algo_str + \"_\"\n  )\n\n  final_epoch = hparams.epochs - 1\n  is_special_epoch = (epoch + 3) == final_epoch or (epoch + 7) == final_epoch\n  is_final_epoch = epoch == final_epoch\n  env_step_multiplier = 3 if is_final_epoch else 2 if is_special_epoch else 1\n  learner.train(\n      env_fn, train_hparams, simulated=True, save_continuously=True,\n      epoch=epoch, env_step_multiplier=env_step_multiplier\n  )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef train_agent_real_env(env, learner, hparams, epoch):\n  base_algo_str = hparams.base_algo\n\n  train_hparams = trainer_lib.create_hparams(hparams.base_algo_params)\n  rl_utils.update_hparams_from_hparams(\n      train_hparams, hparams, \"real_\" + base_algo_str + \"_\"\n  )\n  if hparams.wm_policy_param_sharing:\n    train_hparams.optimizer_zero_grads = True\n\n  env_fn = rl.make_real_env_fn(env)\n  num_env_steps = real_env_step_increment(hparams)\n  learner.train(\n      env_fn,\n      train_hparams,\n      simulated=False,\n      save_continuously=False,\n      epoch=epoch,\n      sampling_temp=hparams.real_sampling_temp,\n      num_env_steps=num_env_steps,\n  )\n  # Save unfinished rollouts to history.\n  env.reset()", "response": "Train the PPO agent in the real environment."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntrain the world model on problem_name.", "response": "def train_world_model(\n    env, data_dir, output_dir, hparams, world_model_steps_num, epoch\n):\n  \"\"\"Train the world model on problem_name.\"\"\"\n  world_model_steps_num += world_model_step_increment(\n      hparams, is_initial_epoch=(epoch == 0)\n  )\n  model_hparams = trainer_lib.create_hparams(hparams.generative_model_params)\n  model_hparams.learning_rate = model_hparams.learning_rate_constant\n  if epoch > 0:\n    model_hparams.learning_rate *= hparams.learning_rate_bump\n  if hparams.wm_policy_param_sharing:\n    model_hparams.optimizer_zero_grads = True\n\n  restarter = Restarter(\"world_model\", output_dir, world_model_steps_num)\n  if restarter.should_skip:\n    return world_model_steps_num\n  with restarter.training_loop():\n    train_supervised(\n        problem=env,\n        model_name=hparams.generative_model,\n        hparams=model_hparams,\n        data_dir=data_dir,\n        output_dir=output_dir,\n        train_steps=restarter.target_global_step,\n        eval_steps=100,\n        local_eval_frequency=2000\n    )\n\n  return world_model_steps_num"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_metrics(event_dir, epoch):\n  metrics = {}\n  for filename in tf.gfile.ListDirectory(event_dir):\n    path = os.path.join(event_dir, filename)\n    for event in tf.train.summary_iterator(path):\n      if event.step == epoch and event.HasField(\"summary\"):\n        value = event.summary.value[0]\n        metrics[value.tag] = value.simple_value\n  return metrics", "response": "Loads metrics for this epoch if they have already been written."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning the main training loop.", "response": "def training_loop(hparams, output_dir, report_fn=None, report_metric=None):\n  \"\"\"Run the main training loop.\"\"\"\n  if report_fn:\n    assert report_metric is not None\n\n  # Directories\n  subdirectories = [\n      \"data\", \"tmp\", \"world_model\", (\"world_model\", \"debug_videos\"),\n      \"policy\", \"eval_metrics\"\n  ]\n  directories = setup_directories(output_dir, subdirectories)\n\n  epoch = -1\n  data_dir = directories[\"data\"]\n  env = rl_utils.setup_env(\n      hparams, batch_size=hparams.real_batch_size,\n      max_num_noops=hparams.max_num_noops,\n      rl_env_max_episode_steps=hparams.rl_env_max_episode_steps\n  )\n  env.start_new_epoch(epoch, data_dir)\n\n  if hparams.wm_policy_param_sharing:\n    policy_model_dir = directories[\"world_model\"]\n  else:\n    policy_model_dir = directories[\"policy\"]\n  learner = rl_utils.LEARNERS[hparams.base_algo](\n      hparams.frame_stack_size, policy_model_dir,\n      policy_model_dir, hparams.epochs\n  )\n\n  # Timing log function\n  log_relative_time = make_relative_timing_fn()\n\n  # Per-epoch state\n  epoch_metrics = []\n  metrics = {}\n\n  # Collect data from the real environment.\n  policy_model_dir = directories[\"policy\"]\n  tf.logging.info(\"Initial training of the policy in real environment.\")\n  train_agent_real_env(env, learner, hparams, epoch)\n  metrics[\"mean_reward/train/clipped\"] = rl_utils.compute_mean_reward(\n      env.current_epoch_rollouts(), clipped=True\n  )\n  tf.logging.info(\"Mean training reward (initial): {}\".format(\n      metrics[\"mean_reward/train/clipped\"]\n  ))\n  env.generate_data(data_dir)\n\n  eval_metrics_writer = tf.summary.FileWriter(\n      directories[\"eval_metrics\"]\n  )\n\n  world_model_steps_num = 0\n\n  for epoch in range(hparams.epochs):\n    log = make_log_fn(epoch, log_relative_time)\n\n    # Train world model\n    log(\"Training world model\")\n    world_model_steps_num = train_world_model(\n        env, data_dir, directories[\"world_model\"], hparams,\n        world_model_steps_num, epoch\n    )\n\n    # Train agent\n    log(\"Training policy in simulated environment.\")\n    train_agent(env, learner, directories[\"world_model\"], hparams, epoch)\n\n    env.start_new_epoch(epoch, data_dir)\n\n    # Train agent on real env (short)\n    log(\"Training policy in real environment.\")\n    train_agent_real_env(env, learner, hparams, epoch)\n\n    if hparams.stop_loop_early:\n      return 0.0\n\n    env.generate_data(data_dir)\n\n    metrics = load_metrics(directories[\"eval_metrics\"], epoch)\n    if metrics:\n      # Skip eval if metrics have already been written for this epoch. Otherwise\n      # we'd overwrite them with wrong data.\n      log(\"Metrics found for this epoch, skipping evaluation.\")\n    else:\n      metrics[\"mean_reward/train/clipped\"] = rl_utils.compute_mean_reward(\n          env.current_epoch_rollouts(), clipped=True\n      )\n      log(\"Mean training reward: {}\".format(\n          metrics[\"mean_reward/train/clipped\"]\n      ))\n\n      eval_metrics = rl_utils.evaluate_all_configs(hparams, policy_model_dir)\n      log(\"Agent eval metrics:\\n{}\".format(pprint.pformat(eval_metrics)))\n      metrics.update(eval_metrics)\n\n      if hparams.eval_world_model:\n        debug_video_path = os.path.join(\n            directories[\"world_model\", \"debug_videos\"],\n            \"{}.avi\".format(env.current_epoch)\n        )\n        wm_metrics = rl_utils.evaluate_world_model(\n            env, hparams, directories[\"world_model\"], debug_video_path\n        )\n        log(\"World model eval metrics:\\n{}\".format(pprint.pformat(wm_metrics)))\n        metrics.update(wm_metrics)\n\n      rl_utils.summarize_metrics(eval_metrics_writer, metrics, epoch)\n\n      # Report metrics\n      if report_fn:\n        if report_metric == \"mean_reward\":\n          metric_name = rl_utils.get_metric_name(\n              sampling_temp=hparams.eval_sampling_temps[0],\n              max_num_noops=hparams.eval_max_num_noops,\n              clipped=False\n          )\n          report_fn(eval_metrics[metric_name], epoch)\n        else:\n          report_fn(eval_metrics[report_metric], epoch)\n\n    epoch_metrics.append(metrics)\n\n  # Return the evaluation metrics from the final epoch\n  return epoch_metrics[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsingling conv layer with relu pooling and dropout.", "response": "def conv_layer(x,\n               hidden_size,\n               kernel_size,\n               stride,\n               pooling_window,\n               dropout_rate,\n               dilation_rate,\n               name=\"conv\"):\n  \"\"\"Single conv layer with relu, optional pooling, and dropout.\"\"\"\n  with tf.variable_scope(name):\n    out = x\n    out = common_layers.conv1d_block(\n        out,\n        hidden_size, [(dilation_rate, kernel_size)],\n        strides=stride,\n        first_relu=False,\n        padding=\"same\")\n    out = tf.nn.relu(out)\n    if pooling_window:\n      out = tf.layers.max_pooling1d(\n          out, pooling_window, pooling_window, padding=\"same\")\n    out = tf.layers.dropout(out, dropout_rate)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute_nats_and_bits_per_dim(data_dim,\n                                  latent_dim,\n                                  average_reconstruction,\n                                  average_prior):\n  \"\"\"Computes negative ELBO, which is an upper bound on the negative likelihood.\n\n  Args:\n    data_dim: int-like indicating data dimensionality.\n    latent_dim: int-like indicating latent dimensionality.\n    average_reconstruction: Scalar Tensor indicating the reconstruction cost\n      averaged over all data dimensions and any data batches.\n    average_prior: Scalar Tensor indicating the negative log-prior probability\n      averaged over all latent dimensions and any data batches.\n\n  Returns:\n    Tuple of scalar Tensors, representing the nats and bits per data dimension\n    (e.g., subpixels) respectively.\n  \"\"\"\n  with tf.name_scope(None, default_name=\"compute_nats_per_dim\"):\n    data_dim = tf.cast(data_dim, average_reconstruction.dtype)\n    latent_dim = tf.cast(latent_dim, average_prior.dtype)\n    negative_log_likelihood = data_dim * average_reconstruction\n    negative_log_prior = latent_dim * average_prior\n    negative_elbo = negative_log_likelihood + negative_log_prior\n    nats_per_dim = tf.divide(negative_elbo, data_dim, name=\"nats_per_dim\")\n    bits_per_dim = tf.divide(nats_per_dim, tf.log(2.), name=\"bits_per_dim\")\n    return nats_per_dim, bits_per_dim", "response": "Computes the negative ELBO which is an upper bound on the negative likelihood."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef multinomial_sample(x, vocab_size=None, sampling_method=\"random\",\n                       temperature=1.0):\n  \"\"\"Multinomial sampling from a n-dimensional tensor.\n\n  Args:\n    x: Tensor of shape [..., vocab_size]. Parameterizes logits of multinomial.\n    vocab_size: Number of classes in multinomial distribution.\n    sampling_method: String, \"random\" or otherwise deterministic.\n    temperature: Positive float.\n\n  Returns:\n    Tensor of shape [...].\n  \"\"\"\n  vocab_size = vocab_size or common_layers.shape_list(x)[-1]\n  if sampling_method == \"random\" and temperature > 0.0:\n    samples = tf.multinomial(tf.reshape(x, [-1, vocab_size]) / temperature, 1)\n  else:\n    samples = tf.argmax(x, axis=-1)\n  reshaped_samples = tf.reshape(samples, common_layers.shape_list(x)[:-1])\n  return reshaped_samples", "response": "Multinomial sampling from a n - dimensional tensor."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ae_latent_softmax(latents_pred, latents_discrete_hot, vocab_size, hparams):\n  with tf.variable_scope(\"latent_logits\"):\n    latents_logits = tf.layers.dense(latents_pred, vocab_size,\n                                     name=\"logits_dense\")\n    if hparams.logit_normalization:\n      latents_logits *= tf.rsqrt(1e-8 +\n                                 tf.reduce_mean(tf.square(latents_logits)))\n    loss = tf.nn.softmax_cross_entropy_with_logits_v2(\n        labels=latents_discrete_hot, logits=latents_logits)\n\n    # TODO(trandustin): tease this out from ae_latent_softmax.\n    # we use just the loss portion to anchor prior / encoder on text.\n    sample = multinomial_sample(latents_logits,\n                                vocab_size,\n                                hparams.sampling_method,\n                                hparams.sampling_temp)\n    return sample, loss", "response": "A function that computes the softmax cross - entropy of the given set of latents."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ae_latent_sample_beam(latents_dense_in, inputs, ed, embed, hparams):\n\n  def symbols_to_logits_fn(ids):\n    \"\"\"Go from ids to logits.\"\"\"\n    ids = tf.expand_dims(ids, axis=2)  # Ids start with added all-zeros.\n    latents_discrete = tf.pad(ids[:, 1:], [[0, 0], [0, 1], [0, 0]])\n\n    with tf.variable_scope(tf.get_variable_scope(), reuse=False):\n      latents_dense = embed(\n          tf.one_hot(latents_discrete, depth=2**hparams.bottleneck_bits),\n          hparams.hidden_size)\n      latents_pred = transformer_latent_decoder(\n          latents_dense, inputs, ed, hparams, name=\"latent_prediction\")\n      logits = tf.layers.dense(\n          latents_pred, 2**hparams.bottleneck_bits, name=\"logits_dense\")\n      current_output_position = common_layers.shape_list(ids)[1] - 1\n      logits = logits[:, current_output_position, :]\n    return logits\n\n  initial_ids = tf.zeros([tf.shape(latents_dense_in)[0]], dtype=tf.int32)\n  length = tf.shape(latents_dense_in)[1]\n  ids, _, _ = beam_search.beam_search(\n      symbols_to_logits_fn,\n      initial_ids,\n      1,\n      length,\n      2**hparams.bottleneck_bits,\n      alpha=0.0,\n      eos_id=-1,\n      stop_early=False)\n\n  res = tf.expand_dims(ids[:, 0, :], axis=2)  # Pick first beam.\n  return res[:, 1:]", "response": "Samples from the latent space in the autoencoder."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef residual_block_layer(inputs, hparams):\n  kernel = (hparams.res_kernel_size, hparams.res_kernel_size)\n  x = inputs\n  for i in range(hparams.num_res_layers):\n    with tf.variable_scope(\"res_conv_%d\" % i):\n      # kernel_size x kernel_size conv block\n      y = common_layers.conv_block(\n          common_layers.layer_norm(x, hparams.hidden_size, name=\"lnorm\"),\n          hparams.hidden_size, [((1, 1), kernel)],\n          strides=(1, 1),\n          padding=\"SAME\",\n          name=\"residual_conv\")\n      # 1x1 conv block\n      y = common_layers.conv_block(\n          y,\n          hparams.hidden_size, [((1, 1), (1, 1))],\n          strides=(1, 1),\n          padding=\"SAME\",\n          name=\"residual_dense\")\n      x = common_layers.layer_postprocess(x, y, hparams)\n  return x", "response": "Residual block over inputs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compress_encoder_2d(x, hparams, name=None):\n  return compress_encoder(\n      x,\n      hparams,\n      strides=(2, 2),\n      kernel_size=(hparams.kernel_size, hparams.kernel_size),\n      name=name)", "response": "Encoder that compresses 2 - D inputs by 2 ** num_compress_steps."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compress_encoder_1d(x, hparams, name=None):\n  x = tf.expand_dims(x, axis=2)\n  return compress_encoder(x,\n                          hparams,\n                          strides=(2, 1),\n                          kernel_size=(hparams.kernel_size, 1),\n                          name=name)", "response": "Encoder that compresses 1 - D inputs by 2 ** num_compress_steps."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decompress_decoder_2d(x, hparams, name=None):\n  return decompress_decoder(x, hparams,\n                            strides=(2, 2),\n                            kernel=(hparams.kernel_size, hparams.kernel_size),\n                            name=name)", "response": "Decoder that decompresses 2 - D inputs by 2 ** num_compress_steps."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes latents given inputs (typically, compressed targets).", "response": "def bottleneck_layer(inputs,\n                     hparams,\n                     name=\"discrete_bottleneck\"):\n  \"\"\"Computes latents given inputs (typically, compressed targets).\"\"\"\n  [\n      latents_dense,\n      latents_discrete,\n      extra_loss,\n      embed_fn,\n      _,\n  ] = hparams.bottleneck(inputs=inputs,\n                         filter_size=hparams.compress_filter_size,\n                         name=name,\n                         mode=hparams.mode)\n  if DO_SUMMARIES:\n    tf.summary.histogram(\"discrete_latents\",\n                         tf.reshape(latents_discrete, [-1]))\n  return latents_dense, latents_discrete, extra_loss, embed_fn"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iaf_flow(one_hot_assignments,\n             scale_weights,\n             scale_bias,\n             num_codes,\n             summary=True,\n             name=None):\n  \"\"\"Performs a single IAF flow using scale and normalization transformations.\n\n  Args:\n    one_hot_assignments: Assignments Tensor with shape [num_samples, batch_size,\n      latent_size, num_codes].\n    scale_weights: Tensor corresponding to lower triangular matrix used to\n      autoregressively generate scale matrix from assignments. To ensure the\n      lower-triangular matrix has length of latent_size, scale_weights should\n      be a rank-one tensor with size latent_size * (latent_size + 1) / 2.\n    scale_bias: Bias tensor to be added to scale tensor, with shape\n      [latent_size, num_codes]. If scale weights are zero, initialize scale_bias\n      to be log(exp(1.) / 2. - 1) so initial transformation is identity.\n    num_codes: Number of codes in codebook.\n    summary: Whether to save summaries.\n    name: String used for name scope.\n\n  Returns:\n    flow_output: Transformed one-hot assignments.\n    inverse_log_det_jacobian: Inverse log deteriminant of Jacobian corresponding\n      to transformation.\n  \"\"\"\n  with tf.name_scope(name, default_name=\"iaf\"):\n    # Pad the one_hot_assignments by zeroing out the first latent dimension and\n    # shifting the rest down by one (and removing the last dimension).\n    padded_assignments = tf.pad(\n        one_hot_assignments, [[0, 0], [0, 0], [1, 0], [0, 0]])[:, :, :-1, :]\n    scale_bijector = tfp.distributions.bijectors.Affine(\n        scale_tril=tfp.distributions.fill_triangular(scale_weights))\n    scale = scale_bijector.forward(\n        tf.transpose(padded_assignments, [0, 1, 3, 2]))\n    # Transpose the bijector output since it performs a batch matmul.\n    scale = tf.transpose(scale, [0, 1, 3, 2])\n    scale = tf.nn.softplus(scale)\n    scale = scale + tf.nn.softplus(scale_bias[tf.newaxis, tf.newaxis, ...])\n    # Don't need last dimension since the transformation keeps it constant.\n    scale = scale[..., :-1]\n\n    z = one_hot_assignments[..., :-1]\n    unnormalized_probs = tf.concat([z * scale,\n                                    one_hot_assignments[..., -1, tf.newaxis]],\n                                   axis=-1)\n    normalizer = tf.reduce_sum(unnormalized_probs, axis=-1)\n    flow_output = unnormalized_probs / (normalizer[..., tf.newaxis])\n    inverse_log_det_jacobian = (-tf.reduce_sum(tf.log(scale), axis=-1)\n                                + num_codes * tf.log(normalizer))\n    if summary:\n      tf.summary.histogram(\"iaf/scale\", tf.reshape(scale, [-1]))\n      tf.summary.histogram(\"iaf/inverse_log_det_jacobian\",\n                           tf.reshape(inverse_log_det_jacobian, [-1]))\n    return flow_output, inverse_log_det_jacobian", "response": "A single IAF flow."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndownload all lsun files to directory unless they are there.", "response": "def _get_lsun(directory, category, split_name):\n  \"\"\"Downloads all lsun files to directory unless they are there.\"\"\"\n  generator_utils.maybe_download(directory,\n                                 _LSUN_DATA_FILENAME % (category, split_name),\n                                 _LSUN_URL % (category, split_name))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if mixed precision is enabled.", "response": "def _mixed_precision_is_enabled(hparams):\n  \"\"\"Should be the same as in common_attention, avoiding import.\"\"\"\n  activation_dtype = hparams.activation_dtype\n  weight_dtype = hparams.weight_dtype\n  return activation_dtype == tf.float16 and weight_dtype == tf.float32"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef weight_decay_and_noise(loss, hparams, learning_rate, var_list=None):\n  if var_list is None:\n    var_list = tf.trainable_variables()\n\n  decay_vars = [v for v in var_list]\n  noise_vars = [v for v in var_list if \"/body/\" in v.name]\n\n  weight_decay_loss = weight_decay(hparams.weight_decay, decay_vars)\n  if hparams.weight_decay and common_layers.should_generate_summaries():\n    tf.summary.scalar(\"losses/weight_decay\", weight_decay_loss)\n  weight_noise_ops = weight_noise(hparams.weight_noise, learning_rate,\n                                  noise_vars)\n\n  with tf.control_dependencies(weight_noise_ops):\n    loss = tf.identity(loss)\n\n  loss += weight_decay_loss\n  return loss", "response": "Apply weight decay and weight noise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying weight noise to vars in var_list.", "response": "def weight_noise(noise_rate, learning_rate, var_list):\n  \"\"\"Apply weight noise to vars in var_list.\"\"\"\n  if not noise_rate:\n    return [tf.no_op()]\n\n  tf.logging.info(\"Applying weight noise scaled by learning rate, \"\n                  \"noise_rate: %0.5f\", noise_rate)\n\n  noise_ops = []\n\n  for v in var_list:\n    with tf.device(v.device):  # pylint: disable=protected-access\n      scale = noise_rate * learning_rate * 0.001\n      if common_layers.should_generate_summaries():\n        tf.summary.scalar(\"weight_noise_scale\", scale)\n      noise = tf.truncated_normal(v.shape) * scale\n      noise_op = v.assign_add(noise)\n      noise_ops.append(noise_op)\n\n  return noise_ops"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef weight_decay(decay_rate, var_list, skip_biases=True):\n  if not decay_rate:\n    return 0.\n\n  tf.logging.info(\"Applying weight decay, decay_rate: %0.5f\", decay_rate)\n\n  weight_decays = []\n  for v in var_list:\n    # Weight decay.\n    # This is a heuristic way to detect biases that works for main tf.layers.\n    is_bias = len(v.shape.as_list()) == 1 and v.name.endswith(\"bias:0\")\n    if not (skip_biases and is_bias):\n      with tf.device(v.device):\n        v_loss = tf.nn.l2_loss(v)\n      weight_decays.append(v_loss)\n\n  return tf.add_n(weight_decays) * decay_rate", "response": "Apply weight decay to vars in var_list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef log_variable_sizes(var_list=None, tag=None, verbose=False):\n  if var_list is None:\n    var_list = tf.trainable_variables()\n  if tag is None:\n    tag = \"Trainable Variables\"\n\n  if not var_list:\n    return\n\n  name_to_var = {v.name: v for v in var_list}\n  total_size = 0\n  for v_name in sorted(list(name_to_var)):\n    v = name_to_var[v_name]\n    v_size = int(np.prod(np.array(v.shape.as_list())))\n    if verbose:\n      tf.logging.info(\"Weight    %s\\tshape    %s\\tsize    %d\",\n                      v.name[:-2].ljust(80),\n                      str(v.shape).ljust(20), v_size)\n    total_size += v_size\n  tf.logging.info(\"%s Total size: %d\", tag, total_size)", "response": "Log the sizes and shapes of variables and the total size."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsummarizing the variables. Args: var_list: a list of variables; defaults to trainable_variables. tag: name scope of the summary; defaults to training_variables/.", "response": "def summarize_variables(var_list=None, tag=None):\n  \"\"\"Summarize the variables.\n\n  Args:\n    var_list: a list of variables; defaults to trainable_variables.\n    tag: name scope of the summary; defaults to training_variables/.\n  \"\"\"\n  if var_list is None:\n    var_list = tf.trainable_variables()\n  if tag is None:\n    tag = \"training_variables/\"\n\n  name_to_var = {v.name: v for v in var_list}\n  for v_name in list(name_to_var):\n    v = name_to_var[v_name]\n    tf.summary.histogram(tag + v_name, v)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_variable_initializer(hparams):\n  if not hparams.initializer:\n    return None\n\n  mlperf_log.transformer_print(key=mlperf_log.MODEL_HP_INITIALIZER_GAIN,\n                               value=hparams.initializer_gain,\n                               hparams=hparams)\n\n  if not tf.executing_eagerly():\n    tf.logging.info(\"Using variable initializer: %s\", hparams.initializer)\n  if hparams.initializer == \"orthogonal\":\n    return tf.orthogonal_initializer(gain=hparams.initializer_gain)\n  elif hparams.initializer == \"uniform\":\n    max_val = 0.1 * hparams.initializer_gain\n    return tf.random_uniform_initializer(-max_val, max_val)\n  elif hparams.initializer == \"normal_unit_scaling\":\n    return tf.variance_scaling_initializer(\n        hparams.initializer_gain, mode=\"fan_avg\", distribution=\"normal\")\n  elif hparams.initializer == \"uniform_unit_scaling\":\n    return tf.variance_scaling_initializer(\n        hparams.initializer_gain, mode=\"fan_avg\", distribution=\"uniform\")\n  elif hparams.initializer == \"xavier\":\n    return tf.initializers.glorot_uniform()\n  else:\n    raise ValueError(\"Unrecognized initializer: %s\" % hparams.initializer)", "response": "Get variable initializer from hparams."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsummarizes the tensors. Args: tensor_dict: a dictionary of tensors. tag: name scope of the summary; defaults to tensors/.", "response": "def summarize_tensors(tensor_dict, tag=None):\n  \"\"\"Summarize the tensors.\n\n  Args:\n    tensor_dict: a dictionary of tensors.\n    tag: name scope of the summary; defaults to tensors/.\n  \"\"\"\n  if tag is None:\n    tag = \"tensors/\"\n\n  for t_name in list(tensor_dict):\n    t = tensor_dict[t_name]\n    tf.summary.histogram(tag + t_name, t)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef image_embedding(images,\n                    model_fn=resnet_v1_152,\n                    trainable=True,\n                    is_training=True,\n                    weight_decay=0.0001,\n                    batch_norm_decay=0.997,\n                    batch_norm_epsilon=1e-5,\n                    batch_norm_scale=True,\n                    add_summaries=False,\n                    reuse=False):\n  \"\"\"Extract image features from pretrained resnet model.\"\"\"\n\n  is_resnet_training = trainable and is_training\n\n  batch_norm_params = {\n      \"is_training\": is_resnet_training,\n      \"trainable\": trainable,\n      \"decay\": batch_norm_decay,\n      \"epsilon\": batch_norm_epsilon,\n      \"scale\": batch_norm_scale,\n  }\n\n  if trainable:\n    weights_regularizer = tf.contrib.layers.l2_regularizer(weight_decay)\n  else:\n    weights_regularizer = None\n\n  with tf.variable_scope(model_fn.__name__, [images], reuse=reuse) as scope:\n    with slim.arg_scope(\n        [slim.conv2d],\n        weights_regularizer=weights_regularizer,\n        trainable=trainable):\n      with slim.arg_scope(\n          [slim.conv2d],\n          weights_initializer=slim.variance_scaling_initializer(),\n          activation_fn=tf.nn.relu,\n          normalizer_fn=slim.batch_norm,\n          normalizer_params=batch_norm_params):\n        with slim.arg_scope([slim.batch_norm],\n                            is_training=is_resnet_training,\n                            trainable=trainable):\n          with slim.arg_scope([slim.max_pool2d], padding=\"SAME\"):\n            net, end_points = model_fn(\n                images, num_classes=None, global_pool=False,\n                is_training=is_resnet_training,\n                reuse=reuse, scope=scope)\n\n  if add_summaries:\n    for v in end_points.values():\n      tf.contrib.layers.summaries.summarize_activation(v)\n\n  return net", "response": "Extract image features from pretrained resnet model."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_timit(directory):\n  if os.path.exists(os.path.join(directory, \"timit\")):\n    return\n\n  assert FLAGS.timit_paths\n  for path in FLAGS.timit_paths.split(\",\"):\n    with tf.gfile.GFile(path) as f:\n      with tarfile.open(fileobj=f, mode=\"r:gz\") as timit_compressed:\n        timit_compressed.extractall(directory)", "response": "Extract TIMIT datasets to directory unless directory / timit exists."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _collect_data(directory, input_ext, target_ext):\n  # Directory from string to tuple pair of strings\n  # key: the filepath to a datafile including the datafile's basename. Example,\n  #   if the datafile was \"/path/to/datafile.wav\" then the key would be\n  #   \"/path/to/datafile\"\n  # value: a pair of strings (input_filepath, target_filepath)\n  data_files = {}\n  for root, _, filenames in os.walk(directory):\n    input_files = [filename for filename in filenames if input_ext in filename]\n    for input_filename in input_files:\n      basename = input_filename.strip(input_ext)\n      input_file = os.path.join(root, input_filename)\n      target_file = os.path.join(root, basename + target_ext)\n      key = os.path.join(root, basename)\n      assert os.path.exists(target_file)\n      assert key not in data_files\n      data_files[key] = (input_file, target_file)\n  return data_files", "response": "Traverses a directory collecting input and target files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate TIMIT transcription problem.", "response": "def timit_generator(data_dir,\n                    tmp_dir,\n                    training,\n                    how_many,\n                    start_from=0,\n                    eos_list=None,\n                    vocab_filename=None,\n                    vocab_size=0):\n  \"\"\"Data generator for TIMIT transcription problem.\n\n  Args:\n    data_dir: path to the data directory.\n    tmp_dir: path to temporary storage directory.\n    training: a Boolean; if true, we use the train set, otherwise the test set.\n    how_many: how many inputs and labels to generate.\n    start_from: from which input to start.\n    eos_list: optional list of end of sentence tokens, otherwise use default\n      value `1`.\n    vocab_filename: file within `tmp_dir` to read vocabulary from. If this is\n      not provided then the target sentence will be encoded by character.\n    vocab_size: integer target to generate vocabulary size to.\n\n  Yields:\n    A dictionary representing the images with the following fields:\n    * inputs: a float sequence containing the audio data\n    * audio/channel_count: an integer\n    * audio/sample_count: an integer\n    * audio/sample_width: an integer\n    * targets: an integer sequence representing the encoded sentence\n  \"\"\"\n  del data_dir\n  eos_list = [1] if eos_list is None else eos_list\n  if vocab_filename is not None:\n    # TODO(lukaszkaiser): Correct this call to generate a vocabulary. No data\n    # sources are being passed.\n    # vocab_symbolizer = generator_utils.get_or_generate_vocab(\n    #     data_dir, tmp_dir, vocab_filename, vocab_size)\n    del vocab_size\n    vocab_symbolizer = None\n    assert False\n  _get_timit(tmp_dir)\n  datasets = (_TIMIT_TRAIN_DATASETS if training else _TIMIT_TEST_DATASETS)\n  i = 0\n  for timit_data_dir, (audio_ext, transcription_ext) in datasets:\n    timit_data_dir = os.path.join(tmp_dir, timit_data_dir)\n    data_files = _collect_data(timit_data_dir, audio_ext, transcription_ext)\n    data_pairs = data_files.values()\n    for input_file, target_file in sorted(data_pairs)[start_from:]:\n      if i == how_many:\n        return\n      i += 1\n      audio_data, sample_count, sample_width, num_channels = _get_audio_data(\n          input_file)\n      text_data = _get_text_data(target_file)\n      if vocab_filename is None:\n        label = [ord(c) for c in text_data] + eos_list\n      else:\n        label = vocab_symbolizer.encode(text_data) + eos_list\n      yield {\n          \"inputs\": audio_data,\n          \"audio/channel_count\": [num_channels],\n          \"audio/sample_count\": [sample_count],\n          \"audio/sample_width\": [sample_width],\n          \"targets\": label\n      }"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _build_vocab(filename, vocab_dir, vocab_name):\n  vocab_path = os.path.join(vocab_dir, vocab_name)\n  if not tf.gfile.Exists(vocab_path):\n    with tf.gfile.GFile(filename, \"r\") as f:\n      data = f.read().split()\n    counter = collections.Counter(data)\n    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n    words, _ = list(zip(*count_pairs))\n    encoder = text_encoder.TokenTextEncoder(None, vocab_list=words)\n    encoder.store_to_file(vocab_path)\n  else:\n    encoder = text_encoder.TokenTextEncoder(vocab_path)\n  return encoder", "response": "Reads a file to build a vocabulary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _maybe_download_corpus(tmp_dir, vocab_type):\n  if vocab_type == text_problems.VocabType.CHARACTER:\n\n    dataset_url = (\"https://s3.amazonaws.com/research.metamind.io/wikitext\"\n                   \"/wikitext-103-raw-v1.zip\")\n    dir_name = \"wikitext-103-raw\"\n  else:\n    dataset_url = (\"https://s3.amazonaws.com/research.metamind.io/wikitext\"\n                   \"/wikitext-103-v1.zip\")\n    dir_name = \"wikitext-103\"\n\n  fname = os.path.basename(dataset_url)\n  compressed_filepath = generator_utils.maybe_download(tmp_dir, fname,\n                                                       dataset_url)\n  zip_ref = zipfile.ZipFile(compressed_filepath, \"r\")\n  zip_ref.extractall(tmp_dir)\n  zip_ref.close()\n\n  files = os.path.join(tmp_dir, dir_name, \"*\")\n  train_file, valid_file, test_file = None, None, None\n  for f in tf.gfile.Glob(files):\n    fname = os.path.basename(f)\n    if \"train\" in fname:\n      train_file = f\n    elif \"valid\" in fname:\n      valid_file = f\n    elif \"test\" in fname:\n      test_file = f\n\n  assert train_file, \"Training file not found\"\n  assert valid_file, \"Validation file not found\"\n  assert test_file, \"Testing file not found\"\n\n  return train_file, valid_file, test_file", "response": "Download and unpack the corpus."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_batch_coordinate(x):\n  # Compute the batch coordinate before flattening all batches\n  batch_coordinate = tf.expand_dims(\n      common_attention.coordinate_tensor(\n          common_layers.shape_list(x)[:-1], axis=0),\n      axis=-1)\n  return batch_coordinate", "response": "Return a flat int32 tensor of shape [ 1 batch_size length 1 )."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef aligned_base():\n  hparams = common_hparams.basic_params1()\n  hparams.hidden_size = 512\n  hparams.batch_size = 5000\n  hparams.max_length = 0\n  hparams.min_length_bucket = 1024\n  hparams.dropout = 0.0\n  hparams.layer_prepostprocess_dropout = 0.0\n  hparams.label_smoothing = 0.0\n  hparams.clip_grad_norm = 0.  # i.e. no gradient clipping\n  hparams.optimizer_adam_epsilon = 1e-9\n  hparams.learning_rate_decay_scheme = \"noam\"\n  hparams.learning_rate = 0.1\n  hparams.learning_rate_warmup_steps = 2000\n  hparams.initializer_gain = 1.0\n  hparams.initializer = \"uniform_unit_scaling\"\n  hparams.weight_decay = 0.0\n  hparams.optimizer_adam_beta1 = 0.9\n  hparams.optimizer_adam_beta2 = 0.98\n  hparams.shared_embedding_and_softmax_weights = True\n  hparams.add_hparam(\"ffn_hidden_sizes\", \"2048\")  # Add new ones like this.\n  hparams.moe_num_experts = 32\n  hparams.layer_preprocess_sequence = \"n\"\n  hparams.layer_postprocess_sequence = \"da\"\n  hparams.add_hparam(\"layers\", \"timing,\" + \"conv,att,ffn,\" * 2)\n\n  # attention-related flags\n  hparams.add_hparam(\"num_heads\", 8)\n  hparams.add_hparam(\"attention_key_channels\", 0)\n  hparams.add_hparam(\"attention_value_channels\", 0)\n  # All hyperparameters ending in \"dropout\" are automatically set to 0.0\n  # when not in training mode.\n  hparams.add_hparam(\"attention_dropout\", 0.0)\n  hparams.add_hparam(\"pos\", \"timing\")  # timing, none\n  # moe params. local attention moe.\n  hparams.add_hparam(\"attention_local\", False)\n  hparams.add_hparam(\"attention_moe_k\", 2)\n  hparams.add_hparam(\"attention_num_experts\", 16)\n  hparams.add_hparam(\"attention_split_batch\", False)\n  # Key, query and value dimensions for the attention\n  hparams.add_hparam(\"attention_kq_size\", 128)\n  hparams.add_hparam(\"attention_v_size\", 256)\n  # Loss coef for load balancing\n  hparams.add_hparam(\"attention_load_balance\", 2e-2)\n  hparams.add_hparam(\"diet_experts\", False)\n  hparams.add_hparam(\"memory_efficient_ffn\", False)\n  hparams.add_hparam(\"local_attention_window\", 128)\n  hparams.add_hparam(\"attention_num_groups\", 8)\n  hparams.add_hparam(\"memory_target_density\", 2.0)\n  hparams.add_hparam(\"multiplicative_overhead\", 1.25)\n  hparams.add_hparam(\"multiplicative_overhead_eval\", 2.0)\n  hparams.add_hparam(\"attention_image_summary\", True)\n  # LSH params\n  hparams.add_hparam(\"lsh_truncated\", True)\n  # For testing right-masking.\n  # This is not implemented in all layers.\n  hparams.add_hparam(\"mask_right\", False)\n  return hparams", "response": "Set of hyperparameters.\n\n  languagemodel_wiki_scramble1k50, 1gpu, 7k steps (10min): log(ppl)_eval = 2.60\n  12.0 steps/sec on P100\n  8gpu (8x batch), 7k steps: log(ppl)_eval = 2.00\n\n  Returns:\n    a hparams object"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nversion for languagemodel_wiki_scramble8k50. aligned_8k_grouped 8gpu", "response": "def aligned_8k_grouped():\n  \"\"\"version for languagemodel_wiki_scramble8k50.\n\n  languagemodel_wiki_scramble1k50, 1gpu, 7k steps: log(ppl)_eval = 2.92\n  3.3 steps/sec on P100\n  8gpu (8x batch), 7k steps: log(ppl)_eval = 2.15\n\n  Returns:\n    a hparams object\n  \"\"\"\n  hparams = aligned_grouped()\n  hparams.batch_size = 8192\n  # hparams.attention_image_summary = False\n  hparams.num_groups = 16\n  hparams.multiplicative_overhead = 1.1\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _unmerge_beam_dim(tensor, batch_size, beam_size):\n  shape = common_layers.shape_list(tensor)\n  new_shape = [batch_size] + [beam_size] + shape[1:]\n  return tf.reshape(tensor, new_shape)", "response": "Reshapes first dimension back to [ batch_size beam_size... )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _expand_to_beam_size(tensor, beam_size):\n  tensor = tf.expand_dims(tensor, axis=1)\n  tile_dims = [1] * tensor.shape.ndims\n  tile_dims[1] = beam_size\n\n  return tf.tile(tensor, tile_dims)", "response": "Tiles a given tensor by beam_size."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the shape of the tensor but sets middle dims to None.", "response": "def get_state_shape_invariants(tensor):\n  \"\"\"Returns the shape of the tensor but sets middle dims to None.\"\"\"\n  shape = tensor.shape.as_list()\n  for i in range(1, len(shape) - 1):\n    shape[i] = None\n  return tf.TensorShape(shape)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the i th coordinate that contains the batch index for gather.", "response": "def compute_batch_indices(batch_size, beam_size):\n  \"\"\"Computes the i'th coordinate that contains the batch index for gathers.\n\n  Batch pos is a tensor like [[0,0,0,0,],[1,1,1,1],..]. It says which\n  batch the beam item is in. This will create the i of the i,j coordinate\n  needed for the gather.\n\n  Args:\n    batch_size: Batch size\n    beam_size: Size of the beam.\n  Returns:\n    batch_pos: [batch_size, beam_size] tensor of ids\n  \"\"\"\n  batch_pos = tf.range(batch_size * beam_size) // beam_size\n  batch_pos = tf.reshape(batch_pos, [batch_size, beam_size])\n  return batch_pos"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fast_tpu_gather(params, indices, name=None):\n  with tf.name_scope(name):\n    dtype = params.dtype\n\n    def _gather(params, indices):\n      \"\"\"Fast gather using one_hot and batch matmul.\"\"\"\n      if dtype != tf.float32:\n        params = tf.to_float(params)\n      shape = common_layers.shape_list(params)\n      indices_shape = common_layers.shape_list(indices)\n      ndims = params.shape.ndims\n      # Adjust the shape of params to match one-hot indices, which is the\n      # requirement of Batch MatMul.\n      if ndims == 2:\n        params = tf.expand_dims(params, axis=-1)\n      if ndims > 3:\n        params = tf.reshape(params, [shape[0], shape[1], -1])\n      gather_result = tf.matmul(\n          tf.one_hot(indices, shape[1], dtype=params.dtype), params)\n      if ndims == 2:\n        gather_result = tf.squeeze(gather_result, axis=-1)\n      if ndims > 3:\n        shape[1] = indices_shape[1]\n        gather_result = tf.reshape(gather_result, shape)\n      if dtype != tf.float32:\n        gather_result = tf.cast(gather_result, dtype)\n      return gather_result\n\n    # If the dtype is int, use the gather instead of one_hot matmul to avoid\n    # precision loss. The max int value can be represented by bfloat16 in MXU is\n    # 256, which is smaller than the possible id values. Encoding/decoding can\n    # potentially used to make it work, but the benenfit is small right now.\n    if dtype.is_integer:\n      gather_result = tf.batch_gather(params, indices)\n    else:\n      gather_result = _gather(params, indices)\n\n    return gather_result", "response": "Fast gather implementation for models running on TPU."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a tensor after element wise transformation that replaces the lower bits of each element with iota.", "response": "def _create_make_unique(inputs):\n  \"\"\"Replaces the lower bits of each element with iota.\n\n  The iota is used to derive the index, and also serves the purpose to\n  make each element unique to break ties.\n\n  Args:\n    inputs: A tensor with rank of 2 and dtype of tf.float32.\n      [batch_size, original_size].\n\n  Returns:\n    A tensor after element wise transformation, with dtype the same as inputs.\n    [batch_size, original_size].\n\n  Raises:\n    ValueError: If the rank of the input tensor does not equal 2.\n  \"\"\"\n  if inputs.shape.ndims != 2:\n    raise ValueError(\"Input of top_k_with_unique must be rank-2 \"\n                     \"but got: %s\" % inputs.shape)\n\n  height = inputs.shape[0]\n  width = inputs.shape[1]\n  zeros = tf.zeros([height, width], dtype=tf.int32)\n\n  # Count_mask is used to mask away the low order bits to ensure that every\n  # element is distinct.\n  log2_ceiling = int(math.ceil(math.log(int(width), 2)))\n  next_power_of_two = 1 << log2_ceiling\n  count_mask = ~(next_power_of_two - 1)\n  count_mask_r0 = tf.constant(count_mask)\n  count_mask_r2 = tf.fill([height, width], count_mask_r0)\n\n  # Smallest_normal is the bit representation of the smallest positive normal\n  # floating point number. The sign is zero, exponent is one, and the fraction\n  # is zero.\n  smallest_normal = 1 << 23\n  smallest_normal_r0 = tf.constant(smallest_normal, dtype=tf.int32)\n  smallest_normal_r2 = tf.fill([height, width], smallest_normal_r0)\n\n  # Low_bit_mask is used to mask away the sign bit when computing the absolute\n  # value.\n  low_bit_mask = ~(1 << 31)\n  low_bit_mask_r0 = tf.constant(low_bit_mask, dtype=tf.int32)\n  low_bit_mask_r2 = tf.fill([height, width], low_bit_mask_r0)\n\n  iota = tf.tile(tf.expand_dims(tf.range(width, dtype=tf.int32), 0),\n                 [height, 1])\n\n  # Compare the absolute value with positive zero to handle negative zero.\n  input_r2 = tf.bitcast(inputs, tf.int32)\n  abs_r2 = tf.bitwise.bitwise_and(input_r2, low_bit_mask_r2)\n  if_zero_r2 = tf.equal(abs_r2, zeros)\n  smallest_normal_preserving_sign_r2 = tf.bitwise.bitwise_or(\n      input_r2, smallest_normal_r2)\n  input_no_zeros_r2 = tf.where(\n      if_zero_r2, smallest_normal_preserving_sign_r2, input_r2)\n\n  # Discard the low-order bits and replace with iota.\n  and_r2 = tf.bitwise.bitwise_and(input_no_zeros_r2, count_mask_r2)\n  or_r2 = tf.bitwise.bitwise_or(and_r2, iota)\n  return tf.bitcast(or_r2, tf.float32)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating the top k values in sorted order with indices.", "response": "def _create_topk_unique(inputs, k):\n  \"\"\"Creates the top k values in sorted order with indices.\n\n  Args:\n    inputs: A tensor with rank of 2. [batch_size, original_size].\n    k: An integer, number of top elements to select.\n\n  Returns:\n    topk_r2: A tensor, the k largest elements. [batch_size, k].\n    topk_indices_r2: A tensor, indices of the top k values. [batch_size, k].\n  \"\"\"\n  height = inputs.shape[0]\n  width = inputs.shape[1]\n  neg_inf_r0 = tf.constant(-np.inf, dtype=tf.float32)\n  ones = tf.ones([height, width], dtype=tf.float32)\n  neg_inf_r2 = ones * neg_inf_r0\n  inputs = tf.where(tf.is_nan(inputs), neg_inf_r2, inputs)\n\n  # Select the current largest value k times and keep them in topk_r2. The\n  # selected largest values are marked as the smallest value to avoid being\n  # selected again.\n  tmp = inputs\n  topk_r2 = tf.zeros([height, k], dtype=tf.float32)\n  for i in range(k):\n    kth_order_statistic = tf.reduce_max(tmp, axis=1, keepdims=True)\n    k_mask = tf.tile(tf.expand_dims(tf.equal(tf.range(k), tf.fill([k], i)), 0),\n                     [height, 1])\n    topk_r2 = tf.where(k_mask, tf.tile(kth_order_statistic, [1, k]), topk_r2)\n    ge_r2 = tf.greater_equal(inputs, tf.tile(kth_order_statistic, [1, width]))\n    tmp = tf.where(ge_r2, neg_inf_r2, inputs)\n\n  log2_ceiling = int(math.ceil(math.log(float(int(width)), 2)))\n  next_power_of_two = 1 << log2_ceiling\n  count_mask = next_power_of_two - 1\n  mask_r0 = tf.constant(count_mask)\n  mask_r2 = tf.fill([height, k], mask_r0)\n  topk_r2_s32 = tf.bitcast(topk_r2, tf.int32)\n  topk_indices_r2 = tf.bitwise.bitwise_and(topk_r2_s32, mask_r2)\n  return topk_r2, topk_indices_r2"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef top_k_with_unique(inputs, k):\n  unique_inputs = _create_make_unique(tf.cast(inputs, tf.float32))\n  top_values, indices = _create_topk_unique(unique_inputs, k)\n  top_values = tf.cast(top_values, inputs.dtype)\n  return top_values, indices", "response": "Finds the values and indices of the k largests entries in sorted order."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive sequences and scores, will gather the top k=beam size sequences. This function is used to grow alive, and finished. It takes sequences, scores, and flags, and returns the top k from sequences, scores_to_gather, and flags based on the values in scores. This method permits easy introspection using tfdbg. It adds three named ops that are prefixed by `prefix`: - _topk_seq: the tensor for topk_seq returned by this method. - _topk_flags: the tensor for topk_finished_flags returned by this method. - _topk_scores: the tensor for tokp_gathered_scores returned by this method. Args: sequences: Tensor of sequences that we need to gather from. [batch_size, beam_size, seq_length] scores: Tensor of scores for each sequence in sequences. [batch_size, beam_size]. We will use these to compute the topk. scores_to_gather: Tensor of scores for each sequence in sequences. [batch_size, beam_size]. We will return the gathered scores from here. Scores to gather is different from scores because for grow_alive, we will need to return log_probs, while for grow_finished, we will need to return the length penalized scores. flags: Tensor of bools for sequences that say whether a sequence has reached EOS or not beam_size: int batch_size: int prefix: string that will prefix unique names for the ops run. states_to_gather: dict (possibly nested) of decoding states. use_tpu: A bool, whether to compute topk scores and sequences on TPU. use_top_k_with_unique: bool, whether to use a fast (but decreased precision) top_k during TPU beam search. Returns: Tuple of (topk_seq [batch_size, beam_size, decode_length], topk_gathered_scores [batch_size, beam_size], topk_finished_flags[batch_size, beam_size])", "response": "def compute_topk_scores_and_seq(sequences,\n                                scores,\n                                scores_to_gather,\n                                flags,\n                                beam_size,\n                                batch_size,\n                                prefix=\"default\",\n                                states_to_gather=None,\n                                use_tpu=False,\n                                use_top_k_with_unique=True):\n  \"\"\"Given sequences and scores, will gather the top k=beam size sequences.\n\n  This function is used to grow alive, and finished. It takes sequences,\n  scores, and flags, and returns the top k from sequences, scores_to_gather,\n  and flags based on the values in scores.\n\n  This method permits easy introspection using tfdbg.  It adds three named ops\n  that are prefixed by `prefix`:\n    - _topk_seq: the tensor for topk_seq returned by this method.\n    - _topk_flags: the tensor for topk_finished_flags returned by this method.\n    - _topk_scores: the tensor for tokp_gathered_scores returned by this method.\n\n  Args:\n    sequences: Tensor of sequences that we need to gather from.\n      [batch_size, beam_size, seq_length]\n    scores: Tensor of scores for each sequence in sequences.\n      [batch_size, beam_size]. We will use these to compute the topk.\n    scores_to_gather: Tensor of scores for each sequence in sequences.\n      [batch_size, beam_size]. We will return the gathered scores from here.\n      Scores to gather is different from scores because for grow_alive, we will\n      need to return log_probs, while for grow_finished, we will need to return\n      the length penalized scores.\n    flags: Tensor of bools for sequences that say whether a sequence has reached\n      EOS or not\n    beam_size: int\n    batch_size: int\n    prefix: string that will prefix unique names for the ops run.\n    states_to_gather: dict (possibly nested) of decoding states.\n    use_tpu: A bool, whether to compute topk scores and sequences on TPU.\n    use_top_k_with_unique: bool, whether to use a fast (but decreased precision)\n      top_k during TPU beam search.\n\n  Returns:\n    Tuple of\n    (topk_seq [batch_size, beam_size, decode_length],\n     topk_gathered_scores [batch_size, beam_size],\n     topk_finished_flags[batch_size, beam_size])\n  \"\"\"\n  if not use_tpu:\n    _, topk_indexes = tf.nn.top_k(scores, k=beam_size)\n    # The next three steps are to create coordinates for tf.gather_nd to pull\n    # out the topk sequences from sequences based on scores.\n    # batch pos is a tensor like [[0,0,0,0,],[1,1,1,1],..]. It says which\n    # batch the beam item is in. This will create the i of the i,j coordinate\n    # needed for the gather\n    batch_pos = compute_batch_indices(batch_size, beam_size)\n\n    # top coordinates will give us the actual coordinates to do the gather.\n    # stacking will create a tensor of dimension batch * beam * 2, where the\n    # last dimension contains the i,j gathering coordinates.\n    top_coordinates = tf.stack([batch_pos, topk_indexes], axis=2)\n\n    # Gather up the highest scoring sequences.  For each operation added, give\n    # it a concrete name to simplify observing these operations with tfdbg.\n    # Clients can capture these tensors by watching these node names.\n    def gather(tensor, name):\n      return tf.gather_nd(tensor, top_coordinates, name=(prefix + name))\n    topk_seq = gather(sequences, \"_topk_seq\")\n    topk_flags = gather(flags, \"_topk_flags\")\n    topk_gathered_scores = gather(scores_to_gather, \"_topk_scores\")\n    if states_to_gather:\n      topk_gathered_states = nest.map_structure(\n          lambda state: gather(state, \"_topk_states\"), states_to_gather)\n    else:\n      topk_gathered_states = states_to_gather\n  else:\n    if use_top_k_with_unique:\n      _, topk_indexes = top_k_with_unique(scores, k=beam_size)\n    else:\n      _, topk_indexes = tf.nn.top_k(scores, k=beam_size)\n    # Gather up the highest scoring sequences.  For each operation added, give\n    # it a concrete name to simplify observing these operations with tfdbg.\n    # Clients can capture these tensors by watching these node names.\n    topk_seq = fast_tpu_gather(sequences, topk_indexes, prefix + \"_topk_seq\")\n    topk_flags = fast_tpu_gather(flags, topk_indexes, prefix + \"_topk_flags\")\n    topk_gathered_scores = fast_tpu_gather(scores_to_gather, topk_indexes,\n                                           prefix + \"_topk_scores\")\n    if states_to_gather:\n      topk_gathered_states = nest.map_structure(\n          # pylint: disable=g-long-lambda\n          lambda state: fast_tpu_gather(state, topk_indexes,\n                                        prefix + \"_topk_states\"),\n          states_to_gather)\n    else:\n      topk_gathered_states = states_to_gather\n  return topk_seq, topk_gathered_scores, topk_flags, topk_gathered_states"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef beam_search(symbols_to_logits_fn,\n                initial_ids,\n                beam_size,\n                decode_length,\n                vocab_size,\n                alpha,\n                states=None,\n                eos_id=EOS_ID,\n                stop_early=True,\n                use_tpu=False,\n                use_top_k_with_unique=True):\n  \"\"\"Beam search with length penalties.\n\n  Requires a function that can take the currently decoded symbols and return\n  the logits for the next symbol. The implementation is inspired by\n  https://arxiv.org/abs/1609.08144.\n\n  When running, the beam search steps can be visualized by using tfdbg to watch\n  the operations generating the output ids for each beam step.  These operations\n  have the pattern:\n    (alive|finished)_topk_(seq,scores)\n\n  Operations marked `alive` represent the new beam sequences that will be\n  processed in the next step.  Operations marked `finished` represent the\n  completed beam sequences, which may be padded with 0s if no beams finished.\n\n  Operations marked `seq` store the full beam sequence for the time step.\n  Operations marked `scores` store the sequence's final log scores.\n\n  The beam search steps will be processed sequentially in order, so when\n  capturing observed from these operations, tensors, clients can make\n  assumptions about which step is being recorded.\n\n  WARNING: Assumes 2nd dimension of tensors in `states` and not invariant, this\n  means that the shape of the 2nd dimension of these tensors will not be\n  available (i.e. set to None) inside symbols_to_logits_fn.\n\n  Args:\n    symbols_to_logits_fn: Interface to the model, to provide logits.\n        Shoud take [batch_size, decoded_ids] and return [batch_size, vocab_size]\n    initial_ids: Ids to start off the decoding, this will be the first thing\n        handed to symbols_to_logits_fn (after expanding to beam size)\n        [batch_size]\n    beam_size: Size of the beam.\n    decode_length: Number of steps to decode for.\n    vocab_size: Size of the vocab, must equal the size of the logits returned by\n        symbols_to_logits_fn\n    alpha: alpha for length penalty.\n    states: dict (possibly nested) of decoding states.\n    eos_id: ID for end of sentence.\n    stop_early: a boolean - stop once best sequence is provably determined.\n    use_tpu: A bool, whether to do beam search on TPU.\n    use_top_k_with_unique: bool, whether to use a fast (but decreased precision)\n      top_k during TPU beam search.\n\n  Returns:\n    Tuple of\n    (decoded beams [batch_size, beam_size, decode_length]\n     decoding probabilities [batch_size, beam_size])\n  \"\"\"\n  batch_size = common_layers.shape_list(initial_ids)[0]\n\n  # Assume initial_ids are prob 1.0\n  initial_log_probs = tf.constant([[0.] + [-INF] * (beam_size - 1)])\n  # Expand to beam_size (batch_size, beam_size)\n  alive_log_probs = tf.tile(initial_log_probs, [batch_size, 1])\n\n  # Expand each batch and state to beam_size\n  alive_seq = _expand_to_beam_size(initial_ids, beam_size)\n  alive_seq = tf.expand_dims(alive_seq, axis=2)  # (batch_size, beam_size, 1)\n  if use_tpu:\n    alive_seq = tf.tile(alive_seq, [1, 1, decode_length + 1])\n  if states:\n    states = nest.map_structure(\n        lambda state: _expand_to_beam_size(state, beam_size), states)\n  else:\n    states = {}\n\n  # Finished will keep track of all the sequences that have finished so far\n  # Finished log probs will be negative infinity in the beginning\n  # finished_flags will keep track of booleans\n  finished_seq = tf.zeros(common_layers.shape_list(alive_seq), tf.int32)\n  # Setting the scores of the initial to negative infinity.\n  finished_scores = tf.ones([batch_size, beam_size]) * -INF\n  finished_flags = tf.zeros([batch_size, beam_size], tf.bool)\n\n  def grow_finished(finished_seq, finished_scores, finished_flags, curr_seq,\n                    curr_scores, curr_finished):\n    \"\"\"Given sequences and scores, will gather the top k=beam size sequences.\n\n    Args:\n      finished_seq: Current finished sequences.\n        [batch_size, beam_size, current_decoded_length]\n      finished_scores: scores for each of these sequences.\n        [batch_size, beam_size]\n      finished_flags: finished bools for each of these sequences.\n        [batch_size, beam_size]\n      curr_seq: current topk sequence that has been grown by one position.\n        [batch_size, beam_size, current_decoded_length]\n      curr_scores: scores for each of these sequences. [batch_size, beam_size]\n      curr_finished: Finished flags for each of these sequences.\n        [batch_size, beam_size]\n    Returns:\n      Tuple of\n        (Topk sequences based on scores,\n         log probs of these sequences,\n         Finished flags of these sequences)\n    \"\"\"\n    if not use_tpu:\n      # First append a column of 0'ids to finished to make the same length with\n      # finished scores\n      finished_seq = tf.concat(\n          [finished_seq,\n           tf.zeros([batch_size, beam_size, 1], tf.int32)], axis=2)\n\n    # Set the scores of the unfinished seq in curr_seq to large negative\n    # values\n    curr_scores += (1. - tf.to_float(curr_finished)) * -INF\n    # concatenating the sequences and scores along beam axis\n    curr_finished_seq = tf.concat([finished_seq, curr_seq], axis=1)\n    curr_finished_scores = tf.concat([finished_scores, curr_scores], axis=1)\n    curr_finished_flags = tf.concat([finished_flags, curr_finished], axis=1)\n    return compute_topk_scores_and_seq(\n        curr_finished_seq,\n        curr_finished_scores,\n        curr_finished_scores,\n        curr_finished_flags,\n        beam_size,\n        batch_size,\n        \"grow_finished\",\n        use_tpu=use_tpu,\n        use_top_k_with_unique=use_top_k_with_unique)\n\n  def grow_alive(curr_seq, curr_scores, curr_log_probs, curr_finished, states):\n    \"\"\"Given sequences and scores, will gather the top k=beam size sequences.\n\n    Args:\n      curr_seq: current topk sequence that has been grown by one position.\n        [batch_size, beam_size, i+1]\n      curr_scores: scores for each of these sequences. [batch_size, beam_size]\n      curr_log_probs: log probs for each of these sequences.\n        [batch_size, beam_size]\n      curr_finished: Finished flags for each of these sequences.\n        [batch_size, beam_size]\n      states: dict (possibly nested) of decoding states.\n    Returns:\n      Tuple of\n        (Topk sequences based on scores,\n         log probs of these sequences,\n         Finished flags of these sequences)\n    \"\"\"\n    # Set the scores of the finished seq in curr_seq to large negative\n    # values\n    curr_scores += tf.to_float(curr_finished) * -INF\n    return compute_topk_scores_and_seq(curr_seq, curr_scores, curr_log_probs,\n                                       curr_finished, beam_size, batch_size,\n                                       \"grow_alive\", states, use_tpu=use_tpu)\n\n  def grow_topk(i, alive_seq, alive_log_probs, states):\n    r\"\"\"Inner beam search loop.\n\n    This function takes the current alive sequences, and grows them to topk\n    sequences where k = 2*beam. We use 2*beam because, we could have beam_size\n    number of sequences that might hit <EOS> and there will be no alive\n    sequences to continue. With 2*beam_size, this will not happen. This relies\n    on the assumption the vocab size is > beam size. If this is true, we'll\n    have at least beam_size non <EOS> extensions if we extract the next top\n    2*beam words.\n    Length penalty is given by = (5+len(decode)/6) ^ -\\alpha. Pls refer to\n    https://arxiv.org/abs/1609.08144.\n\n    Args:\n      i: loop index\n      alive_seq: Topk sequences decoded so far [batch_size, beam_size, i+1]\n      alive_log_probs: probabilities of these sequences. [batch_size, beam_size]\n      states: dict (possibly nested) of decoding states.\n    Returns:\n      Tuple of\n        (Topk sequences extended by the next word,\n         The log probs of these sequences,\n         The scores with length penalty of these sequences,\n         Flags indicating which of these sequences have finished decoding,\n         dict of transformed decoding states)\n    \"\"\"\n    # Get the logits for all the possible next symbols\n    if use_tpu and states:\n      flat_ids = tf.reshape(\n          tf.slice(alive_seq, [0, 0, i], [batch_size, beam_size, 1]),\n          [batch_size * beam_size, -1])\n    else:\n      flat_ids = tf.reshape(alive_seq, [batch_size * beam_size, -1])\n\n    # (batch_size * beam_size, decoded_length)\n    if states:\n      flat_states = nest.map_structure(_merge_beam_dim, states)\n      flat_logits, flat_states = symbols_to_logits_fn(flat_ids, i, flat_states)\n      states = nest.map_structure(\n          lambda t: _unmerge_beam_dim(t, batch_size, beam_size), flat_states)\n    elif use_tpu:\n      flat_logits = symbols_to_logits_fn(flat_ids, i)\n    else:\n      flat_logits = symbols_to_logits_fn(flat_ids)\n\n    logits = tf.reshape(flat_logits, [batch_size, beam_size, -1])\n\n    # Convert logits to normalized log probs\n    candidate_log_probs = common_layers.log_prob_from_logits(logits)\n\n    # Multiply the probabilities by the current probabilities of the beam.\n    # (batch_size, beam_size, vocab_size) + (batch_size, beam_size, 1)\n    log_probs = candidate_log_probs + tf.expand_dims(alive_log_probs, axis=2)\n\n    length_penalty = tf.pow(((5. + tf.to_float(i + 1)) / 6.), alpha)\n\n    curr_scores = log_probs / length_penalty\n    # Flatten out (beam_size, vocab_size) probs in to a list of possibilities\n    flat_curr_scores = tf.reshape(curr_scores, [-1, beam_size * vocab_size])\n\n    if use_tpu and use_top_k_with_unique:\n      topk_scores, topk_ids = top_k_with_unique(\n          flat_curr_scores, k=beam_size * 2)\n    else:\n      topk_scores, topk_ids = tf.nn.top_k(flat_curr_scores, k=beam_size * 2)\n\n    # Recovering the log probs because we will need to send them back\n    topk_log_probs = topk_scores * length_penalty\n\n    # Work out what beam the top probs are in.\n    topk_beam_index = topk_ids // vocab_size\n    topk_ids %= vocab_size  # Unflatten the ids\n\n    if not use_tpu:\n      # The next three steps are to create coordinates for tf.gather_nd to pull\n      # out the correct sequences from id's that we need to grow.\n      # We will also use the coordinates to gather the booleans of the beam\n      # items that survived.\n      batch_pos = compute_batch_indices(batch_size, beam_size * 2)\n\n      # top beams will give us the actual coordinates to do the gather.\n      # stacking will create a tensor of dimension batch * beam * 2, where the\n      # last dimension contains the i,j gathering coordinates.\n      topk_coordinates = tf.stack([batch_pos, topk_beam_index], axis=2)\n\n      # Gather up the most probable 2*beams both for the ids and\n      # finished_in_alive bools\n      topk_seq = tf.gather_nd(alive_seq, topk_coordinates)\n      if states:\n        states = nest.map_structure(\n            lambda state: tf.gather_nd(state, topk_coordinates), states)\n\n      # Append the most probable alive\n      topk_seq = tf.concat([topk_seq, tf.expand_dims(topk_ids, axis=2)], axis=2)\n    else:\n      # Gather up the most probable 2*beams both for the ids and\n      # finished_in_alive bools\n      topk_seq = fast_tpu_gather(alive_seq, topk_beam_index)\n\n      if states:\n        states = nest.map_structure(\n            lambda state: fast_tpu_gather(state, topk_beam_index), states)\n\n      # Update the most probable alive\n      topk_seq = tf.transpose(topk_seq, perm=[2, 0, 1])\n      topk_seq = inplace_ops.alias_inplace_update(topk_seq, i + 1, topk_ids)\n      topk_seq = tf.transpose(topk_seq, perm=[1, 2, 0])\n\n    topk_finished = tf.equal(topk_ids, eos_id)\n\n    return topk_seq, topk_log_probs, topk_scores, topk_finished, states\n\n  def inner_loop(i, alive_seq, alive_log_probs, finished_seq, finished_scores,\n                 finished_flags, states):\n    \"\"\"Inner beam search loop.\n\n    There are three groups of tensors, alive, finished, and topk.\n    The alive group contains information about the current alive sequences\n    The topk group contains information about alive + topk current decoded words\n    the finished group contains information about finished sentences, that is,\n    the ones that have decoded to <EOS>. These are what we return.\n    The general beam search algorithm is as follows:\n    While we haven't terminated (pls look at termination condition)\n      1. Grow the current alive to get beam*2 topk sequences\n      2. Among the topk, keep the top beam_size ones that haven't reached EOS\n      into alive\n      3. Among the topk, keep the top beam_size ones have reached EOS into\n      finished\n    Repeat\n    To make things simple with using fixed size tensors, we will end\n    up inserting unfinished sequences into finished in the beginning. To stop\n    that we add -ve INF to the score of the unfinished sequence so that when a\n    true finished sequence does appear, it will have a higher score than all the\n    unfinished ones.\n\n    Args:\n      i: loop index\n      alive_seq: Topk sequences decoded so far [batch_size, beam_size, i+1]\n      alive_log_probs: probabilities of the beams. [batch_size, beam_size]\n      finished_seq: Current finished sequences.\n        [batch_size, beam_size, i+1]\n      finished_scores: scores for each of these sequences.\n        [batch_size, beam_size]\n      finished_flags: finished bools for each of these sequences.\n        [batch_size, beam_size]\n      states: dict (possibly nested) of decoding states.\n\n    Returns:\n      Tuple of\n        (Incremented loop index\n         New alive sequences,\n         Log probs of the alive sequences,\n         New finished sequences,\n         Scores of the new finished sequences,\n         Flags indicating which sequence in finished as reached EOS,\n         dict of final decoding states)\n    \"\"\"\n\n    # Each inner loop, we carry out three steps:\n    # 1. Get the current topk items.\n    # 2. Extract the ones that have finished and haven't finished\n    # 3. Recompute the contents of finished based on scores.\n    topk_seq, topk_log_probs, topk_scores, topk_finished, states = grow_topk(\n        i, alive_seq, alive_log_probs, states)\n    alive_seq, alive_log_probs, _, states = grow_alive(\n        topk_seq, topk_scores, topk_log_probs, topk_finished, states)\n    finished_seq, finished_scores, finished_flags, _ = grow_finished(\n        finished_seq, finished_scores, finished_flags, topk_seq, topk_scores,\n        topk_finished)\n\n    return (i + 1, alive_seq, alive_log_probs, finished_seq, finished_scores,\n            finished_flags, states)\n\n  def _is_finished(i, unused_alive_seq, alive_log_probs, unused_finished_seq,\n                   finished_scores, unused_finished_in_finished, unused_states):\n    \"\"\"Checking termination condition.\n\n    We terminate when we decoded up to decode_length or the lowest scoring item\n    in finished has a greater score that the highest prob item in alive divided\n    by the max length penalty\n\n    Args:\n      i: loop index\n      alive_log_probs: probabilities of the beams. [batch_size, beam_size]\n      finished_scores: scores for each of these sequences.\n        [batch_size, beam_size]\n\n    Returns:\n      Bool.\n    \"\"\"\n    max_length_penalty = tf.pow(((5. + tf.to_float(decode_length)) / 6.), alpha)\n    # The best possible score of the most likely alive sequence.\n    lower_bound_alive_scores = alive_log_probs[:, 0] / max_length_penalty\n\n    if not stop_early:\n      # by considering the min score (in the top N beams) we ensure that\n      # the decoder will keep decoding until there is at least one beam\n      # (in the top N) that can be improved (w.r.t. the alive beams).\n      # any unfinished beam will have score -INF - thus the min\n      # will always be -INF if there is at least one unfinished beam -\n      # which means the bound_is_met condition cannot be true in this case.\n      lowest_score_of_finished_in_finished = tf.reduce_min(finished_scores)\n    else:\n      # by taking the max score we only care about the first beam;\n      # as soon as this first beam cannot be beaten from the alive beams\n      # the beam decoder can stop.\n      # similarly to the above, if the top beam is not completed, its\n      # finished_score is -INF, thus it will not activate the\n      # bound_is_met condition. (i.e., decoder will keep going on).\n      # note we need to find the max for every sequence eparately - so, we need\n      # to keep the batch dimension (see axis=1)\n      lowest_score_of_finished_in_finished = tf.reduce_max(finished_scores,\n                                                           axis=1)\n\n    bound_is_met = tf.reduce_all(\n        tf.greater(lowest_score_of_finished_in_finished,\n                   lower_bound_alive_scores))\n\n    return tf.logical_and(\n        tf.less(i, decode_length), tf.logical_not(bound_is_met))\n\n  inner_shape = tf.TensorShape([None, None, None])\n  if use_tpu:\n    inner_shape = tf.TensorShape([batch_size, beam_size, decode_length + 1])\n  if use_tpu:\n    state_struc = nest.map_structure(lambda state: state.get_shape(), states)\n  else:\n    state_struc = nest.map_structure(get_state_shape_invariants, states)\n  (_, alive_seq, alive_log_probs, finished_seq, finished_scores,\n   finished_flags, states) = tf.while_loop(\n       _is_finished,\n       inner_loop, [\n           tf.constant(0), alive_seq, alive_log_probs, finished_seq,\n           finished_scores, finished_flags, states\n       ],\n       shape_invariants=[\n           tf.TensorShape([]),\n           inner_shape,\n           alive_log_probs.get_shape(),\n           inner_shape,\n           finished_scores.get_shape(),\n           finished_flags.get_shape(),\n           state_struc\n       ],\n       parallel_iterations=1,\n       back_prop=False)\n\n  alive_seq.set_shape((None, beam_size, None))\n  finished_seq.set_shape((None, beam_size, None))\n\n  # Accounting for corner case: It's possible that no sequence in alive for a\n  # particular batch item ever reached EOS. In that case, we should just copy\n  # the contents of alive for that batch item. tf.reduce_any(finished_flags, 1)\n  # if 0, means that no sequence for that batch index had reached EOS. We need\n  # to do the same for the scores as well.\n  finished_seq = tf.where(\n      tf.reduce_any(finished_flags, 1), finished_seq, alive_seq)\n  finished_scores = tf.where(\n      tf.reduce_any(finished_flags, 1), finished_scores, alive_log_probs)\n  return finished_seq, finished_scores, states", "response": "This function is used to run a beam search on the current state of the current beam."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\naugment video with optional hue saturation and constrast.", "response": "def video_augmentation(features, hue=False, saturate=False, contrast=False):\n  \"\"\"Augments video with optional hue, saturation and constrast.\n\n  Args:\n    features: dict, with keys \"inputs\", \"targets\".\n              features[\"inputs\"], 4-D Tensor, shape=(THWC)\n              features[\"targets\"], 4-D Tensor, shape=(THWC)\n    hue: bool, apply hue_transform.\n    saturate: bool, apply saturation transform.\n    contrast: bool, apply constrast transform.\n  Returns:\n    augment_features: dict with transformed \"inputs\" and \"targets\".\n  \"\"\"\n  inputs, targets = features[\"inputs\"], features[\"targets\"]\n  in_steps = common_layers.shape_list(inputs)[0]\n\n  # makes sure that the same augmentation is applied to both input and targets.\n  # if input is 4-D, then tf.image applies the same transform across the batch.\n  video = tf.concat((inputs, targets), axis=0)\n  if hue:\n    video = tf.image.random_hue(video, max_delta=0.2)\n  if saturate:\n    video = tf.image.random_saturation(video, lower=0.5, upper=1.5)\n  if contrast:\n    video = tf.image.random_contrast(video, lower=0.5, upper=1.5)\n  features[\"inputs\"], features[\"targets\"] = video[:in_steps], video[in_steps:]\n  return features"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_border(video, color=\"blue\", border_percent=2):\n  # Do not create border if the video is not in RGB format\n  if video.shape[-1] != 3:\n    return video\n  color_to_axis = {\"blue\": 2, \"red\": 0, \"green\": 1}\n  axis = color_to_axis[color]\n  _, _, height, width, _ = video.shape\n  border_height = np.ceil(border_percent * height / 100.0).astype(np.int)\n  border_width = np.ceil(border_percent * width / 100.0).astype(np.int)\n  video[:, :, :border_height, :, axis] = 255\n  video[:, :, -border_height:, :, axis] = 255\n  video[:, :, :, :border_width, axis] = 255\n  video[:, :, :, -border_width:, axis] = 255\n  return video", "response": "Creates a border around each frame to differentiate input and target."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_videos_to_summaries(input_videos, output_videos, target_videos,\n                                tag, decode_hparams,\n                                display_ground_truth=False):\n  \"\"\"Converts input, output and target videos into video summaries.\n\n  Args:\n    input_videos: 5-D NumPy array, (NTHWC) conditioning frames.\n    output_videos: 5-D NumPy array, (NTHWC) model predictions.\n    target_videos: 5-D NumPy array, (NTHWC) target frames.\n    tag: tf summary tag.\n    decode_hparams: HParams.\n    display_ground_truth: Whether or not to display ground truth videos.\n  Returns:\n    summaries: a list of tf frame-by-frame and video summaries.\n  \"\"\"\n  fps = decode_hparams.frames_per_second\n  border_percent = decode_hparams.border_percent\n  max_outputs = decode_hparams.max_display_outputs\n  target_steps = target_videos.shape[1]\n  all_summaries = []\n  input_videos = create_border(\n      input_videos, color=\"blue\", border_percent=border_percent)\n  target_videos = create_border(\n      target_videos, color=\"red\", border_percent=border_percent)\n  output_videos = create_border(\n      output_videos, color=\"red\", border_percent=border_percent)\n\n  all_input = np.concatenate((input_videos, target_videos), axis=1)\n  all_output = np.concatenate((input_videos, output_videos), axis=1)\n  output_summ_vals, _ = common_video.py_gif_summary(\n      \"%s/output\" % tag, all_output, max_outputs=max_outputs, fps=fps,\n      return_summary_value=True)\n  all_summaries.extend(output_summ_vals)\n\n  # Optionally display ground truth.\n  if display_ground_truth:\n    input_summ_vals, _ = common_video.py_gif_summary(\n        \"%s/input\" % tag, all_input, max_outputs=max_outputs, fps=fps,\n        return_summary_value=True)\n    all_summaries.extend(input_summ_vals)\n\n  # Frame-by-frame summaries\n  iterable = zip(output_videos[:max_outputs, :target_steps],\n                 target_videos[:max_outputs])\n  for ind, (input_video, output_video) in enumerate(iterable):\n    t, h, w, c = input_video.shape\n    # Tile vertically\n    input_frames = np.reshape(input_video, (t*h, w, c))\n    output_frames = np.reshape(output_video, (t*h, w, c))\n\n    # Concat across width.\n    all_frames = np.concatenate((input_frames, output_frames), axis=1)\n    tag = \"input/output/%s_sample_%d\" % (tag, ind)\n    frame_by_frame_summ = image_utils.image_to_tf_summary_value(\n        all_frames, tag=tag)\n    all_summaries.append(frame_by_frame_summ)\n  return all_summaries", "response": "Converts input output and target videos into video summaries."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhooks to display videos at decode time.", "response": "def display_video_hooks(hook_args):\n  \"\"\"Hooks to display videos at decode time.\"\"\"\n  predictions = hook_args.predictions\n  max_outputs = hook_args.decode_hparams.max_display_outputs\n  max_decodes = hook_args.decode_hparams.max_display_decodes\n\n  with tf.Graph().as_default():\n    _, best_decodes = video_metrics.compute_video_metrics_from_predictions(\n        predictions, decode_hparams=hook_args.decode_hparams)\n\n  all_summaries = []\n  # Displays decodes corresponding to the best/worst metric,\n  for metric, metric_decode_inds in best_decodes.items():\n    curr_metric_inds = metric_decode_inds[:max_outputs]\n    best_inputs, best_outputs, best_targets = [], [], []\n    for sample_ind, decode_ind in enumerate(curr_metric_inds):\n      curr_decode = predictions[decode_ind][sample_ind]\n      best_inputs.append(curr_decode[\"inputs\"])\n      best_outputs.append(curr_decode[\"outputs\"])\n      best_targets.append(curr_decode[\"targets\"])\n    best_inputs = np.array(best_inputs, dtype=np.uint8)\n    best_outputs = np.array(best_outputs, dtype=np.uint8)\n    best_targets = np.array(best_targets, dtype=np.uint8)\n    summaries = convert_videos_to_summaries(\n        best_inputs, best_outputs, best_targets,\n        tag=metric, decode_hparams=hook_args.decode_hparams)\n    all_summaries.extend(summaries)\n\n  # Display random decodes for ten conditioning frames.\n  for decode_ind, decode in enumerate(predictions[: max_decodes]):\n    target_videos = video_metrics.stack_data_given_key(decode, \"targets\")\n    output_videos = video_metrics.stack_data_given_key(decode, \"outputs\")\n    input_videos = video_metrics.stack_data_given_key(decode, \"inputs\")\n    target_videos = np.asarray(target_videos, dtype=np.uint8)\n    output_videos = np.asarray(output_videos, dtype=np.uint8)\n    input_videos = np.asarray(input_videos, dtype=np.uint8)\n    summaries = convert_videos_to_summaries(\n        input_videos, output_videos, target_videos,\n        tag=\"decode_%d\" % decode_ind, decode_hparams=hook_args.decode_hparams,\n        display_ground_truth=decode_ind == 0)\n    all_summaries.extend(summaries)\n  return all_summaries"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef summarize_video_metrics(hook_args):\n  problem_name = hook_args.problem.name\n  current_problem = hook_args.problem\n  hparams = hook_args.hparams\n  output_dirs = hook_args.output_dirs\n  predictions = hook_args.predictions\n  frame_shape = [\n      current_problem.frame_height, current_problem.frame_width,\n      current_problem.num_channels\n  ]\n  metrics_graph = tf.Graph()\n  with metrics_graph.as_default():\n    if predictions:\n      metrics_results, _ = video_metrics.compute_video_metrics_from_predictions(\n          predictions, decode_hparams=hook_args.decode_hparams)\n    else:\n      metrics_results, _ = video_metrics.compute_video_metrics_from_png_files(\n          output_dirs, problem_name, hparams.video_num_target_frames,\n          frame_shape)\n\n  summary_values = []\n  for name, array in six.iteritems(metrics_results):\n    for ind, val in enumerate(array):\n      tag = \"metric_{}/{}\".format(name, ind)\n      summary_values.append(tf.Summary.Value(tag=tag, simple_value=val))\n  return summary_values", "response": "Computes video metrics summaries using the decoder output."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a VideoWriter for debug videos.", "response": "def debug_video_writer_factory(output_dir):\n  \"\"\"Creates a VideoWriter for debug videos.\"\"\"\n  if FLAGS.disable_ffmpeg:\n    return common_video.IndividualFrameWriter(output_dir)\n  else:\n    output_path = os.path.join(output_dir, \"video.avi\")\n    return common_video.WholeVideoWriter(\n        fps=10, output_path=output_path, file_format=\"avi\"\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef preprocess_example(self, example, mode, hparams):\n    if getattr(hparams, \"preprocess_resize_frames\", None) is not None:\n      example[\"frame\"] = tf.image.resize_images(\n          example[\"frame\"], hparams.preprocess_resize_frames,\n          tf.image.ResizeMethod.BILINEAR)\n    return example", "response": "Runtime preprocessing e. g. resize example. frame."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef serving_input_fn(self, hparams):\n    video_input_frames = tf.placeholder(\n        dtype=tf.float32,\n        shape=[\n            None, hparams.video_num_input_frames, self.frame_width,\n            self.frame_height, self.num_channels\n        ])\n\n    # TODO(michalski): add support for passing input_action and input_reward.\n    return tf.estimator.export.ServingInputReceiver(\n        features={\"inputs\": video_input_frames},\n        receiver_tensors=video_input_frames)", "response": "For serving and predict."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_encoded_samples(self, data_dir, tmp_dir, dataset_split):\n    writer = None\n\n    with tf.Graph().as_default():\n      image_t = tf.placeholder(dtype=tf.uint8, shape=(None, None, None))\n      encoded_image_t = tf.image.encode_png(image_t)\n      with tf.Session() as sess:\n        for features in self.generate_samples(data_dir, tmp_dir, dataset_split):\n          unencoded_frame = features.pop(\"frame\")\n          self.validate_frame(unencoded_frame)\n          height, width, _ = unencoded_frame.shape\n          encoded_frame = sess.run(\n              encoded_image_t, feed_dict={image_t: unencoded_frame})\n          features[\"image/encoded\"] = [encoded_frame]\n          features[\"image/format\"] = [\"png\"]\n          features[\"image/height\"] = [height]\n          features[\"image/width\"] = [width]\n\n          has_debug_image = \"image/debug\" in features\n          if has_debug_image:\n            unencoded_debug = features.pop(\"image/debug\")\n            encoded_debug = sess.run(\n                encoded_image_t, feed_dict={image_t: unencoded_debug})\n            features[\"image/encoded_debug\"] = [encoded_debug]\n\n          if self.debug_dump_frames_path:\n            # Defer creating debug writer until we know debug_dump_frames_path.\n            if writer is None:\n              if not tf.gfile.Exists(self.debug_dump_frames_path):\n                tf.gfile.MkDir(self.debug_dump_frames_path)\n              writer = debug_video_writer_factory(self.debug_dump_frames_path)\n            img = unencoded_debug if has_debug_image else unencoded_frame\n            encoded_img = encoded_debug if has_debug_image else encoded_frame\n            writer.write(img, encoded_img)\n\n          yield features\n\n    if self.debug_dump_frames_path:\n      writer.finish_to_disk()", "response": "Generates the encoded samples of the unencoded frames."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a decorator which adds a TF name or variable scope to a function.", "response": "def add_scope(scope=None, scope_fn=None):\n  \"\"\"Return a decorator which add a TF name/variable scope to a function.\n\n  Note that the function returned by the decorator accept an additional 'name'\n  parameter, which can overwrite the name scope given when the function is\n  created.\n\n  Args:\n    scope (str): name of the scope. If None, the function name is used.\n    scope_fn (fct): Either tf.name_scope or tf.variable_scope\n\n  Returns:\n    fct: the add_scope decorator\n  \"\"\"\n  def decorator(f):\n\n    @functools.wraps(f)\n    def decorated(*args, **kwargs):\n      name = kwargs.pop(\"name\", None)  # Python 2 hack for keyword only args\n      with scope_fn(name or scope or f.__name__):\n        return f(*args, **kwargs)\n\n    return decorated\n\n  return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _add_variable_proxy_methods(var, proxy_tensor):\n  proxy_tensor.read_value = lambda: tf.identity(proxy_tensor)\n  proxy_tensor.assign_sub = var.assign_sub\n  proxy_tensor.assign = var.assign\n  proxy_tensor.initialized_value = var.initialized_value", "response": "Adds the proxy methods of underlying variable.\n This enables our custom getters to still work with e. g. batch norm.\n This enables our custom getters to still work with e. g. batch norm.\n"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _prob_in_top_k(\n    clean_values, noisy_values, noise_stddev, noisy_top_values, k):\n  \"\"\"Helper function to NoisyTopKGating.\n\n  Computes the probability that value is in top k, given different random noise.\n\n  This gives us a way of backpropagating from a loss that balances the number\n  of times each expert is in the top k experts per example.\n\n  In the case of no noise, pass in None for noise_stddev, and the result will\n  not be differentiable.\n\n  Args:\n    clean_values: a `Tensor` of shape [batch, n].\n    noisy_values: a `Tensor` of shape [batch, n].  Equal to clean values plus\n      normally distributed noise with standard deviation noise_stddev.\n    noise_stddev: a `Tensor` of shape [batch, n], or None\n    noisy_top_values: a `Tensor` of shape [batch, m].\n       \"values\" Output of tf.top_k(noisy_top_values, m).  m >= k+1\n    k: an integer.\n\n  Returns:\n    a `Tensor` of shape [batch, n].\n  \"\"\"\n  batch = tf.shape(clean_values)[0]\n  m = tf.shape(noisy_top_values)[1]\n  top_values_flat = tf.reshape(noisy_top_values, [-1])\n  # we want to compute the threshold that a particular value would have to\n  # exceed in order to make the top k.  This computation differs depending\n  # on whether the value is already in the top k.\n  threshold_positions_if_in = tf.range(batch) * m + k\n  threshold_if_in = tf.expand_dims(\n      tf.gather(top_values_flat, threshold_positions_if_in), 1)\n  is_in = tf.greater(noisy_values, threshold_if_in)\n  if noise_stddev is None:\n    return tf.to_float(is_in)\n  threshold_positions_if_out = threshold_positions_if_in - 1\n  threshold_if_out = tf.expand_dims(\n      tf.gather(top_values_flat, threshold_positions_if_out), 1)\n  # is each value currently in the top k.\n  prob_if_in = _normal_distribution_cdf(clean_values - threshold_if_in,\n                                        noise_stddev)\n  prob_if_out = _normal_distribution_cdf(clean_values - threshold_if_out,\n                                         noise_stddev)\n  prob = tf.where(is_in, prob_if_in, prob_if_out)\n  return prob", "response": "Private function that computes the probability that a value is in the top k."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the squared coefficient of variation of a sample.", "response": "def cv_squared(x):\n  \"\"\"The squared coefficient of variation of a sample.\n\n  Useful as a loss to encourage a positive distribution to be more uniform.\n  Epsilons added for numerical stability.\n  Returns 0 for an empty Tensor.\n\n  Args:\n    x: a `Tensor`.\n\n  Returns:\n    a `Scalar`.\n  \"\"\"\n  epsilon = 1e-10\n  float_size = tf.to_float(tf.size(x)) + epsilon\n  mean = tf.reduce_sum(x) / float_size\n  variance = tf.reduce_sum(tf.squared_difference(x, mean)) / float_size\n  return variance / (tf.square(mean) + epsilon)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_hparams_for_vq_gating(hparams):\n  hparams.add_hparam(\"z_size\", 4)\n  hparams.add_hparam(\"noise_dev\", 0.5)\n  # Bottleneck kinds supported: dense, vae, dvq.\n  hparams.add_hparam(\"bottleneck_kind\", \"dvq\")\n  hparams.add_hparam(\"num_blocks\", 1)\n  hparams.add_hparam(\"num_residuals\", 1)\n  # Reshape method for DVQ: slice, project\n  hparams.add_hparam(\"beta\", 0.25)\n  hparams.add_hparam(\"epsilon\", 1e-5)\n  hparams.add_hparam(\"decay\", 0.999)\n  hparams.add_hparam(\"ema\", False)  # default is false until ema is implemented\n  hparams.add_hparam(\"random_top_k\", 1)\n  hparams.add_hparam(\"soft_em\", False)\n  hparams.add_hparam(\"num_samples\", 10)\n  hparams.add_hparam(\"gating_type\", \"vq\")\n  hparams.add_hparam(\"use_scales\", int(True))\n  hparams.add_hparam(\"residual_centroids\", int(False))", "response": "Update hparams for vq gating."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _my_top_k(x, k):\n  if k > 10:\n    return tf.nn.top_k(x, k)\n  values = []\n  indices = []\n  depth = tf.shape(x)[1]\n  for i in range(k):\n    values.append(tf.reduce_max(x, 1))\n    argmax = tf.argmax(x, 1)\n    indices.append(argmax)\n    if i + 1 < k:\n      x += tf.one_hot(argmax, depth, -1e9)\n  return tf.stack(values, axis=1), tf.to_int32(tf.stack(indices, axis=1))", "response": "GPU - compatible version of top - k that works for very small constant k."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\napply a function to each coordinate id of a multidimensional tensor.", "response": "def map_ids(x, indices, map_fn):\n  \"\"\"Apply a function to each coordinate ids of a multidimensional tensor.\n\n  This allows to process each sequence of a batch independently. This is\n  similar to tf.map_fn but with tensor where the batch dim has been flatten.\n\n  Warning: The indices ids have to be contiguous and ordered in memory as the\n  output vector for each of the ids are simply concatenated after being\n  processed.\n  Ex: if your indices are [0,2,2,1,2,0], the output will contains the processed\n  rows in the following order: [0,0,1,2,2,2]\n\n  Args:\n    x (Tensor): The tensor to be dispatched of shape [length,...]\n    indices (Tensor): A int32 tensor of size [length, 1] containing the batch\n      coordinate of x\n    map_fn (fct): Function called for every ids of the original tensor. Take\n      as input a tensor of same rank than x and from shape [length_id,...] with\n      length_id <= length. Isn't called if length_id == 0\n\n  Returns:\n    a tensor of same shape as x, where each elements has been processed\n  \"\"\"\n  indices = tf.reshape(indices, [-1])\n\n  t_i = tf.constant(0)\n  # batch_coordinates start at 0\n  t_batch_size = tf.reduce_max(indices) + 1\n\n  # ta_stack_out will store the intermediate results for each individual id\n  # As alternative to tf.TensorArray, scatter_update could potentially be used\n  # but that would require an additional mutable tensor.\n  ta_stack_out = tf.TensorArray(\n      x.dtype,\n      size=t_batch_size,\n  )\n\n  # Then we iterate over each sequence individually and compute the\n  # transformation for each id\n  while_condition = lambda t_i, *args: tf.less(t_i, t_batch_size)\n  def body(t_i, ta_stack_out):\n    \"\"\"Loop body.\"\"\"\n    # Gather the ids\n    current_ids = tf.to_int32(tf.where(tf.equal(indices, t_i)))\n    t_row = tf.gather_nd(x, indices=current_ids)\n\n    # TODO(epot): Should not call map_fn if t_row size is 0\n\n    # Apply transformation to each id\n    # Restore batch_dim=1 as most function expect [batch_dim, length, ...] as\n    # input\n    t_row = tf.expand_dims(t_row, axis=0)\n    t_row = map_fn(t_row)\n    t_row = tf.squeeze(t_row, axis=0)  # Squeeze for concatenation\n    ta_stack_out = ta_stack_out.write(t_i, t_row)\n\n    return [tf.add(t_i, 1), ta_stack_out]  # ++i\n\n  # Run the loop, equivalent to:\n  # stack_out = []\n  # while i < batch_size:\n  #   stack_out.expand(map_fn(x[indices==i]))\n  _, ta_stack_out = tf.while_loop(while_condition, body, [t_i, ta_stack_out])\n\n  # Merge all results\n  return ta_stack_out.concat()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a function that creates a feed - forward network.", "response": "def ffn_expert_fn(input_size,\n                  hidden_sizes,\n                  output_size,\n                  hidden_activation=tf.nn.relu):\n  \"\"\"Returns a function that creates a feed-forward network.\n\n  Use this function to create the expert_fn argument to distributed_moe.\n\n  Args:\n    input_size: an integer\n    hidden_sizes: a list of integers\n    output_size: an integer\n    hidden_activation: a unary function.\n\n  Returns:\n    a unary function\n  \"\"\"\n  def my_fn(x):\n    layer_sizes = [input_size] + hidden_sizes + [output_size]\n    for i in range(1 + len(hidden_sizes)):\n      w = tf.get_variable(\"w_%d\" % i, layer_sizes[i:i+2], tf.float32)\n      x = tf.matmul(x, w)\n      if i < len(hidden_sizes):\n        x = hidden_activation(x)\n      if layer_sizes[i] != input_size:\n        x *= (layer_sizes[i] / float(input_size))**-0.5\n    return x\n  return my_fn"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nflattening all dimensions of a except the last.", "response": "def flatten_all_but_last(a):\n  \"\"\"Flatten all dimensions of a except the last.\"\"\"\n  ret = tf.reshape(a, [-1, tf.shape(a)[-1]])\n  if not tf.executing_eagerly():\n    ret.set_shape([None] + a.get_shape().as_list()[-1:])\n  return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling a local mixture of experts. Args: x: a tensors with shape [... , input_size] train: a boolean scalar. expert_fn: a function. num_experts: an integer - number of experts k: an integer - how many experts to use for each batch element loss_coef: a scalar - multiplier on load-balancing losses hparams: optional hparams for vq gating pass_x: a boolean. If true, x will also be dispatched to the experts. pass_gates: a boolean. If true, gates will be passed to experts. Might be necessary when dealing with sparse encoder-encoder decoder attention additional_dispatch_params: The extra tensors that need to be sent to each expert. Examples include batch batch coordinates (see common_attention.local_expert_attention) name: a string Returns: y: a tensor. Has the same shape as x, except for the last dimension, which is output_size. extra_training_loss: a scalar. This should be added into the overall training loss of the model. The backpropagation of this loss encourages all experts to be approximately equally used across a batch.", "response": "def local_moe(x,\n              train,\n              expert_fn,\n              num_experts,\n              k=1,\n              loss_coef=1e-2,\n              hparams=None,\n              pass_x=True,\n              pass_gates=False,\n              additional_dispatch_params=None,\n              name=None):\n  \"\"\"Call a local mixture of experts.\n\n  Args:\n    x: a tensors with shape [... , input_size]\n    train: a boolean scalar.\n    expert_fn: a function.\n    num_experts: an integer - number of experts\n    k: an integer - how many experts to use for each batch element\n    loss_coef: a scalar - multiplier on load-balancing losses\n    hparams: optional hparams for vq gating\n    pass_x: a boolean. If true, x will also be dispatched to the experts.\n    pass_gates: a boolean. If true, gates will be passed to experts. Might be\n      necessary when dealing with sparse encoder-encoder decoder attention\n    additional_dispatch_params: The extra tensors that need to be sent to each\n      expert. Examples include batch batch coordinates (see\n      common_attention.local_expert_attention)\n    name: a string\n\n  Returns:\n    y: a tensor.  Has the same shape as x, except for the last dimension,\n      which is output_size.\n    extra_training_loss: a scalar.  This should be added into the overall\n      training loss of the model.  The backpropagation of this loss\n      encourages all experts to be approximately equally used across a batch.\n  \"\"\"\n  bneck = DiscreteBottleneck(hparams)\n  with tf.variable_scope(name, default_name=\"local_moe\"):\n    centroids = None\n    x_flat = flatten_all_but_last(x)\n    if hparams.gating_type == \"topk\":\n      tf.logging.info(\"Using noisy top_k with k = {}\".format(k))\n      # The gates indicate which batch elements go to which tensors.\n      # load is a measure of approximately how many examples go to each expert\n      gates, load = noisy_top_k_gating(\n          x_flat,\n          num_experts,\n          train,\n          k,\n          initializer=tf.zeros_initializer(),\n          noisy_gating=True,\n          noise_epsilon=1e-2)\n      importance = tf.reduce_sum(gates, 0)\n      loss = loss_coef * (cv_squared(importance) + cv_squared(load))\n    else:\n      assert hparams.gating_type == \"vq\"\n      tf.logging.info(\"Using VQ gating\")\n      gates, loss, centroids = vq_gating(\n          x_flat, num_experts, k, bneck, hparams=hparams)\n    loss *= loss_coef\n    # Shuffle data between datashards and experts.\n    dispatcher = SparseDispatcher(num_experts, gates)\n    # Set up expert_fn arguments\n    expert_kwargs = {}\n    if pass_x:\n      expert_kwargs[\"x\"] = dispatcher.dispatch(x_flat)\n    if pass_gates:\n      expert_kwargs[\"gates\"] = dispatcher.expert_to_gates()\n    for key, val in six.iteritems(additional_dispatch_params or {}):\n      val = flatten_all_but_last(val)\n      expert_kwargs[key] = dispatcher.dispatch(val)\n\n    ep = Parallelism([DEFAULT_DEV_STRING] * num_experts, reuse=None)\n    expert_outputs = ep(expert_fn, **expert_kwargs)\n\n    y_flat = dispatcher.combine(expert_outputs)\n    if centroids is not None:\n      centroids = tf.squeeze(centroids, axis=[1, 2])\n      y_flat += centroids\n    y = common_layers.reshape_like(y_flat, x)\n    return y, loss"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef local_moe_tpu(inputs,\n                  hidden_size,\n                  output_size,\n                  num_experts,\n                  loss_coef=1e-3,\n                  overhead=1.0):\n  \"\"\"Local mixture of experts that works well on TPU.\n\n  See https://arxiv.org/abs/1701.06538\n\n  There are num_experts expert networks, each containing a relu-activated\n  hidden layer of size hidden_size, followed by an output projection.\n\n  The number of parameters is thus:\n    num_experts * (input_size * hidden_size + hidden_size * output_size)\n\n  The input is 3d: [batch, length, depth], consisting of the representations\n  of all positions in a batch of sequences.\n\n  Each position of each sequence is sent to 0-2 experts.  The expert\n  choices and the combination weights are determined by a learned gating\n  function.\n\n  This function returns a small auxiliary loss that should be added to the\n  training loss of the model.  This loss helps to balance expert usage.\n  Without the loss, it is very likely that a few experts will be trained and\n  the rest will starve.\n\n  Several hacks are necessary to get around current TPU limitations:\n\n  - To ensure static shapes, we enforce (by truncation/padding)\n    that each sequence send the same number of elements to each expert.\n\n    It would make more sense to enforce this equality over the entire batch,\n    as opposed to on individual sequences.  This would allow more freedom\n    for individual sequences to be unbalanced.  Unfortunately, that would\n    slow down our hacked-up gather-by-matmul implementation.\n\n    TODO(noam): There is no real reason for a single sequence to be the unit\n      of equal allocation.  Reshaping the inputs would allow us to pick a\n      different unit of equal allocation.\n\n  TODO(noam): Factor this code better.  We want to be able to substitute\n  different code for the experts themselves.  We also want to integrate this\n  gating/dispatching logic into multi-device mixtures-of-experts.\n\n  Args:\n    inputs: a Tensor with shape [batch, length, depth]\n    hidden_size: an integer\n    output_size: an integer\n    num_experts: an integer\n    loss_coef: a float scalar\n    overhead: multiplicative factor of how much spare capacity to assign\n\n  Returns:\n    outputs: a Tensor with shape [batch, length, output_size]\n    loss: a scalar\n  \"\"\"\n  batch, length, input_size = common_layers.shape_list(inputs)[:]\n  # Each sequence sends expert_capacity positions to each expert.\n  if isinstance(length, int):\n    expert_capacity = min(\n        length, int((length * 2 * overhead) / num_experts))\n  else:\n    expert_capacity = tf.minimum(\n        length, tf.to_int32(\n            tf.to_float(length) * 2 * overhead / num_experts))\n  expert_capacity_f = tf.to_float(expert_capacity)\n\n  # This is the learned gating function.\n  gates = tf.nn.softmax(\n      tf.to_float(common_layers.dense(inputs, num_experts, name=\"logits\")))\n\n  # Find the top expert for each position.\n  gate_1, index_1 = common_layers.top_1_tpu(gates)\n  # [batch, length, num_experts]\n  mask_1 = tf.one_hot(index_1, num_experts)\n  # [batch, length, num_experts]\n  # This is the position within the expert's mini-batch for this sequence\n  position_in_expert_1 = common_layers.cumsum(\n      mask_1, axis=1, exclusive=True) * mask_1\n  # Remove the elements that don't fit.\n  mask_1 *= tf.to_float(tf.less(position_in_expert_1, expert_capacity_f))\n  # [batch, 1, num_experts]\n  # How many examples in this sequence go to this expert\n  mask_1_count = tf.reduce_sum(mask_1, axis=1, keepdims=True)\n  # [batch, length] - mostly ones, but zeros where something didn't fit\n  mask_1_flat = tf.reduce_sum(mask_1, axis=2)\n  position_in_expert_1 = tf.reduce_sum(position_in_expert_1, axis=2)\n  # Weight assigned to first expert.\n  gate_1 *= mask_1_flat\n\n  # Pick a second-place expert for each position.\n  # We first mask out the experts that we expect to be over-capacity\n  space_remaining = expert_capacity_f - mask_1_count\n  use_rate = (mask_1_count + 1.0) / tf.to_float(length)\n  # At what point in the sequence do we expect the expert to be full.\n  expected_exhaustion_pos = space_remaining / use_rate\n  # A Tensor with shape [batch, length, num_experts] representing a boolean\n  #   - whether we expect that the expert will already be full.\n  expected_exhausted = tf.to_float(tf.greater(\n      tf.reshape(tf.to_float(tf.range(length)), [1, length, 1]),\n      expected_exhaustion_pos))\n  masked_gates = gates - mask_1 - expected_exhausted\n  # This section is similar to the section above.\n  gate_2, index_2 = common_layers.top_1_tpu(masked_gates)\n  # [batch, length, num_experts]\n  mask_2 = tf.one_hot(index_2, num_experts)\n  position_in_expert_2 = (\n      common_layers.cumsum(mask_2, axis=1, exclusive=True) + mask_1_count)\n  position_in_expert_2 *= mask_2\n  mask_2 *= tf.to_float(tf.less(position_in_expert_2, expert_capacity_f))\n  mask_2_count = tf.reduce_sum(mask_2, axis=1, keepdims=True)\n  mask_2_flat = tf.reduce_sum(mask_2, axis=2)\n  position_in_expert_2 = tf.reduce_sum(position_in_expert_2, axis=2)\n  gate_2 *= mask_2_flat\n\n  # What fraction didn't fit - show summaries\n  miss_rate_1 = 1.0 - tf.reduce_sum(mask_1_count) / tf.to_float(batch * length)\n  miss_rate_2 = 1.0 - tf.reduce_sum(mask_2_count) / tf.to_float(batch * length)\n  tf.summary.scalar(\"miss_rate_1\", miss_rate_1)\n  tf.summary.scalar(\"miss_rate_2\", miss_rate_2)\n\n  # renormalize the two gate values to add up to 1\n  denom = gate_1 + gate_2 + 1e-9\n  gate_1 /= denom\n  gate_2 /= denom\n\n  # inputs: [batch, length, input_size]\n  # forward_assignment: [batch, length, num_experts * expert_capacity]\n  # expert_inputs: [batch, num_experts * expert_capacity, input_size]\n\n  segment_ids_forward_1 = (\n      (index_1 * expert_capacity) +\n      tf.to_int32(position_in_expert_1) +\n      tf.to_int32(1.0 - mask_1_flat) * (num_experts * expert_capacity))\n\n  segment_ids_forward_2 = (\n      (index_2 * expert_capacity) +\n      tf.to_int32(position_in_expert_2) +\n      tf.to_int32(1.0 - mask_2_flat) * (num_experts * expert_capacity))\n\n  # Gather and scatter are painfully slow on TPU.\n  # We will use one_hot and matmul instead.\n\n  # [batch, length, num_experts * expert_capacity]\n  one_hot_1 = tf.one_hot(\n      segment_ids_forward_1, num_experts * expert_capacity, dtype=inputs.dtype)\n  one_hot_2 = tf.one_hot(\n      segment_ids_forward_2, num_experts * expert_capacity, dtype=inputs.dtype)\n\n  forward_assignment = (one_hot_1 + one_hot_2)\n\n  # [batch, num_experts * expert_capacity, input_size]\n  expert_inputs = tf.matmul(forward_assignment, inputs, transpose_a=True)\n\n  # [batch, num_experts, expert_capacity, input_size]\n  expert_inputs = tf.reshape(\n      expert_inputs, [batch, num_experts, expert_capacity, input_size])\n  # [num_experts, batch, expert_capacity, input_size]\n  expert_inputs = tf.transpose(expert_inputs, [1, 0, 2, 3])\n\n  # [num_experts, batch * expert_capacity, input_size]\n  expert_inputs = tf.reshape(\n      expert_inputs, [num_experts, batch * expert_capacity, input_size])\n\n  # Now feed the expert inputs through the experts.\n  h = common_layers.batch_dense(\n      expert_inputs, hidden_size, activation=tf.nn.relu, name=\"x0\")\n  expert_output = common_layers.batch_dense(h, output_size, name=\"x1\")\n  expert_output = tf.reshape(\n      expert_output, [num_experts, batch, expert_capacity, output_size])\n\n  # [batch, num_experts, expert_capacity, output_size]\n  expert_output = tf.transpose(expert_output, [1, 0, 2, 3])\n  expert_output = tf.reshape(\n      expert_output, [batch, num_experts * expert_capacity, output_size])\n\n  # Again, use matmul instead of unsorted_segment_sum.  This time, we need\n  # to multiply by the combination weights gate_1 and gate_2.\n\n  # expert_output: [batch, num_experts * expert_capacity, output_size]\n  # backward_assigmnent: [batch, length, num_experts * expert_capacity]\n  # output: [batch, length, output_size]\n  backward_assigmnent = (\n      one_hot_1 * tf.cast(tf.expand_dims(gate_1, 2), inputs.dtype) +\n      one_hot_2 * tf.cast(tf.expand_dims(gate_2, 2), inputs.dtype))\n  output = tf.matmul(backward_assigmnent, expert_output)\n\n  # Compute a loss equal to the coefficient ov variation of the\n  # total gate value per expert per sequence.\n  # This loss causes the experts to be used about equally used per sequence.\n  importance = tf.reduce_sum(gates * (mask_1 + mask_2), 1)\n  loss = loss_coef * cv_squared(importance)\n  return output, loss", "response": "Local mixture of experts that works well on TPU."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreduces data per device.", "response": "def reduce_by_device(parallelism, data, reduce_fn):\n  \"\"\"Reduces data per device.\n\n  This can be useful, for example, if we want to all-reduce n tensors on k<n\n  devices (like during eval when we have only one device).  We call\n  reduce_by_device() to first sum the tensors per device, then call our usual\n  all-reduce operation to create one sum per device, followed by\n  expand_by_device, to create the appropriate number of pointers to these\n  results.  See all_reduce_ring() below for an example of how this is used.\n\n  Args:\n    parallelism: a expert_utils.Parallelism object\n    data: a list of Tensors with length parallelism.n\n    reduce_fn: a function taking a list of Tensors.  e.g. tf.add_n\n\n  Returns:\n    device_parallelism: a Parallelism object with each device listed only once.\n    reduced_data: A list of Tensors, one per device.\n  \"\"\"\n  unique_devices = []\n  device_to_data = {}\n  for dev, datum in zip(parallelism.devices, data):\n    if dev not in device_to_data:\n      unique_devices.append(dev)\n      device_to_data[dev] = [datum]\n    else:\n      device_to_data[dev].append(datum)\n  device_parallelism = Parallelism(unique_devices)\n  grouped_data = [device_to_data[dev] for dev in unique_devices]\n  return device_parallelism, device_parallelism(reduce_fn, grouped_data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef expand_by_device(original_parallelism, device_parallelism, data):\n  device_to_datum = {\n      device_parallelism.devices[i]: data[i]\n      for i in range(device_parallelism.n)}\n  return [device_to_datum[d] for d in original_parallelism.devices]", "response": "Opposite of reduce_by_device().\n\n  Args:\n    original_parallelism: a expert_utils.Parallelism object.\n    device_parallelism: a expert_utils.Parallelism object.\n    data: a list of tensors with length device_parallelism.n\n\n  Returns:\n    a list of Tensors with length original_parallelism.n"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the sum of all Tensors and put the result everywhere.", "response": "def all_reduce_ring(x, parallelism, maybe_reduce=True, use_bfloat16=True):\n  \"\"\"Compute the sum of all Tensors and put the result everywhere.\n\n  Assumes that the devices are connected in a ring.\n\n  Args:\n    x: a list of Tensors with length parallelism.n\n    parallelism: a expert_utils.Parallelism object.\n    maybe_reduce: a boolean - first reduce per device.\n    use_bfloat16: a boolean - saves bandwidth but loses precision\n\n  Returns:\n    a list of Tensors with length parallelism.n\n  \"\"\"\n  if parallelism.n == 1:\n    return x\n\n  if maybe_reduce:\n    original_parallelism = parallelism\n    parallelism, x = reduce_by_device(parallelism, x, tf.add_n)\n\n  if parallelism.n == 1:\n    y = x\n  else:\n    # first shard the input:\n    x_flat = parallelism(tf.reshape, x, [[-1]] * parallelism.n)\n    # [device, shard]\n    x_split = parallelism(\n        common_layers.approximate_split, x_flat, parallelism.n, 0)\n    def _step(source_replica, target_replica, x_split, op=\"plus_eq\"):\n      \"\"\"Helper function - one step of summing or copying.\n\n      If op == \"plus_eq\", then adds source_replica into target_replica\n      If op == \"copy\", then copies source_replica onto target_replica\n\n      These operations happen for all shards.  The replica numbers are offset\n      by the shard numbers to keep all physical links busy.\n\n      Args:\n        source_replica: an integer\n        target_replica: an integer\n        x_split: a list of lists of tensors\n        op: a string\n      \"\"\"\n      for shard in range(parallelism.n):\n        source_device = (shard + source_replica) % parallelism.n\n        target_device = (shard + target_replica) % parallelism.n\n        source = x_split[source_device][shard]\n        if use_bfloat16:\n          with tf.device(parallelism.devices[source_device]):\n            source = tf.to_bfloat16(source)\n        with tf.device(parallelism.devices[target_device]):\n          source = tf.to_float(source)\n          if op == \"plus_eq\":\n            x_split[target_device][shard] += source\n          else:\n            assert op == \"copy\"\n            x_split[target_device][shard] = tf.identity(source)\n    center = parallelism.n // 2\n\n    # accumulate everything towards the center.\n    for i in reversed(range(center, parallelism.n - 1)):\n      _step(i + 1, i, x_split, op=\"plus_eq\")\n    for i in range(center):\n      _step(i, i + 1, x_split, op=\"plus_eq\")\n    # copy everything away from the center.\n    for i in range(center, parallelism.n - 1):\n      _step(i, i + 1, x_split, op=\"copy\")\n    for i in reversed(range(center)):\n      _step(i + 1, i, x_split, op=\"copy\")\n    x_concat = parallelism(tf.concat, x_split, 0)\n    y = parallelism(common_layers.reshape_like_all_dims, x_concat, x)\n  if maybe_reduce:\n    y = expand_by_device(original_parallelism, parallelism, y)\n  return y"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove(self, x):\n    with tf.name_scope(\"pad_reduce/remove\"):\n      x_shape = x.get_shape().as_list()\n      x = tf.gather_nd(\n          x,\n          indices=self.nonpad_ids,\n      )\n      if not tf.executing_eagerly():\n        # This is a hack but for some reason, gather_nd return a tensor of\n        # undefined shape, so the shape is set up manually\n        x.set_shape([None] + x_shape[1:])\n    return x", "response": "Remove padding from the given tensor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd padding back to the given tensor.", "response": "def restore(self, x):\n    \"\"\"Add padding back to the given tensor.\n\n    Args:\n      x (tf.Tensor): of shape [dim_compressed,...]\n\n    Returns:\n      a tensor of shape [dim_origin,...] with dim_compressed >= dim_origin. The\n      dim is restored from the original reference tensor\n    \"\"\"\n    with tf.name_scope(\"pad_reduce/restore\"):\n      x = tf.scatter_nd(\n          indices=self.nonpad_ids,\n          updates=x,\n          shape=tf.concat([self.dim_origin, tf.shape(x)[1:]], axis=0),\n      )\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dispatch(self, inp):\n    inp = tf.gather(inp, self._batch_index)\n    return tf.split(inp, self._part_sizes_tensor, 0, num=self._num_experts)", "response": "Create one input Tensor for each expert."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsums together the expert output with the gates.", "response": "def combine(self, expert_out, multiply_by_gates=True):\n    \"\"\"Sum together the expert output, weighted by the gates.\n\n    The slice corresponding to a particular batch element `b` is computed\n    as the sum over all experts `i` of the expert output, weighted by the\n    corresponding gate values.  If `multiply_by_gates` is set to False, the\n    gate values are ignored.\n\n    Args:\n      expert_out: a list of `num_experts` `Tensor`s, each with shape\n        `[expert_batch_size_i, <extra_output_dims>]`.\n      multiply_by_gates: a boolean\n\n    Returns:\n      a `Tensor` with shape `[batch_size, <extra_output_dims>]`.\n    \"\"\"\n    # see comments on convert_gradient_to_tensor\n    stitched = common_layers.convert_gradient_to_tensor(\n        tf.concat(expert_out, 0))\n    if multiply_by_gates:\n      stitched *= tf.expand_dims(self._nonzero_gates, 1)\n    combined = tf.unsorted_segment_sum(stitched, self._batch_index,\n                                       tf.shape(self._gates)[0])\n    return combined"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef expert_to_gates(self):\n    return tf.split(\n        self._nonzero_gates, self._part_sizes_tensor, 0, num=self._num_experts)", "response": "Returns a list of tensors corresponding to the examples in the per - expert Tensor s."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of batch indices corresponding to the examples in the per - expert Tensor s.", "response": "def expert_to_batch_indices(self):\n    \"\"\"Batch indices corresponding to the examples in the per-expert `Tensor`s.\n\n    Returns:\n      a list of `num_experts` one-dimensional `Tensor`s with type `tf.int64`\n          and shapes `[expert_batch_size_i]`\n    \"\"\"\n    return tf.split(\n        self._batch_index, self._part_sizes_tensor, 0, num=self._num_experts)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndispatch the input tensor inp and returns a list of num_experts Tensors with shapes [ batch_size num_examples ].", "response": "def dispatch(self, inp):\n    \"\"\"Create one input Tensor for each expert.\n\n    Args:\n      inp: a list of length num_datashards `Tensor`s with shapes\n        `[batch_size[d], <extra_input_dims>]`.\n    Returns:\n      a list of `num_experts` `Tensor`s with shapes\n        `[num_examples[i], <extra_input_dims>]`.\n    \"\"\"\n    dispatched = self._dp(lambda a, b: a.dispatch(b), self._dispatchers, inp)\n    ret = self._ep(tf.concat, transpose_list_of_lists(dispatched), 0)\n    if ret[0].dtype == tf.float32:\n      # see comments on common_layers.convert_gradient_to_tensor\n      ret = self._ep(common_layers.convert_gradient_to_tensor, ret)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef combine(self, expert_out, multiply_by_gates=True):\n    expert_part_sizes = tf.unstack(\n        tf.stack([d.part_sizes for d in self._dispatchers]),\n        num=self._ep.n,\n        axis=1)\n    # list of lists of shape [num_experts][num_datashards]\n    expert_output_parts = self._ep(tf.split, expert_out, expert_part_sizes)\n    expert_output_parts_t = transpose_list_of_lists(expert_output_parts)\n    def my_combine(dispatcher, parts):\n      return dispatcher.combine(\n          common_layers.convert_gradient_to_tensor(tf.concat(parts, 0)),\n          multiply_by_gates=multiply_by_gates)\n    return self._dp(my_combine, self._dispatchers, expert_output_parts_t)", "response": "Combine the expert output with the dispatchers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of num_experts one - dimensional Tensor s corresponding to the examples in the per - expert Tensor s.", "response": "def expert_to_gates(self):\n    \"\"\"Gate values corresponding to the examples in the per-expert `Tensor`s.\n\n    Returns:\n      a list of `num_experts` one-dimensional `Tensor`s of type `tf.float32`.\n    \"\"\"\n    return self._ep(\n        tf.concat,\n        transpose_list_of_lists(\n            self._dp(lambda d: d.expert_to_gates(), self._dispatchers)), 0)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dispatch(self, inp):\n    inp = tf.reshape(inp, [self._batch * self._length, -1])\n    # [batch, num_experts, expert_capacity, depth]\n    ret = tf.gather(inp, self._flat_indices)\n    return ret", "response": "Send the inputs to the experts.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef combine(self, x):\n    depth = tf.shape(x)[-1]\n    x *= tf.expand_dims(self._nonpadding, -1)\n    ret = tf.unsorted_segment_sum(\n        x, self._flat_indices, num_segments=self._batch * self._length)\n    ret = tf.reshape(ret, [self._batch, self._length, depth])\n    return ret", "response": "Combine the output from the experts."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_env(env_type, real_env, sim_env_kwargs):\n  return {\n      \"real\": lambda: real_env.new_like(  # pylint: disable=g-long-lambda\n          batch_size=sim_env_kwargs[\"batch_size\"],\n          store_rollouts=False,\n      ),\n      \"simulated\": lambda: rl_utils.SimulatedBatchGymEnvWithFixedInitialFrames(  # pylint: disable=g-long-lambda\n          **sim_env_kwargs\n      ),\n  }[env_type]()", "response": "Factory function for envs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_agent(\n    agent_type, env, policy_hparams, policy_dir, sampling_temp,\n    sim_env_kwargs_fn=None, frame_stack_size=None, rollout_agent_type=None,\n    batch_size=None, inner_batch_size=None, env_type=None, **planner_kwargs\n):\n  \"\"\"Factory function for Agents.\"\"\"\n  if batch_size is None:\n    batch_size = env.batch_size\n  return {\n      \"random\": lambda: rl_utils.RandomAgent(  # pylint: disable=g-long-lambda\n          batch_size, env.observation_space, env.action_space\n      ),\n      \"policy\": lambda: rl_utils.PolicyAgent(  # pylint: disable=g-long-lambda\n          batch_size, env.observation_space, env.action_space,\n          policy_hparams, policy_dir, sampling_temp\n      ),\n      \"planner\": lambda: rl_utils.PlannerAgent(  # pylint: disable=g-long-lambda\n          batch_size, make_agent(\n              rollout_agent_type, env, policy_hparams, policy_dir,\n              sampling_temp, batch_size=inner_batch_size\n          ), make_env(env_type, env.env, sim_env_kwargs_fn()),\n          lambda env: rl_utils.BatchStackWrapper(env, frame_stack_size),\n          discount_factor=policy_hparams.gae_gamma, **planner_kwargs\n      ),\n  }[agent_type]()", "response": "Factory function for Agents."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncollects frames from real env for random starts of simulated env.", "response": "def collect_frames_for_random_starts(\n    storage_env, stacked_env, agent, frame_stack_size, random_starts_step_limit,\n    log_every_steps=None\n):\n  \"\"\"Collects frames from real env for random starts of simulated env.\"\"\"\n  del frame_stack_size\n  storage_env.start_new_epoch(0)\n  tf.logging.info(\n      \"Collecting %d frames for random starts.\", random_starts_step_limit\n  )\n  rl_utils.run_rollouts(\n      stacked_env, agent, stacked_env.reset(),\n      step_limit=random_starts_step_limit,\n      many_rollouts_from_each_env=True,\n      log_every_steps=log_every_steps,\n  )\n  # Save unfinished rollouts to history.\n  stacked_env.reset()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_agent_from_hparams(\n    agent_type, base_env, stacked_env, loop_hparams, policy_hparams,\n    planner_hparams, model_dir, policy_dir, sampling_temp, video_writers=()\n):\n  \"\"\"Creates an Agent from hparams.\"\"\"\n  def sim_env_kwargs_fn():\n    return rl.make_simulated_env_kwargs(\n        base_env, loop_hparams, batch_size=planner_hparams.batch_size,\n        model_dir=model_dir\n    )\n  planner_kwargs = planner_hparams.values()\n  planner_kwargs.pop(\"batch_size\")\n  planner_kwargs.pop(\"rollout_agent_type\")\n  planner_kwargs.pop(\"env_type\")\n  return make_agent(\n      agent_type, stacked_env, policy_hparams, policy_dir, sampling_temp,\n      sim_env_kwargs_fn, loop_hparams.frame_stack_size,\n      planner_hparams.rollout_agent_type,\n      inner_batch_size=planner_hparams.batch_size,\n      env_type=planner_hparams.env_type,\n      video_writers=video_writers, **planner_kwargs\n  )", "response": "Creates an Agent from hparams."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_eval_fn_with_agent(\n    agent_type, eval_mode, planner_hparams, model_dir, log_every_steps=None,\n    video_writers=(), random_starts_step_limit=None\n):\n  \"\"\"Returns an out-of-graph eval_fn using the Agent API.\"\"\"\n  def eval_fn(env, loop_hparams, policy_hparams, policy_dir, sampling_temp):\n    \"\"\"Eval function.\"\"\"\n    base_env = env\n    env = rl_utils.BatchStackWrapper(env, loop_hparams.frame_stack_size)\n    agent = make_agent_from_hparams(\n        agent_type, base_env, env, loop_hparams, policy_hparams,\n        planner_hparams, model_dir, policy_dir, sampling_temp, video_writers\n    )\n\n    if eval_mode == \"agent_simulated\":\n      real_env = base_env.new_like(batch_size=1)\n      stacked_env = rl_utils.BatchStackWrapper(\n          real_env, loop_hparams.frame_stack_size\n      )\n      collect_frames_for_random_starts(\n          real_env, stacked_env, agent, loop_hparams.frame_stack_size,\n          random_starts_step_limit, log_every_steps\n      )\n      initial_frame_chooser = rl_utils.make_initial_frame_chooser(\n          real_env, loop_hparams.frame_stack_size,\n          simulation_random_starts=True,\n          simulation_flip_first_random_for_beginning=False,\n          split=None,\n      )\n      env_fn = rl.make_simulated_env_fn_from_hparams(\n          real_env, loop_hparams, batch_size=loop_hparams.eval_batch_size,\n          initial_frame_chooser=initial_frame_chooser, model_dir=model_dir\n      )\n      sim_env = env_fn(in_graph=False)\n      env = rl_utils.BatchStackWrapper(sim_env, loop_hparams.frame_stack_size)\n\n    kwargs = {}\n    if not agent.records_own_videos:\n      kwargs[\"video_writers\"] = video_writers\n    step_limit = base_env.rl_env_max_episode_steps\n    if step_limit == -1:\n      step_limit = None\n    rl_utils.run_rollouts(\n        env, agent, env.reset(), log_every_steps=log_every_steps,\n        step_limit=step_limit, **kwargs\n    )\n    if eval_mode == \"agent_real\":\n      assert len(base_env.current_epoch_rollouts()) == env.batch_size\n  return eval_fn", "response": "Returns an eval_fn using the Agent API."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef evaluate_world_model(\n    agent_type, loop_hparams, planner_hparams, model_dir, policy_dir,\n    random_starts_step_limit, debug_video_path, log_every_steps\n):\n  \"\"\"Evaluates the world model.\"\"\"\n  if debug_video_path:\n    debug_video_path = os.path.join(debug_video_path, \"0.avi\")\n\n  storage_env = rl_utils.setup_env(loop_hparams, batch_size=1, max_num_noops=0)\n  stacked_env = rl_utils.BatchStackWrapper(\n      storage_env, loop_hparams.frame_stack_size\n  )\n  policy_hparams = trainer_lib.create_hparams(loop_hparams.base_algo_params)\n  agent = make_agent_from_hparams(\n      agent_type, storage_env, stacked_env, loop_hparams, policy_hparams,\n      planner_hparams, model_dir, policy_dir,\n      # TODO(koz4k): Loop over eval_sampling_temps?\n      sampling_temp=loop_hparams.eval_sampling_temps[0],\n  )\n  collect_frames_for_random_starts(\n      storage_env, stacked_env, agent, loop_hparams.frame_stack_size,\n      random_starts_step_limit, log_every_steps\n  )\n  return rl_utils.evaluate_world_model(\n      storage_env, loop_hparams, model_dir, debug_video_path, split=None\n  )", "response": "Evaluates the world model."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nevaluates the world model.", "response": "def evaluate(\n    loop_hparams, planner_hparams, policy_dir, model_dir, eval_metrics_dir,\n    agent_type, eval_mode, eval_with_learner, log_every_steps, debug_video_path,\n    num_debug_videos=1, random_starts_step_limit=None,\n    report_fn=None, report_metric=None\n):\n  \"\"\"Evaluate.\"\"\"\n  if eval_with_learner:\n    assert agent_type == \"policy\"\n\n  if report_fn:\n    assert report_metric is not None\n\n  eval_metrics_writer = tf.summary.FileWriter(eval_metrics_dir)\n  video_writers = ()\n  kwargs = {}\n  if eval_mode in [\"agent_real\", \"agent_simulated\"]:\n    if not eval_with_learner:\n      if debug_video_path:\n        tf.gfile.MakeDirs(debug_video_path)\n        video_writers = [\n            common_video.WholeVideoWriter(  # pylint: disable=g-complex-comprehension\n                fps=10,\n                output_path=os.path.join(debug_video_path, \"{}.avi\".format(i)),\n                file_format=\"avi\",\n            )\n            for i in range(num_debug_videos)\n        ]\n      kwargs[\"eval_fn\"] = make_eval_fn_with_agent(\n          agent_type, eval_mode, planner_hparams, model_dir,\n          log_every_steps=log_every_steps,\n          video_writers=video_writers,\n          random_starts_step_limit=random_starts_step_limit\n      )\n    eval_metrics = rl_utils.evaluate_all_configs(\n        loop_hparams, policy_dir, **kwargs\n    )\n  else:\n    eval_metrics = evaluate_world_model(\n        agent_type, loop_hparams, planner_hparams, model_dir, policy_dir,\n        random_starts_step_limit, debug_video_path, log_every_steps\n    )\n  rl_utils.summarize_metrics(eval_metrics_writer, eval_metrics, 0)\n\n  for video_writer in video_writers:\n    video_writer.finish_to_disk()\n\n  # Report metrics\n  if report_fn:\n    if report_metric == \"mean_reward\":\n      metric_name = rl_utils.get_metric_name(\n          sampling_temp=loop_hparams.eval_sampling_temps[0],\n          max_num_noops=loop_hparams.eval_max_num_noops,\n          clipped=False\n      )\n      report_fn(eval_metrics[metric_name], 0)\n    else:\n      report_fn(eval_metrics[report_metric], 0)\n  return eval_metrics"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the game for the given worker.", "response": "def get_game_for_worker(map_name, directory_id):\n  \"\"\"Get game for the given worker (directory) id.\"\"\"\n  if map_name == \"v100unfriendly\":\n    games = [\"chopper_command\", \"boxing\", \"asterix\", \"seaquest\"]\n    worker_per_game = 5\n  elif map_name == \"human_nice\":\n    games = gym_env.ATARI_GAMES_WITH_HUMAN_SCORE_NICE\n    worker_per_game = 5\n  else:\n    raise ValueError(\"Unknown worker to game map name: %s\" % map_name)\n  games.sort()\n  game_id = (directory_id - 1) // worker_per_game\n  tf.logging.info(\"Getting game %d from %s.\" % (game_id, games))\n  return games[game_id]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a representation of the board returns a list of open spaces.", "response": "def get_open_spaces(board):\n  \"\"\"Given a representation of the board, returns a list of open spaces.\"\"\"\n  open_spaces = []\n  for i in range(3):\n    for j in range(3):\n      if board[i][j] == 0:\n        open_spaces.append(encode_pos(i, j))\n  return open_spaces"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_reward_and_done(board):\n  # Returns (reward, done) where:\n  # reward: -1 means lost, +1 means win, 0 means draw or continuing.\n  # done: True if the game is over, i.e. someone won or it is a draw.\n\n  # Sum all rows ...\n  all_sums = [np.sum(board[i, :]) for i in range(3)]\n  # ... all columns\n  all_sums.extend([np.sum(board[:, i]) for i in range(3)])\n  # and both diagonals.\n  all_sums.append(np.sum([board[i, i] for i in range(3)]))\n  all_sums.append(np.sum([board[i, 2 - i] for i in range(3)]))\n\n  if -3 in all_sums:\n    return -1, True\n\n  if 3 in all_sums:\n    return 1, True\n\n  done = True\n  if get_open_spaces(board):\n    done = False\n\n  return 0, done", "response": "Given a representation of the board returns reward and done."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming decoding from dataset.", "response": "def decode_from_dataset(estimator,\n                        problem_name,\n                        hparams,\n                        decode_hp,\n                        decode_to_file=None,\n                        dataset_split=None,\n                        checkpoint_path=None):\n  \"\"\"Perform decoding from dataset.\"\"\"\n  tf.logging.info(\"Performing local inference from dataset for %s.\",\n                  str(problem_name))\n  # We assume that worker_id corresponds to shard number.\n  shard = decode_hp.shard_id if decode_hp.shards > 1 else None\n\n  # Setup output directory for any artifacts that may be written out.\n  output_dir = os.path.join(estimator.model_dir, \"decode\")\n  tf.gfile.MakeDirs(output_dir)\n\n  # If decode_hp.batch_size is specified, use a fixed batch size\n  if decode_hp.batch_size:\n    hparams.batch_size = decode_hp.batch_size\n    hparams.use_fixed_batch_size = True\n\n  dataset_kwargs = {\n      \"shard\": shard,\n      \"dataset_split\": dataset_split,\n      \"max_records\": decode_hp.num_samples\n  }\n\n  # Build the inference input function\n  problem = hparams.problem\n  infer_input_fn = problem.make_estimator_input_fn(\n      tf.estimator.ModeKeys.PREDICT, hparams, dataset_kwargs=dataset_kwargs)\n\n  predictions, output_dirs = [], []\n  for decode_id in range(decode_hp.num_decodes):\n    tf.logging.info(\"Decoding {}\".format(decode_id))\n\n    # Create decode directory if not in-memory decoding.\n    if not decode_hp.decode_in_memory:\n      output_dir = os.path.join(estimator.model_dir, \"decode_%05d\" % decode_id)\n      tf.gfile.MakeDirs(output_dir)\n      output_dirs.append(output_dir)\n\n    result = decode_once(estimator,\n                         problem_name,\n                         hparams,\n                         infer_input_fn,\n                         decode_hp,\n                         decode_to_file,\n                         output_dir,\n                         log_results=decode_hp.log_results,\n                         checkpoint_path=checkpoint_path)\n\n    if decode_hp.decode_in_memory:\n      output_dirs = [output_dir]\n      predictions.append(result)\n\n  if decode_hp.decode_to_file:\n    decode_hp.decode_to_file = _decode_filename(\n        decode_hp.decode_to_file, problem_name, decode_hp)\n\n  run_postdecode_hooks(DecodeHookArgs(\n      estimator=estimator,\n      problem=problem,\n      output_dirs=output_dirs,\n      hparams=hparams,\n      decode_hparams=decode_hp,\n      predictions=predictions\n  ), dataset_split)\n  return predictions"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndecodes one of the encoded images.", "response": "def decode_once(estimator,\n                problem_name,\n                hparams,\n                infer_input_fn,\n                decode_hp,\n                decode_to_file,\n                output_dir,\n                log_results=True,\n                checkpoint_path=None):\n  \"\"\"Decodes once.\n\n  Args:\n    estimator: tf.estimator.Estimator instance. Used to generate encoded\n      predictions.\n    problem_name: str. Name of problem.\n    hparams: HParams instance. HParams for model training.\n    infer_input_fn: zero-arg function. Input function for estimator.\n    decode_hp: HParams instance. See decode_hparams() above.\n    decode_to_file: str. Prefix for filenames. Used to generated filenames to\n      which decoded predictions are written.\n    output_dir: str. Output directory. Only used for writing images.\n    log_results: bool. If False, return encoded predictions without any\n      further processing.\n    checkpoint_path: str. Path to load model checkpoint from. If unspecified,\n      Estimator's default is used.\n\n  Returns:\n    If decode_hp.decode_in_memory is True:\n      List of dicts, one per example. Values are either numpy arrays or decoded\n      strings.\n    If decode_hp.decode_in_memory is False:\n      An empty list.\n  \"\"\"\n\n  # Get the predictions as an iterable\n  predictions = estimator.predict(infer_input_fn,\n                                  checkpoint_path=checkpoint_path)\n\n  if not log_results:\n    return list(predictions)\n\n  # Prepare output file writers if decode_to_file passed\n  decode_to_file = decode_to_file or decode_hp.decode_to_file\n  if decode_to_file:\n    output_filepath = _decode_filename(decode_to_file, problem_name, decode_hp)\n    parts = output_filepath.split(\".\")\n    parts[-1] = \"targets\"\n    target_filepath = \".\".join(parts)\n    parts[-1] = \"inputs\"\n    input_filepath = \".\".join(parts)\n\n    output_file = tf.gfile.Open(output_filepath, \"w\")\n    target_file = tf.gfile.Open(target_filepath, \"w\")\n    input_file = tf.gfile.Open(input_filepath, \"w\")\n\n  problem_hparams = hparams.problem_hparams\n  # Inputs vocabulary is set to targets if there are no inputs in the problem,\n  # e.g., for language models where the inputs are just a prefix of targets.\n  has_input = \"inputs\" in problem_hparams.vocabulary\n  inputs_vocab_key = \"inputs\" if has_input else \"targets\"\n  inputs_vocab = problem_hparams.vocabulary[inputs_vocab_key]\n  targets_vocab = problem_hparams.vocabulary[\"targets\"]\n\n  num_eval_samples = 0\n\n  # all_outputs[i][j] = (input: str, output: str, target: str). Input,\n  # decoded output, and target strings for example i, beam rank j.\n  all_outputs = []\n  for num_predictions, prediction in enumerate(predictions):\n    num_eval_samples += 1\n    num_predictions += 1\n    inputs = prediction.get(\"inputs\")\n    targets = prediction.get(\"targets\")\n    outputs = prediction.get(\"outputs\")\n\n    # Log predictions\n    decoded_outputs = []  # [(str, str, str)]. See all_outputs above.\n    if decode_hp.decode_in_memory:\n      all_outputs.append(decoded_outputs)\n    decoded_scores = []\n\n    if decode_hp.return_beams:\n      output_beams = np.split(outputs, decode_hp.beam_size, axis=0)\n      scores = None\n      if \"scores\" in prediction:\n        scores = np.split(prediction[\"scores\"], decode_hp.beam_size, axis=0)\n      for i, beam in enumerate(output_beams):\n        tf.logging.info(\"BEAM %d:\" % i)\n        score = scores and scores[i]\n        decoded = log_decode_results(\n            inputs,\n            beam,\n            problem_name,\n            num_predictions,\n            inputs_vocab,\n            targets_vocab,\n            save_images=decode_hp.save_images,\n            output_dir=output_dir,\n            identity_output=decode_hp.identity_output,\n            targets=targets,\n            log_results=log_results)\n        decoded_outputs.append(decoded)\n        if decode_hp.write_beam_scores:\n          decoded_scores.append(score)\n    else:\n      decoded = log_decode_results(\n          inputs,\n          outputs,\n          problem_name,\n          num_predictions,\n          inputs_vocab,\n          targets_vocab,\n          save_images=decode_hp.save_images,\n          output_dir=output_dir,\n          identity_output=decode_hp.identity_output,\n          targets=targets,\n          log_results=log_results,\n          skip_eos_postprocess=decode_hp.skip_eos_postprocess)\n      decoded_outputs.append(decoded)\n\n    # Write out predictions if decode_to_file passed\n    if decode_to_file:\n      for i, (d_input, d_output, d_target) in enumerate(decoded_outputs):\n        # Skip if all padding\n        if d_input and re.match(\"^({})+$\".format(text_encoder.PAD), d_input):\n          continue\n        beam_score_str = \"\"\n        if decode_hp.write_beam_scores:\n          beam_score_str = \"\\t%.2f\" % decoded_scores[i]\n        output_file.write(str(d_output) + beam_score_str + decode_hp.delimiter)\n        target_file.write(str(d_target) + decode_hp.delimiter)\n        input_file.write(str(d_input) + decode_hp.delimiter)\n\n    if (decode_hp.num_samples >= 0 and\n        num_predictions >= decode_hp.num_samples):\n      break\n\n  mlperf_log.transformer_print(key=mlperf_log.EVAL_SIZE,\n                               value=num_eval_samples,\n                               hparams=hparams)\n\n  if decode_to_file:\n    output_file.close()\n    target_file.close()\n    input_file.close()\n\n  return all_outputs"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndecodes the given file into a set of predictions.", "response": "def decode_from_file(estimator,\n                     filename,\n                     hparams,\n                     decode_hp,\n                     decode_to_file=None,\n                     checkpoint_path=None):\n  \"\"\"Compute predictions on entries in filename and write them out.\"\"\"\n  if not decode_hp.batch_size:\n    decode_hp.batch_size = 32\n    tf.logging.info(\n        \"decode_hp.batch_size not specified; default=%d\" % decode_hp.batch_size)\n\n  # Inputs vocabulary is set to targets if there are no inputs in the problem,\n  # e.g., for language models where the inputs are just a prefix of targets.\n  p_hp = hparams.problem_hparams\n  has_input = \"inputs\" in p_hp.vocabulary\n  inputs_vocab_key = \"inputs\" if has_input else \"targets\"\n  inputs_vocab = p_hp.vocabulary[inputs_vocab_key]\n  targets_vocab = p_hp.vocabulary[\"targets\"]\n  problem_name = FLAGS.problem\n  filename = _add_shard_to_filename(filename, decode_hp)\n  tf.logging.info(\"Performing decoding from file (%s).\" % filename)\n  if has_input:\n    sorted_inputs, sorted_keys = _get_sorted_inputs(\n        filename, decode_hp.delimiter)\n  else:\n    sorted_inputs = _get_language_modeling_inputs(\n        filename, decode_hp.delimiter, repeat=decode_hp.num_decodes)\n    sorted_keys = range(len(sorted_inputs))\n  num_sentences = len(sorted_inputs)\n  num_decode_batches = (num_sentences - 1) // decode_hp.batch_size + 1\n\n  if estimator.config.use_tpu:\n    length = getattr(hparams, \"length\", 0) or hparams.max_length\n    batch_ids = []\n    for line in sorted_inputs:\n      if has_input:\n        ids = inputs_vocab.encode(line.strip()) + [1]\n      else:\n        ids = targets_vocab.encode(line)\n      if len(ids) < length:\n        ids.extend([0] * (length - len(ids)))\n      else:\n        ids = ids[:length]\n      batch_ids.append(ids)\n    np_ids = np.array(batch_ids, dtype=np.int32)\n    def input_fn(params):\n      batch_size = params[\"batch_size\"]\n      dataset = tf.data.Dataset.from_tensor_slices({\"inputs\": np_ids})\n      dataset = dataset.map(\n          lambda ex: {\"inputs\": tf.reshape(ex[\"inputs\"], (length, 1, 1))})\n      dataset = dataset.batch(batch_size)\n      return dataset\n  else:\n    def input_fn():\n      input_gen = _decode_batch_input_fn(\n          num_decode_batches, sorted_inputs,\n          inputs_vocab, decode_hp.batch_size,\n          decode_hp.max_input_size,\n          task_id=decode_hp.multiproblem_task_id, has_input=has_input)\n      gen_fn = make_input_fn_from_generator(input_gen)\n      example = gen_fn()\n      return _decode_input_tensor_to_features_dict(example, hparams)\n  decodes = []\n  result_iter = estimator.predict(input_fn, checkpoint_path=checkpoint_path)\n\n  start_time = time.time()\n  total_time_per_step = 0\n  total_cnt = 0\n\n  def timer(gen):\n    while True:\n      try:\n        start_time = time.time()\n        item = next(gen)\n        elapsed_time = time.time() - start_time\n        yield elapsed_time, item\n      except StopIteration:\n        break\n\n  for elapsed_time, result in timer(result_iter):\n    if decode_hp.return_beams:\n      beam_decodes = []\n      beam_scores = []\n      output_beams = np.split(result[\"outputs\"], decode_hp.beam_size, axis=0)\n      scores = None\n      if \"scores\" in result:\n        if np.isscalar(result[\"scores\"]):\n          result[\"scores\"] = result[\"scores\"].reshape(1)\n        scores = np.split(result[\"scores\"], decode_hp.beam_size, axis=0)\n      for k, beam in enumerate(output_beams):\n        tf.logging.info(\"BEAM %d:\" % k)\n        score = scores and scores[k]\n        _, decoded_outputs, _ = log_decode_results(\n            result[\"inputs\"],\n            beam,\n            problem_name,\n            None,\n            inputs_vocab,\n            targets_vocab,\n            log_results=decode_hp.log_results,\n            skip_eos_postprocess=decode_hp.skip_eos_postprocess)\n        beam_decodes.append(decoded_outputs)\n        if decode_hp.write_beam_scores:\n          beam_scores.append(score)\n      if decode_hp.write_beam_scores:\n        decodes.append(\"\\t\".join([\n            \"\\t\".join([d, \"%.2f\" % s])\n            for d, s in zip(beam_decodes, beam_scores)\n        ]))\n      else:\n        decodes.append(\"\\t\".join(beam_decodes))\n    else:\n      _, decoded_outputs, _ = log_decode_results(\n          result[\"inputs\"],\n          result[\"outputs\"],\n          problem_name,\n          None,\n          inputs_vocab,\n          targets_vocab,\n          log_results=decode_hp.log_results,\n          skip_eos_postprocess=decode_hp.skip_eos_postprocess)\n      decodes.append(decoded_outputs)\n    total_time_per_step += elapsed_time\n    total_cnt += result[\"outputs\"].shape[-1]\n  duration = time.time() - start_time\n  tf.logging.info(\"Elapsed Time: %5.5f\" % duration)\n  tf.logging.info(\"Averaged Single Token Generation Time: %5.7f \"\n                  \"(time %5.7f count %d)\" %\n                  (total_time_per_step / total_cnt,\n                   total_time_per_step, total_cnt))\n  if decode_hp.batch_size == 1:\n    tf.logging.info(\"Inference time %.4f seconds \"\n                    \"(Latency = %.4f ms/setences)\" %\n                    (duration, 1000.0*duration/num_sentences))\n  else:\n    tf.logging.info(\"Inference time %.4f seconds \"\n                    \"(Throughput = %.4f sentences/second)\" %\n                    (duration, num_sentences/duration))\n\n  # If decode_to_file was provided use it as the output filename without change\n  # (except for adding shard_id if using more shards for decoding).\n  # Otherwise, use the input filename plus model, hp, problem, beam, alpha.\n  decode_filename = decode_to_file if decode_to_file else filename\n  if not decode_to_file:\n    decode_filename = _decode_filename(decode_filename, problem_name, decode_hp)\n  else:\n    decode_filename = _add_shard_to_filename(decode_filename, decode_hp)\n  tf.logging.info(\"Writing decodes into %s\" % decode_filename)\n  outfile = tf.gfile.Open(decode_filename, \"w\")\n  for index in range(len(sorted_inputs)):\n    outfile.write(\"%s%s\" % (decodes[sorted_keys[index]], decode_hp.delimiter))\n  outfile.flush()\n  outfile.close()\n\n  output_dir = os.path.join(estimator.model_dir, \"decode\")\n  tf.gfile.MakeDirs(output_dir)\n\n  run_postdecode_hooks(DecodeHookArgs(\n      estimator=estimator,\n      problem=hparams.problem,\n      output_dirs=[output_dir],\n      hparams=hparams,\n      decode_hparams=decode_hp,\n      predictions=list(result_iter)\n  ), None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates decode filename. Args: base_filename: A string, base of the decode filename. problem_name: A string, name of the problem. decode_hp: HParams for decoding. Returns: A string, produced decode filename.", "response": "def _decode_filename(base_filename, problem_name, decode_hp):\n  \"\"\"Generates decode filename.\n\n  Args:\n    base_filename: A string, base of the decode filename.\n    problem_name: A string, name of the problem.\n    decode_hp: HParams for decoding.\n\n  Returns:\n    A string, produced decode filename.\n  \"\"\"\n  if decode_hp.shards > 1:\n    base_filename = _add_shard_to_filename(base_filename, decode_hp)\n  if (\"beam{beam}.alpha{alpha}.decodes\".format(\n      beam=str(decode_hp.beam_size), alpha=str(decode_hp.alpha))\n      in base_filename):\n    return base_filename\n  else:\n    return (\n        \"{base}.{model}.{hp}.{problem}.beam{beam}.alpha{alpha}.decodes\".format(\n            base=base_filename,\n            model=FLAGS.model,\n            hp=FLAGS.hparams_set,\n            problem=problem_name,\n            beam=str(decode_hp.beam_size),\n            alpha=str(decode_hp.alpha)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuses py_func to yield elements from the given generator.", "response": "def make_input_fn_from_generator(gen):\n  \"\"\"Use py_func to yield elements from the given generator.\"\"\"\n  first_ex = six.next(gen)\n  flattened = tf.contrib.framework.nest.flatten(first_ex)\n  types = [t.dtype for t in flattened]\n  shapes = [[None] * len(t.shape) for t in flattened]\n  first_ex_list = [first_ex]\n\n  def py_func():\n    if first_ex_list:\n      example = first_ex_list.pop()\n    else:\n      example = six.next(gen)\n    return tf.contrib.framework.nest.flatten(example)\n\n  def input_fn():\n    flat_example = tf.py_func(py_func, [], types)\n    _ = [t.set_shape(shape) for t, shape in zip(flat_example, shapes)]\n    example = tf.contrib.framework.nest.pack_sequence_as(first_ex, flat_example)\n    return example\n\n  return input_fn"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _interactive_input_fn(hparams, decode_hp):\n  num_samples = decode_hp.num_samples if decode_hp.num_samples > 0 else 1\n  decode_length = decode_hp.extra_length\n  input_type = \"text\"\n  p_hparams = hparams.problem_hparams\n  has_input = \"inputs\" in p_hparams.modality\n  vocabulary = p_hparams.vocabulary[\"inputs\" if has_input else \"targets\"]\n  # This should be longer than the longest input.\n  const_array_size = 10000\n  # Import readline if available for command line editing and recall.\n  try:\n    import readline  # pylint: disable=g-import-not-at-top,unused-variable\n  except ImportError:\n    pass\n  while True:\n    prompt = (\"INTERACTIVE MODE  num_samples=%d  decode_length=%d  \\n\"\n              \"  it=<input_type>     ('text' or 'image' or 'label', default: \"\n              \"text)\\n\"\n              \"  ns=<num_samples>    (changes number of samples, default: 1)\\n\"\n              \"  dl=<decode_length>  (changes decode length, default: 100)\\n\"\n              \"  <%s>                (decode)\\n\"\n              \"  q                   (quit)\\n\"\n              \">\" % (num_samples, decode_length,\n                     \"source_string\" if has_input else \"target_prefix\"))\n    input_string = input(prompt)\n    if input_string == \"q\":\n      return\n    elif input_string[:3] == \"ns=\":\n      num_samples = int(input_string[3:])\n    elif input_string[:3] == \"dl=\":\n      decode_length = int(input_string[3:])\n    elif input_string[:3] == \"it=\":\n      input_type = input_string[3:]\n    else:\n      if input_type == \"text\":\n        input_ids = vocabulary.encode(input_string)\n        if has_input:\n          input_ids.append(text_encoder.EOS_ID)\n        x = [num_samples, decode_length, len(input_ids)] + input_ids\n        assert len(x) < const_array_size\n        x += [0] * (const_array_size - len(x))\n        features = {\n            \"inputs\": np.array(x).astype(np.int32),\n        }\n      elif input_type == \"image\":\n        input_path = input_string\n        img = vocabulary.encode(input_path)\n        features = {\n            \"inputs\": img.astype(np.int32),\n        }\n      elif input_type == \"label\":\n        input_ids = [int(input_string)]\n        x = [num_samples, decode_length, len(input_ids)] + input_ids\n        features = {\n            \"inputs\": np.array(x).astype(np.int32),\n        }\n      else:\n        raise Exception(\"Unsupported input type.\")\n      for k, v in six.iteritems(\n          problem_lib.problem_hparams_to_features(p_hparams)):\n        features[k] = np.array(v).astype(np.int32)\n      yield features", "response": "Generator that reads from the terminal and yields interactive inputs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_video(video, save_path_template):\n  try:\n    from PIL import Image  # pylint: disable=g-import-not-at-top\n  except ImportError as e:\n    tf.logging.warning(\n        \"Showing and saving an image requires PIL library to be \"\n        \"installed: %s\", e)\n    raise NotImplementedError(\"Image display and save not implemented.\")\n\n  for i, frame in enumerate(video):\n    save_path = save_path_template.format(i)\n    with tf.gfile.Open(save_path, \"wb\") as sp:\n      Image.fromarray(np.uint8(frame)).save(sp)", "response": "Save frames of the videos into files."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef show_and_save_image(img, save_path):\n  try:\n    import matplotlib.pyplot as plt  # pylint: disable=g-import-not-at-top\n  except ImportError as e:\n    tf.logging.warning(\n        \"Showing and saving an image requires matplotlib to be \"\n        \"installed: %s\", e)\n    raise NotImplementedError(\"Image display and save not implemented.\")\n  plt.imshow(img)\n  with tf.gfile.Open(save_path, \"wb\") as sp:\n    plt.savefig(sp)", "response": "Shows an image using matplotlib and saves it."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading a file of partial texts to continue.", "response": "def _get_language_modeling_inputs(filename,\n                                  delimiter=\"\\n\",\n                                  repeat=1,\n                                  append_space_to_final_punctionation=True):\n  \"\"\"Read a file of partial texts to continue.\n\n  The purpose of append_space_to_final_punctionation is that SubwordTokenizer\n  groups punctuation and the ensuing space in the same token.  Adding a space\n  causes the token to be completed.\n\n  Args:\n    filename: a string\n    delimiter: a string\n    repeat: an integer - we repeat the entire file that many times.\n    append_space_to_final_punctionation: a boolean\n\n  Returns:\n    a list of strings\n  \"\"\"\n  with tf.gfile.Open(filename) as f:\n    text = f.read()\n  inputs = text.split(delimiter)\n  if not inputs[-1]:\n    inputs.pop()\n  inputs *= repeat\n  if append_space_to_final_punctionation:\n    inputs = [\n        s + \" \" if s and s[-1] in string.punctuation else s for s in inputs]\n  return inputs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of sorted inputs according to decreasing length.", "response": "def _get_sorted_inputs(filename, delimiter=\"\\n\"):\n  \"\"\"Returning inputs sorted according to decreasing length.\n\n  This causes inputs of similar lengths to be processed in the same batch,\n  facilitating early stopping for short sequences.\n\n  Longer sequences are sorted first so that if you're going to get OOMs,\n  you'll see it in the first batch.\n\n  Args:\n    filename: path to file with inputs, 1 per line.\n    delimiter: str, delimits records in the file.\n\n  Returns:\n    a sorted list of inputs\n\n  \"\"\"\n  tf.logging.info(\"Getting sorted inputs\")\n  with tf.gfile.Open(filename) as f:\n    text = f.read()\n    records = text.split(delimiter)\n    inputs = [record.strip() for record in records]\n    # Strip the last empty line.\n    if not inputs[-1]:\n      inputs.pop()\n  input_lens = [(i, -len(line.split())) for i, line in enumerate(inputs)]\n  sorted_input_lens = sorted(input_lens, key=operator.itemgetter(1))\n  # We'll need the keys to rearrange the inputs back into their original order\n  sorted_keys = {}\n  sorted_inputs = []\n  for i, (index, _) in enumerate(sorted_input_lens):\n    sorted_inputs.append(inputs[index])\n    sorted_keys[index] = i\n  return sorted_inputs, sorted_keys"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _save_until_eos(ids, skip=False):\n  ids = ids.flatten()\n  if skip:\n    return ids\n  try:\n    index = list(ids).index(text_encoder.EOS_ID)\n    return ids[0:index]\n  except ValueError:\n    # No EOS_ID: return the array as-is.\n    return ids", "response": "Strips everything after the first <EOS > token which is normally 1."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _interactive_input_tensor_to_features_dict(feature_map, hparams):\n  inputs = tf.convert_to_tensor(feature_map[\"inputs\"])\n  input_is_image = False if len(inputs.get_shape()) < 3 else True\n\n  x = inputs\n  if input_is_image:\n    x = tf.image.resize_images(x, [299, 299])\n    x = tf.reshape(x, [1, 299, 299, -1])\n    x = tf.to_int32(x)\n  else:\n    # Remove the batch dimension.\n    num_samples = x[0]\n    length = x[2]\n    x = tf.slice(x, [3], tf.to_int32([length]))\n    x = tf.reshape(x, [1, -1, 1, 1])\n    # Transform into a batch of size num_samples to get that many random\n    # decodes.\n    x = tf.tile(x, tf.to_int32([num_samples, 1, 1, 1]))\n\n  p_hparams = hparams.problem_hparams\n  input_space_id = tf.constant(p_hparams.input_space_id)\n  target_space_id = tf.constant(p_hparams.target_space_id)\n\n  features = {}\n  features[\"input_space_id\"] = input_space_id\n  features[\"target_space_id\"] = target_space_id\n  features[\"decode_length\"] = (\n      IMAGE_DECODE_LENGTH if input_is_image else inputs[1])\n  features[\"inputs\"] = x\n  return features", "response": "Convert the interactive input format to a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert the interactive input format to a dictionary.", "response": "def _decode_input_tensor_to_features_dict(feature_map, hparams):\n  \"\"\"Convert the interactive input format (see above) to a dictionary.\n\n  Args:\n    feature_map: dict with inputs.\n    hparams: model hyperparameters\n\n  Returns:\n    a features dictionary, as expected by the decoder.\n  \"\"\"\n  inputs = tf.convert_to_tensor(feature_map[\"inputs\"])\n  input_is_image = False\n\n  x = inputs\n  p_hparams = hparams.problem_hparams\n  # Add a third empty dimension\n  x = tf.expand_dims(x, axis=[2])\n  x = tf.to_int32(x)\n  input_space_id = tf.constant(p_hparams.input_space_id)\n  target_space_id = tf.constant(p_hparams.target_space_id)\n\n  features = {}\n  features[\"input_space_id\"] = input_space_id\n  features[\"target_space_id\"] = target_space_id\n  features[\"decode_length\"] = (\n      IMAGE_DECODE_LENGTH if input_is_image else tf.shape(x)[1] + 50)\n  features[\"inputs\"] = x\n  return features"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning hooks after decodes have run.", "response": "def run_postdecode_hooks(decode_hook_args, dataset_split):\n  \"\"\"Run hooks after decodes have run.\"\"\"\n  hooks = decode_hook_args.problem.decode_hooks\n  if not hooks:\n    return\n  global_step = latest_checkpoint_step(decode_hook_args.estimator.model_dir)\n  if global_step is None:\n    tf.logging.info(\n        \"Skipping decode hooks because no checkpoint yet available.\")\n    return\n  tf.logging.info(\"Running decode hooks.\")\n  parent_dir = os.path.join(decode_hook_args.output_dirs[0], os.pardir)\n  child_dir = decode_hook_args.decode_hparams.summaries_log_dir\n  if dataset_split is not None:\n    child_dir += \"_{}\".format(dataset_split)\n  final_dir = os.path.join(parent_dir, child_dir)\n  summary_writer = tf.summary.FileWriter(final_dir)\n\n  for hook in hooks:\n    # Isolate each hook in case it creates TF ops\n    with tf.Graph().as_default():\n      summaries = hook(decode_hook_args)\n    if summaries:\n      summary = tf.Summary(value=list(summaries))\n      summary_writer.add_summary(summary, global_step)\n  summary_writer.close()\n  tf.logging.info(\"Decode hooks done.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsplit of data to produce and number of output shards for each.", "response": "def dataset_splits(self):\n    \"\"\"Splits of data to produce and number of output shards for each.\"\"\"\n    return [{\n        \"split\": problem.DatasetSplit.TRAIN,\n        \"shards\": _TRAIN_SHARDS,\n    }, {\n        \"split\": problem.DatasetSplit.EVAL,\n        \"shards\": _DEV_SHARDS,\n    }]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef local_attention1d_spatial_decoder(x, kv_dim, heads_dim,\n                                      feedforward_dim, hparams):\n  \"\"\"Image Transformer decoder with local1D spatial layers.\"\"\"\n  batch_dim, length_dim, model_dim = x.shape.dims\n  blocks_w_dim = mtf.Dimension(\"blocksw\", hparams.block_length)\n  num_w_blocks_dim = mtf.Dimension(\"num_wblocks\",\n                                   length_dim.size // blocks_w_dim.size)\n  x = mtf.reshape(\n      x, mtf.Shape([batch_dim, num_w_blocks_dim, blocks_w_dim, model_dim]))\n  # [ self attention - ffn - residual + dropout] x n\n  for layer in range(hparams.num_decoder_layers):\n    layer_name = \"decoder_layer_%d\" % layer\n    with tf.variable_scope(layer_name):\n      # Self attention layer\n      x += layer_prepostprocess_dropout(\n          mtf.layers.local_self_attention_spatial_blocks(\n              mtf.layers.layer_norm(x, model_dim, name=\"layer_norm_att\"),\n              kv_dim,\n              heads_dim,\n              memory_w_dim=blocks_w_dim,\n              mask_right=True,\n              name=\"self_att\"), hparams)\n      # ffn layer\n      x += layer_prepostprocess_dropout(\n          mtf.layers.dense_relu_dense(\n              mtf.layers.layer_norm(x, model_dim, name=\"layer_norm_ffn\"),\n              feedforward_dim,\n              hparams.dropout,\n              dropout_broadcast_dims=[length_dim]), hparams)\n\n  output = mtf.layers.layer_norm(x, model_dim, name=\"final_layer_norm\")\n  return output", "response": "Image Transformer decoder with local1D spatial layers."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef local_attention2d_spatial_decoder(x, kv_dim, heads_dim,\n                                      feedforward_dim, hparams):\n  \"\"\"Image Transformer decoder with local2D spatial layers.\"\"\"\n  batch_dim, length_dim, model_dim = x.shape.dims\n  blocks_h_dim = mtf.Dimension(\"blocksh\", hparams.block_height)\n  blocks_w_dim = mtf.Dimension(\"blocksw\", hparams.block_width)\n  num_h_blocks_dim = mtf.Dimension(\"num_h_blocks\",\n                                   hparams.img_len // hparams.block_height)\n  num_w_blocks_dim = mtf.Dimension(\n      \"num_w_blocks\",\n      hparams.img_len * hparams.num_channels // hparams.block_width)\n  x = mtf.transpose(\n      mtf.reshape(\n          x,\n          mtf.Shape([\n              batch_dim, num_h_blocks_dim, blocks_h_dim,\n              num_w_blocks_dim, blocks_w_dim, model_dim\n          ])),\n      mtf.Shape([\n          batch_dim, num_h_blocks_dim, num_w_blocks_dim,\n          blocks_h_dim, blocks_w_dim, model_dim\n      ]))\n  # Image Transformer Decoder\n  # [ self attention - ffn - residual + dropout] x n\n  for layer in range(hparams.num_decoder_layers):\n    layer_name = \"decoder_layer_%d\" % layer\n    with tf.variable_scope(layer_name):\n      # Self attention layer\n      x += layer_prepostprocess_dropout(\n          mtf.layers.local_2d_self_attention_spatial_blocks(\n              mtf.layers.layer_norm(x, model_dim, name=\"layer_norm_att\"),\n              kv_dim,\n              heads_dim,\n              memory_h_dim=num_h_blocks_dim,\n              memory_w_dim=num_w_blocks_dim,\n              name=\"self_att\"), hparams)\n      # ffn layer\n      x += layer_prepostprocess_dropout(\n          mtf.layers.dense_relu_dense(\n              mtf.layers.layer_norm(x, model_dim, name=\"layer_norm_ffn\"),\n              feedforward_dim,\n              hparams.dropout,\n              dropout_broadcast_dims=[length_dim]), hparams)\n\n  output = mtf.layers.layer_norm(x, model_dim, name=\"final_layer_norm\")\n  return output", "response": "Image Transformer decoder with local2D spatial layers."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef local_attention1d_masked_decoder(x, kv_dim, heads_dim,\n                                     feedforward_dim, hparams):\n  \"\"\"Image Transformer decoder with local1D masked layers.\"\"\"\n  print(x)\n  _, length_dim, model_dim = x.shape.dims\n  for layer in range(hparams.num_decoder_layers):\n    layer_name = \"decoder_layer_%d\" % layer\n    with tf.variable_scope(layer_name):\n      # Self attention layer\n      length_per_split = mtf.tensor_dim_to_size_per_split(\n          hparams.layout, hparams.mesh_shape, length_dim)\n      x += layer_prepostprocess_dropout(\n          mtf.layers.masked_local_attention_1d(\n              mtf.layers.layer_norm(x, model_dim, name=\"layer_norm_att\"),\n              kv_dim,\n              heads_dim,\n              window_size=hparams.block_length,\n              length_per_split=length_per_split,\n              name=\"self_att\"), hparams)\n      # ffn layer\n      x += layer_prepostprocess_dropout(\n          mtf.layers.dense_relu_dense(\n              mtf.layers.layer_norm(x, model_dim, name=\"layer_norm_ffn\"),\n              feedforward_dim,\n              hparams.dropout,\n              dropout_broadcast_dims=[length_dim]), hparams)\n\n  output = mtf.layers.layer_norm(x, model_dim, name=\"final_layer_norm\")\n  return output", "response": "Image Transformer decoder with local1D masked layers."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mtf_image_transformer_base_cifar():\n  hparams = mtf_image_transformer_base()\n  hparams.mesh_shape = \"batch:8\"\n  hparams.layout = \"batch:batch\"\n  hparams.learning_rate_decay_steps = 13600  # one epoch\n  hparams.batch_size = 32\n  hparams.num_heads = 4\n  hparams.num_decoder_layers = 12\n  hparams.block_length = 256\n  hparams.hidden_size = 512\n  hparams.d_ff = 2048\n  hparams.learning_rate = 0.5\n  hparams.layer_preprocess_sequence = \"none\"\n  hparams.layer_postprocess_sequence = \"dan\"\n  hparams.layer_prepostprocess_dropout = 0.3\n  hparams.unconditional = True\n  return hparams", "response": "Data parallel CIFAR parameters."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mtf_image_transformer_cifar_4x():\n  hparams = mtf_image_transformer_base_cifar()\n  hparams.mesh_shape = \"batch:32\"\n  hparams.layout = \"batch:batch\"\n  hparams.batch_size = 128\n  return hparams", "response": "Data parallel CIFAR parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mtf_image_transformer_base_imagenet_mp():\n  hparams = mtf_image_transformer_base_imagenet()\n  hparams.mesh_shape = \"model:4;batch:8\"\n  hparams.layout = \"batch:batch;d_ff:model;heads:model\"\n  hparams.batch_size = 32\n  hparams.num_heads = 8\n  hparams.d_ff = 8192\n  hparams.learning_rate_warmup_steps = 31250\n  hparams.unconditional = True\n  return hparams", "response": "Model parallel ImageNet parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmodels parallel ImageNet parameters.", "response": "def mtf_image_transformer_base_imagenet_mp128():\n  \"\"\"Model parallel ImageNet parameters.\"\"\"\n  hparams = mtf_image_transformer_base_imagenet()\n  hparams.mesh_shape = \"model:8;batch:4\"\n  hparams.layout = \"batch:batch;d_ff:model;heads:model\"\n  hparams.batch_size = 8\n  hparams.img_len = 128\n  hparams.block_length = 128\n  hparams.num_heads = 8\n  hparams.num_decoder_layers = 4\n  hparams.d_ff = 4096\n  hparams.learning_rate_warmup_steps = 31250\n  hparams.unconditional = True\n  hparams.max_length = 256*256*3\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmodels parallel ImageNet parameters.", "response": "def mtf_image_transformer_base_imagenet_mp_sp():\n  \"\"\"Model parallel ImageNet parameters.\"\"\"\n  hparams = mtf_image_transformer_base_imagenet_mp128()\n  hparams.mesh_shape = \"model:8;batch:4\"\n  hparams.layout = \"batch:batch;d_ff:model;num_wblocks:model\"\n  hparams.batch_size = 8\n  hparams.img_len = 128\n  hparams.block_length = 128\n  hparams.attention_type = \"local1d_spatial\"\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mtf_image_transformer_base_imagenet_mp64():\n  hparams = mtf_image_transformer_base_imagenet()\n  hparams.mesh_shape = \"model:8;batch:4\"\n  hparams.layout = \"batch:batch;d_ff:model;heads:model\"\n  hparams.batch_size = 8\n  hparams.img_len = 64\n  hparams.num_decoder_layers = 8\n  return hparams", "response": "Model parallel ImageNet parameters."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a list of degree vectors for each input and hidden unit.", "response": "def create_degrees(input_dim,\n                   hidden_dims,\n                   input_order='left-to-right',\n                   hidden_order='left-to-right'):\n  \"\"\"Returns a list of degree vectors, one for each input and hidden layer.\n\n  A unit with degree d can only receive input from units with degree < d. Output\n  units always have the same degree as their associated input unit.\n\n  Args:\n    input_dim: Number of inputs.\n    hidden_dims: list with the number of hidden units per layer. It does not\n      include the output layer. Each hidden unit size must be at least the size\n      of length (otherwise autoregressivity is not possible).\n    input_order: Order of degrees to the input units: 'random', 'left-to-right',\n      'right-to-left', or an array of an explicit order. For example,\n      'left-to-right' builds an autoregressive model\n      p(x) = p(x1) p(x2 | x1) ... p(xD | x<D).\n    hidden_order: Order of degrees to the hidden units: 'random',\n      'left-to-right'. If 'left-to-right', hidden units are allocated equally\n      (up to a remainder term) to each degree.\n  \"\"\"\n  if (isinstance(input_order, str) and\n      input_order not in ('random', 'left-to-right', 'right-to-left')):\n    raise ValueError('Input order is not valid.')\n  if hidden_order not in ('random', 'left-to-right'):\n    raise ValueError('Hidden order is not valid.')\n\n  degrees = []\n  if isinstance(input_order, str):\n    input_degrees = np.arange(1, input_dim + 1)\n    if input_order == 'right-to-left':\n      input_degrees = np.flip(input_degrees, 0)\n    elif input_order == 'random':\n      np.random.shuffle(input_degrees)\n  else:\n    input_order = np.array(input_order)\n    if np.all(np.sort(input_order) != np.arange(1, input_dim + 1)):\n      raise ValueError('invalid input order')\n    input_degrees = input_order\n  degrees.append(input_degrees)\n\n  for units in hidden_dims:\n    if hidden_order == 'random':\n      min_prev_degree = min(np.min(degrees[-1]), input_dim - 1)\n      hidden_degrees = np.random.randint(\n          low=min_prev_degree, high=input_dim, size=units)\n    elif hidden_order == 'left-to-right':\n      hidden_degrees = (np.arange(units) % max(1, input_dim - 1) +\n                        min(1, input_dim - 1))\n    degrees.append(hidden_degrees)\n  return degrees"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a list of binary masks.", "response": "def create_masks(input_dim,\n                 hidden_dims,\n                 input_order='left-to-right',\n                 hidden_order='left-to-right'):\n  \"\"\"Returns a list of binary mask matrices respecting autoregressive ordering.\n\n  Args:\n    input_dim: Number of inputs.\n    hidden_dims: list with the number of hidden units per layer. It does not\n      include the output layer; those number of units will always be set to\n      input_dim downstream. Each hidden unit size must be at least the size of\n      length (otherwise autoregressivity is not possible).\n    input_order: Order of degrees to the input units: 'random', 'left-to-right',\n      'right-to-left', or an array of an explicit order. For example,\n      'left-to-right' builds an autoregressive model\n      p(x) = p(x1) p(x2 | x1) ... p(xD | x<D).\n    hidden_order: Order of degrees to the hidden units: 'random',\n      'left-to-right'. If 'left-to-right', hidden units are allocated equally\n      (up to a remainder term) to each degree.\n  \"\"\"\n  degrees = create_degrees(input_dim, hidden_dims, input_order, hidden_order)\n  masks = []\n  # Create input-to-hidden and hidden-to-hidden masks.\n  for input_degrees, output_degrees in zip(degrees[:-1], degrees[1:]):\n    mask = tf.cast(input_degrees[:, np.newaxis] <= output_degrees, tf.float32)\n    masks.append(mask)\n\n  # Create hidden-to-output mask.\n  mask = tf.cast(degrees[-1][:, np.newaxis] < degrees[0], tf.float32)\n  masks.append(mask)\n  return masks"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform incomplete Sinkhorn normalization to inputs.", "response": "def sinkhorn(inputs, n_iters=20):\n  \"\"\"Performs incomplete Sinkhorn normalization to inputs.\n\n  By a theorem by Sinkhorn and Knopp [1], a sufficiently well-behaved  matrix\n  with positive entries can be turned into a doubly-stochastic matrix\n  (i.e. its rows and columns add up to one) via the succesive row and column\n  normalization.\n  -To ensure positivity, the effective input to sinkhorn has to be\n  exp(inputs) (elementwise).\n  -However, for stability, sinkhorn works in the log-space. It is only at\n   return time that entries are exponentiated.\n\n  Code is adapted from Mena et al. [2].\n\n  [1] Richard Sinkhorn and Paul Knopp. Concerning nonnegative matrices and\n  doubly stochastic matrices. Pacific Journal of Mathematics, 1967.\n\n  [2] Gonzalo Mena, David Belanger, Scott Linderman, Jasper Snoek.\n  Learning latent permutations with Gumbel-Sinkhorn networks. International\n  Conference on Learning Representations, 2018.\n\n  Args:\n    inputs: A `Tensor` with shape `[..., vocab_size, vocab_size]`.\n    n_iters: Number of sinkhorn iterations (in practice, as little as 20\n      iterations are needed to achieve decent convergence for `vocab_size` ~100)\n\n  Returns:\n    outputs: A `Tensor` of close-to-doubly-stochastic matrices with shape\n      `[:, vocab_size, vocab_size]`.\n  \"\"\"\n  vocab_size = tf.shape(inputs)[-1]\n  log_alpha = tf.reshape(inputs, [-1, vocab_size, vocab_size])\n\n  for _ in range(n_iters):\n    log_alpha -= tf.reshape(tf.reduce_logsumexp(log_alpha, axis=2),\n                            [-1, vocab_size, 1])\n    log_alpha -= tf.reshape(tf.reduce_logsumexp(log_alpha, axis=1),\n                            [-1, 1, vocab_size])\n  outputs = tf.exp(log_alpha)\n  return outputs"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new random variable with transformed distribution.", "response": "def TransformedRandomVariable(random_variable,  # pylint: disable=invalid-name\n                              reversible_layer,\n                              name=None,\n                              sample_shape=(),\n                              value=None):\n  \"\"\"Random variable for f(x), where x ~ p(x) and f is reversible.\"\"\"\n  return ed.RandomVariable(\n      distribution=TransformedDistribution(random_variable.distribution,\n                                           reversible_layer,\n                                           name=name),\n      sample_shape=sample_shape,\n      value=value)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn log det jacobian.", "response": "def log_det_jacobian(self, inputs):\n    \"\"\"Returns log det | dx / dy | = num_events * sum log | scale |.\"\"\"\n    del inputs  # unused\n    # Number of events is number of all elements excluding the batch and\n    # channel dimensions.\n    num_events = tf.reduce_prod(tf.shape(inputs)[1:-1])\n    log_det_jacobian = num_events * tf.reduce_sum(self.log_scale)\n    return log_det_jacobian"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nslicing encoder hidden state into block_dim.", "response": "def slice_hidden(self, x):\n    \"\"\"Slice encoder hidden state into block_dim.\n\n    Args:\n        x: Encoder hidden state of shape [-1, hidden_size].\n\n    Returns:\n        Sliced states of shape [-1, num_blocks, block_dim].\n    \"\"\"\n    x_sliced = tf.reshape(\n        x, shape=[-1, self.hparams.num_blocks, self.hparams.block_dim])\n    return x_sliced"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds the nearest element in means to elements in x.", "response": "def nearest_neighbor(self, x, means):\n    \"\"\"Find the nearest element in means to elements in x.\n\n    Args:\n        x: Batch of encoder continuous latent states sliced/projected into\n           shape [-1, num_blocks, block_dim].\n        means: Embedding means of shape.\n\n    Returns:\n      Tensor with nearest element in mean encoded in one-hot notation.\n    \"\"\"\n    x_norm_sq = tf.reduce_sum(tf.square(x), axis=-1, keep_dims=True)\n    means_norm_sq = tf.reduce_sum(tf.square(means), axis=-1, keep_dims=True)\n    scalar_prod = tf.matmul(\n        tf.transpose(x, perm=[1, 0, 2]), tf.transpose(means, perm=[0, 2, 1]))\n    scalar_prod = tf.transpose(scalar_prod, perm=[1, 0, 2])\n    dist = x_norm_sq + tf.transpose(\n        means_norm_sq, perm=[2, 0, 1]) - 2 * scalar_prod\n\n    if self.hparams.soft_em:\n      nearest_idx = tf.stack(\n          [\n              tf.multinomial(\n                  -dist[:, i, :], num_samples=self.hparams.num_samples)\n              for i in range(self.hparams.num_blocks)\n          ],\n          axis=1)\n      nearest_hot = tf.one_hot(nearest_idx, depth=self.hparams.block_v_size)\n      nearest_hot = tf.reduce_mean(nearest_hot, axis=-2)\n    else:\n      if self.hparams.random_top_k > 1:\n        _, top_k_idx = tf.nn.top_k(-dist, k=self.hparams.random_top_k)\n        nearest_idx = tf.gather(\n            top_k_idx,\n            tf.random_uniform(\n                [1],\n                minval=0,\n                maxval=self.hparams.random_top_k - 1,\n                dtype=tf.int32),\n            axis=-1)\n      else:\n        if self.hparams.use_scales:\n          dist /= tf.reshape(self.hparams.scales,\n                             [1, 1, self.hparams.moe_num_experts])\n        nearest_idx = tf.argmax(-dist, axis=-1)\n      nearest_hot = tf.one_hot(nearest_idx, self.hparams.block_v_size)\n    return nearest_hot"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef embedding_lookup(self, x, means):\n    x_means_hot = self.nearest_neighbor(x, means)\n    x_means_hot_flat = tf.reshape(\n        x_means_hot, [-1, self.hparams.num_blocks, self.hparams.block_v_size])\n    x_means = tf.matmul(tf.transpose(x_means_hot_flat, perm=[1, 0, 2]), means)\n    x_means = tf.transpose(x_means, [1, 0, 2])\n    q_loss = tf.reduce_mean(\n        tf.squared_difference(tf.stop_gradient(x), x_means))\n    e_loss = tf.reduce_mean(\n        tf.squared_difference(x, tf.stop_gradient(x_means)))\n    return x_means_hot, x_means, q_loss, e_loss", "response": "Compute nearest neighbors and loss for training the embeddings."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nturn x_int representing numbers into a bitwise lower - endian tensor.", "response": "def int_to_bit(self, x_int, num_bits, base=2):\n    \"\"\"Turn x_int representing numbers into a bitwise (lower-endian) tensor.\n\n    Args:\n        x_int: Tensor containing integer to be converted into base\n        notation.\n        num_bits: Number of bits in the representation.\n        base: Base of the representation.\n\n    Returns:\n        Corresponding number expressed in base.\n    \"\"\"\n    x_l = tf.to_int32(tf.expand_dims(x_int, axis=-1))\n    # pylint: disable=g-complex-comprehension\n    x_labels = [\n        tf.floormod(\n            tf.floordiv(tf.to_int32(x_l),\n                        tf.to_int32(base)**i), tf.to_int32(base))\n        for i in range(num_bits)]\n    res = tf.concat(x_labels, axis=-1)\n    return tf.to_float(res)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef embed(self, x):\n    shape_x = common_layers.shape_list(x)\n    x_flat = tf.reshape(x, [-1, 1])\n    c = self.int_to_bit(x_flat, num_bits=self.hparams.z_size, base=2)\n    shape = common_layers.shape_list(c)\n    new_shape = shape\n    new_shape.append(self.hparams.num_blocks)\n    new_shape.append(int(self.hparams.z_size / self.hparams.num_blocks))\n    c = tf.to_int32(tf.reshape(c, shape=new_shape))\n    h1_shape = shape_x\n    h1_shape.append(self.hparams.hidden_size)\n    h1 = tf.zeros(dtype=tf.float32, shape=h1_shape)\n    c_int = self.bit_to_int(\n        c, num_bits=int(self.hparams.z_size / self.hparams.num_blocks), base=2)\n    c_hot = tf.one_hot(c_int, depth=self.hparams.block_v_size, axis=-1)\n    c_hot_flat = tf.reshape(\n        c_hot, shape=[-1, self.hparams.num_blocks, self.hparams.block_v_size])\n    h1 = tf.matmul(tf.transpose(c_hot_flat, perm=[1, 0, 2]), self.means)\n    h1 = tf.transpose(h1, perm=[1, 0, 2])\n    h1 = tf.reshape(h1, shape=h1_shape)\n    h1_shape[0] = self.hparams.batch_size\n    h2 = tf.layers.dense(tf.nn.relu(h1), self.hparams.filter_size, name=\"vch2\")\n    res = tf.layers.dense(\n        tf.nn.relu(h2), self.hparams.hidden_size, name=\"vcfin\")\n    return res", "response": "Embedding function that takes discrete latent and returns embedding."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nswitch from Adam to Adafactor.", "response": "def mimic_adam_with_adafactor(hparams):\n  \"\"\"Switch from Adam to Adafactor, approximating the behavior of Adam.\n\n  Some minor things may be different, like epsilon and beta1 correction.\n\n  Args:\n    hparams: model hyperparameters where \"adam\" in hparams.optimizer\n  \"\"\"\n  assert \"adam\" in hparams.optimizer\n  hparams.optimizer = \"adafactor\"\n  hparams.optimizer_adafactor_beta1 = hparams.optimizer_adam_beta1\n  hparams.optimizer_adafactor_beta2 = hparams.optimizer_adam_beta2\n  hparams.optimizer_adafactor_multiply_by_parameter_scale = False\n  hparams.optimizer_adafactor_factored = False\n  hparams.optimizer_adafactor_clipping_threshold = None\n  hparams.optimizer_adafactor_decay_type = \"adam\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef afx_adam():\n  hparams = transformer.transformer_base_v2()\n  hparams.optimizer_adam_beta1 = 0.9\n  hparams.optimizer_adam_beta2 = 0.999\n  hparams.symbol_modality_num_shards = 1\n  hparams.batch_size = 2048\n  hparams.optimizer = \"adam\"\n  hparams.learning_rate_schedule = (\n      \"constant*rsqrt_decay*linear_warmup*rsqrt_hidden_size\")\n  hparams.learning_rate_constant = 2.0\n  return hparams", "response": "Old version - Adam."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef next_frame_emily():\n  hparams = sv2p_params.next_frame_sv2p()\n  hparams.video_num_input_frames = 2\n  hparams.video_num_target_frames = 10\n  hparams.learning_rate_constant = 1e-4\n  seq_length = hparams.video_num_input_frames + hparams.video_num_target_frames\n  # The latent_loss_multiplier is divided by the number of frames because\n  # the image sequence loss in t2t is averaged instead of added through\n  # time as they do in the SVG-LP paper\n  hparams.latent_loss_multiplier = 1e-4 / seq_length\n  hparams.reward_prediction = False\n  hparams.num_iterations_1st_stage = -1\n  hparams.num_iterations_2nd_stage = -1\n  hparams.optimizer_adam_beta1 = 0.9\n  hparams.optimizer_adam_beta2 = 0.999\n  hparams.optimizer_adam_epsilon = 1e-08\n  hparams.anneal_end = -1\n  hparams.clip_grad_norm = 5.0\n  hparams.add_hparam(\"learned_prior\", True)\n  hparams.add_hparam(\"z_dim\", 64)\n  hparams.add_hparam(\"g_dim\", 128)\n  hparams.add_hparam(\"rnn_size\", 256)\n  hparams.add_hparam(\"prior_rnn_layers\", 1)\n  hparams.add_hparam(\"posterior_rnn_layers\", 1)\n  hparams.add_hparam(\"predictor_rnn_layers\", 2)\n  hparams.add_hparam(\"has_skips\", True)\n  hparams.add_hparam(\"has_batchnorm\", True)\n  return hparams", "response": "Emily s model hparams."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main(_):\n  if FLAGS.subword_text_encoder_filename:\n    encoder = text_encoder.SubwordTextEncoder(\n        FLAGS.subword_text_encoder_filename)\n  elif FLAGS.token_text_encoder_filename:\n    encoder = text_encoder.TokenTextEncoder(FLAGS.token_text_encoder_filename)\n  elif FLAGS.byte_text_encoder:\n    encoder = text_encoder.ByteTextEncoder()\n  else:\n    encoder = None\n  reader = tf.python_io.tf_record_iterator(FLAGS.input_filename)\n  total_sequences = 0\n  total_input_tokens = 0\n  total_target_tokens = 0\n  nonpadding_input_tokens = 0\n  nonpadding_target_tokens = 0\n  max_input_length = 0\n  max_target_length = 0\n  for record in reader:\n    x = tf.train.Example()\n    x.ParseFromString(record)\n    inputs = [int(i) for i in x.features.feature[\"inputs\"].int64_list.value]\n    targets = [int(i) for i in x.features.feature[\"targets\"].int64_list.value]\n    if FLAGS.print_inputs:\n      print(\"INPUTS:\\n\" + encoder.decode(inputs) if encoder else inputs)\n    if FLAGS.print_targets:\n      print(\"TARGETS:\\n\" + encoder.decode(targets) if encoder else targets)\n    nonpadding_input_tokens += len(inputs) - inputs.count(0)\n    nonpadding_target_tokens += len(targets) - targets.count(0)\n    total_input_tokens += len(inputs)\n    total_target_tokens += len(targets)\n    total_sequences += 1\n    max_input_length = max(max_input_length, len(inputs))\n    max_target_length = max(max_target_length, len(targets))\n    if FLAGS.print_all:\n      for k, v in six.iteritems(x.features.feature):\n        print(\"%s: %s\" % (k, v.int64_list.value))\n\n  print(\"total_sequences: %d\" % total_sequences)\n  print(\"total_input_tokens: %d\" % total_input_tokens)\n  print(\"total_target_tokens: %d\" % total_target_tokens)\n  print(\"nonpadding_input_tokens: %d\" % nonpadding_input_tokens)\n  print(\"nonpadding_target_tokens: %d\" % nonpadding_target_tokens)\n  print(\"max_input_length: %d\" % max_input_length)\n  print(\"max_target_length: %d\" % max_target_length)", "response": "Convert a file to examples."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef example_reading_spec(self):\n    video_fields, video_decoders = (\n        video_utils.VideoProblem.example_reading_spec(self))\n    env_fields, env_decoders = env_problem.EnvProblem.example_reading_spec(self)\n\n    # Remove raw observations field since we want to capture them as videos.\n    env_fields.pop(env_problem.OBSERVATION_FIELD)\n    env_decoders.pop(env_problem.OBSERVATION_FIELD)\n\n    # Add frame number spec and decoder.\n    env_fields[_FRAME_NUMBER_FIELD] = tf.FixedLenFeature((1,), tf.int64)\n    env_decoders[\n        _FRAME_NUMBER_FIELD] = tf.contrib.slim.tfexample_decoder.Tensor(\n            _FRAME_NUMBER_FIELD)\n\n    # Add video fields and decoders\n    env_fields.update(video_fields)\n    env_decoders.update(video_decoders)\n    return env_fields, env_decoders", "response": "Return a mix of env and video data fields and decoders."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _generate_time_steps(self, trajectory_list):\n    for time_step in env_problem.EnvProblem._generate_time_steps(\n        self, trajectory_list):\n      # Convert the rendered observations from numpy to png format.\n      frame_np = np.array(time_step.pop(env_problem.OBSERVATION_FIELD))\n      frame_np = frame_np.reshape(\n          [self.frame_height, self.frame_width, self.num_channels])\n      # TODO(msaffar) Add support for non RGB rendered environments\n      frame = png.from_array(frame_np, \"RGB\", info={\"bitdepth\": 8})\n      frame_buffer = six.BytesIO()\n      frame.save(frame_buffer)\n\n      # Put the encoded frame back.\n      time_step[_IMAGE_ENCODED_FIELD] = [frame_buffer.getvalue()]\n      time_step[_IMAGE_FORMAT_FIELD] = [_FORMAT]\n      time_step[_IMAGE_HEIGHT_FIELD] = [self.frame_height]\n      time_step[_IMAGE_WIDTH_FIELD] = [self.frame_width]\n\n      # Add the frame number\n      time_step[_FRAME_NUMBER_FIELD] = time_step[env_problem.TIMESTEP_FIELD]\n      yield time_step", "response": "Transforms time step observations to frames of a video."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\niterating through lines of file.", "response": "def txt_line_iterator(txt_path):\n  \"\"\"Iterate through lines of file.\"\"\"\n  with tf.gfile.Open(txt_path) as f:\n    for line in f:\n      yield line.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef text2text_txt_iterator(source_txt_path, target_txt_path):\n  for inputs, targets in zip(\n      txt_line_iterator(source_txt_path), txt_line_iterator(target_txt_path)):\n    yield {\"inputs\": inputs, \"targets\": targets}", "response": "Yield dicts for Text2TextProblem. generate_samples from lines of files."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nyields dicts for Text2TextProblem. generate_samples from lines of files.", "response": "def text2text_distill_iterator(source_txt_path, target_txt_path,\n                               distill_txt_path):\n  \"\"\"Yield dicts for Text2TextProblem.generate_samples from lines of files.\"\"\"\n  for inputs, targets, dist_targets in zip(\n      txt_line_iterator(source_txt_path), txt_line_iterator(target_txt_path),\n      txt_line_iterator(distill_txt_path)):\n    yield {\"inputs\": inputs, \"targets\": targets, \"dist_targets\": dist_targets}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nyield dicts for Text2ClassProblem.generate_samples from lines of files. Args: source_txt_path: txt file with record per line. label_txt_path: txt file with label per line, either as int or str. If string, must provide class_strs. class_strs: list<str> of class label names. Must be in correct order (i.e. [\"a\", \"b\", \"c\"] means that \"a\" will get class ID 0, \"b\" ID 1, etc.). Yields: {\"inputs\": inputs, \"label\": label}", "response": "def text2class_txt_iterator(source_txt_path, label_txt_path, class_strs=None):\n  \"\"\"Yield dicts for Text2ClassProblem.generate_samples from lines of files.\n\n  Args:\n    source_txt_path: txt file with record per line.\n    label_txt_path: txt file with label per line, either as int or str. If\n      string, must provide class_strs.\n    class_strs: list<str> of class label names. Must be in correct order (i.e.\n      [\"a\", \"b\", \"c\"] means that \"a\" will get class ID 0, \"b\" ID 1, etc.).\n\n  Yields:\n    {\"inputs\": inputs, \"label\": label}\n  \"\"\"\n  if class_strs:\n    class_strs = dict([(s, i) for i, s in enumerate(class_strs)])\n  for inputs, label in zip(\n      txt_line_iterator(source_txt_path), txt_line_iterator(label_txt_path)):\n    label = label.strip()\n    if class_strs:\n      label = class_strs[label]\n    else:\n      label = int(label)\n    yield {\"inputs\": inputs, \"label\": label}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nyield dicts for Text2TextProblem. generate_samples from lines of txt_path.", "response": "def text2text_txt_tab_iterator(txt_path):\n  \"\"\"Yield dicts for Text2TextProblem.generate_samples from lines of txt_path.\n\n  Args:\n    txt_path: path to txt file with a record per line, source and target\n      are tab-separated.\n\n  Yields:\n    {\"inputs\": inputs, \"targets\": targets}\n  \"\"\"\n  for line in txt_line_iterator(txt_path):\n    if line and \"\\t\" in line:\n      parts = line.split(\"\\t\", 1)\n      inputs, targets = parts[:2]\n      yield {\"inputs\": inputs.strip(), \"targets\": targets.strip()}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef text2text_generate_encoded(sample_generator,\n                               vocab,\n                               targets_vocab=None,\n                               has_inputs=True,\n                               inputs_prefix=\"\",\n                               targets_prefix=\"\"):\n  \"\"\"Encode Text2Text samples from the generator with the vocab.\"\"\"\n  targets_vocab = targets_vocab or vocab\n  for sample in sample_generator:\n    if has_inputs:\n      sample[\"inputs\"] = vocab.encode(inputs_prefix + sample[\"inputs\"])\n      sample[\"inputs\"].append(text_encoder.EOS_ID)\n    sample[\"targets\"] = targets_vocab.encode(targets_prefix + sample[\"targets\"])\n    sample[\"targets\"].append(text_encoder.EOS_ID)\n    yield sample", "response": "Encode Text2Text samples from the generator with the vocab."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _pack_fn(self):\n    if not self.packed_length:\n      return None\n    def my_fn(records):\n      \"\"\"Function from list of TFRecords to list of TFRecords.\"\"\"\n      examples = []\n      for record in records:\n        x = tf.train.Example()\n        x.ParseFromString(record)\n        example_dict = {}\n        if self.has_inputs:\n          example_dict[\"inputs\"] = [\n              int(i) for i in x.features.feature[\"inputs\"].int64_list.value]\n        example_dict[\"targets\"] = [\n            int(i) for i in x.features.feature[\"targets\"].int64_list.value]\n        examples.append(example_dict)\n      examples = list(self._maybe_pack_examples(examples))\n      return [\n          generator_utils.to_example(x).SerializeToString() for x in examples]\n    return my_fn", "response": "Returns a function to pack examples."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap generator with packer.", "response": "def _maybe_pack_examples(self, generator):\n    \"\"\"Wraps generator with packer if self.packed_length.\"\"\"\n    if not self.packed_length:\n      return generator\n    return generator_utils.pack_examples(\n        generator,\n        self.has_inputs,\n        self.packed_length,\n        spacing=self.packed_spacing,\n        chop_long_sequences=not self.has_inputs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef text_filepaths_for_task(self, tmp_dir, task_id):\n    assert task_id >= 0\n    assert task_id < self.num_train_shards + self.num_dev_shards\n    if task_id < self.num_train_shards:\n      return [\n          f for i, f in enumerate(self.train_text_filepaths(tmp_dir))\n          if i % self.num_train_shards == task_id\n      ]\n    else:\n      return [\n          f for i, f in enumerate(self.dev_text_filepaths(tmp_dir))\n          if i % self.num_dev_shards == task_id - self.num_train_shards\n      ]", "response": "Returns a list of input filepaths for a particular training or dev shard."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading text out of an input file and converts it to unicode and yields one unicode string.", "response": "def filepath_to_unicode_strings(self, filepath):\n    \"\"\"Read text out of an input file.\n\n    The default just reads the text, converts to unicode and yields one\n    unicode string.\n\n    Subclasses can override this function in order to preprocess, and can\n    yield any number of strings.\n\n    Args:\n      filepath: a string\n    Yields:\n      unicode strings.\n    \"\"\"\n    f = tf.gfile.Open(filepath)\n    b = f.read()\n    yield text_encoder.to_unicode_ignore_errors(b)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads complete text of input files and yield unicode strings. By default, one unicode string is produced per file, but this is not guaranteed, since subclasses can override filepath_to_unicode_strings(). max_chars_per_file and max_chars_total can also be specified, in which case some strings may be truncated or dropped to limit the total amount of output. Args: filepaths: a list of strings max_chars_per_file: an optional integer max_chars_total: an optional integer Yields: unicode strings", "response": "def file_generator(self,\n                     filepaths,\n                     max_chars_per_file=None,\n                     max_chars_total=None):\n    \"\"\"Read complete text of input files and yield unicode strings.\n\n    By default, one unicode string is produced per file, but this is\n    not guaranteed, since subclasses can override\n    filepath_to_unicode_strings().\n\n    max_chars_per_file and max_chars_total can also be specified, in which\n    case some strings may be truncated or dropped to limit the total\n    amount of output.\n\n    Args:\n      filepaths: a list of strings\n      max_chars_per_file: an optional integer\n      max_chars_total: an optional integer\n    Yields:\n      unicode strings\n    \"\"\"\n    chars_total = 0\n    for fname in filepaths:\n      chars_this_file = 0\n      tf.logging.info(\"reading file %s\" % fname)\n      for text in self.filepath_to_unicode_strings(fname):\n        if (max_chars_per_file and\n            chars_this_file + len(text) > max_chars_per_file):\n          text = text[:max_chars_per_file - chars_this_file]\n        if max_chars_total and chars_total + len(text) > max_chars_total:\n          text = text[:max_chars_total - chars_total]\n        chars_total += len(text)\n        chars_this_file += len(text)\n        if text:\n          yield text\n        if max_chars_total and chars_total >= max_chars_total:\n          return\n        if max_chars_per_file and chars_this_file >= max_chars_per_file:\n          break"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prepare_to_generate(self, data_dir, tmp_dir):\n    self.get_or_create_vocab(data_dir, tmp_dir)\n    self.train_text_filepaths(tmp_dir)\n    self.dev_text_filepaths(tmp_dir)", "response": "Prepare to generate the vocabulary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_data(self, data_dir, tmp_dir, task_id=-1):\n    tf.logging.info(\"generate_data task_id=%s\" % task_id)\n    encoder = self.get_or_create_vocab(data_dir, tmp_dir)\n    assert task_id >= 0 and task_id < self.num_generate_tasks\n    if task_id < self.num_train_shards:\n      out_file = self.training_filepaths(\n          data_dir, self.num_train_shards, shuffled=False)[task_id]\n    else:\n      out_file = self.dev_filepaths(\n          data_dir, self.num_dev_shards,\n          shuffled=False)[task_id - self.num_train_shards]\n    generator_utils.generate_files(\n        self.example_generator(encoder, tmp_dir, task_id), [out_file])\n    generator_utils.shuffle_dataset([out_file])", "response": "Generates training and dev data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ConvBlock(kernel_size, filters, strides):\n  ks = kernel_size\n  filters1, filters2, filters3 = filters\n  main = layers.Serial(\n      layers.Conv(filters1, (1, 1), strides),\n      layers.BatchNorm(),\n      layers.Relu(),\n      layers.Conv(filters2, (ks, ks), padding='SAME'),\n      layers.BatchNorm(),\n      layers.Relu(),\n      layers.Conv(filters3, (1, 1)),\n      layers.BatchNorm()\n  )\n  shortcut = layers.Serial(\n      layers.Conv(filters3, (1, 1), strides),\n      layers.BatchNorm()\n  )\n  return layers.Serial(\n      layers.Branch(),\n      layers.Parallel(main, shortcut),\n      layers.SumBranches(),\n      layers.Relu()\n  )", "response": "ResNet convolutional striding block."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef WideResnet(num_blocks=3, hidden_size=64, num_output_classes=10,\n               mode='train'):\n  \"\"\"WideResnet from https://arxiv.org/pdf/1605.07146.pdf.\n\n  Args:\n    num_blocks: int, number of blocks in a group.\n    hidden_size: the size of the first hidden layer (multiplied later).\n    num_output_classes: int, number of classes to distinguish.\n    mode: is it training or eval.\n\n  Returns:\n    The WideResnet model with given layer and output sizes.\n  \"\"\"\n  del mode\n  return layers.Serial(\n      layers.Conv(hidden_size, (3, 3), padding='SAME'),\n      WideResnetGroup(num_blocks, hidden_size),\n      WideResnetGroup(num_blocks, hidden_size * 2, (2, 2)),\n      WideResnetGroup(num_blocks, hidden_size * 4, (2, 2)), layers.BatchNorm(),\n      layers.Relu(), layers.AvgPool(pool_size=(8, 8)), layers.Flatten(),\n      layers.Dense(num_output_classes), layers.LogSoftmax())", "response": "WideResnet model from https://arxiv. org / pdf / 1605. 08146. pdf."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GRUCell(units):\n  return GeneralGRUCell(\n      candidate_transform=lambda: core.Dense(units=units),\n      memory_transform=combinators.Identity,\n      gate_nonlinearity=core.Sigmoid,\n      candidate_nonlinearity=core.Tanh)", "response": "Builds a traditional GRU cell with dense internal transformations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ConvGRUCell(units, kernel_size=(3, 3)):\n\n  def BuildConv():\n    return core.Conv(filters=units, kernel_size=kernel_size, padding='SAME')\n\n  return GeneralGRUCell(\n      candidate_transform=BuildConv,\n      memory_transform=combinators.Identity,\n      gate_nonlinearity=core.Sigmoid,\n      candidate_nonlinearity=core.Tanh)", "response": "Builds a convolutional GRU cell."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate an attention mask to hide padding and future words.", "response": "def MakeTargetMask(target, pad=0):\n  \"\"\"Create an attention mask to hide padding and future words.\"\"\"\n  target_mask = (target != pad)[ :, np.newaxis, :]\n  target_dtype = target_mask.dtype\n  causal_mask = onp.tril(onp.ones((1, target.shape[-1], target.shape[-1]),\n                                  dtype=target_dtype), k=0)\n  target_mask = target_mask & causal_mask\n  return np.expand_dims(target_mask, axis=1)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprepare a batch of arrays for paired sequences.", "response": "def PreparePairedSequenceBatch(source, target_in, pad=0):\n  \"\"\"Build masks for this batch.\n\n  Args:\n    source: (batch, source_len) array of integer-coded symbols for inputs\n    target_in: (batch, batch_len) array of integer-coded symbols for targets\n    pad: int: the padding symbol used to pad the above\n\n  Returns:\n    Prepared batch of tuple of arrays: source, input-target, shifted-target,\n    source mask, target mask, source-target \"memory\" mask, minibatch token count\n  \"\"\"\n  target = target_in[:, :-1]\n  target_y = target_in[:, 1:]\n  source_mask = np.reshape(source != pad,\n                           (source.shape[0], 1, 1, source.shape[-1]))\n  target_mask = MakeTargetMask(target, pad)\n  memory_mask = (\n      np.reshape(np.arange(target.shape[-1]) < source.shape[-1], [-1, 1]))\n  ntokens = np.sum(target_y != pad)\n  return (source, target, target_y,\n          source_mask, target_mask, memory_mask, ntokens)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _positional_encoding_new_params(input_shape, rng, max_len=2048):  # pylint: disable=invalid-name\n  del rng\n  # Check if we are operating on chunked inputs by checking if the first\n  # shape is a list/tuple of shapes (otherwise it's an int or numpy array).\n  is_chunked = isinstance(input_shape[0], (list, tuple))\n  feature_depth = input_shape[0][-1] if is_chunked else input_shape[-1]\n  pe = onp.zeros((max_len, feature_depth), dtype=onp.float32)\n  position = onp.arange(0, max_len)[:, onp.newaxis]\n  div_term = onp.exp(\n      onp.arange(0, feature_depth, 2) * -(onp.log(10000.0) / feature_depth))\n  pe[:, 0::2] = onp.sin(position * div_term)\n  pe[:, 1::2] = onp.cos(position * div_term)\n  pe = pe[onp.newaxis, :, :]  # [1, max_len, feature_depth]\n  return np.array(pe)", "response": "Helper function to create positional encoding parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef PositionalEncoding(x, params, **unused_kwargs):\n  if not isinstance(x, (list, tuple)):  # non-chunked inputs\n    symbol_size = np.shape(x)[1]\n    return x + params[:, :symbol_size, :]\n  # Chunked case: apply to all chunks selecting as much as needed.\n  offset = 0\n  results = []\n  for chunk in x:\n    symbol_size = np.shape(chunk)[1]\n    results.append(chunk + params[:, offset:offset + symbol_size, :])\n    offset += symbol_size\n  return results", "response": "Implements bare positional encoding."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef DotProductAttention(query, key, value, mask, dropout, mode, rng):\n  depth = np.shape(query)[-1]\n  dots = np.matmul(query, np.swapaxes(key, -1, -2)) / np.sqrt(depth)\n  if mask is not None:\n    dots = np.where(mask, dots, -1e9)\n  # Softmax.\n  dots = np.exp(dots - backend.logsumexp(dots, axis=-1, keepdims=True))\n  if dropout >= 1.0:\n    raise ValueError('Dropout rates must be lower than 1.')\n  if dropout is not None and dropout > 0.0 and mode == 'train':\n    keep = backend.random.bernoulli(rng, 1.0 - dropout, dots.shape)\n    dots = np.where(keep, dots / (1.0 - dropout), 0)\n  out = np.matmul(dots, value)\n  return out", "response": "Core dot product self - attention."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef PureMultiHeadedAttention(x, params, num_heads=8, dropout=0.0,\n                             mode='train', **kwargs):\n  \"\"\"Pure transformer-style multi-headed attention.\n\n  Args:\n    x: inputs ((q, k, v), mask)\n    params: parameters (none)\n    num_heads: int: number of attention heads\n    dropout: float: dropout rate\n    mode: str: 'train' or 'eval'\n    **kwargs: other arguments including the rng\n\n  Returns:\n    Pure Multi-headed attention layer (no Dense transforms on input).\n  \"\"\"\n  del params\n  rng = kwargs.get('rng', None)\n  (q, k, v), mask = x\n  feature_depth = q.shape[-1]\n  assert feature_depth % num_heads == 0\n  head_depth = feature_depth // num_heads\n  nbatch = np.shape(q)[0]\n  # nbatch, seqlen, feature_depth --> nbatch, num_heads, seqlen, head_depth\n  def SplitHeads(x):\n    return np.transpose(\n        np.reshape(x, (nbatch, -1, num_heads, head_depth)), (0, 2, 1, 3))\n  # nbatch, num_heads, seqlen, head_depth --> nbatch, seqlen, feature_depth\n  def JoinHeads(x):  # pylint: disable=invalid-name\n    return np.reshape(\n        np.transpose(x, (0, 2, 1, 3)), (nbatch, -1, num_heads*head_depth))\n  # Split heads, dot-product attention, rejoin heads.\n  return JoinHeads(\n      DotProductAttention(\n          SplitHeads(q), SplitHeads(k), SplitHeads(v), mask,\n          dropout=dropout, mode=mode, rng=rng))", "response": "Pure Transformer - style multi - headed attention."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef MultiHeadedAttention(\n    feature_depth, num_heads=8, dropout=0.0, mode='train'):\n  \"\"\"Transformer-style multi-headed attention.\n\n  Accepts inputs of the form (x, mask) and constructs (q, k, v) from x.\n\n  Args:\n    feature_depth: int:  depth of embedding\n    num_heads: int: number of attention heads\n    dropout: float: dropout rate\n    mode: str: 'train' or 'eval'\n\n  Returns:\n    Multi-headed self-attention layer.\n  \"\"\"\n  return combinators.Serial(\n      combinators.Parallel(\n          combinators.Branch(num_branches=3),  # q = k = v = first input\n          combinators.Identity()  # pass the mask\n      ),\n      MultiHeadedAttentionQKV(  # pylint: disable=no-value-for-parameter\n          feature_depth, num_heads=num_heads, dropout=dropout, mode=mode),\n  )", "response": "Transformer - style multi - headed attention.\n    Accepts inputs of the form x mask and constructs q k v from x."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nselects which chunks to attend to in chunked attention.", "response": "def ChunkedAttentionSelector(x, params, selector=None, **kwargs):\n  \"\"\"Select which chunks to attend to in chunked attention.\n\n  Args:\n    x: inputs, a list of elements of the form (q, k, v), mask for each chunk.\n    params: parameters (unused).\n    selector: a function from chunk_number -> list of chunk numbers that says\n      which other chunks should be appended to the given one (previous if None).\n    **kwargs: unused other arguments.\n\n  Returns:\n    a list of elements of the form (q, k', v'), mask' where k', v' and mask' are\n    concatenations of k, v and identity-extended masks from selected chunks.\n  \"\"\"\n  del params, kwargs\n  selector = selector or (lambda x: [] if x < 1 else [x-1])\n  triples, masks = zip(*x)\n  (queries, keys, values) = zip(*triples)\n  result = []\n  for i in range(len(x)):\n    selected = selector(i)\n    # Since keys and values are [batch, length, depth] we concatenate on axis=1.\n    # We also always include the current key or value at the end.\n    new_key_list = [keys[j] for j in selected]\n    new_key = np.concatenate(new_key_list + [keys[i]], axis=1)\n    new_value = np.concatenate(\n        [values[j] for j in selected] + [values[i]], axis=1)\n    # Masks are (1, query-len, key-len) so we concatenate on axis=2.\n    new_mask_shapes = [(1, queries[i].shape[1], key.shape[1])\n                       for key in new_key_list]\n    cur_mask = masks[i]\n    # Masks are all-1 for the added chunks (no masking).\n    new_mask_list = [np.ones(s, dtype=cur_mask.dtype) for s in new_mask_shapes]\n    # We still use the current (often causal) mask for the final chunk.\n    new_mask = np.concatenate(new_mask_list + [cur_mask], axis=2)\n    result.append(((queries[i], new_key, new_value), new_mask))\n  return tuple(result)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ChunkedCausalMultiHeadedAttention(\n    feature_depth, num_heads=8, dropout=0.0, chunk_selector=None, mode='train'):\n  \"\"\"Transformer-style causal multi-headed attention operating on chunks.\n\n  Accepts inputs that are a list of chunks and applies causal attention.\n\n  Args:\n    feature_depth: int:  depth of embedding\n    num_heads: int: number of attention heads\n    dropout: float: dropout rate\n    chunk_selector: a function from chunk number to list of chunks to attend.\n    mode: str: 'train' or 'eval'\n\n  Returns:\n    Multi-headed self-attention layer.\n  \"\"\"\n  prepare_attention_input = combinators.Serial(\n      combinators.Branch(),\n      combinators.Parallel(\n          combinators.Branch(num_branches=3),  # q = k = v = first input\n          CausalMask(axis=-2),  # pylint: disable=no-value-for-parameter\n      ),\n      combinators.Parallel(\n          combinators.Parallel(\n              core.Dense(feature_depth),\n              core.Dense(feature_depth),\n              core.Dense(feature_depth),\n          ),\n          combinators.Identity()\n      )\n  )\n  return combinators.Serial(\n      combinators.Map(prepare_attention_input),\n      ChunkedAttentionSelector(selector=chunk_selector),  # pylint: disable=no-value-for-parameter\n      combinators.Map(PureMultiHeadedAttention(  # pylint: disable=no-value-for-parameter\n          feature_depth=feature_depth, num_heads=num_heads,\n          dropout=dropout, mode=mode), check_shapes=False),\n      combinators.Map(core.Dense(feature_depth))\n  )", "response": "Transformer - style causal multi - headed attention operating on chunks."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ShiftRight(x, **unused_kwargs):\n  if not isinstance(x, (list, tuple)):  # non-chunked inputs\n    pad_widths = [(0, 0), (1, 0)]\n    padded = np.pad(x, pad_widths, mode='constant')\n    return padded[:, :-1]\n  # Handling chunked inputs. Recall that the list of chunks represents a big\n  # sequence (the concatenation of the chunks). We want to shift that sequence,\n  # so we put a 0 in the beginning of the first chunk and the last element of\n  # that chunk is used as the new first element of the next chunk, and so on.\n  padded = []\n  last_value = np.zeros_like(x[0][:, -1])\n  for chunk in x:\n    padded_chunk = np.concatenate([last_value[:, np.newaxis], chunk], axis=1)\n    last_value = chunk[:, -1]\n    padded.append(padded_chunk[:, :-1])\n  return padded", "response": "Layer to shift the tensor to the right by padding on axis 1."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef zipf_distribution(nbr_symbols, alpha):\n  tmp = np.power(np.arange(1, nbr_symbols + 1), -alpha)\n  zeta = np.r_[0.0, np.cumsum(tmp)]\n  return [x / zeta[-1] for x in zeta]", "response": "Helper function to create a Zipf distribution."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef lower_endian_to_number(l, base):\n  return sum([d * (base**i) for i, d in enumerate(l)])", "response": "Helper function to convert a list of digits in the given base to a number."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef random_number_lower_endian(length, base):\n  if length == 1:  # Last digit can be 0 only if length is 1.\n    return [np.random.randint(base)]\n  prefix = [np.random.randint(base) for _ in range(length - 1)]\n  return prefix + [np.random.randint(base - 1) + 1]", "response": "Helper function to generate a random number as a lower - endian digits list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun command on GCS instance.", "response": "def remote_run(cmd, instance_name, detach=False, retries=1):\n  \"\"\"Run command on GCS instance, optionally detached.\"\"\"\n  if detach:\n    cmd = SCREEN.format(command=cmd)\n  args = SSH.format(instance_name=instance_name).split()\n  args.append(cmd)\n  for i in range(retries + 1):\n    try:\n      if i > 0:\n        tf.logging.info(\"Retry %d for %s\", i, args)\n      return sp.check_call(args)\n    except sp.CalledProcessError as e:\n      if i == retries:\n        raise e"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wait_for_ssh(ip):\n  for _ in range(12):\n    with safe_socket() as s:\n      try:\n        s.connect((ip, 22))\n        return True\n      except socket.timeout:\n        pass\n    time.sleep(10)\n  return False", "response": "Wait for SSH to be available at given IP address."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef launch_instance(instance_name,\n                    command,\n                    existing_ip=None,\n                    cpu=1,\n                    mem=4,\n                    code_dir=None,\n                    setup_command=None):\n  \"\"\"Launch a GCE instance.\"\"\"\n  # Create instance\n  ip = existing_ip or create_instance(instance_name, cpu=cpu, mem=mem)\n  tf.logging.info(\"Waiting for SSH %s\", instance_name)\n  ready = wait_for_ssh(ip)\n  if not ready:\n    raise ValueError(\"Instance %s never ready for SSH\" % instance_name)\n\n  # Copy code\n  if code_dir:\n    shell_run_with_retry(COPY_CODE, retries=2,\n                         local_dir=code_dir, instance_name=instance_name)\n\n  # Run setup\n  if setup_command:\n    tf.logging.info(\"Running setup on %s\", instance_name)\n    remote_run(setup_command, instance_name)\n\n  # Run command\n  tf.logging.info(\"Running command on %s\", instance_name)\n  remote_run(command, instance_name, detach=True)", "response": "Launch a GCE instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef evolved_transformer_encoder(encoder_input,\n                                encoder_self_attention_bias,\n                                hparams,\n                                name=\"encoder\",\n                                nonpadding=None,\n                                save_weights_to=None,\n                                make_image_summary=True,\n                                losses=None,\n                                attn_bias_for_padding=None):\n  \"\"\"Evolved Transformer encoder. See arxiv.org/abs/1901.11117 for more details.\n\n  Note: Pad remover is not supported.\n\n  Args:\n    encoder_input: a Tensor.\n    encoder_self_attention_bias: bias Tensor for self-attention (see\n      common_attention.attention_bias()).\n    hparams: hyperparameters for model.\n    name: a string.\n    nonpadding: optional Tensor with shape [batch_size, encoder_length]\n      indicating what positions are not padding.  This must either be passed in,\n      which we do for \"packed\" datasets, or inferred from\n      encoder_self_attention_bias.  The knowledge about padding is used for\n      pad_remover(efficiency) and to mask out padding in convolutional layers.\n    save_weights_to: an optional dictionary to capture attention weights for\n      visualization; the weights tensor will be appended there under a string\n      key created from the variable scope (including name).\n    make_image_summary: Whether to make an attention image summary.\n    losses: Not used.\n    attn_bias_for_padding: Padded attention bias in case a unidirectional\n      encoder is being used where future attention is masked.\n\n  Returns:\n    Tensor encoder output.\n  \"\"\"\n  del losses\n\n  hidden_state = encoder_input\n  attention_dropout_broadcast_dims = (\n      common_layers.comma_separated_string_to_integer_list(\n          getattr(hparams, \"attention_dropout_broadcast_dims\", \"\")))\n\n  with tf.variable_scope(name):\n    if nonpadding is not None:\n      padding = 1.0 - nonpadding\n    else:\n      attention_bias = encoder_self_attention_bias\n      if attn_bias_for_padding is not None:\n        attention_bias = attn_bias_for_padding\n      # Only bfloat16 and float32 supported.\n      float_type = hparams.get(\"activation_dtype\", \"float32\")\n      if float_type == \"bfloat16\":\n        cast_fn = tf.to_bfloat16\n      else:\n        assert float_type == \"float32\"\n        cast_fn = tf.to_float\n      padding = common_attention.attention_bias_to_padding(\n          attention_bias, cast_fn)\n      nonpadding = 1.0 - padding\n\n    for layer in range(hparams.num_encoder_layers or hparams.num_hidden_layers):\n      with tf.variable_scope(\"layer_%d\" % layer):\n\n        with tf.variable_scope(\"gated_linear_unit\"):\n\n          residual_state = hidden_state\n          hidden_state = common_layers.layer_preprocess(hidden_state, hparams)\n\n          values = common_layers.layers().Dense(\n              hparams.hidden_size)(hidden_state)\n          gates = common_layers.layers().Dense(\n              hparams.hidden_size, activation=tf.nn.sigmoid)(hidden_state)\n          hidden_state = values * gates\n\n          hidden_state = common_layers.layer_postprocess(\n              residual_state, hidden_state, hparams)\n\n        with tf.variable_scope(\"conv_branches\"):\n\n          residual_state = hidden_state\n          hidden_state = common_layers.layer_preprocess(hidden_state, hparams)\n          # Mask padding from conv layers.\n          mask = tf.tile(\n              tf.expand_dims(nonpadding, 2), [1, 1, hparams.hidden_size])\n          hidden_state *= mask\n\n          left_output_dim = int(hparams.hidden_size * 4)\n          left_state = common_layers.layers().Dense(\n              left_output_dim, activation=tf.nn.relu)(hidden_state)\n          left_state = tf.nn.dropout(left_state,\n                                     1 - hparams.layer_prepostprocess_dropout)\n\n          right_output_dim = int(hparams.hidden_size / 2)\n          right_state = common_layers.layers().Conv1D(\n              right_output_dim,\n              3,\n              padding=\"SAME\",\n              name=\"standard_conv_3x1\",\n              activation=tf.nn.relu)(hidden_state)\n          right_state = tf.nn.dropout(right_state,\n                                      1 - hparams.layer_prepostprocess_dropout)\n\n          right_state = tf.pad(\n              right_state,\n              [[0, 0], [0, 0], [0, left_output_dim - right_output_dim]],\n              constant_values=0)\n          hidden_state = left_state + right_state\n\n          hidden_state = common_layers.layer_preprocess(hidden_state, hparams)\n          # Mask padding from conv layer.\n          mask = tf.tile(tf.expand_dims(nonpadding, 2), [1, 1, left_output_dim])\n          hidden_state *= mask\n\n          separable_conv_9x1 = common_layers.layers().SeparableConv1D(\n              right_output_dim, 9, padding=\"SAME\", name=\"separable_conv_9x1\")\n          hidden_state = separable_conv_9x1(hidden_state)\n          hidden_state = tf.pad(\n              hidden_state,\n              [[0, 0], [0, 0], [0, hparams.hidden_size - right_output_dim]],\n              constant_values=0)\n\n          hidden_state = common_layers.layer_postprocess(\n              residual_state, hidden_state, hparams)\n\n        with tf.variable_scope(\"self_attention\"):\n          residual_state = hidden_state\n          hidden_state = common_layers.layer_preprocess(hidden_state, hparams)\n\n          hidden_state = common_attention.multihead_attention(\n              hidden_state,\n              None,\n              encoder_self_attention_bias,\n              hparams.attention_key_channels or hparams.hidden_size,\n              hparams.attention_value_channels or hparams.hidden_size,\n              hparams.hidden_size,\n              hparams.num_heads,\n              hparams.attention_dropout,\n              attention_type=hparams.self_attention_type,\n              max_relative_position=hparams.max_relative_position,\n              heads_share_relative_embedding=(\n                  hparams.heads_share_relative_embedding),\n              add_relative_to_values=hparams.add_relative_to_values,\n              save_weights_to=save_weights_to,\n              make_image_summary=make_image_summary,\n              dropout_broadcast_dims=attention_dropout_broadcast_dims,\n              max_length=hparams.get(\"max_length\"),\n              vars_3d=hparams.get(\"attention_variables_3d\"),\n              activation_dtype=hparams.get(\"activation_dtype\", \"float32\"),\n              weight_dtype=hparams.get(\"weight_dtype\", \"float32\"))\n\n          hidden_state = common_layers.layer_postprocess(\n              residual_state, hidden_state, hparams)\n\n        with tf.variable_scope(\"dense_layers\"):\n          residual_state = hidden_state\n          hidden_state = common_layers.layer_preprocess(hidden_state, hparams)\n\n          hidden_state = common_layers.layers().Dense(\n              int(hparams.hidden_size * 4), activation=tf.nn.relu)(hidden_state)\n          hidden_state = tf.nn.dropout(hidden_state,\n                                       1 - hparams.layer_prepostprocess_dropout)\n\n          hidden_state = common_layers.layers().Dense(\n              hparams.hidden_size)(hidden_state)\n          hidden_state = common_layers.layer_postprocess(\n              residual_state, hidden_state, hparams)\n\n    # If normalization is done in layer_preprocess, then it should also be done\n    # on the output, since the output can grow very large, being the sum of\n    # a whole stack of unnormalized layer outputs.\n    return common_layers.layer_preprocess(hidden_state, hparams)", "response": "Evolved Transformer encoder. See arxiv.org/abs/1901.11117 for more details.\n\n  Note: Pad remover is not supported.\n\n  Args:\n    encoder_input: a Tensor.\n    encoder_self_attention_bias: bias Tensor for self-attention (see\n      common_attention.attention_bias()).\n    hparams: hyperparameters for model.\n    name: a string.\n    nonpadding: optional Tensor with shape [batch_size, encoder_length]\n      indicating what positions are not padding.  This must either be passed in,\n      which we do for \"packed\" datasets, or inferred from\n      encoder_self_attention_bias.  The knowledge about padding is used for\n      pad_remover(efficiency) and to mask out padding in convolutional layers.\n    save_weights_to: an optional dictionary to capture attention weights for\n      visualization; the weights tensor will be appended there under a string\n      key created from the variable scope (including name).\n    make_image_summary: Whether to make an attention image summary.\n    losses: Not used.\n    attn_bias_for_padding: Padded attention bias in case a unidirectional\n      encoder is being used where future attention is masked.\n\n  Returns:\n    Tensor encoder output."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nevolves Transformer decoder. See arxiv.org/abs/1901.11117 for more details. Args: decoder_input: a Tensor. encoder_output: a Tensor. decoder_self_attention_bias: bias Tensor for self-attention (see common_attention.attention_bias()). encoder_decoder_attention_bias: bias Tensor for encoder-decoder attention (see common_attention.attention_bias()). hparams: hyperparameters for model. cache: dict, containing tensors which are the results of previous layers, used for fast decoding. decode_loop_step: An integer, step number of the decoding loop. Only used for inference on TPU. name: a string. nonpadding: optional Tensor with shape [batch_size, encoder_length] indicating what positions are not padding. This is used to mask out padding in convolutional layers. We generally only need this mask for \"packed\" datasets, because for ordinary datasets, no padding is ever followed by nonpadding. save_weights_to: an optional dictionary to capture attention weights for visualization; the weights tensor will be appended there under a string key created from the variable scope (including name). make_image_summary: Whether to make an attention image summary. losses: Not supported. Returns: Decoder output tensor.", "response": "def evolved_transformer_decoder(decoder_input,\n                                encoder_output,\n                                decoder_self_attention_bias,\n                                encoder_decoder_attention_bias,\n                                hparams,\n                                cache=None,\n                                decode_loop_step=None,\n                                name=\"decoder\",\n                                nonpadding=None,\n                                save_weights_to=None,\n                                make_image_summary=True,\n                                losses=None):\n  \"\"\"Evolved Transformer decoder. See arxiv.org/abs/1901.11117 for more details.\n\n  Args:\n    decoder_input: a Tensor.\n    encoder_output: a Tensor.\n    decoder_self_attention_bias: bias Tensor for self-attention (see\n      common_attention.attention_bias()).\n    encoder_decoder_attention_bias: bias Tensor for encoder-decoder attention\n      (see common_attention.attention_bias()).\n    hparams: hyperparameters for model.\n    cache: dict, containing tensors which are the results of previous\n      layers, used for fast decoding.\n    decode_loop_step: An integer, step number of the decoding loop. Only used\n      for inference on TPU.\n    name: a string.\n    nonpadding: optional Tensor with shape [batch_size, encoder_length]\n      indicating what positions are not padding.  This is used to mask out\n      padding in convolutional layers.  We generally only need this mask for\n      \"packed\" datasets, because for ordinary datasets, no padding is ever\n      followed by nonpadding.\n    save_weights_to: an optional dictionary to capture attention weights for\n      visualization; the weights tensor will be appended there under a string\n      key created from the variable scope (including name).\n    make_image_summary: Whether to make an attention image summary.\n    losses: Not supported.\n\n  Returns:\n    Decoder output tensor.\n  \"\"\"\n  del losses\n\n  attention_dropout_broadcast_dims = (\n      common_layers.comma_separated_string_to_integer_list(\n          getattr(hparams, \"attention_dropout_broadcast_dims\", \"\")))\n\n  with tf.variable_scope(name):\n    hidden_state = decoder_input\n\n    for layer in range(hparams.num_decoder_layers or hparams.num_hidden_layers):\n      layer_name = \"layer_%d\" % layer\n      layer_cache = cache[layer_name] if cache is not None else None\n      with tf.variable_scope(layer_name):\n\n        with tf.variable_scope(_SIXTEEN_HEAD_ATTENTION_NAME):\n          residual_state = hidden_state\n          hidden_state = common_layers.layer_preprocess(hidden_state, hparams)\n\n          attention_cache = layer_cache[\n              _SIXTEEN_HEAD_ATTENTION_NAME] if layer_cache is not None else None\n          left_state = common_attention.multihead_attention(\n              hidden_state,\n              None,\n              decoder_self_attention_bias,\n              hparams.attention_key_channels or hparams.hidden_size,\n              hparams.attention_value_channels or hparams.hidden_size,\n              hparams.hidden_size,\n              _capped_double_heads(hparams.num_heads),\n              hparams.attention_dropout,\n              attention_type=hparams.self_attention_type,\n              max_relative_position=hparams.max_relative_position,\n              heads_share_relative_embedding=(\n                  hparams.heads_share_relative_embedding),\n              add_relative_to_values=hparams.add_relative_to_values,\n              save_weights_to=save_weights_to,\n              cache=attention_cache,\n              make_image_summary=make_image_summary,\n              dropout_broadcast_dims=attention_dropout_broadcast_dims,\n              max_length=hparams.get(\"max_length\"),\n              decode_loop_step=decode_loop_step,\n              vars_3d=hparams.get(\"attention_variables_3d\"),\n              activation_dtype=hparams.get(\"activation_dtype\", \"float32\"),\n              weight_dtype=hparams.get(\"weight_dtype\", \"float32\"))\n\n        if encoder_output is not None:\n          with tf.variable_scope(_FIRST_ATTEND_TO_ENCODER_NAME):\n            attention_cache = (\n                layer_cache[_FIRST_ATTEND_TO_ENCODER_NAME]\n                if layer_cache is not None else None)\n            right_state = common_attention.multihead_attention(\n                hidden_state,\n                encoder_output,\n                encoder_decoder_attention_bias,\n                hparams.attention_key_channels or hparams.hidden_size,\n                hparams.attention_value_channels or hparams.hidden_size,\n                hparams.hidden_size,\n                hparams.num_heads,\n                hparams.attention_dropout,\n                max_relative_position=hparams.max_relative_position,\n                heads_share_relative_embedding=(\n                    hparams.heads_share_relative_embedding),\n                add_relative_to_values=hparams.add_relative_to_values,\n                save_weights_to=save_weights_to,\n                cache=attention_cache,\n                make_image_summary=make_image_summary,\n                dropout_broadcast_dims=attention_dropout_broadcast_dims,\n                max_length=hparams.get(\"max_length\"),\n                vars_3d=hparams.get(\"attention_variables_3d\"),\n                activation_dtype=hparams.get(\"activation_dtype\", \"float32\"),\n                weight_dtype=hparams.get(\"weight_dtype\", \"float32\"))\n\n            left_state = tf.nn.dropout(left_state,\n                                       1 - hparams.layer_prepostprocess_dropout)\n            right_state = tf.nn.dropout(\n                right_state, 1 - hparams.layer_prepostprocess_dropout)\n\n            hidden_state = residual_state + left_state + right_state\n\n        else:\n          hidden_state = common_layers.layer_postprocess(\n              residual_state, left_state, hparams)\n\n        with tf.variable_scope(_CONV_BRANCHES_NAME):\n          residual_state = hidden_state\n          hidden_state = common_layers.layer_preprocess(hidden_state, hparams)\n\n          if nonpadding is not None:\n            # Mask padding from conv layers.\n            mask = tf.tile(\n                tf.expand_dims(nonpadding, 2), [1, 1, hparams.hidden_size])\n            hidden_state *= mask\n\n          if layer_cache:\n            if decode_loop_step is None:\n              hidden_state = layer_cache[\n                  _CONV_BRANCHES_FIRST_LAYER_NAME] = tf.concat(\n                      [\n                          layer_cache[_CONV_BRANCHES_FIRST_LAYER_NAME],\n                          hidden_state\n                      ],\n                      axis=1)[:, -1 * _DECODER_LEFT_CONV_PADDING - 1:, :]\n              left_state = hidden_state\n              right_state = hidden_state[:, _DECODER_LEFT_CONV_PADDING -\n                                         _DECODER_RIGHT_CONV_PADDING:, :]\n\n            else:\n              # Inplace update is required for inference on TPU.\n              # Inplace_ops only supports inplace_update on the first dimension.\n              tmp = tf.transpose(\n                  layer_cache[_CONV_BRANCHES_FIRST_LAYER_NAME], perm=[1, 0, 2])\n              tmp = tf.expand_dims(tmp, axis=1)\n              tmp = inplace_ops.alias_inplace_update(\n                  tmp,\n                  decode_loop_step * tf.shape(hidden_state)[1] +\n                  _DECODER_LEFT_CONV_PADDING,\n                  tf.transpose(hidden_state, perm=[1, 0, 2]))\n              tmp = tf.squeeze(tmp, axis=1)\n              hidden_state = layer_cache[\n                  _CONV_BRANCHES_FIRST_LAYER_NAME] = tf.transpose(\n                      tmp, perm=[1, 0, 2])\n\n              left_state_indexes = [\n                  decode_loop_step + i\n                  for i in range(_DECODER_LEFT_CONV_PADDING + 1)\n              ]\n              left_state = tf.gather(hidden_state, left_state_indexes, axis=1)\n              right_state_indexes = [\n                  decode_loop_step + i +\n                  (_DECODER_LEFT_CONV_PADDING - _DECODER_RIGHT_CONV_PADDING)\n                  for i in range(_DECODER_RIGHT_CONV_PADDING + 1)\n              ]\n              right_state = tf.gather(hidden_state, right_state_indexes, axis=1)\n\n          else:  # No caching.\n            left_state = tf.pad(\n                hidden_state,\n                paddings=[[0, 0], [_DECODER_LEFT_CONV_PADDING, 0], [0, 0]])\n            right_state = tf.pad(\n                hidden_state,\n                paddings=[[0, 0], [_DECODER_RIGHT_CONV_PADDING, 0], [0, 0]])\n\n          left_output_dim = int(hparams.hidden_size * 2)\n          separable_conv_11x1 = tf.layers.SeparableConv1D(\n              left_output_dim,\n              11,\n              padding=\"VALID\",\n              name=\"separable_conv11x1\",\n              activation=tf.nn.relu)\n          left_state = separable_conv_11x1.apply(left_state)\n          left_state = tf.nn.dropout(left_state,\n                                     1 - hparams.layer_prepostprocess_dropout)\n\n          right_output_dim = int(hparams.hidden_size / 2)\n          separable_conv_7x1_1 = tf.layers.SeparableConv1D(\n              right_output_dim, 7, padding=\"VALID\", name=\"separable_conv_7x1_1\")\n          right_state = separable_conv_7x1_1.apply(right_state)\n          right_state = tf.nn.dropout(right_state,\n                                      1 - hparams.layer_prepostprocess_dropout)\n          right_state = tf.pad(\n              right_state,\n              [[0, 0], [0, 0], [0, left_output_dim - right_output_dim]],\n              constant_values=0)\n\n          hidden_state = left_state + right_state\n\n          hidden_state = common_layers.layer_preprocess(hidden_state, hparams)\n          if nonpadding is not None:\n            # Mask padding from conv layers.\n            mask = tf.tile(\n                tf.expand_dims(nonpadding, 2), [1, 1, hparams.hidden_size * 2])\n            hidden_state *= mask\n\n          if layer_cache:\n            if decode_loop_step is None:\n              hidden_state = layer_cache[\n                  _CONV_BRANCHES_SECOND_LAYER_NAME] = tf.concat(\n                      [\n                          layer_cache[_CONV_BRANCHES_SECOND_LAYER_NAME],\n                          hidden_state\n                      ],\n                      axis=1)[:, -1 * _DECODER_FINAL_CONV_PADDING - 1:, :]\n\n            else:\n              # Inplace update is required for inference on TPU.\n              # Inplace_ops only supports inplace_update on the first dimension.\n              tmp = tf.transpose(\n                  layer_cache[_CONV_BRANCHES_SECOND_LAYER_NAME], perm=[1, 0, 2])\n              tmp = tf.expand_dims(tmp, axis=1)\n              tmp = inplace_ops.alias_inplace_update(\n                  tmp, (decode_loop_step + _DECODER_FINAL_CONV_PADDING) *\n                  tf.shape(hidden_state)[1],\n                  tf.transpose(hidden_state, perm=[1, 0, 2]))\n              tmp = tf.squeeze(tmp, axis=1)\n              hidden_state = layer_cache[\n                  _CONV_BRANCHES_SECOND_LAYER_NAME] = tf.transpose(\n                      tmp, perm=[1, 0, 2])\n\n              hidden_state_indexes = [\n                  decode_loop_step + i\n                  for i in range(_DECODER_FINAL_CONV_PADDING + 1)\n              ]\n              hidden_state = tf.gather(\n                  hidden_state, hidden_state_indexes, axis=1)\n          else:\n            hidden_state = tf.pad(\n                hidden_state,\n                paddings=[[0, 0], [_DECODER_FINAL_CONV_PADDING, 0], [0, 0]])\n\n          separable_conv_7x1_2 = tf.layers.SeparableConv1D(\n              hparams.hidden_size,\n              7,\n              padding=\"VALID\",\n              name=\"separable_conv_7x1_2\")\n          hidden_state = separable_conv_7x1_2.apply(hidden_state)\n\n          hidden_state = common_layers.layer_postprocess(\n              residual_state, hidden_state, hparams)\n\n        with tf.variable_scope(_VANILLA_ATTENTION_NAME):\n          residual_state = hidden_state\n          hidden_state = common_layers.layer_preprocess(hidden_state, hparams)\n\n          attention_cache = layer_cache[\n              _VANILLA_ATTENTION_NAME] if layer_cache is not None else None\n          hidden_state = common_attention.multihead_attention(\n              hidden_state,\n              None,\n              decoder_self_attention_bias,\n              hparams.attention_key_channels or hparams.hidden_size,\n              hparams.attention_value_channels or hparams.hidden_size,\n              hparams.hidden_size,\n              hparams.num_heads,\n              hparams.attention_dropout,\n              attention_type=hparams.self_attention_type,\n              max_relative_position=hparams.max_relative_position,\n              heads_share_relative_embedding=(\n                  hparams.heads_share_relative_embedding),\n              add_relative_to_values=hparams.add_relative_to_values,\n              save_weights_to=save_weights_to,\n              cache=attention_cache,\n              make_image_summary=make_image_summary,\n              dropout_broadcast_dims=attention_dropout_broadcast_dims,\n              max_length=hparams.get(\"max_length\"),\n              decode_loop_step=decode_loop_step,\n              vars_3d=hparams.get(\"attention_variables_3d\"),\n              activation_dtype=hparams.get(\"activation_dtype\", \"float32\"),\n              weight_dtype=hparams.get(\"weight_dtype\", \"float32\"))\n          hidden_state = common_layers.layer_postprocess(\n              residual_state, hidden_state, hparams)\n\n        if encoder_output is not None:\n          with tf.variable_scope(_SECOND_ATTEND_TO_ENCODER_NAME):\n            residual_state = hidden_state\n            hidden_state = common_layers.layer_preprocess(hidden_state, hparams)\n\n            attention_cache = (\n                layer_cache[_SECOND_ATTEND_TO_ENCODER_NAME]\n                if layer_cache is not None else None)\n            hidden_state = common_attention.multihead_attention(\n                hidden_state,\n                encoder_output,\n                encoder_decoder_attention_bias,\n                hparams.attention_key_channels or hparams.hidden_size,\n                hparams.attention_value_channels or hparams.hidden_size,\n                hparams.hidden_size,\n                hparams.num_heads,\n                hparams.attention_dropout,\n                max_relative_position=hparams.max_relative_position,\n                heads_share_relative_embedding=(\n                    hparams.heads_share_relative_embedding),\n                add_relative_to_values=hparams.add_relative_to_values,\n                save_weights_to=save_weights_to,\n                cache=attention_cache,\n                make_image_summary=make_image_summary,\n                dropout_broadcast_dims=attention_dropout_broadcast_dims,\n                max_length=hparams.get(\"max_length\"),\n                vars_3d=hparams.get(\"attention_variables_3d\"),\n                activation_dtype=hparams.get(\"activation_dtype\", \"float32\"),\n                weight_dtype=hparams.get(\"weight_dtype\", \"float32\"))\n            hidden_state = common_layers.layer_postprocess(\n                residual_state, hidden_state, hparams)\n\n        with tf.variable_scope(\"dense_layers\"):\n          residual_state = hidden_state\n          hidden_state = common_layers.layer_preprocess(hidden_state, hparams)\n\n          hidden_state = tf.layers.dense(\n              hidden_state,\n              int(hparams.hidden_size * 4),\n              activation=tf.nn.swish)\n          hidden_state = tf.nn.dropout(hidden_state,\n                                       1 - hparams.layer_prepostprocess_dropout)\n\n          hidden_state = common_layers.layer_preprocess(hidden_state, hparams)\n\n          hidden_state = tf.layers.dense(hidden_state, hparams.hidden_size)\n          hidden_state = common_layers.layer_postprocess(\n              residual_state, hidden_state, hparams)\n\n    return common_layers.layer_preprocess(hidden_state, hparams)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds attend - to - encoder layers to cache.", "response": "def _add_attend_to_encoder_cache(cache, attention_name, hparams, num_layers,\n                                 key_channels, value_channels,\n                                 vars_3d_num_heads, scope_prefix,\n                                 encoder_output):\n  \"\"\"Add attend-to-encoder layers to cache.\"\"\"\n  for layer in range(num_layers):\n    layer_name = \"layer_%d\" % layer\n    with tf.variable_scope(\"%sdecoder/%s/%s/multihead_attention\" %\n                           (scope_prefix, layer_name, attention_name)):\n      k_encdec = common_attention.compute_attention_component(\n          encoder_output,\n          key_channels,\n          name=\"k\",\n          vars_3d_num_heads=vars_3d_num_heads)\n      k_encdec = common_attention.split_heads(k_encdec, hparams.num_heads)\n      v_encdec = common_attention.compute_attention_component(\n          encoder_output,\n          value_channels,\n          name=\"v\",\n          vars_3d_num_heads=vars_3d_num_heads)\n      v_encdec = common_attention.split_heads(v_encdec, hparams.num_heads)\n    cache[layer_name][attention_name] = {\n        \"k_encdec\": k_encdec,\n        \"v_encdec\": v_encdec\n    }\n  return cache"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating the initial cache for Evolved Transformer fast decoding.", "response": "def _init_evolved_transformer_cache(cache, hparams, batch_size,\n                                    attention_init_length, encoder_output,\n                                    encoder_decoder_attention_bias,\n                                    scope_prefix):\n  \"\"\"Create the initial cache for Evolved Transformer fast decoding.\"\"\"\n  key_channels = hparams.attention_key_channels or hparams.hidden_size\n  value_channels = hparams.attention_value_channels or hparams.hidden_size\n  num_layers = hparams.num_decoder_layers or hparams.num_hidden_layers\n  vars_3d_num_heads = (\n      hparams.num_heads if hparams.get(\"attention_variables_3d\") else 0)\n\n  # Add self-attentions.\n  if cache is None:\n    cache = {}\n  cache.update({\n      \"layer_%d\" % layer: {  # pylint: disable=g-complex-comprehension\n          _SIXTEEN_HEAD_ATTENTION_NAME: {\n              \"k\":\n                  common_attention.split_heads(\n                      tf.zeros(\n                          [batch_size, attention_init_length, key_channels]),\n                      _capped_double_heads(hparams.num_heads)),\n              \"v\":\n                  common_attention.split_heads(\n                      tf.zeros(\n                          [batch_size, attention_init_length, value_channels]),\n                      _capped_double_heads(hparams.num_heads)),\n          },\n          _VANILLA_ATTENTION_NAME: {\n              \"k\":\n                  common_attention.split_heads(\n                      tf.zeros(\n                          [batch_size, attention_init_length, key_channels]),\n                      hparams.num_heads),\n              \"v\":\n                  common_attention.split_heads(\n                      tf.zeros(\n                          [batch_size, attention_init_length, value_channels]),\n                      hparams.num_heads),\n          }\n      } for layer in range(num_layers)\n  })\n\n  # Add branched layers. Pad with additional zeros for causal convolution.\n  for layer in range(num_layers):\n    cache[\"layer_%d\" % layer][_CONV_BRANCHES_FIRST_LAYER_NAME] = tf.zeros([\n        batch_size, attention_init_length + _DECODER_LEFT_CONV_PADDING,\n        hparams.hidden_size\n    ])\n    cache[\"layer_%d\" % layer][_CONV_BRANCHES_SECOND_LAYER_NAME] = tf.zeros([\n        batch_size, attention_init_length + _DECODER_FINAL_CONV_PADDING,\n        hparams.hidden_size * 2\n    ])\n\n  # Add encoder embedding attentions.\n  if encoder_output is not None:\n    cache = _add_attend_to_encoder_cache(\n        cache=cache,\n        attention_name=_FIRST_ATTEND_TO_ENCODER_NAME,\n        hparams=hparams,\n        num_layers=num_layers,\n        key_channels=key_channels,\n        value_channels=value_channels,\n        vars_3d_num_heads=vars_3d_num_heads,\n        scope_prefix=scope_prefix,\n        encoder_output=encoder_output)\n    cache = _add_attend_to_encoder_cache(\n        cache=cache,\n        attention_name=_SECOND_ATTEND_TO_ENCODER_NAME,\n        hparams=hparams,\n        num_layers=num_layers,\n        key_channels=key_channels,\n        value_channels=value_channels,\n        vars_3d_num_heads=vars_3d_num_heads,\n        scope_prefix=scope_prefix,\n        encoder_output=encoder_output)\n\n    cache[\"encoder_output\"] = encoder_output\n    cache[\"encoder_decoder_attention_bias\"] = encoder_decoder_attention_bias\n\n  return cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_evolved_transformer_hparams(hparams):\n  # Evolved Transformer \"layers\" are twice as deep as Transformer, so roughly\n  # halve the number that we use. These numbers are taken from\n  # arxiv.org/abs/1901.11117 .\n  hparams.num_encoder_layers = 3\n  hparams.num_decoder_layers = 4\n\n  # Learning rate and decay scheme that mimics the transformer Adam config,\n  # but with cosine decay instead of rsqrt.\n  hparams.learning_rate_constant /= hparams.learning_rate_warmup_steps ** 0.5\n  hparams.learning_rate_schedule = (\n      \"constant*linear_warmup*single_cycle_cos_decay*rsqrt_hidden_size\")\n  # The current infrastructure does not support exposing\n  # `train_steps` to the decay functions, and so we are hard coding the decay\n  # steps here to match the default number of train steps used in `t2t_trainer`.\n  # TODO(davidso): Thread `train_steps` through to decay functions so we do not\n  # have to worry about a `learning_rate_decay_steps` mismatch.\n  hparams.learning_rate_decay_steps = 250000\n  return hparams", "response": "Add Evolved Transformer hparams."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbase parameters for Evolved Transformer model on TPU.", "response": "def evolved_transformer_base_tpu():\n  \"\"\"Base parameters for Evolved Transformer model on TPU.\"\"\"\n  hparams = add_evolved_transformer_hparams(transformer.transformer_tpu())\n  hparams.learning_rate_constant = 1 / hparams.learning_rate_warmup_steps ** 0.5\n  hparams.learning_rate_schedule = (\n      \"constant*single_cycle_cos_decay\")\n  return hparams"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef evolved_transformer_big_tpu():\n  hparams = add_evolved_transformer_hparams(transformer.transformer_big_tpu())\n  hparams.learning_rate_constant = 1 / hparams.learning_rate_warmup_steps ** 0.5\n  hparams.learning_rate_schedule = (\n      \"constant*single_cycle_cos_decay\")\n  return hparams", "response": "Big parameters for Evolved Transformer model on TPU."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transformer_moe_layer_v2(inputs, output_dim, hparams, train,\n                             master_dtype=tf.bfloat16, slice_dtype=tf.float32):\n  \"\"\"2-level mixture of experts.\n\n  Adapted from the paper https://arxiv.org/abs/1701.06538\n\n  Note: until the algorithm and inferface solidify, we pass in a hyperparameters\n  dictionary in order not to complicate the interface in mtf_transformer.py .\n  Once this code moves out of \"research\", we should pass the hyperparameters\n  separately.\n\n  Hyperparameters used:\n    hparams.moe_num_experts: number of experts\n    hparams.moe_hidden_size: size of hidden layer in each expert\n    hparams.moe_group_size: size of each \"group\" for gating purposes\n    hparams.moe_capacity_factor_train: a float\n    hparams.moe_capacity_factor_eval: a float\n    hparams.moe_capacity_factor_second_level: a float\n    hparams.moe_gating: a string\n    + all hyperparmeters used by _top_2_gating()\n\n  One set of params for experts in first level and different of hparams\n  per expert in the second level.\n  The number of parameters in the gating network is:\n    (input_dim.size * (hparams.num_experts) +\n      (moe_hidden_size * hparams.num_experts) * hparams.num_experts\n\n\n  The number of parameters in the experts themselves is:\n    (hparams.num_experts\n     * (input_dim.size + output_dim.size)\n     * hparams.moe_hidden_size)\n\n  The input is n-dimensional: [<batch_and_length_dims>, input_dim], consisting\n  of the representations of all positions in a batch of sequences.\n\n  Each position of each sequence is sent to 0-3 experts.  The expert\n  choices and the combination weights are determined by a learned gating\n  function.\n\n  This function returns a small auxiliary loss that should be added to the\n  training loss of the model.  This loss helps to balance expert usage.\n  Without the loss, it is very likely that a few experts will be trained and\n  the rest will starve.\n\n  Several hacks are necessary to get around current TPU limitations:\n\n  - To ensure static shapes, we enforce (by truncation/padding)\n    that each sequence send the same number of elements to each expert.\n\n    It would make more sense to enforce this equality over the entire batch,\n    but due to our hacked-up gather-by-matmul implementation, we need to divide\n    the batch into \"groups\".  For each group, the same number of elements\n    are sent to each expert.\n\n  TODO(noam): Factor this code better.  We want to be able to substitute\n  different code for the experts themselves.\n\n  Dimensions cheat sheet:\n  a, b: batch size\n  l: original sequence length\n  m: input depth\n  n: output depth\n  g, h: number of groups\n  s, t: group size\n  x, y: number of experts\n  c, d: expert capacity\n\n  input: [a0, b1, l, m]\n  input: [a0, g1, s, m]\n  dispatch_tensor_x: [a0, g1, s, x, c]\n  expert_input: [a0, g1, x, c, m]\n  alltoall: [a0, g, x1, c, m]\n  alltoall: [a0, g, x1, c, m]\n  transpose: [x1, a0, g, c, m]\n  reshape: [x1, h0, s, m]\n  assignment2: [x1, h0, t, y, d]\n  expert_input2: [x1, h0, y, d, m]\n  alltoall: [x1, h, y0, d, m]\n  ...\n  reverse of that\n\n  gating params 0: [m, x]\n  gating params 1: [x1, m, y]\n\n  expert params:\n     [x1, y0, m, hidden]\n     [x1, y0, hidden, n]\n\n  Args:\n    inputs: a mtf.Tensor with shape [a, b, l, m]\n    output_dim: a mtf.Dimension (for Transformer, this is input_dim)\n    hparams: model hyperparameters\n    train: a boolean\n    master_dtype: a tf.dtype\n    slice_dtype: a tf.dtype\n\n  Returns:\n    outputs: a Tensor with shape [a, b, l, n]\n    loss: a mtf scalar\n\n  Raises:\n    ValueError: on unrecognized hparams.moe_gating\n  \"\"\"\n  insert_outer_batch_dim = (len(inputs.shape.dims) == 3)\n  if insert_outer_batch_dim:\n    inputs = mtf.reshape(\n        inputs, [mtf.Dimension(\"outer_batch\", 1)] + inputs.shape.dims)\n\n  assert len(hparams.moe_num_experts) == 2\n  a0, b1, l, m = inputs.shape.dims\n  hidden_dim = mtf.Dimension(\"expert_hidden\", hparams.moe_hidden_size)\n  x1 = mtf.Dimension(\"expert_x\", hparams.moe_num_experts[0])\n  y0 = mtf.Dimension(\"expert_y\", hparams.moe_num_experts[1])\n  x = mtf.Dimension(\"expert_x_unsplit\", hparams.moe_num_experts[0])\n  y = mtf.Dimension(\"expert_y_unsplit\", hparams.moe_num_experts[1])\n  n = output_dim\n\n  # We \"cheat\" here and look at the mesh shape and layout. This is to ensure\n  # that the number of groups (g.size) is a multiple of the mesh dimension\n  # over which those groups are split.\n  num_groups, group_size = _split_into_groups(\n      b1.size * l.size, hparams.moe_group_size,\n      mtf.tensor_dim_to_mesh_dim_size(hparams.layout, hparams.mesh_shape, b1))\n  g1 = mtf.Dimension(b1.name, num_groups)\n  g = mtf.Dimension(b1.name + \"_unsplit\", g1.size)\n  s = mtf.Dimension(\"group_size_x\", group_size)\n\n  # Each sequence sends (at most?) expert_capacity positions to each expert.\n  # Static expert_capacity dimension is needed for expert batch sizes\n  capacity_factor = (\n      hparams.moe_capacity_factor_train if train else\n      hparams.moe_capacity_factor_eval)\n  expert_capacity = min(s.size, int((s.size * capacity_factor) / x.size))\n  expert_capacity = max(expert_capacity, 4)\n  c = mtf.Dimension(\"expert_capacity_x\", expert_capacity)\n\n  # We \"cheat\" here and look at the mesh shape and layout. This is to ensure\n  # that the number of groups (h.size) is a multiple of the mesh dimension\n  # over which those groups are split.\n  num_groups, group_size = _split_into_groups(\n      a0.size * g.size * c.size,\n      hparams.moe_group_size,\n      mtf.tensor_dim_to_mesh_dim_size(hparams.layout, hparams.mesh_shape, a0))\n  t = mtf.Dimension(\"group_size_y\", group_size)\n  h0 = mtf.Dimension(a0.name, num_groups)\n  h = mtf.Dimension(a0.name + \"_unsplit\", h0.size)\n\n  expert_capacity = min(\n      t.size,\n      int((t.size * hparams.moe_capacity_factor_second_level) / y.size))\n  expert_capacity = max(expert_capacity, 4)\n  d = mtf.Dimension(\"expert_capacity_y\", expert_capacity)\n\n  # First level of expert routing\n  # Reshape the inner batch size to a multiple of group_dim g1 and\n  # group_size_dim s.\n  inputs = mtf.reshape(inputs, [a0, g1, s, m])\n\n  # Get the assignments for the first level.\n  # dispatch_tensor_x has shape [a0, g1, s, x, c]\n  if hparams.moe_gating == \"top_2\":\n    dispatch_tensor_x, combine_tensor_x, loss_outer = _top_2_gating(\n        inputs=inputs,\n        outer_expert_dims=None,\n        experts_dim=x,\n        expert_capacity_dim=c,\n        hparams=hparams,\n        train=train)\n  else:\n    raise ValueError(\"unknown hparams.moe_gating=%s\" % hparams.moe_gating)\n\n  # Now create expert_inputs based on the assignments.\n  # put num_experts dimension first to make split easier in alltoall\n  expert_inputs_x = mtf.einsum([inputs, dispatch_tensor_x], [x, a0, g1, c, m])\n\n  # we construct an \"importance\" Tensor for the inputs to the second-level\n  # gating.  The importance of an input is 1.0 if it represents the\n  # first-choice expert-group and 0.5 if it represents the second-choice expert\n  # group.  This is used by the second-level gating.\n  importance = mtf.reduce_sum(combine_tensor_x, output_shape=[x, a0, g1, c])\n  importance = 0.5 * (\n      mtf.to_float(mtf.greater(importance, 0.5)) +\n      mtf.to_float(mtf.greater(importance, 0.0)))\n\n  # First level, all to all. Here we change the split dimension from g1 to x1.\n  expert_inputs_x = mtf.reshape(expert_inputs_x, mtf.Shape(\n      [x1, a0, g, c, m]))\n  importance = mtf.reshape(importance, [x1, a0, g, c])\n\n  # Second level of expert routing\n  # Reshape the expert_inputs outer batch dim to be a multiple of group_dim h0\n  # and group_size_dim t.\n  inputs_y = mtf.reshape(expert_inputs_x, [x1, h0, t, m])\n  importance = mtf.reshape(importance, [x1, h0, t])\n\n  # Get the assignments for the second level.\n  # dispatch_tensor_y has shape [x1, h0, t, y, d]\n  if hparams.moe_gating == \"top_2\":\n    dispatch_tensor_y, combine_tensor_y, loss_inner = _top_2_gating(\n        inputs=inputs_y,\n        outer_expert_dims=[x1],\n        experts_dim=y,\n        expert_capacity_dim=d,\n        hparams=hparams,\n        train=train,\n        importance=importance)\n  else:\n    raise ValueError(\"unknown hparams.moe_gating=%s\" % hparams.moe_gating)\n\n  # Now create expert_inputs based on the assignments.\n  # put num_experts dimension first to make split easier in alltoall\n  expert_inputs_y = mtf.einsum([inputs_y, dispatch_tensor_y], [y, x1, h0, d, m])\n\n  # Second level, all to all. Here we change the split dimension from h0 to y0.\n  expert_inputs_y = mtf.reshape(expert_inputs_y, mtf.Shape(\n      [y0, x1, h, d, m]))\n\n  hidden_output = mtf.layers.dense(\n      expert_inputs_y, hidden_dim, expert_dims=[y0, x1],\n      activation=mtf.relu, use_bias=False, master_dtype=master_dtype,\n      slice_dtype=slice_dtype, name=\"expert0\")\n  expert_output = mtf.layers.dense(\n      hidden_output, output_dim, expert_dims=[y0, x1],\n      use_bias=False, master_dtype=master_dtype, slice_dtype=slice_dtype,\n      name=\"expert1\")\n\n  # NOW COMBINE EXPERT OUTPUTS (reversing everything we have done)\n  # expert_output has shape [y0, x1, h, d, n]\n\n  # alltoall\n  expert_output = mtf.reshape(expert_output, mtf.Shape(\n      [y, x1, h0, d, n]))\n\n  # combine results from inner level\n  output_y = mtf.einsum([expert_output, combine_tensor_y], [x1, h0, t, n])\n\n  # Reshape the combined tensor from inner level to now contain outer_batch_dim\n  # a0 and group_dim g\n  output = mtf.reshape(output_y, [x1, a0, g, c, n])\n\n  # alltoall from expert_dim x to group_dim g1\n  expert_output_x = mtf.reshape(output, mtf.Shape([x, a0, g1, c, n]))\n\n  # combine results from outer level\n  output_x = mtf.einsum([expert_output_x, combine_tensor_x], [a0, g1, s, n])\n\n  # Reshape the combined tensor to now contain inner_batch_dim\n  # b1 and the original sequence length\n  output = mtf.reshape(output_x, [a0, b1, l, n])\n  if insert_outer_batch_dim:\n    output = mtf.reshape(output, [b1, l, n])\n  return output, (loss_outer + loss_inner) * hparams.moe_loss_coef", "response": "2 - level mixture of experts."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntop 2 gating for mixture - of - experts in TensorFlow.", "response": "def _top_2_gating(\n    inputs, outer_expert_dims, experts_dim, expert_capacity_dim,\n    hparams, train, importance=None):\n  \"\"\"Compute gating for mixture-of-experts in TensorFlow.\n\n  Note: until the algorithm and inferface solidify, we pass in a hyperparameters\n  dictionary in order not to complicate the interface in mtf_transformer.py .\n  Once this code moves out of \"research\", we should pass the hyperparameters\n  separately.\n\n  Hyperparameters used:\n    hparams.moe_use_second_place_loss: a boolean\n    hparams.moe_second_policy_train: a string\n    hparams.moe_second_policy_eval: a string\n    hparams.moe_second_threshold: a float\n\n  The returned forward assignment is a tensor used to map (via einsum) from the\n  inputs to the expert_inputs.  Likewise, the returned combine_tensor is\n  used to map (via einsum) from the expert outputs to the outputs.  Both the\n  forward and backward assignments are mostly zeros.  The shapes of the tensors\n  are as follows.\n\n  inputs: [<batch_dims>, group_size_dim, input_dim]\n  importance: [<batch_dims>, group_size_dim]\n  dispatch_tensor:\n    [<batch_dims>, group_size_dim, experts_dim, expert_capacity_dim]\n  expert_inputs:\n    [<batch_dims>, experts_dim, expert_capacity_dim, input_dim]\n\n  expert_outputs: [<batch_dims>, experts_dim, expert_capacity_dim, output_dim]\n  combine_tensor:\n    [<batch_dims>, group_size_dim, experts_dim, expert_capacity_dim]\n  outputs: [<batch_dims>, group_size_dim, output_dim]\n\n  \"importance\" is an optional tensor with one floating-point value for each\n  input vector.  If the importance of an input is 1.0, then we send it to\n  up to 2 experts.  If 0.0 < importance < 1.0, then we send it to at most\n  one expert.  If importance == 0.0, then we send it to no experts.\n\n  We use \"importance\" at the second-level gating function of a hierarchical\n  mixture of experts.  Inputs to the first-choice expert-group get importance\n  1.0.  Inputs to the second-choice expert group get importance 0.5.\n  Inputs that represent padding get importance 0.0.\n\n  Args:\n    inputs: a mtf.Tensor with shape [<batch_dims>, group_size_dim, input_dim]\n    outer_expert_dims: an optional list of dimensions.  This is for the case\n      where we are at an inner level of a hierarchical MoE.\n    experts_dim: a Dimension (the number of experts)\n    expert_capacity_dim: a Dimension (number of examples per group per expert)\n    hparams: model hyperparameters.\n    train: a boolean\n    importance: an optional tensor with shape [<batch_dims>, group_size_dim]\n\n  Returns:\n    dispatch_tensor: a Tensor with shape\n      [<batch_dims>, group_size_dim, experts_dim, expert_capacity_dim]\n    combine_tensor: a Tensor with shape\n      [<batch_dims>, group_size_dim, experts_dim, expert_capacity_dim]\n    loss: a mtf scalar\n\n  Raises:\n    ValueError: on illegal hyperparameters\n  \"\"\"\n  group_size_dim, unused_input_dim = inputs.shape.dims[-2:]\n\n  raw_gates = mtf.softmax(mtf.layers.dense(\n      inputs, experts_dim, use_bias=False,\n      expert_dims=outer_expert_dims), experts_dim)\n\n  # The internals of this function run in float32.\n  #   bfloat16 seems to reduce quality.\n  raw_gates = mtf.to_float(raw_gates)\n\n  expert_capacity_f = float(expert_capacity_dim.size)\n\n  # FIND TOP 2 EXPERTS PER POSITON\n  # Find the top expert for each position. shape=[batch, group]\n  index_1, gate_1 = mtf.top_1(raw_gates, experts_dim)\n  # [batch, group, experts]\n  mask_1 = mtf.one_hot(index_1, experts_dim, dtype=raw_gates.dtype)\n  density_1_proxy = raw_gates\n  if importance is not None:\n    mask_1 *= mtf.to_float(mtf.equal(importance, 1.0))\n    gate_1 *= mtf.to_float(mtf.equal(importance, 1.0))\n    density_1_proxy *= mtf.to_float(mtf.equal(importance, 1.0))\n  gates_without_top_1 = raw_gates * (1.0 - mask_1)\n  # [batch, group]\n  index_2, gate_2 = mtf.top_1(gates_without_top_1, experts_dim)\n  # [batch, group, experts]\n  mask_2 = mtf.one_hot(index_2, experts_dim, dtype=raw_gates.dtype)\n  if importance is not None:\n    mask_2 *= mtf.to_float(mtf.greater(importance, 0.0))\n\n  denom = gate_1 + gate_2 + 1e-9\n  gate_1 /= denom\n  gate_2 /= denom\n\n  # BALANCING LOSSES\n  # shape = [batch, experts]\n  # We want to equalize the fraction of the batch assigned to each expert\n  density_1 = mtf.reduce_mean(mask_1, reduced_dim=group_size_dim)\n  # Something continuous that is correlated with what we want to equalize.\n  density_1_proxy = mtf.reduce_mean(density_1_proxy, reduced_dim=group_size_dim)\n  density_1 = mtf.Print(\n      density_1, [mtf.reduce_mean(density_1, output_shape=[experts_dim])],\n      \"density_1\", summarize=1000)\n  loss = (mtf.reduce_mean(density_1_proxy * density_1)\n          * float(experts_dim.size * experts_dim.size))\n\n  if hparams.moe_use_second_place_loss:\n    # Also add a loss to encourage all experts to be used equally also as the\n    # second-place expert.  Experimentally, this seems to be a wash.\n    # We want to equalize the fraction of the batch assigned to each expert:\n    density_2 = mtf.reduce_mean(mask_2, reduced_dim=group_size_dim)\n    # As a proxy for density_2, we renormalize the raw gates after the top one\n    # has been removed.\n    normalized = gates_without_top_1 / (\n        mtf.reduce_sum(gates_without_top_1, reduced_dim=experts_dim) + 1e-9)\n    density_2_proxy = mtf.reduce_mean(normalized, reduced_dim=group_size_dim)\n    loss_2 = (mtf.reduce_mean(density_2_proxy * density_2)\n              * float(experts_dim.size * experts_dim.size))\n    loss += loss_2 * 0.5\n\n  # Depending on the policy in the hparams, we may drop out some of the\n  # second-place experts.\n  policy = (\n      hparams.moe_second_policy_train if train else\n      hparams.moe_second_policy_eval)\n  threshold = (\n      hparams.moe_second_threshold_train if train else\n      hparams.moe_second_threshold_eval)\n  if policy == \"all\":\n    # Use second-place experts for all examples.\n    pass\n  elif policy == \"none\":\n    # Never use second-place experts for all examples.\n    mask_2 = mtf.zeros_like(mask_2)\n  elif policy == \"threshold\":\n    # Use second-place experts if gate_2 > threshold.\n    mask_2 *= mtf.to_float(mtf.greater(gate_2, threshold))\n  elif policy == \"random\":\n    # Use second-place experts with probablity min(1.0, gate_2 / threshold).\n    mask_2 *= mtf.to_float(\n        mtf.less(mtf.random_uniform(gate_2.mesh, gate_2.shape),\n                 gate_2 / max(threshold, 1e-9)))\n  else:\n    raise ValueError(\"Unknown policy %s\" % policy)\n  mask_2 = mtf.Print(\n      mask_2, [mtf.reduce_mean(mask_2, output_shape=[experts_dim])],\n      \"density_2\", summarize=1000)\n\n  # COMPUTE ASSIGNMENT TO EXPERTS\n  # [batch, group, experts]\n  # This is the position within the expert's mini-batch for this sequence\n  position_in_expert_1 = mtf.cumsum(\n      mask_1, group_size_dim, exclusive=True) * mask_1\n  # Remove the elements that don't fit. [batch, group, experts]\n  mask_1 *= mtf.to_float(mtf.less(position_in_expert_1, expert_capacity_f))\n  # [batch, experts]\n  # How many examples in this sequence go to this expert\n  mask_1_count = mtf.reduce_sum(mask_1, reduced_dim=group_size_dim)\n  # [batch, group] - mostly ones, but zeros where something didn't fit\n  mask_1_flat = mtf.reduce_sum(mask_1, reduced_dim=experts_dim)\n  # [batch, group]\n  position_in_expert_1 = mtf.reduce_sum(\n      position_in_expert_1, reduced_dim=experts_dim)\n  # Weight assigned to first expert.  [batch, group]\n  gate_1 *= mask_1_flat\n\n  # [batch, group, experts]\n  position_in_expert_2 = (\n      mtf.cumsum(mask_2, group_size_dim, exclusive=True) + mask_1_count)\n  position_in_expert_2 *= mask_2\n  mask_2 *= mtf.to_float(mtf.less(position_in_expert_2, expert_capacity_f))\n  # mask_2_count = mtf.reduce_sum(mask_2, reduced_dim=experts_dim)\n  mask_2_flat = mtf.reduce_sum(mask_2, reduced_dim=experts_dim)\n  gate_2 *= mask_2_flat\n  position_in_expert_2 = mtf.reduce_sum(\n      position_in_expert_2, reduced_dim=experts_dim)\n\n  # [batch, group, experts, expert_capacity]\n  combine_tensor = (\n      gate_1 * mask_1_flat\n      * mtf.one_hot(index_1, experts_dim)\n      * mtf.one_hot(mtf.to_int32(position_in_expert_1), expert_capacity_dim) +\n      gate_2 * mask_2_flat\n      * mtf.one_hot(index_2, experts_dim)\n      * mtf.one_hot(mtf.to_int32(position_in_expert_2), expert_capacity_dim))\n\n  combine_tensor = mtf.cast(combine_tensor, inputs.dtype)\n  loss = mtf.cast(loss, inputs.dtype)\n\n  dispatch_tensor = mtf.cast(\n      mtf.cast(combine_tensor, tf.bool), combine_tensor.dtype)\n\n  return dispatch_tensor, combine_tensor, loss"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_default_moe_hparams(hparams):\n  hparams.moe_num_experts = 16\n  hparams.moe_loss_coef = 1e-2\n  hparams.add_hparam(\"moe_gating\", \"top_2\")\n  # Experts have fixed capacity per batch.  We need some extra capacity\n  # in case gating is not perfectly balanced.\n  # moe_capacity_factor_* should be set to a value >=1.\n  hparams.add_hparam(\"moe_capacity_factor_train\", 1.25)\n  hparams.add_hparam(\"moe_capacity_factor_eval\", 2.0)\n  hparams.add_hparam(\"moe_capacity_factor_second_level\", 1.0)\n  # Each expert has a hidden layer with this size.\n  hparams.add_hparam(\"moe_hidden_size\", 4096)\n  # For gating, divide inputs into groups of this size before gating.\n  # Each group sends the same number of inputs to each expert.\n  # Ideally, the group size would be the whole batch, but this is expensive\n  # due to our use of matrix multiplication for reordering.\n  hparams.add_hparam(\"moe_group_size\", 1024)\n  # For top_2 gating, whether to impose an additional loss in order to make\n  # the experts equally used as the second-place expert.\n  hparams.add_hparam(\"moe_use_second_place_loss\", 0)\n  # In top_2 gating, policy for whether to use a second-place expert.\n  # Legal values are:\n  #    \"all\": always\n  #    \"none\": never\n  #    \"threshold\": if gate value > the given threshold\n  #    \"random\": if gate value > threshold*random_uniform(0,1)\n  hparams.add_hparam(\"moe_second_policy_train\", \"random\")\n  hparams.add_hparam(\"moe_second_policy_eval\", \"random\")\n  hparams.add_hparam(\"moe_second_threshold_train\", 0.2)\n  hparams.add_hparam(\"moe_second_threshold_eval\", 0.2)", "response": "Add default hyperparameters for mixture - of - experts."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _split_into_groups(n, max_group_size, mesh_dim_size):\n  if n % mesh_dim_size != 0:\n    raise ValueError(\n        \"n=%d is not a multiple of mesh_dim_size=%d\" % (n, mesh_dim_size))\n  num_groups = max(1, n // max_group_size)\n  while (num_groups % mesh_dim_size != 0 or n % num_groups != 0):\n    num_groups += 1\n  group_size = n // num_groups\n  tf.logging.info(\n      \"_split_into_groups(n=%d, max_group_size=%d, mesh_dim_size=%d)\"\n      \" = (num_groups=%d group_size=%d)\" %\n      (n, max_group_size, mesh_dim_size, num_groups, group_size))\n  return num_groups, group_size", "response": "Helper function for figuring out how to split a dimensino into groups."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nresetting the batch of environments.", "response": "def reset(self, indices=None):\n    \"\"\"Reset the batch of environments.\n\n    Args:\n      indices: The batch indices of the environments to reset.\n\n    Returns:\n      Batch tensor of the new observations.\n    \"\"\"\n    return tf.cond(\n        tf.cast(tf.reduce_sum(indices + 1), tf.bool),\n        lambda: self._reset_non_empty(indices),\n        lambda: tf.cast(0, self.observ_dtype))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef adafactor_decay_rate_adam(beta2):\n  t = tf.to_float(tf.train.get_or_create_global_step()) + 1.0\n  decay = beta2 * (1.0 - tf.pow(beta2, t - 1.0)) / (1.0 - tf.pow(beta2, t))\n  # decay = tf.cond(tf.equal(t, 1.0), lambda: beta2, lambda: decay)\n  return decay", "response": "Second - moment decay rate like Adam subsuming the correction factor."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef adafactor_optimizer_from_hparams(hparams, lr):\n  if hparams.optimizer_adafactor_decay_type == \"adam\":\n    decay_rate = adafactor_decay_rate_adam(\n        hparams.optimizer_adafactor_beta2)\n  elif hparams.optimizer_adafactor_decay_type == \"pow\":\n    decay_rate = adafactor_decay_rate_pow(\n        hparams.optimizer_adafactor_memory_exponent)\n  else:\n    raise ValueError(\"unknown optimizer_adafactor_decay_type\")\n  if hparams.weight_dtype == \"bfloat16\":\n    parameter_encoding = quantization.EighthPowerEncoding()\n  else:\n    parameter_encoding = None\n  return AdafactorOptimizer(\n      multiply_by_parameter_scale=(\n          hparams.optimizer_adafactor_multiply_by_parameter_scale),\n      learning_rate=lr,\n      decay_rate=decay_rate,\n      beta1=hparams.optimizer_adafactor_beta1,\n      clipping_threshold=hparams.optimizer_adafactor_clipping_threshold,\n      factored=hparams.optimizer_adafactor_factored,\n      simulated_quantize_bits=getattr(\n          hparams, \"simulated_parameter_quantize_bits\", 0),\n      parameter_encoding=parameter_encoding,\n      use_locking=False,\n      name=\"Adafactor\")", "response": "Create an Adafactor optimizer based on hparams."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _nargs_validator(nargs, message):\n  if message is None:\n    message = \"Registered function must take exactly %d arguments\" % nargs\n\n  def f(key, value):\n    del key\n    spec = inspect.getfullargspec(value)\n    if (len(spec.args) != nargs or spec.varargs is not None or\n        spec.varkw is not None):\n      raise ValueError(message)\n\n  return f", "response": "Makes validator for function to ensure it takes nargs args."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_problem_name(name):\n  # Recursively strip tags until we reach a base name.\n  if name.endswith(\"_rev\"):\n    base, was_reversed, was_copy = parse_problem_name(name[:-4])\n    if was_reversed:\n      # duplicate rev\n      raise ValueError(\n          \"Invalid problem name %s: multiple '_rev' instances\" % name)\n    return ProblemSpec(base, True, was_copy)\n  elif name.endswith(\"_copy\"):\n    base, was_reversed, was_copy = parse_problem_name(name[:-5])\n    if was_copy:\n      raise ValueError(\n          \"Invalid problem_name %s: multiple '_copy' instances\" % name)\n    return ProblemSpec(base, was_reversed, True)\n  else:\n    return ProblemSpec(name, False, False)", "response": "Determines if a problem name specifies a copy and or reversal."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_problem_name(base_name, was_reversed=False, was_copy=False):\n  if any(base_name.endswith(suffix) for suffix in (\"_rev\", \"_copy\")):\n    raise ValueError(\"`base_name` cannot end in '_rev' or '_copy'\")\n  name = base_name\n  if was_copy:\n    name = \"%s_copy\" % name\n  if was_reversed:\n    name = \"%s_rev\" % name\n  return name", "response": "Construct a problem name from base and reversed options."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef optimizer(name):\n  warn_msg = (\"Please update `registry.optimizer` callsite \"\n              \"(likely due to a `HParams.optimizer` value)\")\n  if name == \"SGD\":\n    name = \"sgd\"\n    tf.logging.warning(\"'SGD' optimizer now keyed by 'sgd'. %s\" % warn_msg)\n  elif name == \"RMSProp\":\n    name = \"rms_prop\"\n    tf.logging.warning(\n        \"'RMSProp' optimizer now keyed by 'rms_prop'. %s\" % warn_msg)\n  else:\n    snake_name = misc_utils.camelcase_to_snakecase(name)\n    if name != snake_name:\n      tf.logging.warning(\n          \"optimizer names now keyed by snake_case names. %s\" % warn_msg)\n      name = snake_name\n  return Registries.optimizers[name]", "response": "Get pre - registered optimizer keyed by name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef problem(problem_name, **kwargs):\n  spec = parse_problem_name(problem_name)\n  try:\n    return Registries.problems[spec.base_name](\n        was_copy=spec.was_copy, was_reversed=spec.was_reversed)\n  except KeyError:\n    # If name is not found in base problems then try creating an env problem\n    return env_problem(problem_name, **kwargs)", "response": "Returns a problem in base_registry or env_registry."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets and initialize the EnvProblem with the given name and batch size.", "response": "def env_problem(env_problem_name, **kwargs):\n  \"\"\"Get and initialize the `EnvProblem` with the given name and batch size.\n\n  Args:\n    env_problem_name: string name of the registered env problem.\n    **kwargs: forwarded to env problem's initialize method.\n\n  Returns:\n    an initialized EnvProblem with the given batch size.\n  \"\"\"\n\n  ep_cls = Registries.env_problems[env_problem_name]\n  ep = ep_cls()\n  ep.initialize(**kwargs)\n  return ep"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a help string for names_list grouped by prefix.", "response": "def display_list_by_prefix(names_list, starting_spaces=0):\n  \"\"\"Creates a help string for names_list grouped by prefix.\"\"\"\n  cur_prefix, result_lines = None, []\n  space = \" \" * starting_spaces\n  for name in sorted(names_list):\n    split = name.split(\"_\", 1)\n    prefix = split[0]\n    if cur_prefix != prefix:\n      result_lines.append(space + prefix + \":\")\n      cur_prefix = prefix\n    result_lines.append(space + \"  * \" + name)\n  return \"\\n\".join(result_lines)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate help string with contents of registry.", "response": "def help_string():\n  \"\"\"Generate help string with contents of registry.\"\"\"\n  help_str = \"\"\"\nRegistry contents:\n------------------\n\n  Models:\n%s\n\n  HParams:\n%s\n\n  RangedHParams:\n%s\n\n  Problems:\n%s\n\n  Optimizers:\n%s\n\n  Attacks:\n%s\n\n  Attack HParams:\n%s\n\n  Pruning HParams:\n%s\n\n  Pruning Strategies:\n%s\n\n  Env Problems:\n%s\n\"\"\"\n  lists = tuple(\n      display_list_by_prefix(entries, starting_spaces=4) for entries in [  # pylint: disable=g-complex-comprehension\n          list_models(),\n          list_hparams(),\n          list_ranged_hparams(),\n          list_base_problems(),\n          list_optimizers(),\n          list_attacks(),\n          list_attack_params(),\n          list_pruning_params(),\n          list_pruning_strategies(),\n          list_env_problems(),\n      ])\n  return help_str % lists"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates the given key value pair. Uses function from __init__.", "response": "def validate(self, key, value):\n    \"\"\"Validation function run before setting. Uses function from __init__.\"\"\"\n    if self._validator is not None:\n      self._validator(key, value)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef on_set(self, key, value):\n    if self._on_set is not None:\n      self._on_set(key, value)", "response": "Callback called when a key is set. Uses function from __init__."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_dependicies(objdump_string):\n    GLIBC_version = re.compile(r'0{16}[ \\t]+GLIBC_(\\d{1,2})[.](\\d{1,3})[.]?\\d{,3}[ \\t]+')\n    versions = GLIBC_version.findall(objdump_string)\n    assert len(versions) > 1\n    for major, minor in versions:\n        assert int(major) <= 2\n        assert int(minor) <= 14\n\n    GLIBCXX_version = re.compile(r'0{16}[ \\t]+GLIBCXX_(\\d{1,2})[.](\\d{1,2})[.]?(\\d{,3})[ \\t]+')\n    versions = GLIBCXX_version.findall(objdump_string)\n    assert len(versions) > 1\n    for major, minor, patch in versions:\n        assert int(major) == 3\n        assert int(minor) == 4\n        assert patch == '' or int(patch) <= 19\n\n    GOMP_version = re.compile(r'0{16}[ \\t]+G?OMP_(\\d{1,2})[.](\\d{1,2})[.]?\\d{,3}[ \\t]+')\n    versions = GOMP_version.findall(objdump_string)\n    assert len(versions) > 1\n    for major, minor in versions:\n        assert int(major) == 1\n        assert int(minor) == 0", "response": "Check the dynamic symbol table entries of the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndecorates an objective function. Note ---- For multi-class task, the y_pred is group by class_id first, then group by row_id. If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i] and you should group grad and hess in this way as well. Parameters ---------- func : callable Expects a callable with signature ``func(y_true, y_pred)`` or ``func(y_true, y_pred, group): y_true : array-like of shape = [n_samples] The target values. y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task) The predicted values. group : array-like Group/query data, used for ranking task. Returns ------- new_func : callable The new objective function as expected by ``lightgbm.engine.train``. The signature is ``new_func(preds, dataset)``: preds : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task) The predicted values. dataset : Dataset The training set from which the labels will be extracted using ``dataset.get_label()``.", "response": "def _objective_function_wrapper(func):\n    \"\"\"Decorate an objective function.\n\n    Note\n    ----\n    For multi-class task, the y_pred is group by class_id first, then group by row_id.\n    If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i]\n    and you should group grad and hess in this way as well.\n\n    Parameters\n    ----------\n    func : callable\n        Expects a callable with signature ``func(y_true, y_pred)`` or ``func(y_true, y_pred, group):\n\n            y_true : array-like of shape = [n_samples]\n                The target values.\n            y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n                The predicted values.\n            group : array-like\n                Group/query data, used for ranking task.\n\n    Returns\n    -------\n    new_func : callable\n        The new objective function as expected by ``lightgbm.engine.train``.\n        The signature is ``new_func(preds, dataset)``:\n\n            preds : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n                The predicted values.\n            dataset : Dataset\n                The training set from which the labels will be extracted using ``dataset.get_label()``.\n    \"\"\"\n    def inner(preds, dataset):\n        \"\"\"Call passed function with appropriate arguments.\"\"\"\n        labels = dataset.get_label()\n        argc = argc_(func)\n        if argc == 2:\n            grad, hess = func(labels, preds)\n        elif argc == 3:\n            grad, hess = func(labels, preds, dataset.get_group())\n        else:\n            raise TypeError(\"Self-defined objective function should have 2 or 3 arguments, got %d\" % argc)\n        \"\"\"weighted for objective\"\"\"\n        weight = dataset.get_weight()\n        if weight is not None:\n            \"\"\"only one class\"\"\"\n            if len(weight) == len(grad):\n                grad = np.multiply(grad, weight)\n                hess = np.multiply(hess, weight)\n            else:\n                num_data = len(weight)\n                num_class = len(grad) // num_data\n                if num_class * num_data != len(grad):\n                    raise ValueError(\"Length of grad and hess should equal to num_class * num_data\")\n                for k in range_(num_class):\n                    for i in range_(num_data):\n                        idx = k * num_data + i\n                        grad[idx] *= weight[i]\n                        hess[idx] *= weight[i]\n        return grad, hess\n    return inner"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _eval_function_wrapper(func):\n    def inner(preds, dataset):\n        \"\"\"Call passed function with appropriate arguments.\"\"\"\n        labels = dataset.get_label()\n        argc = argc_(func)\n        if argc == 2:\n            return func(labels, preds)\n        elif argc == 3:\n            return func(labels, preds, dataset.get_weight())\n        elif argc == 4:\n            return func(labels, preds, dataset.get_weight(), dataset.get_group())\n        else:\n            raise TypeError(\"Self-defined eval function should have 2, 3 or 4 arguments, got %d\" % argc)\n    return inner", "response": "Decorator for the eval function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_params(self, deep=True):\n        params = super(LGBMModel, self).get_params(deep=deep)\n        params.update(self._other_params)\n        return params", "response": "Returns the parameters for this estimator."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfitting a gradient boosting model from the training set X and y.", "response": "def fit(self, X, y,\n            sample_weight=None, init_score=None, group=None,\n            eval_set=None, eval_names=None, eval_sample_weight=None,\n            eval_class_weight=None, eval_init_score=None, eval_group=None,\n            eval_metric=None, early_stopping_rounds=None, verbose=True,\n            feature_name='auto', categorical_feature='auto', callbacks=None):\n        \"\"\"Build a gradient boosting model from the training set (X, y).\n\n        Parameters\n        ----------\n        X : array-like or sparse matrix of shape = [n_samples, n_features]\n            Input feature matrix.\n        y : array-like of shape = [n_samples]\n            The target values (class labels in classification, real numbers in regression).\n        sample_weight : array-like of shape = [n_samples] or None, optional (default=None)\n            Weights of training data.\n        init_score : array-like of shape = [n_samples] or None, optional (default=None)\n            Init score of training data.\n        group : array-like or None, optional (default=None)\n            Group data of training data.\n        eval_set : list or None, optional (default=None)\n            A list of (X, y) tuple pairs to use as validation sets.\n        eval_names : list of strings or None, optional (default=None)\n            Names of eval_set.\n        eval_sample_weight : list of arrays or None, optional (default=None)\n            Weights of eval data.\n        eval_class_weight : list or None, optional (default=None)\n            Class weights of eval data.\n        eval_init_score : list of arrays or None, optional (default=None)\n            Init score of eval data.\n        eval_group : list of arrays or None, optional (default=None)\n            Group data of eval data.\n        eval_metric : string, list of strings, callable or None, optional (default=None)\n            If string, it should be a built-in evaluation metric to use.\n            If callable, it should be a custom evaluation metric, see note below for more details.\n            In either case, the ``metric`` from the model parameters will be evaluated and used as well.\n            Default: 'l2' for LGBMRegressor, 'logloss' for LGBMClassifier, 'ndcg' for LGBMRanker.\n        early_stopping_rounds : int or None, optional (default=None)\n            Activates early stopping. The model will train until the validation score stops improving.\n            Validation score needs to improve at least every ``early_stopping_rounds`` round(s)\n            to continue training.\n            Requires at least one validation data and one metric.\n            If there's more than one, will check all of them. But the training data is ignored anyway.\n            To check only the first metric you can pass in ``callbacks``\n            ``early_stopping`` callback with ``first_metric_only=True``.\n        verbose : bool or int, optional (default=True)\n            Requires at least one evaluation data.\n            If True, the eval metric on the eval set is printed at each boosting stage.\n            If int, the eval metric on the eval set is printed at every ``verbose`` boosting stage.\n            The last boosting stage or the boosting stage found by using ``early_stopping_rounds`` is also printed.\n\n            Example\n            -------\n            With ``verbose`` = 4 and at least one item in ``eval_set``,\n            an evaluation metric is printed every 4 (instead of 1) boosting stages.\n\n        feature_name : list of strings or 'auto', optional (default='auto')\n            Feature names.\n            If 'auto' and data is pandas DataFrame, data columns names are used.\n        categorical_feature : list of strings or int, or 'auto', optional (default='auto')\n            Categorical features.\n            If list of int, interpreted as indices.\n            If list of strings, interpreted as feature names (need to specify ``feature_name`` as well).\n            If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n            All values in categorical features should be less than int32 max value (2147483647).\n            Large values could be memory consuming. Consider using consecutive integers starting from zero.\n            All negative values in categorical features will be treated as missing values.\n        callbacks : list of callback functions or None, optional (default=None)\n            List of callback functions that are applied at each iteration.\n            See Callbacks in Python API for more information.\n\n        Returns\n        -------\n        self : object\n            Returns self.\n\n        Note\n        ----\n        Custom eval function expects a callable with following signatures:\n        ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n        ``func(y_true, y_pred, weight, group)``\n        and returns (eval_name, eval_result, is_bigger_better) or\n        list of (eval_name, eval_result, is_bigger_better):\n\n            y_true : array-like of shape = [n_samples]\n                The target values.\n            y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n                The predicted values.\n            weight : array-like of shape = [n_samples]\n                The weight of samples.\n            group : array-like\n                Group/query data, used for ranking task.\n            eval_name : string\n                The name of evaluation.\n            eval_result : float\n                The eval result.\n            is_bigger_better : bool\n                Is eval result bigger better, e.g. AUC is bigger_better.\n\n        For multi-class task, the y_pred is group by class_id first, then group by row_id.\n        If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i].\n        \"\"\"\n        if self._objective is None:\n            if isinstance(self, LGBMRegressor):\n                self._objective = \"regression\"\n            elif isinstance(self, LGBMClassifier):\n                self._objective = \"binary\"\n            elif isinstance(self, LGBMRanker):\n                self._objective = \"lambdarank\"\n            else:\n                raise ValueError(\"Unknown LGBMModel type.\")\n        if callable(self._objective):\n            self._fobj = _objective_function_wrapper(self._objective)\n        else:\n            self._fobj = None\n        evals_result = {}\n        params = self.get_params()\n        # user can set verbose with kwargs, it has higher priority\n        if not any(verbose_alias in params for verbose_alias in ('verbose', 'verbosity')) and self.silent:\n            params['verbose'] = -1\n        params.pop('silent', None)\n        params.pop('importance_type', None)\n        params.pop('n_estimators', None)\n        params.pop('class_weight', None)\n        if self._n_classes is not None and self._n_classes > 2:\n            params['num_class'] = self._n_classes\n        if hasattr(self, '_eval_at'):\n            params['eval_at'] = self._eval_at\n        params['objective'] = self._objective\n        if self._fobj:\n            params['objective'] = 'None'  # objective = nullptr for unknown objective\n\n        if callable(eval_metric):\n            feval = _eval_function_wrapper(eval_metric)\n        else:\n            feval = None\n            # register default metric for consistency with callable eval_metric case\n            original_metric = self._objective if isinstance(self._objective, string_type) else None\n            if original_metric is None:\n                # try to deduce from class instance\n                if isinstance(self, LGBMRegressor):\n                    original_metric = \"l2\"\n                elif isinstance(self, LGBMClassifier):\n                    original_metric = \"multi_logloss\" if self._n_classes > 2 else \"binary_logloss\"\n                elif isinstance(self, LGBMRanker):\n                    original_metric = \"ndcg\"\n            # overwrite default metric by explicitly set metric\n            for metric_alias in ['metric', 'metrics', 'metric_types']:\n                if metric_alias in params:\n                    original_metric = params.pop(metric_alias)\n            # concatenate metric from params (or default if not provided in params) and eval_metric\n            original_metric = [original_metric] if isinstance(original_metric, (string_type, type(None))) else original_metric\n            eval_metric = [eval_metric] if isinstance(eval_metric, (string_type, type(None))) else eval_metric\n            params['metric'] = set(original_metric + eval_metric)\n\n        if not isinstance(X, (DataFrame, DataTable)):\n            _X, _y = _LGBMCheckXY(X, y, accept_sparse=True, force_all_finite=False, ensure_min_samples=2)\n            _LGBMCheckConsistentLength(_X, _y, sample_weight)\n        else:\n            _X, _y = X, y\n\n        if self.class_weight is not None:\n            class_sample_weight = _LGBMComputeSampleWeight(self.class_weight, y)\n            if sample_weight is None or len(sample_weight) == 0:\n                sample_weight = class_sample_weight\n            else:\n                sample_weight = np.multiply(sample_weight, class_sample_weight)\n\n        self._n_features = _X.shape[1]\n\n        def _construct_dataset(X, y, sample_weight, init_score, group, params):\n            ret = Dataset(X, label=y, weight=sample_weight, group=group, params=params)\n            return ret.set_init_score(init_score)\n\n        train_set = _construct_dataset(_X, _y, sample_weight, init_score, group, params)\n\n        valid_sets = []\n        if eval_set is not None:\n\n            def _get_meta_data(collection, i):\n                if collection is None:\n                    return None\n                elif isinstance(collection, list):\n                    return collection[i] if len(collection) > i else None\n                elif isinstance(collection, dict):\n                    return collection.get(i, None)\n                else:\n                    raise TypeError('eval_sample_weight, eval_class_weight, eval_init_score, and eval_group '\n                                    'should be dict or list')\n\n            if isinstance(eval_set, tuple):\n                eval_set = [eval_set]\n            for i, valid_data in enumerate(eval_set):\n                # reduce cost for prediction training data\n                if valid_data[0] is X and valid_data[1] is y:\n                    valid_set = train_set\n                else:\n                    valid_weight = _get_meta_data(eval_sample_weight, i)\n                    if _get_meta_data(eval_class_weight, i) is not None:\n                        valid_class_sample_weight = _LGBMComputeSampleWeight(_get_meta_data(eval_class_weight, i),\n                                                                             valid_data[1])\n                        if valid_weight is None or len(valid_weight) == 0:\n                            valid_weight = valid_class_sample_weight\n                        else:\n                            valid_weight = np.multiply(valid_weight, valid_class_sample_weight)\n                    valid_init_score = _get_meta_data(eval_init_score, i)\n                    valid_group = _get_meta_data(eval_group, i)\n                    valid_set = _construct_dataset(valid_data[0], valid_data[1],\n                                                   valid_weight, valid_init_score, valid_group, params)\n                valid_sets.append(valid_set)\n\n        self._Booster = train(params, train_set,\n                              self.n_estimators, valid_sets=valid_sets, valid_names=eval_names,\n                              early_stopping_rounds=early_stopping_rounds,\n                              evals_result=evals_result, fobj=self._fobj, feval=feval,\n                              verbose_eval=verbose, feature_name=feature_name,\n                              categorical_feature=categorical_feature,\n                              callbacks=callbacks)\n\n        if evals_result:\n            self._evals_result = evals_result\n\n        if early_stopping_rounds is not None:\n            self._best_iteration = self._Booster.best_iteration\n\n        self._best_score = self._Booster.best_score\n\n        # free dataset\n        self.booster_.free_dataset()\n        del train_set, valid_sets\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npredicting the predicted value for each sample.", "response": "def predict(self, X, raw_score=False, num_iteration=None,\n                pred_leaf=False, pred_contrib=False, **kwargs):\n        \"\"\"Return the predicted value for each sample.\n\n        Parameters\n        ----------\n        X : array-like or sparse matrix of shape = [n_samples, n_features]\n            Input features matrix.\n        raw_score : bool, optional (default=False)\n            Whether to predict raw scores.\n        num_iteration : int or None, optional (default=None)\n            Limit number of iterations in the prediction.\n            If None, if the best iteration exists, it is used; otherwise, all trees are used.\n            If <= 0, all trees are used (no limits).\n        pred_leaf : bool, optional (default=False)\n            Whether to predict leaf index.\n        pred_contrib : bool, optional (default=False)\n            Whether to predict feature contributions.\n\n            Note\n            ----\n            If you want to get more explanations for your model's predictions using SHAP values,\n            like SHAP interaction values,\n            you can install the shap package (https://github.com/slundberg/shap).\n            Note that unlike the shap package, with ``pred_contrib`` we return a matrix with an extra\n            column, where the last column is the expected value.\n\n        **kwargs\n            Other parameters for the prediction.\n\n        Returns\n        -------\n        predicted_result : array-like of shape = [n_samples] or shape = [n_samples, n_classes]\n            The predicted values.\n        X_leaves : array-like of shape = [n_samples, n_trees] or shape = [n_samples, n_trees * n_classes]\n            If ``pred_leaf=True``, the predicted leaf of every tree for each sample.\n        X_SHAP_values : array-like of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes]\n            If ``pred_contrib=True``, the feature contributions for each sample.\n        \"\"\"\n        if self._n_features is None:\n            raise LGBMNotFittedError(\"Estimator not fitted, call `fit` before exploiting the model.\")\n        if not isinstance(X, (DataFrame, DataTable)):\n            X = _LGBMCheckArray(X, accept_sparse=True, force_all_finite=False)\n        n_features = X.shape[1]\n        if self._n_features != n_features:\n            raise ValueError(\"Number of features of the model must \"\n                             \"match the input. Model n_features_ is %s and \"\n                             \"input n_features is %s \"\n                             % (self._n_features, n_features))\n        return self.booster_.predict(X, raw_score=raw_score, num_iteration=num_iteration,\n                                     pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting feature importances. Note ---- Feature importance in sklearn interface used to normalize to 1, it's deprecated after 2.0.4 and is the same as Booster.feature_importance() now. ``importance_type`` attribute is passed to the function to configure the type of importance values to be extracted.", "response": "def feature_importances_(self):\n        \"\"\"Get feature importances.\n\n        Note\n        ----\n        Feature importance in sklearn interface used to normalize to 1,\n        it's deprecated after 2.0.4 and is the same as Booster.feature_importance() now.\n        ``importance_type`` attribute is passed to the function\n        to configure the type of importance values to be extracted.\n        \"\"\"\n        if self._n_features is None:\n            raise LGBMNotFittedError('No feature_importances found. Need to call fit beforehand.')\n        return self.booster_.feature_importance(importance_type=self.importance_type)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfitting the LGBM model to the given data.", "response": "def fit(self, X, y,\n            sample_weight=None, init_score=None,\n            eval_set=None, eval_names=None, eval_sample_weight=None,\n            eval_class_weight=None, eval_init_score=None, eval_metric=None,\n            early_stopping_rounds=None, verbose=True,\n            feature_name='auto', categorical_feature='auto', callbacks=None):\n        \"\"\"Docstring is inherited from the LGBMModel.\"\"\"\n        _LGBMAssertAllFinite(y)\n        _LGBMCheckClassificationTargets(y)\n        self._le = _LGBMLabelEncoder().fit(y)\n        _y = self._le.transform(y)\n\n        self._classes = self._le.classes_\n        self._n_classes = len(self._classes)\n        if self._n_classes > 2:\n            # Switch to using a multiclass objective in the underlying LGBM instance\n            ova_aliases = (\"multiclassova\", \"multiclass_ova\", \"ova\", \"ovr\")\n            if self._objective not in ova_aliases and not callable(self._objective):\n                self._objective = \"multiclass\"\n            if eval_metric in ('logloss', 'binary_logloss'):\n                eval_metric = \"multi_logloss\"\n            elif eval_metric in ('error', 'binary_error'):\n                eval_metric = \"multi_error\"\n        else:\n            if eval_metric in ('logloss', 'multi_logloss'):\n                eval_metric = 'binary_logloss'\n            elif eval_metric in ('error', 'multi_error'):\n                eval_metric = 'binary_error'\n\n        if eval_set is not None:\n            if isinstance(eval_set, tuple):\n                eval_set = [eval_set]\n            for i, (valid_x, valid_y) in enumerate(eval_set):\n                if valid_x is X and valid_y is y:\n                    eval_set[i] = (valid_x, _y)\n                else:\n                    eval_set[i] = (valid_x, self._le.transform(valid_y))\n\n        super(LGBMClassifier, self).fit(X, _y, sample_weight=sample_weight,\n                                        init_score=init_score, eval_set=eval_set,\n                                        eval_names=eval_names,\n                                        eval_sample_weight=eval_sample_weight,\n                                        eval_class_weight=eval_class_weight,\n                                        eval_init_score=eval_init_score,\n                                        eval_metric=eval_metric,\n                                        early_stopping_rounds=early_stopping_rounds,\n                                        verbose=verbose, feature_name=feature_name,\n                                        categorical_feature=categorical_feature,\n                                        callbacks=callbacks)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef predict(self, X, raw_score=False, num_iteration=None,\n                pred_leaf=False, pred_contrib=False, **kwargs):\n        \"\"\"Docstring is inherited from the LGBMModel.\"\"\"\n        result = self.predict_proba(X, raw_score, num_iteration,\n                                    pred_leaf, pred_contrib, **kwargs)\n        if raw_score or pred_leaf or pred_contrib:\n            return result\n        else:\n            class_index = np.argmax(result, axis=1)\n            return self._le.inverse_transform(class_index)", "response": "Predict the class of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef predict_proba(self, X, raw_score=False, num_iteration=None,\n                      pred_leaf=False, pred_contrib=False, **kwargs):\n        \"\"\"Return the predicted probability for each class for each sample.\n\n        Parameters\n        ----------\n        X : array-like or sparse matrix of shape = [n_samples, n_features]\n            Input features matrix.\n        raw_score : bool, optional (default=False)\n            Whether to predict raw scores.\n        num_iteration : int or None, optional (default=None)\n            Limit number of iterations in the prediction.\n            If None, if the best iteration exists, it is used; otherwise, all trees are used.\n            If <= 0, all trees are used (no limits).\n        pred_leaf : bool, optional (default=False)\n            Whether to predict leaf index.\n        pred_contrib : bool, optional (default=False)\n            Whether to predict feature contributions.\n\n            Note\n            ----\n            If you want to get more explanations for your model's predictions using SHAP values,\n            like SHAP interaction values,\n            you can install the shap package (https://github.com/slundberg/shap).\n            Note that unlike the shap package, with ``pred_contrib`` we return a matrix with an extra\n            column, where the last column is the expected value.\n\n        **kwargs\n            Other parameters for the prediction.\n\n        Returns\n        -------\n        predicted_probability : array-like of shape = [n_samples, n_classes]\n            The predicted probability for each class for each sample.\n        X_leaves : array-like of shape = [n_samples, n_trees * n_classes]\n            If ``pred_leaf=True``, the predicted leaf of every tree for each sample.\n        X_SHAP_values : array-like of shape = [n_samples, (n_features + 1) * n_classes]\n            If ``pred_contrib=True``, the feature contributions for each sample.\n        \"\"\"\n        result = super(LGBMClassifier, self).predict(X, raw_score, num_iteration,\n                                                     pred_leaf, pred_contrib, **kwargs)\n        if self._n_classes > 2 or raw_score or pred_leaf or pred_contrib:\n            return result\n        else:\n            return np.vstack((1. - result, result)).transpose()", "response": "Predict the probability for each class for each sample."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fit(self, X, y,\n            sample_weight=None, init_score=None, group=None,\n            eval_set=None, eval_names=None, eval_sample_weight=None,\n            eval_init_score=None, eval_group=None, eval_metric=None,\n            eval_at=[1], early_stopping_rounds=None, verbose=True,\n            feature_name='auto', categorical_feature='auto', callbacks=None):\n        \"\"\"Docstring is inherited from the LGBMModel.\"\"\"\n        # check group data\n        if group is None:\n            raise ValueError(\"Should set group for ranking task\")\n\n        if eval_set is not None:\n            if eval_group is None:\n                raise ValueError(\"Eval_group cannot be None when eval_set is not None\")\n            elif len(eval_group) != len(eval_set):\n                raise ValueError(\"Length of eval_group should be equal to eval_set\")\n            elif (isinstance(eval_group, dict)\n                  and any(i not in eval_group or eval_group[i] is None for i in range_(len(eval_group)))\n                  or isinstance(eval_group, list)\n                  and any(group is None for group in eval_group)):\n                raise ValueError(\"Should set group for all eval datasets for ranking task; \"\n                                 \"if you use dict, the index should start from 0\")\n\n        self._eval_at = eval_at\n        super(LGBMRanker, self).fit(X, y, sample_weight=sample_weight,\n                                    init_score=init_score, group=group,\n                                    eval_set=eval_set, eval_names=eval_names,\n                                    eval_sample_weight=eval_sample_weight,\n                                    eval_init_score=eval_init_score, eval_group=eval_group,\n                                    eval_metric=eval_metric,\n                                    early_stopping_rounds=early_stopping_rounds,\n                                    verbose=verbose, feature_name=feature_name,\n                                    categorical_feature=categorical_feature,\n                                    callbacks=callbacks)\n        return self", "response": "Fit the LGBM model to the data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the config header file and return a tuple with names and content of sections.", "response": "def get_parameter_infos(config_hpp):\n    \"\"\"Parse config header file.\n\n    Parameters\n    ----------\n    config_hpp : string\n        Path to the config header file.\n\n    Returns\n    -------\n    infos : tuple\n        Tuple with names and content of sections.\n    \"\"\"\n    is_inparameter = False\n    parameter_group = None\n    cur_key = None\n    cur_info = {}\n    keys = []\n    member_infos = []\n    with open(config_hpp) as config_hpp_file:\n        for line in config_hpp_file:\n            if \"#pragma region Parameters\" in line:\n                is_inparameter = True\n            elif \"#pragma region\" in line and \"Parameters\" in line:\n                cur_key = line.split(\"region\")[1].strip()\n                keys.append(cur_key)\n                member_infos.append([])\n            elif '#pragma endregion' in line:\n                if cur_key is not None:\n                    cur_key = None\n                elif is_inparameter:\n                    is_inparameter = False\n            elif cur_key is not None:\n                line = line.strip()\n                if line.startswith(\"//\"):\n                    key, _, val = line[2:].partition(\"=\")\n                    key = key.strip()\n                    val = val.strip()\n                    if key not in cur_info:\n                        if key == \"descl2\" and \"desc\" not in cur_info:\n                            cur_info[\"desc\"] = []\n                        elif key != \"descl2\":\n                            cur_info[key] = []\n                    if key == \"desc\":\n                        cur_info[\"desc\"].append((\"l1\", val))\n                    elif key == \"descl2\":\n                        cur_info[\"desc\"].append((\"l2\", val))\n                    else:\n                        cur_info[key].append(val)\n                elif line:\n                    has_eqsgn = False\n                    tokens = line.split(\"=\")\n                    if len(tokens) == 2:\n                        if \"default\" not in cur_info:\n                            cur_info[\"default\"] = [tokens[1][:-1].strip()]\n                        has_eqsgn = True\n                    tokens = line.split()\n                    cur_info[\"inner_type\"] = [tokens[0].strip()]\n                    if \"name\" not in cur_info:\n                        if has_eqsgn:\n                            cur_info[\"name\"] = [tokens[1].strip()]\n                        else:\n                            cur_info[\"name\"] = [tokens[1][:-1].strip()]\n                    member_infos[-1].append(cur_info)\n                    cur_info = {}\n    return keys, member_infos"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget names of all parameters.", "response": "def get_names(infos):\n    \"\"\"Get names of all parameters.\n\n    Parameters\n    ----------\n    infos : list\n        Content of the config header file.\n\n    Returns\n    -------\n    names : list\n        Names of all parameters.\n    \"\"\"\n    names = []\n    for x in infos:\n        for y in x:\n            names.append(y[\"name\"][0])\n    return names"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_alias(infos):\n    pairs = []\n    for x in infos:\n        for y in x:\n            if \"alias\" in y:\n                name = y[\"name\"][0]\n                alias = y[\"alias\"][0].split(',')\n                for name2 in alias:\n                    pairs.append((name2.strip(), name))\n    return pairs", "response": "Get aliases of all parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_one_var_from_string(name, param_type, checks):\n    ret = \"\"\n    univar_mapper = {\"int\": \"GetInt\", \"double\": \"GetDouble\", \"bool\": \"GetBool\", \"std::string\": \"GetString\"}\n    if \"vector\" not in param_type:\n        ret += \"  %s(params, \\\"%s\\\", &%s);\\n\" % (univar_mapper[param_type], name, name)\n        if len(checks) > 0:\n            for check in checks:\n                ret += \"  CHECK(%s %s);\\n\" % (name, check)\n        ret += \"\\n\"\n    else:\n        ret += \"  if (GetString(params, \\\"%s\\\", &tmp_str)) {\\n\" % (name)\n        type2 = param_type.split(\"<\")[1][:-1]\n        if type2 == \"std::string\":\n            ret += \"    %s = Common::Split(tmp_str.c_str(), ',');\\n\" % (name)\n        else:\n            ret += \"    %s = Common::StringToArray<%s>(tmp_str, ',');\\n\" % (name, type2)\n        ret += \"  }\\n\\n\"\n    return ret", "response": "Construct code for auto config file for one parameter value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a description of the parameters in the specified sections and descriptions.", "response": "def gen_parameter_description(sections, descriptions, params_rst):\n    \"\"\"Write descriptions of parameters to the documentation file.\n\n    Parameters\n    ----------\n    sections : list\n        Names of parameters sections.\n    descriptions : list\n        Structured descriptions of parameters.\n    params_rst : string\n        Path to the file with parameters documentation.\n    \"\"\"\n    def parse_check(check, reverse=False):\n        \"\"\"Parse the constraint.\n\n        Parameters\n        ----------\n        check : string\n            String representation of the constraint.\n        reverse : bool, optional (default=False)\n            Whether to reverse the sign of the constraint.\n\n        Returns\n        -------\n        pair : tuple\n            Parsed constraint in the form of tuple (value, sign).\n        \"\"\"\n        try:\n            idx = 1\n            float(check[idx:])\n        except ValueError:\n            idx = 2\n            float(check[idx:])\n        if reverse:\n            reversed_sign = {'<': '>', '>': '<', '<=': '>=', '>=': '<='}\n            return check[idx:], reversed_sign[check[:idx]]\n        else:\n            return check[idx:], check[:idx]\n\n    params_to_write = []\n    for section_name, section_params in zip(sections, descriptions):\n        params_to_write.append('{0}\\n{1}'.format(section_name, '-' * len(section_name)))\n        for param_desc in section_params:\n            name = param_desc['name'][0]\n            default_raw = param_desc['default'][0]\n            default = default_raw.strip('\"') if len(default_raw.strip('\"')) > 0 else default_raw\n            param_type = param_desc.get('type', param_desc['inner_type'])[0].split(':')[-1].split('<')[-1].strip('>')\n            options = param_desc.get('options', [])\n            if len(options) > 0:\n                options_str = ', options: ``{0}``'.format('``, ``'.join([x.strip() for x in options[0].split(',')]))\n            else:\n                options_str = ''\n            aliases = param_desc.get('alias', [])\n            if len(aliases) > 0:\n                aliases_str = ', aliases: ``{0}``'.format('``, ``'.join([x.strip() for x in aliases[0].split(',')]))\n            else:\n                aliases_str = ''\n            checks = sorted(param_desc.get('check', []))\n            checks_len = len(checks)\n            if checks_len > 1:\n                number1, sign1 = parse_check(checks[0])\n                number2, sign2 = parse_check(checks[1], reverse=True)\n                checks_str = ', constraints: ``{0} {1} {2} {3} {4}``'.format(number2, sign2, name, sign1, number1)\n            elif checks_len == 1:\n                number, sign = parse_check(checks[0])\n                checks_str = ', constraints: ``{0} {1} {2}``'.format(name, sign, number)\n            else:\n                checks_str = ''\n            main_desc = '-  ``{0}`` :raw-html:`<a id=\"{0}\" title=\"Permalink to this parameter\" href=\"#{0}\">&#x1F517;&#xFE0E;</a>`, default = ``{1}``, type = {2}{3}{4}{5}'.format(name, default, param_type, options_str, aliases_str, checks_str)\n            params_to_write.append(main_desc)\n            params_to_write.extend([' ' * 3 * int(desc[0][-1]) + '-  ' + desc[1] for desc in param_desc['desc']])\n\n    with open(params_rst) as original_params_file:\n        all_lines = original_params_file.read()\n        before, start_sep, _ = all_lines.partition('.. start params list\\n\\n')\n        _, end_sep, after = all_lines.partition('\\n\\n.. end params list')\n\n    with open(params_rst, \"w\") as new_params_file:\n        new_params_file.write(before)\n        new_params_file.write(start_sep)\n        new_params_file.write('\\n\\n'.join(params_to_write))\n        new_params_file.write(end_sep)\n        new_params_file.write(after)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate the code for the parameter generator.", "response": "def gen_parameter_code(config_hpp, config_out_cpp):\n    \"\"\"Generate auto config file.\n\n    Parameters\n    ----------\n    config_hpp : string\n        Path to the config header file.\n    config_out_cpp : string\n        Path to the auto config file.\n\n    Returns\n    -------\n    infos : tuple\n        Tuple with names and content of sections.\n    \"\"\"\n    keys, infos = get_parameter_infos(config_hpp)\n    names = get_names(infos)\n    alias = get_alias(infos)\n    str_to_write = r\"\"\"/*!\n * Copyright (c) 2018 Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See LICENSE file in the project root for license information.\n *\n * \\note\n * This file is auto generated by LightGBM\\helpers\\parameter_generator.py from LightGBM\\include\\LightGBM\\config.h file.\n */\n\"\"\"\n    str_to_write += \"#include<LightGBM/config.h>\\nnamespace LightGBM {\\n\"\n    # alias table\n    str_to_write += \"std::unordered_map<std::string, std::string> Config::alias_table({\\n\"\n    for pair in alias:\n        str_to_write += \"  {\\\"%s\\\", \\\"%s\\\"},\\n\" % (pair[0], pair[1])\n    str_to_write += \"});\\n\\n\"\n    # names\n    str_to_write += \"std::unordered_set<std::string> Config::parameter_set({\\n\"\n    for name in names:\n        str_to_write += \"  \\\"%s\\\",\\n\" % (name)\n    str_to_write += \"});\\n\\n\"\n    # from strings\n    str_to_write += \"void Config::GetMembersFromString(const std::unordered_map<std::string, std::string>& params) {\\n\"\n    str_to_write += \"  std::string tmp_str = \\\"\\\";\\n\"\n    for x in infos:\n        for y in x:\n            if \"[doc-only]\" in y:\n                continue\n            param_type = y[\"inner_type\"][0]\n            name = y[\"name\"][0]\n            checks = []\n            if \"check\" in y:\n                checks = y[\"check\"]\n            tmp = set_one_var_from_string(name, param_type, checks)\n            str_to_write += tmp\n    # tails\n    str_to_write += \"}\\n\\n\"\n    str_to_write += \"std::string Config::SaveMembersToString() const {\\n\"\n    str_to_write += \"  std::stringstream str_buf;\\n\"\n    for x in infos:\n        for y in x:\n            if \"[doc-only]\" in y:\n                continue\n            param_type = y[\"inner_type\"][0]\n            name = y[\"name\"][0]\n            if \"vector\" in param_type:\n                if \"int8\" in param_type:\n                    str_to_write += \"  str_buf << \\\"[%s: \\\" << Common::Join(Common::ArrayCast<int8_t, int>(%s), \\\",\\\") << \\\"]\\\\n\\\";\\n\" % (name, name)\n                else:\n                    str_to_write += \"  str_buf << \\\"[%s: \\\" << Common::Join(%s, \\\",\\\") << \\\"]\\\\n\\\";\\n\" % (name, name)\n            else:\n                str_to_write += \"  str_buf << \\\"[%s: \\\" << %s << \\\"]\\\\n\\\";\\n\" % (name, name)\n    # tails\n    str_to_write += \"  return str_buf.str();\\n\"\n    str_to_write += \"}\\n\\n\"\n    str_to_write += \"}  // namespace LightGBM\\n\"\n    with open(config_out_cpp, \"w\") as config_out_cpp_file:\n        config_out_cpp_file.write(str_to_write)\n\n    return keys, infos"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_to_1d_numpy(data, dtype=np.float32, name='list'):\n    if is_numpy_1d_array(data):\n        if data.dtype == dtype:\n            return data\n        else:\n            return data.astype(dtype=dtype, copy=False)\n    elif is_1d_list(data):\n        return np.array(data, dtype=dtype, copy=False)\n    elif isinstance(data, Series):\n        return data.values.astype(dtype)\n    else:\n        raise TypeError(\"Wrong type({0}) for {1}.\\n\"\n                        \"It should be list, numpy 1-D array or pandas Series\".format(type(data).__name__, name))", "response": "Convert data to 1 - D numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cfloat32_array_to_numpy(cptr, length):\n    if isinstance(cptr, ctypes.POINTER(ctypes.c_float)):\n        return np.fromiter(cptr, dtype=np.float32, count=length)\n    else:\n        raise RuntimeError('Expected float pointer')", "response": "Convert a ctypes float pointer array to a numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cfloat64_array_to_numpy(cptr, length):\n    if isinstance(cptr, ctypes.POINTER(ctypes.c_double)):\n        return np.fromiter(cptr, dtype=np.float64, count=length)\n    else:\n        raise RuntimeError('Expected double pointer')", "response": "Convert a ctypes double pointer array to a numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a ctypes int pointer array to a numpy array.", "response": "def cint32_array_to_numpy(cptr, length):\n    \"\"\"Convert a ctypes int pointer array to a numpy array.\"\"\"\n    if isinstance(cptr, ctypes.POINTER(ctypes.c_int32)):\n        return np.fromiter(cptr, dtype=np.int32, count=length)\n    else:\n        raise RuntimeError('Expected int pointer')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a ctypes int pointer array to a numpy array.", "response": "def cint8_array_to_numpy(cptr, length):\n    \"\"\"Convert a ctypes int pointer array to a numpy array.\"\"\"\n    if isinstance(cptr, ctypes.POINTER(ctypes.c_int8)):\n        return np.fromiter(cptr, dtype=np.int8, count=length)\n    else:\n        raise RuntimeError('Expected int pointer')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert Python dictionary to string which is passed to C API.", "response": "def param_dict_to_str(data):\n    \"\"\"Convert Python dictionary to string, which is passed to C API.\"\"\"\n    if data is None or not data:\n        return \"\"\n    pairs = []\n    for key, val in data.items():\n        if isinstance(val, (list, tuple, set)) or is_numpy_1d_array(val):\n            pairs.append(str(key) + '=' + ','.join(map(str, val)))\n        elif isinstance(val, string_type) or isinstance(val, numeric_types) or is_numeric(val):\n            pairs.append(str(key) + '=' + str(val))\n        elif val is not None:\n            raise TypeError('Unknown type of parameter:%s, got:%s'\n                            % (key, type(val).__name__))\n    return ' '.join(pairs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert_from_sliced_object(data):\n    if data.base is not None and isinstance(data, np.ndarray) and isinstance(data.base, np.ndarray):\n        if not data.flags.c_contiguous:\n            warnings.warn(\"Usage of np.ndarray subset (sliced data) is not recommended \"\n                          \"due to it will double the peak memory cost in LightGBM.\")\n            return np.copy(data)\n    return data", "response": "Fix the memory of multi - dimensional sliced object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef c_float_array(data):\n    if is_1d_list(data):\n        data = np.array(data, copy=False)\n    if is_numpy_1d_array(data):\n        data = convert_from_sliced_object(data)\n        assert data.flags.c_contiguous\n        if data.dtype == np.float32:\n            ptr_data = data.ctypes.data_as(ctypes.POINTER(ctypes.c_float))\n            type_data = C_API_DTYPE_FLOAT32\n        elif data.dtype == np.float64:\n            ptr_data = data.ctypes.data_as(ctypes.POINTER(ctypes.c_double))\n            type_data = C_API_DTYPE_FLOAT64\n        else:\n            raise TypeError(\"Expected np.float32 or np.float64, met type({})\"\n                            .format(data.dtype))\n    else:\n        raise TypeError(\"Unknown type({})\".format(type(data).__name__))\n    return (ptr_data, type_data, data)", "response": "Get pointer of float numpy array / list."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets pointer of int numpy array / list.", "response": "def c_int_array(data):\n    \"\"\"Get pointer of int numpy array / list.\"\"\"\n    if is_1d_list(data):\n        data = np.array(data, copy=False)\n    if is_numpy_1d_array(data):\n        data = convert_from_sliced_object(data)\n        assert data.flags.c_contiguous\n        if data.dtype == np.int32:\n            ptr_data = data.ctypes.data_as(ctypes.POINTER(ctypes.c_int32))\n            type_data = C_API_DTYPE_INT32\n        elif data.dtype == np.int64:\n            ptr_data = data.ctypes.data_as(ctypes.POINTER(ctypes.c_int64))\n            type_data = C_API_DTYPE_INT64\n        else:\n            raise TypeError(\"Expected np.int32 or np.int64, met type({})\"\n                            .format(data.dtype))\n    else:\n        raise TypeError(\"Unknown type({})\".format(type(data).__name__))\n    return (ptr_data, type_data, data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef predict(self, data, num_iteration=-1,\n                raw_score=False, pred_leaf=False, pred_contrib=False, data_has_header=False,\n                is_reshape=True):\n        \"\"\"Predict logic.\n\n        Parameters\n        ----------\n        data : string, numpy array, pandas DataFrame, H2O DataTable's Frame or scipy.sparse\n            Data source for prediction.\n            When data type is string, it represents the path of txt file.\n        num_iteration : int, optional (default=-1)\n            Iteration used for prediction.\n        raw_score : bool, optional (default=False)\n            Whether to predict raw scores.\n        pred_leaf : bool, optional (default=False)\n            Whether to predict leaf index.\n        pred_contrib : bool, optional (default=False)\n            Whether to predict feature contributions.\n        data_has_header : bool, optional (default=False)\n            Whether data has header.\n            Used only for txt data.\n        is_reshape : bool, optional (default=True)\n            Whether to reshape to (nrow, ncol).\n\n        Returns\n        -------\n        result : numpy array\n            Prediction result.\n        \"\"\"\n        if isinstance(data, Dataset):\n            raise TypeError(\"Cannot use Dataset instance for prediction, please use raw data instead\")\n        data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n        predict_type = C_API_PREDICT_NORMAL\n        if raw_score:\n            predict_type = C_API_PREDICT_RAW_SCORE\n        if pred_leaf:\n            predict_type = C_API_PREDICT_LEAF_INDEX\n        if pred_contrib:\n            predict_type = C_API_PREDICT_CONTRIB\n        int_data_has_header = 1 if data_has_header else 0\n        if num_iteration > self.num_total_iteration:\n            num_iteration = self.num_total_iteration\n\n        if isinstance(data, string_type):\n            with _TempFile() as f:\n                _safe_call(_LIB.LGBM_BoosterPredictForFile(\n                    self.handle,\n                    c_str(data),\n                    ctypes.c_int(int_data_has_header),\n                    ctypes.c_int(predict_type),\n                    ctypes.c_int(num_iteration),\n                    c_str(self.pred_parameter),\n                    c_str(f.name)))\n                lines = f.readlines()\n                nrow = len(lines)\n                preds = [float(token) for line in lines for token in line.split('\\t')]\n                preds = np.array(preds, dtype=np.float64, copy=False)\n        elif isinstance(data, scipy.sparse.csr_matrix):\n            preds, nrow = self.__pred_for_csr(data, num_iteration, predict_type)\n        elif isinstance(data, scipy.sparse.csc_matrix):\n            preds, nrow = self.__pred_for_csc(data, num_iteration, predict_type)\n        elif isinstance(data, np.ndarray):\n            preds, nrow = self.__pred_for_np2d(data, num_iteration, predict_type)\n        elif isinstance(data, list):\n            try:\n                data = np.array(data)\n            except BaseException:\n                raise ValueError('Cannot convert data list to numpy array.')\n            preds, nrow = self.__pred_for_np2d(data, num_iteration, predict_type)\n        elif isinstance(data, DataTable):\n            preds, nrow = self.__pred_for_np2d(data.to_numpy(), num_iteration, predict_type)\n        else:\n            try:\n                warnings.warn('Converting data to scipy sparse matrix.')\n                csr = scipy.sparse.csr_matrix(data)\n            except BaseException:\n                raise TypeError('Cannot predict data for type {}'.format(type(data).__name__))\n            preds, nrow = self.__pred_for_csr(csr, num_iteration, predict_type)\n        if pred_leaf:\n            preds = preds.astype(np.int32)\n        if is_reshape and preds.size != nrow:\n            if preds.size % nrow == 0:\n                preds = preds.reshape(nrow, -1)\n            else:\n                raise ValueError('Length of predict result (%d) cannot be divide nrow (%d)'\n                                 % (preds.size, nrow))\n        return preds", "response": "Predicts the current state of an object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __get_num_preds(self, num_iteration, nrow, predict_type):\n        if nrow > MAX_INT32:\n            raise LightGBMError('LightGBM cannot perform prediction for data'\n                                'with number of rows greater than MAX_INT32 (%d).\\n'\n                                'You can split your data into chunks'\n                                'and then concatenate predictions for them' % MAX_INT32)\n        n_preds = ctypes.c_int64(0)\n        _safe_call(_LIB.LGBM_BoosterCalcNumPredict(\n            self.handle,\n            ctypes.c_int(nrow),\n            ctypes.c_int(predict_type),\n            ctypes.c_int(num_iteration),\n            ctypes.byref(n_preds)))\n        return n_preds.value", "response": "Get size of prediction result."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __pred_for_np2d(self, mat, num_iteration, predict_type):\n        if len(mat.shape) != 2:\n            raise ValueError('Input numpy.ndarray or list must be 2 dimensional')\n\n        def inner_predict(mat, num_iteration, predict_type, preds=None):\n            if mat.dtype == np.float32 or mat.dtype == np.float64:\n                data = np.array(mat.reshape(mat.size), dtype=mat.dtype, copy=False)\n            else:\n                \"\"\"change non-float data to float data, need to copy\"\"\"\n                data = np.array(mat.reshape(mat.size), dtype=np.float32)\n            ptr_data, type_ptr_data, _ = c_float_array(data)\n            n_preds = self.__get_num_preds(num_iteration, mat.shape[0], predict_type)\n            if preds is None:\n                preds = np.zeros(n_preds, dtype=np.float64)\n            elif len(preds.shape) != 1 or len(preds) != n_preds:\n                raise ValueError(\"Wrong length of pre-allocated predict array\")\n            out_num_preds = ctypes.c_int64(0)\n            _safe_call(_LIB.LGBM_BoosterPredictForMat(\n                self.handle,\n                ptr_data,\n                ctypes.c_int(type_ptr_data),\n                ctypes.c_int(mat.shape[0]),\n                ctypes.c_int(mat.shape[1]),\n                ctypes.c_int(C_API_IS_ROW_MAJOR),\n                ctypes.c_int(predict_type),\n                ctypes.c_int(num_iteration),\n                c_str(self.pred_parameter),\n                ctypes.byref(out_num_preds),\n                preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n            if n_preds != out_num_preds.value:\n                raise ValueError(\"Wrong length for predict results\")\n            return preds, mat.shape[0]\n\n        nrow = mat.shape[0]\n        if nrow > MAX_INT32:\n            sections = np.arange(start=MAX_INT32, stop=nrow, step=MAX_INT32)\n            # __get_num_preds() cannot work with nrow > MAX_INT32, so calculate overall number of predictions piecemeal\n            n_preds = [self.__get_num_preds(num_iteration, i, predict_type) for i in np.diff([0] + list(sections) + [nrow])]\n            n_preds_sections = np.array([0] + n_preds, dtype=np.intp).cumsum()\n            preds = np.zeros(sum(n_preds), dtype=np.float64)\n            for chunk, (start_idx_pred, end_idx_pred) in zip_(np.array_split(mat, sections),\n                                                              zip_(n_preds_sections, n_preds_sections[1:])):\n                # avoid memory consumption by arrays concatenation operations\n                inner_predict(chunk, num_iteration, predict_type, preds[start_idx_pred:end_idx_pred])\n            return preds, nrow\n        else:\n            return inner_predict(mat, num_iteration, predict_type)", "response": "Predict for a 2 - D numpy matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __pred_for_csr(self, csr, num_iteration, predict_type):\n        def inner_predict(csr, num_iteration, predict_type, preds=None):\n            nrow = len(csr.indptr) - 1\n            n_preds = self.__get_num_preds(num_iteration, nrow, predict_type)\n            if preds is None:\n                preds = np.zeros(n_preds, dtype=np.float64)\n            elif len(preds.shape) != 1 or len(preds) != n_preds:\n                raise ValueError(\"Wrong length of pre-allocated predict array\")\n            out_num_preds = ctypes.c_int64(0)\n\n            ptr_indptr, type_ptr_indptr, __ = c_int_array(csr.indptr)\n            ptr_data, type_ptr_data, _ = c_float_array(csr.data)\n\n            assert csr.shape[1] <= MAX_INT32\n            csr.indices = csr.indices.astype(np.int32, copy=False)\n\n            _safe_call(_LIB.LGBM_BoosterPredictForCSR(\n                self.handle,\n                ptr_indptr,\n                ctypes.c_int32(type_ptr_indptr),\n                csr.indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n                ptr_data,\n                ctypes.c_int(type_ptr_data),\n                ctypes.c_int64(len(csr.indptr)),\n                ctypes.c_int64(len(csr.data)),\n                ctypes.c_int64(csr.shape[1]),\n                ctypes.c_int(predict_type),\n                ctypes.c_int(num_iteration),\n                c_str(self.pred_parameter),\n                ctypes.byref(out_num_preds),\n                preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n            if n_preds != out_num_preds.value:\n                raise ValueError(\"Wrong length for predict results\")\n            return preds, nrow\n\n        nrow = len(csr.indptr) - 1\n        if nrow > MAX_INT32:\n            sections = [0] + list(np.arange(start=MAX_INT32, stop=nrow, step=MAX_INT32)) + [nrow]\n            # __get_num_preds() cannot work with nrow > MAX_INT32, so calculate overall number of predictions piecemeal\n            n_preds = [self.__get_num_preds(num_iteration, i, predict_type) for i in np.diff(sections)]\n            n_preds_sections = np.array([0] + n_preds, dtype=np.intp).cumsum()\n            preds = np.zeros(sum(n_preds), dtype=np.float64)\n            for (start_idx, end_idx), (start_idx_pred, end_idx_pred) in zip_(zip_(sections, sections[1:]),\n                                                                             zip_(n_preds_sections, n_preds_sections[1:])):\n                # avoid memory consumption by arrays concatenation operations\n                inner_predict(csr[start_idx:end_idx], num_iteration, predict_type, preds[start_idx_pred:end_idx_pred])\n            return preds, nrow\n        else:\n            return inner_predict(csr, num_iteration, predict_type)", "response": "Predict for a CSR data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npredicting for a CSC data.", "response": "def __pred_for_csc(self, csc, num_iteration, predict_type):\n        \"\"\"Predict for a CSC data.\"\"\"\n        nrow = csc.shape[0]\n        if nrow > MAX_INT32:\n            return self.__pred_for_csr(csc.tocsr(), num_iteration, predict_type)\n        n_preds = self.__get_num_preds(num_iteration, nrow, predict_type)\n        preds = np.zeros(n_preds, dtype=np.float64)\n        out_num_preds = ctypes.c_int64(0)\n\n        ptr_indptr, type_ptr_indptr, __ = c_int_array(csc.indptr)\n        ptr_data, type_ptr_data, _ = c_float_array(csc.data)\n\n        assert csc.shape[0] <= MAX_INT32\n        csc.indices = csc.indices.astype(np.int32, copy=False)\n\n        _safe_call(_LIB.LGBM_BoosterPredictForCSC(\n            self.handle,\n            ptr_indptr,\n            ctypes.c_int32(type_ptr_indptr),\n            csc.indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n            ptr_data,\n            ctypes.c_int(type_ptr_data),\n            ctypes.c_int64(len(csc.indptr)),\n            ctypes.c_int64(len(csc.data)),\n            ctypes.c_int64(csc.shape[0]),\n            ctypes.c_int(predict_type),\n            ctypes.c_int(num_iteration),\n            c_str(self.pred_parameter),\n            ctypes.byref(out_num_preds),\n            preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n        if n_preds != out_num_preds.value:\n            raise ValueError(\"Wrong length for predict results\")\n        return preds, nrow"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __init_from_np2d(self, mat, params_str, ref_dataset):\n        if len(mat.shape) != 2:\n            raise ValueError('Input numpy.ndarray must be 2 dimensional')\n\n        self.handle = ctypes.c_void_p()\n        if mat.dtype == np.float32 or mat.dtype == np.float64:\n            data = np.array(mat.reshape(mat.size), dtype=mat.dtype, copy=False)\n        else:\n            # change non-float data to float data, need to copy\n            data = np.array(mat.reshape(mat.size), dtype=np.float32)\n\n        ptr_data, type_ptr_data, _ = c_float_array(data)\n        _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n            ptr_data,\n            ctypes.c_int(type_ptr_data),\n            ctypes.c_int(mat.shape[0]),\n            ctypes.c_int(mat.shape[1]),\n            ctypes.c_int(C_API_IS_ROW_MAJOR),\n            c_str(params_str),\n            ref_dataset,\n            ctypes.byref(self.handle)))\n        return self", "response": "Initialize data from a 2 - D numpy matrix."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes data from a list of 2 - D numpy matrices.", "response": "def __init_from_list_np2d(self, mats, params_str, ref_dataset):\n        \"\"\"Initialize data from a list of 2-D numpy matrices.\"\"\"\n        ncol = mats[0].shape[1]\n        nrow = np.zeros((len(mats),), np.int32)\n        if mats[0].dtype == np.float64:\n            ptr_data = (ctypes.POINTER(ctypes.c_double) * len(mats))()\n        else:\n            ptr_data = (ctypes.POINTER(ctypes.c_float) * len(mats))()\n\n        holders = []\n        type_ptr_data = None\n\n        for i, mat in enumerate(mats):\n            if len(mat.shape) != 2:\n                raise ValueError('Input numpy.ndarray must be 2 dimensional')\n\n            if mat.shape[1] != ncol:\n                raise ValueError('Input arrays must have same number of columns')\n\n            nrow[i] = mat.shape[0]\n\n            if mat.dtype == np.float32 or mat.dtype == np.float64:\n                mats[i] = np.array(mat.reshape(mat.size), dtype=mat.dtype, copy=False)\n            else:\n                # change non-float data to float data, need to copy\n                mats[i] = np.array(mat.reshape(mat.size), dtype=np.float32)\n\n            chunk_ptr_data, chunk_type_ptr_data, holder = c_float_array(mats[i])\n            if type_ptr_data is not None and chunk_type_ptr_data != type_ptr_data:\n                raise ValueError('Input chunks must have same type')\n            ptr_data[i] = chunk_ptr_data\n            type_ptr_data = chunk_type_ptr_data\n            holders.append(holder)\n\n        self.handle = ctypes.c_void_p()\n        _safe_call(_LIB.LGBM_DatasetCreateFromMats(\n            ctypes.c_int(len(mats)),\n            ctypes.cast(ptr_data, ctypes.POINTER(ctypes.POINTER(ctypes.c_double))),\n            ctypes.c_int(type_ptr_data),\n            nrow.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n            ctypes.c_int(ncol),\n            ctypes.c_int(C_API_IS_ROW_MAJOR),\n            c_str(params_str),\n            ref_dataset,\n            ctypes.byref(self.handle)))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninitializes data from a CSR matrix.", "response": "def __init_from_csr(self, csr, params_str, ref_dataset):\n        \"\"\"Initialize data from a CSR matrix.\"\"\"\n        if len(csr.indices) != len(csr.data):\n            raise ValueError('Length mismatch: {} vs {}'.format(len(csr.indices), len(csr.data)))\n        self.handle = ctypes.c_void_p()\n\n        ptr_indptr, type_ptr_indptr, __ = c_int_array(csr.indptr)\n        ptr_data, type_ptr_data, _ = c_float_array(csr.data)\n\n        assert csr.shape[1] <= MAX_INT32\n        csr.indices = csr.indices.astype(np.int32, copy=False)\n\n        _safe_call(_LIB.LGBM_DatasetCreateFromCSR(\n            ptr_indptr,\n            ctypes.c_int(type_ptr_indptr),\n            csr.indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n            ptr_data,\n            ctypes.c_int(type_ptr_data),\n            ctypes.c_int64(len(csr.indptr)),\n            ctypes.c_int64(len(csr.data)),\n            ctypes.c_int64(csr.shape[1]),\n            c_str(params_str),\n            ref_dataset,\n            ctypes.byref(self.handle)))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize data from a CSC matrix.", "response": "def __init_from_csc(self, csc, params_str, ref_dataset):\n        \"\"\"Initialize data from a CSC matrix.\"\"\"\n        if len(csc.indices) != len(csc.data):\n            raise ValueError('Length mismatch: {} vs {}'.format(len(csc.indices), len(csc.data)))\n        self.handle = ctypes.c_void_p()\n\n        ptr_indptr, type_ptr_indptr, __ = c_int_array(csc.indptr)\n        ptr_data, type_ptr_data, _ = c_float_array(csc.data)\n\n        assert csc.shape[0] <= MAX_INT32\n        csc.indices = csc.indices.astype(np.int32, copy=False)\n\n        _safe_call(_LIB.LGBM_DatasetCreateFromCSC(\n            ptr_indptr,\n            ctypes.c_int(type_ptr_indptr),\n            csc.indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n            ptr_data,\n            ctypes.c_int(type_ptr_data),\n            ctypes.c_int64(len(csc.indptr)),\n            ctypes.c_int64(len(csc.data)),\n            ctypes.c_int64(csc.shape[0]),\n            c_str(params_str),\n            ref_dataset,\n            ctypes.byref(self.handle)))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef construct(self):\n        if self.handle is None:\n            if self.reference is not None:\n                if self.used_indices is None:\n                    # create valid\n                    self._lazy_init(self.data, label=self.label, reference=self.reference,\n                                    weight=self.weight, group=self.group,\n                                    init_score=self.init_score, predictor=self._predictor,\n                                    silent=self.silent, feature_name=self.feature_name, params=self.params)\n                else:\n                    # construct subset\n                    used_indices = list_to_1d_numpy(self.used_indices, np.int32, name='used_indices')\n                    assert used_indices.flags.c_contiguous\n                    if self.reference.group is not None:\n                        group_info = np.array(self.reference.group).astype(int)\n                        _, self.group = np.unique(np.repeat(range_(len(group_info)), repeats=group_info)[self.used_indices],\n                                                  return_counts=True)\n                    self.handle = ctypes.c_void_p()\n                    params_str = param_dict_to_str(self.params)\n                    _safe_call(_LIB.LGBM_DatasetGetSubset(\n                        self.reference.construct().handle,\n                        used_indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n                        ctypes.c_int(used_indices.shape[0]),\n                        c_str(params_str),\n                        ctypes.byref(self.handle)))\n                    self.data = self.reference.data\n                    self.get_data()\n                    if self.group is not None:\n                        self.set_group(self.group)\n                    if self.get_label() is None:\n                        raise ValueError(\"Label should not be None.\")\n            else:\n                # create train\n                self._lazy_init(self.data, label=self.label,\n                                weight=self.weight, group=self.group,\n                                init_score=self.init_score, predictor=self._predictor,\n                                silent=self.silent, feature_name=self.feature_name,\n                                categorical_feature=self.categorical_feature, params=self.params)\n            if self.free_raw_data:\n                self.data = None\n        return self", "response": "Lazy init.\n\n        Returns\n        -------\n        self : Dataset\n            Constructed Dataset object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates validation data align with current Dataset.", "response": "def create_valid(self, data, label=None, weight=None, group=None,\n                     init_score=None, silent=False, params=None):\n        \"\"\"Create validation data align with current Dataset.\n\n        Parameters\n        ----------\n        data : string, numpy array, pandas DataFrame, H2O DataTable's Frame, scipy.sparse or list of numpy arrays\n            Data source of Dataset.\n            If string, it represents the path to txt file.\n        label : list, numpy 1-D array, pandas Series / one-column DataFrame or None, optional (default=None)\n            Label of the data.\n        weight : list, numpy 1-D array, pandas Series or None, optional (default=None)\n            Weight for each instance.\n        group : list, numpy 1-D array, pandas Series or None, optional (default=None)\n            Group/query size for Dataset.\n        init_score : list, numpy 1-D array, pandas Series or None, optional (default=None)\n            Init score for Dataset.\n        silent : bool, optional (default=False)\n            Whether to print messages during construction.\n        params : dict or None, optional (default=None)\n            Other parameters for validation Dataset.\n\n        Returns\n        -------\n        valid : Dataset\n            Validation Dataset with reference to self.\n        \"\"\"\n        ret = Dataset(data, label=label, reference=self,\n                      weight=weight, group=group, init_score=init_score,\n                      silent=silent, params=params, free_raw_data=self.free_raw_data)\n        ret._predictor = self._predictor\n        ret.pandas_categorical = self.pandas_categorical\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef subset(self, used_indices, params=None):\n        if params is None:\n            params = self.params\n        ret = Dataset(None, reference=self, feature_name=self.feature_name,\n                      categorical_feature=self.categorical_feature, params=params,\n                      free_raw_data=self.free_raw_data)\n        ret._predictor = self._predictor\n        ret.pandas_categorical = self.pandas_categorical\n        ret.used_indices = used_indices\n        return ret", "response": "Returns a subset of the current Dataset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_binary(self, filename):\n        _safe_call(_LIB.LGBM_DatasetSaveBinary(\n            self.construct().handle,\n            c_str(filename)))\n        return self", "response": "Save the dataset to a binary file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_field(self, field_name, data):\n        if self.handle is None:\n            raise Exception(\"Cannot set %s before construct dataset\" % field_name)\n        if data is None:\n            # set to None\n            _safe_call(_LIB.LGBM_DatasetSetField(\n                self.handle,\n                c_str(field_name),\n                None,\n                ctypes.c_int(0),\n                ctypes.c_int(FIELD_TYPE_MAPPER[field_name])))\n            return self\n        dtype = np.float32\n        if field_name == 'group':\n            dtype = np.int32\n        elif field_name == 'init_score':\n            dtype = np.float64\n        data = list_to_1d_numpy(data, dtype, name=field_name)\n        if data.dtype == np.float32 or data.dtype == np.float64:\n            ptr_data, type_data, _ = c_float_array(data)\n        elif data.dtype == np.int32:\n            ptr_data, type_data, _ = c_int_array(data)\n        else:\n            raise TypeError(\"Excepted np.float32/64 or np.int32, meet type({})\".format(data.dtype))\n        if type_data != FIELD_TYPE_MAPPER[field_name]:\n            raise TypeError(\"Input type error for set_field\")\n        _safe_call(_LIB.LGBM_DatasetSetField(\n            self.handle,\n            c_str(field_name),\n            ptr_data,\n            ctypes.c_int(len(data)),\n            ctypes.c_int(type_data)))\n        return self", "response": "Set the value of a specific field in the Dataset."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the value of a specific field from the Dataset.", "response": "def get_field(self, field_name):\n        \"\"\"Get property from the Dataset.\n\n        Parameters\n        ----------\n        field_name : string\n            The field name of the information.\n\n        Returns\n        -------\n        info : numpy array\n            A numpy array with information from the Dataset.\n        \"\"\"\n        if self.handle is None:\n            raise Exception(\"Cannot get %s before construct Dataset\" % field_name)\n        tmp_out_len = ctypes.c_int()\n        out_type = ctypes.c_int()\n        ret = ctypes.POINTER(ctypes.c_void_p)()\n        _safe_call(_LIB.LGBM_DatasetGetField(\n            self.handle,\n            c_str(field_name),\n            ctypes.byref(tmp_out_len),\n            ctypes.byref(ret),\n            ctypes.byref(out_type)))\n        if out_type.value != FIELD_TYPE_MAPPER[field_name]:\n            raise TypeError(\"Return type error for get_field\")\n        if tmp_out_len.value == 0:\n            return None\n        if out_type.value == C_API_DTYPE_INT32:\n            return cint32_array_to_numpy(ctypes.cast(ret, ctypes.POINTER(ctypes.c_int32)), tmp_out_len.value)\n        elif out_type.value == C_API_DTYPE_FLOAT32:\n            return cfloat32_array_to_numpy(ctypes.cast(ret, ctypes.POINTER(ctypes.c_float)), tmp_out_len.value)\n        elif out_type.value == C_API_DTYPE_FLOAT64:\n            return cfloat64_array_to_numpy(ctypes.cast(ret, ctypes.POINTER(ctypes.c_double)), tmp_out_len.value)\n        elif out_type.value == C_API_DTYPE_INT8:\n            return cint8_array_to_numpy(ctypes.cast(ret, ctypes.POINTER(ctypes.c_int8)), tmp_out_len.value)\n        else:\n            raise TypeError(\"Unknown type\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the categorical feature of the related object.", "response": "def set_categorical_feature(self, categorical_feature):\n        \"\"\"Set categorical features.\n\n        Parameters\n        ----------\n        categorical_feature : list of int or strings\n            Names or indices of categorical features.\n\n        Returns\n        -------\n        self : Dataset\n            Dataset with set categorical features.\n        \"\"\"\n        if self.categorical_feature == categorical_feature:\n            return self\n        if self.data is not None:\n            if self.categorical_feature is None:\n                self.categorical_feature = categorical_feature\n                return self._free_handle()\n            elif categorical_feature == 'auto':\n                warnings.warn('Using categorical_feature in Dataset.')\n                return self\n            else:\n                warnings.warn('categorical_feature in Dataset is overridden.\\n'\n                              'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n                self.categorical_feature = categorical_feature\n                return self._free_handle()\n        else:\n            raise LightGBMError(\"Cannot set categorical feature after freed raw data, \"\n                                \"set free_raw_data=False when construct Dataset to avoid this.\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset predictor for continued training.", "response": "def _set_predictor(self, predictor):\n        \"\"\"Set predictor for continued training.\n\n        It is not recommended for user to call this function.\n        Please use init_model argument in engine.train() or engine.cv() instead.\n        \"\"\"\n        if predictor is self._predictor:\n            return self\n        if self.data is not None:\n            self._predictor = predictor\n            return self._free_handle()\n        else:\n            raise LightGBMError(\"Cannot set predictor after freed raw data, \"\n                                \"set free_raw_data=False when construct Dataset to avoid this.\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_reference(self, reference):\n        self.set_categorical_feature(reference.categorical_feature) \\\n            .set_feature_name(reference.feature_name) \\\n            ._set_predictor(reference._predictor)\n        # we're done if self and reference share a common upstrem reference\n        if self.get_ref_chain().intersection(reference.get_ref_chain()):\n            return self\n        if self.data is not None:\n            self.reference = reference\n            return self._free_handle()\n        else:\n            raise LightGBMError(\"Cannot set reference after freed raw data, \"\n                                \"set free_raw_data=False when construct Dataset to avoid this.\")", "response": "Sets the current Dataset s reference."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_feature_name(self, feature_name):\n        if feature_name != 'auto':\n            self.feature_name = feature_name\n        if self.handle is not None and feature_name is not None and feature_name != 'auto':\n            if len(feature_name) != self.num_feature():\n                raise ValueError(\"Length of feature_name({}) and num_feature({}) don't match\"\n                                 .format(len(feature_name), self.num_feature()))\n            c_feature_name = [c_str(name) for name in feature_name]\n            _safe_call(_LIB.LGBM_DatasetSetFeatureNames(\n                self.handle,\n                c_array(ctypes.c_char_p, c_feature_name),\n                ctypes.c_int(len(feature_name))))\n        return self", "response": "Sets the feature name of the current Dataset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_label(self, label):\n        self.label = label\n        if self.handle is not None:\n            label = list_to_1d_numpy(_label_from_pandas(label), name='label')\n            self.set_field('label', label)\n        return self", "response": "Set label of the object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the weight of each instance.", "response": "def set_weight(self, weight):\n        \"\"\"Set weight of each instance.\n\n        Parameters\n        ----------\n        weight : list, numpy 1-D array, pandas Series or None\n            Weight to be set for each data point.\n\n        Returns\n        -------\n        self : Dataset\n            Dataset with set weight.\n        \"\"\"\n        if weight is not None and np.all(weight == 1):\n            weight = None\n        self.weight = weight\n        if self.handle is not None and weight is not None:\n            weight = list_to_1d_numpy(weight, name='weight')\n            self.set_field('weight', weight)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the init score of the object.", "response": "def set_init_score(self, init_score):\n        \"\"\"Set init score of Booster to start from.\n\n        Parameters\n        ----------\n        init_score : list, numpy 1-D array, pandas Series or None\n            Init score for Booster.\n\n        Returns\n        -------\n        self : Dataset\n            Dataset with set init score.\n        \"\"\"\n        self.init_score = init_score\n        if self.handle is not None and init_score is not None:\n            init_score = list_to_1d_numpy(init_score, np.float64, name='init_score')\n            self.set_field('init_score', init_score)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_group(self, group):\n        self.group = group\n        if self.handle is not None and group is not None:\n            group = list_to_1d_numpy(group, np.int32, name='group')\n            self.set_field('group', group)\n        return self", "response": "Set group size of Dataset."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_label(self):\n        if self.label is None:\n            self.label = self.get_field('label')\n        return self.label", "response": "Get the label of the Dataset."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the weight of the Dataset.", "response": "def get_weight(self):\n        \"\"\"Get the weight of the Dataset.\n\n        Returns\n        -------\n        weight : numpy array or None\n            Weight for each data point from the Dataset.\n        \"\"\"\n        if self.weight is None:\n            self.weight = self.get_field('weight')\n        return self.weight"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_feature_penalty(self):\n        if self.feature_penalty is None:\n            self.feature_penalty = self.get_field('feature_penalty')\n        return self.feature_penalty", "response": "Get the feature penalty of the Dataset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the monotone constraints of the Dataset.", "response": "def get_monotone_constraints(self):\n        \"\"\"Get the monotone constraints of the Dataset.\n\n        Returns\n        -------\n        monotone_constraints : numpy array or None\n            Monotone constraints: -1, 0 or 1, for each feature in the Dataset.\n        \"\"\"\n        if self.monotone_constraints is None:\n            self.monotone_constraints = self.get_field('monotone_constraints')\n        return self.monotone_constraints"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the initial score of the Dataset.", "response": "def get_init_score(self):\n        \"\"\"Get the initial score of the Dataset.\n\n        Returns\n        -------\n        init_score : numpy array or None\n            Init score of Booster.\n        \"\"\"\n        if self.init_score is None:\n            self.init_score = self.get_field('init_score')\n        return self.init_score"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the raw data of the Dataset.", "response": "def get_data(self):\n        \"\"\"Get the raw data of the Dataset.\n\n        Returns\n        -------\n        data : string, numpy array, pandas DataFrame, H2O DataTable's Frame, scipy.sparse, list of numpy arrays or None\n            Raw data used in the Dataset construction.\n        \"\"\"\n        if self.handle is None:\n            raise Exception(\"Cannot get data before construct Dataset\")\n        if self.data is not None and self.used_indices is not None and self.need_slice:\n            if isinstance(self.data, np.ndarray) or scipy.sparse.issparse(self.data):\n                self.data = self.data[self.used_indices, :]\n            elif isinstance(self.data, DataFrame):\n                self.data = self.data.iloc[self.used_indices].copy()\n            elif isinstance(self.data, DataTable):\n                self.data = self.data[self.used_indices, :]\n            else:\n                warnings.warn(\"Cannot subset {} type of raw data.\\n\"\n                              \"Returning original raw data\".format(type(self.data).__name__))\n            self.need_slice = False\n        return self.data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_group(self):\n        if self.group is None:\n            self.group = self.get_field('group')\n            if self.group is not None:\n                # group data from LightGBM is boundaries data, need to convert to group size\n                self.group = np.diff(self.group)\n        return self.group", "response": "Get the group of the Dataset."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the number of rows in the Dataset.", "response": "def num_data(self):\n        \"\"\"Get the number of rows in the Dataset.\n\n        Returns\n        -------\n        number_of_rows : int\n            The number of rows in the Dataset.\n        \"\"\"\n        if self.handle is not None:\n            ret = ctypes.c_int()\n            _safe_call(_LIB.LGBM_DatasetGetNumData(self.handle,\n                                                   ctypes.byref(ret)))\n            return ret.value\n        else:\n            raise LightGBMError(\"Cannot get num_data before construct dataset\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef num_feature(self):\n        if self.handle is not None:\n            ret = ctypes.c_int()\n            _safe_call(_LIB.LGBM_DatasetGetNumFeature(self.handle,\n                                                      ctypes.byref(ret)))\n            return ret.value\n        else:\n            raise LightGBMError(\"Cannot get num_feature before construct dataset\")", "response": "Get the number of features in the Dataset."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_ref_chain(self, ref_limit=100):\n        head = self\n        ref_chain = set()\n        while len(ref_chain) < ref_limit:\n            if isinstance(head, Dataset):\n                ref_chain.add(head)\n                if (head.reference is not None) and (head.reference not in ref_chain):\n                    head = head.reference\n                else:\n                    break\n            else:\n                break\n        return ref_chain", "response": "Get a chain of Dataset objects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd features from other Dataset to the current Dataset.", "response": "def add_features_from(self, other):\n        \"\"\"Add features from other Dataset to the current Dataset.\n\n        Both Datasets must be constructed before calling this method.\n\n        Parameters\n        ----------\n        other : Dataset\n            The Dataset to take features from.\n\n        Returns\n        -------\n        self : Dataset\n            Dataset with the new features added.\n        \"\"\"\n        if self.handle is None or other.handle is None:\n            raise ValueError('Both source and target Datasets must be constructed before adding features')\n        _safe_call(_LIB.LGBM_DatasetAddFeaturesFrom(self.handle, other.handle))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves Dataset to a text file.", "response": "def dump_text(self, filename):\n        \"\"\"Save Dataset to a text file.\n\n        This format cannot be loaded back in by LightGBM, but is useful for debugging purposes.\n\n        Parameters\n        ----------\n        filename : string\n            Name of the output file.\n\n        Returns\n        -------\n        self : Dataset\n            Returns self.\n        \"\"\"\n        _safe_call(_LIB.LGBM_DatasetDumpText(\n            self.construct().handle,\n            c_str(filename)))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfrees the Booster s Datasets.", "response": "def free_dataset(self):\n        \"\"\"Free Booster's Datasets.\n\n        Returns\n        -------\n        self : Booster\n            Booster without Datasets.\n        \"\"\"\n        self.__dict__.pop('train_set', None)\n        self.__dict__.pop('valid_sets', None)\n        self.__num_dataset = 0\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_network(self, machines, local_listen_port=12400,\n                    listen_time_out=120, num_machines=1):\n        \"\"\"Set the network configuration.\n\n        Parameters\n        ----------\n        machines : list, set or string\n            Names of machines.\n        local_listen_port : int, optional (default=12400)\n            TCP listen port for local machines.\n        listen_time_out : int, optional (default=120)\n            Socket time-out in minutes.\n        num_machines : int, optional (default=1)\n            The number of machines for parallel learning application.\n\n        Returns\n        -------\n        self : Booster\n            Booster with set network.\n        \"\"\"\n        _safe_call(_LIB.LGBM_NetworkInit(c_str(machines),\n                                         ctypes.c_int(local_listen_port),\n                                         ctypes.c_int(listen_time_out),\n                                         ctypes.c_int(num_machines)))\n        self.network = True\n        return self", "response": "Sets the network configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds validation data to Booster.", "response": "def add_valid(self, data, name):\n        \"\"\"Add validation data.\n\n        Parameters\n        ----------\n        data : Dataset\n            Validation data.\n        name : string\n            Name of validation data.\n\n        Returns\n        -------\n        self : Booster\n            Booster with set validation data.\n        \"\"\"\n        if not isinstance(data, Dataset):\n            raise TypeError('Validation data should be Dataset instance, met {}'\n                            .format(type(data).__name__))\n        if data._predictor is not self.__init_predictor:\n            raise LightGBMError(\"Add validation data failed, \"\n                                \"you should use same predictor for these data\")\n        _safe_call(_LIB.LGBM_BoosterAddValidData(\n            self.handle,\n            data.construct().handle))\n        self.valid_sets.append(data)\n        self.name_valid_sets.append(name)\n        self.__num_dataset += 1\n        self.__inner_predict_buffer.append(None)\n        self.__is_predicted_cur_iter.append(False)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nresetting Booster s parameters to the given dictionary.", "response": "def reset_parameter(self, params):\n        \"\"\"Reset parameters of Booster.\n\n        Parameters\n        ----------\n        params : dict\n            New parameters for Booster.\n\n        Returns\n        -------\n        self : Booster\n            Booster with new parameters.\n        \"\"\"\n        if any(metric_alias in params for metric_alias in ('metric', 'metrics', 'metric_types')):\n            self.__need_reload_eval_info = True\n        params_str = param_dict_to_str(params)\n        if params_str:\n            _safe_call(_LIB.LGBM_BoosterResetParameter(\n                self.handle,\n                c_str(params_str)))\n        self.params.update(params)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, train_set=None, fobj=None):\n        # need reset training data\n        if train_set is not None and train_set is not self.train_set:\n            if not isinstance(train_set, Dataset):\n                raise TypeError('Training data should be Dataset instance, met {}'\n                                .format(type(train_set).__name__))\n            if train_set._predictor is not self.__init_predictor:\n                raise LightGBMError(\"Replace training data failed, \"\n                                    \"you should use same predictor for these data\")\n            self.train_set = train_set\n            _safe_call(_LIB.LGBM_BoosterResetTrainingData(\n                self.handle,\n                self.train_set.construct().handle))\n            self.__inner_predict_buffer[0] = None\n        is_finished = ctypes.c_int(0)\n        if fobj is None:\n            if self.__set_objective_to_none:\n                raise LightGBMError('Cannot update due to null objective function.')\n            _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n                self.handle,\n                ctypes.byref(is_finished)))\n            self.__is_predicted_cur_iter = [False for _ in range_(self.__num_dataset)]\n            return is_finished.value == 1\n        else:\n            if not self.__set_objective_to_none:\n                self.reset_parameter({\"objective\": \"none\"}).__set_objective_to_none = True\n            grad, hess = fobj(self.__inner_predict(0), self.train_set)\n            return self.__boost(grad, hess)", "response": "Update Booster for one iteration."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __boost(self, grad, hess):\n        grad = list_to_1d_numpy(grad, name='gradient')\n        hess = list_to_1d_numpy(hess, name='hessian')\n        assert grad.flags.c_contiguous\n        assert hess.flags.c_contiguous\n        if len(grad) != len(hess):\n            raise ValueError(\"Lengths of gradient({}) and hessian({}) don't match\"\n                             .format(len(grad), len(hess)))\n        is_finished = ctypes.c_int(0)\n        _safe_call(_LIB.LGBM_BoosterUpdateOneIterCustom(\n            self.handle,\n            grad.ctypes.data_as(ctypes.POINTER(ctypes.c_float)),\n            hess.ctypes.data_as(ctypes.POINTER(ctypes.c_float)),\n            ctypes.byref(is_finished)))\n        self.__is_predicted_cur_iter = [False for _ in range_(self.__num_dataset)]\n        return is_finished.value == 1", "response": "Boost the log - likelihood of the current cluster."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rollback_one_iter(self):\n        _safe_call(_LIB.LGBM_BoosterRollbackOneIter(\n            self.handle))\n        self.__is_predicted_cur_iter = [False for _ in range_(self.__num_dataset)]\n        return self", "response": "Rollback one iteration.\n\n        Returns\n        -------\n        self : Booster\n            Booster with rolled back one iteration."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the index of the current iteration.", "response": "def current_iteration(self):\n        \"\"\"Get the index of the current iteration.\n\n        Returns\n        -------\n        cur_iter : int\n            The index of the current iteration.\n        \"\"\"\n        out_cur_iter = ctypes.c_int(0)\n        _safe_call(_LIB.LGBM_BoosterGetCurrentIteration(\n            self.handle,\n            ctypes.byref(out_cur_iter)))\n        return out_cur_iter.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef num_model_per_iteration(self):\n        model_per_iter = ctypes.c_int(0)\n        _safe_call(_LIB.LGBM_BoosterNumModelPerIteration(\n            self.handle,\n            ctypes.byref(model_per_iter)))\n        return model_per_iter.value", "response": "Get number of models per iteration."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef num_trees(self):\n        num_trees = ctypes.c_int(0)\n        _safe_call(_LIB.LGBM_BoosterNumberOfTotalModel(\n            self.handle,\n            ctypes.byref(num_trees)))\n        return num_trees.value", "response": "Get number of weak sub - models."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nevaluating for data. Parameters ---------- data : Dataset Data for the evaluating. name : string Name of the data. feval : callable or None, optional (default=None) Customized evaluation function. Should accept two parameters: preds, train_data, and return (eval_name, eval_result, is_higher_better) or list of such tuples. For multi-class task, the preds is group by class_id first, then group by row_id. If you want to get i-th row preds in j-th class, the access way is preds[j * num_data + i]. Returns ------- result : list List with evaluation results.", "response": "def eval(self, data, name, feval=None):\n        \"\"\"Evaluate for data.\n\n        Parameters\n        ----------\n        data : Dataset\n            Data for the evaluating.\n        name : string\n            Name of the data.\n        feval : callable or None, optional (default=None)\n            Customized evaluation function.\n            Should accept two parameters: preds, train_data,\n            and return (eval_name, eval_result, is_higher_better) or list of such tuples.\n            For multi-class task, the preds is group by class_id first, then group by row_id.\n            If you want to get i-th row preds in j-th class, the access way is preds[j * num_data + i].\n\n        Returns\n        -------\n        result : list\n            List with evaluation results.\n        \"\"\"\n        if not isinstance(data, Dataset):\n            raise TypeError(\"Can only eval for Dataset instance\")\n        data_idx = -1\n        if data is self.train_set:\n            data_idx = 0\n        else:\n            for i in range_(len(self.valid_sets)):\n                if data is self.valid_sets[i]:\n                    data_idx = i + 1\n                    break\n        # need to push new valid data\n        if data_idx == -1:\n            self.add_valid(data, name)\n            data_idx = self.__num_dataset - 1\n\n        return self.__inner_eval(name, data_idx, feval)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef eval_valid(self, feval=None):\n        return [item for i in range_(1, self.__num_dataset)\n                for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]", "response": "Evaluate for validation data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_model(self, filename, num_iteration=None, start_iteration=0):\n        if num_iteration is None:\n            num_iteration = self.best_iteration\n        _safe_call(_LIB.LGBM_BoosterSaveModel(\n            self.handle,\n            ctypes.c_int(start_iteration),\n            ctypes.c_int(num_iteration),\n            c_str(filename)))\n        _dump_pandas_categorical(self.pandas_categorical, filename)\n        return self", "response": "Save Booster to file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nshuffles the Booster with shuffled models.", "response": "def shuffle_models(self, start_iteration=0, end_iteration=-1):\n        \"\"\"Shuffle models.\n\n        Parameters\n        ----------\n        start_iteration : int, optional (default=0)\n            The first iteration that will be shuffled.\n        end_iteration : int, optional (default=-1)\n            The last iteration that will be shuffled.\n            If <= 0, means the last available iteration.\n\n        Returns\n        -------\n        self : Booster\n            Booster with shuffled models.\n        \"\"\"\n        _safe_call(_LIB.LGBM_BoosterShuffleModels(\n            self.handle,\n            ctypes.c_int(start_iteration),\n            ctypes.c_int(end_iteration)))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads a Booster from a string.", "response": "def model_from_string(self, model_str, verbose=True):\n        \"\"\"Load Booster from a string.\n\n        Parameters\n        ----------\n        model_str : string\n            Model will be loaded from this string.\n        verbose : bool, optional (default=True)\n            Whether to print messages while loading model.\n\n        Returns\n        -------\n        self : Booster\n            Loaded Booster object.\n        \"\"\"\n        if self.handle is not None:\n            _safe_call(_LIB.LGBM_BoosterFree(self.handle))\n        self._free_buffer()\n        self.handle = ctypes.c_void_p()\n        out_num_iterations = ctypes.c_int(0)\n        _safe_call(_LIB.LGBM_BoosterLoadModelFromString(\n            c_str(model_str),\n            ctypes.byref(out_num_iterations),\n            ctypes.byref(self.handle)))\n        out_num_class = ctypes.c_int(0)\n        _safe_call(_LIB.LGBM_BoosterGetNumClasses(\n            self.handle,\n            ctypes.byref(out_num_class)))\n        if verbose:\n            print('Finished loading model, total used %d iterations' % int(out_num_iterations.value))\n        self.__num_class = out_num_class.value\n        self.pandas_categorical = _load_pandas_categorical(model_str=model_str)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves Booster to string.", "response": "def model_to_string(self, num_iteration=None, start_iteration=0):\n        \"\"\"Save Booster to string.\n\n        Parameters\n        ----------\n        num_iteration : int or None, optional (default=None)\n            Index of the iteration that should be saved.\n            If None, if the best iteration exists, it is saved; otherwise, all iterations are saved.\n            If <= 0, all iterations are saved.\n        start_iteration : int, optional (default=0)\n            Start index of the iteration that should be saved.\n\n        Returns\n        -------\n        str_repr : string\n            String representation of Booster.\n        \"\"\"\n        if num_iteration is None:\n            num_iteration = self.best_iteration\n        buffer_len = 1 << 20\n        tmp_out_len = ctypes.c_int64(0)\n        string_buffer = ctypes.create_string_buffer(buffer_len)\n        ptr_string_buffer = ctypes.c_char_p(*[ctypes.addressof(string_buffer)])\n        _safe_call(_LIB.LGBM_BoosterSaveModelToString(\n            self.handle,\n            ctypes.c_int(start_iteration),\n            ctypes.c_int(num_iteration),\n            ctypes.c_int64(buffer_len),\n            ctypes.byref(tmp_out_len),\n            ptr_string_buffer))\n        actual_len = tmp_out_len.value\n        # if buffer length is not long enough, re-allocate a buffer\n        if actual_len > buffer_len:\n            string_buffer = ctypes.create_string_buffer(actual_len)\n            ptr_string_buffer = ctypes.c_char_p(*[ctypes.addressof(string_buffer)])\n            _safe_call(_LIB.LGBM_BoosterSaveModelToString(\n                self.handle,\n                ctypes.c_int(start_iteration),\n                ctypes.c_int(num_iteration),\n                ctypes.c_int64(actual_len),\n                ctypes.byref(tmp_out_len),\n                ptr_string_buffer))\n        ret = string_buffer.value.decode()\n        ret += _dump_pandas_categorical(self.pandas_categorical)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndumps Booster to JSON format.", "response": "def dump_model(self, num_iteration=None, start_iteration=0):\n        \"\"\"Dump Booster to JSON format.\n\n        Parameters\n        ----------\n        num_iteration : int or None, optional (default=None)\n            Index of the iteration that should be dumped.\n            If None, if the best iteration exists, it is dumped; otherwise, all iterations are dumped.\n            If <= 0, all iterations are dumped.\n        start_iteration : int, optional (default=0)\n            Start index of the iteration that should be dumped.\n\n        Returns\n        -------\n        json_repr : dict\n            JSON format of Booster.\n        \"\"\"\n        if num_iteration is None:\n            num_iteration = self.best_iteration\n        buffer_len = 1 << 20\n        tmp_out_len = ctypes.c_int64(0)\n        string_buffer = ctypes.create_string_buffer(buffer_len)\n        ptr_string_buffer = ctypes.c_char_p(*[ctypes.addressof(string_buffer)])\n        _safe_call(_LIB.LGBM_BoosterDumpModel(\n            self.handle,\n            ctypes.c_int(start_iteration),\n            ctypes.c_int(num_iteration),\n            ctypes.c_int64(buffer_len),\n            ctypes.byref(tmp_out_len),\n            ptr_string_buffer))\n        actual_len = tmp_out_len.value\n        # if buffer length is not long enough, reallocate a buffer\n        if actual_len > buffer_len:\n            string_buffer = ctypes.create_string_buffer(actual_len)\n            ptr_string_buffer = ctypes.c_char_p(*[ctypes.addressof(string_buffer)])\n            _safe_call(_LIB.LGBM_BoosterDumpModel(\n                self.handle,\n                ctypes.c_int(start_iteration),\n                ctypes.c_int(num_iteration),\n                ctypes.c_int64(actual_len),\n                ctypes.byref(tmp_out_len),\n                ptr_string_buffer))\n        ret = json.loads(string_buffer.value.decode())\n        ret['pandas_categorical'] = json.loads(json.dumps(self.pandas_categorical,\n                                                          default=json_default_with_numpy))\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmake a prediction of a set of data.", "response": "def predict(self, data, num_iteration=None,\n                raw_score=False, pred_leaf=False, pred_contrib=False,\n                data_has_header=False, is_reshape=True, **kwargs):\n        \"\"\"Make a prediction.\n\n        Parameters\n        ----------\n        data : string, numpy array, pandas DataFrame, H2O DataTable's Frame or scipy.sparse\n            Data source for prediction.\n            If string, it represents the path to txt file.\n        num_iteration : int or None, optional (default=None)\n            Limit number of iterations in the prediction.\n            If None, if the best iteration exists, it is used; otherwise, all iterations are used.\n            If <= 0, all iterations are used (no limits).\n        raw_score : bool, optional (default=False)\n            Whether to predict raw scores.\n        pred_leaf : bool, optional (default=False)\n            Whether to predict leaf index.\n        pred_contrib : bool, optional (default=False)\n            Whether to predict feature contributions.\n\n            Note\n            ----\n            If you want to get more explanations for your model's predictions using SHAP values,\n            like SHAP interaction values,\n            you can install the shap package (https://github.com/slundberg/shap).\n            Note that unlike the shap package, with ``pred_contrib`` we return a matrix with an extra\n            column, where the last column is the expected value.\n\n        data_has_header : bool, optional (default=False)\n            Whether the data has header.\n            Used only if data is string.\n        is_reshape : bool, optional (default=True)\n            If True, result is reshaped to [nrow, ncol].\n        **kwargs\n            Other parameters for the prediction.\n\n        Returns\n        -------\n        result : numpy array\n            Prediction result.\n        \"\"\"\n        predictor = self._to_predictor(copy.deepcopy(kwargs))\n        if num_iteration is None:\n            num_iteration = self.best_iteration\n        return predictor.predict(data, num_iteration,\n                                 raw_score, pred_leaf, pred_contrib,\n                                 data_has_header, is_reshape)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef refit(self, data, label, decay_rate=0.9, **kwargs):\n        if self.__set_objective_to_none:\n            raise LightGBMError('Cannot refit due to null objective function.')\n        predictor = self._to_predictor(copy.deepcopy(kwargs))\n        leaf_preds = predictor.predict(data, -1, pred_leaf=True)\n        nrow, ncol = leaf_preds.shape\n        train_set = Dataset(data, label, silent=True)\n        new_booster = Booster(self.params, train_set, silent=True)\n        # Copy models\n        _safe_call(_LIB.LGBM_BoosterMerge(\n            new_booster.handle,\n            predictor.handle))\n        leaf_preds = leaf_preds.reshape(-1)\n        ptr_data, type_ptr_data, _ = c_int_array(leaf_preds)\n        _safe_call(_LIB.LGBM_BoosterRefit(\n            new_booster.handle,\n            ptr_data,\n            ctypes.c_int(nrow),\n            ctypes.c_int(ncol)))\n        new_booster.network = self.network\n        new_booster.__attr = self.__attr.copy()\n        return new_booster", "response": "Refit the existing Booster by new data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the output of a leaf.", "response": "def get_leaf_output(self, tree_id, leaf_id):\n        \"\"\"Get the output of a leaf.\n\n        Parameters\n        ----------\n        tree_id : int\n            The index of the tree.\n        leaf_id : int\n            The index of the leaf in the tree.\n\n        Returns\n        -------\n        result : float\n            The output of the leaf.\n        \"\"\"\n        ret = ctypes.c_double(0)\n        _safe_call(_LIB.LGBM_BoosterGetLeafValue(\n            self.handle,\n            ctypes.c_int(tree_id),\n            ctypes.c_int(leaf_id),\n            ctypes.byref(ret)))\n        return ret.value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget number of features.", "response": "def num_feature(self):\n        \"\"\"Get number of features.\n\n        Returns\n        -------\n        num_feature : int\n            The number of features.\n        \"\"\"\n        out_num_feature = ctypes.c_int(0)\n        _safe_call(_LIB.LGBM_BoosterGetNumFeature(\n            self.handle,\n            ctypes.byref(out_num_feature)))\n        return out_num_feature.value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef feature_name(self):\n        num_feature = self.num_feature()\n        # Get name of features\n        tmp_out_len = ctypes.c_int(0)\n        string_buffers = [ctypes.create_string_buffer(255) for i in range_(num_feature)]\n        ptr_string_buffers = (ctypes.c_char_p * num_feature)(*map(ctypes.addressof, string_buffers))\n        _safe_call(_LIB.LGBM_BoosterGetFeatureNames(\n            self.handle,\n            ctypes.byref(tmp_out_len),\n            ptr_string_buffers))\n        if num_feature != tmp_out_len.value:\n            raise ValueError(\"Length of feature names doesn't equal with num_feature\")\n        return [string_buffers[i].value.decode() for i in range_(num_feature)]", "response": "Get names of features."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets feature importances. Parameters ---------- importance_type : string, optional (default=\"split\") How the importance is calculated. If \"split\", result contains numbers of times the feature is used in a model. If \"gain\", result contains total gains of splits which use the feature. iteration : int or None, optional (default=None) Limit number of iterations in the feature importance calculation. If None, if the best iteration exists, it is used; otherwise, all trees are used. If <= 0, all trees are used (no limits). Returns ------- result : numpy array Array with feature importances.", "response": "def feature_importance(self, importance_type='split', iteration=None):\n        \"\"\"Get feature importances.\n\n        Parameters\n        ----------\n        importance_type : string, optional (default=\"split\")\n            How the importance is calculated.\n            If \"split\", result contains numbers of times the feature is used in a model.\n            If \"gain\", result contains total gains of splits which use the feature.\n        iteration : int or None, optional (default=None)\n            Limit number of iterations in the feature importance calculation.\n            If None, if the best iteration exists, it is used; otherwise, all trees are used.\n            If <= 0, all trees are used (no limits).\n\n        Returns\n        -------\n        result : numpy array\n            Array with feature importances.\n        \"\"\"\n        if iteration is None:\n            iteration = self.best_iteration\n        if importance_type == \"split\":\n            importance_type_int = 0\n        elif importance_type == \"gain\":\n            importance_type_int = 1\n        else:\n            importance_type_int = -1\n        result = np.zeros(self.num_feature(), dtype=np.float64)\n        _safe_call(_LIB.LGBM_BoosterFeatureImportance(\n            self.handle,\n            ctypes.c_int(iteration),\n            ctypes.c_int(importance_type_int),\n            result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n        if importance_type_int == 0:\n            return result.astype(int)\n        else:\n            return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the split value histogram for the specified feature.", "response": "def get_split_value_histogram(self, feature, bins=None, xgboost_style=False):\n        \"\"\"Get split value histogram for the specified feature.\n\n        Parameters\n        ----------\n        feature : int or string\n            The feature name or index the histogram is calculated for.\n            If int, interpreted as index.\n            If string, interpreted as name.\n\n            Note\n            ----\n            Categorical features are not supported.\n\n        bins : int, string or None, optional (default=None)\n            The maximum number of bins.\n            If None, or int and > number of unique split values and ``xgboost_style=True``,\n            the number of bins equals number of unique split values.\n            If string, it should be one from the list of the supported values by ``numpy.histogram()`` function.\n        xgboost_style : bool, optional (default=False)\n            Whether the returned result should be in the same form as it is in XGBoost.\n            If False, the returned value is tuple of 2 numpy arrays as it is in ``numpy.histogram()`` function.\n            If True, the returned value is matrix, in which the first column is the right edges of non-empty bins\n            and the second one is the histogram values.\n\n        Returns\n        -------\n        result_tuple : tuple of 2 numpy arrays\n            If ``xgboost_style=False``, the values of the histogram of used splitting values for the specified feature\n            and the bin edges.\n        result_array_like : numpy array or pandas DataFrame (if pandas is installed)\n            If ``xgboost_style=True``, the histogram of used splitting values for the specified feature.\n        \"\"\"\n        def add(root):\n            \"\"\"Recursively add thresholds.\"\"\"\n            if 'split_index' in root:  # non-leaf\n                if feature_names is not None and isinstance(feature, string_type):\n                    split_feature = feature_names[root['split_feature']]\n                else:\n                    split_feature = root['split_feature']\n                if split_feature == feature:\n                    if isinstance(root['threshold'], string_type):\n                        raise LightGBMError('Cannot compute split value histogram for the categorical feature')\n                    else:\n                        values.append(root['threshold'])\n                add(root['left_child'])\n                add(root['right_child'])\n\n        model = self.dump_model()\n        feature_names = model.get('feature_names')\n        tree_infos = model['tree_info']\n        values = []\n        for tree_info in tree_infos:\n            add(tree_info['tree_structure'])\n\n        if bins is None or isinstance(bins, integer_types) and xgboost_style:\n            n_unique = len(np.unique(values))\n            bins = max(min(n_unique, bins) if bins is not None else n_unique, 1)\n        hist, bin_edges = np.histogram(values, bins=bins)\n        if xgboost_style:\n            ret = np.column_stack((bin_edges[1:], hist))\n            ret = ret[ret[:, 1] > 0]\n            if PANDAS_INSTALLED:\n                return DataFrame(ret, columns=['SplitValue', 'Count'])\n            else:\n                return ret\n        else:\n            return hist, bin_edges"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nevaluating training or validation data.", "response": "def __inner_eval(self, data_name, data_idx, feval=None):\n        \"\"\"Evaluate training or validation data.\"\"\"\n        if data_idx >= self.__num_dataset:\n            raise ValueError(\"Data_idx should be smaller than number of dataset\")\n        self.__get_eval_info()\n        ret = []\n        if self.__num_inner_eval > 0:\n            result = np.zeros(self.__num_inner_eval, dtype=np.float64)\n            tmp_out_len = ctypes.c_int(0)\n            _safe_call(_LIB.LGBM_BoosterGetEval(\n                self.handle,\n                ctypes.c_int(data_idx),\n                ctypes.byref(tmp_out_len),\n                result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n            if tmp_out_len.value != self.__num_inner_eval:\n                raise ValueError(\"Wrong length of eval results\")\n            for i in range_(self.__num_inner_eval):\n                ret.append((data_name, self.__name_inner_eval[i],\n                            result[i], self.__higher_better_inner_eval[i]))\n        if feval is not None:\n            if data_idx == 0:\n                cur_data = self.train_set\n            else:\n                cur_data = self.valid_sets[data_idx - 1]\n            feval_ret = feval(self.__inner_predict(data_idx), cur_data)\n            if isinstance(feval_ret, list):\n                for eval_name, val, is_higher_better in feval_ret:\n                    ret.append((data_name, eval_name, val, is_higher_better))\n            else:\n                eval_name, val, is_higher_better = feval_ret\n                ret.append((data_name, eval_name, val, is_higher_better))\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npredict for training and validation dataset.", "response": "def __inner_predict(self, data_idx):\n        \"\"\"Predict for training and validation dataset.\"\"\"\n        if data_idx >= self.__num_dataset:\n            raise ValueError(\"Data_idx should be smaller than number of dataset\")\n        if self.__inner_predict_buffer[data_idx] is None:\n            if data_idx == 0:\n                n_preds = self.train_set.num_data() * self.__num_class\n            else:\n                n_preds = self.valid_sets[data_idx - 1].num_data() * self.__num_class\n            self.__inner_predict_buffer[data_idx] = np.zeros(n_preds, dtype=np.float64)\n        # avoid to predict many time in one iteration\n        if not self.__is_predicted_cur_iter[data_idx]:\n            tmp_out_len = ctypes.c_int64(0)\n            data_ptr = self.__inner_predict_buffer[data_idx].ctypes.data_as(ctypes.POINTER(ctypes.c_double))\n            _safe_call(_LIB.LGBM_BoosterGetPredict(\n                self.handle,\n                ctypes.c_int(data_idx),\n                ctypes.byref(tmp_out_len),\n                data_ptr))\n            if tmp_out_len.value != len(self.__inner_predict_buffer[data_idx]):\n                raise ValueError(\"Wrong length of predict results for data %d\" % (data_idx))\n            self.__is_predicted_cur_iter[data_idx] = True\n        return self.__inner_predict_buffer[data_idx]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets inner evaluation count and names.", "response": "def __get_eval_info(self):\n        \"\"\"Get inner evaluation count and names.\"\"\"\n        if self.__need_reload_eval_info:\n            self.__need_reload_eval_info = False\n            out_num_eval = ctypes.c_int(0)\n            # Get num of inner evals\n            _safe_call(_LIB.LGBM_BoosterGetEvalCounts(\n                self.handle,\n                ctypes.byref(out_num_eval)))\n            self.__num_inner_eval = out_num_eval.value\n            if self.__num_inner_eval > 0:\n                # Get name of evals\n                tmp_out_len = ctypes.c_int(0)\n                string_buffers = [ctypes.create_string_buffer(255) for i in range_(self.__num_inner_eval)]\n                ptr_string_buffers = (ctypes.c_char_p * self.__num_inner_eval)(*map(ctypes.addressof, string_buffers))\n                _safe_call(_LIB.LGBM_BoosterGetEvalNames(\n                    self.handle,\n                    ctypes.byref(tmp_out_len),\n                    ptr_string_buffers))\n                if self.__num_inner_eval != tmp_out_len.value:\n                    raise ValueError(\"Length of eval names doesn't equal with num_evals\")\n                self.__name_inner_eval = \\\n                    [string_buffers[i].value.decode() for i in range_(self.__num_inner_eval)]\n                self.__higher_better_inner_eval = \\\n                    [name.startswith(('auc', 'ndcg@', 'map@')) for name in self.__name_inner_eval]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_attr(self, **kwargs):\n        for key, value in kwargs.items():\n            if value is not None:\n                if not isinstance(value, string_type):\n                    raise ValueError(\"Only string values are accepted\")\n                self.__attr[key] = value\n            else:\n                self.__attr.pop(key, None)\n        return self", "response": "Set attributes to the Booster."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the path to LightGBM library files.", "response": "def find_lib_path():\n    \"\"\"Find the path to LightGBM library files.\n\n    Returns\n    -------\n    lib_path: list of strings\n       List of all found library paths to LightGBM.\n    \"\"\"\n    if os.environ.get('LIGHTGBM_BUILD_DOC', False):\n        # we don't need lib_lightgbm while building docs\n        return []\n\n    curr_path = os.path.dirname(os.path.abspath(os.path.expanduser(__file__)))\n    dll_path = [curr_path,\n                os.path.join(curr_path, '../../'),\n                os.path.join(curr_path, 'compile'),\n                os.path.join(curr_path, '../compile'),\n                os.path.join(curr_path, '../../lib/')]\n    if system() in ('Windows', 'Microsoft'):\n        dll_path.append(os.path.join(curr_path, '../compile/Release/'))\n        dll_path.append(os.path.join(curr_path, '../compile/windows/x64/DLL/'))\n        dll_path.append(os.path.join(curr_path, '../../Release/'))\n        dll_path.append(os.path.join(curr_path, '../../windows/x64/DLL/'))\n        dll_path = [os.path.join(p, 'lib_lightgbm.dll') for p in dll_path]\n    else:\n        dll_path = [os.path.join(p, 'lib_lightgbm.so') for p in dll_path]\n    lib_path = [p for p in dll_path if os.path.exists(p) and os.path.isfile(p)]\n    if not lib_path:\n        dll_path = [os.path.realpath(p) for p in dll_path]\n        raise Exception('Cannot find lightgbm library file in following paths:\\n' + '\\n'.join(dll_path))\n    return lib_path"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef json_default_with_numpy(obj):\n    if isinstance(obj, (np.integer, np.floating, np.bool_)):\n        return obj.item()\n    elif isinstance(obj, np.ndarray):\n        return obj.tolist()\n    else:\n        return obj", "response": "Convert numpy classes to JSON serializable objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a callback that prints the evaluation results.", "response": "def print_evaluation(period=1, show_stdv=True):\n    \"\"\"Create a callback that prints the evaluation results.\n\n    Parameters\n    ----------\n    period : int, optional (default=1)\n        The period to print the evaluation results.\n    show_stdv : bool, optional (default=True)\n        Whether to show stdv (if provided).\n\n    Returns\n    -------\n    callback : function\n        The callback that prints the evaluation results every ``period`` iteration(s).\n    \"\"\"\n    def _callback(env):\n        if period > 0 and env.evaluation_result_list and (env.iteration + 1) % period == 0:\n            result = '\\t'.join([_format_eval_result(x, show_stdv) for x in env.evaluation_result_list])\n            print('[%d]\\t%s' % (env.iteration + 1, result))\n    _callback.order = 10\n    return _callback"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a callback that records the evaluation history into the passed dictionary.", "response": "def record_evaluation(eval_result):\n    \"\"\"Create a callback that records the evaluation history into ``eval_result``.\n\n    Parameters\n    ----------\n    eval_result : dict\n       A dictionary to store the evaluation results.\n\n    Returns\n    -------\n    callback : function\n        The callback that records the evaluation history into the passed dictionary.\n    \"\"\"\n    if not isinstance(eval_result, dict):\n        raise TypeError('Eval_result should be a dictionary')\n    eval_result.clear()\n\n    def _init(env):\n        for data_name, _, _, _ in env.evaluation_result_list:\n            eval_result.setdefault(data_name, collections.defaultdict(list))\n\n    def _callback(env):\n        if not eval_result:\n            _init(env)\n        for data_name, eval_name, result, _ in env.evaluation_result_list:\n            eval_result[data_name][eval_name].append(result)\n    _callback.order = 20\n    return _callback"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a callback that resets the parameter after the first iteration.", "response": "def reset_parameter(**kwargs):\n    \"\"\"Create a callback that resets the parameter after the first iteration.\n\n    Note\n    ----\n    The initial parameter will still take in-effect on first iteration.\n\n    Parameters\n    ----------\n    **kwargs : value should be list or function\n        List of parameters for each boosting round\n        or a customized function that calculates the parameter in terms of\n        current number of round (e.g. yields learning rate decay).\n        If list lst, parameter = lst[current_round].\n        If function func, parameter = func(current_round).\n\n    Returns\n    -------\n    callback : function\n        The callback that resets the parameter after the first iteration.\n    \"\"\"\n    def _callback(env):\n        new_parameters = {}\n        for key, value in kwargs.items():\n            if key in ['num_class', 'num_classes',\n                       'boosting', 'boost', 'boosting_type',\n                       'metric', 'metrics', 'metric_types']:\n                raise RuntimeError(\"cannot reset {} during training\".format(repr(key)))\n            if isinstance(value, list):\n                if len(value) != env.end_iteration - env.begin_iteration:\n                    raise ValueError(\"Length of list {} has to equal to 'num_boost_round'.\"\n                                     .format(repr(key)))\n                new_param = value[env.iteration - env.begin_iteration]\n            else:\n                new_param = value(env.iteration - env.begin_iteration)\n            if new_param != env.params.get(key, None):\n                new_parameters[key] = new_param\n        if new_parameters:\n            env.model.reset_parameter(new_parameters)\n            env.params.update(new_parameters)\n    _callback.before_iteration = True\n    _callback.order = 10\n    return _callback"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef early_stopping(stopping_rounds, first_metric_only=False, verbose=True):\n    best_score = []\n    best_iter = []\n    best_score_list = []\n    cmp_op = []\n    enabled = [True]\n\n    def _init(env):\n        enabled[0] = not any((boost_alias in env.params\n                              and env.params[boost_alias] == 'dart') for boost_alias in ('boosting',\n                                                                                         'boosting_type',\n                                                                                         'boost'))\n        if not enabled[0]:\n            warnings.warn('Early stopping is not available in dart mode')\n            return\n        if not env.evaluation_result_list:\n            raise ValueError('For early stopping, '\n                             'at least one dataset and eval metric is required for evaluation')\n\n        if verbose:\n            msg = \"Training until validation scores don't improve for {} rounds.\"\n            print(msg.format(stopping_rounds))\n\n        for eval_ret in env.evaluation_result_list:\n            best_iter.append(0)\n            best_score_list.append(None)\n            if eval_ret[3]:\n                best_score.append(float('-inf'))\n                cmp_op.append(gt)\n            else:\n                best_score.append(float('inf'))\n                cmp_op.append(lt)\n\n    def _callback(env):\n        if not cmp_op:\n            _init(env)\n        if not enabled[0]:\n            return\n        for i in range_(len(env.evaluation_result_list)):\n            score = env.evaluation_result_list[i][2]\n            if best_score_list[i] is None or cmp_op[i](score, best_score[i]):\n                best_score[i] = score\n                best_iter[i] = env.iteration\n                best_score_list[i] = env.evaluation_result_list\n            elif env.iteration - best_iter[i] >= stopping_rounds:\n                if verbose:\n                    print('Early stopping, best iteration is:\\n[%d]\\t%s' % (\n                        best_iter[i] + 1, '\\t'.join([_format_eval_result(x) for x in best_score_list[i]])))\n                raise EarlyStopException(best_iter[i], best_score_list[i])\n            if env.iteration == env.end_iteration - 1:\n                if verbose:\n                    print('Did not meet early stopping. Best iteration is:\\n[%d]\\t%s' % (\n                        best_iter[i] + 1, '\\t'.join([_format_eval_result(x) for x in best_score_list[i]])))\n                raise EarlyStopException(best_iter[i], best_score_list[i])\n            if first_metric_only:  # the only first metric is used for early stopping\n                break\n    _callback.order = 30\n    return _callback", "response": "Create a callback that activates early stopping."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef train(params, train_set, num_boost_round=100,\n          valid_sets=None, valid_names=None,\n          fobj=None, feval=None, init_model=None,\n          feature_name='auto', categorical_feature='auto',\n          early_stopping_rounds=None, evals_result=None,\n          verbose_eval=True, learning_rates=None,\n          keep_training_booster=False, callbacks=None):\n    \"\"\"Perform the training with given parameters.\n\n    Parameters\n    ----------\n    params : dict\n        Parameters for training.\n    train_set : Dataset\n        Data to be trained on.\n    num_boost_round : int, optional (default=100)\n        Number of boosting iterations.\n    valid_sets : list of Datasets or None, optional (default=None)\n        List of data to be evaluated on during training.\n    valid_names : list of strings or None, optional (default=None)\n        Names of ``valid_sets``.\n    fobj : callable or None, optional (default=None)\n        Customized objective function.\n    feval : callable or None, optional (default=None)\n        Customized evaluation function.\n        Should accept two parameters: preds, train_data,\n        and return (eval_name, eval_result, is_higher_better) or list of such tuples.\n        For multi-class task, the preds is group by class_id first, then group by row_id.\n        If you want to get i-th row preds in j-th class, the access way is preds[j * num_data + i].\n        To ignore the default metric corresponding to the used objective,\n        set the ``metric`` parameter to the string ``\"None\"`` in ``params``.\n    init_model : string, Booster or None, optional (default=None)\n        Filename of LightGBM model or Booster instance used for continue training.\n    feature_name : list of strings or 'auto', optional (default=\"auto\")\n        Feature names.\n        If 'auto' and data is pandas DataFrame, data columns names are used.\n    categorical_feature : list of strings or int, or 'auto', optional (default=\"auto\")\n        Categorical features.\n        If list of int, interpreted as indices.\n        If list of strings, interpreted as feature names (need to specify ``feature_name`` as well).\n        If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n        All values in categorical features should be less than int32 max value (2147483647).\n        Large values could be memory consuming. Consider using consecutive integers starting from zero.\n        All negative values in categorical features will be treated as missing values.\n    early_stopping_rounds : int or None, optional (default=None)\n        Activates early stopping. The model will train until the validation score stops improving.\n        Validation score needs to improve at least every ``early_stopping_rounds`` round(s)\n        to continue training.\n        Requires at least one validation data and one metric.\n        If there's more than one, will check all of them. But the training data is ignored anyway.\n        To check only the first metric you can pass in ``callbacks``\n        ``early_stopping`` callback with ``first_metric_only=True``.\n        The index of iteration that has the best performance will be saved in the ``best_iteration`` field\n        if early stopping logic is enabled by setting ``early_stopping_rounds``.\n    evals_result: dict or None, optional (default=None)\n        This dictionary used to store all evaluation results of all the items in ``valid_sets``.\n\n        Example\n        -------\n        With a ``valid_sets`` = [valid_set, train_set],\n        ``valid_names`` = ['eval', 'train']\n        and a ``params`` = {'metric': 'logloss'}\n        returns {'train': {'logloss': ['0.48253', '0.35953', ...]},\n        'eval': {'logloss': ['0.480385', '0.357756', ...]}}.\n\n    verbose_eval : bool or int, optional (default=True)\n        Requires at least one validation data.\n        If True, the eval metric on the valid set is printed at each boosting stage.\n        If int, the eval metric on the valid set is printed at every ``verbose_eval`` boosting stage.\n        The last boosting stage or the boosting stage found by using ``early_stopping_rounds`` is also printed.\n\n        Example\n        -------\n        With ``verbose_eval`` = 4 and at least one item in ``valid_sets``,\n        an evaluation metric is printed every 4 (instead of 1) boosting stages.\n\n    learning_rates : list, callable or None, optional (default=None)\n        List of learning rates for each boosting round\n        or a customized function that calculates ``learning_rate``\n        in terms of current number of round (e.g. yields learning rate decay).\n    keep_training_booster : bool, optional (default=False)\n        Whether the returned Booster will be used to keep training.\n        If False, the returned value will be converted into _InnerPredictor before returning.\n        You can still use _InnerPredictor as ``init_model`` for future continue training.\n    callbacks : list of callables or None, optional (default=None)\n        List of callback functions that are applied at each iteration.\n        See Callbacks in Python API for more information.\n\n    Returns\n    -------\n    booster : Booster\n        The trained Booster model.\n    \"\"\"\n    # create predictor first\n    params = copy.deepcopy(params)\n    if fobj is not None:\n        params['objective'] = 'none'\n    for alias in [\"num_iterations\", \"num_iteration\", \"n_iter\", \"num_tree\", \"num_trees\",\n                  \"num_round\", \"num_rounds\", \"num_boost_round\", \"n_estimators\"]:\n        if alias in params:\n            num_boost_round = int(params.pop(alias))\n            warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n            break\n    for alias in [\"early_stopping_round\", \"early_stopping_rounds\", \"early_stopping\"]:\n        if alias in params and params[alias] is not None:\n            early_stopping_rounds = int(params.pop(alias))\n            warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n            break\n\n    if num_boost_round <= 0:\n        raise ValueError(\"num_boost_round should be greater than zero.\")\n    if isinstance(init_model, string_type):\n        predictor = _InnerPredictor(model_file=init_model, pred_parameter=params)\n    elif isinstance(init_model, Booster):\n        predictor = init_model._to_predictor(dict(init_model.params, **params))\n    else:\n        predictor = None\n    init_iteration = predictor.num_total_iteration if predictor is not None else 0\n    # check dataset\n    if not isinstance(train_set, Dataset):\n        raise TypeError(\"Training only accepts Dataset object\")\n\n    train_set._update_params(params) \\\n             ._set_predictor(predictor) \\\n             .set_feature_name(feature_name) \\\n             .set_categorical_feature(categorical_feature)\n\n    is_valid_contain_train = False\n    train_data_name = \"training\"\n    reduced_valid_sets = []\n    name_valid_sets = []\n    if valid_sets is not None:\n        if isinstance(valid_sets, Dataset):\n            valid_sets = [valid_sets]\n        if isinstance(valid_names, string_type):\n            valid_names = [valid_names]\n        for i, valid_data in enumerate(valid_sets):\n            # reduce cost for prediction training data\n            if valid_data is train_set:\n                is_valid_contain_train = True\n                if valid_names is not None:\n                    train_data_name = valid_names[i]\n                continue\n            if not isinstance(valid_data, Dataset):\n                raise TypeError(\"Traninig only accepts Dataset object\")\n            reduced_valid_sets.append(valid_data._update_params(params).set_reference(train_set))\n            if valid_names is not None and len(valid_names) > i:\n                name_valid_sets.append(valid_names[i])\n            else:\n                name_valid_sets.append('valid_' + str(i))\n    # process callbacks\n    if callbacks is None:\n        callbacks = set()\n    else:\n        for i, cb in enumerate(callbacks):\n            cb.__dict__.setdefault('order', i - len(callbacks))\n        callbacks = set(callbacks)\n\n    # Most of legacy advanced options becomes callbacks\n    if verbose_eval is True:\n        callbacks.add(callback.print_evaluation())\n    elif isinstance(verbose_eval, integer_types):\n        callbacks.add(callback.print_evaluation(verbose_eval))\n\n    if early_stopping_rounds is not None:\n        callbacks.add(callback.early_stopping(early_stopping_rounds, verbose=bool(verbose_eval)))\n\n    if learning_rates is not None:\n        callbacks.add(callback.reset_parameter(learning_rate=learning_rates))\n\n    if evals_result is not None:\n        callbacks.add(callback.record_evaluation(evals_result))\n\n    callbacks_before_iter = {cb for cb in callbacks if getattr(cb, 'before_iteration', False)}\n    callbacks_after_iter = callbacks - callbacks_before_iter\n    callbacks_before_iter = sorted(callbacks_before_iter, key=attrgetter('order'))\n    callbacks_after_iter = sorted(callbacks_after_iter, key=attrgetter('order'))\n\n    # construct booster\n    try:\n        booster = Booster(params=params, train_set=train_set)\n        if is_valid_contain_train:\n            booster.set_train_data_name(train_data_name)\n        for valid_set, name_valid_set in zip_(reduced_valid_sets, name_valid_sets):\n            booster.add_valid(valid_set, name_valid_set)\n    finally:\n        train_set._reverse_update_params()\n        for valid_set in reduced_valid_sets:\n            valid_set._reverse_update_params()\n    booster.best_iteration = 0\n\n    # start training\n    for i in range_(init_iteration, init_iteration + num_boost_round):\n        for cb in callbacks_before_iter:\n            cb(callback.CallbackEnv(model=booster,\n                                    params=params,\n                                    iteration=i,\n                                    begin_iteration=init_iteration,\n                                    end_iteration=init_iteration + num_boost_round,\n                                    evaluation_result_list=None))\n\n        booster.update(fobj=fobj)\n\n        evaluation_result_list = []\n        # check evaluation result.\n        if valid_sets is not None:\n            if is_valid_contain_train:\n                evaluation_result_list.extend(booster.eval_train(feval))\n            evaluation_result_list.extend(booster.eval_valid(feval))\n        try:\n            for cb in callbacks_after_iter:\n                cb(callback.CallbackEnv(model=booster,\n                                        params=params,\n                                        iteration=i,\n                                        begin_iteration=init_iteration,\n                                        end_iteration=init_iteration + num_boost_round,\n                                        evaluation_result_list=evaluation_result_list))\n        except callback.EarlyStopException as earlyStopException:\n            booster.best_iteration = earlyStopException.best_iteration + 1\n            evaluation_result_list = earlyStopException.best_score\n            break\n    booster.best_score = collections.defaultdict(dict)\n    for dataset_name, eval_name, score, _ in evaluation_result_list:\n        booster.best_score[dataset_name][eval_name] = score\n    if not keep_training_booster:\n        booster.model_from_string(booster.model_to_string(), False).free_dataset()\n    return booster", "response": "Perform the training on a set of data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking a n - fold list of Booster from random indices.", "response": "def _make_n_folds(full_data, folds, nfold, params, seed, fpreproc=None, stratified=True,\n                  shuffle=True, eval_train_metric=False):\n    \"\"\"Make a n-fold list of Booster from random indices.\"\"\"\n    full_data = full_data.construct()\n    num_data = full_data.num_data()\n    if folds is not None:\n        if not hasattr(folds, '__iter__') and not hasattr(folds, 'split'):\n            raise AttributeError(\"folds should be a generator or iterator of (train_idx, test_idx) tuples \"\n                                 \"or scikit-learn splitter object with split method\")\n        if hasattr(folds, 'split'):\n            group_info = full_data.get_group()\n            if group_info is not None:\n                group_info = group_info.astype(int)\n                flatted_group = np.repeat(range_(len(group_info)), repeats=group_info)\n            else:\n                flatted_group = np.zeros(num_data, dtype=int)\n            folds = folds.split(X=np.zeros(num_data), y=full_data.get_label(), groups=flatted_group)\n    else:\n        if 'objective' in params and params['objective'] == 'lambdarank':\n            if not SKLEARN_INSTALLED:\n                raise LightGBMError('Scikit-learn is required for lambdarank cv.')\n            # lambdarank task, split according to groups\n            group_info = full_data.get_group().astype(int)\n            flatted_group = np.repeat(range_(len(group_info)), repeats=group_info)\n            group_kfold = _LGBMGroupKFold(n_splits=nfold)\n            folds = group_kfold.split(X=np.zeros(num_data), groups=flatted_group)\n        elif stratified:\n            if not SKLEARN_INSTALLED:\n                raise LightGBMError('Scikit-learn is required for stratified cv.')\n            skf = _LGBMStratifiedKFold(n_splits=nfold, shuffle=shuffle, random_state=seed)\n            folds = skf.split(X=np.zeros(num_data), y=full_data.get_label())\n        else:\n            if shuffle:\n                randidx = np.random.RandomState(seed).permutation(num_data)\n            else:\n                randidx = np.arange(num_data)\n            kstep = int(num_data / nfold)\n            test_id = [randidx[i: i + kstep] for i in range_(0, num_data, kstep)]\n            train_id = [np.concatenate([test_id[i] for i in range_(nfold) if k != i]) for k in range_(nfold)]\n            folds = zip_(train_id, test_id)\n\n    ret = _CVBooster()\n    for train_idx, test_idx in folds:\n        train_set = full_data.subset(train_idx)\n        valid_set = full_data.subset(test_idx)\n        # run preprocessing on the data set if needed\n        if fpreproc is not None:\n            train_set, valid_set, tparam = fpreproc(train_set, valid_set, params.copy())\n        else:\n            tparam = params\n        cvbooster = Booster(tparam, train_set)\n        if eval_train_metric:\n            cvbooster.add_valid(train_set, 'train')\n        cvbooster.add_valid(valid_set, 'valid')\n        ret.append(cvbooster)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _agg_cv_result(raw_results, eval_train_metric=False):\n    cvmap = collections.defaultdict(list)\n    metric_type = {}\n    for one_result in raw_results:\n        for one_line in one_result:\n            if eval_train_metric:\n                key = \"{} {}\".format(one_line[0], one_line[1])\n            else:\n                key = one_line[1]\n            metric_type[key] = one_line[3]\n            cvmap[key].append(one_line[2])\n    return [('cv_agg', k, np.mean(v), metric_type[k], np.std(v)) for k, v in cvmap.items()]", "response": "Aggregate cross - validation results."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cv(params, train_set, num_boost_round=100,\n       folds=None, nfold=5, stratified=True, shuffle=True,\n       metrics=None, fobj=None, feval=None, init_model=None,\n       feature_name='auto', categorical_feature='auto',\n       early_stopping_rounds=None, fpreproc=None,\n       verbose_eval=None, show_stdv=True, seed=0,\n       callbacks=None, eval_train_metric=False):\n    \"\"\"Perform the cross-validation with given paramaters.\n\n    Parameters\n    ----------\n    params : dict\n        Parameters for Booster.\n    train_set : Dataset\n        Data to be trained on.\n    num_boost_round : int, optional (default=100)\n        Number of boosting iterations.\n    folds : generator or iterator of (train_idx, test_idx) tuples, scikit-learn splitter object or None, optional (default=None)\n        If generator or iterator, it should yield the train and test indices for each fold.\n        If object, it should be one of the scikit-learn splitter classes\n        (https://scikit-learn.org/stable/modules/classes.html#splitter-classes)\n        and have ``split`` method.\n        This argument has highest priority over other data split arguments.\n    nfold : int, optional (default=5)\n        Number of folds in CV.\n    stratified : bool, optional (default=True)\n        Whether to perform stratified sampling.\n    shuffle : bool, optional (default=True)\n        Whether to shuffle before splitting data.\n    metrics : string, list of strings or None, optional (default=None)\n        Evaluation metrics to be monitored while CV.\n        If not None, the metric in ``params`` will be overridden.\n    fobj : callable or None, optional (default=None)\n        Custom objective function.\n    feval : callable or None, optional (default=None)\n        Customized evaluation function.\n        Should accept two parameters: preds, train_data,\n        and return (eval_name, eval_result, is_higher_better) or list of such tuples.\n        For multi-class task, the preds is group by class_id first, then group by row_id.\n        If you want to get i-th row preds in j-th class, the access way is preds[j * num_data + i].\n        To ignore the default metric corresponding to the used objective,\n        set ``metrics`` to the string ``\"None\"``.\n    init_model : string, Booster or None, optional (default=None)\n        Filename of LightGBM model or Booster instance used for continue training.\n    feature_name : list of strings or 'auto', optional (default=\"auto\")\n        Feature names.\n        If 'auto' and data is pandas DataFrame, data columns names are used.\n    categorical_feature : list of strings or int, or 'auto', optional (default=\"auto\")\n        Categorical features.\n        If list of int, interpreted as indices.\n        If list of strings, interpreted as feature names (need to specify ``feature_name`` as well).\n        If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n        All values in categorical features should be less than int32 max value (2147483647).\n        Large values could be memory consuming. Consider using consecutive integers starting from zero.\n        All negative values in categorical features will be treated as missing values.\n    early_stopping_rounds : int or None, optional (default=None)\n        Activates early stopping.\n        CV score needs to improve at least every ``early_stopping_rounds`` round(s)\n        to continue.\n        Requires at least one metric. If there's more than one, will check all of them.\n        To check only the first metric you can pass in ``callbacks``\n        ``early_stopping`` callback with ``first_metric_only=True``.\n        Last entry in evaluation history is the one from the best iteration.\n    fpreproc : callable or None, optional (default=None)\n        Preprocessing function that takes (dtrain, dtest, params)\n        and returns transformed versions of those.\n    verbose_eval : bool, int, or None, optional (default=None)\n        Whether to display the progress.\n        If None, progress will be displayed when np.ndarray is returned.\n        If True, progress will be displayed at every boosting stage.\n        If int, progress will be displayed at every given ``verbose_eval`` boosting stage.\n    show_stdv : bool, optional (default=True)\n        Whether to display the standard deviation in progress.\n        Results are not affected by this parameter, and always contain std.\n    seed : int, optional (default=0)\n        Seed used to generate the folds (passed to numpy.random.seed).\n    callbacks : list of callables or None, optional (default=None)\n        List of callback functions that are applied at each iteration.\n        See Callbacks in Python API for more information.\n    eval_train_metric : bool, optional (default=False)\n        Whether to display the train metric in progress.\n        The score of the metric is calculated again after each training step, so there is some impact on performance.\n\n    Returns\n    -------\n    eval_hist : dict\n        Evaluation history.\n        The dictionary has the following format:\n        {'metric1-mean': [values], 'metric1-stdv': [values],\n        'metric2-mean': [values], 'metric2-stdv': [values],\n        ...}.\n    \"\"\"\n    if not isinstance(train_set, Dataset):\n        raise TypeError(\"Traninig only accepts Dataset object\")\n\n    params = copy.deepcopy(params)\n    if fobj is not None:\n        params['objective'] = 'none'\n    for alias in [\"num_iterations\", \"num_iteration\", \"n_iter\", \"num_tree\", \"num_trees\",\n                  \"num_round\", \"num_rounds\", \"num_boost_round\", \"n_estimators\"]:\n        if alias in params:\n            warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n            num_boost_round = params.pop(alias)\n            break\n    for alias in [\"early_stopping_round\", \"early_stopping_rounds\", \"early_stopping\"]:\n        if alias in params:\n            warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n            early_stopping_rounds = params.pop(alias)\n            break\n\n    if num_boost_round <= 0:\n        raise ValueError(\"num_boost_round should be greater than zero.\")\n    if isinstance(init_model, string_type):\n        predictor = _InnerPredictor(model_file=init_model, pred_parameter=params)\n    elif isinstance(init_model, Booster):\n        predictor = init_model._to_predictor(dict(init_model.params, **params))\n    else:\n        predictor = None\n    train_set._update_params(params) \\\n             ._set_predictor(predictor) \\\n             .set_feature_name(feature_name) \\\n             .set_categorical_feature(categorical_feature)\n\n    if metrics is not None:\n        params['metric'] = metrics\n\n    results = collections.defaultdict(list)\n    cvfolds = _make_n_folds(train_set, folds=folds, nfold=nfold,\n                            params=params, seed=seed, fpreproc=fpreproc,\n                            stratified=stratified, shuffle=shuffle,\n                            eval_train_metric=eval_train_metric)\n\n    # setup callbacks\n    if callbacks is None:\n        callbacks = set()\n    else:\n        for i, cb in enumerate(callbacks):\n            cb.__dict__.setdefault('order', i - len(callbacks))\n        callbacks = set(callbacks)\n    if early_stopping_rounds is not None:\n        callbacks.add(callback.early_stopping(early_stopping_rounds, verbose=False))\n    if verbose_eval is True:\n        callbacks.add(callback.print_evaluation(show_stdv=show_stdv))\n    elif isinstance(verbose_eval, integer_types):\n        callbacks.add(callback.print_evaluation(verbose_eval, show_stdv=show_stdv))\n\n    callbacks_before_iter = {cb for cb in callbacks if getattr(cb, 'before_iteration', False)}\n    callbacks_after_iter = callbacks - callbacks_before_iter\n    callbacks_before_iter = sorted(callbacks_before_iter, key=attrgetter('order'))\n    callbacks_after_iter = sorted(callbacks_after_iter, key=attrgetter('order'))\n\n    for i in range_(num_boost_round):\n        for cb in callbacks_before_iter:\n            cb(callback.CallbackEnv(model=cvfolds,\n                                    params=params,\n                                    iteration=i,\n                                    begin_iteration=0,\n                                    end_iteration=num_boost_round,\n                                    evaluation_result_list=None))\n        cvfolds.update(fobj=fobj)\n        res = _agg_cv_result(cvfolds.eval_valid(feval), eval_train_metric)\n        for _, key, mean, _, std in res:\n            results[key + '-mean'].append(mean)\n            results[key + '-stdv'].append(std)\n        try:\n            for cb in callbacks_after_iter:\n                cb(callback.CallbackEnv(model=cvfolds,\n                                        params=params,\n                                        iteration=i,\n                                        begin_iteration=0,\n                                        end_iteration=num_boost_round,\n                                        evaluation_result_list=res))\n        except callback.EarlyStopException as earlyStopException:\n            cvfolds.best_iteration = earlyStopException.best_iteration + 1\n            for k in results:\n                results[k] = results[k][:cvfolds.best_iteration]\n            break\n    return dict(results)", "response": "Perform cross - validation with given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the performance of an objective.", "response": "def experiment(objective, label_type, data):\n    \"\"\"Measure performance of an objective.\n\n    Parameters\n    ----------\n    objective : string 'binary' or 'xentropy'\n        Objective function.\n    label_type : string 'binary' or 'probability'\n        Type of the label.\n    data : dict\n        Data for training.\n\n    Returns\n    -------\n    result : dict\n        Experiment summary stats.\n    \"\"\"\n    np.random.seed(0)\n    nrounds = 5\n    lgb_data = data['lgb_with_' + label_type + '_labels']\n    params = {\n        'objective': objective,\n        'feature_fraction': 1,\n        'bagging_fraction': 1,\n        'verbose': -1\n    }\n    time_zero = time.time()\n    gbm = lgb.train(params, lgb_data, num_boost_round=nrounds)\n    y_fitted = gbm.predict(data['X'])\n    y_true = data[label_type + '_labels']\n    duration = time.time() - time_zero\n    return {\n        'time': duration,\n        'correlation': np.corrcoef(y_fitted, y_true)[0, 1],\n        'logloss': log_loss(y_fitted, y_true)\n    }"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_not_tuple_of_2_elements(obj, obj_name='obj'):\n    if not isinstance(obj, tuple) or len(obj) != 2:\n        raise TypeError('%s must be a tuple of 2 elements.' % obj_name)", "response": "Check that the object is not tuple of 2 elements."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_importance(booster, ax=None, height=0.2,\n                    xlim=None, ylim=None, title='Feature importance',\n                    xlabel='Feature importance', ylabel='Features',\n                    importance_type='split', max_num_features=None,\n                    ignore_zero=True, figsize=None, grid=True,\n                    precision=None, **kwargs):\n    \"\"\"Plot model's feature importances.\n\n    Parameters\n    ----------\n    booster : Booster or LGBMModel\n        Booster or LGBMModel instance which feature importance should be plotted.\n    ax : matplotlib.axes.Axes or None, optional (default=None)\n        Target axes instance.\n        If None, new figure and axes will be created.\n    height : float, optional (default=0.2)\n        Bar height, passed to ``ax.barh()``.\n    xlim : tuple of 2 elements or None, optional (default=None)\n        Tuple passed to ``ax.xlim()``.\n    ylim : tuple of 2 elements or None, optional (default=None)\n        Tuple passed to ``ax.ylim()``.\n    title : string or None, optional (default=\"Feature importance\")\n        Axes title.\n        If None, title is disabled.\n    xlabel : string or None, optional (default=\"Feature importance\")\n        X-axis title label.\n        If None, title is disabled.\n    ylabel : string or None, optional (default=\"Features\")\n        Y-axis title label.\n        If None, title is disabled.\n    importance_type : string, optional (default=\"split\")\n        How the importance is calculated.\n        If \"split\", result contains numbers of times the feature is used in a model.\n        If \"gain\", result contains total gains of splits which use the feature.\n    max_num_features : int or None, optional (default=None)\n        Max number of top features displayed on plot.\n        If None or <1, all features will be displayed.\n    ignore_zero : bool, optional (default=True)\n        Whether to ignore features with zero importance.\n    figsize : tuple of 2 elements or None, optional (default=None)\n        Figure size.\n    grid : bool, optional (default=True)\n        Whether to add a grid for axes.\n    precision : int or None, optional (default=None)\n        Used to restrict the display of floating point values to a certain precision.\n    **kwargs\n        Other parameters passed to ``ax.barh()``.\n\n    Returns\n    -------\n    ax : matplotlib.axes.Axes\n        The plot with model's feature importances.\n    \"\"\"\n    if MATPLOTLIB_INSTALLED:\n        import matplotlib.pyplot as plt\n    else:\n        raise ImportError('You must install matplotlib to plot importance.')\n\n    if isinstance(booster, LGBMModel):\n        booster = booster.booster_\n    elif not isinstance(booster, Booster):\n        raise TypeError('booster must be Booster or LGBMModel.')\n\n    importance = booster.feature_importance(importance_type=importance_type)\n    feature_name = booster.feature_name()\n\n    if not len(importance):\n        raise ValueError(\"Booster's feature_importance is empty.\")\n\n    tuples = sorted(zip_(feature_name, importance), key=lambda x: x[1])\n    if ignore_zero:\n        tuples = [x for x in tuples if x[1] > 0]\n    if max_num_features is not None and max_num_features > 0:\n        tuples = tuples[-max_num_features:]\n    labels, values = zip_(*tuples)\n\n    if ax is None:\n        if figsize is not None:\n            _check_not_tuple_of_2_elements(figsize, 'figsize')\n        _, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ylocs = np.arange(len(values))\n    ax.barh(ylocs, values, align='center', height=height, **kwargs)\n\n    for x, y in zip_(values, ylocs):\n        ax.text(x + 1, y,\n                _float2str(x, precision) if importance_type == 'gain' else x,\n                va='center')\n\n    ax.set_yticks(ylocs)\n    ax.set_yticklabels(labels)\n\n    if xlim is not None:\n        _check_not_tuple_of_2_elements(xlim, 'xlim')\n    else:\n        xlim = (0, max(values) * 1.1)\n    ax.set_xlim(xlim)\n\n    if ylim is not None:\n        _check_not_tuple_of_2_elements(ylim, 'ylim')\n    else:\n        ylim = (-1, len(values))\n    ax.set_ylim(ylim)\n\n    if title is not None:\n        ax.set_title(title)\n    if xlabel is not None:\n        ax.set_xlabel(xlabel)\n    if ylabel is not None:\n        ax.set_ylabel(ylabel)\n    ax.grid(grid)\n    return ax", "response": "Plot the feature importances of the current model."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot one metric during training.", "response": "def plot_metric(booster, metric=None, dataset_names=None,\n                ax=None, xlim=None, ylim=None,\n                title='Metric during training',\n                xlabel='Iterations', ylabel='auto',\n                figsize=None, grid=True):\n    \"\"\"Plot one metric during training.\n\n    Parameters\n    ----------\n    booster : dict or LGBMModel\n        Dictionary returned from ``lightgbm.train()`` or LGBMModel instance.\n    metric : string or None, optional (default=None)\n        The metric name to plot.\n        Only one metric supported because different metrics have various scales.\n        If None, first metric picked from dictionary (according to hashcode).\n    dataset_names : list of strings or None, optional (default=None)\n        List of the dataset names which are used to calculate metric to plot.\n        If None, all datasets are used.\n    ax : matplotlib.axes.Axes or None, optional (default=None)\n        Target axes instance.\n        If None, new figure and axes will be created.\n    xlim : tuple of 2 elements or None, optional (default=None)\n        Tuple passed to ``ax.xlim()``.\n    ylim : tuple of 2 elements or None, optional (default=None)\n        Tuple passed to ``ax.ylim()``.\n    title : string or None, optional (default=\"Metric during training\")\n        Axes title.\n        If None, title is disabled.\n    xlabel : string or None, optional (default=\"Iterations\")\n        X-axis title label.\n        If None, title is disabled.\n    ylabel : string or None, optional (default=\"auto\")\n        Y-axis title label.\n        If 'auto', metric name is used.\n        If None, title is disabled.\n    figsize : tuple of 2 elements or None, optional (default=None)\n        Figure size.\n    grid : bool, optional (default=True)\n        Whether to add a grid for axes.\n\n    Returns\n    -------\n    ax : matplotlib.axes.Axes\n        The plot with metric's history over the training.\n    \"\"\"\n    if MATPLOTLIB_INSTALLED:\n        import matplotlib.pyplot as plt\n    else:\n        raise ImportError('You must install matplotlib to plot metric.')\n\n    if isinstance(booster, LGBMModel):\n        eval_results = deepcopy(booster.evals_result_)\n    elif isinstance(booster, dict):\n        eval_results = deepcopy(booster)\n    else:\n        raise TypeError('booster must be dict or LGBMModel.')\n\n    num_data = len(eval_results)\n\n    if not num_data:\n        raise ValueError('eval results cannot be empty.')\n\n    if ax is None:\n        if figsize is not None:\n            _check_not_tuple_of_2_elements(figsize, 'figsize')\n        _, ax = plt.subplots(1, 1, figsize=figsize)\n\n    if dataset_names is None:\n        dataset_names = iter(eval_results.keys())\n    elif not isinstance(dataset_names, (list, tuple, set)) or not dataset_names:\n        raise ValueError('dataset_names should be iterable and cannot be empty')\n    else:\n        dataset_names = iter(dataset_names)\n\n    name = next(dataset_names)  # take one as sample\n    metrics_for_one = eval_results[name]\n    num_metric = len(metrics_for_one)\n    if metric is None:\n        if num_metric > 1:\n            msg = \"\"\"more than one metric available, picking one to plot.\"\"\"\n            warnings.warn(msg, stacklevel=2)\n        metric, results = metrics_for_one.popitem()\n    else:\n        if metric not in metrics_for_one:\n            raise KeyError('No given metric in eval results.')\n        results = metrics_for_one[metric]\n    num_iteration, max_result, min_result = len(results), max(results), min(results)\n    x_ = range_(num_iteration)\n    ax.plot(x_, results, label=name)\n\n    for name in dataset_names:\n        metrics_for_one = eval_results[name]\n        results = metrics_for_one[metric]\n        max_result, min_result = max(max(results), max_result), min(min(results), min_result)\n        ax.plot(x_, results, label=name)\n\n    ax.legend(loc='best')\n\n    if xlim is not None:\n        _check_not_tuple_of_2_elements(xlim, 'xlim')\n    else:\n        xlim = (0, num_iteration)\n    ax.set_xlim(xlim)\n\n    if ylim is not None:\n        _check_not_tuple_of_2_elements(ylim, 'ylim')\n    else:\n        range_result = max_result - min_result\n        ylim = (min_result - range_result * 0.2, max_result + range_result * 0.2)\n    ax.set_ylim(ylim)\n\n    if ylabel == 'auto':\n        ylabel = metric\n\n    if title is not None:\n        ax.set_title(title)\n    if xlabel is not None:\n        ax.set_xlabel(xlabel)\n    if ylabel is not None:\n        ax.set_ylabel(ylabel)\n    ax.grid(grid)\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a tree to graphviz instance.", "response": "def _to_graphviz(tree_info, show_info, feature_names, precision=None, **kwargs):\n    \"\"\"Convert specified tree to graphviz instance.\n\n    See:\n      - https://graphviz.readthedocs.io/en/stable/api.html#digraph\n    \"\"\"\n    if GRAPHVIZ_INSTALLED:\n        from graphviz import Digraph\n    else:\n        raise ImportError('You must install graphviz to plot tree.')\n\n    def add(root, parent=None, decision=None):\n        \"\"\"Recursively add node or edge.\"\"\"\n        if 'split_index' in root:  # non-leaf\n            name = 'split{0}'.format(root['split_index'])\n            if feature_names is not None:\n                label = 'split_feature_name: {0}'.format(feature_names[root['split_feature']])\n            else:\n                label = 'split_feature_index: {0}'.format(root['split_feature'])\n            label += r'\\nthreshold: {0}'.format(_float2str(root['threshold'], precision))\n            for info in show_info:\n                if info in {'split_gain', 'internal_value'}:\n                    label += r'\\n{0}: {1}'.format(info, _float2str(root[info], precision))\n                elif info == 'internal_count':\n                    label += r'\\n{0}: {1}'.format(info, root[info])\n            graph.node(name, label=label)\n            if root['decision_type'] == '<=':\n                l_dec, r_dec = '<=', '>'\n            elif root['decision_type'] == '==':\n                l_dec, r_dec = 'is', \"isn't\"\n            else:\n                raise ValueError('Invalid decision type in tree model.')\n            add(root['left_child'], name, l_dec)\n            add(root['right_child'], name, r_dec)\n        else:  # leaf\n            name = 'leaf{0}'.format(root['leaf_index'])\n            label = 'leaf_index: {0}'.format(root['leaf_index'])\n            label += r'\\nleaf_value: {0}'.format(_float2str(root['leaf_value'], precision))\n            if 'leaf_count' in show_info:\n                label += r'\\nleaf_count: {0}'.format(root['leaf_count'])\n            graph.node(name, label=label)\n        if parent is not None:\n            graph.edge(parent, name, decision)\n\n    graph = Digraph(**kwargs)\n    add(tree_info['tree_structure'])\n\n    return graph"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a digraph representation of a tree.", "response": "def create_tree_digraph(booster, tree_index=0, show_info=None, precision=None,\n                        old_name=None, old_comment=None, old_filename=None, old_directory=None,\n                        old_format=None, old_engine=None, old_encoding=None, old_graph_attr=None,\n                        old_node_attr=None, old_edge_attr=None, old_body=None, old_strict=False, **kwargs):\n    \"\"\"Create a digraph representation of specified tree.\n\n    Note\n    ----\n    For more information please visit\n    https://graphviz.readthedocs.io/en/stable/api.html#digraph.\n\n    Parameters\n    ----------\n    booster : Booster or LGBMModel\n        Booster or LGBMModel instance to be converted.\n    tree_index : int, optional (default=0)\n        The index of a target tree to convert.\n    show_info : list of strings or None, optional (default=None)\n        What information should be shown in nodes.\n        Possible values of list items: 'split_gain', 'internal_value', 'internal_count', 'leaf_count'.\n    precision : int or None, optional (default=None)\n        Used to restrict the display of floating point values to a certain precision.\n    **kwargs\n        Other parameters passed to ``Digraph`` constructor.\n        Check https://graphviz.readthedocs.io/en/stable/api.html#digraph for the full list of supported parameters.\n\n    Returns\n    -------\n    graph : graphviz.Digraph\n        The digraph representation of specified tree.\n    \"\"\"\n    if isinstance(booster, LGBMModel):\n        booster = booster.booster_\n    elif not isinstance(booster, Booster):\n        raise TypeError('booster must be Booster or LGBMModel.')\n\n    for param_name in ['old_name', 'old_comment', 'old_filename', 'old_directory',\n                       'old_format', 'old_engine', 'old_encoding', 'old_graph_attr',\n                       'old_node_attr', 'old_edge_attr', 'old_body']:\n        param = locals().get(param_name)\n        if param is not None:\n            warnings.warn('{0} parameter is deprecated and will be removed in 2.4 version.\\n'\n                          'Please use **kwargs to pass {1} parameter.'.format(param_name, param_name[4:]),\n                          LGBMDeprecationWarning)\n            if param_name[4:] not in kwargs:\n                kwargs[param_name[4:]] = param\n    if locals().get('strict'):\n        warnings.warn('old_strict parameter is deprecated and will be removed in 2.4 version.\\n'\n                      'Please use **kwargs to pass strict parameter.',\n                      LGBMDeprecationWarning)\n        if 'strict' not in kwargs:\n            kwargs['strict'] = True\n\n    model = booster.dump_model()\n    tree_infos = model['tree_info']\n    if 'feature_names' in model:\n        feature_names = model['feature_names']\n    else:\n        feature_names = None\n\n    if tree_index < len(tree_infos):\n        tree_info = tree_infos[tree_index]\n    else:\n        raise IndexError('tree_index is out of range.')\n\n    if show_info is None:\n        show_info = []\n\n    graph = _to_graphviz(tree_info, show_info, feature_names, precision, **kwargs)\n\n    return graph"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_tree(booster, ax=None, tree_index=0, figsize=None,\n              old_graph_attr=None, old_node_attr=None, old_edge_attr=None,\n              show_info=None, precision=None, **kwargs):\n    \"\"\"Plot specified tree.\n\n    Note\n    ----\n    It is preferable to use ``create_tree_digraph()`` because of its lossless quality\n    and returned objects can be also rendered and displayed directly inside a Jupyter notebook.\n\n    Parameters\n    ----------\n    booster : Booster or LGBMModel\n        Booster or LGBMModel instance to be plotted.\n    ax : matplotlib.axes.Axes or None, optional (default=None)\n        Target axes instance.\n        If None, new figure and axes will be created.\n    tree_index : int, optional (default=0)\n        The index of a target tree to plot.\n    figsize : tuple of 2 elements or None, optional (default=None)\n        Figure size.\n    show_info : list of strings or None, optional (default=None)\n        What information should be shown in nodes.\n        Possible values of list items: 'split_gain', 'internal_value', 'internal_count', 'leaf_count'.\n    precision : int or None, optional (default=None)\n        Used to restrict the display of floating point values to a certain precision.\n    **kwargs\n        Other parameters passed to ``Digraph`` constructor.\n        Check https://graphviz.readthedocs.io/en/stable/api.html#digraph for the full list of supported parameters.\n\n    Returns\n    -------\n    ax : matplotlib.axes.Axes\n        The plot with single tree.\n    \"\"\"\n    if MATPLOTLIB_INSTALLED:\n        import matplotlib.pyplot as plt\n        import matplotlib.image as image\n    else:\n        raise ImportError('You must install matplotlib to plot tree.')\n\n    for param_name in ['old_graph_attr', 'old_node_attr', 'old_edge_attr']:\n        param = locals().get(param_name)\n        if param is not None:\n            warnings.warn('{0} parameter is deprecated and will be removed in 2.4 version.\\n'\n                          'Please use **kwargs to pass {1} parameter.'.format(param_name, param_name[4:]),\n                          LGBMDeprecationWarning)\n            if param_name[4:] not in kwargs:\n                kwargs[param_name[4:]] = param\n\n    if ax is None:\n        if figsize is not None:\n            _check_not_tuple_of_2_elements(figsize, 'figsize')\n        _, ax = plt.subplots(1, 1, figsize=figsize)\n\n    graph = create_tree_digraph(booster=booster, tree_index=tree_index,\n                                show_info=show_info, precision=precision, **kwargs)\n\n    s = BytesIO()\n    s.write(graph.pipe(format='png'))\n    s.seek(0)\n    img = image.imread(s)\n\n    ax.imshow(img)\n    ax.axis('off')\n    return ax", "response": "Plots a single tree with the specified booster."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the - std = c ++ 14 - std = c ++ 11 - std = c ++ 0x", "response": "def cpp_flag(compiler):\n    \"\"\"Return the -std=c++[0x/11/14] compiler flag.\n    The c++14 is preferred over c++0x/11 (when it is available).\n    \"\"\"\n    standards = ['-std=c++14', '-std=c++11', '-std=c++0x']\n    for standard in standards:\n        if has_flag(compiler, [standard]):\n            return standard\n    raise RuntimeError(\n        'Unsupported compiler -- at least C++0x support '\n        'is needed!'\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_nearest_neighbor(query, vectors, ban_set, cossims=None):\n    if cossims is None:\n        cossims = np.matmul(vectors, query, out=cossims)\n    else:\n        np.matmul(vectors, query, out=cossims)\n    rank = len(cossims) - 1\n    result_i = np.argpartition(cossims, rank)[rank]\n    while result_i in ban_set:\n        rank -= 1\n        result_i = np.argpartition(cossims, rank)[rank]\n    return result_i", "response": "find the nearest neighbor to a vector"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntrains a supervised model and return a model object.", "response": "def train_supervised(\n    input,\n    lr=0.1,\n    dim=100,\n    ws=5,\n    epoch=5,\n    minCount=1,\n    minCountLabel=0,\n    minn=0,\n    maxn=0,\n    neg=5,\n    wordNgrams=1,\n    loss=\"softmax\",\n    bucket=2000000,\n    thread=multiprocessing.cpu_count() - 1,\n    lrUpdateRate=100,\n    t=1e-4,\n    label=\"__label__\",\n    verbose=2,\n    pretrainedVectors=\"\",\n):\n    \"\"\"\n    Train a supervised model and return a model object.\n\n    input must be a filepath. The input text does not need to be tokenized\n    as per the tokenize function, but it must be preprocessed and encoded\n    as UTF-8. You might want to consult standard preprocessing scripts such\n    as tokenizer.perl mentioned here: http://www.statmt.org/wmt07/baseline.html\n\n    The input file must must contain at least one label per line. For an\n    example consult the example datasets which are part of the fastText\n    repository such as the dataset pulled by classification-example.sh.\n    \"\"\"\n    model = \"supervised\"\n    a = _build_args(locals())\n    ft = _FastText()\n    fasttext.train(ft.f, a)\n    return ft"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_word_vector(self, word):\n        dim = self.get_dimension()\n        b = fasttext.Vector(dim)\n        self.f.getWordVector(b, word)\n        return np.array(b)", "response": "Get the vector representation of word."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_sentence_vector(self, text):\n        if text.find('\\n') != -1:\n            raise ValueError(\n                \"predict processes one line at a time (remove \\'\\\\n\\')\"\n            )\n        text += \"\\n\"\n        dim = self.get_dimension()\n        b = fasttext.Vector(dim)\n        self.f.getSentenceVector(b, text)\n        return np.array(b)", "response": "Given a string get a vector represenation. This function assumes that the text is a single line of text."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_subwords(self, word, on_unicode_error='strict'):\n        pair = self.f.getSubwords(word, on_unicode_error)\n        return pair[0], np.array(pair[1])", "response": "Given a word get the subwords and their indicies."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_input_vector(self, ind):\n        dim = self.get_dimension()\n        b = fasttext.Vector(dim)\n        self.f.getInputVector(b, ind)\n        return np.array(b)", "response": "Given an index get the corresponding vector of the Input Matrix."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npredict the most likely label and probability of a given text.", "response": "def predict(self, text, k=1, threshold=0.0, on_unicode_error='strict'):\n        \"\"\"\n        Given a string, get a list of labels and a list of\n        corresponding probabilities. k controls the number\n        of returned labels. A choice of 5, will return the 5\n        most probable labels. By default this returns only\n        the most likely label and probability. threshold filters\n        the returned labels by a threshold on probability. A\n        choice of 0.5 will return labels with at least 0.5\n        probability. k and threshold will be applied together to\n        determine the returned labels.\n\n        This function assumes to be given\n        a single line of text. We split words on whitespace (space,\n        newline, tab, vertical tab) and the control characters carriage\n        return, formfeed and the null character.\n\n        If the model is not supervised, this function will throw a ValueError.\n\n        If given a list of strings, it will return a list of results as usually\n        received for a single line of text.\n        \"\"\"\n\n        def check(entry):\n            if entry.find('\\n') != -1:\n                raise ValueError(\n                    \"predict processes one line at a time (remove \\'\\\\n\\')\"\n                )\n            entry += \"\\n\"\n            return entry\n\n        if type(text) == list:\n            text = [check(entry) for entry in text]\n            predictions = self.f.multilinePredict(text, k, threshold, on_unicode_error)\n            dt = np.dtype([('probability', 'float64'), ('label', 'object')])\n            result_as_pair = np.array(predictions, dtype=dt)\n\n            return result_as_pair['label'].tolist(), result_as_pair['probability']\n        else:\n            text = check(text)\n            predictions = self.f.predict(text, k, threshold, on_unicode_error)\n            probs, labels = zip(*predictions)\n\n            return labels, np.array(probs, copy=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_input_matrix(self):\n        if self.f.isQuant():\n            raise ValueError(\"Can't get quantized Matrix\")\n        return np.array(self.f.getInputMatrix())", "response": "Get a copy of the full input matrix of a Model. This only works if the model is not quantized."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a copy of the full output matrix of a Model. This only works if the model is not quantized.", "response": "def get_output_matrix(self):\n        \"\"\"\n        Get a copy of the full output matrix of a Model. This only\n        works if the model is not quantized.\n        \"\"\"\n        if self.f.isQuant():\n            raise ValueError(\"Can't get quantized Matrix\")\n        return np.array(self.f.getOutputMatrix())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the entire list of words of the dictionary optionally including the frequency of the individual words.", "response": "def get_words(self, include_freq=False, on_unicode_error='strict'):\n        \"\"\"\n        Get the entire list of words of the dictionary optionally\n        including the frequency of the individual words. This\n        does not include any subwords. For that please consult\n        the function get_subwords.\n        \"\"\"\n        pair = self.f.getVocab(on_unicode_error)\n        if include_freq:\n            return (pair[0], np.array(pair[1]))\n        else:\n            return pair[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the entire list of labels of the dictionary optionally including the frequency of the individual labels.", "response": "def get_labels(self, include_freq=False, on_unicode_error='strict'):\n        \"\"\"\n        Get the entire list of labels of the dictionary optionally\n        including the frequency of the individual labels. Unsupervised\n        models use words as labels, which is why get_labels\n        will call and return get_words for this type of\n        model.\n        \"\"\"\n        a = self.f.getArgs()\n        if a.model == model_name.supervised:\n            pair = self.f.getLabels(on_unicode_error)\n            if include_freq:\n                return (pair[0], np.array(pair[1]))\n            else:\n                return pair[0]\n        else:\n            return self.get_words(include_freq)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a line of text.", "response": "def get_line(self, text, on_unicode_error='strict'):\n        \"\"\"\n        Split a line of text into words and labels. Labels must start with\n        the prefix used to create the model (__label__ by default).\n        \"\"\"\n\n        def check(entry):\n            if entry.find('\\n') != -1:\n                raise ValueError(\n                    \"get_line processes one line at a time (remove \\'\\\\n\\')\"\n                )\n            entry += \"\\n\"\n            return entry\n\n        if type(text) == list:\n            text = [check(entry) for entry in text]\n            return self.f.multilineGetLine(text, on_unicode_error)\n        else:\n            text = check(text)\n            return self.f.getLine(text, on_unicode_error)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef quantize(\n        self,\n        input=None,\n        qout=False,\n        cutoff=0,\n        retrain=False,\n        epoch=None,\n        lr=None,\n        thread=None,\n        verbose=None,\n        dsub=2,\n        qnorm=False\n    ):\n        \"\"\"\n        Quantize the model reducing the size of the model and\n        it's memory footprint.\n        \"\"\"\n        a = self.f.getArgs()\n        if not epoch:\n            epoch = a.epoch\n        if not lr:\n            lr = a.lr\n        if not thread:\n            thread = a.thread\n        if not verbose:\n            verbose = a.verbose\n        if retrain and not input:\n            raise ValueError(\"Need input file path if retraining\")\n        if input is None:\n            input = \"\"\n        self.f.quantize(\n            input, qout, cutoff, retrain, epoch, lr, thread, verbose, dsub,\n            qnorm\n        )", "response": "Quantize the model and store the result in the object s memory footprint."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_params(cls, params: Iterable[Tuple[str, Params]] = ()) -> Optional['RegularizerApplicator']:\n        if not params:\n            return None\n\n        instantiated_regularizers = []\n        for parameter_regex, regularizer_params in params:\n            if isinstance(regularizer_params, str):\n                regularizer = Regularizer.by_name(regularizer_params)()\n            else:\n                regularizer_type = Regularizer.by_name(regularizer_params.pop(\"type\"))\n                regularizer = regularizer_type(**regularizer_params)  # type: ignore\n            instantiated_regularizers.append((parameter_regex, regularizer))\n        return RegularizerApplicator(instantiated_regularizers)", "response": "Converts a list of pairs of regularizers and parameters into a RegularizerApplicator."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting available service keys.", "response": "def list_available(cls) -> List[str]:\n        \"\"\"List default first if it exists\"\"\"\n        keys = list(Registrable._registry[cls].keys())\n        default = cls.default_implementation\n\n        if default is None:\n            return keys\n        elif default not in keys:\n            message = \"Default implementation %s is not registered\" % default\n            raise ConfigurationError(message)\n        else:\n            return [default] + [k for k in keys if k != default]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sanitize(x: Any) -> Any:  # pylint: disable=invalid-name,too-many-return-statements\n    if isinstance(x, (str, float, int, bool)):\n        # x is already serializable\n        return x\n    elif isinstance(x, torch.Tensor):\n        # tensor needs to be converted to a list (and moved to cpu if necessary)\n        return x.cpu().tolist()\n    elif isinstance(x, numpy.ndarray):\n        # array needs to be converted to a list\n        return x.tolist()\n    elif isinstance(x, numpy.number):  # pylint: disable=no-member\n        # NumPy numbers need to be converted to Python numbers\n        return x.item()\n    elif isinstance(x, dict):\n        # Dicts need their values sanitized\n        return {key: sanitize(value) for key, value in x.items()}\n    elif isinstance(x, (spacy.tokens.Token, allennlp.data.Token)):\n        # Tokens get sanitized to just their text.\n        return x.text\n    elif isinstance(x, (list, tuple)):\n        # Lists and Tuples need their values sanitized\n        return [sanitize(x_i) for x_i in x]\n    elif x is None:\n        return \"None\"\n    elif hasattr(x, 'to_json'):\n        return x.to_json()\n    else:\n        raise ValueError(f\"Cannot sanitize {x} of type {type(x)}. \"\n                         \"If this is your own custom class, add a `to_json(self)` method \"\n                         \"that returns a JSON-like object.\")", "response": "Sanitize a Python object to be JSON - serializable."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef group_by_count(iterable: List[Any], count: int, default_value: Any) -> List[List[Any]]:\n    return [list(l) for l in zip_longest(*[iter(iterable)] * count, fillvalue=default_value)]", "response": "Takes a list and groups it into sublists of size count using default_value to pad the list at the end if the list is not divisable by count."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake an iterator and batches the individual instances into lists of the specified size.", "response": "def lazy_groups_of(iterator: Iterator[A], group_size: int) -> Iterator[List[A]]:\n    \"\"\"\n    Takes an iterator and batches the individual instances into lists of the\n    specified size. The last list may be smaller if there are instances left over.\n    \"\"\"\n    return iter(lambda: list(islice(iterator, 0, group_size)), [])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntaking a list of objects and pads it to the desired length.", "response": "def pad_sequence_to_length(sequence: List,\n                           desired_length: int,\n                           default_value: Callable[[], Any] = lambda: 0,\n                           padding_on_right: bool = True) -> List:\n    \"\"\"\n    Take a list of objects and pads it to the desired length, returning the padded list.  The\n    original list is not modified.\n\n    Parameters\n    ----------\n    sequence : List\n        A list of objects to be padded.\n\n    desired_length : int\n        Maximum length of each sequence. Longer sequences are truncated to this length, and\n        shorter ones are padded to it.\n\n    default_value: Callable, default=lambda: 0\n        Callable that outputs a default value (of any type) to use as padding values.  This is\n        a lambda to avoid using the same object when the default value is more complex, like a\n        list.\n\n    padding_on_right : bool, default=True\n        When we add padding tokens (or truncate the sequence), should we do it on the right or\n        the left?\n\n    Returns\n    -------\n    padded_sequence : List\n    \"\"\"\n    # Truncates the sequence to the desired length.\n    if padding_on_right:\n        padded_sequence = sequence[:desired_length]\n    else:\n        padded_sequence = sequence[-desired_length:]\n    # Continues to pad with default_value() until we reach the desired length.\n    for _ in range(desired_length - len(padded_sequence)):\n        if padding_on_right:\n            padded_sequence.append(default_value())\n        else:\n            padded_sequence.insert(0, default_value())\n    return padded_sequence"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new dictionary with noise added to every key in dictionary.", "response": "def add_noise_to_dict_values(dictionary: Dict[A, float], noise_param: float) -> Dict[A, float]:\n    \"\"\"\n    Returns a new dictionary with noise added to every key in ``dictionary``.  The noise is\n    uniformly distributed within ``noise_param`` percent of the value for every value in the\n    dictionary.\n    \"\"\"\n    new_dict = {}\n    for key, value in dictionary.items():\n        noise_value = value * noise_param\n        noise = random.uniform(-noise_value, noise_value)\n        new_dict[key] = value + noise\n    return new_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef namespace_match(pattern: str, namespace: str):\n    if pattern[0] == '*' and namespace.endswith(pattern[1:]):\n        return True\n    elif pattern == namespace:\n        return True\n    return False", "response": "Matches a namespace pattern against a namespace string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprepare the environment for training.", "response": "def prepare_environment(params: Params):\n    \"\"\"\n    Sets random seeds for reproducible experiments. This may not work as expected\n    if you use this from within a python project in which you have already imported Pytorch.\n    If you use the scripts/run_model.py entry point to training models with this library,\n    your experiments should be reasonably reproducible. If you are using this from your own\n    project, you will want to call this function before importing Pytorch. Complete determinism\n    is very difficult to achieve with libraries doing optimized linear algebra due to massively\n    parallel execution, which is exacerbated by using GPUs.\n\n    Parameters\n    ----------\n    params: Params object or dict, required.\n        A ``Params`` object or dict holding the json parameters.\n    \"\"\"\n    seed = params.pop_int(\"random_seed\", 13370)\n    numpy_seed = params.pop_int(\"numpy_seed\", 1337)\n    torch_seed = params.pop_int(\"pytorch_seed\", 133)\n\n    if seed is not None:\n        random.seed(seed)\n    if numpy_seed is not None:\n        numpy.random.seed(numpy_seed)\n    if torch_seed is not None:\n        torch.manual_seed(torch_seed)\n        # Seed all GPUs with the same seed if available.\n        if torch.cuda.is_available():\n            torch.cuda.manual_seed_all(torch_seed)\n\n    log_pytorch_version_info()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cleanup_global_logging(stdout_handler: logging.FileHandler) -> None:\n    stdout_handler.close()\n    logging.getLogger().removeHandler(stdout_handler)\n\n    if isinstance(sys.stdout, TeeLogger):\n        sys.stdout = sys.stdout.cleanup()\n    if isinstance(sys.stderr, TeeLogger):\n        sys.stderr = sys.stderr.cleanup()", "response": "This function closes any open file handles and logs set up by prepare_global_logging."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_spacy_model(spacy_model_name: str, pos_tags: bool, parse: bool, ner: bool) -> SpacyModelType:\n\n    options = (spacy_model_name, pos_tags, parse, ner)\n    if options not in LOADED_SPACY_MODELS:\n        disable = ['vectors', 'textcat']\n        if not pos_tags:\n            disable.append('tagger')\n        if not parse:\n            disable.append('parser')\n        if not ner:\n            disable.append('ner')\n        try:\n            spacy_model = spacy.load(spacy_model_name, disable=disable)\n        except OSError:\n            logger.warning(f\"Spacy models '{spacy_model_name}' not found.  Downloading and installing.\")\n            spacy_download(spacy_model_name)\n            # NOTE(mattg): The following four lines are a workaround suggested by Ines for spacy\n            # 2.1.0, which removed the linking that was done in spacy 2.0.  importlib doesn't find\n            # packages that were installed in the same python session, so the way `spacy_download`\n            # works in 2.1.0 is broken for this use case.  These four lines can probably be removed\n            # at some point in the future, once spacy has figured out a better way to handle this.\n            # See https://github.com/explosion/spaCy/issues/3435.\n            from spacy.cli import link\n            from spacy.util import get_package_path\n            package_path = get_package_path(spacy_model_name)\n            link(spacy_model_name, spacy_model_name, model_path=package_path)\n            spacy_model = spacy.load(spacy_model_name, disable=disable)\n\n        LOADED_SPACY_MODELS[options] = spacy_model\n    return LOADED_SPACY_MODELS[options]", "response": "Load and load a spacy model."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nimports all submodules under the given package.", "response": "def import_submodules(package_name: str) -> None:\n    \"\"\"\n    Import all submodules under the given package.\n    Primarily useful so that people using AllenNLP as a library\n    can specify their own custom packages and have their custom\n    classes get loaded and registered.\n    \"\"\"\n    importlib.invalidate_caches()\n\n    # For some reason, python doesn't always add this by default to your path, but you pretty much\n    # always want it when using `--include-package`.  And if it's already there, adding it again at\n    # the end won't hurt anything.\n    sys.path.append('.')\n\n    # Import at top level\n    module = importlib.import_module(package_name)\n    path = getattr(module, '__path__', [])\n    path_string = '' if not path else path[0]\n\n    # walk_packages only finds immediate children, so need to recurse.\n    for module_finder, name, _ in pkgutil.walk_packages(path):\n        # Sometimes when you import third-party libraries that are on your path,\n        # `pkgutil.walk_packages` returns those too, so we need to skip them.\n        if path_string and module_finder.path != path_string:\n            continue\n        subpackage = f\"{package_name}.{name}\"\n        import_submodules(subpackage)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting peak memory usage for this process.", "response": "def peak_memory_mb() -> float:\n    \"\"\"\n    Get peak memory usage for this process, as measured by\n    max-resident-set size:\n\n    https://unix.stackexchange.com/questions/30940/getrusage-system-call-what-is-maximum-resident-set-size\n\n    Only works on OSX and Linux, returns 0.0 otherwise.\n    \"\"\"\n    if resource is None or sys.platform not in ('linux', 'darwin'):\n        return 0.0\n\n    # TODO(joelgrus): For whatever, our pinned version 0.521 of mypy does not like\n    # next line, but later versions (e.g. 0.530) are fine with it. Once we get that\n    # figured out, remove the type: ignore.\n    peak = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss  # type: ignore\n\n    if sys.platform == 'darwin':\n        # On OSX the result is in bytes.\n        return peak / 1_000_000\n\n    else:\n        # On Linux the result is in kilobytes.\n        return peak / 1_000"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the current GPU memory usage.", "response": "def gpu_memory_mb() -> Dict[int, int]:\n    \"\"\"\n    Get the current GPU memory usage.\n    Based on https://discuss.pytorch.org/t/access-gpu-memory-usage-in-pytorch/3192/4\n\n    Returns\n    -------\n    ``Dict[int, int]``\n        Keys are device ids as integers.\n        Values are memory usage as integers in MB.\n        Returns an empty ``dict`` if GPUs are not available.\n    \"\"\"\n    # pylint: disable=bare-except\n    try:\n        result = subprocess.check_output(['nvidia-smi', '--query-gpu=memory.used',\n                                          '--format=csv,nounits,noheader'],\n                                         encoding='utf-8')\n        gpu_memory = [int(x) for x in result.strip().split('\\n')]\n        return {gpu: memory for gpu, memory in enumerate(gpu_memory)}\n    except FileNotFoundError:\n        # `nvidia-smi` doesn't exist, assume that means no GPU.\n        return {}\n    except:\n        # Catch *all* exceptions, because this memory check is a nice-to-have\n        # and we'd never want a training run to fail because of it.\n        logger.exception(\"unable to check gpu_memory_mb(), continuing\")\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nensures that the given iterable is a list.", "response": "def ensure_list(iterable: Iterable[A]) -> List[A]:\n    \"\"\"\n    An Iterable may be a list or a generator.\n    This ensures we get a list without making an unnecessary copy.\n    \"\"\"\n    if isinstance(iterable, list):\n        return iterable\n    else:\n        return list(iterable)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(self, action: torch.Tensor) -> 'ChecklistStatelet':\n        checklist_addition = (self.terminal_actions == action).float()\n        new_checklist = self.checklist + checklist_addition\n        new_checklist_state = ChecklistStatelet(terminal_actions=self.terminal_actions,\n                                                checklist_target=self.checklist_target,\n                                                checklist_mask=self.checklist_mask,\n                                                checklist=new_checklist,\n                                                terminal_indices_dict=self.terminal_indices_dict)\n        return new_checklist_state", "response": "Updates the checklist with the new action index."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _remove_action_from_type(valid_actions: Dict[str, List[str]],\n                                 type_: str,\n                                 filter_function: Callable[[str], bool]) -> None:\n        \"\"\"\n        Finds the production rule matching the filter function in the given type's valid action\n        list, and removes it.  If there is more than one matching function, we crash.\n        \"\"\"\n        action_list = valid_actions[type_]\n        matching_action_index = [i for i, action in enumerate(action_list) if filter_function(action)]\n        assert len(matching_action_index) == 1, \"Filter function didn't find one action\"\n        action_list.pop(matching_action_index[0])", "response": "Removes the action from the given type s valid action list."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef forward(self,  # pylint: disable=arguments-differ\n                inputs: torch.FloatTensor,\n                batch_lengths: List[int],\n                initial_state: Optional[Tuple[torch.Tensor, torch.Tensor]] = None):\n        \"\"\"\n        Parameters\n        ----------\n        inputs : ``torch.FloatTensor``, required.\n            A tensor of shape (batch_size, num_timesteps, input_size)\n            to apply the LSTM over.\n        batch_lengths : ``List[int]``, required.\n            A list of length batch_size containing the lengths of the sequences in batch.\n        initial_state : ``Tuple[torch.Tensor, torch.Tensor]``, optional, (default = None)\n            A tuple (state, memory) representing the initial hidden state and memory\n            of the LSTM. The ``state`` has shape (1, batch_size, hidden_size) and the\n            ``memory`` has shape (1, batch_size, cell_size).\n\n        Returns\n        -------\n        output_accumulator : ``torch.FloatTensor``\n            The outputs of the LSTM for each timestep. A tensor of shape\n            (batch_size, max_timesteps, hidden_size) where for a given batch\n            element, all outputs past the sequence length for that batch are\n            zero tensors.\n        final_state : ``Tuple[``torch.FloatTensor, torch.FloatTensor]``\n            A tuple (state, memory) representing the initial hidden state and memory\n            of the LSTM. The ``state`` has shape (1, batch_size, hidden_size) and the\n            ``memory`` has shape (1, batch_size, cell_size).\n        \"\"\"\n        batch_size = inputs.size()[0]\n        total_timesteps = inputs.size()[1]\n\n        output_accumulator = inputs.new_zeros(batch_size, total_timesteps, self.hidden_size)\n\n        if initial_state is None:\n            full_batch_previous_memory = inputs.new_zeros(batch_size, self.cell_size)\n            full_batch_previous_state = inputs.new_zeros(batch_size, self.hidden_size)\n        else:\n            full_batch_previous_state = initial_state[0].squeeze(0)\n            full_batch_previous_memory = initial_state[1].squeeze(0)\n\n        current_length_index = batch_size - 1 if self.go_forward else 0\n        if self.recurrent_dropout_probability > 0.0 and self.training:\n            dropout_mask = get_dropout_mask(self.recurrent_dropout_probability,\n                                            full_batch_previous_state)\n        else:\n            dropout_mask = None\n\n        for timestep in range(total_timesteps):\n            # The index depends on which end we start.\n            index = timestep if self.go_forward else total_timesteps - timestep - 1\n\n            # What we are doing here is finding the index into the batch dimension\n            # which we need to use for this timestep, because the sequences have\n            # variable length, so once the index is greater than the length of this\n            # particular batch sequence, we no longer need to do the computation for\n            # this sequence. The key thing to recognise here is that the batch inputs\n            # must be _ordered_ by length from longest (first in batch) to shortest\n            # (last) so initially, we are going forwards with every sequence and as we\n            # pass the index at which the shortest elements of the batch finish,\n            # we stop picking them up for the computation.\n            if self.go_forward:\n                while batch_lengths[current_length_index] <= index:\n                    current_length_index -= 1\n            # If we're going backwards, we are _picking up_ more indices.\n            else:\n                # First conditional: Are we already at the maximum number of elements in the batch?\n                # Second conditional: Does the next shortest sequence beyond the current batch\n                # index require computation use this timestep?\n                while current_length_index < (len(batch_lengths) - 1) and \\\n                                batch_lengths[current_length_index + 1] > index:\n                    current_length_index += 1\n\n            # Actually get the slices of the batch which we\n            # need for the computation at this timestep.\n            # shape (batch_size, cell_size)\n            previous_memory = full_batch_previous_memory[0: current_length_index + 1].clone()\n            # Shape (batch_size, hidden_size)\n            previous_state = full_batch_previous_state[0: current_length_index + 1].clone()\n            # Shape (batch_size, input_size)\n            timestep_input = inputs[0: current_length_index + 1, index]\n\n            # Do the projections for all the gates all at once.\n            # Both have shape (batch_size, 4 * cell_size)\n            projected_input = self.input_linearity(timestep_input)\n            projected_state = self.state_linearity(previous_state)\n\n            # Main LSTM equations using relevant chunks of the big linear\n            # projections of the hidden state and inputs.\n            input_gate = torch.sigmoid(projected_input[:, (0 * self.cell_size):(1 * self.cell_size)] +\n                                       projected_state[:, (0 * self.cell_size):(1 * self.cell_size)])\n            forget_gate = torch.sigmoid(projected_input[:, (1 * self.cell_size):(2 * self.cell_size)] +\n                                        projected_state[:, (1 * self.cell_size):(2 * self.cell_size)])\n            memory_init = torch.tanh(projected_input[:, (2 * self.cell_size):(3 * self.cell_size)] +\n                                     projected_state[:, (2 * self.cell_size):(3 * self.cell_size)])\n            output_gate = torch.sigmoid(projected_input[:, (3 * self.cell_size):(4 * self.cell_size)] +\n                                        projected_state[:, (3 * self.cell_size):(4 * self.cell_size)])\n            memory = input_gate * memory_init + forget_gate * previous_memory\n\n            # Here is the non-standard part of this LSTM cell; first, we clip the\n            # memory cell, then we project the output of the timestep to a smaller size\n            # and again clip it.\n\n            if self.memory_cell_clip_value:\n                # pylint: disable=invalid-unary-operand-type\n                memory = torch.clamp(memory, -self.memory_cell_clip_value, self.memory_cell_clip_value)\n\n            # shape (current_length_index, cell_size)\n            pre_projection_timestep_output = output_gate * torch.tanh(memory)\n\n            # shape (current_length_index, hidden_size)\n            timestep_output = self.state_projection(pre_projection_timestep_output)\n            if self.state_projection_clip_value:\n                # pylint: disable=invalid-unary-operand-type\n                timestep_output = torch.clamp(timestep_output,\n                                              -self.state_projection_clip_value,\n                                              self.state_projection_clip_value)\n\n            # Only do dropout if the dropout prob is > 0.0 and we are in training mode.\n            if dropout_mask is not None:\n                timestep_output = timestep_output * dropout_mask[0: current_length_index + 1]\n\n            # We've been doing computation with less than the full batch, so here we create a new\n            # variable for the the whole batch at this timestep and insert the result for the\n            # relevant elements of the batch into it.\n            full_batch_previous_memory = full_batch_previous_memory.clone()\n            full_batch_previous_state = full_batch_previous_state.clone()\n            full_batch_previous_memory[0:current_length_index + 1] = memory\n            full_batch_previous_state[0:current_length_index + 1] = timestep_output\n            output_accumulator[0:current_length_index + 1, index] = timestep_output\n\n        # Mimic the pytorch API by returning state in the following shape:\n        # (num_layers * num_directions, batch_size, ...). As this\n        # LSTM cell cannot be stacked, the first dimension here is just 1.\n        final_state = (full_batch_previous_state.unsqueeze(0),\n                       full_batch_previous_memory.unsqueeze(0))\n\n        return output_accumulator, final_state", "response": "Forward computation of the cluster - level LSTM."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef linkcode_resolve(domain, info):\n    if domain != 'py':\n        return None\n\n    modname = info['module']\n    fullname = info['fullname']\n\n    submod = sys.modules.get(modname)\n    if submod is None:\n        return None\n\n    obj = submod\n    for part in fullname.split('.'):\n        try:\n            obj = getattr(obj, part)\n        except:\n            return None\n\n    try:\n        fn = inspect.getsourcefile(obj)\n    except:\n        fn = None\n    if not fn:\n        return None\n\n    try:\n        source, lineno = inspect.getsourcelines(obj)\n    except:\n        lineno = None\n\n    if lineno:\n        linespec = \"#L%d-L%d\" % (lineno, lineno + len(source) - 1)\n    else:\n        linespec = \"\"\n\n    filename = info['module'].replace('.', '/')\n    return \"http://github.com/allenai/allennlp/blob/master/%s.py%s\" % (filename, linespec)", "response": "Determine the URL corresponding to Python object\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_initial_rnn_and_grammar_state(self,\n                                           question: Dict[str, torch.LongTensor],\n                                           table: Dict[str, torch.LongTensor],\n                                           world: List[WikiTablesWorld],\n                                           actions: List[List[ProductionRule]],\n                                           outputs: Dict[str, Any]) -> Tuple[List[RnnStatelet],\n                                                                             List[LambdaGrammarStatelet]]:\n        \"\"\"\n        Encodes the question and table, computes a linking between the two, and constructs an\n        initial RnnStatelet and LambdaGrammarStatelet for each batch instance to pass to the\n        decoder.\n\n        We take ``outputs`` as a parameter here and `modify` it, adding things that we want to\n        visualize in a demo.\n        \"\"\"\n        table_text = table['text']\n        # (batch_size, question_length, embedding_dim)\n        embedded_question = self._question_embedder(question)\n        question_mask = util.get_text_field_mask(question).float()\n        # (batch_size, num_entities, num_entity_tokens, embedding_dim)\n        embedded_table = self._question_embedder(table_text, num_wrapping_dims=1)\n        table_mask = util.get_text_field_mask(table_text, num_wrapping_dims=1).float()\n\n        batch_size, num_entities, num_entity_tokens, _ = embedded_table.size()\n        num_question_tokens = embedded_question.size(1)\n\n        # (batch_size, num_entities, embedding_dim)\n        encoded_table = self._entity_encoder(embedded_table, table_mask)\n        # (batch_size, num_entities, num_neighbors)\n        neighbor_indices = self._get_neighbor_indices(world, num_entities, encoded_table)\n\n        # Neighbor_indices is padded with -1 since 0 is a potential neighbor index.\n        # Thus, the absolute value needs to be taken in the index_select, and 1 needs to\n        # be added for the mask since that method expects 0 for padding.\n        # (batch_size, num_entities, num_neighbors, embedding_dim)\n        embedded_neighbors = util.batched_index_select(encoded_table, torch.abs(neighbor_indices))\n\n        neighbor_mask = util.get_text_field_mask({'ignored': neighbor_indices + 1},\n                                                 num_wrapping_dims=1).float()\n\n        # Encoder initialized to easily obtain a masked average.\n        neighbor_encoder = TimeDistributed(BagOfEmbeddingsEncoder(self._embedding_dim, averaged=True))\n        # (batch_size, num_entities, embedding_dim)\n        embedded_neighbors = neighbor_encoder(embedded_neighbors, neighbor_mask)\n\n        # entity_types: tensor with shape (batch_size, num_entities), where each entry is the\n        # entity's type id.\n        # entity_type_dict: Dict[int, int], mapping flattened_entity_index -> type_index\n        # These encode the same information, but for efficiency reasons later it's nice\n        # to have one version as a tensor and one that's accessible on the cpu.\n        entity_types, entity_type_dict = self._get_type_vector(world, num_entities, encoded_table)\n\n        entity_type_embeddings = self._entity_type_encoder_embedding(entity_types)\n        projected_neighbor_embeddings = self._neighbor_params(embedded_neighbors.float())\n        # (batch_size, num_entities, embedding_dim)\n        entity_embeddings = torch.tanh(entity_type_embeddings + projected_neighbor_embeddings)\n\n\n        # Compute entity and question word similarity.  We tried using cosine distance here, but\n        # because this similarity is the main mechanism that the model can use to push apart logit\n        # scores for certain actions (like \"n -> 1\" and \"n -> -1\"), this needs to have a larger\n        # output range than [-1, 1].\n        question_entity_similarity = torch.bmm(embedded_table.view(batch_size,\n                                                                   num_entities * num_entity_tokens,\n                                                                   self._embedding_dim),\n                                               torch.transpose(embedded_question, 1, 2))\n\n        question_entity_similarity = question_entity_similarity.view(batch_size,\n                                                                     num_entities,\n                                                                     num_entity_tokens,\n                                                                     num_question_tokens)\n\n        # (batch_size, num_entities, num_question_tokens)\n        question_entity_similarity_max_score, _ = torch.max(question_entity_similarity, 2)\n\n        # (batch_size, num_entities, num_question_tokens, num_features)\n        linking_features = table['linking']\n\n        linking_scores = question_entity_similarity_max_score\n\n        if self._use_neighbor_similarity_for_linking:\n            # The linking score is computed as a linear projection of two terms. The first is the\n            # maximum similarity score over the entity's words and the question token. The second\n            # is the maximum similarity over the words in the entity's neighbors and the question\n            # token.\n            #\n            # The second term, projected_question_neighbor_similarity, is useful when a column\n            # needs to be selected. For example, the question token might have no similarity with\n            # the column name, but is similar with the cells in the column.\n            #\n            # Note that projected_question_neighbor_similarity is intended to capture the same\n            # information as the related_column feature.\n            #\n            # Also note that this block needs to be _before_ the `linking_params` block, because\n            # we're overwriting `linking_scores`, not adding to it.\n\n            # (batch_size, num_entities, num_neighbors, num_question_tokens)\n            question_neighbor_similarity = util.batched_index_select(question_entity_similarity_max_score,\n                                                                     torch.abs(neighbor_indices))\n            # (batch_size, num_entities, num_question_tokens)\n            question_neighbor_similarity_max_score, _ = torch.max(question_neighbor_similarity, 2)\n            projected_question_entity_similarity = self._question_entity_params(\n                    question_entity_similarity_max_score.unsqueeze(-1)).squeeze(-1)\n            projected_question_neighbor_similarity = self._question_neighbor_params(\n                    question_neighbor_similarity_max_score.unsqueeze(-1)).squeeze(-1)\n            linking_scores = projected_question_entity_similarity + projected_question_neighbor_similarity\n\n        feature_scores = None\n        if self._linking_params is not None:\n            feature_scores = self._linking_params(linking_features).squeeze(3)\n            linking_scores = linking_scores + feature_scores\n\n        # (batch_size, num_question_tokens, num_entities)\n        linking_probabilities = self._get_linking_probabilities(world, linking_scores.transpose(1, 2),\n                                                                question_mask, entity_type_dict)\n\n        # (batch_size, num_question_tokens, embedding_dim)\n        link_embedding = util.weighted_sum(entity_embeddings, linking_probabilities)\n        encoder_input = torch.cat([link_embedding, embedded_question], 2)\n\n        # (batch_size, question_length, encoder_output_dim)\n        encoder_outputs = self._dropout(self._encoder(encoder_input, question_mask))\n\n        # This will be our initial hidden state and memory cell for the decoder LSTM.\n        final_encoder_output = util.get_final_encoder_states(encoder_outputs,\n                                                             question_mask,\n                                                             self._encoder.is_bidirectional())\n        memory_cell = encoder_outputs.new_zeros(batch_size, self._encoder.get_output_dim())\n\n        # To make grouping states together in the decoder easier, we convert the batch dimension in\n        # all of our tensors into an outer list.  For instance, the encoder outputs have shape\n        # `(batch_size, question_length, encoder_output_dim)`.  We need to convert this into a list\n        # of `batch_size` tensors, each of shape `(question_length, encoder_output_dim)`.  Then we\n        # won't have to do any index selects, or anything, we'll just do some `torch.cat()`s.\n        encoder_output_list = [encoder_outputs[i] for i in range(batch_size)]\n        question_mask_list = [question_mask[i] for i in range(batch_size)]\n        initial_rnn_state = []\n        for i in range(batch_size):\n            initial_rnn_state.append(RnnStatelet(final_encoder_output[i],\n                                                 memory_cell[i],\n                                                 self._first_action_embedding,\n                                                 self._first_attended_question,\n                                                 encoder_output_list,\n                                                 question_mask_list))\n        initial_grammar_state = [self._create_grammar_state(world[i],\n                                                            actions[i],\n                                                            linking_scores[i],\n                                                            entity_types[i])\n                                 for i in range(batch_size)]\n        if not self.training:\n            # We add a few things to the outputs that will be returned from `forward` at evaluation\n            # time, for visualization in a demo.\n            outputs['linking_scores'] = linking_scores\n            if feature_scores is not None:\n                outputs['feature_scores'] = feature_scores\n            outputs['similarity_scores'] = question_entity_similarity_max_score\n        return initial_rnn_state, initial_grammar_state", "response": "This method is used to get the initial RNN and LambdaGrammarStatelet state for each batch instance. It is used to construct the initial RNN and LambdaGrammarStatelet state for each batch instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a tensor that encodes each entity s type and returns that tensor.", "response": "def _get_type_vector(worlds: List[WikiTablesWorld],\n                         num_entities: int,\n                         tensor: torch.Tensor) -> Tuple[torch.LongTensor, Dict[int, int]]:\n        \"\"\"\n        Produces a tensor with shape ``(batch_size, num_entities)`` that encodes each entity's\n        type. In addition, a map from a flattened entity index to type is returned to combine\n        entity type operations into one method.\n\n        Parameters\n        ----------\n        worlds : ``List[WikiTablesWorld]``\n        num_entities : ``int``\n        tensor : ``torch.Tensor``\n            Used for copying the constructed list onto the right device.\n\n        Returns\n        -------\n        A ``torch.LongTensor`` with shape ``(batch_size, num_entities)``.\n        entity_types : ``Dict[int, int]``\n            This is a mapping from ((batch_index * num_entities) + entity_index) to entity type id.\n        \"\"\"\n        entity_types = {}\n        batch_types = []\n        for batch_index, world in enumerate(worlds):\n            types = []\n            for entity_index, entity in enumerate(world.table_graph.entities):\n                # We need numbers to be first, then cells, then parts, then row, because our\n                # entities are going to be sorted.  We do a split by type and then a merge later,\n                # and it relies on this sorting.\n                if entity.startswith('fb:cell'):\n                    entity_type = 1\n                elif entity.startswith('fb:part'):\n                    entity_type = 2\n                elif entity.startswith('fb:row'):\n                    entity_type = 3\n                else:\n                    entity_type = 0\n                types.append(entity_type)\n\n                # For easier lookups later, we're actually using a _flattened_ version\n                # of (batch_index, entity_index) for the key, because this is how the\n                # linking scores are stored.\n                flattened_entity_index = batch_index * num_entities + entity_index\n                entity_types[flattened_entity_index] = entity_type\n            padded = pad_sequence_to_length(types, num_entities, lambda: 0)\n            batch_types.append(padded)\n        return tensor.new_tensor(batch_types, dtype=torch.long), entity_types"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_linking_probabilities(self,\n                                   worlds: List[WikiTablesWorld],\n                                   linking_scores: torch.FloatTensor,\n                                   question_mask: torch.LongTensor,\n                                   entity_type_dict: Dict[int, int]) -> torch.FloatTensor:\n        \"\"\"\n        Produces the probability of an entity given a question word and type. The logic below\n        separates the entities by type since the softmax normalization term sums over entities\n        of a single type.\n\n        Parameters\n        ----------\n        worlds : ``List[WikiTablesWorld]``\n        linking_scores : ``torch.FloatTensor``\n            Has shape (batch_size, num_question_tokens, num_entities).\n        question_mask: ``torch.LongTensor``\n            Has shape (batch_size, num_question_tokens).\n        entity_type_dict : ``Dict[int, int]``\n            This is a mapping from ((batch_index * num_entities) + entity_index) to entity type id.\n\n        Returns\n        -------\n        batch_probabilities : ``torch.FloatTensor``\n            Has shape ``(batch_size, num_question_tokens, num_entities)``.\n            Contains all the probabilities for an entity given a question word.\n        \"\"\"\n        _, num_question_tokens, num_entities = linking_scores.size()\n        batch_probabilities = []\n\n        for batch_index, world in enumerate(worlds):\n            all_probabilities = []\n            num_entities_in_instance = 0\n\n            # NOTE: The way that we're doing this here relies on the fact that entities are\n            # implicitly sorted by their types when we sort them by name, and that numbers come\n            # before \"fb:cell\", and \"fb:cell\" comes before \"fb:row\".  This is not a great\n            # assumption, and could easily break later, but it should work for now.\n            for type_index in range(self._num_entity_types):\n                # This index of 0 is for the null entity for each type, representing the case where a\n                # word doesn't link to any entity.\n                entity_indices = [0]\n                entities = world.table_graph.entities\n                for entity_index, _ in enumerate(entities):\n                    if entity_type_dict[batch_index * num_entities + entity_index] == type_index:\n                        entity_indices.append(entity_index)\n\n                if len(entity_indices) == 1:\n                    # No entities of this type; move along...\n                    continue\n\n                # We're subtracting one here because of the null entity we added above.\n                num_entities_in_instance += len(entity_indices) - 1\n\n                # We separate the scores by type, since normalization is done per type.  There's an\n                # extra \"null\" entity per type, also, so we have `num_entities_per_type + 1`.  We're\n                # selecting from a (num_question_tokens, num_entities) linking tensor on _dimension 1_,\n                # so we get back something of shape (num_question_tokens,) for each index we're\n                # selecting.  All of the selected indices together then make a tensor of shape\n                # (num_question_tokens, num_entities_per_type + 1).\n                indices = linking_scores.new_tensor(entity_indices, dtype=torch.long)\n                entity_scores = linking_scores[batch_index].index_select(1, indices)\n\n                # We used index 0 for the null entity, so this will actually have some values in it.\n                # But we want the null entity's score to be 0, so we set that here.\n                entity_scores[:, 0] = 0\n\n                # No need for a mask here, as this is done per batch instance, with no padding.\n                type_probabilities = torch.nn.functional.softmax(entity_scores, dim=1)\n                all_probabilities.append(type_probabilities[:, 1:])\n\n            # We need to add padding here if we don't have the right number of entities.\n            if num_entities_in_instance != num_entities:\n                zeros = linking_scores.new_zeros(num_question_tokens,\n                                                 num_entities - num_entities_in_instance)\n                all_probabilities.append(zeros)\n\n            # (num_question_tokens, num_entities)\n            probabilities = torch.cat(all_probabilities, dim=1)\n            batch_probabilities.append(probabilities)\n        batch_probabilities = torch.stack(batch_probabilities, dim=0)\n        return batch_probabilities * question_mask.unsqueeze(-1).float()", "response": "Returns the probability of an entity given a question word and type."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a dictionary of metrics that can be used to compute the correct or negative value of a .", "response": "def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n        \"\"\"\n        We track three metrics here:\n\n            1. dpd_acc, which is the percentage of the time that our best output action sequence is\n            in the set of action sequences provided by DPD.  This is an easy-to-compute lower bound\n            on denotation accuracy for the set of examples where we actually have DPD output.  We\n            only score dpd_acc on that subset.\n\n            2. denotation_acc, which is the percentage of examples where we get the correct\n            denotation.  This is the typical \"accuracy\" metric, and it is what you should usually\n            report in an experimental result.  You need to be careful, though, that you're\n            computing this on the full data, and not just the subset that has DPD output (make sure\n            you pass \"keep_if_no_dpd=True\" to the dataset reader, which we do for validation data,\n            but not training data).\n\n            3. lf_percent, which is the percentage of time that decoding actually produces a\n            finished logical form.  We might not produce a valid logical form if the decoder gets\n            into a repetitive loop, or we're trying to produce a super long logical form and run\n            out of time steps, or something.\n        \"\"\"\n        return {\n                'dpd_acc': self._action_sequence_accuracy.get_metric(reset),\n                'denotation_acc': self._denotation_accuracy.get_metric(reset),\n                'lf_percent': self._has_logical_form.get_metric(reset),\n                }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_grammar_state(self,\n                              world: WikiTablesWorld,\n                              possible_actions: List[ProductionRule],\n                              linking_scores: torch.Tensor,\n                              entity_types: torch.Tensor) -> LambdaGrammarStatelet:\n        \"\"\"\n        This method creates the LambdaGrammarStatelet object that's used for decoding.  Part of\n        creating that is creating the `valid_actions` dictionary, which contains embedded\n        representations of all of the valid actions.  So, we create that here as well.\n\n        The way we represent the valid expansions is a little complicated: we use a\n        dictionary of `action types`, where the key is the action type (like \"global\", \"linked\", or\n        whatever your model is expecting), and the value is a tuple representing all actions of\n        that type.  The tuple is (input tensor, output tensor, action id).  The input tensor has\n        the representation that is used when `selecting` actions, for all actions of this type.\n        The output tensor has the representation that is used when feeding the action to the next\n        step of the decoder (this could just be the same as the input tensor).  The action ids are\n        a list of indices into the main action list for each batch instance.\n\n        The inputs to this method are for a `single instance in the batch`; none of the tensors we\n        create here are batched.  We grab the global action ids from the input\n        ``ProductionRules``, and we use those to embed the valid actions for every\n        non-terminal type.  We use the input ``linking_scores`` for non-global actions.\n\n        Parameters\n        ----------\n        world : ``WikiTablesWorld``\n            From the input to ``forward`` for a single batch instance.\n        possible_actions : ``List[ProductionRule]``\n            From the input to ``forward`` for a single batch instance.\n        linking_scores : ``torch.Tensor``\n            Assumed to have shape ``(num_entities, num_question_tokens)`` (i.e., there is no batch\n            dimension).\n        entity_types : ``torch.Tensor``\n            Assumed to have shape ``(num_entities,)`` (i.e., there is no batch dimension).\n        \"\"\"\n        # TODO(mattg): Move the \"valid_actions\" construction to another method.\n        action_map = {}\n        for action_index, action in enumerate(possible_actions):\n            action_string = action[0]\n            action_map[action_string] = action_index\n        entity_map = {}\n        for entity_index, entity in enumerate(world.table_graph.entities):\n            entity_map[entity] = entity_index\n\n        valid_actions = world.get_valid_actions()\n        translated_valid_actions: Dict[str, Dict[str, Tuple[torch.Tensor, torch.Tensor, List[int]]]] = {}\n        for key, action_strings in valid_actions.items():\n            translated_valid_actions[key] = {}\n            # `key` here is a non-terminal from the grammar, and `action_strings` are all the valid\n            # productions of that non-terminal.  We'll first split those productions by global vs.\n            # linked action.\n            action_indices = [action_map[action_string] for action_string in action_strings]\n            production_rule_arrays = [(possible_actions[index], index) for index in action_indices]\n            global_actions = []\n            linked_actions = []\n            for production_rule_array, action_index in production_rule_arrays:\n                if production_rule_array[1]:\n                    global_actions.append((production_rule_array[2], action_index))\n                else:\n                    linked_actions.append((production_rule_array[0], action_index))\n\n            # Then we get the embedded representations of the global actions.\n            global_action_tensors, global_action_ids = zip(*global_actions)\n            global_action_tensor = torch.cat(global_action_tensors, dim=0)\n            global_input_embeddings = self._action_embedder(global_action_tensor)\n            if self._add_action_bias:\n                global_action_biases = self._action_biases(global_action_tensor)\n                global_input_embeddings = torch.cat([global_input_embeddings, global_action_biases], dim=-1)\n            global_output_embeddings = self._output_action_embedder(global_action_tensor)\n            translated_valid_actions[key]['global'] = (global_input_embeddings,\n                                                       global_output_embeddings,\n                                                       list(global_action_ids))\n\n            # Then the representations of the linked actions.\n            if linked_actions:\n                linked_rules, linked_action_ids = zip(*linked_actions)\n                entities = [rule.split(' -> ')[1] for rule in linked_rules]\n                entity_ids = [entity_map[entity] for entity in entities]\n                # (num_linked_actions, num_question_tokens)\n                entity_linking_scores = linking_scores[entity_ids]\n                # (num_linked_actions,)\n                entity_type_tensor = entity_types[entity_ids]\n                # (num_linked_actions, entity_type_embedding_dim)\n                entity_type_embeddings = self._entity_type_decoder_embedding(entity_type_tensor)\n                translated_valid_actions[key]['linked'] = (entity_linking_scores,\n                                                           entity_type_embeddings,\n                                                           list(linked_action_ids))\n\n        # Lastly, we need to also create embedded representations of context-specific actions.  In\n        # this case, those are only variable productions, like \"r -> x\".  Note that our language\n        # only permits one lambda at a time, so we don't need to worry about how nested lambdas\n        # might impact this.\n        context_actions = {}\n        for action_id, action in enumerate(possible_actions):\n            if action[0].endswith(\" -> x\"):\n                input_embedding = self._action_embedder(action[2])\n                if self._add_action_bias:\n                    input_bias = self._action_biases(action[2])\n                    input_embedding = torch.cat([input_embedding, input_bias], dim=-1)\n                output_embedding = self._output_action_embedder(action[2])\n                context_actions[action[0]] = (input_embedding, output_embedding, action_id)\n\n        return LambdaGrammarStatelet([START_SYMBOL],\n                                     {},\n                                     translated_valid_actions,\n                                     context_actions,\n                                     type_declaration.is_nonterminal)", "response": "This method creates the LambdaGrammarStatelet object that is used for decoding."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the validation outputs for the given actions and metadata.", "response": "def _compute_validation_outputs(self,\n                                    actions: List[List[ProductionRule]],\n                                    best_final_states: Mapping[int, Sequence[GrammarBasedState]],\n                                    world: List[WikiTablesWorld],\n                                    example_lisp_string: List[str],\n                                    metadata: List[Dict[str, Any]],\n                                    outputs: Dict[str, Any]) -> None:\n        \"\"\"\n        Does common things for validation time: computing logical form accuracy (which is expensive\n        and unnecessary during training), adding visualization info to the output dictionary, etc.\n\n        This doesn't return anything; instead it `modifies` the given ``outputs`` dictionary, and\n        calls metrics on ``self``.\n        \"\"\"\n        batch_size = len(actions)\n        action_mapping = {}\n        for batch_index, batch_actions in enumerate(actions):\n            for action_index, action in enumerate(batch_actions):\n                action_mapping[(batch_index, action_index)] = action[0]\n        outputs['action_mapping'] = action_mapping\n        outputs['best_action_sequence'] = []\n        outputs['debug_info'] = []\n        outputs['entities'] = []\n        outputs['logical_form'] = []\n        for i in range(batch_size):\n            # Decoding may not have terminated with any completed logical forms, if `num_steps`\n            # isn't long enough (or if the model is not trained enough and gets into an\n            # infinite action loop).\n            if i in best_final_states:\n                best_action_indices = best_final_states[i][0].action_history[0]\n                action_strings = [action_mapping[(i, action_index)] for action_index in best_action_indices]\n                try:\n                    logical_form = world[i].get_logical_form(action_strings, add_var_function=False)\n                    self._has_logical_form(1.0)\n                except ParsingError:\n                    self._has_logical_form(0.0)\n                    logical_form = 'Error producing logical form'\n                if example_lisp_string:\n                    denotation_correct = self._executor.evaluate_logical_form(logical_form,\n                                                                              example_lisp_string[i])\n                    self._denotation_accuracy(1.0 if denotation_correct else 0.0)\n                outputs['best_action_sequence'].append(action_strings)\n                outputs['logical_form'].append(logical_form)\n                outputs['debug_info'].append(best_final_states[i][0].debug_info[0])  # type: ignore\n                outputs['entities'].append(world[i].table_graph.entities)\n            else:\n                outputs['logical_form'].append('')\n                self._has_logical_form(0.0)\n                self._denotation_accuracy(0.0)\n        if metadata is not None:\n            outputs[\"question_tokens\"] = [x[\"question_tokens\"] for x in metadata]\n            outputs[\"original_table\"] = [x[\"original_table\"] for x in metadata]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_linked_logits_addition(checklist_state: ChecklistStatelet,\n                                    action_ids: List[int],\n                                    action_logits: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Gets the logits of desired terminal actions yet to be produced by the decoder, and\n        returns them for the decoder to add to the prior action logits, biasing the model towards\n        predicting missing linked actions.\n        \"\"\"\n        # Our basic approach here will be to figure out which actions we want to bias, by doing\n        # some fancy indexing work, then multiply the action embeddings by a mask for those\n        # actions, and return the sum of the result.\n\n        # Shape: (num_terminal_actions, 1).  This is 1 if we still want to predict something on the\n        # checklist, and 0 otherwise.\n        checklist_balance = checklist_state.get_balance().clamp(min=0)\n\n        # (num_terminal_actions, 1)\n        actions_in_agenda = checklist_state.terminal_actions\n        # (1, num_current_actions)\n        action_id_tensor = checklist_balance.new(action_ids).long().unsqueeze(0)\n        # Shape: (num_terminal_actions, num_current_actions).  Will have a value of 1 if the\n        # terminal action i is our current action j, and a value of 0 otherwise.  Because both sets\n        # of actions are free of duplicates, there will be at most one non-zero value per current\n        # action, and per terminal action.\n        current_agenda_actions = (actions_in_agenda == action_id_tensor).float()\n\n        # Shape: (num_current_actions,).  With the inner multiplication, we remove any current\n        # agenda actions that are not in our checklist balance, then we sum over the terminal\n        # action dimension, which will have a sum of at most one.  So this will be a 0/1 tensor,\n        # where a 1 means to encourage the current action in that position.\n        actions_to_encourage = torch.sum(current_agenda_actions * checklist_balance, dim=0)\n\n        # Shape: (num_current_actions,).  This is the sum of the action embeddings that we want\n        # the model to prefer.\n        logit_addition = action_logits * actions_to_encourage\n        return logit_addition", "response": "Gets the logits of desired terminal actions that need to be added to the prior model."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef attend_on_question(self,\n                           query: torch.Tensor,\n                           encoder_outputs: torch.Tensor,\n                           encoder_output_mask: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Given a query (which is typically the decoder hidden state), compute an attention over the\n        output of the question encoder, and return a weighted sum of the question representations\n        given this attention.  We also return the attention weights themselves.\n\n        This is a simple computation, but we have it as a separate method so that the ``forward``\n        method on the main parser module can call it on the initial hidden state, to simplify the\n        logic in ``take_step``.\n        \"\"\"\n        # (group_size, question_length)\n        question_attention_weights = self._input_attention(query,\n                                                           encoder_outputs,\n                                                           encoder_output_mask)\n        # (group_size, encoder_output_dim)\n        attended_question = util.weighted_sum(encoder_outputs, question_attention_weights)\n        return attended_question, question_attention_weights", "response": "Given a query and encoder outputs and encoder outputs compute an attendant over the encoder outputs and return the sum of the question representations\n        given this attention."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwalk over the action space to collect completed paths of at most self. _max_path_length steps.", "response": "def _walk(self) -> None:\n        \"\"\"\n        Walk over action space to collect completed paths of at most ``self._max_path_length`` steps.\n        \"\"\"\n        # Buffer of NTs to expand, previous actions\n        incomplete_paths = [([str(type_)], [f\"{START_SYMBOL} -> {type_}\"]) for type_ in\n                            self._world.get_valid_starting_types()]\n\n        self._completed_paths = []\n        actions = self._world.get_valid_actions()\n        # Keeps track of `MultiMatchNamedBasicTypes` to substitute them with appropriate types.\n        multi_match_substitutions = self._world.get_multi_match_mapping()\n        # Overview: We keep track of the buffer of non-terminals to expand, and the action history\n        # for each incomplete path. At every iteration in the while loop below, we iterate over all\n        # incomplete paths, expand one non-terminal from the buffer in a depth-first fashion, get\n        # all possible next actions triggered by that non-terminal and add to the paths. Then, we\n        # check the expanded paths, to see if they are 1) complete, in which case they are\n        # added to completed_paths, 2) longer than max_path_length, in which case they are\n        # discarded, or 3) neither, in which case they are used to form the incomplete_paths for the\n        # next iteration of this while loop.\n        # While the non-terminal expansion is done in a depth-first fashion, note that the search over\n        # the action space itself is breadth-first.\n        while incomplete_paths:\n            next_paths = []\n            for nonterminal_buffer, history in incomplete_paths:\n                # Taking the last non-terminal added to the buffer. We're going depth-first.\n                nonterminal = nonterminal_buffer.pop()\n                next_actions = []\n                if nonterminal in multi_match_substitutions:\n                    for current_nonterminal in [nonterminal] + multi_match_substitutions[nonterminal]:\n                        if current_nonterminal in actions:\n                            next_actions.extend(actions[current_nonterminal])\n                elif nonterminal not in actions:\n                    # This happens when the nonterminal corresponds to a type that does not exist in\n                    # the context. For example, in the variable free variant of the WikiTables\n                    # world, there are nonterminals for specific column types (like date). Say we\n                    # produced a path containing \"filter_date_greater\" already, and we do not have\n                    # an columns of type \"date\", then this condition would be triggered. We should\n                    # just discard those paths.\n                    continue\n                else:\n                    next_actions.extend(actions[nonterminal])\n                # Iterating over all possible next actions.\n                for action in next_actions:\n                    new_history = history + [action]\n                    new_nonterminal_buffer = nonterminal_buffer[:]\n                    # Since we expand the last action added to the buffer, the left child should be\n                    # added after the right child.\n                    for right_side_part in reversed(self._get_right_side_parts(action)):\n                        if types.is_nonterminal(right_side_part):\n                            new_nonterminal_buffer.append(right_side_part)\n                    next_paths.append((new_nonterminal_buffer, new_history))\n            incomplete_paths = []\n            for nonterminal_buffer, path in next_paths:\n                # An empty buffer means that we've completed this path.\n                if not nonterminal_buffer:\n                    # Indexing completed paths by the nonterminals they contain.\n                    next_path_index = len(self._completed_paths)\n                    for action in path:\n                        for value in self._get_right_side_parts(action):\n                            if not types.is_nonterminal(value):\n                                self._terminal_path_index[action].add(next_path_index)\n                    self._completed_paths.append(path)\n                # We're adding to incomplete_paths for the next iteration, only those paths that are\n                # shorter than the max_path_length. The remaining paths will be discarded.\n                elif len(path) <= self._max_path_length:\n                    incomplete_paths.append((nonterminal_buffer, path))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck that all the fields and types of the instances are the same.", "response": "def _check_types(self) -> None:\n        \"\"\"\n        Check that all the instances have the same types.\n        \"\"\"\n        all_instance_fields_and_types: List[Dict[str, str]] = [{k: v.__class__.__name__\n                                                                for k, v in x.fields.items()}\n                                                               for x in self.instances]\n        # Check all the field names and Field types are the same for every instance.\n        if not all([all_instance_fields_and_types[0] == x for x in all_instance_fields_and_types]):\n            raise ConfigurationError(\"You cannot construct a Batch with non-homogeneous Instances.\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_padding_lengths(self) -> Dict[str, Dict[str, int]]:\n        padding_lengths: Dict[str, Dict[str, int]] = defaultdict(dict)\n        all_instance_lengths: List[Dict[str, Dict[str, int]]] = [instance.get_padding_lengths()\n                                                                 for instance in self.instances]\n        if not all_instance_lengths:\n            return {**padding_lengths}\n        all_field_lengths: Dict[str, List[Dict[str, int]]] = defaultdict(list)\n        for instance_lengths in all_instance_lengths:\n            for field_name, instance_field_lengths in instance_lengths.items():\n                all_field_lengths[field_name].append(instance_field_lengths)\n        for field_name, field_lengths in all_field_lengths.items():\n            for padding_key in field_lengths[0].keys():\n                max_value = max(x[padding_key] if padding_key in x else 0 for x in field_lengths)\n                padding_lengths[field_name][padding_key] = max_value\n        return {**padding_lengths}", "response": "Gets the maximum padding lengths from all Instances and Fields in this batch."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting this batch into a dictionary of pytorch Tensors.", "response": "def as_tensor_dict(self,\n                       padding_lengths: Dict[str, Dict[str, int]] = None,\n                       verbose: bool = False) -> Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor]]]:\n        # This complex return type is actually predefined elsewhere as a DataArray,\n        # but we can't use it because mypy doesn't like it.\n        \"\"\"\n        This method converts this ``Batch`` into a set of pytorch Tensors that can be passed\n        through a model.  In order for the tensors to be valid tensors, all ``Instances`` in this\n        batch need to be padded to the same lengths wherever padding is necessary, so we do that\n        first, then we combine all of the tensors for each field in each instance into a set of\n        batched tensors for each field.\n\n        Parameters\n        ----------\n        padding_lengths : ``Dict[str, Dict[str, int]]``\n            If a key is present in this dictionary with a non-``None`` value, we will pad to that\n            length instead of the length calculated from the data.  This lets you, e.g., set a\n            maximum value for sentence length if you want to throw out long sequences.\n\n            Entries in this dictionary are keyed first by field name (e.g., \"question\"), then by\n            padding key (e.g., \"num_tokens\").\n        verbose : ``bool``, optional (default=``False``)\n            Should we output logging information when we're doing this padding?  If the batch is\n            large, this is nice to have, because padding a large batch could take a long time.\n            But if you're doing this inside of a data generator, having all of this output per\n            batch is a bit obnoxious (and really slow).\n\n        Returns\n        -------\n        tensors : ``Dict[str, DataArray]``\n            A dictionary of tensors, keyed by field name, suitable for passing as input to a model.\n            This is a `batch` of instances, so, e.g., if the instances have a \"question\" field and\n            an \"answer\" field, the \"question\" fields for all of the instances will be grouped\n            together into a single tensor, and the \"answer\" fields for all instances will be\n            similarly grouped in a parallel set of tensors, for batched computation. Additionally,\n            for complex ``Fields``, the value of the dictionary key is not necessarily a single\n            tensor.  For example, with the ``TextField``, the output is a dictionary mapping\n            ``TokenIndexer`` keys to tensors. The number of elements in this sub-dictionary\n            therefore corresponds to the number of ``TokenIndexers`` used to index the\n            ``TextField``.  Each ``Field`` class is responsible for batching its own output.\n        \"\"\"\n        if padding_lengths is None:\n            padding_lengths = defaultdict(dict)\n        # First we need to decide _how much_ to pad.  To do that, we find the max length for all\n        # relevant padding decisions from the instances themselves.  Then we check whether we were\n        # given a max length for a particular field and padding key.  If we were, we use that\n        # instead of the instance-based one.\n        if verbose:\n            logger.info(\"Padding batch of size %d to lengths %s\", len(self.instances), str(padding_lengths))\n            logger.info(\"Getting max lengths from instances\")\n        instance_padding_lengths = self.get_padding_lengths()\n        if verbose:\n            logger.info(\"Instance max lengths: %s\", str(instance_padding_lengths))\n        lengths_to_use: Dict[str, Dict[str, int]] = defaultdict(dict)\n        for field_name, instance_field_lengths in instance_padding_lengths.items():\n            for padding_key in instance_field_lengths.keys():\n                if padding_lengths[field_name].get(padding_key) is not None:\n                    lengths_to_use[field_name][padding_key] = padding_lengths[field_name][padding_key]\n                else:\n                    lengths_to_use[field_name][padding_key] = instance_field_lengths[padding_key]\n\n        # Now we actually pad the instances to tensors.\n        field_tensors: Dict[str, list] = defaultdict(list)\n        if verbose:\n            logger.info(\"Now actually padding instances to length: %s\", str(lengths_to_use))\n        for instance in self.instances:\n            for field, tensors in instance.as_tensor_dict(lengths_to_use).items():\n                field_tensors[field].append(tensors)\n\n        # Finally, we combine the tensors that we got for each instance into one big tensor (or set\n        # of tensors) per field.  The `Field` classes themselves have the logic for batching the\n        # tensors together, so we grab a dictionary of field_name -> field class from the first\n        # instance in the batch.\n        field_classes = self.instances[0].fields\n        final_fields = {}\n        for field_name, field_tensor_list in field_tensors.items():\n            final_fields[field_name] = field_classes[field_name].batch_tensors(field_tensor_list)\n        return final_fields"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dictionary where the keys are the strings in the database that map to lists of the token indices that they are linked to.", "response": "def get_strings_from_utterance(tokenized_utterance: List[Token]) -> Dict[str, List[int]]:\n    \"\"\"\n    Based on the current utterance, return a dictionary where the keys are the strings in\n    the database that map to lists of the token indices that they are linked to.\n    \"\"\"\n    string_linking_scores: Dict[str, List[int]] = defaultdict(list)\n\n    for index, token in enumerate(tokenized_utterance):\n        for string in ATIS_TRIGGER_DICT.get(token.text.lower(), []):\n            string_linking_scores[string].append(index)\n\n    token_bigrams = bigrams([token.text for token in tokenized_utterance])\n    for index, token_bigram in enumerate(token_bigrams):\n        for string in ATIS_TRIGGER_DICT.get(' '.join(token_bigram).lower(), []):\n            string_linking_scores[string].extend([index,\n                                                  index + 1])\n\n    trigrams = ngrams([token.text for token in tokenized_utterance], 3)\n    for index, trigram in enumerate(trigrams):\n        if trigram[0] == 'st':\n            natural_language_key = f'st. {trigram[2]}'.lower()\n        else:\n            natural_language_key = ' '.join(trigram).lower()\n        for string in ATIS_TRIGGER_DICT.get(natural_language_key, []):\n            string_linking_scores[string].extend([index,\n                                                  index + 1,\n                                                  index + 2])\n    return string_linking_scores"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _update_grammar(self):\n\n        # This will give us a shallow copy. We have to be careful here because the ``Grammar`` object\n        # contains ``Expression`` objects that have tuples containing the members of that expression.\n        # We have to create new sub-expression objects so that original grammar is not mutated.\n        new_grammar = copy(AtisWorld.sql_table_context.grammar)\n\n        for numeric_nonterminal in NUMERIC_NONTERMINALS:\n            self._add_numeric_nonterminal_to_grammar(numeric_nonterminal, new_grammar)\n        self._update_expression_reference(new_grammar, 'pos_value', 'number')\n\n        ternary_expressions = [self._get_sequence_with_spacing(new_grammar,\n                                                               [new_grammar['col_ref'],\n                                                                Literal('BETWEEN'),\n                                                                new_grammar['time_range_start'],\n                                                                Literal(f'AND'),\n                                                                new_grammar['time_range_end']]),\n                               self._get_sequence_with_spacing(new_grammar,\n                                                               [new_grammar['col_ref'],\n                                                                Literal('NOT'),\n                                                                Literal('BETWEEN'),\n                                                                new_grammar['time_range_start'],\n                                                                Literal(f'AND'),\n                                                                new_grammar['time_range_end']]),\n                               self._get_sequence_with_spacing(new_grammar,\n                                                               [new_grammar['col_ref'],\n                                                                Literal('not'),\n                                                                Literal('BETWEEN'),\n                                                                new_grammar['time_range_start'],\n                                                                Literal(f'AND'),\n                                                                new_grammar['time_range_end']])]\n\n        new_grammar['ternaryexpr'] = OneOf(*ternary_expressions, name='ternaryexpr')\n        self._update_expression_reference(new_grammar, 'condition', 'ternaryexpr')\n\n        new_binary_expressions = []\n\n        fare_round_trip_cost_expression = \\\n                    self._get_sequence_with_spacing(new_grammar,\n                                                    [Literal('fare'),\n                                                     Literal('.'),\n                                                     Literal('round_trip_cost'),\n                                                     new_grammar['binaryop'],\n                                                     new_grammar['fare_round_trip_cost']])\n        new_binary_expressions.append(fare_round_trip_cost_expression)\n\n        fare_one_direction_cost_expression = \\\n                    self._get_sequence_with_spacing(new_grammar,\n                                                    [Literal('fare'),\n                                                     Literal('.'),\n                                                     Literal('one_direction_cost'),\n                                                     new_grammar['binaryop'],\n                                                     new_grammar['fare_one_direction_cost']])\n\n        new_binary_expressions.append(fare_one_direction_cost_expression)\n\n        flight_number_expression = \\\n                    self._get_sequence_with_spacing(new_grammar,\n                                                    [Literal('flight'),\n                                                     Literal('.'),\n                                                     Literal('flight_number'),\n                                                     new_grammar['binaryop'],\n                                                     new_grammar['flight_number']])\n        new_binary_expressions.append(flight_number_expression)\n\n        if self.dates:\n            year_binary_expression = self._get_sequence_with_spacing(new_grammar,\n                                                                     [Literal('date_day'),\n                                                                      Literal('.'),\n                                                                      Literal('year'),\n                                                                      new_grammar['binaryop'],\n                                                                      new_grammar['year_number']])\n            month_binary_expression = self._get_sequence_with_spacing(new_grammar,\n                                                                      [Literal('date_day'),\n                                                                       Literal('.'),\n                                                                       Literal('month_number'),\n                                                                       new_grammar['binaryop'],\n                                                                       new_grammar['month_number']])\n            day_binary_expression = self._get_sequence_with_spacing(new_grammar,\n                                                                    [Literal('date_day'),\n                                                                     Literal('.'),\n                                                                     Literal('day_number'),\n                                                                     new_grammar['binaryop'],\n                                                                     new_grammar['day_number']])\n            new_binary_expressions.extend([year_binary_expression,\n                                           month_binary_expression,\n                                           day_binary_expression])\n\n        new_binary_expressions = new_binary_expressions + list(new_grammar['biexpr'].members)\n        new_grammar['biexpr'] = OneOf(*new_binary_expressions, name='biexpr')\n        self._update_expression_reference(new_grammar, 'condition', 'biexpr')\n        return new_grammar", "response": "Update the grammar of the atis sql table context."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the expression reference in the grammar.", "response": "def _update_expression_reference(self, # pylint: disable=no-self-use\n                                     grammar: Grammar,\n                                     parent_expression_nonterminal: str,\n                                     child_expression_nonterminal: str) -> None:\n        \"\"\"\n        When we add a new expression, there may be other expressions that refer to\n        it, and we need to update those to point to the new expression.\n        \"\"\"\n        grammar[parent_expression_nonterminal].members = \\\n                [member if member.name != child_expression_nonterminal\n                 else grammar[child_expression_nonterminal]\n                 for member in grammar[parent_expression_nonterminal].members]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_sequence_with_spacing(self, # pylint: disable=no-self-use\n                                   new_grammar,\n                                   expressions: List[Expression],\n                                   name: str = '') -> Sequence:\n        \"\"\"\n        This is a helper method for generating sequences, since we often want a list of expressions\n        with whitespaces between them.\n        \"\"\"\n        expressions = [subexpression\n                       for expression in expressions\n                       for subexpression in (expression, new_grammar['ws'])]\n        return Sequence(*expressions, name=name)", "response": "This method is a helper method for generating a sequence of new_grammar with whitespaces between expressions."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_to_number_linking_scores(self,\n                                     all_numbers: Set[str],\n                                     number_linking_scores: Dict[str, Tuple[str, str, List[int]]],\n                                     get_number_linking_dict: Callable[[str, List[Token]],\n                                                                       Dict[str, List[int]]],\n                                     current_tokenized_utterance: List[Token],\n                                     nonterminal: str) -> None:\n        \"\"\"\n        This is a helper method for adding different types of numbers (eg. starting time ranges) as entities.\n        We first go through all utterances in the interaction and find the numbers of a certain type and add\n        them to the set ``all_numbers``, which is initialized with default values. We want to add all numbers\n        that occur in the interaction, and not just the current turn because the query could contain numbers\n        that were triggered before the current turn. For each entity, we then check if it is triggered by tokens\n        in the current utterance and construct the linking score.\n        \"\"\"\n        number_linking_dict: Dict[str, List[int]] = {}\n        for utterance, tokenized_utterance in zip(self.utterances, self.tokenized_utterances):\n            number_linking_dict = get_number_linking_dict(utterance, tokenized_utterance)\n            all_numbers.update(number_linking_dict.keys())\n        all_numbers_list: List[str] = sorted(all_numbers, reverse=True)\n        for number in all_numbers_list:\n            entity_linking = [0 for token in current_tokenized_utterance]\n            # ``number_linking_dict`` is for the last utterance here. If the number was triggered\n            # before the last utterance, then it will have linking scores of 0's.\n            for token_index in number_linking_dict.get(number, []):\n                if token_index < len(entity_linking):\n                    entity_linking[token_index] = 1\n            action = format_action(nonterminal, number, is_number=True, keywords_to_uppercase=KEYWORDS)\n            number_linking_scores[action] = (nonterminal, number, entity_linking)", "response": "This method adds the number linking scores of all the utterances that occur in the current utterance and the current tokenized utterance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of all possible actions in the current directory.", "response": "def all_possible_actions(self) -> List[str]:\n        \"\"\"\n        Return a sorted list of strings representing all possible actions\n        of the form: nonterminal -> [right_hand_side]\n        \"\"\"\n        all_actions = set()\n        for _, action_list in self.valid_actions.items():\n            for action in action_list:\n                all_actions.add(action)\n        return sorted(all_actions)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _flatten_entities(self) -> Tuple[List[str], numpy.ndarray]:\n        entities = []\n        linking_scores = []\n        for entity in sorted(self.linked_entities['number']):\n            entities.append(entity)\n            linking_scores.append(self.linked_entities['number'][entity][2])\n\n        for entity in sorted(self.linked_entities['string']):\n            entities.append(entity)\n            linking_scores.append(self.linked_entities['string'][entity][2])\n\n        return entities, numpy.array(linking_scores)", "response": "Flatten the entities and linking scores for the current language."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a Flask app that serves up a simple configuration wizard.", "response": "def make_app(include_packages: Sequence[str] = ()) -> Flask:\n    \"\"\"\n    Creates a Flask app that serves up a simple configuration wizard.\n    \"\"\"\n    # Load modules\n    for package_name in include_packages:\n        import_submodules(package_name)\n\n    app = Flask(__name__)  # pylint: disable=invalid-name\n\n    @app.errorhandler(ServerError)\n    def handle_invalid_usage(error: ServerError) -> Response:  # pylint: disable=unused-variable\n        response = jsonify(error.to_dict())\n        response.status_code = error.status_code\n        return response\n\n    @app.route('/')\n    def index() -> Response:  # pylint: disable=unused-variable\n        return send_file('config_explorer.html')\n\n    @app.route('/api/config/')\n    def api_config() -> Response:  # pylint: disable=unused-variable\n        \"\"\"\n        There are basically two things that can happen here.\n        If this method is called with a ``Registrable`` class (e.g. ``Model``),\n        it should return the list of possible ``Model`` subclasses.\n        If it is called with an instantiable subclass (e.g. ``CrfTagger``),\n        is should return the config for that subclass.\n\n        This is complicated by the fact that some Registrable base classes\n        (e.g. Vocabulary, Trainer) are _themselves_ instantiable.\n\n        We handle this in two ways: first, we insist that the first case\n        include an extra ``get_choices`` parameter. That is, if you call\n        this method for ``Trainer`` with get_choices=true, you get the list\n        of Trainer subclasses. If you call it without that extra flag, you\n        get the config for the class itself.\n\n        There are basically two UX situations in which this API is called.\n        The first is when you have a dropdown list of choices (e.g. Model types)\n        and you select one. Such an API request is made *without* the get_choices flag,\n        which means that the config is returned *even if the class in question\n        is a Registrable class that has subclass choices*.\n\n        The second is when you click a \"Configure\" button, which configures\n        a class that may (e.g. ``Model``) or may not (e.g. ``FeedForward``)\n        have registrable subclasses. In this case the API request is made\n        with the \"get_choices\" flag, but will return the corresponding config\n        object if no choices are available (e.g. in the ``FeedForward``) case.\n\n        This is not elegant, but it works.\n        \"\"\"\n        class_name = request.args.get('class', '')\n        get_choices = request.args.get('get_choices', None)\n\n        # Get the configuration for this class name\n        config = configure(class_name)\n        try:\n            # May not have choices\n            choice5 = choices(class_name)\n        except ValueError:\n            choice5 = []\n\n        if get_choices and choice5:\n            return jsonify({\n                    \"className\": class_name,\n                    \"choices\": choice5\n            })\n        else:\n            return jsonify({\n                    \"className\": class_name,\n                    \"config\": config.to_json()\n            })\n\n    return app"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef train_model_from_file(parameter_filename: str,\n                          serialization_dir: str,\n                          overrides: str = \"\",\n                          file_friendly_logging: bool = False,\n                          recover: bool = False,\n                          force: bool = False,\n                          cache_directory: str = None,\n                          cache_prefix: str = None) -> Model:\n    \"\"\"\n    A wrapper around :func:`train_model` which loads the params from a file.\n\n    Parameters\n    ----------\n    parameter_filename : ``str``\n        A json parameter file specifying an AllenNLP experiment.\n    serialization_dir : ``str``\n        The directory in which to save results and logs. We just pass this along to\n        :func:`train_model`.\n    overrides : ``str``\n        A JSON string that we will use to override values in the input parameter file.\n    file_friendly_logging : ``bool``, optional (default=False)\n        If ``True``, we make our output more friendly to saved model files.  We just pass this\n        along to :func:`train_model`.\n    recover : ``bool`, optional (default=False)\n        If ``True``, we will try to recover a training run from an existing serialization\n        directory.  This is only intended for use when something actually crashed during the middle\n        of a run.  For continuing training a model on new data, see the ``fine-tune`` command.\n    force : ``bool``, optional (default=False)\n        If ``True``, we will overwrite the serialization directory if it already exists.\n    cache_directory : ``str``, optional\n        For caching data pre-processing.  See :func:`allennlp.training.util.datasets_from_params`.\n    cache_prefix : ``str``, optional\n        For caching data pre-processing.  See :func:`allennlp.training.util.datasets_from_params`.\n    \"\"\"\n    # Load the experiment config from a file and pass it to ``train_model``.\n    params = Params.from_file(parameter_filename, overrides)\n    return train_model(params,\n                       serialization_dir,\n                       file_friendly_logging,\n                       recover,\n                       force,\n                       cache_directory, cache_prefix)", "response": "Loads the model from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef train_model(params: Params,\n                serialization_dir: str,\n                file_friendly_logging: bool = False,\n                recover: bool = False,\n                force: bool = False,\n                cache_directory: str = None,\n                cache_prefix: str = None) -> Model:\n    \"\"\"\n    Trains the model specified in the given :class:`Params` object, using the data and training\n    parameters also specified in that object, and saves the results in ``serialization_dir``.\n\n    Parameters\n    ----------\n    params : ``Params``\n        A parameter object specifying an AllenNLP Experiment.\n    serialization_dir : ``str``\n        The directory in which to save results and logs.\n    file_friendly_logging : ``bool``, optional (default=False)\n        If ``True``, we add newlines to tqdm output, even on an interactive terminal, and we slow\n        down tqdm's output to only once every 10 seconds.\n    recover : ``bool``, optional (default=False)\n        If ``True``, we will try to recover a training run from an existing serialization\n        directory.  This is only intended for use when something actually crashed during the middle\n        of a run.  For continuing training a model on new data, see the ``fine-tune`` command.\n    force : ``bool``, optional (default=False)\n        If ``True``, we will overwrite the serialization directory if it already exists.\n    cache_directory : ``str``, optional\n        For caching data pre-processing.  See :func:`allennlp.training.util.datasets_from_params`.\n    cache_prefix : ``str``, optional\n        For caching data pre-processing.  See :func:`allennlp.training.util.datasets_from_params`.\n\n    Returns\n    -------\n    best_model: ``Model``\n        The model with the best epoch weights.\n    \"\"\"\n    prepare_environment(params)\n    create_serialization_dir(params, serialization_dir, recover, force)\n    stdout_handler = prepare_global_logging(serialization_dir, file_friendly_logging)\n\n    cuda_device = params.params.get('trainer').get('cuda_device', -1)\n    check_for_gpu(cuda_device)\n\n    params.to_file(os.path.join(serialization_dir, CONFIG_NAME))\n\n    evaluate_on_test = params.pop_bool(\"evaluate_on_test\", False)\n\n    trainer_type = params.get(\"trainer\", {}).get(\"type\", \"default\")\n\n    if trainer_type == \"default\":\n        # Special logic to instantiate backward-compatible trainer.\n        pieces = TrainerPieces.from_params(params,  # pylint: disable=no-member\n                                           serialization_dir,\n                                           recover,\n                                           cache_directory,\n                                           cache_prefix)\n        trainer = Trainer.from_params(\n                model=pieces.model,\n                serialization_dir=serialization_dir,\n                iterator=pieces.iterator,\n                train_data=pieces.train_dataset,\n                validation_data=pieces.validation_dataset,\n                params=pieces.params,\n                validation_iterator=pieces.validation_iterator)\n        evaluation_iterator = pieces.validation_iterator or pieces.iterator\n        evaluation_dataset = pieces.test_dataset\n\n    else:\n        trainer = TrainerBase.from_params(params, serialization_dir, recover)\n        # TODO(joelgrus): handle evaluation in the general case\n        evaluation_iterator = evaluation_dataset = None\n\n    params.assert_empty('base train command')\n\n    try:\n        metrics = trainer.train()\n    except KeyboardInterrupt:\n        # if we have completed an epoch, try to create a model archive.\n        if os.path.exists(os.path.join(serialization_dir, _DEFAULT_WEIGHTS)):\n            logging.info(\"Training interrupted by the user. Attempting to create \"\n                         \"a model archive using the current best epoch weights.\")\n            archive_model(serialization_dir, files_to_archive=params.files_to_archive)\n        raise\n\n    # Evaluate\n    if evaluation_dataset and evaluate_on_test:\n        logger.info(\"The model will be evaluated using the best epoch weights.\")\n        test_metrics = evaluate(trainer.model, evaluation_dataset, evaluation_iterator,\n                                cuda_device=trainer._cuda_devices[0], # pylint: disable=protected-access,\n                                # TODO(brendanr): Pass in an arg following Joel's trainer refactor.\n                                batch_weight_key=\"\")\n\n        for key, value in test_metrics.items():\n            metrics[\"test_\" + key] = value\n\n    elif evaluation_dataset:\n        logger.info(\"To evaluate on the test set after training, pass the \"\n                    \"'evaluate_on_test' flag, or use the 'allennlp evaluate' command.\")\n\n    cleanup_global_logging(stdout_handler)\n\n    # Now tar up results\n    archive_model(serialization_dir, files_to_archive=params.files_to_archive)\n    dump_metrics(os.path.join(serialization_dir, \"metrics.json\"), metrics, log=True)\n\n    # We count on the trainer to have the model with best weights\n    return trainer.model", "response": "Train the model specified in the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform division and handles divide - by - zero.", "response": "def _prf_divide(numerator, denominator):\n    \"\"\"Performs division and handles divide-by-zero.\n\n    On zero-division, sets the corresponding result elements to zero.\n    \"\"\"\n    result = numerator / denominator\n    mask = denominator == 0.0\n    if not mask.any():\n        return result\n\n    # remove nan\n    result[mask] = 0.0\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading the data from a file.", "response": "def load_data(file_path: str) -> Tuple[List[str], List[str]]:\n    \"\"\"\n    One sentence per line, formatted like\n\n        The###DET dog###NN ate###V the###DET apple###NN\n\n    Returns a list of pairs (tokenized_sentence, tags)\n    \"\"\"\n    data = []\n\n    with open(file_path) as f:\n        for line in f:\n            pairs = line.strip().split()\n            sentence, tags = zip(*(pair.split(\"###\") for pair in pairs))\n            data.append((sentence, tags))\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pop_max_vocab_size(params: Params) -> Union[int, Dict[str, int]]:\n    size = params.pop(\"max_vocab_size\", None)\n\n    if isinstance(size, Params):\n        # This is the Dict[str, int] case.\n        return size.as_dict()\n    elif size is not None:\n        # This is the int / str case.\n        return int(size)\n    else:\n        return None", "response": "Pops the max_vocab_size from the params and returns it as a dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves this Vocabulary to files.", "response": "def save_to_files(self, directory: str) -> None:\n        \"\"\"\n        Persist this Vocabulary to files so it can be reloaded later.\n        Each namespace corresponds to one file.\n\n        Parameters\n        ----------\n        directory : ``str``\n            The directory where we save the serialized vocabulary.\n        \"\"\"\n        os.makedirs(directory, exist_ok=True)\n        if os.listdir(directory):\n            logging.warning(\"vocabulary serialization directory %s is not empty\", directory)\n\n        with codecs.open(os.path.join(directory, NAMESPACE_PADDING_FILE), 'w', 'utf-8') as namespace_file:\n            for namespace_str in self._non_padded_namespaces:\n                print(namespace_str, file=namespace_file)\n\n        for namespace, mapping in self._index_to_token.items():\n            # Each namespace gets written to its own file, in index order.\n            with codecs.open(os.path.join(directory, namespace + '.txt'), 'w', 'utf-8') as token_file:\n                num_tokens = len(mapping)\n                start_index = 1 if mapping[0] == self._padding_token else 0\n                for i in range(start_index, num_tokens):\n                    print(mapping[i].replace('\\n', '@@NEWLINE@@'), file=token_file)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_files(cls, directory: str) -> 'Vocabulary':\n        logger.info(\"Loading token dictionary from %s.\", directory)\n        with codecs.open(os.path.join(directory, NAMESPACE_PADDING_FILE), 'r', 'utf-8') as namespace_file:\n            non_padded_namespaces = [namespace_str.strip() for namespace_str in namespace_file]\n\n        vocab = cls(non_padded_namespaces=non_padded_namespaces)\n\n        # Check every file in the directory.\n        for namespace_filename in os.listdir(directory):\n            if namespace_filename == NAMESPACE_PADDING_FILE:\n                continue\n            if namespace_filename.startswith(\".\"):\n                continue\n            namespace = namespace_filename.replace('.txt', '')\n            if any(namespace_match(pattern, namespace) for pattern in non_padded_namespaces):\n                is_padded = False\n            else:\n                is_padded = True\n            filename = os.path.join(directory, namespace_filename)\n            vocab.set_from_file(filename, is_padded, namespace=namespace)\n\n        return vocab", "response": "Loads a vocabulary from a directory containing the serialized vocabulary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_from_file(self,\n                      filename: str,\n                      is_padded: bool = True,\n                      oov_token: str = DEFAULT_OOV_TOKEN,\n                      namespace: str = \"tokens\"):\n        \"\"\"\n        If you already have a vocabulary file for a trained model somewhere, and you really want to\n        use that vocabulary file instead of just setting the vocabulary from a dataset, for\n        whatever reason, you can do that with this method.  You must specify the namespace to use,\n        and we assume that you want to use padding and OOV tokens for this.\n\n        Parameters\n        ----------\n        filename : ``str``\n            The file containing the vocabulary to load.  It should be formatted as one token per\n            line, with nothing else in the line.  The index we assign to the token is the line\n            number in the file (1-indexed if ``is_padded``, 0-indexed otherwise).  Note that this\n            file should contain the OOV token string!\n        is_padded : ``bool``, optional (default=True)\n            Is this vocabulary padded?  For token / word / character vocabularies, this should be\n            ``True``; while for tag or label vocabularies, this should typically be ``False``.  If\n            ``True``, we add a padding token with index 0, and we enforce that the ``oov_token`` is\n            present in the file.\n        oov_token : ``str``, optional (default=DEFAULT_OOV_TOKEN)\n            What token does this vocabulary use to represent out-of-vocabulary characters?  This\n            must show up as a line in the vocabulary file.  When we find it, we replace\n            ``oov_token`` with ``self._oov_token``, because we only use one OOV token across\n            namespaces.\n        namespace : ``str``, optional (default=\"tokens\")\n            What namespace should we overwrite with this vocab file?\n        \"\"\"\n        if is_padded:\n            self._token_to_index[namespace] = {self._padding_token: 0}\n            self._index_to_token[namespace] = {0: self._padding_token}\n        else:\n            self._token_to_index[namespace] = {}\n            self._index_to_token[namespace] = {}\n        with codecs.open(filename, 'r', 'utf-8') as input_file:\n            lines = input_file.read().split('\\n')\n            # Be flexible about having final newline or not\n            if lines and lines[-1] == '':\n                lines = lines[:-1]\n            for i, line in enumerate(lines):\n                index = i + 1 if is_padded else i\n                token = line.replace('@@NEWLINE@@', '\\n')\n                if token == oov_token:\n                    token = self._oov_token\n                self._token_to_index[namespace][token] = index\n                self._index_to_token[namespace][index] = token\n        if is_padded:\n            assert self._oov_token in self._token_to_index[namespace], \"OOV token not found!\"", "response": "This method will set the vocabulary from a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_instances(cls,\n                       instances: Iterable['adi.Instance'],\n                       min_count: Dict[str, int] = None,\n                       max_vocab_size: Union[int, Dict[str, int]] = None,\n                       non_padded_namespaces: Iterable[str] = DEFAULT_NON_PADDED_NAMESPACES,\n                       pretrained_files: Optional[Dict[str, str]] = None,\n                       only_include_pretrained_words: bool = False,\n                       tokens_to_add: Dict[str, List[str]] = None,\n                       min_pretrained_embeddings: Dict[str, int] = None) -> 'Vocabulary':\n        \"\"\"\n        Constructs a vocabulary given a collection of `Instances` and some parameters.\n        We count all of the vocabulary items in the instances, then pass those counts\n        and the other parameters, to :func:`__init__`.  See that method for a description\n        of what the other parameters do.\n        \"\"\"\n        logger.info(\"Fitting token dictionary from dataset.\")\n        namespace_token_counts: Dict[str, Dict[str, int]] = defaultdict(lambda: defaultdict(int))\n        for instance in Tqdm.tqdm(instances):\n            instance.count_vocab_items(namespace_token_counts)\n\n        return cls(counter=namespace_token_counts,\n                   min_count=min_count,\n                   max_vocab_size=max_vocab_size,\n                   non_padded_namespaces=non_padded_namespaces,\n                   pretrained_files=pretrained_files,\n                   only_include_pretrained_words=only_include_pretrained_words,\n                   tokens_to_add=tokens_to_add,\n                   min_pretrained_embeddings=min_pretrained_embeddings)", "response": "Constructs a new vocabulary from a collection of adi. Instances."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_params(cls, params: Params, instances: Iterable['adi.Instance'] = None):  # type: ignore\n        # pylint: disable=arguments-differ\n        # Vocabulary is ``Registrable`` so that you can configure a custom subclass,\n        # but (unlike most of our registrables) almost everyone will want to use the\n        # base implementation. So instead of having an abstract ``VocabularyBase`` or\n        # such, we just add the logic for instantiating a registered subclass here,\n        # so that most users can continue doing what they were doing.\n        vocab_type = params.pop(\"type\", None)\n        if vocab_type is not None:\n            return cls.by_name(vocab_type).from_params(params=params, instances=instances)\n\n        extend = params.pop(\"extend\", False)\n        vocabulary_directory = params.pop(\"directory_path\", None)\n        if not vocabulary_directory and not instances:\n            raise ConfigurationError(\"You must provide either a Params object containing a \"\n                                     \"vocab_directory key or a Dataset to build a vocabulary from.\")\n        if extend and not instances:\n            raise ConfigurationError(\"'extend' is true but there are not instances passed to extend.\")\n        if extend and not vocabulary_directory:\n            raise ConfigurationError(\"'extend' is true but there is not 'directory_path' to extend from.\")\n\n        if vocabulary_directory and instances:\n            if extend:\n                logger.info(\"Loading Vocab from files and extending it with dataset.\")\n            else:\n                logger.info(\"Loading Vocab from files instead of dataset.\")\n\n        if vocabulary_directory:\n            vocab = cls.from_files(vocabulary_directory)\n            if not extend:\n                params.assert_empty(\"Vocabulary - from files\")\n                return vocab\n        if extend:\n            vocab.extend_from_instances(params, instances=instances)\n            return vocab\n        min_count = params.pop(\"min_count\", None)\n        max_vocab_size = pop_max_vocab_size(params)\n        non_padded_namespaces = params.pop(\"non_padded_namespaces\", DEFAULT_NON_PADDED_NAMESPACES)\n        pretrained_files = params.pop(\"pretrained_files\", {})\n        min_pretrained_embeddings = params.pop(\"min_pretrained_embeddings\", None)\n        only_include_pretrained_words = params.pop_bool(\"only_include_pretrained_words\", False)\n        tokens_to_add = params.pop(\"tokens_to_add\", None)\n        params.assert_empty(\"Vocabulary - from dataset\")\n        return cls.from_instances(instances=instances,\n                                  min_count=min_count,\n                                  max_vocab_size=max_vocab_size,\n                                  non_padded_namespaces=non_padded_namespaces,\n                                  pretrained_files=pretrained_files,\n                                  only_include_pretrained_words=only_include_pretrained_words,\n                                  tokens_to_add=tokens_to_add,\n                                  min_pretrained_embeddings=min_pretrained_embeddings)", "response": "Create a new instance of the class based on the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextending an already generated vocabulary using a collection of instances.", "response": "def extend_from_instances(self,\n                              params: Params,\n                              instances: Iterable['adi.Instance'] = ()) -> None:\n        \"\"\"\n        Extends an already generated vocabulary using a collection of instances.\n        \"\"\"\n        min_count = params.pop(\"min_count\", None)\n        max_vocab_size = pop_max_vocab_size(params)\n        non_padded_namespaces = params.pop(\"non_padded_namespaces\", DEFAULT_NON_PADDED_NAMESPACES)\n        pretrained_files = params.pop(\"pretrained_files\", {})\n        min_pretrained_embeddings = params.pop(\"min_pretrained_embeddings\", None)\n        only_include_pretrained_words = params.pop_bool(\"only_include_pretrained_words\", False)\n        tokens_to_add = params.pop(\"tokens_to_add\", None)\n        params.assert_empty(\"Vocabulary - from dataset\")\n\n        logger.info(\"Fitting token dictionary from dataset.\")\n        namespace_token_counts: Dict[str, Dict[str, int]] = defaultdict(lambda: defaultdict(int))\n        for instance in Tqdm.tqdm(instances):\n            instance.count_vocab_items(namespace_token_counts)\n        self._extend(counter=namespace_token_counts,\n                     min_count=min_count,\n                     max_vocab_size=max_vocab_size,\n                     non_padded_namespaces=non_padded_namespaces,\n                     pretrained_files=pretrained_files,\n                     only_include_pretrained_words=only_include_pretrained_words,\n                     tokens_to_add=tokens_to_add,\n                     min_pretrained_embeddings=min_pretrained_embeddings)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_padded(self, namespace: str) -> bool:\n        return self._index_to_token[namespace][0] == self._padding_token", "response": "Returns whether or not there are padding and OOV tokens added to the given namespace."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a token to the index if it is not already present.", "response": "def add_token_to_namespace(self, token: str, namespace: str = 'tokens') -> int:\n        \"\"\"\n        Adds ``token`` to the index, if it is not already present.  Either way, we return the index of\n        the token.\n        \"\"\"\n        if not isinstance(token, str):\n            raise ValueError(\"Vocabulary tokens must be strings, or saving and loading will break.\"\n                             \"  Got %s (with type %s)\" % (repr(token), type(token)))\n        if token not in self._token_to_index[namespace]:\n            index = len(self._token_to_index[namespace])\n            self._token_to_index[namespace][token] = index\n            self._index_to_token[namespace][index] = token\n            return index\n        else:\n            return self._token_to_index[namespace][token]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_regularization_penalty(self) -> Union[float, torch.Tensor]:\n        if self._regularizer is None:\n            return 0.0\n        else:\n            return self._regularizer(self)", "response": "Returns the regularization penalty for the current class."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef forward_on_instance(self, instance: Instance) -> Dict[str, numpy.ndarray]:\n        return self.forward_on_instances([instance])[0]", "response": "Forward the text in the given instance to the model s vocabulary and returns the first array."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a list of instances converts that text into arrays and decodes that text into numpy arrays and then runs the model on them.", "response": "def forward_on_instances(self,\n                             instances: List[Instance]) -> List[Dict[str, numpy.ndarray]]:\n        \"\"\"\n        Takes a list of  :class:`~allennlp.data.instance.Instance`s, converts that text into\n        arrays using this model's :class:`Vocabulary`, passes those arrays through\n        :func:`self.forward()` and :func:`self.decode()` (which by default does nothing)\n        and returns the result.  Before returning the result, we convert any\n        ``torch.Tensors`` into numpy arrays and separate the\n        batched output into a list of individual dicts per instance. Note that typically\n        this will be faster on a GPU (and conditionally, on a CPU) than repeated calls to\n        :func:`forward_on_instance`.\n\n        Parameters\n        ----------\n        instances : List[Instance], required\n            The instances to run the model on.\n\n        Returns\n        -------\n        A list of the models output for each instance.\n        \"\"\"\n        batch_size = len(instances)\n        with torch.no_grad():\n            cuda_device = self._get_prediction_device()\n            dataset = Batch(instances)\n            dataset.index_instances(self.vocab)\n            model_input = util.move_to_device(dataset.as_tensor_dict(), cuda_device)\n            outputs = self.decode(self(**model_input))\n\n            instance_separated_output: List[Dict[str, numpy.ndarray]] = [{} for _ in dataset.instances]\n            for name, output in list(outputs.items()):\n                if isinstance(output, torch.Tensor):\n                    # NOTE(markn): This is a hack because 0-dim pytorch tensors are not iterable.\n                    # This occurs with batch size 1, because we still want to include the loss in that case.\n                    if output.dim() == 0:\n                        output = output.unsqueeze(0)\n\n                    if output.size(0) != batch_size:\n                        self._maybe_warn_for_unseparable_batches(name)\n                        continue\n                    output = output.detach().cpu().numpy()\n                elif len(output) != batch_size:\n                    self._maybe_warn_for_unseparable_batches(name)\n                    continue\n                for instance_output, batch_element in zip(instance_separated_output, output):\n                    instance_output[name] = batch_element\n            return instance_separated_output"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decode(self, output_dict: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n        # pylint: disable=no-self-use\n        return output_dict", "response": "This method takes the result of forward and runs inference and decoding and returns the output dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_prediction_device(self) -> int:\n        devices = {util.get_device_of(param) for param in self.parameters()}\n\n        if len(devices) > 1:\n            devices_string = \", \".join(str(x) for x in devices)\n            raise ConfigurationError(f\"Parameters have mismatching cuda_devices: {devices_string}\")\n        elif len(devices) == 1:\n            return devices.pop()\n        else:\n            return -1", "response": "This method checks the device of the model parameters to determine the cuda_device that this model should be run on for predictions."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _load(cls,\n              config: Params,\n              serialization_dir: str,\n              weights_file: str = None,\n              cuda_device: int = -1) -> 'Model':\n        \"\"\"\n        Instantiates an already-trained model, based on the experiment\n        configuration and some optional overrides.\n        \"\"\"\n        weights_file = weights_file or os.path.join(serialization_dir, _DEFAULT_WEIGHTS)\n\n        # Load vocabulary from file\n        vocab_dir = os.path.join(serialization_dir, 'vocabulary')\n        # If the config specifies a vocabulary subclass, we need to use it.\n        vocab_params = config.get(\"vocabulary\", Params({}))\n        vocab_choice = vocab_params.pop_choice(\"type\", Vocabulary.list_available(), True)\n        vocab = Vocabulary.by_name(vocab_choice).from_files(vocab_dir)\n\n        model_params = config.get('model')\n\n        # The experiment config tells us how to _train_ a model, including where to get pre-trained\n        # embeddings from.  We're now _loading_ the model, so those embeddings will already be\n        # stored in our weights.  We don't need any pretrained weight file anymore, and we don't\n        # want the code to look for it, so we remove it from the parameters here.\n        remove_pretrained_embedding_params(model_params)\n        model = Model.from_params(vocab=vocab, params=model_params)\n\n        # If vocab+embedding extension was done, the model initialized from from_params\n        # and one defined by state dict in weights_file might not have same embedding shapes.\n        # Eg. when model embedder module was transferred along with vocab extension, the\n        # initialized embedding weight shape would be smaller than one in the state_dict.\n        # So calling model embedding extension is required before load_state_dict.\n        # If vocab and model embeddings are in sync, following would be just a no-op.\n        model.extend_embedder_vocab()\n\n        model_state = torch.load(weights_file, map_location=util.device_mapping(cuda_device))\n        model.load_state_dict(model_state)\n\n        # Force model to cpu or gpu, as appropriate, to make sure that the embeddings are\n        # in sync with the weights\n        if cuda_device >= 0:\n            model.cuda(cuda_device)\n        else:\n            model.cpu()\n\n        return model", "response": "Loads a previously - trained model from a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading a previously - trained model from a configuration file.", "response": "def load(cls,\n             config: Params,\n             serialization_dir: str,\n             weights_file: str = None,\n             cuda_device: int = -1) -> 'Model':\n        \"\"\"\n        Instantiates an already-trained model, based on the experiment\n        configuration and some optional overrides.\n\n        Parameters\n        ----------\n        config: Params\n            The configuration that was used to train the model. It should definitely\n            have a `model` section, and should probably have a `trainer` section\n            as well.\n        serialization_dir: str = None\n            The directory containing the serialized weights, parameters, and vocabulary\n            of the model.\n        weights_file: str = None\n            By default we load the weights from `best.th` in the serialization\n            directory, but you can override that value here.\n        cuda_device: int = -1\n            By default we load the model on the CPU, but if you want to load it\n            for GPU usage you can specify the id of your GPU here\n\n\n        Returns\n        -------\n        model: Model\n            The model specified in the configuration, loaded with the serialized\n            vocabulary and the trained weights.\n        \"\"\"\n\n        # Peak at the class of the model.\n        model_type = config[\"model\"][\"type\"]\n\n        # Load using an overridable _load method.\n        # This allows subclasses of Model to override _load.\n        # pylint: disable=protected-access\n        return cls.by_name(model_type)._load(config, serialization_dir, weights_file, cuda_device)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extend_embedder_vocab(self, embedding_sources_mapping: Dict[str, str] = None) -> None:\n        # self.named_modules() gives all sub-modules (including nested children)\n        # The path nesting is already separated by \".\": eg. parent_module_name.child_module_name\n        embedding_sources_mapping = embedding_sources_mapping or {}\n        for model_path, module in self.named_modules():\n            if hasattr(module, 'extend_vocab'):\n                pretrained_file = embedding_sources_mapping.get(model_path, None)\n                module.extend_vocab(self.vocab,\n                                    extension_pretrained_file=pretrained_file,\n                                    model_path=model_path)", "response": "Extends the embedding vocabulary with the extended vocabulary of the embedded modules."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an agenda that can be used guide search.", "response": "def get_agenda(self,\n                   conservative: bool = False):\n        \"\"\"\n        Returns an agenda that can be used guide search.\n\n        Parameters\n        ----------\n        conservative : ``bool``\n            Setting this flag will return a subset of the agenda items that correspond to high\n            confidence lexical matches. You'll need this if you are going to use this agenda to\n            penalize a model for producing logical forms that do not contain some items in it. In\n            that case, you'll want this agenda to have close to perfect precision, at the cost of a\n            lower recall. You may not want to set this flag if you are sorting the output from a\n            search procedure based on how much of this agenda is satisfied.\n        \"\"\"\n        agenda_items = []\n        question_tokens = [token.text for token in self.table_context.question_tokens]\n        question = \" \".join(question_tokens)\n\n        added_number_filters = False\n        if self._table_has_number_columns:\n            if \"at least\" in question:\n                agenda_items.append(\"filter_number_greater_equals\")\n            if \"at most\" in question:\n                agenda_items.append(\"filter_number_lesser_equals\")\n\n            comparison_triggers = [\"greater\", \"larger\", \"more\"]\n            if any(f\"no {word} than\" in question for word in comparison_triggers):\n                agenda_items.append(\"filter_number_lesser_equals\")\n            elif any(f\"{word} than\" in question for word in comparison_triggers):\n                agenda_items.append(\"filter_number_greater\")\n\n            # We want to keep track of this because we do not want to add both number and date\n            # filters to the agenda if we want to be conservative.\n            if agenda_items:\n                added_number_filters = True\n        for token in question_tokens:\n            if token in [\"next\", \"below\"] or (token == \"after\" and not conservative):\n                agenda_items.append(\"next\")\n            if token in [\"previous\", \"above\"] or (token == \"before\" and not conservative):\n                agenda_items.append(\"previous\")\n            if token in [\"first\", \"top\"]:\n                agenda_items.append(\"first\")\n            if token in [\"last\", \"bottom\"]:\n                agenda_items.append(\"last\")\n            if token == \"same\":\n                agenda_items.append(\"same_as\")\n\n            if self._table_has_number_columns:\n                # \"total\" does not always map to an actual summing operation.\n                if token == \"total\" and not conservative:\n                    agenda_items.append(\"sum\")\n                if token == \"difference\" or \"how many more\" in question or \"how much more\" in question:\n                    agenda_items.append(\"diff\")\n                if token == \"average\":\n                    agenda_items.append(\"average\")\n                if token in [\"least\", \"smallest\", \"shortest\", \"lowest\"] and \"at least\" not in question:\n                    # This condition is too brittle. But for most logical forms with \"min\", there are\n                    # semantically equivalent ones with \"argmin\". The exceptions are rare.\n                    if \"what is the least\" not in question:\n                        agenda_items.append(\"argmin\")\n                if token in [\"most\", \"largest\", \"highest\", \"longest\", \"greatest\"] and \"at most\" not in question:\n                    # This condition is too brittle. But for most logical forms with \"max\", there are\n                    # semantically equivalent ones with \"argmax\". The exceptions are rare.\n                    if \"what is the most\" not in question:\n                        agenda_items.append(\"argmax\")\n\n            if self._table_has_date_columns:\n                if token in MONTH_NUMBERS or (token.isdigit() and len(token) == 4 and\n                                              int(token) < 2100 and int(token) > 1100):\n                    # Token is either a month or an year. We'll add date functions.\n                    if not added_number_filters or not conservative:\n                        if \"after\" in question_tokens:\n                            agenda_items.append(\"filter_date_greater\")\n                        elif \"before\" in question_tokens:\n                            agenda_items.append(\"filter_date_lesser\")\n                        elif \"not\" in question_tokens:\n                            agenda_items.append(\"filter_date_not_equals\")\n                        else:\n                            agenda_items.append(\"filter_date_equals\")\n\n            if \"what is the least\" in question and self._table_has_number_columns:\n                agenda_items.append(\"min_number\")\n            if \"what is the most\" in question and self._table_has_number_columns:\n                agenda_items.append(\"max_number\")\n            if \"when\" in question_tokens and self._table_has_date_columns:\n                if \"last\" in question_tokens:\n                    agenda_items.append(\"max_date\")\n                elif \"first\" in question_tokens:\n                    agenda_items.append(\"min_date\")\n                else:\n                    agenda_items.append(\"select_date\")\n\n\n        if \"how many\" in question:\n            if \"sum\" not in agenda_items and \"average\" not in agenda_items:\n                # The question probably just requires counting the rows. But this is not very\n                # accurate. The question could also be asking for a value that is in the table.\n                agenda_items.append(\"count\")\n        agenda = []\n        # Adding productions from the global set.\n        for agenda_item in set(agenda_items):\n            # Some agenda items may not be present in the terminal productions because some of these\n            # terminals are table-content specific. For example, if the question triggered \"sum\",\n            # and the table does not have number columns, we should not add \"<r,<f,n>> -> sum\" to\n            # the agenda.\n            if agenda_item in self.terminal_productions:\n                agenda.append(self.terminal_productions[agenda_item])\n\n        if conservative:\n            # Some of the columns in the table have multiple types, and thus occur in the KG as\n            # different columns. We do not want to add them all to the agenda if their names,\n            # because it is unlikely that logical forms use them all. In fact, to be conservative,\n            # we won't add any of them. So we'll first identify such column names.\n            refined_column_productions: Dict[str, str] = {}\n            for column_name, signature in self._column_productions_for_agenda.items():\n                column_type, name = column_name.split(\":\")\n                if column_type == \"string_column\":\n                    if f\"number_column:{name}\" not in self._column_productions_for_agenda and \\\n                       f\"date_column:{name}\" not in self._column_productions_for_agenda:\n                        refined_column_productions[column_name] = signature\n\n                elif column_type == \"number_column\":\n                    if f\"string_column:{name}\" not in self._column_productions_for_agenda and \\\n                       f\"date_column:{name}\" not in self._column_productions_for_agenda:\n                        refined_column_productions[column_name] = signature\n\n                else:\n                    if f\"string_column:{name}\" not in self._column_productions_for_agenda and \\\n                       f\"number_column:{name}\" not in self._column_productions_for_agenda:\n                        refined_column_productions[column_name] = signature\n            # Similarly, we do not want the same spans in the question to be added to the agenda as\n            # both string and number productions.\n            refined_entities: List[str] = []\n            refined_numbers: List[str] = []\n            for entity in self._question_entities:\n                if entity.replace(\"string:\", \"\") not in self._question_numbers:\n                    refined_entities.append(entity)\n            for number in self._question_numbers:\n                if f\"string:{number}\" not in self._question_entities:\n                    refined_numbers.append(number)\n        else:\n            refined_column_productions = dict(self._column_productions_for_agenda)\n            refined_entities = list(self._question_entities)\n            refined_numbers = list(self._question_numbers)\n\n        # Adding column names that occur in question.\n        question_with_underscores = \"_\".join(question_tokens)\n        normalized_question = re.sub(\"[^a-z0-9_]\", \"\", question_with_underscores)\n        # We keep track of tokens that are in column names being added to the agenda. We will not\n        # add string productions to the agenda if those tokens were already captured as column\n        # names.\n        # Note: If the same string occurs multiple times, this may cause string productions being\n        # omitted from the agenda unnecessarily. That is fine, as we want to err on the side of\n        # adding fewer rules to the agenda.\n        tokens_in_column_names: Set[str] = set()\n        for column_name_with_type, signature in refined_column_productions.items():\n            column_name = column_name_with_type.split(\":\")[1]\n            # Underscores ensure that the match is of whole words.\n            if f\"_{column_name}_\" in normalized_question:\n                agenda.append(signature)\n                for token in column_name.split(\"_\"):\n                    tokens_in_column_names.add(token)\n\n        # Adding all productions that lead to entities and numbers extracted from the question.\n        for entity in refined_entities:\n            if entity.replace(\"string:\", \"\") not in tokens_in_column_names:\n                agenda.append(f\"str -> {entity}\")\n\n        for number in refined_numbers:\n            # The reason we check for the presence of the number in the question again is because\n            # some of these numbers are extracted from number words like month names and ordinals\n            # like \"first\". On looking at some agenda outputs, I found that they hurt more than help\n            # in the agenda.\n            if f\"_{number}_\" in normalized_question:\n                agenda.append(f\"Number -> {number}\")\n        return agenda"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nevaluating the logical form against the list of target values as strings from the original lisp string and returns True iff the logical form evaluates to the target list.", "response": "def evaluate_logical_form(self, logical_form: str, target_list: List[str]) -> bool:\n        \"\"\"\n        Takes a logical form, and the list of target values as strings from the original lisp\n        string, and returns True iff the logical form executes to the target list, using the\n        official WikiTableQuestions evaluation script.\n        \"\"\"\n        normalized_target_list = [TableQuestionContext.normalize_string(value) for value in\n                                  target_list]\n        target_value_list = evaluator.to_value_list(normalized_target_list)\n        try:\n            denotation = self.execute(logical_form)\n        except ExecutionError:\n            logger.warning(f'Failed to execute: {logical_form}')\n            return False\n        if isinstance(denotation, list):\n            denotation_list = [str(denotation_item) for denotation_item in denotation]\n        else:\n            denotation_list = [str(denotation)]\n        denotation_value_list = evaluator.to_value_list(denotation_list)\n        return evaluator.check_denotation(target_value_list, denotation_value_list)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef select_string(self, rows: List[Row], column: StringColumn) -> List[str]:\n        return [str(row.values[column.name]) for row in rows if row.values[column.name] is not None]", "response": "Select a string from a list of rows and a column name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef select_number(self, rows: List[Row], column: NumberColumn) -> Number:\n        numbers: List[float] = []\n        for row in rows:\n            cell_value = row.values[column.name]\n            if isinstance(cell_value, float):\n                numbers.append(cell_value)\n\n        return numbers[0] if numbers else -1", "response": "Select number in thatCOOKIE table."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nselects date in a list of rows and a column name.", "response": "def select_date(self, rows: List[Row], column: DateColumn) -> Date:\n        \"\"\"\n        Select function takes a row as a list and a column name and returns the date in that column.\n        \"\"\"\n        dates: List[Date] = []\n        for row in rows:\n            cell_value = row.values[column.name]\n            if isinstance(cell_value, Date):\n                dates.append(cell_value)\n\n        return dates[0] if dates else Date(-1, -1, -1)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef same_as(self, rows: List[Row], column: Column) -> List[Row]:\n        cell_value = rows[0].values[column.name]\n        return_list = []\n        for table_row in self.table_data:\n            if table_row.values[column.name] == cell_value:\n                return_list.append(table_row)\n        return return_list", "response": "Takes a row and a column and returns a list of rows that contain the same value under the given column."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef date(self, year: Number, month: Number, day: Number) -> Date:\n        return Date(year, month, day)", "response": "Takes three numbers and returns a Date object whose year month and day are the three numbers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake an expression that evaluates to a list of rows and returns the first one in that list.", "response": "def first(self, rows: List[Row]) -> List[Row]:\n        \"\"\"\n        Takes an expression that evaluates to a list of rows, and returns the first one in that\n        list.\n        \"\"\"\n        if not rows:\n            logger.warning(\"Trying to get first row from an empty list\")\n            return []\n        return [rows[0]]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef last(self, rows: List[Row]) -> List[Row]:\n        if not rows:\n            logger.warning(\"Trying to get last row from an empty list\")\n            return []\n        return [rows[-1]]", "response": "Takes an expression that evaluates to a list of rows and returns the last one in that list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef previous(self, rows: List[Row]) -> List[Row]:\n        if not rows:\n            return []\n        input_row_index = self._get_row_index(rows[0])\n        if input_row_index > 0:\n            return [self.table_data[input_row_index - 1]]\n        return []", "response": "Takes an expression that evaluates to a single row and returns the row that occurs before the input row."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake an expression that evaluates to a single row and returns the row that occurs after the input row.", "response": "def next(self, rows: List[Row]) -> List[Row]:\n        \"\"\"\n        Takes an expression that evaluates to a single row, and returns the row that occurs after\n        the input row in the original set of rows. If the input row happens to be the last row, we\n        will return an empty list.\n        \"\"\"\n        if not rows:\n            return []\n        input_row_index = self._get_row_index(rows[0])\n        if input_row_index < len(self.table_data) - 1 and input_row_index != -1:\n            return [self.table_data[input_row_index + 1]]\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mode_string(self, rows: List[Row], column: StringColumn) -> List[str]:\n        most_frequent_list = self._get_most_frequent_values(rows, column)\n        if not most_frequent_list:\n            return []\n        if not all([isinstance(value, str) for value in most_frequent_list]):\n            raise ExecutionError(f\"Invalid values for mode_string: {most_frequent_list}\")\n        return most_frequent_list", "response": "Takes a list of rows and a column and returns the most frequent values under that column."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the most frequent value under the column in the rows and returns the value under that column.", "response": "def mode_number(self, rows: List[Row], column: NumberColumn) -> Number:\n        \"\"\"\n        Takes a list of rows and a column and returns the most frequent value under\n        that column in those rows.\n        \"\"\"\n        most_frequent_list = self._get_most_frequent_values(rows, column)\n        if not most_frequent_list:\n            return 0.0  # type: ignore\n        most_frequent_value = most_frequent_list[0]\n        if not isinstance(most_frequent_value, Number):\n            raise ExecutionError(f\"Invalid valus for mode_number: {most_frequent_value}\")\n        return most_frequent_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mode_date(self, rows: List[Row], column: DateColumn) -> Date:\n        most_frequent_list = self._get_most_frequent_values(rows, column)\n        if not most_frequent_list:\n            return Date(-1, -1, -1)\n        most_frequent_value = most_frequent_list[0]\n        if not isinstance(most_frequent_value, Date):\n            raise ExecutionError(f\"Invalid valus for mode_date: {most_frequent_value}\")\n        return most_frequent_value", "response": "Returns the most frequent value under the given column."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntakes a list of rows and a column name and returns a list containing a single row with the maximum numerical value in the given column.", "response": "def argmax(self, rows: List[Row], column: ComparableColumn) -> List[Row]:\n        \"\"\"\n        Takes a list of rows and a column name and returns a list containing a single row (dict from\n        columns to cells) that has the maximum numerical value in the given column. We return a list\n        instead of a single dict to be consistent with the return type of ``select`` and\n        ``all_rows``.\n        \"\"\"\n        if not rows:\n            return []\n        value_row_pairs = [(row.values[column.name], row) for row in rows]\n        if not value_row_pairs:\n            return []\n        # Returns a list containing the row with the max cell value.\n        return [sorted(value_row_pairs, key=lambda x: x[0], reverse=True)[0][1]]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes a list of rows and a column and returns a list containing a single row that has the minimum numerical value in the given column.", "response": "def argmin(self, rows: List[Row], column: ComparableColumn) -> List[Row]:\n        \"\"\"\n        Takes a list of rows and a column and returns a list containing a single row (dict from\n        columns to cells) that has the minimum numerical value in the given column. We return a list\n        instead of a single dict to be consistent with the return type of ``select`` and\n        ``all_rows``.\n        \"\"\"\n        if not rows:\n            return []\n        value_row_pairs = [(row.values[column.name], row) for row in rows]\n        if not value_row_pairs:\n            return []\n        # Returns a list containing the row with the max cell value.\n        return [sorted(value_row_pairs, key=lambda x: x[0])[0][1]]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef max_date(self, rows: List[Row], column: DateColumn) -> Date:\n        cell_values = [row.values[column.name] for row in rows]\n        if not cell_values:\n            return Date(-1, -1, -1)\n        if not all([isinstance(value, Date) for value in cell_values]):\n            raise ExecutionError(f\"Invalid values for date selection function: {cell_values}\")\n        return max(cell_values)", "response": "Returns the maximum value of a column in the rows and the max value of that column in the rows."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef max_number(self, rows: List[Row], column: NumberColumn) -> Number:\n        cell_values = [row.values[column.name] for row in rows]\n        if not cell_values:\n            return 0.0  # type: ignore\n        if not all([isinstance(value, Number) for value in cell_values]):\n            raise ExecutionError(f\"Invalid values for number selection function: {cell_values}\")\n        return max(cell_values)", "response": "Returns the maximum number in the given rows and a column."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef average(self, rows: List[Row], column: NumberColumn) -> Number:\n        cell_values = [row.values[column.name] for row in rows]\n        if not cell_values:\n            return 0.0  # type: ignore\n        return sum(cell_values) / len(cell_values)", "response": "Takes a list of rows and a column and returns the mean of the values under that column in those rows."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntake a two rows and a number column and returns the difference between the values under that column in those two rows.", "response": "def diff(self, first_row: List[Row], second_row: List[Row], column: NumberColumn) -> Number:\n        \"\"\"\n        Takes a two rows and a number column and returns the difference between the values under\n        that column in those two rows.\n        \"\"\"\n        if not first_row or not second_row:\n            return 0.0  # type: ignore\n        first_value = first_row[0].values[column.name]\n        second_value = second_row[0].values[column.name]\n        if isinstance(first_value, float) and isinstance(second_value, float):\n            return first_value - second_value  # type: ignore\n        else:\n            raise ExecutionError(f\"Invalid column for diff: {column.name}\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_row_index(self, row: Row) -> int:\n        row_index = -1\n        for index, table_row in enumerate(self.table_data):\n            if table_row.values == row.values:\n                row_index = index\n                break\n        return row_index", "response": "Takes a row and returns its index in the full list of rows."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if the given symbol is a terminal symbol.", "response": "def is_terminal(self, symbol: str) -> bool:\n        \"\"\"\n        This function will be called on nodes of a logical form tree, which are either non-terminal\n        symbols that can be expanded or terminal symbols that must be leaf nodes.  Returns ``True``\n        if the given symbol is a terminal symbol.\n        \"\"\"\n        # We special-case 'lambda' here because it behaves weirdly in action sequences.\n        return (symbol in self.global_name_mapping or\n                symbol in self.local_name_mapping or\n                'lambda' in symbol)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_paths_to_root(self,\n                          action: str,\n                          max_path_length: int = 20,\n                          beam_size: int = 30,\n                          max_num_paths: int = 10) -> List[List[str]]:\n        \"\"\"\n        For a given action, returns at most ``max_num_paths`` paths to the root (production with\n        ``START_SYMBOL``) that are not longer than ``max_path_length``.\n        \"\"\"\n        action_left_side, _ = action.split(' -> ')\n        right_side_indexed_actions = self._get_right_side_indexed_actions()\n        lists_to_expand: List[Tuple[str, List[str]]] = [(action_left_side, [action])]\n        completed_paths = []\n        while lists_to_expand:\n            need_to_expand = False\n            for left_side, path in lists_to_expand:\n                if left_side == types.START_SYMBOL:\n                    completed_paths.append(path)\n                else:\n                    need_to_expand = True\n            if not need_to_expand or len(completed_paths) >= max_num_paths:\n                break\n            # We keep track of finished and unfinished lists separately because we truncate the beam\n            # later, and we want the finished lists to be at the top of the beam.\n            finished_new_lists = []\n            unfinished_new_lists = []\n            for left_side, actions in lists_to_expand:\n                for next_left_side, next_action in right_side_indexed_actions[left_side]:\n                    if next_action in actions:\n                        # Ignoring paths with loops (of size 1)\n                        continue\n                    new_actions = list(actions)\n                    new_actions.append(next_action)\n                    # Ignoring lists that are too long, and have too many repetitions.\n                    path_length = len(new_actions)\n                    if path_length <= max_path_length or next_left_side == types.START_SYMBOL:\n                        if next_left_side == types.START_SYMBOL:\n                            finished_new_lists.append((next_left_side, new_actions))\n                        else:\n                            unfinished_new_lists.append((next_left_side, new_actions))\n            new_lists = finished_new_lists + unfinished_new_lists\n            lists_to_expand = new_lists[:beam_size]\n        return completed_paths[:max_num_paths]", "response": "Returns at most max_num_paths paths to the root."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_multi_match_mapping(self) -> Dict[Type, List[Type]]:\n        if self._multi_match_mapping is None:\n            self._multi_match_mapping = {}\n            basic_types = self.get_basic_types()\n            for basic_type in basic_types:\n                if isinstance(basic_type, types.MultiMatchNamedBasicType):\n                    matched_types: List[str] = []\n                    # We need to check if each type in the `types_to_match` field for the given\n                    # MultiMatchNamedBasic type is itself in the set of basic types allowed in this\n                    # world, and add it to the mapping only if it is. Some basic types that the\n                    # multi match type can match with may be diallowed in the world due to the\n                    # instance-specific context.\n                    for type_ in basic_type.types_to_match:\n                        if type_ in basic_types:\n                            matched_types.append(type_)\n                    self._multi_match_mapping[basic_type] = matched_types\n        return self._multi_match_mapping", "response": "Returns a mapping from each MultiMatchNamedBasicType to all the NamedBasicTypes that it matches."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a logical form as a string and returns a parsed expression.", "response": "def parse_logical_form(self,\n                           logical_form: str,\n                           remove_var_function: bool = True) -> Expression:\n        \"\"\"\n        Takes a logical form as a string, maps its tokens using the mapping and returns a parsed expression.\n\n        Parameters\n        ----------\n        logical_form : ``str``\n            Logical form to parse\n        remove_var_function : ``bool`` (optional)\n            ``var`` is a special function that some languages use within lambda functions to\n            indicate the usage of a variable. If your language uses it, and you do not want to\n            include it in the parsed expression, set this flag. You may want to do this if you are\n            generating an action sequence from this parsed expression, because it is easier to let\n            the decoder not produce this function due to the way constrained decoding is currently\n            implemented.\n        \"\"\"\n        if not logical_form.startswith(\"(\"):\n            logical_form = f\"({logical_form})\"\n        if remove_var_function:\n            # Replace \"(x)\" with \"x\"\n            logical_form = re.sub(r'\\(([x-z])\\)', r'\\1', logical_form)\n            # Replace \"(var x)\" with \"(x)\"\n            logical_form = re.sub(r'\\(var ([x-z])\\)', r'(\\1)', logical_form)\n        parsed_lisp = semparse_util.lisp_to_nested_expression(logical_form)\n        translated_string = self._process_nested_expression(parsed_lisp)\n        type_signature = self.local_type_signatures.copy()\n        type_signature.update(self.global_type_signatures)\n        return self._logic_parser.parse(translated_string, signature=type_signature)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_action_sequence(self, expression: Expression) -> List[str]:\n        # Starting with the type of the whole expression\n        return self._get_transitions(expression,\n                                     [f\"{types.START_TYPE} -> {expression.type}\"])", "response": "Returns the sequence of actions that resulted in the given expression."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_logical_form(self,\n                         action_sequence: List[str],\n                         add_var_function: bool = True) -> str:\n        \"\"\"\n        Takes an action sequence and constructs a logical form from it. This is useful if you want\n        to get a logical form from a decoded sequence of actions generated by a transition based\n        semantic parser.\n\n        Parameters\n        ----------\n        action_sequence : ``List[str]``\n            The sequence of actions as strings (eg.: ``['{START_SYMBOL} -> t', 't -> <e,t>', ...]``).\n        add_var_function : ``bool`` (optional)\n             ``var`` is a special function that some languages use within lambda functions to\n             indicate the use of a variable (eg.: ``(lambda x (fb:row.row.year (var x)))``). Due to\n             the way constrained decoding is currently implemented, it is easier for the decoder to\n             not produce these functions. In that case, setting this flag adds the function in the\n             logical form even though it is not present in the action sequence.\n        \"\"\"\n        # Basic outline: we assume that the bracketing that we get in the RHS of each action is the\n        # correct bracketing for reconstructing the logical form.  This is true when there is no\n        # currying in the action sequence.  Given this assumption, we just need to construct a tree\n        # from the action sequence, then output all of the leaves in the tree, with brackets around\n        # the children of all non-terminal nodes.\n\n        remaining_actions = [action.split(\" -> \") for action in action_sequence]\n        tree = Tree(remaining_actions[0][1], [])\n\n        try:\n            remaining_actions = self._construct_node_from_actions(tree,\n                                                                  remaining_actions[1:],\n                                                                  add_var_function)\n        except ParsingError:\n            logger.error(\"Error parsing action sequence: %s\", action_sequence)\n            raise\n\n        if remaining_actions:\n            logger.error(\"Error parsing action sequence: %s\", action_sequence)\n            logger.error(\"Remaining actions were: %s\", remaining_actions)\n            raise ParsingError(\"Extra actions in action sequence\")\n        return nltk_tree_to_logical_form(tree)", "response": "This method takes an action sequence and constructs a logical form from it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a current node in the logical form tree, and a list of actions in an action sequence, this method fills in the children of the current node from the action sequence, then returns whatever actions are left. For example, we could get a node with type ``c``, and an action sequence that begins with ``c -> [<r,c>, r]``. This method will add two children to the input node, consuming actions from the action sequence for nodes of type ``<r,c>`` (and all of its children, recursively) and ``r`` (and all of its children, recursively). This method assumes that action sequences are produced `depth-first`, so all actions for the subtree under ``<r,c>`` appear before actions for the subtree under ``r``. If there are any actions in the action sequence after the ``<r,c>`` and ``r`` subtrees have terminated in leaf nodes, they will be returned.", "response": "def _construct_node_from_actions(self,\n                                     current_node: Tree,\n                                     remaining_actions: List[List[str]],\n                                     add_var_function: bool) -> List[List[str]]:\n        \"\"\"\n        Given a current node in the logical form tree, and a list of actions in an action sequence,\n        this method fills in the children of the current node from the action sequence, then\n        returns whatever actions are left.\n\n        For example, we could get a node with type ``c``, and an action sequence that begins with\n        ``c -> [<r,c>, r]``.  This method will add two children to the input node, consuming\n        actions from the action sequence for nodes of type ``<r,c>`` (and all of its children,\n        recursively) and ``r`` (and all of its children, recursively).  This method assumes that\n        action sequences are produced `depth-first`, so all actions for the subtree under ``<r,c>``\n        appear before actions for the subtree under ``r``.  If there are any actions in the action\n        sequence after the ``<r,c>`` and ``r`` subtrees have terminated in leaf nodes, they will be\n        returned.\n        \"\"\"\n        if not remaining_actions:\n            logger.error(\"No actions left to construct current node: %s\", current_node)\n            raise ParsingError(\"Incomplete action sequence\")\n        left_side, right_side = remaining_actions.pop(0)\n        if left_side != current_node.label():\n            mismatch = True\n            multi_match_mapping = {str(key): [str(value) for value in values] for key,\n                                   values in self.get_multi_match_mapping().items()}\n            current_label = current_node.label()\n            if current_label in multi_match_mapping and left_side in multi_match_mapping[current_label]:\n                mismatch = False\n            if mismatch:\n                logger.error(\"Current node: %s\", current_node)\n                logger.error(\"Next action: %s -> %s\", left_side, right_side)\n                logger.error(\"Remaining actions were: %s\", remaining_actions)\n                raise ParsingError(\"Current node does not match next action\")\n        if right_side[0] == '[':\n            # This is a non-terminal expansion, with more than one child node.\n            for child_type in right_side[1:-1].split(', '):\n                if child_type.startswith(\"'lambda\"):\n                    # We need to special-case the handling of lambda here, because it's handled a\n                    # bit weirdly in the action sequence.  This is stripping off the single quotes\n                    # around something like `'lambda x'`.\n                    child_type = child_type[1:-1]\n                child_node = Tree(child_type, [])\n                current_node.append(child_node)  # you add a child to an nltk.Tree with `append`\n                if not self.is_terminal(child_type):\n                    remaining_actions = self._construct_node_from_actions(child_node,\n                                                                          remaining_actions,\n                                                                          add_var_function)\n        elif self.is_terminal(right_side):\n            # The current node is a pre-terminal; we'll add a single terminal child.  We need to\n            # check first for whether we need to add a (var _) around the terminal node, though.\n            if add_var_function and right_side in self._lambda_variables:\n                right_side = f\"(var {right_side})\"\n            if add_var_function and right_side == 'var':\n                raise ParsingError('add_var_function was true, but action sequence already had var')\n            current_node.append(Tree(right_side, []))  # you add a child to an nltk.Tree with `append`\n        else:\n            # The only way this can happen is if you have a unary non-terminal production rule.\n            # That is almost certainly not what you want with this kind of grammar, so we'll crash.\n            # If you really do want this, open a PR with a valid use case.\n            raise ParsingError(f\"Found a unary production rule: {left_side} -> {right_side}. \"\n                               \"Are you sure you want a unary production rule in your grammar?\")\n        return remaining_actions"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninfer the number of arguments the corresponding function takes.", "response": "def _infer_num_arguments(cls, type_signature: str) -> int:\n        \"\"\"\n        Takes a type signature and infers the number of arguments the corresponding function takes.\n        Examples:\n            e -> 0\n            <r,e> -> 1\n            <e,<e,t>> -> 2\n            <b,<<b,#1>,<#1,b>>> -> 3\n        \"\"\"\n        if not \"<\" in type_signature:\n            return 0\n        # We need to find the return type from the signature. We do that by removing the outer most\n        # angular brackets and traversing the remaining substring till the angular brackets (if any)\n        # balance. Once we hit a comma after the angular brackets are balanced, whatever is left\n        # after it is the return type.\n        type_signature = type_signature[1:-1]\n        num_brackets = 0\n        char_index = 0\n        for char in type_signature:\n            if char == '<':\n                num_brackets += 1\n            elif char == '>':\n                num_brackets -= 1\n            elif char == ',':\n                if num_brackets == 0:\n                    break\n            char_index += 1\n        return_type = type_signature[char_index+1:]\n        return 1 + cls._infer_num_arguments(return_type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprocesses a nested expression in Lisp format and returns a string that can be used to parse the logical form in Lisp format.", "response": "def _process_nested_expression(self, nested_expression) -> str:\n        \"\"\"\n        ``nested_expression`` is the result of parsing a logical form in Lisp format.\n        We process it recursively and return a string in the format that NLTK's ``LogicParser``\n        would understand.\n        \"\"\"\n        expression_is_list = isinstance(nested_expression, list)\n        expression_size = len(nested_expression)\n        if expression_is_list and expression_size == 1 and isinstance(nested_expression[0], list):\n            return self._process_nested_expression(nested_expression[0])\n        elements_are_leaves = [isinstance(element, str) for element in nested_expression]\n        if all(elements_are_leaves):\n            mapped_names = [self._map_name(name) for name in nested_expression]\n        else:\n            mapped_names = []\n            for element, is_leaf in zip(nested_expression, elements_are_leaves):\n                if is_leaf:\n                    mapped_names.append(self._map_name(element))\n                else:\n                    mapped_names.append(self._process_nested_expression(element))\n        if mapped_names[0] == \"\\\\\":\n            # This means the predicate is lambda. NLTK wants the variable name to not be within parantheses.\n            # Adding parentheses after the variable.\n            arguments = [mapped_names[1]] + [f\"({name})\" for name in mapped_names[2:]]\n        else:\n            arguments = [f\"({name})\" for name in mapped_names[1:]]\n        return f'({mapped_names[0]} {\" \".join(arguments)})'"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nforwarding computation of the LSTM.", "response": "def forward(self,  # pylint: disable=arguments-differ\n                inputs: PackedSequence,\n                initial_state: Optional[Tuple[torch.Tensor, torch.Tensor]] = None):\n        \"\"\"\n        Parameters\n        ----------\n        inputs : PackedSequence, required.\n            A tensor of shape (batch_size, num_timesteps, input_size)\n            to apply the LSTM over.\n\n        initial_state : Tuple[torch.Tensor, torch.Tensor], optional, (default = None)\n            A tuple (state, memory) representing the initial hidden state and memory\n            of the LSTM. Each tensor has shape (1, batch_size, output_dimension).\n\n        Returns\n        -------\n        A PackedSequence containing a torch.FloatTensor of shape\n        (batch_size, num_timesteps, output_dimension) representing\n        the outputs of the LSTM per timestep and a tuple containing\n        the LSTM state, with shape (1, batch_size, hidden_size) to\n        match the Pytorch API.\n        \"\"\"\n        if not isinstance(inputs, PackedSequence):\n            raise ConfigurationError('inputs must be PackedSequence but got %s' % (type(inputs)))\n\n        sequence_tensor, batch_lengths = pad_packed_sequence(inputs, batch_first=True)\n        batch_size = sequence_tensor.size()[0]\n        total_timesteps = sequence_tensor.size()[1]\n\n        output_accumulator = sequence_tensor.new_zeros(batch_size, total_timesteps, self.hidden_size)\n        if initial_state is None:\n            full_batch_previous_memory = sequence_tensor.new_zeros(batch_size, self.hidden_size)\n            full_batch_previous_state = sequence_tensor.new_zeros(batch_size, self.hidden_size)\n        else:\n            full_batch_previous_state = initial_state[0].squeeze(0)\n            full_batch_previous_memory = initial_state[1].squeeze(0)\n\n        current_length_index = batch_size - 1 if self.go_forward else 0\n        if self.recurrent_dropout_probability > 0.0:\n            dropout_mask = get_dropout_mask(self.recurrent_dropout_probability, full_batch_previous_memory)\n        else:\n            dropout_mask = None\n\n        for timestep in range(total_timesteps):\n            # The index depends on which end we start.\n            index = timestep if self.go_forward else total_timesteps - timestep - 1\n\n            # What we are doing here is finding the index into the batch dimension\n            # which we need to use for this timestep, because the sequences have\n            # variable length, so once the index is greater than the length of this\n            # particular batch sequence, we no longer need to do the computation for\n            # this sequence. The key thing to recognise here is that the batch inputs\n            # must be _ordered_ by length from longest (first in batch) to shortest\n            # (last) so initially, we are going forwards with every sequence and as we\n            # pass the index at which the shortest elements of the batch finish,\n            # we stop picking them up for the computation.\n            if self.go_forward:\n                while batch_lengths[current_length_index] <= index:\n                    current_length_index -= 1\n            # If we're going backwards, we are _picking up_ more indices.\n            else:\n                # First conditional: Are we already at the maximum number of elements in the batch?\n                # Second conditional: Does the next shortest sequence beyond the current batch\n                # index require computation use this timestep?\n                while current_length_index < (len(batch_lengths) - 1) and \\\n                                batch_lengths[current_length_index + 1] > index:\n                    current_length_index += 1\n\n            # Actually get the slices of the batch which we need for the computation at this timestep.\n            previous_memory = full_batch_previous_memory[0: current_length_index + 1].clone()\n            previous_state = full_batch_previous_state[0: current_length_index + 1].clone()\n            # Only do recurrent dropout if the dropout prob is > 0.0 and we are in training mode.\n            if dropout_mask is not None and self.training:\n                previous_state = previous_state * dropout_mask[0: current_length_index + 1]\n            timestep_input = sequence_tensor[0: current_length_index + 1, index]\n\n            # Do the projections for all the gates all at once.\n            projected_input = self.input_linearity(timestep_input)\n            projected_state = self.state_linearity(previous_state)\n\n            # Main LSTM equations using relevant chunks of the big linear\n            # projections of the hidden state and inputs.\n            input_gate = torch.sigmoid(projected_input[:, 0 * self.hidden_size:1 * self.hidden_size] +\n                                       projected_state[:, 0 * self.hidden_size:1 * self.hidden_size])\n            forget_gate = torch.sigmoid(projected_input[:, 1 * self.hidden_size:2 * self.hidden_size] +\n                                        projected_state[:, 1 * self.hidden_size:2 * self.hidden_size])\n            memory_init = torch.tanh(projected_input[:, 2 * self.hidden_size:3 * self.hidden_size] +\n                                     projected_state[:, 2 * self.hidden_size:3 * self.hidden_size])\n            output_gate = torch.sigmoid(projected_input[:, 3 * self.hidden_size:4 * self.hidden_size] +\n                                        projected_state[:, 3 * self.hidden_size:4 * self.hidden_size])\n            memory = input_gate * memory_init + forget_gate * previous_memory\n            timestep_output = output_gate * torch.tanh(memory)\n\n            if self.use_highway:\n                highway_gate = torch.sigmoid(projected_input[:, 4 * self.hidden_size:5 * self.hidden_size] +\n                                             projected_state[:, 4 * self.hidden_size:5 * self.hidden_size])\n                highway_input_projection = projected_input[:, 5 * self.hidden_size:6 * self.hidden_size]\n                timestep_output = highway_gate * timestep_output + (1 - highway_gate) * highway_input_projection\n\n            # We've been doing computation with less than the full batch, so here we create a new\n            # variable for the the whole batch at this timestep and insert the result for the\n            # relevant elements of the batch into it.\n            full_batch_previous_memory = full_batch_previous_memory.clone()\n            full_batch_previous_state = full_batch_previous_state.clone()\n            full_batch_previous_memory[0:current_length_index + 1] = memory\n            full_batch_previous_state[0:current_length_index + 1] = timestep_output\n            output_accumulator[0:current_length_index + 1, index] = timestep_output\n\n        output_accumulator = pack_padded_sequence(output_accumulator, batch_lengths, batch_first=True)\n\n        # Mimic the pytorch API by returning state in the following shape:\n        # (num_layers * num_directions, batch_size, hidden_size). As this\n        # LSTM cannot be stacked, the first dimension here is just 1.\n        final_state = (full_batch_previous_state.unsqueeze(0),\n                       full_batch_previous_memory.unsqueeze(0))\n\n        return output_accumulator, final_state"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a SEMPRE server running SEMPRE for evaluation.", "response": "def _create_sempre_executor(self) -> None:\n        \"\"\"\n        Creates a server running SEMPRE that we can send logical forms to for evaluation.  This\n        uses inter-process communication, because SEMPRE is java code.  We also need to be careful\n        to clean up the process when our program exits.\n        \"\"\"\n        if self._executor_process:\n            return\n\n        # It'd be much nicer to just use `cached_path` for these files.  However, the SEMPRE jar\n        # that we're using expects to find these files in a particular location, so we need to make\n        # sure we put the files in that location.\n        os.makedirs(SEMPRE_DIR, exist_ok=True)\n        abbreviations_path = os.path.join(SEMPRE_DIR, 'abbreviations.tsv')\n        if not os.path.exists(abbreviations_path):\n            result = requests.get(ABBREVIATIONS_FILE)\n            with open(abbreviations_path, 'wb') as downloaded_file:\n                downloaded_file.write(result.content)\n\n        grammar_path = os.path.join(SEMPRE_DIR, 'grow.grammar')\n        if not os.path.exists(grammar_path):\n            result = requests.get(GROW_FILE)\n            with open(grammar_path, 'wb') as downloaded_file:\n                downloaded_file.write(result.content)\n\n        if not check_for_java():\n            raise RuntimeError('Java is not installed properly.')\n        args = ['java', '-jar', cached_path(SEMPRE_EXECUTOR_JAR), 'serve', self._table_directory]\n        self._executor_process = subprocess.Popen(args,\n                                                  stdin=subprocess.PIPE,\n                                                  stdout=subprocess.PIPE,\n                                                  bufsize=1)\n\n        lines = []\n        for _ in range(6):\n            # SEMPRE outputs six lines of stuff when it loads that I can't disable.  So, we clear\n            # that here.\n            lines.append(str(self._executor_process.stdout.readline()))\n        assert 'Parser' in lines[-1], \"SEMPRE server output unexpected; the server may have changed\"\n        logger.info(\"Started SEMPRE server for evaluating logical forms\")\n\n        # This is supposed to ensure that the subprocess gets killed when python exits.\n        atexit.register(self._stop_sempre_executor)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef b_cubed(clusters, mention_to_gold):\n        numerator, denominator = 0, 0\n        for cluster in clusters:\n            if len(cluster) == 1:\n                continue\n            gold_counts = Counter()\n            correct = 0\n            for mention in cluster:\n                if mention in mention_to_gold:\n                    gold_counts[tuple(mention_to_gold[mention])] += 1\n            for cluster2, count in gold_counts.items():\n                if len(cluster2) != 1:\n                    correct += count * count\n            numerator += correct / float(len(cluster))\n            denominator += len(cluster)\n        return numerator, denominator", "response": "Calculate the number of cubed entries for a given set of clusters."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncounts the number of mentions in each predicted cluster that need to be re - allocated in the respective gold cluster.", "response": "def muc(clusters, mention_to_gold):\n        \"\"\"\n        Counts the mentions in each predicted cluster which need to be re-allocated in\n        order for each predicted cluster to be contained by the respective gold cluster.\n        <http://aclweb.org/anthology/M/M95/M95-1005.pdf>\n        \"\"\"\n        true_p, all_p = 0, 0\n        for cluster in clusters:\n            all_p += len(cluster) - 1\n            true_p += len(cluster)\n            linked = set()\n            for mention in cluster:\n                if mention in mention_to_gold:\n                    linked.add(mention_to_gold[mention])\n                else:\n                    true_p -= 1\n            true_p -= len(linked)\n        return true_p, all_p"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the mention F measure between gold and predicted mentions in a cluster.", "response": "def phi4(gold_clustering, predicted_clustering):\n        \"\"\"\n        Subroutine for ceafe. Computes the mention F measure between gold and\n        predicted mentions in a cluster.\n        \"\"\"\n        return 2 * len([mention for mention in gold_clustering if mention in predicted_clustering]) \\\n               / float(len(gold_clustering) + len(predicted_clustering))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ceafe(clusters, gold_clusters):\n        clusters = [cluster for cluster in clusters if len(cluster) != 1]\n        scores = np.zeros((len(gold_clusters), len(clusters)))\n        for i, gold_cluster in enumerate(gold_clusters):\n            for j, cluster in enumerate(clusters):\n                scores[i, j] = Scorer.phi4(gold_cluster, cluster)\n        matching = linear_assignment(-scores)\n        similarity = sum(scores[matching[:, 0], matching[:, 1]])\n        return similarity, len(clusters), similarity, len(gold_clusters)", "response": "Computes the Constrained EntityAlignment F - Measure for evaluating coreference."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes an action in the current grammar state returning a new grammar state with whatever update is necessary.", "response": "def take_action(self, production_rule: str) -> 'GrammarStatelet':\n        \"\"\"\n        Takes an action in the current grammar state, returning a new grammar state with whatever\n        updates are necessary.  The production rule is assumed to be formatted as \"LHS -> RHS\".\n\n        This will update the non-terminal stack.  Updating the non-terminal stack involves popping\n        the non-terminal that was expanded off of the stack, then pushing on any non-terminals in\n        the production rule back on the stack.\n\n        For example, if our current ``nonterminal_stack`` is ``[\"r\", \"<e,r>\", \"d\"]``, and\n        ``action`` is ``d -> [<e,d>, e]``, the resulting stack will be ``[\"r\", \"<e,r>\", \"e\",\n        \"<e,d>\"]``.\n\n        If ``self._reverse_productions`` is set to ``False`` then we push the non-terminals on in\n        in their given order, which means that the first non-terminal in the production rule gets\n        popped off the stack `last`.\n        \"\"\"\n        left_side, right_side = production_rule.split(' -> ')\n        assert self._nonterminal_stack[-1] == left_side, (f\"Tried to expand {self._nonterminal_stack[-1]}\"\n                                                          f\"but got rule {left_side} -> {right_side}\")\n\n        new_stack = self._nonterminal_stack[:-1]\n\n        productions = self._get_productions_from_string(right_side)\n        if self._reverse_productions:\n            productions = list(reversed(productions))\n\n        for production in productions:\n            if self._is_nonterminal(production):\n                new_stack.append(production)\n\n        return GrammarStatelet(nonterminal_stack=new_stack,\n                               valid_actions=self._valid_actions,\n                               is_nonterminal=self._is_nonterminal,\n                               reverse_productions=self._reverse_productions)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sparse_clip_norm(parameters, max_norm, norm_type=2) -> float:\n    # pylint: disable=invalid-name,protected-access\n    parameters = list(filter(lambda p: p.grad is not None, parameters))\n    max_norm = float(max_norm)\n    norm_type = float(norm_type)\n    if norm_type == float('inf'):\n        total_norm = max(p.grad.data.abs().max() for p in parameters)\n    else:\n        total_norm = 0\n        for p in parameters:\n            if p.grad.is_sparse:\n                # need to coalesce the repeated indices before finding norm\n                grad = p.grad.data.coalesce()\n                param_norm = grad._values().norm(norm_type)\n            else:\n                param_norm = p.grad.data.norm(norm_type)\n            total_norm += param_norm ** norm_type\n        total_norm = total_norm ** (1. / norm_type)\n    clip_coef = max_norm / (total_norm + 1e-6)\n    if clip_coef < 1:\n        for p in parameters:\n            if p.grad.is_sparse:\n                p.grad.data._values().mul_(clip_coef)\n            else:\n                p.grad.data.mul_(clip_coef)\n    return total_norm", "response": "Clips gradient norm of an iterable of parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmove the optimizer state to GPU if necessary.", "response": "def move_optimizer_to_cuda(optimizer):\n    \"\"\"\n    Move the optimizer state to GPU, if necessary.\n    After calling, any parameter specific state in the optimizer\n    will be located on the same device as the parameter.\n    \"\"\"\n    for param_group in optimizer.param_groups:\n        for param in param_group['params']:\n            if param.is_cuda:\n                param_state = optimizer.state[param]\n                for k in param_state.keys():\n                    if isinstance(param_state[k], torch.Tensor):\n                        param_state[k] = param_state[k].cuda(device=param.get_device())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the size of the batch dimension. Assumes a well - formed batch returns 0 otherwise.", "response": "def get_batch_size(batch: Union[Dict, torch.Tensor]) -> int:\n    \"\"\"\n    Returns the size of the batch dimension. Assumes a well-formed batch,\n    returns 0 otherwise.\n    \"\"\"\n    if isinstance(batch, torch.Tensor):\n        return batch.size(0) # type: ignore\n    elif isinstance(batch, Dict):\n        return get_batch_size(next(iter(batch.values())))\n    else:\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert seconds past Epoch to human readable string.", "response": "def time_to_str(timestamp: int) -> str:\n    \"\"\"\n    Convert seconds past Epoch to human readable string.\n    \"\"\"\n    datetimestamp = datetime.datetime.fromtimestamp(timestamp)\n    return '{:04d}-{:02d}-{:02d}-{:02d}-{:02d}-{:02d}'.format(\n            datetimestamp.year, datetimestamp.month, datetimestamp.day,\n            datetimestamp.hour, datetimestamp.minute, datetimestamp.second\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting human readable string to datetime. datetime.", "response": "def str_to_time(time_str: str) -> datetime.datetime:\n    \"\"\"\n    Convert human readable string to datetime.datetime.\n    \"\"\"\n    pieces: Any = [int(piece) for piece in time_str.split('-')]\n    return datetime.datetime(*pieces)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload all the datasets specified by the config.", "response": "def datasets_from_params(params: Params,\n                         cache_directory: str = None,\n                         cache_prefix: str = None) -> Dict[str, Iterable[Instance]]:\n    \"\"\"\n    Load all the datasets specified by the config.\n\n    Parameters\n    ----------\n    params : ``Params``\n    cache_directory : ``str``, optional\n        If given, we will instruct the ``DatasetReaders`` that we construct to cache their\n        instances in this location (or read their instances from caches in this location, if a\n        suitable cache already exists).  This is essentially a `base` directory for the cache, as\n        we will additionally add the ``cache_prefix`` to this directory, giving an actual cache\n        location of ``cache_directory + cache_prefix``.\n    cache_prefix : ``str``, optional\n        This works in conjunction with the ``cache_directory``.  The idea is that the\n        ``cache_directory`` contains caches for all different parameter settings, while the\n        ``cache_prefix`` captures a specific set of parameters that led to a particular cache file.\n        That is, if you change the tokenization settings inside your ``DatasetReader``, you don't\n        want to read cached data that used the old settings.  In order to avoid this, we compute a\n        hash of the parameters used to construct each ``DatasetReader`` and use that as a \"prefix\"\n        to the cache files inside the base ``cache_directory``.  So, a given ``input_file`` would\n        be cached essentially as ``cache_directory + cache_prefix + input_file``, where you specify\n        a ``cache_directory``, the ``cache_prefix`` is based on the dataset reader parameters, and\n        the ``input_file`` is whatever path you provided to ``DatasetReader.read()``.  In order to\n        allow you to give recognizable names to these prefixes if you want them, you can manually\n        specify the ``cache_prefix``.  Note that in some rare cases this can be dangerous, as we'll\n        use the `same` prefix for both train and validation dataset readers.\n    \"\"\"\n    dataset_reader_params = params.pop('dataset_reader')\n    validation_dataset_reader_params = params.pop('validation_dataset_reader', None)\n    train_cache_dir, validation_cache_dir = _set_up_cache_files(dataset_reader_params,\n                                                                validation_dataset_reader_params,\n                                                                cache_directory,\n                                                                cache_prefix)\n\n    dataset_reader = DatasetReader.from_params(dataset_reader_params)\n\n    validation_and_test_dataset_reader: DatasetReader = dataset_reader\n    if validation_dataset_reader_params is not None:\n        logger.info(\"Using a separate dataset reader to load validation and test data.\")\n        validation_and_test_dataset_reader = DatasetReader.from_params(validation_dataset_reader_params)\n\n    if train_cache_dir:\n        dataset_reader.cache_data(train_cache_dir)\n        validation_and_test_dataset_reader.cache_data(validation_cache_dir)\n\n    train_data_path = params.pop('train_data_path')\n    logger.info(\"Reading training data from %s\", train_data_path)\n    train_data = dataset_reader.read(train_data_path)\n\n    datasets: Dict[str, Iterable[Instance]] = {\"train\": train_data}\n\n    validation_data_path = params.pop('validation_data_path', None)\n    if validation_data_path is not None:\n        logger.info(\"Reading validation data from %s\", validation_data_path)\n        validation_data = validation_and_test_dataset_reader.read(validation_data_path)\n        datasets[\"validation\"] = validation_data\n\n    test_data_path = params.pop(\"test_data_path\", None)\n    if test_data_path is not None:\n        logger.info(\"Reading test data from %s\", test_data_path)\n        test_data = validation_and_test_dataset_reader.read(test_data_path)\n        datasets[\"test\"] = test_data\n\n    return datasets"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms a forward pass using multiple GPUs.", "response": "def data_parallel(batch_group: List[TensorDict],\n                  model: Model,\n                  cuda_devices: List) -> Dict[str, torch.Tensor]:\n    \"\"\"\n    Performs a forward pass using multiple GPUs.  This is a simplification\n    of torch.nn.parallel.data_parallel to support the allennlp model\n    interface.\n    \"\"\"\n    assert len(batch_group) <= len(cuda_devices)\n\n    moved = [nn_util.move_to_device(batch, device)\n             for batch, device in zip(batch_group, cuda_devices)]\n\n    used_device_ids = cuda_devices[:len(moved)]\n    # Counterintuitively, it appears replicate expects the source device id to be the first element\n    # in the device id list. See torch.cuda.comm.broadcast_coalesced, which is called indirectly.\n    replicas = replicate(model, used_device_ids)\n\n    # We pass all our arguments as kwargs. Create a list of empty tuples of the\n    # correct shape to serve as (non-existent) positional arguments.\n    inputs = [()] * len(batch_group)\n    outputs = parallel_apply(replicas, inputs, moved, used_device_ids)\n\n    # Only the 'loss' is needed.\n    # a (num_gpu, ) tensor with loss on each GPU\n    losses = gather([output['loss'].unsqueeze(0) for output in outputs], used_device_ids[0], 0)\n    return {'loss': losses.mean()}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms gradient rescaling. Is a no-op if gradient rescaling is not enabled.", "response": "def rescale_gradients(model: Model, grad_norm: Optional[float] = None) -> Optional[float]:\n    \"\"\"\n    Performs gradient rescaling. Is a no-op if gradient rescaling is not enabled.\n    \"\"\"\n    if grad_norm:\n        parameters_to_clip = [p for p in model.parameters()\n                              if p.grad is not None]\n        return sparse_clip_norm(parameters_to_clip, grad_norm)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_metrics(model: Model, total_loss: float, num_batches: int, reset: bool = False) -> Dict[str, float]:\n    metrics = model.get_metrics(reset=reset)\n    metrics[\"loss\"] = float(total_loss / num_batches) if num_batches > 0 else 0.0\n    return metrics", "response": "Gets the metrics but sets loss to average loss per batch."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse all dependencies out of the requirements. txt file.", "response": "def parse_requirements() -> Tuple[PackagesType, PackagesType, Set[str]]:\n    \"\"\"Parse all dependencies out of the requirements.txt file.\"\"\"\n    essential_packages: PackagesType = {}\n    other_packages: PackagesType = {}\n    duplicates: Set[str] = set()\n    with open(\"requirements.txt\", \"r\") as req_file:\n        section: str = \"\"\n        for line in req_file:\n            line = line.strip()\n\n            if line.startswith(\"####\"):\n                # Line is a section name.\n                section = parse_section_name(line)\n                continue\n\n            if not line or line.startswith(\"#\"):\n                # Line is empty or just regular comment.\n                continue\n\n            module, version = parse_package(line)\n            if module in essential_packages or module in other_packages:\n                duplicates.add(module)\n\n            if section.startswith(\"ESSENTIAL\"):\n                essential_packages[module] = version\n            else:\n                other_packages[module] = version\n\n    return essential_packages, other_packages, duplicates"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the setup. py script.", "response": "def parse_setup() -> Tuple[PackagesType, PackagesType, Set[str], Set[str]]:\n    \"\"\"Parse all dependencies out of the setup.py script.\"\"\"\n    essential_packages: PackagesType = {}\n    test_packages: PackagesType = {}\n    essential_duplicates: Set[str] = set()\n    test_duplicates: Set[str] = set()\n\n    with open('setup.py') as setup_file:\n        contents = setup_file.read()\n\n    # Parse out essential packages.\n    package_string = re.search(r\"\"\"install_requires=\\[[\\s\\n]*['\"](.*?)['\"],?[\\s\\n]*\\]\"\"\",\n                               contents, re.DOTALL).groups()[0].strip()\n    for package in re.split(r\"\"\"['\"],[\\s\\n]+['\"]\"\"\", package_string):\n        module, version = parse_package(package)\n        if module in essential_packages:\n            essential_duplicates.add(module)\n        else:\n            essential_packages[module] = version\n\n    # Parse packages only needed for testing.\n    package_string = re.search(r\"\"\"tests_require=\\[[\\s\\n]*['\"](.*?)['\"],?[\\s\\n]*\\]\"\"\",\n                               contents, re.DOTALL).groups()[0].strip()\n    for package in re.split(r\"\"\"['\"],[\\s\\n]+['\"]\"\"\", package_string):\n        module, version = parse_package(package)\n        if module in test_packages:\n            test_duplicates.add(module)\n        else:\n            test_packages[module] = version\n\n    return essential_packages, test_packages, essential_duplicates, test_duplicates"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef enumerate_spans(sentence: List[T],\n                    offset: int = 0,\n                    max_span_width: int = None,\n                    min_span_width: int = 1,\n                    filter_function: Callable[[List[T]], bool] = None) -> List[Tuple[int, int]]:\n    \"\"\"\n    Given a sentence, return all token spans within the sentence. Spans are `inclusive`.\n    Additionally, you can provide a maximum and minimum span width, which will be used\n    to exclude spans outside of this range.\n\n    Finally, you can provide a function mapping ``List[T] -> bool``, which will\n    be applied to every span to decide whether that span should be included. This\n    allows filtering by length, regex matches, pos tags or any Spacy ``Token``\n    attributes, for example.\n\n    Parameters\n    ----------\n    sentence : ``List[T]``, required.\n        The sentence to generate spans for. The type is generic, as this function\n        can be used with strings, or Spacy ``Tokens`` or other sequences.\n    offset : ``int``, optional (default = 0)\n        A numeric offset to add to all span start and end indices. This is helpful\n        if the sentence is part of a larger structure, such as a document, which\n        the indices need to respect.\n    max_span_width : ``int``, optional (default = None)\n        The maximum length of spans which should be included. Defaults to len(sentence).\n    min_span_width : ``int``, optional (default = 1)\n        The minimum length of spans which should be included. Defaults to 1.\n    filter_function : ``Callable[[List[T]], bool]``, optional (default = None)\n        A function mapping sequences of the passed type T to a boolean value.\n        If ``True``, the span is included in the returned spans from the\n        sentence, otherwise it is excluded..\n    \"\"\"\n    max_span_width = max_span_width or len(sentence)\n    filter_function = filter_function or (lambda x: True)\n    spans: List[Tuple[int, int]] = []\n\n    for start_index in range(len(sentence)):\n        last_end_index = min(start_index + max_span_width, len(sentence))\n        first_end_index = min(start_index + min_span_width - 1, len(sentence))\n        for end_index in range(first_end_index, last_end_index):\n            start = offset + start_index\n            end = offset + end_index\n            # add 1 to end index because span indices are inclusive.\n            if filter_function(sentence[slice(start_index, end_index + 1)]):\n                spans.append((start, end))\n    return spans", "response": "Given a list of sentences return all token spans within the sentence."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bio_tags_to_spans(tag_sequence: List[str],\n                      classes_to_ignore: List[str] = None) -> List[TypedStringSpan]:\n    \"\"\"\n    Given a sequence corresponding to BIO tags, extracts spans.\n    Spans are inclusive and can be of zero length, representing a single word span.\n    Ill-formed spans are also included (i.e those which do not start with a \"B-LABEL\"),\n    as otherwise it is possible to get a perfect precision score whilst still predicting\n    ill-formed spans in addition to the correct spans. This function works properly when\n    the spans are unlabeled (i.e., your labels are simply \"B\", \"I\", and \"O\").\n\n    Parameters\n    ----------\n    tag_sequence : List[str], required.\n        The integer class labels for a sequence.\n    classes_to_ignore : List[str], optional (default = None).\n        A list of string class labels `excluding` the bio tag\n        which should be ignored when extracting spans.\n\n    Returns\n    -------\n    spans : List[TypedStringSpan]\n        The typed, extracted spans from the sequence, in the format (label, (span_start, span_end)).\n        Note that the label `does not` contain any BIO tag prefixes.\n    \"\"\"\n    classes_to_ignore = classes_to_ignore or []\n    spans: Set[Tuple[str, Tuple[int, int]]] = set()\n    span_start = 0\n    span_end = 0\n    active_conll_tag = None\n    for index, string_tag in enumerate(tag_sequence):\n        # Actual BIO tag.\n        bio_tag = string_tag[0]\n        if bio_tag not in [\"B\", \"I\", \"O\"]:\n            raise InvalidTagSequence(tag_sequence)\n        conll_tag = string_tag[2:]\n        if bio_tag == \"O\" or conll_tag in classes_to_ignore:\n            # The span has ended.\n            if active_conll_tag is not None:\n                spans.add((active_conll_tag, (span_start, span_end)))\n            active_conll_tag = None\n            # We don't care about tags we are\n            # told to ignore, so we do nothing.\n            continue\n        elif bio_tag == \"B\":\n            # We are entering a new span; reset indices\n            # and active tag to new span.\n            if active_conll_tag is not None:\n                spans.add((active_conll_tag, (span_start, span_end)))\n            active_conll_tag = conll_tag\n            span_start = index\n            span_end = index\n        elif bio_tag == \"I\" and conll_tag == active_conll_tag:\n            # We're inside a span.\n            span_end += 1\n        else:\n            # This is the case the bio label is an \"I\", but either:\n            # 1) the span hasn't started - i.e. an ill formed span.\n            # 2) The span is an I tag for a different conll annotation.\n            # We'll process the previous span if it exists, but also\n            # include this span. This is important, because otherwise,\n            # a model may get a perfect F1 score whilst still including\n            # false positive ill-formed spans.\n            if active_conll_tag is not None:\n                spans.add((active_conll_tag, (span_start, span_end)))\n            active_conll_tag = conll_tag\n            span_start = index\n            span_end = index\n    # Last token might have been a part of a valid span.\n    if active_conll_tag is not None:\n        spans.add((active_conll_tag, (span_start, span_end)))\n    return list(spans)", "response": "Given a sequence corresponding to BIO tags extracts spans from the BIO tags and returns a list of typed string spans."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iob1_tags_to_spans(tag_sequence: List[str],\n                       classes_to_ignore: List[str] = None) -> List[TypedStringSpan]:\n    \"\"\"\n    Given a sequence corresponding to IOB1 tags, extracts spans.\n    Spans are inclusive and can be of zero length, representing a single word span.\n    Ill-formed spans are also included (i.e., those where \"B-LABEL\" is not preceded\n    by \"I-LABEL\" or \"B-LABEL\").\n\n    Parameters\n    ----------\n    tag_sequence : List[str], required.\n        The integer class labels for a sequence.\n    classes_to_ignore : List[str], optional (default = None).\n        A list of string class labels `excluding` the bio tag\n        which should be ignored when extracting spans.\n\n    Returns\n    -------\n    spans : List[TypedStringSpan]\n        The typed, extracted spans from the sequence, in the format (label, (span_start, span_end)).\n        Note that the label `does not` contain any BIO tag prefixes.\n    \"\"\"\n    classes_to_ignore = classes_to_ignore or []\n    spans: Set[Tuple[str, Tuple[int, int]]] = set()\n    span_start = 0\n    span_end = 0\n    active_conll_tag = None\n    prev_bio_tag = None\n    prev_conll_tag = None\n    for index, string_tag in enumerate(tag_sequence):\n        curr_bio_tag = string_tag[0]\n        curr_conll_tag = string_tag[2:]\n\n        if curr_bio_tag not in [\"B\", \"I\", \"O\"]:\n            raise InvalidTagSequence(tag_sequence)\n        if curr_bio_tag == \"O\" or curr_conll_tag in classes_to_ignore:\n            # The span has ended.\n            if active_conll_tag is not None:\n                spans.add((active_conll_tag, (span_start, span_end)))\n            active_conll_tag = None\n        elif _iob1_start_of_chunk(prev_bio_tag, prev_conll_tag,\n                                  curr_bio_tag, curr_conll_tag):\n            # We are entering a new span; reset indices\n            # and active tag to new span.\n            if active_conll_tag is not None:\n                spans.add((active_conll_tag, (span_start, span_end)))\n            active_conll_tag = curr_conll_tag\n            span_start = index\n            span_end = index\n        else:\n            # bio_tag == \"I\" and curr_conll_tag == active_conll_tag\n            # We're continuing a span.\n            span_end += 1\n\n        prev_bio_tag = string_tag[0]\n        prev_conll_tag = string_tag[2:]\n    # Last token might have been a part of a valid span.\n    if active_conll_tag is not None:\n        spans.add((active_conll_tag, (span_start, span_end)))\n    return list(spans)", "response": "Given a sequence corresponding to IOB1 tags extracts spans from the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bioul_tags_to_spans(tag_sequence: List[str],\n                        classes_to_ignore: List[str] = None) -> List[TypedStringSpan]:\n    \"\"\"\n    Given a sequence corresponding to BIOUL tags, extracts spans.\n    Spans are inclusive and can be of zero length, representing a single word span.\n    Ill-formed spans are not allowed and will raise ``InvalidTagSequence``.\n    This function works properly when the spans are unlabeled (i.e., your labels are\n    simply \"B\", \"I\", \"O\", \"U\", and \"L\").\n\n    Parameters\n    ----------\n    tag_sequence : ``List[str]``, required.\n        The tag sequence encoded in BIOUL, e.g. [\"B-PER\", \"L-PER\", \"O\"].\n    classes_to_ignore : ``List[str]``, optional (default = None).\n        A list of string class labels `excluding` the bio tag\n        which should be ignored when extracting spans.\n\n    Returns\n    -------\n    spans : ``List[TypedStringSpan]``\n        The typed, extracted spans from the sequence, in the format (label, (span_start, span_end)).\n    \"\"\"\n    spans = []\n    classes_to_ignore = classes_to_ignore or []\n    index = 0\n    while index < len(tag_sequence):\n        label = tag_sequence[index]\n        if label[0] == 'U':\n            spans.append((label.partition('-')[2], (index, index)))\n        elif label[0] == 'B':\n            start = index\n            while label[0] != 'L':\n                index += 1\n                if index >= len(tag_sequence):\n                    raise InvalidTagSequence(tag_sequence)\n                label = tag_sequence[index]\n                if not (label[0] == 'I' or label[0] == 'L'):\n                    raise InvalidTagSequence(tag_sequence)\n            spans.append((label.partition('-')[2], (start, index)))\n        else:\n            if label != 'O':\n                raise InvalidTagSequence(tag_sequence)\n        index += 1\n    return [span for span in spans if span[0] not in classes_to_ignore]", "response": "Given a sequence corresponding to BIOUL tags extracts spans from the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a tag sequence encoded with IOB1 labels to BIOUL.", "response": "def to_bioul(tag_sequence: List[str], encoding: str = \"IOB1\") -> List[str]:\n    \"\"\"\n    Given a tag sequence encoded with IOB1 labels, recode to BIOUL.\n\n    In the IOB1 scheme, I is a token inside a span, O is a token outside\n    a span and B is the beginning of span immediately following another\n    span of the same type.\n\n    In the BIO scheme, I is a token inside a span, O is a token outside\n    a span and B is the beginning of a span.\n\n    Parameters\n    ----------\n    tag_sequence : ``List[str]``, required.\n        The tag sequence encoded in IOB1, e.g. [\"I-PER\", \"I-PER\", \"O\"].\n    encoding : `str`, optional, (default = ``IOB1``).\n        The encoding type to convert from. Must be either \"IOB1\" or \"BIO\".\n\n    Returns\n    -------\n    bioul_sequence: ``List[str]``\n        The tag sequence encoded in IOB1, e.g. [\"B-PER\", \"L-PER\", \"O\"].\n    \"\"\"\n\n    if not encoding in {\"IOB1\", \"BIO\"}:\n        raise ConfigurationError(f\"Invalid encoding {encoding} passed to 'to_bioul'.\")\n    # pylint: disable=len-as-condition\n\n    def replace_label(full_label, new_label):\n        # example: full_label = 'I-PER', new_label = 'U', returns 'U-PER'\n        parts = list(full_label.partition('-'))\n        parts[0] = new_label\n        return ''.join(parts)\n\n    def pop_replace_append(in_stack, out_stack, new_label):\n        # pop the last element from in_stack, replace the label, append\n        # to out_stack\n        tag = in_stack.pop()\n        new_tag = replace_label(tag, new_label)\n        out_stack.append(new_tag)\n\n    def process_stack(stack, out_stack):\n        # process a stack of labels, add them to out_stack\n        if len(stack) == 1:\n            # just a U token\n            pop_replace_append(stack, out_stack, 'U')\n        else:\n            # need to code as BIL\n            recoded_stack = []\n            pop_replace_append(stack, recoded_stack, 'L')\n            while len(stack) >= 2:\n                pop_replace_append(stack, recoded_stack, 'I')\n            pop_replace_append(stack, recoded_stack, 'B')\n            recoded_stack.reverse()\n            out_stack.extend(recoded_stack)\n\n\n    # Process the tag_sequence one tag at a time, adding spans to a stack,\n    # then recode them.\n    bioul_sequence = []\n    stack: List[str] = []\n\n    for label in tag_sequence:\n        # need to make a dict like\n        # token = {'token': 'Matt', \"labels\": {'conll2003': \"B-PER\"}\n        #                   'gold': 'I-PER'}\n        # where 'gold' is the raw value from the CoNLL data set\n\n        if label == 'O' and len(stack) == 0:\n            bioul_sequence.append(label)\n        elif label == 'O' and len(stack) > 0:\n            # need to process the entries on the stack plus this one\n            process_stack(stack, bioul_sequence)\n            bioul_sequence.append(label)\n        elif label[0] == 'I':\n            # check if the previous type is the same as this one\n            # if it is then append to stack\n            # otherwise this start a new entity if the type\n            # is different\n            if len(stack) == 0:\n                if encoding == \"BIO\":\n                    raise InvalidTagSequence(tag_sequence)\n                stack.append(label)\n            else:\n                # check if the previous type is the same as this one\n                this_type = label.partition('-')[2]\n                prev_type = stack[-1].partition('-')[2]\n                if this_type == prev_type:\n                    stack.append(label)\n                else:\n                    if encoding == \"BIO\":\n                        raise InvalidTagSequence(tag_sequence)\n                    # a new entity\n                    process_stack(stack, bioul_sequence)\n                    stack.append(label)\n        elif label[0] == 'B':\n            if len(stack) > 0:\n                process_stack(stack, bioul_sequence)\n            stack.append(label)\n        else:\n            raise InvalidTagSequence(tag_sequence)\n\n    # process the stack\n    if len(stack) > 0:\n        process_stack(stack, bioul_sequence)\n\n    return bioul_sequence"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a sequence corresponding to BMES tags extracts spans from the BMES tag and returns a list of typed string spans.", "response": "def bmes_tags_to_spans(tag_sequence: List[str],\n                       classes_to_ignore: List[str] = None) -> List[TypedStringSpan]:\n    \"\"\"\n    Given a sequence corresponding to BMES tags, extracts spans.\n    Spans are inclusive and can be of zero length, representing a single word span.\n    Ill-formed spans are also included (i.e those which do not start with a \"B-LABEL\"),\n    as otherwise it is possible to get a perfect precision score whilst still predicting\n    ill-formed spans in addition to the correct spans.\n    This function works properly when the spans are unlabeled (i.e., your labels are\n    simply \"B\", \"M\", \"E\" and \"S\").\n\n    Parameters\n    ----------\n    tag_sequence : List[str], required.\n        The integer class labels for a sequence.\n    classes_to_ignore : List[str], optional (default = None).\n        A list of string class labels `excluding` the bio tag\n        which should be ignored when extracting spans.\n\n    Returns\n    -------\n    spans : List[TypedStringSpan]\n        The typed, extracted spans from the sequence, in the format (label, (span_start, span_end)).\n        Note that the label `does not` contain any BIO tag prefixes.\n    \"\"\"\n\n    def extract_bmes_tag_label(text):\n        bmes_tag = text[0]\n        label = text[2:]\n        return bmes_tag, label\n\n    spans: List[Tuple[str, List[int]]] = []\n    prev_bmes_tag: Optional[str] = None\n    for index, tag in enumerate(tag_sequence):\n        bmes_tag, label = extract_bmes_tag_label(tag)\n        if bmes_tag in ('B', 'S'):\n            # Regardless of tag, we start a new span when reaching B & S.\n            spans.append(\n                    (label, [index, index])\n                    )\n        elif bmes_tag in ('M', 'E') and prev_bmes_tag in ('B', 'M') and spans[-1][0] == label:\n            # Only expand the span if\n            # 1. Valid transition: B/M -> M/E.\n            # 2. Matched label.\n            spans[-1][1][1] = index\n        else:\n            # Best effort split for invalid span.\n            spans.append(\n                    (label, [index, index])\n                    )\n        # update previous BMES tag.\n        prev_bmes_tag = bmes_tag\n\n    classes_to_ignore = classes_to_ignore or []\n    return [\n            # to tuple.\n            (span[0], (span[1][0], span[1][1]))\n            for span in spans\n            if span[0] not in classes_to_ignore\n            ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dry_run_from_args(args: argparse.Namespace):\n    parameter_path = args.param_path\n    serialization_dir = args.serialization_dir\n    overrides = args.overrides\n\n    params = Params.from_file(parameter_path, overrides)\n\n    dry_run_from_params(params, serialization_dir)", "response": "Just converts from an argparse. Namespace object to params.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsearching for the next state in the beam.", "response": "def search(self,\n               initial_state: State,\n               transition_function: TransitionFunction) -> Dict[int, List[State]]:\n        \"\"\"\n        Parameters\n        ----------\n        initial_state : ``State``\n            The starting state of our search.  This is assumed to be `batched`, and our beam search\n            is batch-aware - we'll keep ``beam_size`` states around for each instance in the batch.\n        transition_function : ``TransitionFunction``\n            The ``TransitionFunction`` object that defines and scores transitions from one state to the\n            next.\n\n        Returns\n        -------\n        best_states : ``Dict[int, List[State]]``\n            This is a mapping from batch index to the top states for that instance.\n        \"\"\"\n        finished_states: Dict[int, List[State]] = defaultdict(list)\n        states = [initial_state]\n        step_num = 0\n        while states:\n            step_num += 1\n            next_states: Dict[int, List[State]] = defaultdict(list)\n            grouped_state = states[0].combine_states(states)\n            allowed_actions = []\n            for batch_index, action_history in zip(grouped_state.batch_indices,\n                                                   grouped_state.action_history):\n                allowed_actions.append(self._allowed_transitions[batch_index][tuple(action_history)])\n            for next_state in transition_function.take_step(grouped_state,\n                                                            max_actions=self._per_node_beam_size,\n                                                            allowed_actions=allowed_actions):\n                # NOTE: we're doing state.batch_indices[0] here (and similar things below),\n                # hard-coding a group size of 1.  But, our use of `next_state.is_finished()`\n                # already checks for that, as it crashes if the group size is not 1.\n                batch_index = next_state.batch_indices[0]\n                if next_state.is_finished():\n                    finished_states[batch_index].append(next_state)\n                else:\n                    next_states[batch_index].append(next_state)\n            states = []\n            for batch_index, batch_states in next_states.items():\n                # The states from the generator are already sorted, so we can just take the first\n                # ones here, without an additional sort.\n                if self._beam_size:\n                    batch_states = batch_states[:self._beam_size]\n                states.extend(batch_states)\n        best_states: Dict[int, List[State]] = {}\n        for batch_index, batch_states in finished_states.items():\n            # The time this sort takes is pretty negligible, no particular need to optimize this\n            # yet.  Maybe with a larger beam size...\n            finished_to_sort = [(-state.score[0].item(), state) for state in batch_states]\n            finished_to_sort.sort(key=lambda x: x[0])\n            best_states[batch_index] = [state[1] for state in finished_to_sort[:self._beam_size]]\n        return best_states"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef url_ok(match_tuple: MatchTuple) -> bool:\n    try:\n        result = requests.get(match_tuple.link, timeout=5)\n        return result.ok\n    except (requests.ConnectionError, requests.Timeout):\n        return False", "response": "Check if a URL is reachable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if a file in this repository exists.", "response": "def path_ok(match_tuple: MatchTuple) -> bool:\n    \"\"\"Check if a file in this repository exists.\"\"\"\n    relative_path = match_tuple.link.split(\"#\")[0]\n    full_path = os.path.join(os.path.dirname(str(match_tuple.source)), relative_path)\n    return os.path.exists(full_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef infer_and_cast(value: Any):\n    # pylint: disable=too-many-return-statements\n    if isinstance(value, (int, float, bool)):\n        # Already one of our desired types, so leave as is.\n        return value\n    elif isinstance(value, list):\n        # Recursively call on each list element.\n        return [infer_and_cast(item) for item in value]\n    elif isinstance(value, dict):\n        # Recursively call on each dict value.\n        return {key: infer_and_cast(item) for key, item in value.items()}\n    elif isinstance(value, str):\n        # If it looks like a bool, make it a bool.\n        if value.lower() == \"true\":\n            return True\n        elif value.lower() == \"false\":\n            return False\n        else:\n            # See if it could be an int.\n            try:\n                return int(value)\n            except ValueError:\n                pass\n            # See if it could be a float.\n            try:\n                return float(value)\n            except ValueError:\n                # Just return it as a string.\n                return value\n    else:\n        raise ValueError(f\"cannot infer type of {value}\")", "response": "Infer the type of the value and return it."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dictionary of environment variables that can be used to filter out non - encodable values.", "response": "def _environment_variables() -> Dict[str, str]:\n    \"\"\"\n    Wraps `os.environ` to filter out non-encodable values.\n    \"\"\"\n    return {key: value\n            for key, value in os.environ.items()\n            if _is_encodable(value)}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unflatten(flat_dict: Dict[str, Any]) -> Dict[str, Any]:\n    unflat: Dict[str, Any] = {}\n\n    for compound_key, value in flat_dict.items():\n        curr_dict = unflat\n        parts = compound_key.split(\".\")\n        for key in parts[:-1]:\n            curr_value = curr_dict.get(key)\n            if key not in curr_dict:\n                curr_dict[key] = {}\n                curr_dict = curr_dict[key]\n            elif isinstance(curr_value, dict):\n                curr_dict = curr_value\n            else:\n                raise ConfigurationError(\"flattened dictionary is invalid\")\n        if not isinstance(curr_dict, dict) or parts[-1] in curr_dict:\n            raise ConfigurationError(\"flattened dictionary is invalid\")\n        else:\n            curr_dict[parts[-1]] = value\n\n    return unflat", "response": "Given a flattened dictionary with compound keys e. g. a. b. c returns a new dict with the flattened keys."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef with_fallback(preferred: Dict[str, Any], fallback: Dict[str, Any]) -> Dict[str, Any]:\n    def merge(preferred_value: Any, fallback_value: Any) -> Any:\n        if isinstance(preferred_value, dict) and isinstance(fallback_value, dict):\n            return with_fallback(preferred_value, fallback_value)\n        elif isinstance(preferred_value, dict) and isinstance(fallback_value, list):\n            # treat preferred_value as a sparse list, where each key is an index to be overridden\n            merged_list = fallback_value\n            for elem_key, preferred_element in preferred_value.items():\n                try:\n                    index = int(elem_key)\n                    merged_list[index] = merge(preferred_element, fallback_value[index])\n                except ValueError:\n                    raise ConfigurationError(\"could not merge dicts - the preferred dict contains \"\n                                             f\"invalid keys (key {elem_key} is not a valid list index)\")\n                except IndexError:\n                    raise ConfigurationError(\"could not merge dicts - the preferred dict contains \"\n                                             f\"invalid keys (key {index} is out of bounds)\")\n            return merged_list\n        else:\n            return copy.deepcopy(preferred_value)\n\n    preferred_keys = set(preferred.keys())\n    fallback_keys = set(fallback.keys())\n    common_keys = preferred_keys & fallback_keys\n\n    merged: Dict[str, Any] = {}\n\n    for key in preferred_keys - fallback_keys:\n        merged[key] = copy.deepcopy(preferred[key])\n    for key in fallback_keys - preferred_keys:\n        merged[key] = copy.deepcopy(fallback[key])\n\n    for key in common_keys:\n        preferred_value = preferred[key]\n        fallback_value = fallback[key]\n\n        merged[key] = merge(preferred_value, fallback_value)\n    return merged", "response": "Deep merge two dicts preferring values from fallback."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pop_choice(params: Dict[str, Any],\n               key: str,\n               choices: List[Any],\n               default_to_first_choice: bool = False,\n               history: str = \"?.\") -> Any:\n    \"\"\"\n    Performs the same function as :func:`Params.pop_choice`, but is required in order to deal with\n    places that the Params object is not welcome, such as inside Keras layers.  See the docstring\n    of that method for more detail on how this function works.\n\n    This method adds a ``history`` parameter, in the off-chance that you know it, so that we can\n    reproduce :func:`Params.pop_choice` exactly.  We default to using \"?.\" if you don't know the\n    history, so you'll have to fix that in the log if you want to actually recover the logged\n    parameters.\n    \"\"\"\n    value = Params(params, history).pop_choice(key, choices, default_to_first_choice)\n    return value", "response": "Pop a choice from a list of parameters."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_file_to_archive(self, name: str) -> None:\n        if not self.loading_from_archive:\n            self.files_to_archive[f\"{self.history}{name}\"] = cached_path(self.get(name))", "response": "Add a file to the archive."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pop(self, key: str, default: Any = DEFAULT) -> Any:\n        if default is self.DEFAULT:\n            try:\n                value = self.params.pop(key)\n            except KeyError:\n                raise ConfigurationError(\"key \\\"{}\\\" is required at location \\\"{}\\\"\".format(key, self.history))\n        else:\n            value = self.params.pop(key, default)\n        if not isinstance(value, dict):\n            logger.info(self.history + key + \" = \" + str(value))  # type: ignore\n        return self._check_is_dict(key, value)", "response": "Removes a key from the dictionary and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntaking a key and returns the corresponding int value.", "response": "def pop_int(self, key: str, default: Any = DEFAULT) -> int:\n        \"\"\"\n        Performs a pop and coerces to an int.\n        \"\"\"\n        value = self.pop(key, default)\n        if value is None:\n            return None\n        else:\n            return int(value)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntake a string key and returns the float value.", "response": "def pop_float(self, key: str, default: Any = DEFAULT) -> float:\n        \"\"\"\n        Performs a pop and coerces to a float.\n        \"\"\"\n        value = self.pop(key, default)\n        if value is None:\n            return None\n        else:\n            return float(value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform a pop and coerces to a bool.", "response": "def pop_bool(self, key: str, default: Any = DEFAULT) -> bool:\n        \"\"\"\n        Performs a pop and coerces to a bool.\n        \"\"\"\n        value = self.pop(key, default)\n        if value is None:\n            return None\n        elif isinstance(value, bool):\n            return value\n        elif value == \"true\":\n            return True\n        elif value == \"false\":\n            return False\n        else:\n            raise ValueError(\"Cannot convert variable to bool: \" + value)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, key: str, default: Any = DEFAULT):\n        if default is self.DEFAULT:\n            try:\n                value = self.params.get(key)\n            except KeyError:\n                raise ConfigurationError(\"key \\\"{}\\\" is required at location \\\"{}\\\"\".format(key, self.history))\n        else:\n            value = self.params.get(key, default)\n        return self._check_is_dict(key, value)", "response": "Returns a dict object for the given key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npop the value of key from the parameter dictionary ensuring that the value is one of the given choices.", "response": "def pop_choice(self, key: str, choices: List[Any], default_to_first_choice: bool = False) -> Any:\n        \"\"\"\n        Gets the value of ``key`` in the ``params`` dictionary, ensuring that the value is one of\n        the given choices. Note that this `pops` the key from params, modifying the dictionary,\n        consistent with how parameters are processed in this codebase.\n\n        Parameters\n        ----------\n        key: str\n            Key to get the value from in the param dictionary\n        choices: List[Any]\n            A list of valid options for values corresponding to ``key``.  For example, if you're\n            specifying the type of encoder to use for some part of your model, the choices might be\n            the list of encoder classes we know about and can instantiate.  If the value we find in\n            the param dictionary is not in ``choices``, we raise a ``ConfigurationError``, because\n            the user specified an invalid value in their parameter file.\n        default_to_first_choice: bool, optional (default=False)\n            If this is ``True``, we allow the ``key`` to not be present in the parameter\n            dictionary.  If the key is not present, we will use the return as the value the first\n            choice in the ``choices`` list.  If this is ``False``, we raise a\n            ``ConfigurationError``, because specifying the ``key`` is required (e.g., you `have` to\n            specify your model class when running an experiment, but you can feel free to use\n            default settings for encoders if you want).\n        \"\"\"\n        default = choices[0] if default_to_first_choice else self.DEFAULT\n        value = self.pop(key, default)\n        if value not in choices:\n            key_str = self.history + key\n            message = '%s not in acceptable choices for %s: %s' % (value, key_str, str(choices))\n            raise ConfigurationError(message)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef as_dict(self, quiet: bool = False, infer_type_and_cast: bool = False):\n        if infer_type_and_cast:\n            params_as_dict = infer_and_cast(self.params)\n        else:\n            params_as_dict = self.params\n\n        if quiet:\n            return params_as_dict\n\n        def log_recursively(parameters, history):\n            for key, value in parameters.items():\n                if isinstance(value, dict):\n                    new_local_history = history + key  + \".\"\n                    log_recursively(value, new_local_history)\n                else:\n                    logger.info(history + key + \" = \" + str(value))\n\n        logger.info(\"Converting Params object to dict; logging of default \"\n                    \"values will not occur when dictionary parameters are \"\n                    \"used subsequently.\")\n        logger.info(\"CURRENTLY DEFINED PARAMETERS: \")\n        log_recursively(self.params, self.history)\n        return params_as_dict", "response": "Convert the parameters object to a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the parameters of a flat dictionary from keys to values.", "response": "def as_flat_dict(self):\n        \"\"\"\n        Returns the parameters of a flat dictionary from keys to values.\n        Nested structure is collapsed with periods.\n        \"\"\"\n        flat_params = {}\n        def recurse(parameters, path):\n            for key, value in parameters.items():\n                newpath = path + [key]\n                if isinstance(value, dict):\n                    recurse(value, newpath)\n                else:\n                    flat_params['.'.join(newpath)] = value\n\n        recurse(self.params, [])\n        return flat_params"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nraise a ConfigurationError if self. params is not empty.", "response": "def assert_empty(self, class_name: str):\n        \"\"\"\n        Raises a ``ConfigurationError`` if ``self.params`` is not empty.  We take ``class_name`` as\n        an argument so that the error message gives some idea of where an error happened, if there\n        was one.  ``class_name`` should be the name of the `calling` class, the one that got extra\n        parameters (if there are any).\n        \"\"\"\n        if self.params:\n            raise ConfigurationError(\"Extra parameters passed to {}: {}\".format(class_name, self.params))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_file(params_file: str, params_overrides: str = \"\", ext_vars: dict = None) -> 'Params':\n        if ext_vars is None:\n            ext_vars = {}\n\n        # redirect to cache, if necessary\n        params_file = cached_path(params_file)\n        ext_vars = {**_environment_variables(), **ext_vars}\n\n        file_dict = json.loads(evaluate_file(params_file, ext_vars=ext_vars))\n\n        overrides_dict = parse_overrides(params_overrides)\n        param_dict = with_fallback(preferred=overrides_dict, fallback=file_dict)\n\n        return Params(param_dict)", "response": "Load a Params object from a configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef as_ordered_dict(self, preference_orders: List[List[str]] = None) -> OrderedDict:\n        params_dict = self.as_dict(quiet=True)\n        if not preference_orders:\n            preference_orders = []\n            preference_orders.append([\"dataset_reader\", \"iterator\", \"model\",\n                                      \"train_data_path\", \"validation_data_path\", \"test_data_path\",\n                                      \"trainer\", \"vocabulary\"])\n            preference_orders.append([\"type\"])\n\n        def order_func(key):\n            # Makes a tuple to use for ordering.  The tuple is an index into each of the `preference_orders`,\n            # followed by the key itself.  This gives us integer sorting if you have a key in one of the\n            # `preference_orders`, followed by alphabetical ordering if not.\n            order_tuple = [order.index(key) if key in order else len(order) for order in preference_orders]\n            return order_tuple + [key]\n\n        def order_dict(dictionary, order_func):\n            # Recursively orders dictionary according to scoring order_func\n            result = OrderedDict()\n            for key, val in sorted(dictionary.items(), key=lambda item: order_func(item[0])):\n                result[key] = order_dict(val, order_func) if isinstance(val, dict) else val\n            return result\n\n        return order_dict(params_dict, order_func)", "response": "Returns an OrderedDict of Params from the current instance."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a hash code representing the current state of this Params object.", "response": "def get_hash(self) -> str:\n        \"\"\"\n        Returns a hash code representing the current state of this ``Params`` object.  We don't\n        want to implement ``__hash__`` because that has deeper python implications (and this is a\n        mutable object), but this will give you a representation of the current state.\n        \"\"\"\n        return str(hash(json.dumps(self.params, sort_keys=True)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clear(self) -> None:\n        self._best_so_far = None\n        self._epochs_with_no_improvement = 0\n        self._is_best_so_far = True\n        self._epoch_number = 0\n        self.best_epoch = None", "response": "Clears out the current set of tracked metrics."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a metric to the log.", "response": "def add_metric(self, metric: float) -> None:\n        \"\"\"\n        Record a new value of the metric and update the various things that depend on it.\n        \"\"\"\n        new_best = ((self._best_so_far is None) or\n                    (self._should_decrease and metric < self._best_so_far) or\n                    (not self._should_decrease and metric > self._best_so_far))\n\n        if new_best:\n            self.best_epoch = self._epoch_number\n            self._is_best_so_far = True\n            self._best_so_far = metric\n            self._epochs_with_no_improvement = 0\n        else:\n            self._is_best_so_far = False\n            self._epochs_with_no_improvement += 1\n        self._epoch_number += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_metrics(self, metrics: Iterable[float]) -> None:\n        for metric in metrics:\n            self.add_metric(metric)", "response": "Helper to add multiple metrics at once."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef should_stop_early(self) -> bool:\n        if self._patience is None:\n            return False\n        else:\n            return self._epochs_with_no_improvement >= self._patience", "response": "Returns true if improvement has stopped for long enough."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef archive_model(serialization_dir: str,\n                  weights: str = _DEFAULT_WEIGHTS,\n                  files_to_archive: Dict[str, str] = None,\n                  archive_path: str = None) -> None:\n    \"\"\"\n    Archive the model weights, its training configuration, and its\n    vocabulary to `model.tar.gz`. Include the additional ``files_to_archive``\n    if provided.\n\n    Parameters\n    ----------\n    serialization_dir: ``str``\n        The directory where the weights and vocabulary are written out.\n    weights: ``str``, optional (default=_DEFAULT_WEIGHTS)\n        Which weights file to include in the archive. The default is ``best.th``.\n    files_to_archive: ``Dict[str, str]``, optional (default=None)\n        A mapping {flattened_key -> filename} of supplementary files to include\n        in the archive. That is, if you wanted to include ``params['model']['weights']``\n        then you would specify the key as `\"model.weights\"`.\n    archive_path : ``str``, optional, (default = None)\n        A full path to serialize the model to. The default is \"model.tar.gz\" inside the\n        serialization_dir. If you pass a directory here, we'll serialize the model\n        to \"model.tar.gz\" inside the directory.\n    \"\"\"\n    weights_file = os.path.join(serialization_dir, weights)\n    if not os.path.exists(weights_file):\n        logger.error(\"weights file %s does not exist, unable to archive model\", weights_file)\n        return\n\n    config_file = os.path.join(serialization_dir, CONFIG_NAME)\n    if not os.path.exists(config_file):\n        logger.error(\"config file %s does not exist, unable to archive model\", config_file)\n\n    # If there are files we want to archive, write out the mapping\n    # so that we can use it during de-archiving.\n    if files_to_archive:\n        fta_filename = os.path.join(serialization_dir, _FTA_NAME)\n        with open(fta_filename, 'w') as fta_file:\n            fta_file.write(json.dumps(files_to_archive))\n\n    if archive_path is not None:\n        archive_file = archive_path\n        if os.path.isdir(archive_file):\n            archive_file = os.path.join(archive_file, \"model.tar.gz\")\n    else:\n        archive_file = os.path.join(serialization_dir, \"model.tar.gz\")\n    logger.info(\"archiving weights and vocabulary to %s\", archive_file)\n    with tarfile.open(archive_file, 'w:gz') as archive:\n        archive.add(config_file, arcname=CONFIG_NAME)\n        archive.add(weights_file, arcname=_WEIGHTS_NAME)\n        archive.add(os.path.join(serialization_dir, \"vocabulary\"),\n                    arcname=\"vocabulary\")\n\n        # If there are supplemental files to archive:\n        if files_to_archive:\n            # Archive the { flattened_key -> original_filename } mapping.\n            archive.add(fta_filename, arcname=_FTA_NAME)\n            # And add each requested file to the archive.\n            for key, filename in files_to_archive.items():\n                archive.add(filename, arcname=f\"fta/{key}\")", "response": "Archive the model with the given weights and vocabulary."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads an archive file into a new object.", "response": "def load_archive(archive_file: str,\n                 cuda_device: int = -1,\n                 overrides: str = \"\",\n                 weights_file: str = None) -> Archive:\n    \"\"\"\n    Instantiates an Archive from an archived `tar.gz` file.\n\n    Parameters\n    ----------\n    archive_file: ``str``\n        The archive file to load the model from.\n    weights_file: ``str``, optional (default = None)\n        The weights file to use.  If unspecified, weights.th in the archive_file will be used.\n    cuda_device: ``int``, optional (default = -1)\n        If `cuda_device` is >= 0, the model will be loaded onto the\n        corresponding GPU. Otherwise it will be loaded onto the CPU.\n    overrides: ``str``, optional (default = \"\")\n        JSON overrides to apply to the unarchived ``Params`` object.\n    \"\"\"\n    # redirect to the cache, if necessary\n    resolved_archive_file = cached_path(archive_file)\n\n    if resolved_archive_file == archive_file:\n        logger.info(f\"loading archive file {archive_file}\")\n    else:\n        logger.info(f\"loading archive file {archive_file} from cache at {resolved_archive_file}\")\n\n    if os.path.isdir(resolved_archive_file):\n        serialization_dir = resolved_archive_file\n    else:\n        # Extract archive to temp dir\n        tempdir = tempfile.mkdtemp()\n        logger.info(f\"extracting archive file {resolved_archive_file} to temp dir {tempdir}\")\n        with tarfile.open(resolved_archive_file, 'r:gz') as archive:\n            archive.extractall(tempdir)\n        # Postpone cleanup until exit in case the unarchived contents are needed outside\n        # this function.\n        atexit.register(_cleanup_archive_dir, tempdir)\n\n        serialization_dir = tempdir\n\n    # Check for supplemental files in archive\n    fta_filename = os.path.join(serialization_dir, _FTA_NAME)\n    if os.path.exists(fta_filename):\n        with open(fta_filename, 'r') as fta_file:\n            files_to_archive = json.loads(fta_file.read())\n\n        # Add these replacements to overrides\n        replacements_dict: Dict[str, Any] = {}\n        for key, original_filename in files_to_archive.items():\n            replacement_filename = os.path.join(serialization_dir, f\"fta/{key}\")\n            if os.path.exists(replacement_filename):\n                replacements_dict[key] = replacement_filename\n            else:\n                logger.warning(f\"Archived file {replacement_filename} not found! At train time \"\n                               f\"this file was located at {original_filename}. This may be \"\n                               \"because you are loading a serialization directory. Attempting to \"\n                               \"load the file from its train-time location.\")\n\n        overrides_dict = parse_overrides(overrides)\n        combined_dict = with_fallback(preferred=overrides_dict, fallback=unflatten(replacements_dict))\n        overrides = json.dumps(combined_dict)\n\n    # Load config\n    config = Params.from_file(os.path.join(serialization_dir, CONFIG_NAME), overrides)\n    config.loading_from_archive = True\n\n    if weights_file:\n        weights_path = weights_file\n    else:\n        weights_path = os.path.join(serialization_dir, _WEIGHTS_NAME)\n        # Fallback for serialization directories.\n        if not os.path.exists(weights_path):\n            weights_path = os.path.join(serialization_dir, _DEFAULT_WEIGHTS)\n\n\n    # Instantiate model. Use a duplicate of the config, as it will get consumed.\n    model = Model.load(config.duplicate(),\n                       weights_file=weights_path,\n                       serialization_dir=serialization_dir,\n                       cuda_device=cuda_device)\n\n    return Archive(model=model, config=config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extract_module(self, path: str, freeze: bool = True) -> Module:\n        modules_dict = {path: module for path, module in self.model.named_modules()}\n        module = modules_dict.get(path, None)\n\n        if not module:\n            raise ConfigurationError(f\"You asked to transfer module at path {path} from \"\n                                     f\"the model {type(self.model)}. But it's not present.\")\n        if not isinstance(module, Module):\n            raise ConfigurationError(f\"The transferred object from model {type(self.model)} at path \"\n                                     f\"{path} is not a PyTorch Module.\")\n\n        for parameter in module.parameters(): # type: ignore\n            parameter.requires_grad_(not freeze)\n        return module", "response": "This method extracts a module from the pretrained model archive."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntaking a list of possible actions and indices of decoded actions into those possible actions and returns a list of all possible action strings.", "response": "def _get_action_strings(cls,\n                            possible_actions: List[List[ProductionRule]],\n                            action_indices: Dict[int, List[List[int]]]) -> List[List[List[str]]]:\n        \"\"\"\n        Takes a list of possible actions and indices of decoded actions into those possible actions\n        for a batch and returns sequences of action strings. We assume ``action_indices`` is a dict\n        mapping batch indices to k-best decoded sequence lists.\n        \"\"\"\n        all_action_strings: List[List[List[str]]] = []\n        batch_size = len(possible_actions)\n        for i in range(batch_size):\n            batch_actions = possible_actions[i]\n            batch_best_sequences = action_indices[i] if i in action_indices else []\n            # This will append an empty list to ``all_action_strings`` if ``batch_best_sequences``\n            # is empty.\n            action_strings = [[batch_actions[rule_id][0] for rule_id in sequence]\n                              for sequence in batch_best_sequences]\n            all_action_strings.append(action_strings)\n        return all_action_strings"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decode(self, output_dict: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n        best_action_strings = output_dict[\"best_action_strings\"]\n        # Instantiating an empty world for getting logical forms.\n        world = NlvrLanguage(set())\n        logical_forms = []\n        for instance_action_sequences in best_action_strings:\n            instance_logical_forms = []\n            for action_strings in instance_action_sequences:\n                if action_strings:\n                    instance_logical_forms.append(world.action_sequence_to_logical_form(action_strings))\n                else:\n                    instance_logical_forms.append('')\n            logical_forms.append(instance_logical_forms)\n\n        action_mapping = output_dict['action_mapping']\n        best_actions = output_dict['best_action_strings']\n        debug_infos = output_dict['debug_info']\n        batch_action_info = []\n        for batch_index, (predicted_actions, debug_info) in enumerate(zip(best_actions, debug_infos)):\n            instance_action_info = []\n            for predicted_action, action_debug_info in zip(predicted_actions[0], debug_info):\n                action_info = {}\n                action_info['predicted_action'] = predicted_action\n                considered_actions = action_debug_info['considered_actions']\n                probabilities = action_debug_info['probabilities']\n                actions = []\n                for action, probability in zip(considered_actions, probabilities):\n                    if action != -1:\n                        actions.append((action_mapping[(batch_index, action)], probability))\n                actions.sort()\n                considered_actions, probabilities = zip(*actions)\n                action_info['considered_actions'] = considered_actions\n                action_info['action_probabilities'] = probabilities\n                action_info['question_attention'] = action_debug_info.get('question_attention', [])\n                instance_action_info.append(action_info)\n            batch_action_info.append(instance_action_info)\n        output_dict[\"predicted_actions\"] = batch_action_info\n        output_dict[\"logical_form\"] = logical_forms\n        return output_dict", "response": "This method decodes the output dictionary into a list of logical forms."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning whether the state evaluates to the correct denotations over all the worlds.", "response": "def _check_state_denotations(self, state: GrammarBasedState, worlds: List[NlvrLanguage]) -> List[bool]:\n        \"\"\"\n        Returns whether action history in the state evaluates to the correct denotations over all\n        worlds. Only defined when the state is finished.\n        \"\"\"\n        assert state.is_finished(), \"Cannot compute denotations for unfinished states!\"\n        # Since this is a finished state, its group size must be 1.\n        batch_index = state.batch_indices[0]\n        instance_label_strings = state.extras[batch_index]\n        history = state.action_history[0]\n        all_actions = state.possible_actions[0]\n        action_sequence = [all_actions[action][0] for action in history]\n        return self._check_denotation(action_sequence, instance_label_strings, worlds)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting learning rate finder for given args", "response": "def find_learning_rate_from_args(args: argparse.Namespace) -> None:\n    \"\"\"\n    Start learning rate finder for given args\n    \"\"\"\n    params = Params.from_file(args.param_path, args.overrides)\n    find_learning_rate_model(params, args.serialization_dir,\n                             start_lr=args.start_lr,\n                             end_lr=args.end_lr,\n                             num_batches=args.num_batches,\n                             linear_steps=args.linear,\n                             stopping_factor=args.stopping_factor,\n                             force=args.force)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_learning_rate_model(params: Params, serialization_dir: str,\n                             start_lr: float = 1e-5,\n                             end_lr: float = 10,\n                             num_batches: int = 100,\n                             linear_steps: bool = False,\n                             stopping_factor: float = None,\n                             force: bool = False) -> None:\n    \"\"\"\n    Runs learning rate search for given `num_batches` and saves the results in ``serialization_dir``\n\n    Parameters\n    ----------\n    params : ``Params``\n        A parameter object specifying an AllenNLP Experiment.\n    serialization_dir : ``str``\n        The directory in which to save results.\n    start_lr: ``float``\n        Learning rate to start the search.\n    end_lr: ``float``\n        Learning rate upto which search is done.\n    num_batches: ``int``\n        Number of mini-batches to run Learning rate finder.\n    linear_steps: ``bool``\n        Increase learning rate linearly if False exponentially.\n    stopping_factor: ``float``\n        Stop the search when the current loss exceeds the best loss recorded by\n        multiple of stopping factor. If ``None`` search proceeds till the ``end_lr``\n    force: ``bool``\n        If True and the serialization directory already exists, everything in it will\n        be removed prior to finding the learning rate.\n    \"\"\"\n    if os.path.exists(serialization_dir) and force:\n        shutil.rmtree(serialization_dir)\n\n    if os.path.exists(serialization_dir) and os.listdir(serialization_dir):\n        raise ConfigurationError(f'Serialization directory {serialization_dir} already exists and is '\n                                 f'not empty.')\n    else:\n        os.makedirs(serialization_dir, exist_ok=True)\n\n    prepare_environment(params)\n\n    cuda_device = params.params.get('trainer').get('cuda_device', -1)\n    check_for_gpu(cuda_device)\n\n    all_datasets = datasets_from_params(params)\n    datasets_for_vocab_creation = set(params.pop(\"datasets_for_vocab_creation\", all_datasets))\n\n    for dataset in datasets_for_vocab_creation:\n        if dataset not in all_datasets:\n            raise ConfigurationError(f\"invalid 'dataset_for_vocab_creation' {dataset}\")\n\n    logger.info(\"From dataset instances, %s will be considered for vocabulary creation.\",\n                \", \".join(datasets_for_vocab_creation))\n    vocab = Vocabulary.from_params(\n            params.pop(\"vocabulary\", {}),\n            (instance for key, dataset in all_datasets.items()\n             for instance in dataset\n             if key in datasets_for_vocab_creation)\n    )\n\n    model = Model.from_params(vocab=vocab, params=params.pop('model'))\n    iterator = DataIterator.from_params(params.pop(\"iterator\"))\n    iterator.index_with(vocab)\n\n    train_data = all_datasets['train']\n\n    trainer_params = params.pop(\"trainer\")\n    no_grad_regexes = trainer_params.pop(\"no_grad\", ())\n    for name, parameter in model.named_parameters():\n        if any(re.search(regex, name) for regex in no_grad_regexes):\n            parameter.requires_grad_(False)\n\n\n    trainer_choice = trainer_params.pop(\"type\", \"default\")\n    if trainer_choice != \"default\":\n        raise ConfigurationError(\"currently find-learning-rate only works with the default Trainer\")\n    trainer = Trainer.from_params(model=model,\n                                  serialization_dir=serialization_dir,\n                                  iterator=iterator,\n                                  train_data=train_data,\n                                  validation_data=None,\n                                  params=trainer_params,\n                                  validation_iterator=None)\n\n    logger.info(f'Starting learning rate search from {start_lr} to {end_lr} in {num_batches} iterations.')\n    learning_rates, losses = search_learning_rate(trainer,\n                                                  start_lr=start_lr,\n                                                  end_lr=end_lr,\n                                                  num_batches=num_batches,\n                                                  linear_steps=linear_steps,\n                                                  stopping_factor=stopping_factor)\n    logger.info(f'Finished learning rate search.')\n    losses = _smooth(losses, 0.98)\n\n    _save_plot(learning_rates, losses, os.path.join(serialization_dir, 'lr-losses.png'))", "response": "Searches for a learning rate model in the given serialization directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef search_learning_rate(trainer: Trainer,\n                         start_lr: float = 1e-5,\n                         end_lr: float = 10,\n                         num_batches: int = 100,\n                         linear_steps: bool = False,\n                         stopping_factor: float = None) -> Tuple[List[float], List[float]]:\n    \"\"\"\n    Runs training loop on the model using :class:`~allennlp.training.trainer.Trainer`\n    increasing learning rate from ``start_lr`` to ``end_lr`` recording the losses.\n    Parameters\n    ----------\n    trainer: :class:`~allennlp.training.trainer.Trainer`\n    start_lr: ``float``\n        The learning rate to start the search.\n    end_lr: ``float``\n        The learning rate upto which search is done.\n    num_batches: ``int``\n        Number of batches to run the learning rate finder.\n    linear_steps: ``bool``\n        Increase learning rate linearly if False exponentially.\n    stopping_factor: ``float``\n        Stop the search when the current loss exceeds the best loss recorded by\n        multiple of stopping factor. If ``None`` search proceeds till the ``end_lr``\n    Returns\n    -------\n    (learning_rates, losses): ``Tuple[List[float], List[float]]``\n        Returns list of learning rates and corresponding losses.\n        Note: The losses are recorded before applying the corresponding learning rate\n    \"\"\"\n    if num_batches <= 10:\n        raise ConfigurationError('The number of iterations for learning rate finder should be greater than 10.')\n\n    trainer.model.train()\n\n    num_gpus = len(trainer._cuda_devices) # pylint: disable=protected-access\n\n    raw_train_generator = trainer.iterator(trainer.train_data,\n                                           shuffle=trainer.shuffle)\n    train_generator = lazy_groups_of(raw_train_generator, num_gpus)\n    train_generator_tqdm = Tqdm.tqdm(train_generator,\n                                     total=num_batches)\n\n    learning_rates = []\n    losses = []\n    best = 1e9\n    if linear_steps:\n        lr_update_factor = (end_lr - start_lr) / num_batches\n    else:\n        lr_update_factor = (end_lr / start_lr) ** (1.0 / num_batches)\n\n    for i, batch_group in enumerate(train_generator_tqdm):\n\n        if linear_steps:\n            current_lr = start_lr + (lr_update_factor * i)\n        else:\n            current_lr = start_lr * (lr_update_factor ** i)\n\n        for param_group in trainer.optimizer.param_groups:\n            param_group['lr'] = current_lr\n\n        trainer.optimizer.zero_grad()\n        loss = trainer.batch_loss(batch_group, for_training=True)\n        loss.backward()\n        loss = loss.detach().cpu().item()\n\n        if stopping_factor is not None and (math.isnan(loss) or loss > stopping_factor * best):\n            logger.info(f'Loss ({loss}) exceeds stopping_factor * lowest recorded loss.')\n            break\n\n        trainer.rescale_gradients()\n        trainer.optimizer.step()\n\n        learning_rates.append(current_lr)\n        losses.append(loss)\n\n        if loss < best and i > 10:\n            best = loss\n\n        if i == num_batches:\n            break\n\n    return learning_rates, losses", "response": "Search the learning rate finder."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef forward(self, tensors: List[torch.Tensor],  # pylint: disable=arguments-differ\n                mask: torch.Tensor = None) -> torch.Tensor:\n        \"\"\"\n        Compute a weighted average of the ``tensors``.  The input tensors an be any shape\n        with at least two dimensions, but must all be the same shape.\n\n        When ``do_layer_norm=True``, the ``mask`` is required input.  If the ``tensors`` are\n        dimensioned  ``(dim_0, ..., dim_{n-1}, dim_n)``, then the ``mask`` is dimensioned\n        ``(dim_0, ..., dim_{n-1})``, as in the typical case with ``tensors`` of shape\n        ``(batch_size, timesteps, dim)`` and ``mask`` of shape ``(batch_size, timesteps)``.\n\n        When ``do_layer_norm=False`` the ``mask`` is ignored.\n        \"\"\"\n        if len(tensors) != self.mixture_size:\n            raise ConfigurationError(\"{} tensors were passed, but the module was initialized to \"\n                                     \"mix {} tensors.\".format(len(tensors), self.mixture_size))\n\n        def _do_layer_norm(tensor, broadcast_mask, num_elements_not_masked):\n            tensor_masked = tensor * broadcast_mask\n            mean = torch.sum(tensor_masked) / num_elements_not_masked\n            variance = torch.sum(((tensor_masked - mean) * broadcast_mask)**2) / num_elements_not_masked\n            return (tensor - mean) / torch.sqrt(variance + 1E-12)\n\n        normed_weights = torch.nn.functional.softmax(torch.cat([parameter for parameter\n                                                                in self.scalar_parameters]), dim=0)\n        normed_weights = torch.split(normed_weights, split_size_or_sections=1)\n\n        if not self.do_layer_norm:\n            pieces = []\n            for weight, tensor in zip(normed_weights, tensors):\n                pieces.append(weight * tensor)\n            return self.gamma * sum(pieces)\n\n        else:\n            mask_float = mask.float()\n            broadcast_mask = mask_float.unsqueeze(-1)\n            input_dim = tensors[0].size(-1)\n            num_elements_not_masked = torch.sum(mask_float) * input_dim\n\n            pieces = []\n            for weight, tensor in zip(normed_weights, tensors):\n                pieces.append(weight * _do_layer_norm(tensor,\n                                                      broadcast_mask, num_elements_not_masked))\n            return self.gamma * sum(pieces)", "response": "Computes the weighted average of the input tensors."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlike :func:`predicate`, but used when some of the arguments to the function are meant to be provided by the decoder or other state, instead of from the language. For example, you might want to have a function use the decoder's attention over some input text when a terminal was predicted. That attention won't show up in the language productions. Use this decorator, and pass in the required state to :func:`DomainLanguage.execute_action_sequence`, if you need to ignore some arguments when doing grammar induction. In order for this to work out, the side arguments `must` be after any non-side arguments. This is because we use ``*args`` to pass the non-side arguments, and ``**kwargs`` to pass the side arguments, and python requires that ``*args`` be before ``**kwargs``.", "response": "def predicate_with_side_args(side_arguments: List[str]) -> Callable:  # pylint: disable=invalid-name\n    \"\"\"\n    Like :func:`predicate`, but used when some of the arguments to the function are meant to be\n    provided by the decoder or other state, instead of from the language.  For example, you might\n    want to have a function use the decoder's attention over some input text when a terminal was\n    predicted.  That attention won't show up in the language productions.  Use this decorator, and\n    pass in the required state to :func:`DomainLanguage.execute_action_sequence`, if you need to\n    ignore some arguments when doing grammar induction.\n\n    In order for this to work out, the side arguments `must` be after any non-side arguments.  This\n    is because we use ``*args`` to pass the non-side arguments, and ``**kwargs`` to pass the side\n    arguments, and python requires that ``*args`` be before ``**kwargs``.\n    \"\"\"\n    def decorator(function: Callable) -> Callable:\n        setattr(function, '_side_arguments', side_arguments)\n        return predicate(function)\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a nltk. Tree into a logical form.", "response": "def nltk_tree_to_logical_form(tree: Tree) -> str:\n    \"\"\"\n    Given an ``nltk.Tree`` representing the syntax tree that generates a logical form, this method\n    produces the actual (lisp-like) logical form, with all of the non-terminal symbols converted\n    into the correct number of parentheses.\n\n    This is used in the logic that converts action sequences back into logical forms.  It's very\n    unlikely that you will need this anywhere else.\n    \"\"\"\n    # nltk.Tree actually inherits from `list`, so you use `len()` to get the number of children.\n    # We're going to be explicit about checking length, instead of using `if tree:`, just to avoid\n    # any funny business nltk might have done (e.g., it's really odd if `if tree:` evaluates to\n    # `False` if there's a single leaf node with no children).\n    if len(tree) == 0:  # pylint: disable=len-as-condition\n        return tree.label()\n    if len(tree) == 1:\n        return tree[0].label()\n    return '(' + ' '.join(nltk_tree_to_logical_form(child) for child in tree) + ')'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_type(type_: Type) -> 'PredicateType':\n        if is_callable(type_):\n            callable_args = type_.__args__\n            argument_types = [PredicateType.get_type(t) for t in callable_args[:-1]]\n            return_type = PredicateType.get_type(callable_args[-1])\n            return FunctionType(argument_types, return_type)\n        elif is_generic(type_):\n            # This is something like List[int].  type_.__name__ doesn't do the right thing (and\n            # crashes in python 3.7), so we need to do some magic here.\n            name = get_generic_name(type_)\n        else:\n            name = type_.__name__\n        return BasicType(name)", "response": "Converts a python type annotation into a predicate type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef execute(self, logical_form: str):\n        if not hasattr(self, '_functions'):\n            raise RuntimeError(\"You must call super().__init__() in your Language constructor\")\n        logical_form = logical_form.replace(\",\", \" \")\n        expression = util.lisp_to_nested_expression(logical_form)\n        return self._execute_expression(expression)", "response": "Executes a logical form using the predicates you have defined."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute_action_sequence(self, action_sequence: List[str], side_arguments: List[Dict] = None):\n        # We'll strip off the first action, because it doesn't matter for execution.\n        first_action = action_sequence[0]\n        left_side = first_action.split(' -> ')[0]\n        if left_side != '@start@':\n            raise ExecutionError('invalid action sequence')\n        remaining_side_args = side_arguments[1:] if side_arguments else None\n        return self._execute_sequence(action_sequence[1:], remaining_side_args)[0]", "response": "Executes the action sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninducing a grammar from the defined collection of predicates in this language and returns all productions that are not in the grammar.", "response": "def get_nonterminal_productions(self) -> Dict[str, List[str]]:\n        \"\"\"\n        Induces a grammar from the defined collection of predicates in this language and returns\n        all productions in that grammar, keyed by the non-terminal they are expanding.\n\n        This includes terminal productions implied by each predicate as well as productions for the\n        `return type` of each defined predicate.  For example, defining a \"multiply\" predicate adds\n        a \"<int,int:int> -> multiply\" terminal production to the grammar, and `also` a \"int ->\n        [<int,int:int>, int, int]\" non-terminal production, because I can use the \"multiply\"\n        predicate to produce an int.\n        \"\"\"\n        if not self._nonterminal_productions:\n            actions: Dict[str, Set[str]] = defaultdict(set)\n            # If you didn't give us a set of valid start types, we'll assume all types we know\n            # about (including functional types) are valid start types.\n            if self._start_types:\n                start_types = self._start_types\n            else:\n                start_types = set()\n                for type_list in self._function_types.values():\n                    start_types.update(type_list)\n            for start_type in start_types:\n                actions[START_SYMBOL].add(f\"{START_SYMBOL} -> {start_type}\")\n            for name, function_type_list in self._function_types.items():\n                for function_type in function_type_list:\n                    actions[str(function_type)].add(f\"{function_type} -> {name}\")\n                    if isinstance(function_type, FunctionType):\n                        return_type = function_type.return_type\n                        arg_types = function_type.argument_types\n                        right_side = f\"[{function_type}, {', '.join(str(arg_type) for arg_type in arg_types)}]\"\n                        actions[str(return_type)].add(f\"{return_type} -> {right_side}\")\n            self._nonterminal_productions = {key: sorted(value) for key, value in actions.items()}\n        return self._nonterminal_productions"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of all possible production rules in the grammar.", "response": "def all_possible_productions(self) -> List[str]:\n        \"\"\"\n        Returns a sorted list of all production rules in the grammar induced by\n        :func:`get_nonterminal_productions`.\n        \"\"\"\n        all_actions = set()\n        for action_set in self.get_nonterminal_productions().values():\n            all_actions.update(action_set)\n        return sorted(all_actions)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a logical form into a list of action sequences.", "response": "def logical_form_to_action_sequence(self, logical_form: str) -> List[str]:\n        \"\"\"\n        Converts a logical form into a linearization of the production rules from its abstract\n        syntax tree.  The linearization is top-down, depth-first.\n\n        Each production rule is formatted as \"LHS -> RHS\", where \"LHS\" is a single non-terminal\n        type, and RHS is either a terminal or a list of non-terminals (other possible values for\n        RHS in a more general context-free grammar are not produced by our grammar induction\n        logic).\n\n        Non-terminals are `types` in the grammar, either basic types (like ``int``, ``str``, or\n        some class that you define), or functional types, represented with angle brackets with a\n        colon separating arguments from the return type.  Multi-argument functions have commas\n        separating their argument types.  For example, ``<int:int>`` is a function that takes an\n        integer and returns an integer, and ``<int,int:int>`` is a function that takes two integer\n        arguments and returns an integer.\n\n        As an example translation from logical form to complete action sequence, the logical form\n        ``(add 2 3)`` would be translated to ``['@start@ -> int', 'int -> [<int,int:int>, int, int]',\n        '<int,int:int> -> add', 'int -> 2', 'int -> 3']``.\n        \"\"\"\n        expression = util.lisp_to_nested_expression(logical_form)\n        try:\n            transitions, start_type = self._get_transitions(expression, expected_type=None)\n            if self._start_types and start_type not in self._start_types:\n                raise ParsingError(f\"Expression had unallowed start type of {start_type}: {expression}\")\n        except ParsingError:\n            logger.error(f'Error parsing logical form: {logical_form}')\n            raise\n        transitions.insert(0, f'@start@ -> {start_type}')\n        return transitions"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef action_sequence_to_logical_form(self, action_sequence: List[str]) -> str:\n        # Basic outline: we assume that the bracketing that we get in the RHS of each action is the\n        # correct bracketing for reconstructing the logical form.  This is true when there is no\n        # currying in the action sequence.  Given this assumption, we just need to construct a tree\n        # from the action sequence, then output all of the leaves in the tree, with brackets around\n        # the children of all non-terminal nodes.\n\n        remaining_actions = [action.split(\" -> \") for action in action_sequence]\n        tree = Tree(remaining_actions[0][1], [])\n\n        try:\n            remaining_actions = self._construct_node_from_actions(tree, remaining_actions[1:])\n        except ParsingError:\n            logger.error(\"Error parsing action sequence: %s\", action_sequence)\n            raise\n\n        if remaining_actions:\n            logger.error(\"Error parsing action sequence: %s\", action_sequence)\n            logger.error(\"Remaining actions were: %s\", remaining_actions)\n            raise ParsingError(\"Extra actions in action sequence\")\n        return nltk_tree_to_logical_form(tree)", "response": "Takes an action sequence as produced by logical_form_to_action_sequence and reconstructs the logical form of that tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_predicate(self, name: str, function: Callable, side_arguments: List[str] = None):\n        side_arguments = side_arguments or []\n        signature = inspect.signature(function)\n        argument_types = [param.annotation for name, param in signature.parameters.items()\n                          if name not in side_arguments]\n        return_type = signature.return_annotation\n        argument_nltk_types: List[PredicateType] = [PredicateType.get_type(arg_type)\n                                                    for arg_type in argument_types]\n        return_nltk_type = PredicateType.get_type(return_type)\n        function_nltk_type = PredicateType.get_function_type(argument_nltk_types, return_nltk_type)\n        self._functions[name] = function\n        self._function_types[name].append(function_nltk_type)", "response": "Adds a predicate to the internal dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_constant(self, name: str, value: Any, type_: Type = None):\n        value_type = type_ if type_ else type(value)\n        constant_type = PredicateType.get_type(value_type)\n        self._functions[name] = lambda: value\n        self._function_types[name].append(constant_type)", "response": "Adds a constant to this domain language."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines whether an input symbol is a valid non - terminal in the grammar.", "response": "def is_nonterminal(self, symbol: str) -> bool:\n        \"\"\"\n        Determines whether an input symbol is a valid non-terminal in the grammar.\n        \"\"\"\n        nonterminal_productions = self.get_nonterminal_productions()\n        return symbol in nonterminal_productions"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _execute_expression(self, expression: Any):\n        # pylint: disable=too-many-return-statements\n        if isinstance(expression, list):\n            if isinstance(expression[0], list):\n                function = self._execute_expression(expression[0])\n            elif expression[0] in self._functions:\n                function = self._functions[expression[0]]\n            else:\n                if isinstance(expression[0], str):\n                    raise ExecutionError(f\"Unrecognized function: {expression[0]}\")\n                else:\n                    raise ExecutionError(f\"Unsupported expression type: {expression}\")\n            arguments = [self._execute_expression(arg) for arg in expression[1:]]\n            try:\n                return function(*arguments)\n            except (TypeError, ValueError):\n                traceback.print_exc()\n                raise ExecutionError(f\"Error executing expression {expression} (see stderr for stack trace)\")\n        elif isinstance(expression, str):\n            if expression not in self._functions:\n                raise ExecutionError(f\"Unrecognized constant: {expression}\")\n            # This is a bit of a quirk in how we represent constants and zero-argument functions.\n            # For consistency, constants are wrapped in a zero-argument lambda.  So both constants\n            # and zero-argument functions are callable in `self._functions`, and are `BasicTypes`\n            # in `self._function_types`.  For these, we want to return\n            # `self._functions[expression]()` _calling_ the zero-argument function.  If we get a\n            # `FunctionType` in here, that means we're referring to the function as a first-class\n            # object, instead of calling it (maybe as an argument to a higher-order function).  In\n            # that case, we return the function _without_ calling it.\n            # Also, we just check the first function type here, because we assume you haven't\n            # registered the same function with both a constant type and a `FunctionType`.\n            if isinstance(self._function_types[expression][0], FunctionType):\n                return self._functions[expression]\n            else:\n                return self._functions[expression]()\n            return self._functions[expression]\n        else:\n            raise ExecutionError(\"Not sure how you got here. Please open a github issue with details.\")", "response": "Executes a logical form of expression."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_transitions(self, expression: Any, expected_type: PredicateType) -> Tuple[List[str], PredicateType]:\n        if isinstance(expression, (list, tuple)):\n            function_transitions, return_type, argument_types = self._get_function_transitions(expression[0],\n                                                                                               expected_type)\n            if len(argument_types) != len(expression[1:]):\n                raise ParsingError(f'Wrong number of arguments for function in {expression}')\n            argument_transitions = []\n            for argument_type, subexpression in zip(argument_types, expression[1:]):\n                argument_transitions.extend(self._get_transitions(subexpression, argument_type)[0])\n            return function_transitions + argument_transitions, return_type\n        elif isinstance(expression, str):\n            if expression not in self._functions:\n                raise ParsingError(f\"Unrecognized constant: {expression}\")\n            constant_types = self._function_types[expression]\n            if len(constant_types) == 1:\n                constant_type = constant_types[0]\n                # This constant had only one type; that's the easy case.\n                if expected_type and expected_type != constant_type:\n                    raise ParsingError(f'{expression} did not have expected type {expected_type} '\n                                       f'(found {constant_type})')\n                return [f'{constant_type} -> {expression}'], constant_type\n            else:\n                if not expected_type:\n                    raise ParsingError('With no expected type and multiple types to pick from '\n                                       f\"I don't know what type to use (constant was {expression})\")\n                if expected_type not in constant_types:\n                    raise ParsingError(f'{expression} did not have expected type {expected_type} '\n                                       f'(found these options: {constant_types}; none matched)')\n                return [f'{expected_type} -> {expression}'], expected_type\n\n        else:\n            raise ParsingError('Not sure how you got here. Please open an issue on github with details.')", "response": "This is used when converting a logical form into an action sequence. This is used when converting a logical form into an action sequence. This is used when converting a logical form into an action sequence."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_function_transitions(self,\n                                  expression: Union[str, List],\n                                  expected_type: PredicateType) -> Tuple[List[str],\n                                                                         PredicateType,\n                                                                         List[PredicateType]]:\n        \"\"\"\n        A helper method for ``_get_transitions``.  This gets the transitions for the predicate\n        itself in a function call.  If we only had simple functions (e.g., \"(add 2 3)\"), this would\n        be pretty straightforward and we wouldn't need a separate method to handle it.  We split it\n        out into its own method because handling higher-order functions is complicated (e.g.,\n        something like \"((negate add) 2 3)\").\n        \"\"\"\n        # This first block handles getting the transitions and function type (and some error\n        # checking) _just for the function itself_.  If this is a simple function, this is easy; if\n        # it's a higher-order function, it involves some recursion.\n        if isinstance(expression, list):\n            # This is a higher-order function.  TODO(mattg): we'll just ignore type checking on\n            # higher-order functions, for now.\n            transitions, function_type = self._get_transitions(expression, None)\n        elif expression in self._functions:\n            name = expression\n            function_types = self._function_types[expression]\n            if len(function_types) != 1:\n                raise ParsingError(f\"{expression} had multiple types; this is not yet supported for functions\")\n            function_type = function_types[0]\n            transitions = [f'{function_type} -> {name}']\n        else:\n            if isinstance(expression, str):\n                raise ParsingError(f\"Unrecognized function: {expression[0]}\")\n            else:\n                raise ParsingError(f\"Unsupported expression type: {expression}\")\n        if not isinstance(function_type, FunctionType):\n            raise ParsingError(f'Zero-arg function or constant called with arguments: {name}')\n\n        # Now that we have the transitions for the function itself, and the function's type, we can\n        # get argument types and do the rest of the transitions.\n        argument_types = function_type.argument_types\n        return_type = function_type.return_type\n        right_side = f'[{function_type}, {\", \".join(str(arg) for arg in argument_types)}]'\n        first_transition = f'{return_type} -> {right_side}'\n        transitions.insert(0, first_transition)\n        if expected_type and expected_type != return_type:\n            raise ParsingError(f'{expression} did not have expected type {expected_type} '\n                               f'(found {return_type})')\n        return transitions, return_type, argument_types", "response": "A helper method for _get_transitions."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _construct_node_from_actions(self,\n                                     current_node: Tree,\n                                     remaining_actions: List[List[str]]) -> List[List[str]]:\n        \"\"\"\n        Given a current node in the logical form tree, and a list of actions in an action sequence,\n        this method fills in the children of the current node from the action sequence, then\n        returns whatever actions are left.\n\n        For example, we could get a node with type ``c``, and an action sequence that begins with\n        ``c -> [<r,c>, r]``.  This method will add two children to the input node, consuming\n        actions from the action sequence for nodes of type ``<r,c>`` (and all of its children,\n        recursively) and ``r`` (and all of its children, recursively).  This method assumes that\n        action sequences are produced `depth-first`, so all actions for the subtree under ``<r,c>``\n        appear before actions for the subtree under ``r``.  If there are any actions in the action\n        sequence after the ``<r,c>`` and ``r`` subtrees have terminated in leaf nodes, they will be\n        returned.\n        \"\"\"\n        if not remaining_actions:\n            logger.error(\"No actions left to construct current node: %s\", current_node)\n            raise ParsingError(\"Incomplete action sequence\")\n        left_side, right_side = remaining_actions.pop(0)\n        if left_side != current_node.label():\n            logger.error(\"Current node: %s\", current_node)\n            logger.error(\"Next action: %s -> %s\", left_side, right_side)\n            logger.error(\"Remaining actions were: %s\", remaining_actions)\n            raise ParsingError(\"Current node does not match next action\")\n        if right_side[0] == '[':\n            # This is a non-terminal expansion, with more than one child node.\n            for child_type in right_side[1:-1].split(', '):\n                child_node = Tree(child_type, [])\n                current_node.append(child_node)  # you add a child to an nltk.Tree with `append`\n                # For now, we assume that all children in a list like this are non-terminals, so we\n                # recurse on them.  I'm pretty sure that will always be true for the way our\n                # grammar induction works.  We can revisit this later if we need to.\n                remaining_actions = self._construct_node_from_actions(child_node, remaining_actions)\n        else:\n            # The current node is a pre-terminal; we'll add a single terminal child.  By\n            # construction, the right-hand side of our production rules are only ever terminal\n            # productions or lists of non-terminals.\n            current_node.append(Tree(right_side, []))  # you add a child to an nltk.Tree with `append`\n        return remaining_actions", "response": "This method constructs a node from a list of actions in an action sequence and returns the list of actions that are left in the action sequence."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _choice(num_words: int, num_samples: int) -> Tuple[np.ndarray, int]:\n    num_tries = 0\n    num_chosen = 0\n\n    def get_buffer() -> np.ndarray:\n        log_samples = np.random.rand(num_samples) * np.log(num_words + 1)\n        samples = np.exp(log_samples).astype('int64') - 1\n        return np.clip(samples, a_min=0, a_max=num_words - 1)\n\n    sample_buffer = get_buffer()\n    buffer_index = 0\n    samples: Set[int] = set()\n\n    while num_chosen < num_samples:\n        num_tries += 1\n        # choose sample\n        sample_id = sample_buffer[buffer_index]\n        if sample_id not in samples:\n            samples.add(sample_id)\n            num_chosen += 1\n\n        buffer_index += 1\n        if buffer_index == num_samples:\n            # Reset the buffer\n            sample_buffer = get_buffer()\n            buffer_index = 0\n\n    return np.array(list(samples)), num_tries", "response": "Return a random set of num_samples samples with replacement from [ 0... num_words )."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntaking a list of tokens and converts them to one or more sets of indices.", "response": "def tokens_to_indices(self,\n                          tokens: List[Token],\n                          vocabulary: Vocabulary,\n                          index_name: str) -> Dict[str, List[TokenType]]:\n        \"\"\"\n        Takes a list of tokens and converts them to one or more sets of indices.\n        This could be just an ID for each token from the vocabulary.\n        Or it could split each token into characters and return one ID per character.\n        Or (for instance, in the case of byte-pair encoding) there might not be a clean\n        mapping from individual tokens to indices.\n        \"\"\"\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pad_token_sequence(self,\n                           tokens: Dict[str, List[TokenType]],\n                           desired_num_tokens: Dict[str, int],\n                           padding_lengths: Dict[str, int]) -> Dict[str, List[TokenType]]:\n        \"\"\"\n        This method pads a list of tokens to ``desired_num_tokens`` and returns a padded copy of the\n        input tokens.  If the input token list is longer than ``desired_num_tokens`` then it will be\n        truncated.\n\n        ``padding_lengths`` is used to provide supplemental padding parameters which are needed\n        in some cases.  For example, it contains the widths to pad characters to when doing\n        character-level padding.\n        \"\"\"\n        raise NotImplementedError", "response": "This method pads a list of tokens to desired_num_tokens and returns a padded copy of the input tokens."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\njoining multi - word predicates to a single - word predicate ('V') token.", "response": "def join_mwp(tags: List[str]) -> List[str]:\n    \"\"\"\n    Join multi-word predicates to a single\n    predicate ('V') token.\n    \"\"\"\n    ret = []\n    verb_flag = False\n    for tag in tags:\n        if \"V\" in tag:\n            # Create a continuous 'V' BIO span\n            prefix, _ = tag.split(\"-\")\n            if verb_flag:\n                # Continue a verb label across the different predicate parts\n                prefix = 'I'\n            ret.append(f\"{prefix}-V\")\n            verb_flag = True\n        else:\n            ret.append(tag)\n            verb_flag = False\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a list of model outputs into an inline bracket representation of the prediction.", "response": "def make_oie_string(tokens: List[Token], tags: List[str]) -> str:\n    \"\"\"\n    Converts a list of model outputs (i.e., a list of lists of bio tags, each\n    pertaining to a single word), returns an inline bracket representation of\n    the prediction.\n    \"\"\"\n    frame = []\n    chunk = []\n    words = [token.text for token in tokens]\n\n    for (token, tag) in zip(words, tags):\n        if tag.startswith(\"I-\"):\n            chunk.append(token)\n        else:\n            if chunk:\n                frame.append(\"[\" + \" \".join(chunk) + \"]\")\n                chunk = []\n\n            if tag.startswith(\"B-\"):\n                chunk.append(tag[2:] + \": \" + token)\n            elif tag == \"O\":\n                frame.append(token)\n\n    if chunk:\n        frame.append(\"[\" + \" \".join(chunk) + \"]\")\n\n    return \" \".join(frame)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the word indices of a predicate in BIO tags.", "response": "def get_predicate_indices(tags: List[str]) -> List[int]:\n    \"\"\"\n    Return the word indices of a predicate in BIO tags.\n    \"\"\"\n    return [ind for ind, tag in enumerate(tags) if 'V' in tag]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the predicate in this prediction.", "response": "def get_predicate_text(sent_tokens: List[Token], tags: List[str]) -> str:\n    \"\"\"\n    Get the predicate in this prediction.\n    \"\"\"\n    return \" \".join([sent_tokens[pred_id].text\n                     for pred_id in get_predicate_indices(tags)])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef predicates_overlap(tags1: List[str], tags2: List[str]) -> bool:\n    # Get predicate word indices from both predictions\n    pred_ind1 = get_predicate_indices(tags1)\n    pred_ind2 = get_predicate_indices(tags2)\n\n    # Return if pred_ind1 pred_ind2 overlap\n    return any(set.intersection(set(pred_ind1), set(pred_ind2)))", "response": "Tests whether the predicate in BIO tags1 overlap with those of tags2."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_coherent_next_tag(prev_label: str, cur_label: str) -> str:\n    if cur_label == \"O\":\n        # Don't need to add prefix to an \"O\" label\n        return \"O\"\n\n    if prev_label == cur_label:\n        return f\"I-{cur_label}\"\n    else:\n        return f\"B-{cur_label}\"", "response": "Generate a coherent next tag given previous and current label."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef merge_overlapping_predictions(tags1: List[str], tags2: List[str]) -> List[str]:\n    ret_sequence = []\n    prev_label = \"O\"\n\n    # Build a coherent sequence out of two\n    # spans which predicates' overlap\n\n    for tag1, tag2 in zip(tags1, tags2):\n        label1 = tag1.split(\"-\")[-1]\n        label2 = tag2.split(\"-\")[-1]\n        if (label1 == \"V\") or (label2 == \"V\"):\n            # Construct maximal predicate length -\n            # add predicate tag if any of the sequence predict it\n            cur_label = \"V\"\n\n        # Else - prefer an argument over 'O' label\n        elif label1 != \"O\":\n            cur_label = label1\n        else:\n            cur_label = label2\n\n        # Append cur tag to the returned sequence\n        cur_tag = get_coherent_next_tag(prev_label, cur_label)\n        prev_label = cur_label\n        ret_sequence.append(cur_tag)\n    return ret_sequence", "response": "Merge two predictions into one. Assumes the predicate in tags1 overlap with tags2."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef consolidate_predictions(outputs: List[List[str]], sent_tokens: List[Token]) -> Dict[str, List[str]]:\n    pred_dict: Dict[str, List[str]] = {}\n    merged_outputs = [join_mwp(output) for output in outputs]\n    predicate_texts = [get_predicate_text(sent_tokens, tags)\n                       for tags in merged_outputs]\n\n    for pred1_text, tags1 in zip(predicate_texts, merged_outputs):\n        # A flag indicating whether to add tags1 to predictions\n        add_to_prediction = True\n\n        #  Check if this predicate overlaps another predicate\n        for pred2_text, tags2 in pred_dict.items():\n            if predicates_overlap(tags1, tags2):\n                # tags1 overlaps tags2\n                pred_dict[pred2_text] = merge_overlapping_predictions(tags1, tags2)\n                add_to_prediction = False\n\n        # This predicate doesn't overlap - add as a new predicate\n        if add_to_prediction:\n            pred_dict[pred1_text] = tags1\n\n    return pred_dict", "response": "Combine the prediction and predictions into one single - word predicate."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsanitize a BIO label - this deals with OIE labels sometimes having some noise as parentheses.", "response": "def sanitize_label(label: str) -> str:\n    \"\"\"\n    Sanitize a BIO label - this deals with OIE\n    labels sometimes having some noise, as parentheses.\n    \"\"\"\n    if \"-\" in label:\n        prefix, suffix = label.split(\"-\")\n        suffix = suffix.split(\"(\")[-1]\n        return f\"{prefix}-{suffix}\"\n    else:\n        return label"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a batch of tokenized sentences to a tensor representing the sentences with encoded characters.", "response": "def batch_to_ids(batch: List[List[str]]) -> torch.Tensor:\n    \"\"\"\n    Converts a batch of tokenized sentences to a tensor representing the sentences with encoded characters\n    (len(batch), max sentence length, max word length).\n\n    Parameters\n    ----------\n    batch : ``List[List[str]]``, required\n        A list of tokenized sentences.\n\n    Returns\n    -------\n        A tensor of padded character ids.\n    \"\"\"\n    instances = []\n    indexer = ELMoTokenCharactersIndexer()\n    for sentence in batch:\n        tokens = [Token(token) for token in sentence]\n        field = TextField(tokens,\n                          {'character_ids': indexer})\n        instance = Instance({\"elmo\": field})\n        instances.append(instance)\n\n    dataset = Batch(instances)\n    vocab = Vocabulary()\n    dataset.index_instances(vocab)\n    return dataset.as_tensor_dict()['elmo']['character_ids']"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nforwards computation of the current batch of characters.", "response": "def forward(self,    # pylint: disable=arguments-differ\n                inputs: torch.Tensor,\n                word_inputs: torch.Tensor = None) -> Dict[str, Union[torch.Tensor, List[torch.Tensor]]]:\n        \"\"\"\n        Parameters\n        ----------\n        inputs: ``torch.Tensor``, required.\n        Shape ``(batch_size, timesteps, 50)`` of character ids representing the current batch.\n        word_inputs : ``torch.Tensor``, required.\n            If you passed a cached vocab, you can in addition pass a tensor of shape\n            ``(batch_size, timesteps)``, which represent word ids which have been pre-cached.\n\n        Returns\n        -------\n        Dict with keys:\n        ``'elmo_representations'``: ``List[torch.Tensor]``\n            A ``num_output_representations`` list of ELMo representations for the input sequence.\n            Each representation is shape ``(batch_size, timesteps, embedding_dim)``\n        ``'mask'``:  ``torch.Tensor``\n            Shape ``(batch_size, timesteps)`` long tensor with sequence mask.\n        \"\"\"\n        # reshape the input if needed\n        original_shape = inputs.size()\n        if len(original_shape) > 3:\n            timesteps, num_characters = original_shape[-2:]\n            reshaped_inputs = inputs.view(-1, timesteps, num_characters)\n        else:\n            reshaped_inputs = inputs\n\n        if word_inputs is not None:\n            original_word_size = word_inputs.size()\n            if self._has_cached_vocab and len(original_word_size) > 2:\n                reshaped_word_inputs = word_inputs.view(-1, original_word_size[-1])\n            elif not self._has_cached_vocab:\n                logger.warning(\"Word inputs were passed to ELMo but it does not have a cached vocab.\")\n                reshaped_word_inputs = None\n            else:\n                reshaped_word_inputs = word_inputs\n        else:\n            reshaped_word_inputs = word_inputs\n\n        # run the biLM\n        bilm_output = self._elmo_lstm(reshaped_inputs, reshaped_word_inputs)\n        layer_activations = bilm_output['activations']\n        mask_with_bos_eos = bilm_output['mask']\n\n        # compute the elmo representations\n        representations = []\n        for i in range(len(self._scalar_mixes)):\n            scalar_mix = getattr(self, 'scalar_mix_{}'.format(i))\n            representation_with_bos_eos = scalar_mix(layer_activations, mask_with_bos_eos)\n            if self._keep_sentence_boundaries:\n                processed_representation = representation_with_bos_eos\n                processed_mask = mask_with_bos_eos\n            else:\n                representation_without_bos_eos, mask_without_bos_eos = remove_sentence_boundaries(\n                        representation_with_bos_eos, mask_with_bos_eos)\n                processed_representation = representation_without_bos_eos\n                processed_mask = mask_without_bos_eos\n            representations.append(self._dropout(processed_representation))\n\n        # reshape if necessary\n        if word_inputs is not None and len(original_word_size) > 2:\n            mask = processed_mask.view(original_word_size)\n            elmo_representations = [representation.view(original_word_size + (-1, ))\n                                    for representation in representations]\n        elif len(original_shape) > 3:\n            mask = processed_mask.view(original_shape[:-1])\n            elmo_representations = [representation.view(original_shape[:-1] + (-1, ))\n                                    for representation in representations]\n        else:\n            mask = processed_mask\n            elmo_representations = representations\n\n        return {'elmo_representations': elmo_representations, 'mask': mask}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the forward pass of the context insensitive token embedding for the current batch of characters.", "response": "def forward(self, inputs: torch.Tensor) -> Dict[str, torch.Tensor]:  # pylint: disable=arguments-differ\n        \"\"\"\n        Compute context insensitive token embeddings for ELMo representations.\n\n        Parameters\n        ----------\n        inputs: ``torch.Tensor``\n            Shape ``(batch_size, sequence_length, 50)`` of character ids representing the\n            current batch.\n\n        Returns\n        -------\n        Dict with keys:\n        ``'token_embedding'``: ``torch.Tensor``\n            Shape ``(batch_size, sequence_length + 2, embedding_dim)`` tensor with context\n            insensitive token representations.\n        ``'mask'``:  ``torch.Tensor``\n            Shape ``(batch_size, sequence_length + 2)`` long tensor with sequence mask.\n        \"\"\"\n        # Add BOS/EOS\n        mask = ((inputs > 0).long().sum(dim=-1) > 0).long()\n        character_ids_with_bos_eos, mask_with_bos_eos = add_sentence_boundary_token_ids(\n                inputs,\n                mask,\n                self._beginning_of_sentence_characters,\n                self._end_of_sentence_characters\n        )\n\n        # the character id embedding\n        max_chars_per_token = self._options['char_cnn']['max_characters_per_token']\n        # (batch_size * sequence_length, max_chars_per_token, embed_dim)\n        character_embedding = torch.nn.functional.embedding(\n                character_ids_with_bos_eos.view(-1, max_chars_per_token),\n                self._char_embedding_weights\n        )\n\n        # run convolutions\n        cnn_options = self._options['char_cnn']\n        if cnn_options['activation'] == 'tanh':\n            activation = torch.tanh\n        elif cnn_options['activation'] == 'relu':\n            activation = torch.nn.functional.relu\n        else:\n            raise ConfigurationError(\"Unknown activation\")\n\n        # (batch_size * sequence_length, embed_dim, max_chars_per_token)\n        character_embedding = torch.transpose(character_embedding, 1, 2)\n        convs = []\n        for i in range(len(self._convolutions)):\n            conv = getattr(self, 'char_conv_{}'.format(i))\n            convolved = conv(character_embedding)\n            # (batch_size * sequence_length, n_filters for this width)\n            convolved, _ = torch.max(convolved, dim=-1)\n            convolved = activation(convolved)\n            convs.append(convolved)\n\n        # (batch_size * sequence_length, n_filters)\n        token_embedding = torch.cat(convs, dim=-1)\n\n        # apply the highway layers (batch_size * sequence_length, n_filters)\n        token_embedding = self._highways(token_embedding)\n\n        # final projection  (batch_size * sequence_length, embedding_dim)\n        token_embedding = self._projection(token_embedding)\n\n        # reshape to (batch_size, sequence_length, embedding_dim)\n        batch_size, sequence_length, _ = character_ids_with_bos_eos.size()\n\n        return {\n                'mask': mask_with_bos_eos,\n                'token_embedding': token_embedding.view(batch_size, sequence_length, -1)\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef forward(self,  # pylint: disable=arguments-differ\n                inputs: torch.Tensor,\n                word_inputs: torch.Tensor = None) -> Dict[str, Union[torch.Tensor, List[torch.Tensor]]]:\n        \"\"\"\n        Parameters\n        ----------\n        inputs: ``torch.Tensor``, required.\n            Shape ``(batch_size, timesteps, 50)`` of character ids representing the current batch.\n        word_inputs : ``torch.Tensor``, required.\n            If you passed a cached vocab, you can in addition pass a tensor of shape ``(batch_size, timesteps)``,\n            which represent word ids which have been pre-cached.\n\n        Returns\n        -------\n        Dict with keys:\n\n        ``'activations'``: ``List[torch.Tensor]``\n            A list of activations at each layer of the network, each of shape\n            ``(batch_size, timesteps + 2, embedding_dim)``\n        ``'mask'``:  ``torch.Tensor``\n            Shape ``(batch_size, timesteps + 2)`` long tensor with sequence mask.\n\n        Note that the output tensors all include additional special begin and end of sequence\n        markers.\n        \"\"\"\n        if self._word_embedding is not None and word_inputs is not None:\n            try:\n                mask_without_bos_eos = (word_inputs > 0).long()\n                # The character cnn part is cached - just look it up.\n                embedded_inputs = self._word_embedding(word_inputs) # type: ignore\n                # shape (batch_size, timesteps + 2, embedding_dim)\n                type_representation, mask = add_sentence_boundary_token_ids(\n                        embedded_inputs,\n                        mask_without_bos_eos,\n                        self._bos_embedding,\n                        self._eos_embedding\n                )\n            except RuntimeError:\n                # Back off to running the character convolutions,\n                # as we might not have the words in the cache.\n                token_embedding = self._token_embedder(inputs)\n                mask = token_embedding['mask']\n                type_representation = token_embedding['token_embedding']\n        else:\n            token_embedding = self._token_embedder(inputs)\n            mask = token_embedding['mask']\n            type_representation = token_embedding['token_embedding']\n        lstm_outputs = self._elmo_lstm(type_representation, mask)\n\n        # Prepare the output.  The first layer is duplicated.\n        # Because of minor differences in how masking is applied depending\n        # on whether the char cnn layers are cached, we'll be defensive and\n        # multiply by the mask here. It's not strictly necessary, as the\n        # mask passed on is correct, but the values in the padded areas\n        # of the char cnn representations can change.\n        output_tensors = [\n                torch.cat([type_representation, type_representation], dim=-1) * mask.float().unsqueeze(-1)\n        ]\n        for layer_activations in torch.chunk(lstm_outputs, lstm_outputs.size(0), dim=0):\n            output_tensors.append(layer_activations.squeeze(0))\n\n        return {\n                'activations': output_tensors,\n                'mask': mask,\n        }", "response": "Forward computation of the current character set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_cached_cnn_embeddings(self, tokens: List[str]) -> None:\n        tokens = [ELMoCharacterMapper.bos_token, ELMoCharacterMapper.eos_token] + tokens\n        timesteps = 32\n        batch_size = 32\n        chunked_tokens = lazy_groups_of(iter(tokens), timesteps)\n\n        all_embeddings = []\n        device = get_device_of(next(self.parameters()))\n        for batch in lazy_groups_of(chunked_tokens, batch_size):\n            # Shape (batch_size, timesteps, 50)\n            batched_tensor = batch_to_ids(batch)\n            # NOTE: This device check is for when a user calls this method having\n            # already placed the model on a device. If this is called in the\n            # constructor, it will probably happen on the CPU. This isn't too bad,\n            # because it's only a few convolutions and will likely be very fast.\n            if device >= 0:\n                batched_tensor = batched_tensor.cuda(device)\n            output = self._token_embedder(batched_tensor)\n            token_embedding = output[\"token_embedding\"]\n            mask = output[\"mask\"]\n            token_embedding, _ = remove_sentence_boundaries(token_embedding, mask)\n            all_embeddings.append(token_embedding.view(-1, token_embedding.size(-1)))\n        full_embedding = torch.cat(all_embeddings, 0)\n\n        # We might have some trailing embeddings from padding in the batch, so\n        # we clip the embedding and lookup to the right size.\n        full_embedding = full_embedding[:len(tokens), :]\n        embedding = full_embedding[2:len(tokens), :]\n        vocab_size, embedding_dim = list(embedding.size())\n\n        from allennlp.modules.token_embedders import Embedding # type: ignore\n        self._bos_embedding = full_embedding[0, :]\n        self._eos_embedding = full_embedding[1, :]\n        self._word_embedding = Embedding(vocab_size, # type: ignore\n                                         embedding_dim,\n                                         weight=embedding.data,\n                                         trainable=self._requires_grad,\n                                         padding_index=0)", "response": "Creates the word embedding tensors for each token in the list of tokens."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nnormalize the given text to be a more efficient form.", "response": "def normalize_text(text: str) -> str:\n    \"\"\"\n    Performs a normalization that is very similar to that done by the normalization functions in\n    SQuAD and TriviaQA.\n\n    This involves splitting and rejoining the text, and could be a somewhat expensive operation.\n    \"\"\"\n    return ' '.join([token\n                     for token in text.lower().strip(STRIPPED_CHARACTERS).split()\n                     if token not in IGNORED_TOKENS])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a character span into a token span in the tokenized version.", "response": "def char_span_to_token_span(token_offsets: List[Tuple[int, int]],\n                            character_span: Tuple[int, int]) -> Tuple[Tuple[int, int], bool]:\n    \"\"\"\n    Converts a character span from a passage into the corresponding token span in the tokenized\n    version of the passage.  If you pass in a character span that does not correspond to complete\n    tokens in the tokenized version, we'll do our best, but the behavior is officially undefined.\n    We return an error flag in this case, and have some debug logging so you can figure out the\n    cause of this issue (in SQuAD, these are mostly either tokenization problems or annotation\n    problems; there's a fair amount of both).\n\n    The basic outline of this method is to find the token span that has the same offsets as the\n    input character span.  If the tokenizer tokenized the passage correctly and has matching\n    offsets, this is easy.  We try to be a little smart about cases where they don't match exactly,\n    but mostly just find the closest thing we can.\n\n    The returned ``(begin, end)`` indices are `inclusive` for both ``begin`` and ``end``.\n    So, for example, ``(2, 2)`` is the one word span beginning at token index 2, ``(3, 4)`` is the\n    two-word span beginning at token index 3, and so on.\n\n    Returns\n    -------\n    token_span : ``Tuple[int, int]``\n        `Inclusive` span start and end token indices that match as closely as possible to the input\n        character spans.\n    error : ``bool``\n        Whether the token spans match the input character spans exactly.  If this is ``False``, it\n        means there was an error in either the tokenization or the annotated character span.\n    \"\"\"\n    # We have token offsets into the passage from the tokenizer; we _should_ be able to just find\n    # the tokens that have the same offsets as our span.\n    error = False\n    start_index = 0\n    while start_index < len(token_offsets) and token_offsets[start_index][0] < character_span[0]:\n        start_index += 1\n    # start_index should now be pointing at the span start index.\n    if token_offsets[start_index][0] > character_span[0]:\n        # In this case, a tokenization or labeling issue made us go too far - the character span\n        # we're looking for actually starts in the previous token.  We'll back up one.\n        logger.debug(\"Bad labelling or tokenization - start offset doesn't match\")\n        start_index -= 1\n    if token_offsets[start_index][0] != character_span[0]:\n        error = True\n    end_index = start_index\n    while end_index < len(token_offsets) and token_offsets[end_index][1] < character_span[1]:\n        end_index += 1\n    if end_index == start_index and token_offsets[end_index][1] > character_span[1]:\n        # Looks like there was a token that should have been split, like \"1854-1855\", where the\n        # answer is \"1854\".  We can't do much in this case, except keep the answer as the whole\n        # token.\n        logger.debug(\"Bad tokenization - end offset doesn't match\")\n    elif token_offsets[end_index][1] > character_span[1]:\n        # This is a case where the given answer span is more than one token, and the last token is\n        # cut off for some reason, like \"split with Luckett and Rober\", when the original passage\n        # said \"split with Luckett and Roberson\".  In this case, we'll just keep the end index\n        # where it is, and assume the intent was to mark the whole token.\n        logger.debug(\"Bad labelling or tokenization - end offset doesn't match\")\n    if token_offsets[end_index][1] != character_span[1]:\n        error = True\n    return (start_index, end_index), error"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind a list of token spans in passage_tokens that match the given answer_texts.", "response": "def find_valid_answer_spans(passage_tokens: List[Token],\n                            answer_texts: List[str]) -> List[Tuple[int, int]]:\n    \"\"\"\n    Finds a list of token spans in ``passage_tokens`` that match the given ``answer_texts``.  This\n    tries to find all spans that would evaluate to correct given the SQuAD and TriviaQA official\n    evaluation scripts, which do some normalization of the input text.\n\n    Note that this could return duplicate spans!  The caller is expected to be able to handle\n    possible duplicates (as already happens in the SQuAD dev set, for instance).\n    \"\"\"\n    normalized_tokens = [token.text.lower().strip(STRIPPED_CHARACTERS) for token in passage_tokens]\n    # Because there could be many `answer_texts`, we'll do the most expensive pre-processing\n    # step once.  This gives us a map from tokens to the position in the passage they appear.\n    word_positions: Dict[str, List[int]] = defaultdict(list)\n    for i, token in enumerate(normalized_tokens):\n        word_positions[token].append(i)\n    spans = []\n    for answer_text in answer_texts:\n        # For each answer, we'll first find all valid start positions in the passage.  Then\n        # we'll grow each span to the same length as the number of answer tokens, and see if we\n        # have a match.  We're a little tricky as we grow the span, skipping words that are\n        # already pruned from the normalized answer text, and stopping early if we don't match.\n        answer_tokens = answer_text.lower().strip(STRIPPED_CHARACTERS).split()\n        num_answer_tokens = len(answer_tokens)\n        for span_start in word_positions[answer_tokens[0]]:\n            span_end = span_start  # span_end is _inclusive_\n            answer_index = 1\n            while answer_index < num_answer_tokens and span_end + 1 < len(normalized_tokens):\n                token = normalized_tokens[span_end + 1]\n                if answer_tokens[answer_index] == token:\n                    answer_index += 1\n                    span_end += 1\n                elif token in IGNORED_TOKENS:\n                    span_end += 1\n                else:\n                    break\n            if num_answer_tokens == answer_index:\n                spans.append((span_start, span_end))\n    return spans"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a list of tokens into a reading comprehension instance.", "response": "def make_reading_comprehension_instance(question_tokens: List[Token],\n                                        passage_tokens: List[Token],\n                                        token_indexers: Dict[str, TokenIndexer],\n                                        passage_text: str,\n                                        token_spans: List[Tuple[int, int]] = None,\n                                        answer_texts: List[str] = None,\n                                        additional_metadata: Dict[str, Any] = None) -> Instance:\n    \"\"\"\n    Converts a question, a passage, and an optional answer (or answers) to an ``Instance`` for use\n    in a reading comprehension model.\n\n    Creates an ``Instance`` with at least these fields: ``question`` and ``passage``, both\n    ``TextFields``; and ``metadata``, a ``MetadataField``.  Additionally, if both ``answer_texts``\n    and ``char_span_starts`` are given, the ``Instance`` has ``span_start`` and ``span_end``\n    fields, which are both ``IndexFields``.\n\n    Parameters\n    ----------\n    question_tokens : ``List[Token]``\n        An already-tokenized question.\n    passage_tokens : ``List[Token]``\n        An already-tokenized passage that contains the answer to the given question.\n    token_indexers : ``Dict[str, TokenIndexer]``\n        Determines how the question and passage ``TextFields`` will be converted into tensors that\n        get input to a model.  See :class:`TokenIndexer`.\n    passage_text : ``str``\n        The original passage text.  We need this so that we can recover the actual span from the\n        original passage that the model predicts as the answer to the question.  This is used in\n        official evaluation scripts.\n    token_spans : ``List[Tuple[int, int]]``, optional\n        Indices into ``passage_tokens`` to use as the answer to the question for training.  This is\n        a list because there might be several possible correct answer spans in the passage.\n        Currently, we just select the most frequent span in this list (i.e., SQuAD has multiple\n        annotations on the dev set; this will select the span that the most annotators gave as\n        correct).\n    answer_texts : ``List[str]``, optional\n        All valid answer strings for the given question.  In SQuAD, e.g., the training set has\n        exactly one answer per question, but the dev and test sets have several.  TriviaQA has many\n        possible answers, which are the aliases for the known correct entity.  This is put into the\n        metadata for use with official evaluation scripts, but not used anywhere else.\n    additional_metadata : ``Dict[str, Any]``, optional\n        The constructed ``metadata`` field will by default contain ``original_passage``,\n        ``token_offsets``, ``question_tokens``, ``passage_tokens``, and ``answer_texts`` keys.  If\n        you want any other metadata to be associated with each instance, you can pass that in here.\n        This dictionary will get added to the ``metadata`` dictionary we already construct.\n    \"\"\"\n    additional_metadata = additional_metadata or {}\n    fields: Dict[str, Field] = {}\n    passage_offsets = [(token.idx, token.idx + len(token.text)) for token in passage_tokens]\n\n    # This is separate so we can reference it later with a known type.\n    passage_field = TextField(passage_tokens, token_indexers)\n    fields['passage'] = passage_field\n    fields['question'] = TextField(question_tokens, token_indexers)\n    metadata = {'original_passage': passage_text, 'token_offsets': passage_offsets,\n                'question_tokens': [token.text for token in question_tokens],\n                'passage_tokens': [token.text for token in passage_tokens], }\n    if answer_texts:\n        metadata['answer_texts'] = answer_texts\n\n    if token_spans:\n        # There may be multiple answer annotations, so we pick the one that occurs the most.  This\n        # only matters on the SQuAD dev set, and it means our computed metrics (\"start_acc\",\n        # \"end_acc\", and \"span_acc\") aren't quite the same as the official metrics, which look at\n        # all of the annotations.  This is why we have a separate official SQuAD metric calculation\n        # (the \"em\" and \"f1\" metrics use the official script).\n        candidate_answers: Counter = Counter()\n        for span_start, span_end in token_spans:\n            candidate_answers[(span_start, span_end)] += 1\n        span_start, span_end = candidate_answers.most_common(1)[0][0]\n\n        fields['span_start'] = IndexField(span_start, passage_field)\n        fields['span_end'] = IndexField(span_end, passage_field)\n\n    metadata.update(additional_metadata)\n    fields['metadata'] = MetadataField(metadata)\n    return Instance(fields)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_reading_comprehension_instance_quac(question_list_tokens: List[List[Token]],\n                                             passage_tokens: List[Token],\n                                             token_indexers: Dict[str, TokenIndexer],\n                                             passage_text: str,\n                                             token_span_lists: List[List[Tuple[int, int]]] = None,\n                                             yesno_list: List[int] = None,\n                                             followup_list: List[int] = None,\n                                             additional_metadata: Dict[str, Any] = None,\n                                             num_context_answers: int = 0) -> Instance:\n    \"\"\"\n    Converts a question, a passage, and an optional answer (or answers) to an ``Instance`` for use\n    in a reading comprehension model.\n\n    Creates an ``Instance`` with at least these fields: ``question`` and ``passage``, both\n    ``TextFields``; and ``metadata``, a ``MetadataField``.  Additionally, if both ``answer_texts``\n    and ``char_span_starts`` are given, the ``Instance`` has ``span_start`` and ``span_end``\n    fields, which are both ``IndexFields``.\n\n    Parameters\n    ----------\n    question_list_tokens : ``List[List[Token]]``\n        An already-tokenized list of questions. Each dialog have multiple questions.\n    passage_tokens : ``List[Token]``\n        An already-tokenized passage that contains the answer to the given question.\n    token_indexers : ``Dict[str, TokenIndexer]``\n        Determines how the question and passage ``TextFields`` will be converted into tensors that\n        get input to a model.  See :class:`TokenIndexer`.\n    passage_text : ``str``\n        The original passage text.  We need this so that we can recover the actual span from the\n        original passage that the model predicts as the answer to the question.  This is used in\n        official evaluation scripts.\n    token_span_lists : ``List[List[Tuple[int, int]]]``, optional\n        Indices into ``passage_tokens`` to use as the answer to the question for training.  This is\n        a list of list, first because there is multiple questions per dialog, and\n        because there might be several possible correct answer spans in the passage.\n        Currently, we just select the last span in this list (i.e., QuAC has multiple\n        annotations on the dev set; this will select the last span, which was given by the original annotator).\n    yesno_list : ``List[int]``\n        List of the affirmation bit for each question answer pairs.\n    followup_list : ``List[int]``\n        List of the continuation bit for each question answer pairs.\n    num_context_answers : ``int``, optional\n        How many answers to encode into the passage.\n    additional_metadata : ``Dict[str, Any]``, optional\n        The constructed ``metadata`` field will by default contain ``original_passage``,\n        ``token_offsets``, ``question_tokens``, ``passage_tokens``, and ``answer_texts`` keys.  If\n        you want any other metadata to be associated with each instance, you can pass that in here.\n        This dictionary will get added to the ``metadata`` dictionary we already construct.\n    \"\"\"\n    additional_metadata = additional_metadata or {}\n    fields: Dict[str, Field] = {}\n    passage_offsets = [(token.idx, token.idx + len(token.text)) for token in passage_tokens]\n    # This is separate so we can reference it later with a known type.\n    passage_field = TextField(passage_tokens, token_indexers)\n    fields['passage'] = passage_field\n    fields['question'] = ListField([TextField(q_tokens, token_indexers) for q_tokens in question_list_tokens])\n    metadata = {'original_passage': passage_text,\n                'token_offsets': passage_offsets,\n                'question_tokens': [[token.text for token in question_tokens] \\\n                                    for question_tokens in question_list_tokens],\n                'passage_tokens': [token.text for token in passage_tokens], }\n    p1_answer_marker_list: List[Field] = []\n    p2_answer_marker_list: List[Field] = []\n    p3_answer_marker_list: List[Field] = []\n\n    def get_tag(i, i_name):\n        # Generate a tag to mark previous answer span in the passage.\n        return \"<{0:d}_{1:s}>\".format(i, i_name)\n\n    def mark_tag(span_start, span_end, passage_tags, prev_answer_distance):\n        try:\n            assert span_start >= 0\n            assert span_end >= 0\n        except:\n            raise ValueError(\"Previous {0:d}th answer span should have been updated!\".format(prev_answer_distance))\n        # Modify \"tags\" to mark previous answer span.\n        if span_start == span_end:\n            passage_tags[prev_answer_distance][span_start] = get_tag(prev_answer_distance, \"\")\n        else:\n            passage_tags[prev_answer_distance][span_start] = get_tag(prev_answer_distance, \"start\")\n            passage_tags[prev_answer_distance][span_end] = get_tag(prev_answer_distance, \"end\")\n            for passage_index in range(span_start + 1, span_end):\n                passage_tags[prev_answer_distance][passage_index] = get_tag(prev_answer_distance, \"in\")\n\n    if token_span_lists:\n        span_start_list: List[Field] = []\n        span_end_list: List[Field] = []\n        p1_span_start, p1_span_end, p2_span_start = -1, -1, -1\n        p2_span_end, p3_span_start, p3_span_end = -1, -1, -1\n        # Looping each <<answers>>.\n        for question_index, answer_span_lists in enumerate(token_span_lists):\n            span_start, span_end = answer_span_lists[-1]  # Last one is the original answer\n            span_start_list.append(IndexField(span_start, passage_field))\n            span_end_list.append(IndexField(span_end, passage_field))\n            prev_answer_marker_lists = [[\"O\"] * len(passage_tokens), [\"O\"] * len(passage_tokens),\n                                        [\"O\"] * len(passage_tokens), [\"O\"] * len(passage_tokens)]\n            if question_index > 0 and num_context_answers > 0:\n                mark_tag(p1_span_start, p1_span_end, prev_answer_marker_lists, 1)\n                if question_index > 1 and num_context_answers > 1:\n                    mark_tag(p2_span_start, p2_span_end, prev_answer_marker_lists, 2)\n                    if question_index > 2 and num_context_answers > 2:\n                        mark_tag(p3_span_start, p3_span_end, prev_answer_marker_lists, 3)\n                    p3_span_start = p2_span_start\n                    p3_span_end = p2_span_end\n                p2_span_start = p1_span_start\n                p2_span_end = p1_span_end\n            p1_span_start = span_start\n            p1_span_end = span_end\n            if num_context_answers > 2:\n                p3_answer_marker_list.append(SequenceLabelField(prev_answer_marker_lists[3],\n                                                                passage_field,\n                                                                label_namespace=\"answer_tags\"))\n            if num_context_answers > 1:\n                p2_answer_marker_list.append(SequenceLabelField(prev_answer_marker_lists[2],\n                                                                passage_field,\n                                                                label_namespace=\"answer_tags\"))\n            if num_context_answers > 0:\n                p1_answer_marker_list.append(SequenceLabelField(prev_answer_marker_lists[1],\n                                                                passage_field,\n                                                                label_namespace=\"answer_tags\"))\n        fields['span_start'] = ListField(span_start_list)\n        fields['span_end'] = ListField(span_end_list)\n        if num_context_answers > 0:\n            fields['p1_answer_marker'] = ListField(p1_answer_marker_list)\n            if num_context_answers > 1:\n                fields['p2_answer_marker'] = ListField(p2_answer_marker_list)\n                if num_context_answers > 2:\n                    fields['p3_answer_marker'] = ListField(p3_answer_marker_list)\n        fields['yesno_list'] = ListField( \\\n            [LabelField(yesno, label_namespace=\"yesno_labels\") for yesno in yesno_list])\n        fields['followup_list'] = ListField([LabelField(followup, label_namespace=\"followup_labels\") \\\n                                             for followup in followup_list])\n    metadata.update(additional_metadata)\n    fields['metadata'] = MetadataField(metadata)\n    return Instance(fields)", "response": "Creates a reading comprehension instance from a list of questions passages and answers."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle_cannot(reference_answers: List[str]):\n    num_cannot = 0\n    num_spans = 0\n    for ref in reference_answers:\n        if ref == 'CANNOTANSWER':\n            num_cannot += 1\n        else:\n            num_spans += 1\n    if num_cannot >= num_spans:\n        reference_answers = ['CANNOTANSWER']\n    else:\n        reference_answers = [x for x in reference_answers if x != 'CANNOTANSWER']\n    return reference_answers", "response": "Process a list of reference answers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef constrained_to(self, initial_sequence: torch.Tensor, keep_beam_details: bool = True) -> 'BeamSearch':\n        return BeamSearch(self._beam_size, self._per_node_beam_size, initial_sequence, keep_beam_details)", "response": "Returns a new instance that s like this one but with the specified constraint."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching for a specific state in the cluster.", "response": "def search(self,\n               num_steps: int,\n               initial_state: StateType,\n               transition_function: TransitionFunction,\n               keep_final_unfinished_states: bool = True) -> Dict[int, List[StateType]]:\n        \"\"\"\n        Parameters\n        ----------\n        num_steps : ``int``\n            How many steps should we take in our search?  This is an upper bound, as it's possible\n            for the search to run out of valid actions before hitting this number, or for all\n            states on the beam to finish.\n        initial_state : ``StateType``\n            The starting state of our search.  This is assumed to be `batched`, and our beam search\n            is batch-aware - we'll keep ``beam_size`` states around for each instance in the batch.\n        transition_function : ``TransitionFunction``\n            The ``TransitionFunction`` object that defines and scores transitions from one state to the\n            next.\n        keep_final_unfinished_states : ``bool``, optional (default=True)\n            If we run out of steps before a state is \"finished\", should we return that state in our\n            search results?\n\n        Returns\n        -------\n        best_states : ``Dict[int, List[StateType]]``\n            This is a mapping from batch index to the top states for that instance.\n        \"\"\"\n        finished_states: Dict[int, List[StateType]] = defaultdict(list)\n        states = [initial_state]\n        step_num = 1\n\n        # Erase stored beams, if we're tracking them.\n        if self.beam_snapshots is not None:\n            self.beam_snapshots = defaultdict(list)\n\n        while states and step_num <= num_steps:\n            next_states: Dict[int, List[StateType]] = defaultdict(list)\n            grouped_state = states[0].combine_states(states)\n\n            if self._allowed_transitions:\n                # We were provided an initial sequence, so we need to check\n                # if the current sequence is still constrained.\n                key = tuple(grouped_state.action_history[0])\n                if key in self._allowed_transitions:\n                    # We're still in the initial_sequence, so our hand is forced.\n                    allowed_actions = [self._allowed_transitions[key]]\n                else:\n                    # We've gone past the end of the initial sequence, so no constraint.\n                    allowed_actions = None\n            else:\n                # No initial sequence was provided, so all actions are allowed.\n                allowed_actions = None\n\n            for next_state in transition_function.take_step(grouped_state,\n                                                            max_actions=self._per_node_beam_size,\n                                                            allowed_actions=allowed_actions):\n                # NOTE: we're doing state.batch_indices[0] here (and similar things below),\n                # hard-coding a group size of 1.  But, our use of `next_state.is_finished()`\n                # already checks for that, as it crashes if the group size is not 1.\n                batch_index = next_state.batch_indices[0]\n                if next_state.is_finished():\n                    finished_states[batch_index].append(next_state)\n                else:\n                    if step_num == num_steps and keep_final_unfinished_states:\n                        finished_states[batch_index].append(next_state)\n                    next_states[batch_index].append(next_state)\n            states = []\n            for batch_index, batch_states in next_states.items():\n                # The states from the generator are already sorted, so we can just take the first\n                # ones here, without an additional sort.\n                states.extend(batch_states[:self._beam_size])\n\n                if self.beam_snapshots is not None:\n                    # Add to beams\n                    self.beam_snapshots[batch_index].append(\n                            [(state.score[0].item(), state.action_history[0])\n                             for state in batch_states]\n                    )\n            step_num += 1\n\n        # Add finished states to the stored beams as well.\n        if self.beam_snapshots is not None:\n            for batch_index, states in finished_states.items():\n                for state in states:\n                    score = state.score[0].item()\n                    action_history = state.action_history[0]\n\n                    while len(self.beam_snapshots[batch_index]) < len(action_history):\n                        self.beam_snapshots[batch_index].append([])\n\n                    self.beam_snapshots[batch_index][len(action_history) - 1].append((score, action_history))\n\n        best_states: Dict[int, List[StateType]] = {}\n        for batch_index, batch_states in finished_states.items():\n            # The time this sort takes is pretty negligible, no particular need to optimize this\n            # yet.  Maybe with a larger beam size...\n            finished_to_sort = [(-state.score[0].item(), state) for state in batch_states]\n            finished_to_sort.sort(key=lambda x: x[0])\n            best_states[batch_index] = [state[1] for state in finished_to_sort[:self._beam_size]]\n        return best_states"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _normalize_answer(text: str) -> str:\n\n    parts = [_white_space_fix(_remove_articles(_normalize_number(_remove_punc(_lower(token)))))\n             for token in _tokenize(text)]\n    parts = [part for part in parts if part.strip()]\n    normalized = ' '.join(parts).strip()\n    return normalized", "response": "Lower text and remove punctuation articles and extra whitespace."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _align_bags(predicted: List[Set[str]], gold: List[Set[str]]) -> List[float]:\n    f1_scores = []\n    for gold_index, gold_item in enumerate(gold):\n        max_f1 = 0.0\n        max_index = None\n        best_alignment: Tuple[Set[str], Set[str]] = (set(), set())\n        if predicted:\n            for pred_index, pred_item in enumerate(predicted):\n                current_f1 = _compute_f1(pred_item, gold_item)\n                if current_f1 >= max_f1:\n                    best_alignment = (gold_item, pred_item)\n                    max_f1 = current_f1\n                    max_index = pred_index\n            match_flag = _match_numbers_if_present(*best_alignment)\n            gold[gold_index] = set()\n            predicted[max_index] = set()\n        else:\n            match_flag = False\n        if match_flag:\n            f1_scores.append(max_f1)\n        else:\n            f1_scores.append(0.0)\n    return f1_scores", "response": "Given gold and predicted answer sets returns a list of scores that are the maximum metric values over all the answers\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the metrics for the prediction and the DROP F1 metric for the gold answer.", "response": "def get_metrics(predicted: Union[str, List[str], Tuple[str, ...]],\n                gold: Union[str, List[str], Tuple[str, ...]]) -> Tuple[float, float]:\n    \"\"\"\n    Takes a predicted answer and a gold answer (that are both either a string or a list of\n    strings), and returns exact match and the DROP F1 metric for the prediction.  If you are\n    writing a script for evaluating objects in memory (say, the output of predictions during\n    validation, or while training), this is the function you want to call, after using\n    :func:`answer_json_to_strings` when reading the gold answer from the released data file.\n    \"\"\"\n    predicted_bags = _answer_to_bags(predicted)\n    gold_bags = _answer_to_bags(gold)\n\n    exact_match = 1.0 if predicted_bags[0] == gold_bags[0] else 0\n\n    f1_per_bag = _align_bags(predicted_bags[1], gold_bags[1])\n    f1 = np.mean(f1_per_bag)\n    f1 = round(f1, 2)\n    return exact_match, f1"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef answer_json_to_strings(answer: Dict[str, Any]) -> Tuple[Tuple[str, ...], str]:\n    if \"number\" in answer and answer[\"number\"]:\n        return tuple([str(answer[\"number\"])]), \"number\"\n    elif \"spans\" in answer and answer[\"spans\"]:\n        return tuple(answer[\"spans\"]), \"span\" if len(answer[\"spans\"]) == 1 else \"spans\"\n    elif \"date\" in answer:\n        return tuple([\"{0} {1} {2}\".format(answer[\"date\"][\"day\"],\n                                           answer[\"date\"][\"month\"],\n                                           answer[\"date\"][\"year\"])]), \"date\"\n    else:\n        raise ValueError(f\"Answer type not found, should be one of number, spans or date at: {json.dumps(answer)}\")", "response": "Takes an answer JSON blob from the DROP data release and converts it into a list of strings used for evaluation."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nevaluates the JSON for each question in the gold annotations and predicted answers and returns the predicted answer and the best answer for each question in the gold annotations.", "response": "def evaluate_json(annotations: Dict[str, Any], predicted_answers: Dict[str, Any]) -> Tuple[float, float]:\n    \"\"\"\n    Takes gold annotations and predicted answers and  evaluates the predictions for each question\n    in the gold annotations.  Both JSON dictionaries must have query_id keys, which are used to\n    match predictions to gold annotations (note that these are somewhat deep in the JSON for the\n    gold annotations, but must be top-level keys in the predicted answers).\n\n    The ``annotations`` are assumed to have the format of the dev set in the DROP data release.\n    The ``predicted_answers`` JSON must be a dictionary keyed by query id, where the value is a string\n    (or list of strings) that is the answer.\n    \"\"\"\n    instance_exact_match = []\n    instance_f1 = []\n    # for each type as well\n    type_to_em: Dict[str, List[float]] = defaultdict(list)\n    type_to_f1: Dict[str, List[float]] = defaultdict(list)\n    for _, annotation in annotations.items():\n        for qa_pair in annotation[\"qa_pairs\"]:\n            query_id = qa_pair[\"query_id\"]\n            max_em_score = 0.0\n            max_f1_score = 0.0\n            max_type = None\n            if query_id in predicted_answers:\n                predicted = predicted_answers[query_id]\n                candidate_answers = [qa_pair[\"answer\"]]\n                if \"validated_answers\" in qa_pair and qa_pair[\"validated_answers\"]:\n                    candidate_answers += qa_pair[\"validated_answers\"]\n                for answer in candidate_answers:\n                    gold_answer, gold_type = answer_json_to_strings(answer)\n                    em_score, f1_score = get_metrics(predicted, gold_answer)\n                    if gold_answer[0].strip() != \"\":\n                        max_em_score = max(max_em_score, em_score)\n                        max_f1_score = max(max_f1_score, f1_score)\n                        if max_em_score == em_score or max_f1_score == f1_score:\n                            max_type = gold_type\n            else:\n                print(\"Missing prediction for question: {}\".format(query_id))\n                if qa_pair and qa_pair[\"answer\"]:\n                    max_type = answer_json_to_strings(qa_pair[\"answer\"])[1]\n                else:\n                    max_type = \"number\"\n                max_em_score = 0.0\n                max_f1_score = 0.0\n        instance_exact_match.append(max_em_score)\n        instance_f1.append(max_f1_score)\n        type_to_em[max_type].append(max_em_score)\n        type_to_f1[max_type].append(max_f1_score)\n\n    global_em = np.mean(instance_exact_match)\n    global_f1 = np.mean(instance_f1)\n    print(\"Exact-match accuracy {0:.2f}\".format(global_em * 100))\n    print(\"F1 score {0:.2f}\".format(global_f1 * 100))\n    print(\"{0:.2f}   &   {1:.2f}\".format(global_em * 100, global_f1 * 100))\n    print(\"----\")\n    total = np.sum([len(v) for v in type_to_em.values()])\n    for typ in sorted(type_to_em.keys()):\n        print(\"{0}: {1} ({2:.2f}%)\".format(typ, len(type_to_em[typ]), 100. * len(type_to_em[typ])/total))\n        print(\"  Exact-match accuracy {0:.3f}\".format(100. * np.mean(type_to_em[typ])))\n        print(\"  F1 score {0:.3f}\".format(100. * np.mean(type_to_f1[typ])))\n    return global_em, global_f1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntake a prediction file and a gold file and evaluates the predictions for each question in the .", "response": "def evaluate_prediction_file(prediction_path: str, gold_path: str) -> Tuple[float, float]:\n    \"\"\"\n    Takes a prediction file and a gold file and evaluates the predictions for each question in the\n    gold file.  Both files must be json formatted and must have query_id keys, which are used to\n    match predictions to gold annotations.  The gold file is assumed to have the format of the dev\n    set in the DROP data release.  The prediction file must be a JSON dictionary keyed by query id,\n    where the value is either a JSON dictionary with an \"answer\" key, or just a string (or list of\n    strings) that is the answer.\n    \"\"\"\n    predicted_answers = json.load(open(prediction_path, encoding='utf-8'))\n    annotations = json.load(open(gold_path, encoding='utf-8'))\n    return evaluate_json(annotations, predicted_answers)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read(self, file_path: str) -> Iterable[Instance]:\n        lazy = getattr(self, 'lazy', None)\n\n        if lazy is None:\n            logger.warning(\"DatasetReader.lazy is not set, \"\n                           \"did you forget to call the superclass constructor?\")\n\n        if self._cache_directory:\n            cache_file = self._get_cache_location_for_file_path(file_path)\n        else:\n            cache_file = None\n\n        if lazy:\n            return _LazyInstances(lambda: self._read(file_path),\n                                  cache_file,\n                                  self.deserialize_instance,\n                                  self.serialize_instance)\n        else:\n            # First we read the instances, either from a cache or from the original file.\n            if cache_file and os.path.exists(cache_file):\n                instances = self._instances_from_cache_file(cache_file)\n            else:\n                instances = self._read(file_path)\n\n            # Then some validation.\n            if not isinstance(instances, list):\n                instances = [instance for instance in Tqdm.tqdm(instances)]\n            if not instances:\n                raise ConfigurationError(\"No instances were read from the given filepath {}. \"\n                                         \"Is the path correct?\".format(file_path))\n\n            # And finally we write to the cache if we need to.\n            if cache_file and not os.path.exists(cache_file):\n                logger.info(f\"Caching instances to {cache_file}\")\n                with open(cache_file, 'w') as cache:\n                    for instance in Tqdm.tqdm(instances):\n                        cache.write(self.serialize_instance(instance) + '\\n')\n            return instances", "response": "Reads the specified file and returns an iterable of all the instances in the specified dataset."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrestore a model from a serialization_dir to the last saved checkpoint.", "response": "def restore_checkpoint(self) -> Tuple[Dict[str, Any], Dict[str, Any]]:\n        \"\"\"\n        Restores a model from a serialization_dir to the last saved checkpoint.\n        This includes a training state (typically consisting of an epoch count and optimizer state),\n        which is serialized separately from  model parameters. This function should only be used to\n        continue training - if you wish to load a model for inference/load parts of a model into a new\n        computation graph, you should use the native Pytorch functions:\n        `` model.load_state_dict(torch.load(\"/path/to/model/weights.th\"))``\n\n        If ``self._serialization_dir`` does not exist or does not contain any checkpointed weights,\n        this function will do nothing and return empty dicts.\n\n        Returns\n        -------\n        states: Tuple[Dict[str, Any], Dict[str, Any]]\n            The model state and the training state.\n        \"\"\"\n        latest_checkpoint = self.find_latest_checkpoint()\n\n        if latest_checkpoint is None:\n            # No checkpoint to restore, start at 0\n            return {}, {}\n\n        model_path, training_state_path = latest_checkpoint\n\n        # Load the parameters onto CPU, then transfer to GPU.\n        # This avoids potential OOM on GPU for large models that\n        # load parameters onto GPU then make a new GPU copy into the parameter\n        # buffer. The GPU transfer happens implicitly in load_state_dict.\n        model_state = torch.load(model_path, map_location=nn_util.device_mapping(-1))\n        training_state = torch.load(training_state_path, map_location=nn_util.device_mapping(-1))\n        return model_state, training_state"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite predictions and gold labels for a single verbal taxonomy in a single word sentence to a two provided file references.", "response": "def write_to_conll_eval_file(prediction_file: TextIO,\n                             gold_file: TextIO,\n                             verb_index: Optional[int],\n                             sentence: List[str],\n                             prediction: List[str],\n                             gold_labels: List[str]):\n    \"\"\"\n    Prints predicate argument predictions and gold labels for a single verbal\n    predicate in a sentence to two provided file references.\n\n    Parameters\n    ----------\n    prediction_file : TextIO, required.\n        A file reference to print predictions to.\n    gold_file : TextIO, required.\n        A file reference to print gold labels to.\n    verb_index : Optional[int], required.\n        The index of the verbal predicate in the sentence which\n        the gold labels are the arguments for, or None if the sentence\n        contains no verbal predicate.\n    sentence : List[str], required.\n        The word tokens.\n    prediction : List[str], required.\n        The predicted BIO labels.\n    gold_labels : List[str], required.\n        The gold BIO labels.\n    \"\"\"\n    verb_only_sentence = [\"-\"] * len(sentence)\n    if verb_index:\n        verb_only_sentence[verb_index] = sentence[verb_index]\n\n    conll_format_predictions = convert_bio_tags_to_conll_format(prediction)\n    conll_format_gold_labels = convert_bio_tags_to_conll_format(gold_labels)\n\n    for word, predicted, gold in zip(verb_only_sentence,\n                                     conll_format_predictions,\n                                     conll_format_gold_labels):\n        prediction_file.write(word.ljust(15))\n        prediction_file.write(predicted.rjust(15) + \"\\n\")\n        gold_file.write(word.ljust(15))\n        gold_file.write(gold.rjust(15) + \"\\n\")\n    prediction_file.write(\"\\n\")\n    gold_file.write(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a list of BIO formatted SRL tags to the CONLL format required for evaluation with the given CONLL 2005 perl script.", "response": "def convert_bio_tags_to_conll_format(labels: List[str]):\n    \"\"\"\n    Converts BIO formatted SRL tags to the format required for evaluation with the\n    official CONLL 2005 perl script. Spans are represented by bracketed labels,\n    with the labels of words inside spans being the same as those outside spans.\n    Beginning spans always have a opening bracket and a closing asterisk (e.g. \"(ARG-1*\" )\n    and closing spans always have a closing bracket (e.g. \"*)\" ). This applies even for\n    length 1 spans, (e.g \"(ARG-0*)\").\n\n    A full example of the conversion performed:\n\n    [B-ARG-1, I-ARG-1, I-ARG-1, I-ARG-1, I-ARG-1, O]\n    [ \"(ARG-1*\", \"*\", \"*\", \"*\", \"*)\", \"*\"]\n\n    Parameters\n    ----------\n    labels : List[str], required.\n        A list of BIO tags to convert to the CONLL span based format.\n\n    Returns\n    -------\n    A list of labels in the CONLL span based format.\n    \"\"\"\n    sentence_length = len(labels)\n    conll_labels = []\n    for i, label in enumerate(labels):\n        if label == \"O\":\n            conll_labels.append(\"*\")\n            continue\n        new_label = \"*\"\n        # Are we at the beginning of a new span, at the first word in the sentence,\n        # or is the label different from the previous one? If so, we are seeing a new label.\n        if label[0] == \"B\" or i == 0 or label[1:] != labels[i - 1][1:]:\n            new_label = \"(\" + label[2:] + new_label\n        # Are we at the end of the sentence, is the next word a new span, or is the next\n        # word not in a span? If so, we need to close the label span.\n        if i == sentence_length - 1 or labels[i + 1][0] == \"B\" or label[1:] != labels[i + 1][1:]:\n            new_label = new_label + \")\"\n        conll_labels.append(new_label)\n    return conll_labels"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_agenda_for_sentence(self, sentence: str) -> List[str]:\n        agenda = []\n        sentence = sentence.lower()\n        if sentence.startswith(\"there is a box\") or sentence.startswith(\"there is a tower \"):\n            agenda.append(self.terminal_productions[\"box_exists\"])\n        elif sentence.startswith(\"there is a \"):\n            agenda.append(self.terminal_productions[\"object_exists\"])\n\n        if \"<Set[Box]:bool> -> box_exists\" not in agenda:\n            # These are object filters and do not apply if we have a box_exists at the top.\n            if \"touch\" in sentence:\n                if \"top\" in sentence:\n                    agenda.append(self.terminal_productions[\"touch_top\"])\n                elif \"bottom\" in sentence or \"base\" in sentence:\n                    agenda.append(self.terminal_productions[\"touch_bottom\"])\n                elif \"corner\" in sentence:\n                    agenda.append(self.terminal_productions[\"touch_corner\"])\n                elif \"right\" in sentence:\n                    agenda.append(self.terminal_productions[\"touch_right\"])\n                elif \"left\" in sentence:\n                    agenda.append(self.terminal_productions[\"touch_left\"])\n                elif \"wall\" in sentence or \"edge\" in sentence:\n                    agenda.append(self.terminal_productions[\"touch_wall\"])\n                else:\n                    agenda.append(self.terminal_productions[\"touch_object\"])\n            else:\n                # The words \"top\" and \"bottom\" may be referring to top and bottom blocks in a tower.\n                if \"top\" in sentence:\n                    agenda.append(self.terminal_productions[\"top\"])\n                elif \"bottom\" in sentence or \"base\" in sentence:\n                    agenda.append(self.terminal_productions[\"bottom\"])\n\n            if \" not \" in sentence:\n                agenda.append(self.terminal_productions[\"negate_filter\"])\n\n        if \" contains \" in sentence or \" has \" in sentence:\n            agenda.append(self.terminal_productions[\"all_boxes\"])\n        # This takes care of shapes, colors, top, bottom, big, small etc.\n        for constant, production in self.terminal_productions.items():\n            # TODO(pradeep): Deal with constant names with underscores.\n            if \"top\" in constant or \"bottom\" in constant:\n                # We already dealt with top, bottom, touch_top and touch_bottom above.\n                continue\n            if constant in sentence:\n                if \"<Set[Object]:Set[Object]> ->\" in production and \"<Set[Box]:bool> -> box_exists\" in agenda:\n                    if constant in [\"square\", \"circle\", \"triangle\"]:\n                        agenda.append(self.terminal_productions[f\"shape_{constant}\"])\n                    elif constant in [\"yellow\", \"blue\", \"black\"]:\n                        agenda.append(self.terminal_productions[f\"color_{constant}\"])\n                    else:\n                        continue\n                else:\n                    agenda.append(production)\n        # TODO (pradeep): Rules for \"member_*\" productions (\"tower\" or \"box\" followed by a color,\n        # shape or number...)\n        number_productions = self._get_number_productions(sentence)\n        for production in number_productions:\n            agenda.append(production)\n        if not agenda:\n            # None of the rules above was triggered!\n            if \"box\" in sentence:\n                agenda.append(self.terminal_productions[\"all_boxes\"])\n            else:\n                agenda.append(self.terminal_productions[\"all_objects\"])\n        return agenda", "response": "Given a sentence returns a list of actions the sentence triggers as an agenda."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngathering all the numbers in the sentence and returns the productions that lead to them.", "response": "def _get_number_productions(sentence: str) -> List[str]:\n        \"\"\"\n        Gathers all the numbers in the sentence, and returns productions that lead to them.\n        \"\"\"\n        # The mapping here is very simple and limited, which also shouldn't be a problem\n        # because numbers seem to be represented fairly regularly.\n        number_strings = {\"one\": \"1\", \"two\": \"2\", \"three\": \"3\", \"four\": \"4\", \"five\": \"5\", \"six\":\n                          \"6\", \"seven\": \"7\", \"eight\": \"8\", \"nine\": \"9\", \"ten\": \"10\"}\n        number_productions = []\n        tokens = sentence.split()\n        numbers = number_strings.values()\n        for token in tokens:\n            if token in numbers:\n                number_productions.append(f\"int -> {token}\")\n            elif token in number_strings:\n                number_productions.append(f\"int -> {number_strings[token]}\")\n        return number_productions"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef same_color(self, objects: Set[Object]) -> Set[Object]:\n        return self._get_objects_with_same_attribute(objects, lambda x: x.color)", "response": "Filters the set of objects and returns those objects whose color is the most frequent one."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef same_shape(self, objects: Set[Object]) -> Set[Object]:\n        return self._get_objects_with_same_attribute(objects, lambda x: x.shape)", "response": "Filters the set of objects and returns those objects whose shape is the same shape as the set of objects."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef touch_object(self, objects: Set[Object]) -> Set[Object]:\n        objects_per_box = self._separate_objects_by_boxes(objects)\n        return_set = set()\n        for box, box_objects in objects_per_box.items():\n            candidate_objects = box.objects\n            for object_ in box_objects:\n                for candidate_object in candidate_objects:\n                    if self._objects_touch_each_other(object_, candidate_object):\n                        return_set.add(candidate_object)\n        return return_set", "response": "Returns all objects that touch the given set of objects."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef top(self, objects: Set[Object]) -> Set[Object]:\n        objects_per_box = self._separate_objects_by_boxes(objects)\n        return_set: Set[Object] = set()\n        for _, box_objects in objects_per_box.items():\n            min_y_loc = min([obj.y_loc for obj in box_objects])\n            return_set.update(set([obj for obj in box_objects if obj.y_loc == min_y_loc]))\n        return return_set", "response": "Return the topmost objects in a set."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bottom(self, objects: Set[Object]) -> Set[Object]:\n        objects_per_box = self._separate_objects_by_boxes(objects)\n        return_set: Set[Object] = set()\n        for _, box_objects in objects_per_box.items():\n            max_y_loc = max([obj.y_loc for obj in box_objects])\n            return_set.update(set([obj for obj in box_objects if obj.y_loc == max_y_loc]))\n        return return_set", "response": "Return the bottom most objects in a set."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the set of objects in the same boxes that are above the given objects.", "response": "def above(self, objects: Set[Object]) -> Set[Object]:\n        \"\"\"\n        Returns the set of objects in the same boxes that are above the given objects. That is, if\n        the input is a set of two objects, one in each box, we will return a union of the objects\n        above the first object in the first box, and those above the second object in the second box.\n        \"\"\"\n        objects_per_box = self._separate_objects_by_boxes(objects)\n        return_set = set()\n        for box in objects_per_box:\n            # min_y_loc corresponds to the top-most object.\n            min_y_loc = min([obj.y_loc for obj in objects_per_box[box]])\n            for candidate_obj in box.objects:\n                if candidate_obj.y_loc < min_y_loc:\n                    return_set.add(candidate_obj)\n        return return_set"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the set of objects in the same boxes that are below the given objects.", "response": "def below(self, objects: Set[Object]) -> Set[Object]:\n        \"\"\"\n        Returns the set of objects in the same boxes that are below the given objects. That is, if\n        the input is a set of two objects, one in each box, we will return a union of the objects\n        below the first object in the first box, and those below the second object in the second box.\n        \"\"\"\n        objects_per_box = self._separate_objects_by_boxes(objects)\n        return_set = set()\n        for box in objects_per_box:\n            # max_y_loc corresponds to the bottom-most object.\n            max_y_loc = max([obj.y_loc for obj in objects_per_box[box]])\n            for candidate_obj in box.objects:\n                if candidate_obj.y_loc > max_y_loc:\n                    return_set.add(candidate_obj)\n        return return_set"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn true iff the objects touch each other.", "response": "def _objects_touch_each_other(self, object1: Object, object2: Object) -> bool:\n        \"\"\"\n        Returns true iff the objects touch each other.\n        \"\"\"\n        in_vertical_range = object1.y_loc <= object2.y_loc + object2.size and \\\n                            object1.y_loc + object1.size >= object2.y_loc\n        in_horizantal_range = object1.x_loc <= object2.x_loc + object2.size and \\\n                            object1.x_loc + object1.size >= object2.x_loc\n        touch_side = object1.x_loc + object1.size == object2.x_loc or \\\n                     object2.x_loc + object2.size == object1.x_loc\n        touch_top_or_bottom = object1.y_loc + object1.size == object2.y_loc or \\\n                              object2.y_loc + object2.size == object1.y_loc\n        return (in_vertical_range and touch_side) or (in_horizantal_range and touch_top_or_bottom)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a set of objects separate them by the boxes they belong to and return a dict.", "response": "def _separate_objects_by_boxes(self, objects: Set[Object]) -> Dict[Box, List[Object]]:\n        \"\"\"\n        Given a set of objects, separate them by the boxes they belong to and return a dict.\n        \"\"\"\n        objects_per_box: Dict[Box, List[Object]] = defaultdict(list)\n        for box in self.boxes:\n            for object_ in objects:\n                if object_ in box.objects:\n                    objects_per_box[box].append(object_)\n        return objects_per_box"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the set of objects for which the attribute function returns an attribute value that is most frequent in the initial set.", "response": "def _get_objects_with_same_attribute(self,\n                                         objects: Set[Object],\n                                         attribute_function: Callable[[Object], str]) -> Set[Object]:\n        \"\"\"\n        Returns the set of objects for which the attribute function returns an attribute value that\n        is most frequent in the initial set, if the frequency is greater than 1. If not, all\n        objects have different attribute values, and this method returns an empty set.\n        \"\"\"\n        objects_of_attribute: Dict[str, Set[Object]] = defaultdict(set)\n        for entity in objects:\n            objects_of_attribute[attribute_function(entity)].add(entity)\n        if not objects_of_attribute:\n            return set()\n        most_frequent_attribute = max(objects_of_attribute, key=lambda x: len(objects_of_attribute[x]))\n        if len(objects_of_attribute[most_frequent_attribute]) <= 1:\n            return set()\n        return objects_of_attribute[most_frequent_attribute]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if a possibly complex data structure has any torch. Tensors in it.", "response": "def has_tensor(obj) -> bool:\n    \"\"\"\n    Given a possibly complex data structure,\n    check if it has any torch.Tensors in it.\n    \"\"\"\n    if isinstance(obj, torch.Tensor):\n        return True\n    elif isinstance(obj, dict):\n        return any(has_tensor(value) for value in obj.values())\n    elif isinstance(obj, (list, tuple)):\n        return any(has_tensor(item) for item in obj)\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a structure containing Tensors on the CPU move all the Tensors to the specified GPU.", "response": "def move_to_device(obj, cuda_device: int):\n    \"\"\"\n    Given a structure (possibly) containing Tensors on the CPU,\n    move all the Tensors to the specified GPU (or do nothing, if they should be on the CPU).\n    \"\"\"\n    if cuda_device < 0 or not has_tensor(obj):\n        return obj\n    elif isinstance(obj, torch.Tensor):\n        return obj.cuda(cuda_device)\n    elif isinstance(obj, dict):\n        return {key: move_to_device(value, cuda_device) for key, value in obj.items()}\n    elif isinstance(obj, list):\n        return [move_to_device(item, cuda_device) for item in obj]\n    elif isinstance(obj, tuple):\n        return tuple([move_to_device(item, cuda_device) for item in obj])\n    else:\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a tensor with values clamped between the provided minimum and maximum.", "response": "def clamp_tensor(tensor, minimum, maximum):\n    \"\"\"\n    Supports sparse and dense tensors.\n    Returns a tensor with values clamped between the provided minimum and maximum,\n    without modifying the original tensor.\n    \"\"\"\n    if tensor.is_sparse:\n        coalesced_tensor = tensor.coalesce()\n        # pylint: disable=protected-access\n        coalesced_tensor._values().clamp_(minimum, maximum)\n        return coalesced_tensor\n    else:\n        return tensor.clamp(minimum, maximum)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntaking a list of tensor dictionaries where each dictionary is assumed to have matching keys and returns a single dictionary with all tensors with the same key batched together.", "response": "def batch_tensor_dicts(tensor_dicts: List[Dict[str, torch.Tensor]],\n                       remove_trailing_dimension: bool = False) -> Dict[str, torch.Tensor]:\n    \"\"\"\n    Takes a list of tensor dictionaries, where each dictionary is assumed to have matching keys,\n    and returns a single dictionary with all tensors with the same key batched together.\n\n    Parameters\n    ----------\n    tensor_dicts : ``List[Dict[str, torch.Tensor]]``\n        The list of tensor dictionaries to batch.\n    remove_trailing_dimension : ``bool``\n        If ``True``, we will check for a trailing dimension of size 1 on the tensors that are being\n        batched, and remove it if we find it.\n    \"\"\"\n    key_to_tensors: Dict[str, List[torch.Tensor]] = defaultdict(list)\n    for tensor_dict in tensor_dicts:\n        for key, tensor in tensor_dict.items():\n            key_to_tensors[key].append(tensor)\n    batched_tensors = {}\n    for key, tensor_list in key_to_tensors.items():\n        batched_tensor = torch.stack(tensor_list)\n        if remove_trailing_dimension and all(tensor.size(-1) == 1 for tensor in tensor_list):\n            batched_tensor = batched_tensor.squeeze(-1)\n        batched_tensors[key] = batched_tensor\n    return batched_tensors"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_mask_from_sequence_lengths(sequence_lengths: torch.Tensor, max_length: int) -> torch.Tensor:\n    # (batch_size, max_length)\n    ones = sequence_lengths.new_ones(sequence_lengths.size(0), max_length)\n    range_tensor = ones.cumsum(dim=1)\n    return (sequence_lengths.unsqueeze(1) >= range_tensor).long()", "response": "Returns a mask variable that is a tensor that is greater than or equal to the given max_length."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sort_batch_by_length(tensor: torch.Tensor, sequence_lengths: torch.Tensor):\n\n    if not isinstance(tensor, torch.Tensor) or not isinstance(sequence_lengths, torch.Tensor):\n        raise ConfigurationError(\"Both the tensor and sequence lengths must be torch.Tensors.\")\n\n    sorted_sequence_lengths, permutation_index = sequence_lengths.sort(0, descending=True)\n    sorted_tensor = tensor.index_select(0, permutation_index)\n\n    index_range = torch.arange(0, len(sequence_lengths), device=sequence_lengths.device)\n    # This is the equivalent of zipping with index, sorting by the original\n    # sequence lengths and returning the now sorted indices.\n    _, reverse_mapping = permutation_index.sort(0, descending=False)\n    restoration_indices = index_range.index_select(0, reverse_mapping)\n    return sorted_tensor, sorted_sequence_lengths, restoration_indices, permutation_index", "response": "Sorts a batch first tensor by some specified length."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive the output from a Seq2SeqEncoder this method returns the final hidden state for each encoder instance.", "response": "def get_final_encoder_states(encoder_outputs: torch.Tensor,\n                             mask: torch.Tensor,\n                             bidirectional: bool = False) -> torch.Tensor:\n    \"\"\"\n    Given the output from a ``Seq2SeqEncoder``, with shape ``(batch_size, sequence_length,\n    encoding_dim)``, this method returns the final hidden state for each element of the batch,\n    giving a tensor of shape ``(batch_size, encoding_dim)``.  This is not as simple as\n    ``encoder_outputs[:, -1]``, because the sequences could have different lengths.  We use the\n    mask (which has shape ``(batch_size, sequence_length)``) to find the final state for each batch\n    instance.\n\n    Additionally, if ``bidirectional`` is ``True``, we will split the final dimension of the\n    ``encoder_outputs`` into two and assume that the first half is for the forward direction of the\n    encoder and the second half is for the backward direction.  We will concatenate the last state\n    for each encoder dimension, giving ``encoder_outputs[:, -1, :encoding_dim/2]`` concatenated with\n    ``encoder_outputs[:, 0, encoding_dim/2:]``.\n    \"\"\"\n    # These are the indices of the last words in the sequences (i.e. length sans padding - 1).  We\n    # are assuming sequences are right padded.\n    # Shape: (batch_size,)\n    last_word_indices = mask.sum(1).long() - 1\n    batch_size, _, encoder_output_dim = encoder_outputs.size()\n    expanded_indices = last_word_indices.view(-1, 1, 1).expand(batch_size, 1, encoder_output_dim)\n    # Shape: (batch_size, 1, encoder_output_dim)\n    final_encoder_output = encoder_outputs.gather(1, expanded_indices)\n    final_encoder_output = final_encoder_output.squeeze(1)  # (batch_size, encoder_output_dim)\n    if bidirectional:\n        final_forward_output = final_encoder_output[:, :(encoder_output_dim // 2)]\n        final_backward_output = encoder_outputs[:, 0, (encoder_output_dim // 2):]\n        final_encoder_output = torch.cat([final_forward_output, final_backward_output], dim=-1)\n    return final_encoder_output"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_dropout_mask(dropout_probability: float, tensor_for_masking: torch.Tensor):\n    binary_mask = (torch.rand(tensor_for_masking.size()) > dropout_probability).to(tensor_for_masking.device)\n    # Scale mask by 1/keep_prob to preserve output statistics.\n    dropout_mask = binary_mask.float().div(1.0 - dropout_probability)\n    return dropout_mask", "response": "Computes and returns an element - wise dropout mask for a given tensor."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef masked_log_softmax(vector: torch.Tensor, mask: torch.Tensor, dim: int = -1) -> torch.Tensor:\n    if mask is not None:\n        mask = mask.float()\n        while mask.dim() < vector.dim():\n            mask = mask.unsqueeze(1)\n        # vector + mask.log() is an easy way to zero out masked elements in logspace, but it\n        # results in nans when the whole vector is masked.  We need a very small value instead of a\n        # zero in the mask for these cases.  log(1 + 1e-45) is still basically 0, so we can safely\n        # just add 1e-45 before calling mask.log().  We use 1e-45 because 1e-46 is so small it\n        # becomes 0 - this is just the smallest value we can actually use.\n        vector = vector + (mask + 1e-45).log()\n    return torch.nn.functional.log_softmax(vector, dim=dim)", "response": "This function performs a log_softmax on the given vector and returns the result of the log_softmax function."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef masked_max(vector: torch.Tensor,\n               mask: torch.Tensor,\n               dim: int,\n               keepdim: bool = False,\n               min_val: float = -1e7) -> torch.Tensor:\n    \"\"\"\n    To calculate max along certain dimensions on masked values\n\n    Parameters\n    ----------\n    vector : ``torch.Tensor``\n        The vector to calculate max, assume unmasked parts are already zeros\n    mask : ``torch.Tensor``\n        The mask of the vector. It must be broadcastable with vector.\n    dim : ``int``\n        The dimension to calculate max\n    keepdim : ``bool``\n        Whether to keep dimension\n    min_val : ``float``\n        The minimal value for paddings\n\n    Returns\n    -------\n    A ``torch.Tensor`` of including the maximum values.\n    \"\"\"\n    one_minus_mask = (1.0 - mask).byte()\n    replaced_vector = vector.masked_fill(one_minus_mask, min_val)\n    max_value, _ = replaced_vector.max(dim=dim, keepdim=keepdim)\n    return max_value", "response": "Returns the maximum value of a set of unmasked parts along certain dimensions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef masked_mean(vector: torch.Tensor,\n                mask: torch.Tensor,\n                dim: int,\n                keepdim: bool = False,\n                eps: float = 1e-8) -> torch.Tensor:\n    \"\"\"\n    To calculate mean along certain dimensions on masked values\n\n    Parameters\n    ----------\n    vector : ``torch.Tensor``\n        The vector to calculate mean.\n    mask : ``torch.Tensor``\n        The mask of the vector. It must be broadcastable with vector.\n    dim : ``int``\n        The dimension to calculate mean\n    keepdim : ``bool``\n        Whether to keep dimension\n    eps : ``float``\n        A small value to avoid zero division problem.\n\n    Returns\n    -------\n    A ``torch.Tensor`` of including the mean values.\n    \"\"\"\n    one_minus_mask = (1.0 - mask).byte()\n    replaced_vector = vector.masked_fill(one_minus_mask, 0.0)\n\n    value_sum = torch.sum(replaced_vector, dim=dim, keepdim=keepdim)\n    value_count = torch.sum(mask.float(), dim=dim, keepdim=keepdim)\n    return value_sum / value_count.clamp(min=eps)", "response": "Calculates the mean along certain dimensions on masked values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nflip a padded tensor along the time dimension without affecting masked entries.", "response": "def masked_flip(padded_sequence: torch.Tensor,\n                sequence_lengths: List[int]) -> torch.Tensor:\n    \"\"\"\n        Flips a padded tensor along the time dimension without affecting masked entries.\n\n        Parameters\n        ----------\n        padded_sequence : ``torch.Tensor``\n            The tensor to flip along the time dimension.\n            Assumed to be of dimensions (batch size, num timesteps, ...)\n        sequence_lengths : ``torch.Tensor``\n            A list containing the lengths of each unpadded sequence in the batch.\n\n        Returns\n        -------\n        A ``torch.Tensor`` of the same shape as padded_sequence.\n        \"\"\"\n    assert padded_sequence.size(0) == len(sequence_lengths), \\\n        f'sequence_lengths length ${len(sequence_lengths)} does not match batch size ${padded_sequence.size(0)}'\n    num_timesteps = padded_sequence.size(1)\n    flipped_padded_sequence = torch.flip(padded_sequence, [1])\n    sequences = [flipped_padded_sequence[i, num_timesteps - length:] for i, length in enumerate(sequence_lengths)]\n    return torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef viterbi_decode(tag_sequence: torch.Tensor,\n                   transition_matrix: torch.Tensor,\n                   tag_observations: Optional[List[int]] = None):\n    \"\"\"\n    Perform Viterbi decoding in log space over a sequence given a transition matrix\n    specifying pairwise (transition) potentials between tags and a matrix of shape\n    (sequence_length, num_tags) specifying unary potentials for possible tags per\n    timestep.\n\n    Parameters\n    ----------\n    tag_sequence : torch.Tensor, required.\n        A tensor of shape (sequence_length, num_tags) representing scores for\n        a set of tags over a given sequence.\n    transition_matrix : torch.Tensor, required.\n        A tensor of shape (num_tags, num_tags) representing the binary potentials\n        for transitioning between a given pair of tags.\n    tag_observations : Optional[List[int]], optional, (default = None)\n        A list of length ``sequence_length`` containing the class ids of observed\n        elements in the sequence, with unobserved elements being set to -1. Note that\n        it is possible to provide evidence which results in degenerate labelings if\n        the sequences of tags you provide as evidence cannot transition between each\n        other, or those transitions are extremely unlikely. In this situation we log a\n        warning, but the responsibility for providing self-consistent evidence ultimately\n        lies with the user.\n\n    Returns\n    -------\n    viterbi_path : List[int]\n        The tag indices of the maximum likelihood tag sequence.\n    viterbi_score : torch.Tensor\n        The score of the viterbi path.\n    \"\"\"\n    sequence_length, num_tags = list(tag_sequence.size())\n    if tag_observations:\n        if len(tag_observations) != sequence_length:\n            raise ConfigurationError(\"Observations were provided, but they were not the same length \"\n                                     \"as the sequence. Found sequence of length: {} and evidence: {}\"\n                                     .format(sequence_length, tag_observations))\n    else:\n        tag_observations = [-1 for _ in range(sequence_length)]\n\n    path_scores = []\n    path_indices = []\n\n    if tag_observations[0] != -1:\n        one_hot = torch.zeros(num_tags)\n        one_hot[tag_observations[0]] = 100000.\n        path_scores.append(one_hot)\n    else:\n        path_scores.append(tag_sequence[0, :])\n\n    # Evaluate the scores for all possible paths.\n    for timestep in range(1, sequence_length):\n        # Add pairwise potentials to current scores.\n        summed_potentials = path_scores[timestep - 1].unsqueeze(-1) + transition_matrix\n        scores, paths = torch.max(summed_potentials, 0)\n\n        # If we have an observation for this timestep, use it\n        # instead of the distribution over tags.\n        observation = tag_observations[timestep]\n        # Warn the user if they have passed\n        # invalid/extremely unlikely evidence.\n        if tag_observations[timestep - 1] != -1:\n            if transition_matrix[tag_observations[timestep - 1], observation] < -10000:\n                logger.warning(\"The pairwise potential between tags you have passed as \"\n                               \"observations is extremely unlikely. Double check your evidence \"\n                               \"or transition potentials!\")\n        if observation != -1:\n            one_hot = torch.zeros(num_tags)\n            one_hot[observation] = 100000.\n            path_scores.append(one_hot)\n        else:\n            path_scores.append(tag_sequence[timestep, :] + scores.squeeze())\n        path_indices.append(paths.squeeze())\n\n    # Construct the most likely sequence backwards.\n    viterbi_score, best_path = torch.max(path_scores[-1], 0)\n    viterbi_path = [int(best_path.numpy())]\n    for backward_timestep in reversed(path_indices):\n        viterbi_path.append(int(backward_timestep[viterbi_path[-1]]))\n    # Reverse the backward path.\n    viterbi_path.reverse()\n    return viterbi_path, viterbi_score", "response": "This function performs Viterbi decoding in log space over a sequence given a transition matrix and a list of unobserved tags."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_text_field_mask(text_field_tensors: Dict[str, torch.Tensor],\n                        num_wrapping_dims: int = 0) -> torch.LongTensor:\n    \"\"\"\n    Takes the dictionary of tensors produced by a ``TextField`` and returns a mask\n    with 0 where the tokens are padding, and 1 otherwise.  We also handle ``TextFields``\n    wrapped by an arbitrary number of ``ListFields``, where the number of wrapping ``ListFields``\n    is given by ``num_wrapping_dims``.\n\n    If ``num_wrapping_dims == 0``, the returned mask has shape ``(batch_size, num_tokens)``.\n    If ``num_wrapping_dims > 0`` then the returned mask has ``num_wrapping_dims`` extra\n    dimensions, so the shape will be ``(batch_size, ..., num_tokens)``.\n\n    There could be several entries in the tensor dictionary with different shapes (e.g., one for\n    word ids, one for character ids).  In order to get a token mask, we use the tensor in\n    the dictionary with the lowest number of dimensions.  After subtracting ``num_wrapping_dims``,\n    if this tensor has two dimensions we assume it has shape ``(batch_size, ..., num_tokens)``,\n    and use it for the mask.  If instead it has three dimensions, we assume it has shape\n    ``(batch_size, ..., num_tokens, num_features)``, and sum over the last dimension to produce\n    the mask.  Most frequently this will be a character id tensor, but it could also be a\n    featurized representation of each token, etc.\n\n    If the input ``text_field_tensors`` contains the \"mask\" key, this is returned instead of inferring the mask.\n\n    TODO(joelgrus): can we change this?\n    NOTE: Our functions for generating masks create torch.LongTensors, because using\n    torch.ByteTensors  makes it easy to run into overflow errors\n    when doing mask manipulation, such as summing to get the lengths of sequences - see below.\n    >>> mask = torch.ones([260]).byte()\n    >>> mask.sum() # equals 260.\n    >>> var_mask = torch.autograd.V(mask)\n    >>> var_mask.sum() # equals 4, due to 8 bit precision - the sum overflows.\n    \"\"\"\n    if \"mask\" in text_field_tensors:\n        return text_field_tensors[\"mask\"]\n\n    tensor_dims = [(tensor.dim(), tensor) for tensor in text_field_tensors.values()]\n    tensor_dims.sort(key=lambda x: x[0])\n\n    smallest_dim = tensor_dims[0][0] - num_wrapping_dims\n    if smallest_dim == 2:\n        token_tensor = tensor_dims[0][1]\n        return (token_tensor != 0).long()\n    elif smallest_dim == 3:\n        character_tensor = tensor_dims[0][1]\n        return ((character_tensor > 0).long().sum(dim=-1) > 0).long()\n    else:\n        raise ValueError(\"Expected a tensor with dimension 2 or 3, found {}\".format(smallest_dim))", "response": "Takes a dictionary of text field tensors produced by a TextField and returns a mask of the same length as the input text_field_tensors."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef weighted_sum(matrix: torch.Tensor, attention: torch.Tensor) -> torch.Tensor:\n    # We'll special-case a few settings here, where there are efficient (but poorly-named)\n    # operations in pytorch that already do the computation we need.\n    if attention.dim() == 2 and matrix.dim() == 3:\n        return attention.unsqueeze(1).bmm(matrix).squeeze(1)\n    if attention.dim() == 3 and matrix.dim() == 3:\n        return attention.bmm(matrix)\n    if matrix.dim() - 1 < attention.dim():\n        expanded_size = list(matrix.size())\n        for i in range(attention.dim() - matrix.dim() + 1):\n            matrix = matrix.unsqueeze(1)\n            expanded_size.insert(i + 1, attention.size(i + 1))\n        matrix = matrix.expand(*expanded_size)\n    intermediate = attention.unsqueeze(-1).expand_as(matrix) * matrix\n    return intermediate.sum(dim=-2)", "response": "Computes the weighted sum of the rows in the matrix and the attention vector."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the cross - entropy loss of a sequence with the given logits targets and weights.", "response": "def sequence_cross_entropy_with_logits(logits: torch.FloatTensor,\n                                       targets: torch.LongTensor,\n                                       weights: torch.FloatTensor,\n                                       average: str = \"batch\",\n                                       label_smoothing: float = None) -> torch.FloatTensor:\n    \"\"\"\n    Computes the cross entropy loss of a sequence, weighted with respect to\n    some user provided weights. Note that the weighting here is not the same as\n    in the :func:`torch.nn.CrossEntropyLoss()` criterion, which is weighting\n    classes; here we are weighting the loss contribution from particular elements\n    in the sequence. This allows loss computations for models which use padding.\n\n    Parameters\n    ----------\n    logits : ``torch.FloatTensor``, required.\n        A ``torch.FloatTensor`` of size (batch_size, sequence_length, num_classes)\n        which contains the unnormalized probability for each class.\n    targets : ``torch.LongTensor``, required.\n        A ``torch.LongTensor`` of size (batch, sequence_length) which contains the\n        index of the true class for each corresponding step.\n    weights : ``torch.FloatTensor``, required.\n        A ``torch.FloatTensor`` of size (batch, sequence_length)\n    average: str, optional (default = \"batch\")\n        If \"batch\", average the loss across the batches. If \"token\", average\n        the loss across each item in the input. If ``None``, return a vector\n        of losses per batch element.\n    label_smoothing : ``float``, optional (default = None)\n        Whether or not to apply label smoothing to the cross-entropy loss.\n        For example, with a label smoothing value of 0.2, a 4 class classification\n        target would look like ``[0.05, 0.05, 0.85, 0.05]`` if the 3rd class was\n        the correct label.\n\n    Returns\n    -------\n    A torch.FloatTensor representing the cross entropy loss.\n    If ``average==\"batch\"`` or ``average==\"token\"``, the returned loss is a scalar.\n    If ``average is None``, the returned loss is a vector of shape (batch_size,).\n\n    \"\"\"\n    if average not in {None, \"token\", \"batch\"}:\n        raise ValueError(\"Got average f{average}, expected one of \"\n                         \"None, 'token', or 'batch'\")\n\n    # shape : (batch * sequence_length, num_classes)\n    logits_flat = logits.view(-1, logits.size(-1))\n    # shape : (batch * sequence_length, num_classes)\n    log_probs_flat = torch.nn.functional.log_softmax(logits_flat, dim=-1)\n    # shape : (batch * max_len, 1)\n    targets_flat = targets.view(-1, 1).long()\n\n    if label_smoothing is not None and label_smoothing > 0.0:\n        num_classes = logits.size(-1)\n        smoothing_value = label_smoothing / num_classes\n        # Fill all the correct indices with 1 - smoothing value.\n        one_hot_targets = torch.zeros_like(log_probs_flat).scatter_(-1, targets_flat, 1.0 - label_smoothing)\n        smoothed_targets = one_hot_targets + smoothing_value\n        negative_log_likelihood_flat = - log_probs_flat * smoothed_targets\n        negative_log_likelihood_flat = negative_log_likelihood_flat.sum(-1, keepdim=True)\n    else:\n        # Contribution to the negative log likelihood only comes from the exact indices\n        # of the targets, as the target distributions are one-hot. Here we use torch.gather\n        # to extract the indices of the num_classes dimension which contribute to the loss.\n        # shape : (batch * sequence_length, 1)\n        negative_log_likelihood_flat = - torch.gather(log_probs_flat, dim=1, index=targets_flat)\n    # shape : (batch, sequence_length)\n    negative_log_likelihood = negative_log_likelihood_flat.view(*targets.size())\n    # shape : (batch, sequence_length)\n    negative_log_likelihood = negative_log_likelihood * weights.float()\n\n    if average == \"batch\":\n        # shape : (batch_size,)\n        per_batch_loss = negative_log_likelihood.sum(1) / (weights.sum(1).float() + 1e-13)\n        num_non_empty_sequences = ((weights.sum(1) > 0).float().sum() + 1e-13)\n        return per_batch_loss.sum() / num_non_empty_sequences\n    elif average == \"token\":\n        return negative_log_likelihood.sum() / (weights.sum().float() + 1e-13)\n    else:\n        # shape : (batch_size,)\n        per_batch_loss = negative_log_likelihood.sum(1) / (weights.sum(1).float() + 1e-13)\n        return per_batch_loss"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreplaces all masked values in tensor with replace_with.", "response": "def replace_masked_values(tensor: torch.Tensor, mask: torch.Tensor, replace_with: float) -> torch.Tensor:\n    \"\"\"\n    Replaces all masked values in ``tensor`` with ``replace_with``.  ``mask`` must be broadcastable\n    to the same shape as ``tensor``. We require that ``tensor.dim() == mask.dim()``, as otherwise we\n    won't know which dimensions of the mask to unsqueeze.\n\n    This just does ``tensor.masked_fill()``, except the pytorch method fills in things with a mask\n    value of 1, where we want the opposite.  You can do this in your own code with\n    ``tensor.masked_fill((1 - mask).byte(), replace_with)``.\n    \"\"\"\n    if tensor.dim() != mask.dim():\n        raise ConfigurationError(\"tensor.dim() (%d) != mask.dim() (%d)\" % (tensor.dim(), mask.dim()))\n    return tensor.masked_fill((1 - mask).byte(), replace_with)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a function that maps a GPU - trained model onto a CPU or specific GPU.", "response": "def device_mapping(cuda_device: int):\n    \"\"\"\n    In order to `torch.load()` a GPU-trained model onto a CPU (or specific GPU),\n    you have to supply a `map_location` function. Call this with\n    the desired `cuda_device` to get the function that `torch.load()` needs.\n    \"\"\"\n\n    def inner_device_mapping(storage: torch.Storage, location) -> torch.Storage:  # pylint: disable=unused-argument\n        if cuda_device >= 0:\n            return storage.cuda(cuda_device)\n        else:\n            return storage\n\n    return inner_device_mapping"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncombines a list of tensors using element - wise operations and concatenation of tensors.", "response": "def combine_tensors(combination: str, tensors: List[torch.Tensor]) -> torch.Tensor:\n    \"\"\"\n    Combines a list of tensors using element-wise operations and concatenation, specified by a\n    ``combination`` string.  The string refers to (1-indexed) positions in the input tensor list,\n    and looks like ``\"1,2,1+2,3-1\"``.\n\n    We allow the following kinds of combinations: ``x``, ``x*y``, ``x+y``, ``x-y``, and ``x/y``,\n    where ``x`` and ``y`` are positive integers less than or equal to ``len(tensors)``.  Each of\n    the binary operations is performed elementwise.  You can give as many combinations as you want\n    in the ``combination`` string.  For example, for the input string ``\"1,2,1*2\"``, the result\n    would be ``[1;2;1*2]``, as you would expect, where ``[;]`` is concatenation along the last\n    dimension.\n\n    If you have a fixed, known way to combine tensors that you use in a model, you should probably\n    just use something like ``torch.cat([x_tensor, y_tensor, x_tensor * y_tensor])``.  This\n    function adds some complexity that is only necessary if you want the specific combination used\n    to be `configurable`.\n\n    If you want to do any element-wise operations, the tensors involved in each element-wise\n    operation must have the same shape.\n\n    This function also accepts ``x`` and ``y`` in place of ``1`` and ``2`` in the combination\n    string.\n    \"\"\"\n    if len(tensors) > 9:\n        raise ConfigurationError(\"Double-digit tensor lists not currently supported\")\n    combination = combination.replace('x', '1').replace('y', '2')\n    to_concatenate = [_get_combination(piece, tensors) for piece in combination.split(',')]\n    return torch.cat(to_concatenate, dim=-1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the index in the sequence of the last item whose value is equal to obj. Raises a ValueError if there is no such item.", "response": "def _rindex(sequence: Sequence[T], obj: T) -> int:\n    \"\"\"\n    Return zero-based index in the sequence of the last item whose value is equal to obj.  Raises a\n    ValueError if there is no such item.\n\n    Parameters\n    ----------\n    sequence : ``Sequence[T]``\n    obj : ``T``\n\n    Returns\n    -------\n    zero-based index associated to the position of the last item equal to obj\n    \"\"\"\n    for i in range(len(sequence) - 1, -1, -1):\n        if sequence[i] == obj:\n            return i\n\n    raise ValueError(f\"Unable to find {obj} in sequence {sequence}.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef combine_tensors_and_multiply(combination: str,\n                                 tensors: List[torch.Tensor],\n                                 weights: torch.nn.Parameter) -> torch.Tensor:\n    \"\"\"\n    Like :func:`combine_tensors`, but does a weighted (linear) multiplication while combining.\n    This is a separate function from ``combine_tensors`` because we try to avoid instantiating\n    large intermediate tensors during the combination, which is possible because we know that we're\n    going to be multiplying by a weight vector in the end.\n\n    Parameters\n    ----------\n    combination : ``str``\n        Same as in :func:`combine_tensors`\n    tensors : ``List[torch.Tensor]``\n        A list of tensors to combine, where the integers in the ``combination`` are (1-indexed)\n        positions in this list of tensors.  These tensors are all expected to have either three or\n        four dimensions, with the final dimension being an embedding.  If there are four\n        dimensions, one of them must have length 1.\n    weights : ``torch.nn.Parameter``\n        A vector of weights to use for the combinations.  This should have shape (combined_dim,),\n        as calculated by :func:`get_combined_dim`.\n    \"\"\"\n    if len(tensors) > 9:\n        raise ConfigurationError(\"Double-digit tensor lists not currently supported\")\n    combination = combination.replace('x', '1').replace('y', '2')\n    pieces = combination.split(',')\n    tensor_dims = [tensor.size(-1) for tensor in tensors]\n    combination_dims = [_get_combination_dim(piece, tensor_dims) for piece in pieces]\n    dims_so_far = 0\n    to_sum = []\n    for piece, combination_dim in zip(pieces, combination_dims):\n        weight = weights[dims_so_far:(dims_so_far + combination_dim)]\n        dims_so_far += combination_dim\n        to_sum.append(_get_combination_and_multiply(piece, tensors, weight))\n    result = to_sum[0]\n    for result_piece in to_sum[1:]:\n        result = result + result_piece\n    return result", "response": "Combine a list of tensors and a weighted multiplication of them."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_combined_dim(combination: str, tensor_dims: List[int]) -> int:\n    if len(tensor_dims) > 9:\n        raise ConfigurationError(\"Double-digit tensor lists not currently supported\")\n    combination = combination.replace('x', '1').replace('y', '2')\n    return sum([_get_combination_dim(piece, tensor_dims) for piece in combination.split(',')])", "response": "Returns the dimension of the combined tensor."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef logsumexp(tensor: torch.Tensor,\n              dim: int = -1,\n              keepdim: bool = False) -> torch.Tensor:\n    \"\"\"\n    A numerically stable computation of logsumexp. This is mathematically equivalent to\n    `tensor.exp().sum(dim, keep=keepdim).log()`.  This function is typically used for summing log\n    probabilities.\n\n    Parameters\n    ----------\n    tensor : torch.FloatTensor, required.\n        A tensor of arbitrary size.\n    dim : int, optional (default = -1)\n        The dimension of the tensor to apply the logsumexp to.\n    keepdim: bool, optional (default = False)\n        Whether to retain a dimension of size one at the dimension we reduce over.\n    \"\"\"\n    max_score, _ = tensor.max(dim, keepdim=keepdim)\n    if keepdim:\n        stable_vec = tensor - max_score\n    else:\n        stable_vec = tensor - max_score.unsqueeze(dim)\n    return max_score + (stable_vec.exp().sum(dim, keepdim=keepdim)).log()", "response": "A numerically stable computation of logsumexp."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef flatten_and_batch_shift_indices(indices: torch.Tensor,\n                                    sequence_length: int) -> torch.Tensor:\n    \"\"\"\n    This is a subroutine for :func:`~batched_index_select`. The given ``indices`` of size\n    ``(batch_size, d_1, ..., d_n)`` indexes into dimension 2 of a target tensor, which has size\n    ``(batch_size, sequence_length, embedding_size)``. This function returns a vector that\n    correctly indexes into the flattened target. The sequence length of the target must be\n    provided to compute the appropriate offsets.\n\n    .. code-block:: python\n\n        indices = torch.ones([2,3], dtype=torch.long)\n        # Sequence length of the target tensor.\n        sequence_length = 10\n        shifted_indices = flatten_and_batch_shift_indices(indices, sequence_length)\n        # Indices into the second element in the batch are correctly shifted\n        # to take into account that the target tensor will be flattened before\n        # the indices are applied.\n        assert shifted_indices == [1, 1, 1, 11, 11, 11]\n\n    Parameters\n    ----------\n    indices : ``torch.LongTensor``, required.\n    sequence_length : ``int``, required.\n        The length of the sequence the indices index into.\n        This must be the second dimension of the tensor.\n\n    Returns\n    -------\n    offset_indices : ``torch.LongTensor``\n    \"\"\"\n    # Shape: (batch_size)\n    offsets = get_range_vector(indices.size(0), get_device_of(indices)) * sequence_length\n    for _ in range(len(indices.size()) - 1):\n        offsets = offsets.unsqueeze(1)\n\n    # Shape: (batch_size, d_1, ..., d_n)\n    offset_indices = indices + offsets\n\n    # Shape: (batch_size * d_1 * ... * d_n)\n    offset_indices = offset_indices.view(-1)\n    return offset_indices", "response": "This function is a subroutine for batched index_select. It returns a vector that is flattened with the given indices shifted into the batch_size d_1... d_n."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef batched_index_select(target: torch.Tensor,\n                         indices: torch.LongTensor,\n                         flattened_indices: Optional[torch.LongTensor] = None) -> torch.Tensor:\n    \"\"\"\n    The given ``indices`` of size ``(batch_size, d_1, ..., d_n)`` indexes into the sequence\n    dimension (dimension 2) of the target, which has size ``(batch_size, sequence_length,\n    embedding_size)``.\n\n    This function returns selected values in the target with respect to the provided indices, which\n    have size ``(batch_size, d_1, ..., d_n, embedding_size)``. This can use the optionally\n    precomputed :func:`~flattened_indices` with size ``(batch_size * d_1 * ... * d_n)`` if given.\n\n    An example use case of this function is looking up the start and end indices of spans in a\n    sequence tensor. This is used in the\n    :class:`~allennlp.models.coreference_resolution.CoreferenceResolver`. Model to select\n    contextual word representations corresponding to the start and end indices of mentions. The key\n    reason this can't be done with basic torch functions is that we want to be able to use look-up\n    tensors with an arbitrary number of dimensions (for example, in the coref model, we don't know\n    a-priori how many spans we are looking up).\n\n    Parameters\n    ----------\n    target : ``torch.Tensor``, required.\n        A 3 dimensional tensor of shape (batch_size, sequence_length, embedding_size).\n        This is the tensor to be indexed.\n    indices : ``torch.LongTensor``\n        A tensor of shape (batch_size, ...), where each element is an index into the\n        ``sequence_length`` dimension of the ``target`` tensor.\n    flattened_indices : Optional[torch.Tensor], optional (default = None)\n        An optional tensor representing the result of calling :func:~`flatten_and_batch_shift_indices`\n        on ``indices``. This is helpful in the case that the indices can be flattened once and\n        cached for many batch lookups.\n\n    Returns\n    -------\n    selected_targets : ``torch.Tensor``\n        A tensor with shape [indices.size(), target.size(-1)] representing the embedded indices\n        extracted from the batch flattened target tensor.\n    \"\"\"\n    if flattened_indices is None:\n        # Shape: (batch_size * d_1 * ... * d_n)\n        flattened_indices = flatten_and_batch_shift_indices(indices, target.size(1))\n\n    # Shape: (batch_size * sequence_length, embedding_size)\n    flattened_target = target.view(-1, target.size(-1))\n\n    # Shape: (batch_size * d_1 * ... * d_n, embedding_size)\n    flattened_selected = flattened_target.index_select(0, flattened_indices)\n    selected_shape = list(indices.size()) + [target.size(-1)]\n    # Shape: (batch_size, d_1, ..., d_n, embedding_size)\n    selected_targets = flattened_selected.view(*selected_shape)\n    return selected_targets", "response": "Select values from target with respect to the given indices."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a flattened version of the index_select function.", "response": "def flattened_index_select(target: torch.Tensor,\n                           indices: torch.LongTensor) -> torch.Tensor:\n    \"\"\"\n    The given ``indices`` of size ``(set_size, subset_size)`` specifies subsets of the ``target``\n    that each of the set_size rows should select. The `target` has size\n    ``(batch_size, sequence_length, embedding_size)``, and the resulting selected tensor has size\n    ``(batch_size, set_size, subset_size, embedding_size)``.\n\n    Parameters\n    ----------\n    target : ``torch.Tensor``, required.\n        A Tensor of shape (batch_size, sequence_length, embedding_size).\n    indices : ``torch.LongTensor``, required.\n        A LongTensor of shape (set_size, subset_size). All indices must be < sequence_length\n        as this tensor is an index into the sequence_length dimension of the target.\n\n    Returns\n    -------\n    selected : ``torch.Tensor``, required.\n        A Tensor of shape (batch_size, set_size, subset_size, embedding_size).\n    \"\"\"\n    if indices.dim() != 2:\n        raise ConfigurationError(\"Indices passed to flattened_index_select had shape {} but \"\n                                 \"only 2 dimensional inputs are supported.\".format(indices.size()))\n    # Shape: (batch_size, set_size * subset_size, embedding_size)\n    flattened_selected = target.index_select(1, indices.view(-1))\n\n    # Shape: (batch_size, set_size, subset_size, embedding_size)\n    selected = flattened_selected.view(target.size(0), indices.size(0), indices.size(1), -1)\n    return selected"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_range_vector(size: int, device: int) -> torch.Tensor:\n    if device > -1:\n        return torch.cuda.LongTensor(size, device=device).fill_(1).cumsum(0) - 1\n    else:\n        return torch.arange(0, size, dtype=torch.long)", "response": "Returns a range vector with the desired size starting at 0."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a tensor that contains the values for each bucket in the given distances.", "response": "def bucket_values(distances: torch.Tensor,\n                  num_identity_buckets: int = 4,\n                  num_total_buckets: int = 10) -> torch.Tensor:\n    \"\"\"\n    Places the given values (designed for distances) into ``num_total_buckets``semi-logscale\n    buckets, with ``num_identity_buckets`` of these capturing single values.\n\n    The default settings will bucket values into the following buckets:\n    [0, 1, 2, 3, 4, 5-7, 8-15, 16-31, 32-63, 64+].\n\n    Parameters\n    ----------\n    distances : ``torch.Tensor``, required.\n        A Tensor of any size, to be bucketed.\n    num_identity_buckets: int, optional (default = 4).\n        The number of identity buckets (those only holding a single value).\n    num_total_buckets : int, (default = 10)\n        The total number of buckets to bucket values into.\n\n    Returns\n    -------\n    A tensor of the same shape as the input, containing the indices of the buckets\n    the values were placed in.\n    \"\"\"\n    # Chunk the values into semi-logscale buckets using .floor().\n    # This is a semi-logscale bucketing because we divide by log(2) after taking the log.\n    # We do this to make the buckets more granular in the initial range, where we expect\n    # most values to fall. We then add (num_identity_buckets - 1) because we want these indices\n    # to start _after_ the fixed number of buckets which we specified would only hold single values.\n    logspace_index = (distances.float().log() / math.log(2)).floor().long() + (num_identity_buckets - 1)\n    # create a mask for values which will go into single number buckets (i.e not a range).\n    use_identity_mask = (distances <= num_identity_buckets).long()\n    use_buckets_mask = 1 + (-1 * use_identity_mask)\n    # Use the original values if they are less than num_identity_buckets, otherwise\n    # use the logspace indices.\n    combined_index = use_identity_mask * distances + use_buckets_mask * logspace_index\n    # Clamp to put anything > num_total_buckets into the final bucket.\n    return combined_index.clamp(0, num_total_buckets - 1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_sentence_boundary_token_ids(tensor: torch.Tensor,\n                                    mask: torch.Tensor,\n                                    sentence_begin_token: Any,\n                                    sentence_end_token: Any) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Add begin/end of sentence tokens to the batch of sentences.\n    Given a batch of sentences with size ``(batch_size, timesteps)`` or\n    ``(batch_size, timesteps, dim)`` this returns a tensor of shape\n    ``(batch_size, timesteps + 2)`` or ``(batch_size, timesteps + 2, dim)`` respectively.\n\n    Returns both the new tensor and updated mask.\n\n    Parameters\n    ----------\n    tensor : ``torch.Tensor``\n        A tensor of shape ``(batch_size, timesteps)`` or ``(batch_size, timesteps, dim)``\n    mask : ``torch.Tensor``\n         A tensor of shape ``(batch_size, timesteps)``\n    sentence_begin_token: Any (anything that can be broadcast in torch for assignment)\n        For 2D input, a scalar with the <S> id. For 3D input, a tensor with length dim.\n    sentence_end_token: Any (anything that can be broadcast in torch for assignment)\n        For 2D input, a scalar with the </S> id. For 3D input, a tensor with length dim.\n\n    Returns\n    -------\n    tensor_with_boundary_tokens : ``torch.Tensor``\n        The tensor with the appended and prepended boundary tokens. If the input was 2D,\n        it has shape (batch_size, timesteps + 2) and if the input was 3D, it has shape\n        (batch_size, timesteps + 2, dim).\n    new_mask : ``torch.Tensor``\n        The new mask for the tensor, taking into account the appended tokens\n        marking the beginning and end of the sentence.\n    \"\"\"\n    # TODO: matthewp, profile this transfer\n    sequence_lengths = mask.sum(dim=1).detach().cpu().numpy()\n    tensor_shape = list(tensor.data.shape)\n    new_shape = list(tensor_shape)\n    new_shape[1] = tensor_shape[1] + 2\n    tensor_with_boundary_tokens = tensor.new_zeros(*new_shape)\n    if len(tensor_shape) == 2:\n        tensor_with_boundary_tokens[:, 1:-1] = tensor\n        tensor_with_boundary_tokens[:, 0] = sentence_begin_token\n        for i, j in enumerate(sequence_lengths):\n            tensor_with_boundary_tokens[i, j + 1] = sentence_end_token\n        new_mask = (tensor_with_boundary_tokens != 0).long()\n    elif len(tensor_shape) == 3:\n        tensor_with_boundary_tokens[:, 1:-1, :] = tensor\n        for i, j in enumerate(sequence_lengths):\n            tensor_with_boundary_tokens[i, 0, :] = sentence_begin_token\n            tensor_with_boundary_tokens[i, j + 1, :] = sentence_end_token\n        new_mask = ((tensor_with_boundary_tokens > 0).long().sum(dim=-1) > 0).long()\n    else:\n        raise ValueError(\"add_sentence_boundary_token_ids only accepts 2D and 3D input\")\n\n    return tensor_with_boundary_tokens, new_mask", "response": "Add begin and end of sentence tokens to the batch of sentences."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_sentence_boundaries(tensor: torch.Tensor,\n                               mask: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Remove begin/end of sentence embeddings from the batch of sentences.\n    Given a batch of sentences with size ``(batch_size, timesteps, dim)``\n    this returns a tensor of shape ``(batch_size, timesteps - 2, dim)`` after removing\n    the beginning and end sentence markers.  The sentences are assumed to be padded on the right,\n    with the beginning of each sentence assumed to occur at index 0 (i.e., ``mask[:, 0]`` is assumed\n    to be 1).\n\n    Returns both the new tensor and updated mask.\n\n    This function is the inverse of ``add_sentence_boundary_token_ids``.\n\n    Parameters\n    ----------\n    tensor : ``torch.Tensor``\n        A tensor of shape ``(batch_size, timesteps, dim)``\n    mask : ``torch.Tensor``\n         A tensor of shape ``(batch_size, timesteps)``\n\n    Returns\n    -------\n    tensor_without_boundary_tokens : ``torch.Tensor``\n        The tensor after removing the boundary tokens of shape ``(batch_size, timesteps - 2, dim)``\n    new_mask : ``torch.Tensor``\n        The new mask for the tensor of shape ``(batch_size, timesteps - 2)``.\n    \"\"\"\n    # TODO: matthewp, profile this transfer\n    sequence_lengths = mask.sum(dim=1).detach().cpu().numpy()\n    tensor_shape = list(tensor.data.shape)\n    new_shape = list(tensor_shape)\n    new_shape[1] = tensor_shape[1] - 2\n    tensor_without_boundary_tokens = tensor.new_zeros(*new_shape)\n    new_mask = tensor.new_zeros((new_shape[0], new_shape[1]), dtype=torch.long)\n    for i, j in enumerate(sequence_lengths):\n        if j > 2:\n            tensor_without_boundary_tokens[i, :(j - 2), :] = tensor[i, 1:(j - 1), :]\n            new_mask[i, :(j - 2)] = 1\n\n    return tensor_without_boundary_tokens, new_mask", "response": "Removes the sentence boundaries from the batch of sentences."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_positional_features(tensor: torch.Tensor,\n                            min_timescale: float = 1.0,\n                            max_timescale: float = 1.0e4):\n    # pylint: disable=line-too-long\n    \"\"\"\n    Implements the frequency-based positional encoding described\n    in `Attention is all you Need\n    <https://www.semanticscholar.org/paper/Attention-Is-All-You-Need-Vaswani-Shazeer/0737da0767d77606169cbf4187b83e1ab62f6077>`_ .\n\n    Adds sinusoids of different frequencies to a ``Tensor``. A sinusoid of a\n    different frequency and phase is added to each dimension of the input ``Tensor``.\n    This allows the attention heads to use absolute and relative positions.\n\n    The number of timescales is equal to hidden_dim / 2 within the range\n    (min_timescale, max_timescale). For each timescale, the two sinusoidal\n    signals sin(timestep / timescale) and cos(timestep / timescale) are\n    generated and concatenated along the hidden_dim dimension.\n\n    Parameters\n    ----------\n    tensor : ``torch.Tensor``\n        a Tensor with shape (batch_size, timesteps, hidden_dim).\n    min_timescale : ``float``, optional (default = 1.0)\n        The smallest timescale to use.\n    max_timescale : ``float``, optional (default = 1.0e4)\n        The largest timescale to use.\n\n    Returns\n    -------\n    The input tensor augmented with the sinusoidal frequencies.\n    \"\"\"\n    _, timesteps, hidden_dim = tensor.size()\n\n    timestep_range = get_range_vector(timesteps, get_device_of(tensor)).data.float()\n    # We're generating both cos and sin frequencies,\n    # so half for each.\n    num_timescales = hidden_dim // 2\n    timescale_range = get_range_vector(num_timescales, get_device_of(tensor)).data.float()\n\n    log_timescale_increments = math.log(float(max_timescale) / float(min_timescale)) / float(num_timescales - 1)\n    inverse_timescales = min_timescale * torch.exp(timescale_range * -log_timescale_increments)\n\n    # Broadcasted multiplication - shape (timesteps, num_timescales)\n    scaled_time = timestep_range.unsqueeze(1) * inverse_timescales.unsqueeze(0)\n    # shape (timesteps, 2 * num_timescales)\n    sinusoids = torch.cat([torch.sin(scaled_time), torch.cos(scaled_time)], 1)\n    if hidden_dim % 2 != 0:\n        # if the number of dimensions is odd, the cos and sin\n        # timescales had size (hidden_dim - 1) / 2, so we need\n        # to add a row of zeros to make up the difference.\n        sinusoids = torch.cat([sinusoids, sinusoids.new_zeros(timesteps, 1)], 1)\n    return tensor + sinusoids.unsqueeze(0)", "response": "A function that adds positional features to a base - 2 vocab."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nproduce N identical layers.", "response": "def clone(module: torch.nn.Module, num_copies: int) -> torch.nn.ModuleList:\n    \"\"\"Produce N identical layers.\"\"\"\n    return torch.nn.ModuleList([copy.deepcopy(module) for _ in range(num_copies)])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef combine_initial_dims(tensor: torch.Tensor) -> torch.Tensor:\n    if tensor.dim() <= 2:\n        return tensor\n    else:\n        return tensor.view(-1, tensor.size(-1))", "response": "Combine initial dimensions of a sequence of ids with shape\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef uncombine_initial_dims(tensor: torch.Tensor, original_size: torch.Size) -> torch.Tensor:\n    if len(original_size) <= 2:\n        return tensor\n    else:\n        view_args = list(original_size) + [tensor.size(-1)]\n        return tensor.view(*view_args)", "response": "Unbine initial dimensions of a single node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the string occurs in the table and returns the names of the columns that occur in the table.", "response": "def _string_in_table(self, candidate: str) -> List[str]:\n        \"\"\"\n        Checks if the string occurs in the table, and if it does, returns the names of the columns\n        under which it occurs. If it does not, returns an empty list.\n        \"\"\"\n        candidate_column_names: List[str] = []\n        # First check if the entire candidate occurs as a cell.\n        if candidate in self._string_column_mapping:\n            candidate_column_names = self._string_column_mapping[candidate]\n        # If not, check if it is a substring pf any cell value.\n        if not candidate_column_names:\n            for cell_value, column_names in self._string_column_mapping.items():\n                if candidate in cell_value:\n                    candidate_column_names.extend(column_names)\n        candidate_column_names = list(set(candidate_column_names))\n        return candidate_column_names"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef normalize_string(string: str) -> str:\n        # Normalization rules from Sempre\n        # \\u201A -> ,\n        string = re.sub(\"\u201a\", \",\", string)\n        string = re.sub(\"\u201e\", \",,\", string)\n        string = re.sub(\"[\u00b7\u30fb]\", \".\", string)\n        string = re.sub(\"\u2026\", \"...\", string)\n        string = re.sub(\"\u02c6\", \"^\", string)\n        string = re.sub(\"\u02dc\", \"~\", string)\n        string = re.sub(\"\u2039\", \"<\", string)\n        string = re.sub(\"\u203a\", \">\", string)\n        string = re.sub(\"[\u2018\u2019\u00b4`]\", \"'\", string)\n        string = re.sub(\"[\u201c\u201d\u00ab\u00bb]\", \"\\\"\", string)\n        string = re.sub(\"[\u2022\u2020\u2021\u00b2\u00b3]\", \"\", string)\n        string = re.sub(\"[\u2010\u2011\u2013\u2014\u2212]\", \"-\", string)\n        # Oddly, some unicode characters get converted to _ instead of being stripped.  Not really\n        # sure how sempre decides what to do with these...  TODO(mattg): can we just get rid of the\n        # need for this function somehow?  It's causing a whole lot of headaches.\n        string = re.sub(\"[\u00f0\u00f8\u2032\u2033\u20ac\u2044\u00aa\u03a3]\", \"_\", string)\n        # This is such a mess.  There isn't just a block of unicode that we can strip out, because\n        # sometimes sempre just strips diacritics...  We'll try stripping out a few separate\n        # blocks, skipping the ones that sempre skips...\n        string = re.sub(\"[\\\\u0180-\\\\u0210]\", \"\", string).strip()\n        string = re.sub(\"[\\\\u0220-\\\\uFFFF]\", \"\", string).strip()\n        string = string.replace(\"\\\\n\", \"_\")\n        string = re.sub(\"\\\\s+\", \" \", string)\n        # Canonicalization rules from Sempre.\n        string = re.sub(\"[^\\\\w]\", \"_\", string)\n        string = re.sub(\"_+\", \"_\", string)\n        string = re.sub(\"_$\", \"\", string)\n        return unidecode(string.lower())", "response": "Normalizes a string according to Sempre s rules."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef lisp_to_nested_expression(lisp_string: str) -> List:\n    stack: List = []\n    current_expression: List = []\n    tokens = lisp_string.split()\n    for token in tokens:\n        while token[0] == '(':\n            nested_expression: List = []\n            current_expression.append(nested_expression)\n            stack.append(current_expression)\n            current_expression = nested_expression\n            token = token[1:]\n        current_expression.append(token.replace(')', ''))\n        while token[-1] == ')':\n            current_expression = stack.pop()\n            token = token[:-1]\n    return current_expression[0]", "response": "Takes a logical form as a lisp string and returns a nested list representation of the lisp string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef batch_to_embeddings(self, batch: List[List[str]]) -> Tuple[torch.Tensor, torch.Tensor]:\n        character_ids = batch_to_ids(batch)\n        if self.cuda_device >= 0:\n            character_ids = character_ids.cuda(device=self.cuda_device)\n\n        bilm_output = self.elmo_bilm(character_ids)\n        layer_activations = bilm_output['activations']\n        mask_with_bos_eos = bilm_output['mask']\n\n        # without_bos_eos is a 3 element list of (activation, mask) tensor pairs,\n        # each with size (batch_size, num_timesteps, dim and (batch_size, num_timesteps)\n        # respectively.\n        without_bos_eos = [remove_sentence_boundaries(layer, mask_with_bos_eos)\n                           for layer in layer_activations]\n        # Converts a list of pairs (activation, mask) tensors to a single tensor of activations.\n        activations = torch.cat([ele[0].unsqueeze(1) for ele in without_bos_eos], dim=1)\n        # The mask is the same for each ELMo vector, so just take the first.\n        mask = without_bos_eos[0][1]\n\n        return activations, mask", "response": "Converts a batch of sentences to an embeddings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the ELMo embeddings for a single tokenized sentence.", "response": "def embed_sentence(self, sentence: List[str]) -> numpy.ndarray:\n        \"\"\"\n        Computes the ELMo embeddings for a single tokenized sentence.\n\n        Please note that ELMo has internal state and will give different results for the same input.\n        See the comment under the class definition.\n\n        Parameters\n        ----------\n        sentence : ``List[str]``, required\n            A tokenized sentence.\n\n        Returns\n        -------\n        A tensor containing the ELMo vectors.\n        \"\"\"\n\n        return self.embed_batch([sentence])[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the ELMo embeddings for a batch of tokenized sentences.", "response": "def embed_batch(self, batch: List[List[str]]) -> List[numpy.ndarray]:\n        \"\"\"\n        Computes the ELMo embeddings for a batch of tokenized sentences.\n\n        Please note that ELMo has internal state and will give different results for the same input.\n        See the comment under the class definition.\n\n        Parameters\n        ----------\n        batch : ``List[List[str]]``, required\n            A list of tokenized sentences.\n\n        Returns\n        -------\n            A list of tensors, each representing the ELMo vectors for the input sentence at the same index.\n        \"\"\"\n        elmo_embeddings = []\n\n        # Batches with only an empty sentence will throw an exception inside AllenNLP, so we handle this case\n        # and return an empty embedding instead.\n        if batch == [[]]:\n            elmo_embeddings.append(empty_embedding())\n        else:\n            embeddings, mask = self.batch_to_embeddings(batch)\n            for i in range(len(batch)):\n                length = int(mask[i, :].sum())\n                # Slicing the embedding :0 throws an exception so we need to special case for empty sentences.\n                if length == 0:\n                    elmo_embeddings.append(empty_embedding())\n                else:\n                    elmo_embeddings.append(embeddings[i, :, :length, :].detach().cpu().numpy())\n\n        return elmo_embeddings"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef embed_sentences(self,\n                        sentences: Iterable[List[str]],\n                        batch_size: int = DEFAULT_BATCH_SIZE) -> Iterable[numpy.ndarray]:\n        \"\"\"\n        Computes the ELMo embeddings for a iterable of sentences.\n\n        Please note that ELMo has internal state and will give different results for the same input.\n        See the comment under the class definition.\n\n        Parameters\n        ----------\n        sentences : ``Iterable[List[str]]``, required\n            An iterable of tokenized sentences.\n        batch_size : ``int``, required\n            The number of sentences ELMo should process at once.\n\n        Returns\n        -------\n            A list of tensors, each representing the ELMo vectors for the input sentence at the same index.\n        \"\"\"\n        for batch in lazy_groups_of(iter(sentences), batch_size):\n            yield from self.embed_batch(batch)", "response": "Given a list of tokenized sentences and a batch size embeds them into a single ELMo vector."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nembeds a file into a new hdf5 file.", "response": "def embed_file(self,\n                   input_file: IO,\n                   output_file_path: str,\n                   output_format: str = \"all\",\n                   batch_size: int = DEFAULT_BATCH_SIZE,\n                   forget_sentences: bool = False,\n                   use_sentence_keys: bool = False) -> None:\n        \"\"\"\n        Computes ELMo embeddings from an input_file where each line contains a sentence tokenized by whitespace.\n        The ELMo embeddings are written out in HDF5 format, where each sentence embedding\n        is saved in a dataset with the line number in the original file as the key.\n\n        Parameters\n        ----------\n        input_file : ``IO``, required\n            A file with one tokenized sentence per line.\n        output_file_path : ``str``, required\n            A path to the output hdf5 file.\n        output_format : ``str``, optional, (default = \"all\")\n            The embeddings to output.  Must be one of \"all\", \"top\", or \"average\".\n        batch_size : ``int``, optional, (default = 64)\n            The number of sentences to process in ELMo at one time.\n        forget_sentences : ``bool``, optional, (default = False).\n            If use_sentence_keys is False, whether or not to include a string\n            serialized JSON dictionary that associates sentences with their\n            line number (its HDF5 key). The mapping is placed in the\n            \"sentence_to_index\" HDF5 key. This is useful if\n            you want to use the embeddings without keeping the original file\n            of sentences around.\n        use_sentence_keys : ``bool``, optional, (default = False).\n            Whether or not to use full sentences as keys. By default,\n            the line numbers of the input file are used as ids, which is more robust.\n        \"\"\"\n\n        assert output_format in [\"all\", \"top\", \"average\"]\n\n        # Tokenizes the sentences.\n        sentences = [line.strip() for line in input_file]\n\n        blank_lines = [i for (i, line) in enumerate(sentences) if line == \"\"]\n        if blank_lines:\n            raise ConfigurationError(f\"Your input file contains empty lines at indexes \"\n                                     f\"{blank_lines}. Please remove them.\")\n        split_sentences = [sentence.split() for sentence in sentences]\n        # Uses the sentence index as the key.\n\n        if use_sentence_keys:\n            logger.warning(\"Using sentences as keys can fail if sentences \"\n                           \"contain forward slashes or colons. Use with caution.\")\n            embedded_sentences = zip(sentences, self.embed_sentences(split_sentences, batch_size))\n        else:\n            embedded_sentences = ((str(i), x) for i, x in\n                                  enumerate(self.embed_sentences(split_sentences, batch_size)))\n\n        sentence_to_index = {}\n        logger.info(\"Processing sentences.\")\n        with h5py.File(output_file_path, 'w') as fout:\n            for key, embeddings in Tqdm.tqdm(embedded_sentences):\n                if use_sentence_keys and key in fout.keys():\n                    raise ConfigurationError(f\"Key already exists in {output_file_path}. \"\n                                             f\"To encode duplicate sentences, do not pass \"\n                                             f\"the --use-sentence-keys flag.\")\n\n                if not forget_sentences and not use_sentence_keys:\n                    sentence = sentences[int(key)]\n                    sentence_to_index[sentence] = key\n\n                if output_format == \"all\":\n                    output = embeddings\n                elif output_format == \"top\":\n                    output = embeddings[-1]\n                elif output_format == \"average\":\n                    output = numpy.average(embeddings, axis=0)\n\n                fout.create_dataset(\n                        str(key),\n                        output.shape, dtype='float32',\n                        data=output\n                )\n            if not forget_sentences and not use_sentence_keys:\n                sentence_index_dataset = fout.create_dataset(\n                        \"sentence_to_index\",\n                        (1,),\n                        dtype=h5py.special_dtype(vlen=str))\n                sentence_index_dataset[0] = json.dumps(sentence_to_index)\n\n        input_file.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds the field to the existing fields mapping.", "response": "def add_field(self, field_name: str, field: Field, vocab: Vocabulary = None) -> None:\n        \"\"\"\n        Add the field to the existing fields mapping.\n        If we have already indexed the Instance, then we also index `field`, so\n        it is necessary to supply the vocab.\n        \"\"\"\n        self.fields[field_name] = field\n        if self.indexed:\n            field.index(vocab)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nincrement counts in the given counter for all of the vocabulary items in all of the fields in this instance.", "response": "def count_vocab_items(self, counter: Dict[str, Dict[str, int]]):\n        \"\"\"\n        Increments counts in the given ``counter`` for all of the vocabulary items in all of the\n        ``Fields`` in this ``Instance``.\n        \"\"\"\n        for field in self.fields.values():\n            field.count_vocab_items(counter)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nindex all fields in this instance using the provided vocabulary.", "response": "def index_fields(self, vocab: Vocabulary) -> None:\n        \"\"\"\n        Indexes all fields in this ``Instance`` using the provided ``Vocabulary``.\n        This `mutates` the current object, it does not return a new ``Instance``.\n        A ``DataIterator`` will call this on each pass through a dataset; we use the ``indexed``\n        flag to make sure that indexing only happens once.\n\n        This means that if for some reason you modify your vocabulary after you've\n        indexed your instances, you might get unexpected behavior.\n        \"\"\"\n        if not self.indexed:\n            self.indexed = True\n            for field in self.fields.values():\n                field.index(vocab)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dictionary of padding lengths keyed by field name.", "response": "def get_padding_lengths(self) -> Dict[str, Dict[str, int]]:\n        \"\"\"\n        Returns a dictionary of padding lengths, keyed by field name.  Each ``Field`` returns a\n        mapping from padding keys to actual lengths, and we just key that dictionary by field name.\n        \"\"\"\n        lengths = {}\n        for field_name, field in self.fields.items():\n            lengths[field_name] = field.get_padding_lengths()\n        return lengths"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dictionary of torch tensors for each field in this instance.", "response": "def as_tensor_dict(self,\n                       padding_lengths: Dict[str, Dict[str, int]] = None) -> Dict[str, DataArray]:\n        \"\"\"\n        Pads each ``Field`` in this instance to the lengths given in ``padding_lengths`` (which is\n        keyed by field name, then by padding key, the same as the return value in\n        :func:`get_padding_lengths`), returning a list of torch tensors for each field.\n\n        If ``padding_lengths`` is omitted, we will call ``self.get_padding_lengths()`` to get the\n        sizes of the tensors to create.\n        \"\"\"\n        padding_lengths = padding_lengths or self.get_padding_lengths()\n        tensors = {}\n        for field_name, field in self.fields.items():\n            tensors[field_name] = field.as_tensor(padding_lengths[field_name])\n        return tensors"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef full_name(cla55: Optional[type]) -> str:\n    # Special case to handle None:\n    if cla55 is None:\n        return \"?\"\n\n    if issubclass(cla55, Initializer) and cla55 not in [Initializer, PretrainedModelInitializer]:\n        init_fn = cla55()._init_function\n        return f\"{init_fn.__module__}.{init_fn.__name__}\"\n\n    origin = getattr(cla55, '__origin__', None)\n    args = getattr(cla55, '__args__', ())\n\n    # Special handling for compound types\n    if origin in (Dict, dict):\n        key_type, value_type = args\n        return f\"\"\"Dict[{full_name(key_type)}, {full_name(value_type)}]\"\"\"\n    elif origin in (Tuple, tuple, List, list, Sequence, collections.abc.Sequence):\n        return f\"\"\"{_remove_prefix(str(origin))}[{\", \".join(full_name(arg) for arg in args)}]\"\"\"\n    elif origin == Union:\n        # Special special case to handle optional types:\n        if len(args) == 2 and args[-1] == type(None):\n            return f\"\"\"Optional[{full_name(args[0])}]\"\"\"\n        else:\n            return f\"\"\"Union[{\", \".join(full_name(arg) for arg in args)}]\"\"\"\n    else:\n        return _remove_prefix(f\"{cla55.__module__}.{cla55.__name__}\")", "response": "Returns the full name of the given class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_config_type(cla55: type) -> Optional[str]:\n    # Special handling for pytorch RNN types:\n    if cla55 == torch.nn.RNN:\n        return \"rnn\"\n    elif cla55 == torch.nn.LSTM:\n        return \"lstm\"\n    elif cla55 == torch.nn.GRU:\n        return \"gru\"\n\n    for subclass_dict in Registrable._registry.values():\n        for name, subclass in subclass_dict.items():\n            if subclass == cla55:\n                return name\n\n        # Special handling for initializer functions\n            if hasattr(subclass, '_initializer_wrapper'):\n                sif = subclass()._init_function\n                if sif == cla55:\n                    return sif.__name__.rstrip(\"_\")\n\n    return None", "response": "Returns the name of the config type that a subclass was registered under."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninspect the docstring and get the comments for each parameter.", "response": "def _docspec_comments(obj) -> Dict[str, str]:\n    \"\"\"\n    Inspect the docstring and get the comments for each parameter.\n    \"\"\"\n    # Sometimes our docstring is on the class, and sometimes it's on the initializer,\n    # so we've got to check both.\n    class_docstring = getattr(obj, '__doc__', None)\n    init_docstring = getattr(obj.__init__, '__doc__', None) if hasattr(obj, '__init__') else None\n\n    docstring = class_docstring or init_docstring or ''\n\n    doc = NumpyDocString(docstring)\n    params = doc[\"Parameters\"]\n    comments: Dict[str, str] = {}\n\n    for line in params:\n        # It looks like when there's not a space after the parameter name,\n        # numpydocstring parses it incorrectly.\n        name_bad = line[0]\n        name = name_bad.split(\":\")[0]\n\n        # Sometimes the line has 3 fields, sometimes it has 4 fields.\n        comment = \"\\n\".join(line[-1])\n\n        comments[name] = comment\n\n    return comments"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _auto_config(cla55: Type[T]) -> Config[T]:\n    typ3 = _get_config_type(cla55)\n\n    # Don't include self, or vocab\n    names_to_ignore = {\"self\", \"vocab\"}\n\n    # Hack for RNNs\n    if cla55 in [torch.nn.RNN, torch.nn.LSTM, torch.nn.GRU]:\n        cla55 = torch.nn.RNNBase\n        names_to_ignore.add(\"mode\")\n\n    if isinstance(cla55, type):\n        # It's a class, so inspect its constructor\n        function_to_inspect = cla55.__init__\n    else:\n        # It's a function, so inspect it, and ignore tensor\n        function_to_inspect = cla55\n        names_to_ignore.add(\"tensor\")\n\n    argspec = inspect.getfullargspec(function_to_inspect)\n    comments = _docspec_comments(cla55)\n\n    items: List[ConfigItem] = []\n\n    num_args = len(argspec.args)\n    defaults = list(argspec.defaults or [])\n    num_default_args = len(defaults)\n    num_non_default_args = num_args - num_default_args\n\n    # Required args all come first, default args at the end.\n    defaults = [_NO_DEFAULT for _ in range(num_non_default_args)] + defaults\n\n    for name, default in zip(argspec.args, defaults):\n        if name in names_to_ignore:\n            continue\n        annotation = argspec.annotations.get(name)\n        comment = comments.get(name)\n\n        # Don't include Model, the only place you'd specify that is top-level.\n        if annotation == Model:\n            continue\n\n        # Don't include DataIterator, the only place you'd specify that is top-level.\n        if annotation == DataIterator:\n            continue\n\n        # Don't include params for an Optimizer\n        if torch.optim.Optimizer in getattr(cla55, '__bases__', ()) and name == \"params\":\n            continue\n\n        # Don't include datasets in the trainer\n        if cla55 == Trainer and name.endswith(\"_dataset\"):\n            continue\n\n        # Hack in our Optimizer class to the trainer\n        if cla55 == Trainer and annotation == torch.optim.Optimizer:\n            annotation = AllenNLPOptimizer\n\n        # Hack in embedding num_embeddings as optional (it can be inferred from the pretrained file)\n        if cla55 == Embedding and name == \"num_embeddings\":\n            default = None\n\n        items.append(ConfigItem(name, annotation, default, comment))\n\n    # More hacks, Embedding\n    if cla55 == Embedding:\n        items.insert(1, ConfigItem(\"pretrained_file\", str, None))\n\n    return Config(items, typ3=typ3)", "response": "Auto - creates a new Config for a class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render_config(config: Config, indent: str = \"\") -> str:\n    # Add four spaces to the indent.\n    new_indent = indent + \"    \"\n\n    return \"\".join([\n            # opening brace + newline\n            \"{\\n\",\n            # \"type\": \"...\", (if present)\n            f'{new_indent}\"type\": \"{config.typ3}\",\\n' if config.typ3 else '',\n            # render each item\n            \"\".join(_render(item, new_indent) for item in config.items),\n            # indent and close the brace\n            indent,\n            \"}\\n\"\n    ])", "response": "Pretty - print a config in sort - of - JSON + comments."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _render(item: ConfigItem, indent: str = \"\") -> str:\n    optional = item.default_value != _NO_DEFAULT\n\n    if is_configurable(item.annotation):\n        rendered_annotation = f\"{item.annotation} (configurable)\"\n    else:\n        rendered_annotation = str(item.annotation)\n\n    rendered_item = \"\".join([\n            # rendered_comment,\n            indent,\n            \"// \" if optional else \"\",\n            f'\"{item.name}\": ',\n            rendered_annotation,\n            f\" (default: {item.default_value} )\" if optional else \"\",\n            f\" // {item.comment}\" if item.comment else \"\",\n            \"\\n\"\n    ])\n\n    return rendered_item", "response": "Render a single config item with the provided indent"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a mapping from registered_name to subclass_name", "response": "def _valid_choices(cla55: type) -> Dict[str, str]:\n    \"\"\"\n    Return a mapping {registered_name -> subclass_name}\n    for the registered subclasses of `cla55`.\n    \"\"\"\n    valid_choices: Dict[str, str] = {}\n\n    if cla55 not in Registrable._registry:\n        raise ValueError(f\"{cla55} is not a known Registrable class\")\n\n    for name, subclass in Registrable._registry[cla55].items():\n        # These wrapper classes need special treatment\n        if isinstance(subclass, (_Seq2SeqWrapper, _Seq2VecWrapper)):\n            subclass = subclass._module_class\n\n        valid_choices[name] = full_name(subclass)\n\n    return valid_choices"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef url_to_filename(url: str, etag: str = None) -> str:\n    url_bytes = url.encode('utf-8')\n    url_hash = sha256(url_bytes)\n    filename = url_hash.hexdigest()\n\n    if etag:\n        etag_bytes = etag.encode('utf-8')\n        etag_hash = sha256(etag_bytes)\n        filename += '.' + etag_hash.hexdigest()\n\n    return filename", "response": "Convert a url into a hashed filename in a repeatable way."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the url and etag for a given filename.", "response": "def filename_to_url(filename: str, cache_dir: str = None) -> Tuple[str, str]:\n    \"\"\"\n    Return the url and etag (which may be ``None``) stored for `filename`.\n    Raise ``FileNotFoundError`` if `filename` or its stored metadata do not exist.\n    \"\"\"\n    if cache_dir is None:\n        cache_dir = CACHE_DIRECTORY\n\n    cache_path = os.path.join(cache_dir, filename)\n    if not os.path.exists(cache_path):\n        raise FileNotFoundError(\"file {} not found\".format(cache_path))\n\n    meta_path = cache_path + '.json'\n    if not os.path.exists(meta_path):\n        raise FileNotFoundError(\"file {} not found\".format(meta_path))\n\n    with open(meta_path) as meta_file:\n        metadata = json.load(meta_file)\n    url = metadata['url']\n    etag = metadata['etag']\n\n    return url, etag"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cached_path(url_or_filename: Union[str, Path], cache_dir: str = None) -> str:\n    if cache_dir is None:\n        cache_dir = CACHE_DIRECTORY\n    if isinstance(url_or_filename, Path):\n        url_or_filename = str(url_or_filename)\n\n    url_or_filename = os.path.expanduser(url_or_filename)\n    parsed = urlparse(url_or_filename)\n\n    if parsed.scheme in ('http', 'https', 's3'):\n        # URL, so get it from the cache (downloading if necessary)\n        return get_from_cache(url_or_filename, cache_dir)\n    elif os.path.exists(url_or_filename):\n        # File, and it exists.\n        return url_or_filename\n    elif parsed.scheme == '':\n        # File, but it doesn't exist.\n        raise FileNotFoundError(\"file {} not found\".format(url_or_filename))\n    else:\n        # Something unknown\n        raise ValueError(\"unable to parse {} as a URL or as a local path\".format(url_or_filename))", "response": "Given something that might be a URL or a local path determine which."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_url_or_existing_file(url_or_filename: Union[str, Path, None]) -> bool:\n    if url_or_filename is None:\n        return False\n    url_or_filename = os.path.expanduser(str(url_or_filename))\n    parsed = urlparse(url_or_filename)\n    return parsed.scheme in ('http', 'https', 's3') or os.path.exists(url_or_filename)", "response": "Determines if a URL or an existing file path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsplit a full s3 path into the bucket name and path.", "response": "def split_s3_path(url: str) -> Tuple[str, str]:\n    \"\"\"Split a full s3 path into the bucket name and path.\"\"\"\n    parsed = urlparse(url)\n    if not parsed.netloc or not parsed.path:\n        raise ValueError(\"bad s3 path {}\".format(url))\n    bucket_name = parsed.netloc\n    s3_path = parsed.path\n    # Remove '/' at beginning of path.\n    if s3_path.startswith(\"/\"):\n        s3_path = s3_path[1:]\n    return bucket_name, s3_path"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrap function for s3 requests in order to create more helpful error messages.", "response": "def s3_request(func: Callable):\n    \"\"\"\n    Wrapper function for s3 requests in order to create more helpful error\n    messages.\n    \"\"\"\n\n    @wraps(func)\n    def wrapper(url: str, *args, **kwargs):\n        try:\n            return func(url, *args, **kwargs)\n        except ClientError as exc:\n            if int(exc.response[\"Error\"][\"Code\"]) == 404:\n                raise FileNotFoundError(\"file {} not found\".format(url))\n            else:\n                raise\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef s3_etag(url: str) -> Optional[str]:\n    s3_resource = boto3.resource(\"s3\")\n    bucket_name, s3_path = split_s3_path(url)\n    s3_object = s3_resource.Object(bucket_name, s3_path)\n    return s3_object.e_tag", "response": "Check ETag on S3 object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef s3_get(url: str, temp_file: IO) -> None:\n    s3_resource = boto3.resource(\"s3\")\n    bucket_name, s3_path = split_s3_path(url)\n    s3_resource.Bucket(bucket_name).download_fileobj(s3_path, temp_file)", "response": "Pull a file directly from S3."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_from_cache(url: str, cache_dir: str = None) -> str:\n    if cache_dir is None:\n        cache_dir = CACHE_DIRECTORY\n\n    os.makedirs(cache_dir, exist_ok=True)\n\n    # Get eTag to add to filename, if it exists.\n    if url.startswith(\"s3://\"):\n        etag = s3_etag(url)\n    else:\n        response = requests.head(url, allow_redirects=True)\n        if response.status_code != 200:\n            raise IOError(\"HEAD request failed for url {} with status code {}\"\n                          .format(url, response.status_code))\n        etag = response.headers.get(\"ETag\")\n\n    filename = url_to_filename(url, etag)\n\n    # get cache path to put the file\n    cache_path = os.path.join(cache_dir, filename)\n\n    if not os.path.exists(cache_path):\n        # Download to temporary file, then copy to cache dir once finished.\n        # Otherwise you get corrupt cache entries if the download gets interrupted.\n        with tempfile.NamedTemporaryFile() as temp_file:\n            logger.info(\"%s not found in cache, downloading to %s\", url, temp_file.name)\n\n            # GET file object\n            if url.startswith(\"s3://\"):\n                s3_get(url, temp_file)\n            else:\n                http_get(url, temp_file)\n\n            # we are copying the file before closing it, so flush to avoid truncation\n            temp_file.flush()\n            # shutil.copyfileobj() starts at the current position, so go to the start\n            temp_file.seek(0)\n\n            logger.info(\"copying %s to cache at %s\", temp_file.name, cache_path)\n            with open(cache_path, 'wb') as cache_file:\n                shutil.copyfileobj(temp_file, cache_file)\n\n            logger.info(\"creating metadata file for %s\", cache_path)\n            meta = {'url': url, 'etag': etag}\n            meta_path = cache_path + '.json'\n            with open(meta_path, 'w') as meta_file:\n                json.dump(meta, meta_file)\n\n            logger.info(\"removing temp file %s\", temp_file.name)\n\n    return cache_path", "response": "Download a file from the local cache and return the path to the cached file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting a de - duped collection of text from a file.", "response": "def read_set_from_file(filename: str) -> Set[str]:\n    \"\"\"\n    Extract a de-duped collection (set) of text from a file.\n    Expected file format is one item per line.\n    \"\"\"\n    collection = set()\n    with open(filename, 'r') as file_:\n        for line in file_:\n            collection.add(line.rstrip())\n    return collection"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess the text2sql data into the following directory structure: ``dataset/{query_split, question_split}/{train,dev,test}.json`` for datasets which have train, dev and test splits, or: ``dataset/{query_split, question_split}/{split_{split_id}}.json`` for datasets which use cross validation. The JSON format is identical to the original datasets, apart from they are split into separate files with respect to the split_type. This means that for the question split, all of the sql data is duplicated for each sentence which is bucketed together as having the same semantics. As an example, the following blob would be put \"as-is\" into the query split dataset, and split into two datasets with identical blobs for the question split, differing only in the \"sentence\" key, where blob1 would end up in the train split and blob2 would be in the dev split, with the rest of the json duplicated in each. { \"comments\": [], \"old-name\": \"\", \"query-split\": \"train\", \"sentences\": [{blob1, \"question-split\": \"train\"}, {blob2, \"question-split\": \"dev\"}], \"sql\": [], \"variables\": [] }, Parameters ---------- output_directory : str, required. The output directory. data: str, default = None The path to the data director of https://github.com/jkkummerfeld/text2sql-data.", "response": "def main(output_directory: int, data: str) -> None:\n    \"\"\"\n    Processes the text2sql data into the following directory structure:\n\n    ``dataset/{query_split, question_split}/{train,dev,test}.json``\n\n    for datasets which have train, dev and test splits, or:\n\n    ``dataset/{query_split, question_split}/{split_{split_id}}.json``\n\n    for datasets which use cross validation.\n\n    The JSON format is identical to the original datasets, apart from they\n    are split into separate files with respect to the split_type. This means that\n    for the question split, all of the sql data is duplicated for each sentence\n    which is bucketed together as having the same semantics.\n\n    As an example, the following blob would be put \"as-is\" into the query split\n    dataset, and split into two datasets with identical blobs for the question split,\n    differing only in the \"sentence\" key, where blob1 would end up in the train split\n    and blob2 would be in the dev split, with the rest of the json duplicated in each.\n    {\n        \"comments\": [],\n        \"old-name\": \"\",\n        \"query-split\": \"train\",\n        \"sentences\": [{blob1, \"question-split\": \"train\"}, {blob2, \"question-split\": \"dev\"}],\n        \"sql\": [],\n        \"variables\": []\n    },\n\n    Parameters\n    ----------\n    output_directory : str, required.\n        The output directory.\n    data: str, default = None\n        The path to the data director of https://github.com/jkkummerfeld/text2sql-data.\n    \"\"\"\n    json_files = glob.glob(os.path.join(data, \"*.json\"))\n\n    for dataset in json_files:\n        dataset_name = os.path.basename(dataset)[:-5]\n        print(f\"Processing dataset: {dataset} into query and question \"\n              f\"splits at output path: {output_directory + '/' + dataset_name}\")\n        full_dataset = json.load(open(dataset))\n        if not isinstance(full_dataset, list):\n            full_dataset = [full_dataset]\n\n        for split_type in [\"query_split\", \"question_split\"]:\n            dataset_out = os.path.join(output_directory, dataset_name, split_type)\n\n            for split, split_dataset in process_dataset(full_dataset, split_type):\n                dataset_out = os.path.join(output_directory, dataset_name, split_type)\n                os.makedirs(dataset_out, exist_ok=True)\n                json.dump(split_dataset, open(os.path.join(dataset_out, split), \"w\"), indent=4)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resolve(self, other: Type) -> Optional[Type]:\n        if not isinstance(other, NltkComplexType):\n            return None\n        expected_second = ComplexType(NUMBER_TYPE,\n                                      ComplexType(ANY_TYPE, ComplexType(ComplexType(ANY_TYPE, ANY_TYPE),\n                                                                        ANY_TYPE)))\n        resolved_second = other.second.resolve(expected_second)\n        if resolved_second is None:\n            return None\n\n        # The lambda function that we use inside the argmax  must take either a number or a date as\n        # an argument.\n        lambda_arg_type = other.second.second.second.first.first\n        if lambda_arg_type.resolve(NUMBER_TYPE) is None and lambda_arg_type.resolve(DATE_TYPE) is None:\n            return None\n\n        try:\n            # This is the first #1 in the type signature above.\n            selector_function_type = resolved_second.second.first\n            # This is the second #1 in the type signature above.\n            quant_function_argument_type = resolved_second.second.second.first.second\n            # This is the third #1 in the type signature above.\n            return_type = resolved_second.second.second.second\n\n            # All three placeholder (ph) types above should resolve against each other.\n            resolved_first_ph = selector_function_type.resolve(quant_function_argument_type)\n            resolved_first_ph.resolve(return_type)\n\n            resolved_second_ph = quant_function_argument_type.resolve(resolved_first_ph)\n            resolved_second_ph.resolve(return_type)\n\n            resolved_third_ph = return_type.resolve(resolved_first_ph)\n            resolved_third_ph = return_type.resolve(resolved_second_ph)\n\n            if not resolved_first_ph or not resolved_second_ph or not resolved_third_ph:\n                return None\n\n            return ArgExtremeType(resolved_first_ph, lambda_arg_type)\n        except AttributeError:\n            return None", "response": "Resolves the type signature of two NltkComplexTypes and returns the corresponding type."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresolves the type of other to the type of self.", "response": "def resolve(self, other: Type) -> Type:\n        \"\"\"See ``PlaceholderType.resolve``\"\"\"\n        if not isinstance(other, NltkComplexType):\n            return None\n        resolved_second = NUMBER_TYPE.resolve(other.second)\n        if not resolved_second:\n            return None\n        return CountType(other.first)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading an NLVR dataset and returns a JSON representation of the data.", "response": "def process_data(input_file: str,\n                 output_file: str,\n                 max_path_length: int,\n                 max_num_logical_forms: int,\n                 ignore_agenda: bool,\n                 write_sequences: bool) -> None:\n    \"\"\"\n    Reads an NLVR dataset and returns a JSON representation containing sentences, labels, correct and\n    incorrect logical forms. The output will contain at most `max_num_logical_forms` logical forms\n    each in both correct and incorrect lists. The output format is:\n        ``[{\"id\": str, \"label\": str, \"sentence\": str, \"correct\": List[str], \"incorrect\": List[str]}]``\n    \"\"\"\n    processed_data: JsonDict = []\n    # We can instantiate the ``ActionSpaceWalker`` with any world because the action space is the\n    # same for all the ``NlvrWorlds``. It is just the execution that differs.\n    serialized_walker_path = f\"serialized_action_space_walker_pl={max_path_length}.pkl\"\n    if os.path.isfile(serialized_walker_path):\n        print(\"Reading walker from serialized file\", file=sys.stderr)\n        walker = pickle.load(open(serialized_walker_path, \"rb\"))\n    else:\n        walker = ActionSpaceWalker(NlvrWorld({}), max_path_length=max_path_length)\n        pickle.dump(walker, open(serialized_walker_path, \"wb\"))\n    for line in open(input_file):\n        instance_id, sentence, structured_reps, label_strings = read_json_line(line)\n        worlds = [NlvrWorld(structured_rep) for structured_rep in structured_reps]\n        labels = [label_string == \"true\" for label_string in label_strings]\n        correct_logical_forms = []\n        incorrect_logical_forms = []\n        if ignore_agenda:\n            # Get 1000 shortest logical forms.\n            logical_forms = walker.get_all_logical_forms(max_num_logical_forms=1000)\n        else:\n            # TODO (pradeep): Assuming all worlds give the same agenda.\n            sentence_agenda = worlds[0].get_agenda_for_sentence(sentence, add_paths_to_agenda=False)\n            logical_forms = walker.get_logical_forms_with_agenda(sentence_agenda,\n                                                                 max_num_logical_forms * 10)\n        for logical_form in logical_forms:\n            if all([world.execute(logical_form) == label for world, label in zip(worlds, labels)]):\n                if len(correct_logical_forms) <= max_num_logical_forms:\n                    correct_logical_forms.append(logical_form)\n            else:\n                if len(incorrect_logical_forms) <= max_num_logical_forms:\n                    incorrect_logical_forms.append(logical_form)\n            if len(correct_logical_forms) >= max_num_logical_forms \\\n               and len(incorrect_logical_forms) >= max_num_logical_forms:\n                break\n        if write_sequences:\n            parsed_correct_forms = [worlds[0].parse_logical_form(logical_form) for logical_form in\n                                    correct_logical_forms]\n            correct_sequences = [worlds[0].get_action_sequence(parsed_form) for parsed_form in\n                                 parsed_correct_forms]\n            parsed_incorrect_forms = [worlds[0].parse_logical_form(logical_form) for logical_form in\n                                      incorrect_logical_forms]\n            incorrect_sequences = [worlds[0].get_action_sequence(parsed_form) for parsed_form in\n                                   parsed_incorrect_forms]\n            processed_data.append({\"id\": instance_id,\n                                   \"sentence\": sentence,\n                                   \"correct_sequences\": correct_sequences,\n                                   \"incorrect_sequences\": incorrect_sequences,\n                                   \"worlds\": structured_reps,\n                                   \"labels\": label_strings})\n        else:\n            processed_data.append({\"id\": instance_id,\n                                   \"sentence\": sentence,\n                                   \"correct_logical_forms\": correct_logical_forms,\n                                   \"incorrect_logical_forms\": incorrect_logical_forms,\n                                   \"worlds\": structured_reps,\n                                   \"labels\": label_strings})\n    with open(output_file, \"w\") as outfile:\n        for instance_processed_data in processed_data:\n            json.dump(instance_processed_data, outfile)\n            outfile.write('\\n')\n        outfile.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a list of annotations for a single word and a list of span labels and a list of current span labels compute the BIO tags for each annotation and append to a list of lists.", "response": "def _process_span_annotations_for_word(annotations: List[str],\n                                           span_labels: List[List[str]],\n                                           current_span_labels: List[Optional[str]]) -> None:\n        \"\"\"\n        Given a sequence of different label types for a single word and the current\n        span label we are inside, compute the BIO tag for each label and append to a list.\n\n        Parameters\n        ----------\n        annotations: ``List[str]``\n            A list of labels to compute BIO tags for.\n        span_labels : ``List[List[str]]``\n            A list of lists, one for each annotation, to incrementally collect\n            the BIO tags for a sequence.\n        current_span_labels : ``List[Optional[str]]``\n            The currently open span per annotation type, or ``None`` if there is no open span.\n        \"\"\"\n        for annotation_index, annotation in enumerate(annotations):\n            # strip all bracketing information to\n            # get the actual propbank label.\n            label = annotation.strip(\"()*\")\n\n            if \"(\" in annotation:\n                # Entering into a span for a particular semantic role label.\n                # We append the label and set the current span for this annotation.\n                bio_label = \"B-\" + label\n                span_labels[annotation_index].append(bio_label)\n                current_span_labels[annotation_index] = label\n            elif current_span_labels[annotation_index] is not None:\n                # If there's no '(' token, but the current_span_label is not None,\n                # then we are inside a span.\n                bio_label = \"I-\" + current_span_labels[annotation_index]\n                span_labels[annotation_index].append(bio_label)\n            else:\n                # We're outside a span.\n                span_labels[annotation_index].append(\"O\")\n            # Exiting a span, so we reset the current span label for this annotation.\n            if \")\" in annotation:\n                current_span_labels[annotation_index] = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef print_results_from_args(args: argparse.Namespace):\n    path = args.path\n    metrics_name = args.metrics_filename\n    keys = args.keys\n\n    results_dict = {}\n    for root, _, files in os.walk(path):\n\n        if metrics_name in files:\n            full_name = os.path.join(root, metrics_name)\n            metrics = json.load(open(full_name))\n            results_dict[full_name] = metrics\n\n\n    sorted_keys = sorted(list(results_dict.keys()))\n    print(f\"model_run, {', '.join(keys)}\")\n    for name in sorted_keys:\n        results = results_dict[name]\n        keys_to_print = [str(results.get(key, \"N/A\")) for key in keys]\n        print(f\"{name}, {', '.join(keys_to_print)}\")", "response": "Prints results from an argparse. Namespace object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef forward(self, input_tensor):\n        # pylint: disable=arguments-differ\n        \"\"\"\n        Apply dropout to input tensor.\n\n        Parameters\n        ----------\n        input_tensor: ``torch.FloatTensor``\n            A tensor of shape ``(batch_size, num_timesteps, embedding_dim)``\n\n        Returns\n        -------\n        output: ``torch.FloatTensor``\n            A tensor of shape ``(batch_size, num_timesteps, embedding_dim)`` with dropout applied.\n        \"\"\"\n        ones = input_tensor.data.new_ones(input_tensor.shape[0], input_tensor.shape[-1])\n        dropout_mask = torch.nn.functional.dropout(ones, self.p, self.training, inplace=False)\n        if self.inplace:\n            input_tensor *= dropout_mask.unsqueeze(1)\n            return None\n        else:\n            return dropout_mask.unsqueeze(1) * input_tensor", "response": "Forward computation of the log - likelihood of a single entry."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute and return the metric. Optionally reset the metric.", "response": "def get_metric(self, reset: bool) -> Union[float, Tuple[float, ...], Dict[str, float], Dict[str, List[float]]]:\n        \"\"\"\n        Compute and return the metric. Optionally also call :func:`self.reset`.\n        \"\"\"\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unwrap_to_tensors(*tensors: torch.Tensor):\n        return (x.detach().cpu() if isinstance(x, torch.Tensor) else x for x in tensors)", "response": "Unwraps a list of tensors into a Metric."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreplace abstract variables in text with their concrete counterparts.", "response": "def replace_variables(sentence: List[str],\n                      sentence_variables: Dict[str, str]) -> Tuple[List[str], List[str]]:\n    \"\"\"\n    Replaces abstract variables in text with their concrete counterparts.\n    \"\"\"\n    tokens = []\n    tags = []\n    for token in sentence:\n        if token not in sentence_variables:\n            tokens.append(token)\n            tags.append(\"O\")\n        else:\n            for word in sentence_variables[token].split():\n                tokens.append(word)\n                tags.append(token)\n    return tokens, tags"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncleaning up and unifies a SQL query and splits it into a list of SQL tokens.", "response": "def clean_and_split_sql(sql: str) -> List[str]:\n    \"\"\"\n    Cleans up and unifies a SQL query. This involves unifying quoted strings\n    and splitting brackets which aren't formatted consistently in the data.\n    \"\"\"\n    sql_tokens: List[str] = []\n    for token in sql.strip().split():\n        token = token.replace('\"', \"'\").replace(\"%\", \"\")\n        if token.endswith(\"(\") and len(token) > 1:\n            sql_tokens.extend(split_table_and_column_names(token[:-1]))\n            sql_tokens.extend(split_table_and_column_names(token[-1]))\n        else:\n            sql_tokens.extend(split_table_and_column_names(token))\n    return sql_tokens"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resolve_primary_keys_in_schema(sql_tokens: List[str],\n                                   schema: Dict[str, List[TableColumn]]) -> List[str]:\n    \"\"\"\n    Some examples in the text2sql datasets use ID as a column reference to the\n    column of a table which has a primary key. This causes problems if you are trying\n    to constrain a grammar to only produce the column names directly, because you don't\n    know what ID refers to. So instead of dealing with that, we just replace it.\n    \"\"\"\n    primary_keys_for_tables = {name: max(columns, key=lambda x: x.is_primary_key).name\n                               for name, columns in schema.items()}\n    resolved_tokens = []\n    for i, token in enumerate(sql_tokens):\n        if i > 2:\n            table_name = sql_tokens[i - 2]\n            if token == \"ID\" and table_name in primary_keys_for_tables.keys():\n                token = primary_keys_for_tables[table_name]\n        resolved_tokens.append(token)\n    return resolved_tokens", "response": "Resolve primary keys in the SQL tokens."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_dataset_schema(schema_path: str) -> Dict[str, List[TableColumn]]:\n    schema: Dict[str, List[TableColumn]] = defaultdict(list)\n    for i, line in enumerate(open(schema_path, \"r\")):\n        if i == 0:\n            header = [x.strip() for x in line.split(\",\")]\n        elif line[0] == \"-\":\n            continue\n        else:\n            data = {key: value for key, value in zip(header, [x.strip() for x in line.split(\",\")])}\n\n            table = data.get(\"Table Name\", None) or data.get(\"Table\")\n            column = data.get(\"Field Name\", None) or data.get(\"Field\")\n            is_primary_key = data.get(\"Primary Key\") == \"y\"\n            schema[table.upper()].append(TableColumn(column.upper(), data[\"Type\"], is_primary_key))\n\n    return {**schema}", "response": "Reads a schema from the text2sql data file and returns a dictionary mapping table names to column names and respective types."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sort_and_run_forward(self,\n                             module: Callable[[PackedSequence, Optional[RnnState]],\n                                              Tuple[Union[PackedSequence, torch.Tensor], RnnState]],\n                             inputs: torch.Tensor,\n                             mask: torch.Tensor,\n                             hidden_state: Optional[RnnState] = None):\n        \"\"\"\n        This function exists because Pytorch RNNs require that their inputs be sorted\n        before being passed as input. As all of our Seq2xxxEncoders use this functionality,\n        it is provided in a base class. This method can be called on any module which\n        takes as input a ``PackedSequence`` and some ``hidden_state``, which can either be a\n        tuple of tensors or a tensor.\n\n        As all of our Seq2xxxEncoders have different return types, we return `sorted`\n        outputs from the module, which is called directly. Additionally, we return the\n        indices into the batch dimension required to restore the tensor to it's correct,\n        unsorted order and the number of valid batch elements (i.e the number of elements\n        in the batch which are not completely masked). This un-sorting and re-padding\n        of the module outputs is left to the subclasses because their outputs have different\n        types and handling them smoothly here is difficult.\n\n        Parameters\n        ----------\n        module : ``Callable[[PackedSequence, Optional[RnnState]],\n                            Tuple[Union[PackedSequence, torch.Tensor], RnnState]]``, required.\n            A function to run on the inputs. In most cases, this is a ``torch.nn.Module``.\n        inputs : ``torch.Tensor``, required.\n            A tensor of shape ``(batch_size, sequence_length, embedding_size)`` representing\n            the inputs to the Encoder.\n        mask : ``torch.Tensor``, required.\n            A tensor of shape ``(batch_size, sequence_length)``, representing masked and\n            non-masked elements of the sequence for each element in the batch.\n        hidden_state : ``Optional[RnnState]``, (default = None).\n            A single tensor of shape (num_layers, batch_size, hidden_size) representing the\n            state of an RNN with or a tuple of\n            tensors of shapes (num_layers, batch_size, hidden_size) and\n            (num_layers, batch_size, memory_size), representing the hidden state and memory\n            state of an LSTM-like RNN.\n\n        Returns\n        -------\n        module_output : ``Union[torch.Tensor, PackedSequence]``.\n            A Tensor or PackedSequence representing the output of the Pytorch Module.\n            The batch size dimension will be equal to ``num_valid``, as sequences of zero\n            length are clipped off before the module is called, as Pytorch cannot handle\n            zero length sequences.\n        final_states : ``Optional[RnnState]``\n            A Tensor representing the hidden state of the Pytorch Module. This can either\n            be a single tensor of shape (num_layers, num_valid, hidden_size), for instance in\n            the case of a GRU, or a tuple of tensors, such as those required for an LSTM.\n        restoration_indices : ``torch.LongTensor``\n            A tensor of shape ``(batch_size,)``, describing the re-indexing required to transform\n            the outputs back to their original batch order.\n        \"\"\"\n        # In some circumstances you may have sequences of zero length. ``pack_padded_sequence``\n        # requires all sequence lengths to be > 0, so remove sequences of zero length before\n        # calling self._module, then fill with zeros.\n\n        # First count how many sequences are empty.\n        batch_size = mask.size(0)\n        num_valid = torch.sum(mask[:, 0]).int().item()\n\n        sequence_lengths = get_lengths_from_binary_sequence_mask(mask)\n        sorted_inputs, sorted_sequence_lengths, restoration_indices, sorting_indices =\\\n            sort_batch_by_length(inputs, sequence_lengths)\n\n        # Now create a PackedSequence with only the non-empty, sorted sequences.\n        packed_sequence_input = pack_padded_sequence(sorted_inputs[:num_valid, :, :],\n                                                     sorted_sequence_lengths[:num_valid].data.tolist(),\n                                                     batch_first=True)\n        # Prepare the initial states.\n        if not self.stateful:\n            if hidden_state is None:\n                initial_states = hidden_state\n            elif isinstance(hidden_state, tuple):\n                initial_states = [state.index_select(1, sorting_indices)[:, :num_valid, :].contiguous()\n                                  for state in hidden_state]\n            else:\n                initial_states = hidden_state.index_select(1, sorting_indices)[:, :num_valid, :].contiguous()\n\n        else:\n            initial_states = self._get_initial_states(batch_size, num_valid, sorting_indices)\n\n        # Actually call the module on the sorted PackedSequence.\n        module_output, final_states = module(packed_sequence_input, initial_states)\n\n        return module_output, final_states, restoration_indices", "response": "This method sorts and runs forward on the inputs and returns the outputs of the encoder."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_initial_states(self,\n                            batch_size: int,\n                            num_valid: int,\n                            sorting_indices: torch.LongTensor) -> Optional[RnnState]:\n        \"\"\"\n        Returns an initial state for use in an RNN. Additionally, this method handles\n        the batch size changing across calls by mutating the state to append initial states\n        for new elements in the batch. Finally, it also handles sorting the states\n        with respect to the sequence lengths of elements in the batch and removing rows\n        which are completely padded. Importantly, this `mutates` the state if the\n        current batch size is larger than when it was previously called.\n\n        Parameters\n        ----------\n        batch_size : ``int``, required.\n            The batch size can change size across calls to stateful RNNs, so we need\n            to know if we need to expand or shrink the states before returning them.\n            Expanded states will be set to zero.\n        num_valid : ``int``, required.\n            The batch may contain completely padded sequences which get removed before\n            the sequence is passed through the encoder. We also need to clip these off\n            of the state too.\n        sorting_indices ``torch.LongTensor``, required.\n            Pytorch RNNs take sequences sorted by length. When we return the states to be\n            used for a given call to ``module.forward``, we need the states to match up to\n            the sorted sequences, so before returning them, we sort the states using the\n            same indices used to sort the sequences.\n\n        Returns\n        -------\n        This method has a complex return type because it has to deal with the first time it\n        is called, when it has no state, and the fact that types of RNN have heterogeneous\n        states.\n\n        If it is the first time the module has been called, it returns ``None``, regardless\n        of the type of the ``Module``.\n\n        Otherwise, for LSTMs, it returns a tuple of ``torch.Tensors`` with shape\n        ``(num_layers, num_valid, state_size)`` and ``(num_layers, num_valid, memory_size)``\n        respectively, or for GRUs, it returns a single ``torch.Tensor`` of shape\n        ``(num_layers, num_valid, state_size)``.\n        \"\"\"\n        # We don't know the state sizes the first time calling forward,\n        # so we let the module define what it's initial hidden state looks like.\n        if self._states is None:\n            return None\n\n        # Otherwise, we have some previous states.\n        if batch_size > self._states[0].size(1):\n            # This batch is larger than the all previous states.\n            # If so, resize the states.\n            num_states_to_concat = batch_size - self._states[0].size(1)\n            resized_states = []\n            # state has shape (num_layers, batch_size, hidden_size)\n            for state in self._states:\n                # This _must_ be inside the loop because some\n                # RNNs have states with different last dimension sizes.\n                zeros = state.new_zeros(state.size(0),\n                                        num_states_to_concat,\n                                        state.size(2))\n                resized_states.append(torch.cat([state, zeros], 1))\n            self._states = tuple(resized_states)\n            correctly_shaped_states = self._states\n\n        elif batch_size < self._states[0].size(1):\n            # This batch is smaller than the previous one.\n            correctly_shaped_states = tuple(state[:, :batch_size, :] for state in self._states)\n        else:\n            correctly_shaped_states = self._states\n\n        # At this point, our states are of shape (num_layers, batch_size, hidden_size).\n        # However, the encoder uses sorted sequences and additionally removes elements\n        # of the batch which are fully padded. We need the states to match up to these\n        # sorted and filtered sequences, so we do that in the next two blocks before\n        # returning the state/s.\n        if len(self._states) == 1:\n            # GRUs only have a single state. This `unpacks` it from the\n            # tuple and returns the tensor directly.\n            correctly_shaped_state = correctly_shaped_states[0]\n            sorted_state = correctly_shaped_state.index_select(1, sorting_indices)\n            return sorted_state[:, :num_valid, :].contiguous()\n        else:\n            # LSTMs have a state tuple of (state, memory).\n            sorted_states = [state.index_select(1, sorting_indices)\n                             for state in correctly_shaped_states]\n            return tuple(state[:, :num_valid, :].contiguous() for state in sorted_states)", "response": "This method returns the initial state for use in an RNN."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _update_states(self,\n                       final_states: RnnStateStorage,\n                       restoration_indices: torch.LongTensor) -> None:\n        \"\"\"\n        After the RNN has run forward, the states need to be updated.\n        This method just sets the state to the updated new state, performing\n        several pieces of book-keeping along the way - namely, unsorting the\n        states and ensuring that the states of completely padded sequences are\n        not updated. Finally, it also detaches the state variable from the\n        computational graph, such that the graph can be garbage collected after\n        each batch iteration.\n\n        Parameters\n        ----------\n        final_states : ``RnnStateStorage``, required.\n            The hidden states returned as output from the RNN.\n        restoration_indices : ``torch.LongTensor``, required.\n            The indices that invert the sorting used in ``sort_and_run_forward``\n            to order the states with respect to the lengths of the sequences in\n            the batch.\n        \"\"\"\n        # TODO(Mark): seems weird to sort here, but append zeros in the subclasses.\n        # which way around is best?\n        new_unsorted_states = [state.index_select(1, restoration_indices)\n                               for state in final_states]\n\n        if self._states is None:\n            # We don't already have states, so just set the\n            # ones we receive to be the current state.\n            self._states = tuple(state.data for state in new_unsorted_states)\n        else:\n            # Now we've sorted the states back so that they correspond to the original\n            # indices, we need to figure out what states we need to update, because if we\n            # didn't use a state for a particular row, we want to preserve its state.\n            # Thankfully, the rows which are all zero in the state correspond exactly\n            # to those which aren't used, so we create masks of shape (new_batch_size,),\n            # denoting which states were used in the RNN computation.\n            current_state_batch_size = self._states[0].size(1)\n            new_state_batch_size = final_states[0].size(1)\n            # Masks for the unused states of shape (1, new_batch_size, 1)\n            used_new_rows_mask = [(state[0, :, :].sum(-1)\n                                   != 0.0).float().view(1, new_state_batch_size, 1)\n                                  for state in new_unsorted_states]\n            new_states = []\n            if current_state_batch_size > new_state_batch_size:\n                # The new state is smaller than the old one,\n                # so just update the indices which we used.\n                for old_state, new_state, used_mask in zip(self._states,\n                                                           new_unsorted_states,\n                                                           used_new_rows_mask):\n                    # zero out all rows in the previous state\n                    # which _were_ used in the current state.\n                    masked_old_state = old_state[:, :new_state_batch_size, :] * (1 - used_mask)\n                    # The old state is larger, so update the relevant parts of it.\n                    old_state[:, :new_state_batch_size, :] = new_state + masked_old_state\n                    new_states.append(old_state.detach())\n            else:\n                # The states are the same size, so we just have to\n                # deal with the possibility that some rows weren't used.\n                new_states = []\n                for old_state, new_state, used_mask in zip(self._states,\n                                                           new_unsorted_states,\n                                                           used_new_rows_mask):\n                    # zero out all rows which _were_ used in the current state.\n                    masked_old_state = old_state * (1 - used_mask)\n                    # The old state is larger, so update the relevant parts of it.\n                    new_state += masked_old_state\n                    new_states.append(new_state.detach())\n\n            # It looks like there should be another case handled here - when\n            # the current_state_batch_size < new_state_batch_size. However,\n            # this never happens, because the states themeselves are mutated\n            # by appending zeros when calling _get_inital_states, meaning that\n            # the new states are either of equal size, or smaller, in the case\n            # that there are some unused elements (zero-length) for the RNN computation.\n            self._states = tuple(new_states)", "response": "Updates the state variables of the internal state storage."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconstructing a prefix tree for all possible target action sequences.", "response": "def construct_prefix_tree(targets: Union[torch.Tensor, List[List[List[int]]]],\n                          target_mask: Optional[torch.Tensor] = None) -> List[Dict[Tuple[int, ...], Set[int]]]:\n    \"\"\"\n    Takes a list of valid target action sequences and creates a mapping from all possible\n    (valid) action prefixes to allowed actions given that prefix.  While the method is called\n    ``construct_prefix_tree``, we're actually returning a map that has as keys the paths to\n    `all internal nodes of the trie`, and as values all of the outgoing edges from that node.\n\n    ``targets`` is assumed to be a tensor of shape ``(batch_size, num_valid_sequences,\n    sequence_length)``.  If the mask is not ``None``, it is assumed to have the same shape, and\n    we will ignore any value in ``targets`` that has a value of ``0`` in the corresponding\n    position in the mask.  We assume that the mask has the format 1*0* for each item in\n    ``targets`` - that is, once we see our first zero, we stop processing that target.\n\n    For example, if ``targets`` is the following tensor: ``[[1, 2, 3], [1, 4, 5]]``, the return\n    value will be: ``{(): set([1]), (1,): set([2, 4]), (1, 2): set([3]), (1, 4): set([5])}``.\n\n    This could be used, e.g., to do an efficient constrained beam search, or to efficiently\n    evaluate the probability of all of the target sequences.\n    \"\"\"\n    batched_allowed_transitions: List[Dict[Tuple[int, ...], Set[int]]] = []\n\n    if not isinstance(targets, list):\n        assert targets.dim() == 3, \"targets tensor needs to be batched!\"\n        targets = targets.detach().cpu().numpy().tolist()\n    if target_mask is not None:\n        target_mask = target_mask.detach().cpu().numpy().tolist()\n    else:\n        target_mask = [None for _ in targets]\n\n    for instance_targets, instance_mask in zip(targets, target_mask):\n        allowed_transitions: Dict[Tuple[int, ...], Set[int]] = defaultdict(set)\n        for i, target_sequence in enumerate(instance_targets):\n            history: Tuple[int, ...] = ()\n            for j, action in enumerate(target_sequence):\n                if instance_mask and instance_mask[i][j] == 0:\n                    break\n                allowed_transitions[history].add(action)\n                history = history + (action,)\n        batched_allowed_transitions.append(allowed_transitions)\n    return batched_allowed_transitions"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_value(original_string, corenlp_value=None):\n    if isinstance(original_string, Value):\n        # Already a Value\n        return original_string\n    if not corenlp_value:\n        corenlp_value = original_string\n    # Number?\n    amount = NumberValue.parse(corenlp_value)\n    if amount is not None:\n        return NumberValue(amount, original_string)\n    # Date?\n    ymd = DateValue.parse(corenlp_value)\n    if ymd is not None:\n        if ymd[1] == ymd[2] == -1:\n            return NumberValue(ymd[0], original_string)\n        else:\n            return DateValue(ymd[0], ymd[1], ymd[2], original_string)\n    # String.\n    return StringValue(original_string)", "response": "Convert the string to Value object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a list of strings to a list of Values", "response": "def to_value_list(original_strings, corenlp_values=None):\n    \"\"\"Convert a list of strings to a list of Values\n\n    Args:\n        original_strings (list[basestring])\n        corenlp_values (list[basestring or None])\n    Returns:\n        list[Value]\n    \"\"\"\n    assert isinstance(original_strings, (list, tuple, set))\n    if corenlp_values is not None:\n        assert isinstance(corenlp_values, (list, tuple, set))\n        assert len(original_strings) == len(corenlp_values)\n        return list(set(to_value(x, y) for (x, y)\n                        in zip(original_strings, corenlp_values)))\n    else:\n        return list(set(to_value(x) for x in original_strings))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_denotation(target_values, predicted_values):\n    # Check size\n    if len(target_values) != len(predicted_values):\n        return False\n    # Check items\n    for target in target_values:\n        if not any(target.match(pred) for pred in predicted_values):\n            return False\n    return True", "response": "Check if the predicted denotation is correct."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse(text):\n        try:\n            return int(text)\n        except ValueError:\n            try:\n                amount = float(text)\n                assert not isnan(amount) and not isinf(amount)\n                return amount\n            except (ValueError, AssertionError):\n                return None", "response": "Try to parse into a number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse(text):\n        try:\n            ymd = text.lower().split('-')\n            assert len(ymd) == 3\n            year = -1 if ymd[0] in ('xx', 'xxxx') else int(ymd[0])\n            month = -1 if ymd[1] == 'xx' else int(ymd[1])\n            day = -1 if ymd[2] == 'xx' else int(ymd[2])\n            assert not year == month == day == -1\n            assert month == -1 or 1 <= month <= 12\n            assert day == -1 or 1 <= day <= 31\n            return (year, month, day)\n        except (ValueError, AssertionError):\n            return None", "response": "Try to parse into a date."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a sequence tensor extract spans and return representations of the valid elements.", "response": "def forward(self, # pylint: disable=arguments-differ\n                sequence_tensor: torch.FloatTensor,\n                span_indices: torch.LongTensor,\n                sequence_mask: torch.LongTensor = None,\n                span_indices_mask: torch.LongTensor = None):\n        \"\"\"\n        Given a sequence tensor, extract spans and return representations of\n        them. Span representation can be computed in many different ways,\n        such as concatenation of the start and end spans, attention over the\n        vectors contained inside the span, etc.\n\n        Parameters\n        ----------\n        sequence_tensor : ``torch.FloatTensor``, required.\n            A tensor of shape (batch_size, sequence_length, embedding_size)\n            representing an embedded sequence of words.\n        span_indices : ``torch.LongTensor``, required.\n            A tensor of shape ``(batch_size, num_spans, 2)``, where the last\n            dimension represents the inclusive start and end indices of the\n            span to be extracted from the ``sequence_tensor``.\n        sequence_mask : ``torch.LongTensor``, optional (default = ``None``).\n            A tensor of shape (batch_size, sequence_length) representing padded\n            elements of the sequence.\n        span_indices_mask : ``torch.LongTensor``, optional (default = ``None``).\n            A tensor of shape (batch_size, num_spans) representing the valid\n            spans in the ``indices`` tensor. This mask is optional because\n            sometimes it's easier to worry about masking after calling this\n            function, rather than passing a mask directly.\n\n        Returns\n        -------\n        A tensor of shape ``(batch_size, num_spans, embedded_span_size)``,\n        where ``embedded_span_size`` depends on the way spans are represented.\n        \"\"\"\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main(serialization_directory: int,\n         device: int,\n         data: str,\n         prefix: str,\n         domain: str = None):\n    \"\"\"\n    serialization_directory : str, required.\n        The directory containing the serialized weights.\n    device: int, default = -1\n        The device to run the evaluation on.\n    data: str, default = None\n        The data to evaluate on. By default, we use the validation data from\n        the original experiment.\n    prefix: str, default=\"\"\n        The prefix to prepend to the generated gold and prediction files, to distinguish\n        different models/data.\n    domain: str, optional (default = None)\n        If passed, filters the ontonotes evaluation/test dataset to only contain the\n        specified domain. This overwrites the domain in the config file from the model,\n        to allow evaluation on domains other than the one the model was trained on.\n    \"\"\"\n    config = Params.from_file(os.path.join(serialization_directory, \"config.json\"))\n\n    if domain is not None:\n        # Hack to allow evaluation on different domains than the\n        # model was trained on.\n        config[\"dataset_reader\"][\"domain_identifier\"] = domain\n        prefix = f\"{domain}_{prefix}\"\n    else:\n        config[\"dataset_reader\"].pop(\"domain_identifier\", None)\n\n    dataset_reader = DatasetReader.from_params(config['dataset_reader'])\n    evaluation_data_path = data if data else config['validation_data_path']\n\n    archive = load_archive(os.path.join(serialization_directory, \"model.tar.gz\"), cuda_device=device)\n    model = archive.model\n    model.eval()\n\n    prediction_file_path = os.path.join(serialization_directory, prefix + \"_predictions.txt\")\n    gold_file_path = os.path.join(serialization_directory, prefix + \"_gold.txt\")\n    prediction_file = open(prediction_file_path, \"w+\")\n    gold_file = open(gold_file_path, \"w+\")\n\n    # Load the evaluation data and index it.\n    print(\"reading evaluation data from {}\".format(evaluation_data_path))\n    instances = dataset_reader.read(evaluation_data_path)\n\n    with torch.autograd.no_grad():\n        iterator = BasicIterator(batch_size=32)\n        iterator.index_with(model.vocab)\n\n        model_predictions = []\n        batches = iterator(instances, num_epochs=1, shuffle=False, cuda_device=device)\n        for batch in Tqdm.tqdm(batches):\n            result = model(**batch)\n            predictions = model.decode(result)\n            model_predictions.extend(predictions[\"tags\"])\n\n        for instance, prediction in zip(instances, model_predictions):\n            fields = instance.fields\n            try:\n                # Most sentences have a verbal predicate, but not all.\n                verb_index = fields[\"verb_indicator\"].labels.index(1)\n            except ValueError:\n                verb_index = None\n\n            gold_tags = fields[\"tags\"].labels\n            sentence = [x.text for x in fields[\"tokens\"].tokens]\n\n            write_to_conll_eval_file(prediction_file, gold_file,\n                                     verb_index, sentence, prediction, gold_tags)\n        prediction_file.close()\n        gold_file.close()", "response": "This function is the main function of the ontonotes evaluation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndecoding a set of possible actions from a state to a state and returns a dictionary of next states.", "response": "def decode(self,\n               initial_state: State,\n               transition_function: TransitionFunction,\n               supervision: SupervisionType) -> Dict[str, torch.Tensor]:\n        \"\"\"\n        Takes an initial state object, a means of transitioning from state to state, and a\n        supervision signal, and uses the supervision to train the transition function to pick\n        \"good\" states.\n\n        This function should typically return a ``loss`` key during training, which the ``Model``\n        will use as its loss.\n\n        Parameters\n        ----------\n        initial_state : ``State``\n            This is the initial state for decoding, typically initialized after running some kind\n            of encoder on some inputs.\n        transition_function : ``TransitionFunction``\n            This is the transition function that scores all possible actions that can be taken in a\n            given state, and returns a ranked list of next states at each step of decoding.\n        supervision : ``SupervisionType``\n            This is the supervision that is used to train the ``transition_function`` function to\n            pick \"good\" states.  You can use whatever kind of supervision you want (e.g., a single\n            \"gold\" action sequence, a set of possible \"gold\" action sequences, a reward function,\n            etc.).  We use ``typing.Generics`` to make sure that our static type checker is happy\n            with how you've matched the supervision that you provide in the model to the\n            ``DecoderTrainer`` that you want to use.\n        \"\"\"\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the state of the scheduler as a dict.", "response": "def state_dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Returns the state of the scheduler as a ``dict``.\n        \"\"\"\n        return {key: value for key, value in self.__dict__.items() if key != 'optimizer'}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading the schedulers state.", "response": "def load_state_dict(self, state_dict: Dict[str, Any]) -> None:\n        \"\"\"\n        Load the schedulers state.\n\n        Parameters\n        ----------\n        state_dict : ``Dict[str, Any]``\n            Scheduler state. Should be an object returned from a call to ``state_dict``.\n        \"\"\"\n        self.__dict__.update(state_dict)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nforwards method that converts a text field input into a new tensor.", "response": "def forward(self,  # pylint: disable=arguments-differ\n                text_field_input: Dict[str, torch.Tensor],\n                num_wrapping_dims: int = 0) -> torch.Tensor:\n        \"\"\"\n        Parameters\n        ----------\n        text_field_input : ``Dict[str, torch.Tensor]``\n            A dictionary that was the output of a call to ``TextField.as_tensor``.  Each tensor in\n            here is assumed to have a shape roughly similar to ``(batch_size, sequence_length)``\n            (perhaps with an extra trailing dimension for the characters in each token).\n        num_wrapping_dims : ``int``, optional (default=0)\n            If you have a ``ListField[TextField]`` that created the ``text_field_input``, you'll\n            end up with tensors of shape ``(batch_size, wrapping_dim1, wrapping_dim2, ...,\n            sequence_length)``.  This parameter tells us how many wrapping dimensions there are, so\n            that we can correctly ``TimeDistribute`` the embedding of each named representation.\n        \"\"\"\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ensemble(subresults: List[Dict[str, torch.Tensor]]) -> torch.Tensor:\n\n    # Choose the highest average confidence span.\n\n    span_start_probs = sum(subresult['span_start_probs'] for subresult in subresults) / len(subresults)\n    span_end_probs = sum(subresult['span_end_probs'] for subresult in subresults) / len(subresults)\n    return get_best_span(span_start_probs.log(), span_end_probs.log())", "response": "Returns the index of the best prediction given the results from the submodels."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef forward(self,  # pylint: disable=arguments-differ\n                inputs: torch.Tensor,\n                mask: torch.LongTensor) -> torch.Tensor:\n        \"\"\"\n        Parameters\n        ----------\n        inputs : ``torch.Tensor``, required.\n            A Tensor of shape ``(batch_size, sequence_length, hidden_size)``.\n        mask : ``torch.LongTensor``, required.\n            A binary mask of shape ``(batch_size, sequence_length)`` representing the\n            non-padded elements in each sequence in the batch.\n\n        Returns\n        -------\n        A ``torch.Tensor`` of shape (num_layers, batch_size, sequence_length, hidden_size),\n        where the num_layers dimension represents the LSTM output from that layer.\n        \"\"\"\n        batch_size, total_sequence_length = mask.size()\n        stacked_sequence_output, final_states, restoration_indices = \\\n            self.sort_and_run_forward(self._lstm_forward, inputs, mask)\n\n        num_layers, num_valid, returned_timesteps, encoder_dim = stacked_sequence_output.size()\n        # Add back invalid rows which were removed in the call to sort_and_run_forward.\n        if num_valid < batch_size:\n            zeros = stacked_sequence_output.new_zeros(num_layers,\n                                                      batch_size - num_valid,\n                                                      returned_timesteps,\n                                                      encoder_dim)\n            stacked_sequence_output = torch.cat([stacked_sequence_output, zeros], 1)\n\n            # The states also need to have invalid rows added back.\n            new_states = []\n            for state in final_states:\n                state_dim = state.size(-1)\n                zeros = state.new_zeros(num_layers, batch_size - num_valid, state_dim)\n                new_states.append(torch.cat([state, zeros], 1))\n            final_states = new_states\n\n        # It's possible to need to pass sequences which are padded to longer than the\n        # max length of the sequence to a Seq2StackEncoder. However, packing and unpacking\n        # the sequences mean that the returned tensor won't include these dimensions, because\n        # the RNN did not need to process them. We add them back on in the form of zeros here.\n        sequence_length_difference = total_sequence_length - returned_timesteps\n        if sequence_length_difference > 0:\n            zeros = stacked_sequence_output.new_zeros(num_layers,\n                                                      batch_size,\n                                                      sequence_length_difference,\n                                                      stacked_sequence_output[0].size(-1))\n            stacked_sequence_output = torch.cat([stacked_sequence_output, zeros], 2)\n\n        self._update_states(final_states, restoration_indices)\n\n        # Restore the original indices and return the sequence.\n        # Has shape (num_layers, batch_size, sequence_length, hidden_size)\n        return stacked_sequence_output.index_select(1, restoration_indices)", "response": "This method is used to forward the LSTM."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _lstm_forward(self,\n                      inputs: PackedSequence,\n                      initial_state: Optional[Tuple[torch.Tensor, torch.Tensor]] = None) -> \\\n            Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        \"\"\"\n        Parameters\n        ----------\n        inputs : ``PackedSequence``, required.\n            A batch first ``PackedSequence`` to run the stacked LSTM over.\n        initial_state : ``Tuple[torch.Tensor, torch.Tensor]``, optional, (default = None)\n            A tuple (state, memory) representing the initial hidden state and memory\n            of the LSTM, with shape (num_layers, batch_size, 2 * hidden_size) and\n            (num_layers, batch_size, 2 * cell_size) respectively.\n\n        Returns\n        -------\n        output_sequence : ``torch.FloatTensor``\n            The encoded sequence of shape (num_layers, batch_size, sequence_length, hidden_size)\n        final_states: ``Tuple[torch.FloatTensor, torch.FloatTensor]``\n            The per-layer final (state, memory) states of the LSTM, with shape\n            (num_layers, batch_size, 2 * hidden_size) and  (num_layers, batch_size, 2 * cell_size)\n            respectively. The last dimension is duplicated because it contains the state/memory\n            for both the forward and backward layers.\n        \"\"\"\n        if initial_state is None:\n            hidden_states: List[Optional[Tuple[torch.Tensor,\n                                               torch.Tensor]]] = [None] * len(self.forward_layers)\n        elif initial_state[0].size()[0] != len(self.forward_layers):\n            raise ConfigurationError(\"Initial states were passed to forward() but the number of \"\n                                     \"initial states does not match the number of layers.\")\n        else:\n            hidden_states = list(zip(initial_state[0].split(1, 0), initial_state[1].split(1, 0)))\n\n        inputs, batch_lengths = pad_packed_sequence(inputs, batch_first=True)\n        forward_output_sequence = inputs\n        backward_output_sequence = inputs\n\n        final_states = []\n        sequence_outputs = []\n        for layer_index, state in enumerate(hidden_states):\n            forward_layer = getattr(self, 'forward_layer_{}'.format(layer_index))\n            backward_layer = getattr(self, 'backward_layer_{}'.format(layer_index))\n\n            forward_cache = forward_output_sequence\n            backward_cache = backward_output_sequence\n\n            if state is not None:\n                forward_hidden_state, backward_hidden_state = state[0].split(self.hidden_size, 2)\n                forward_memory_state, backward_memory_state = state[1].split(self.cell_size, 2)\n                forward_state = (forward_hidden_state, forward_memory_state)\n                backward_state = (backward_hidden_state, backward_memory_state)\n            else:\n                forward_state = None\n                backward_state = None\n\n            forward_output_sequence, forward_state = forward_layer(forward_output_sequence,\n                                                                   batch_lengths,\n                                                                   forward_state)\n            backward_output_sequence, backward_state = backward_layer(backward_output_sequence,\n                                                                      batch_lengths,\n                                                                      backward_state)\n            # Skip connections, just adding the input to the output.\n            if layer_index != 0:\n                forward_output_sequence += forward_cache\n                backward_output_sequence += backward_cache\n\n            sequence_outputs.append(torch.cat([forward_output_sequence,\n                                               backward_output_sequence], -1))\n            # Append the state tuples in a list, so that we can return\n            # the final states for all the layers.\n            final_states.append((torch.cat([forward_state[0], backward_state[0]], -1),\n                                 torch.cat([forward_state[1], backward_state[1]], -1)))\n\n        stacked_sequence_outputs: torch.FloatTensor = torch.stack(sequence_outputs)\n        # Stack the hidden state and memory for each layer into 2 tensors of shape\n        # (num_layers, batch_size, hidden_size) and (num_layers, batch_size, cell_size)\n        # respectively.\n        final_hidden_states, final_memory_states = zip(*final_states)\n        final_state_tuple: Tuple[torch.FloatTensor,\n                                 torch.FloatTensor] = (torch.cat(final_hidden_states, 0),\n                                                       torch.cat(final_memory_states, 0))\n        return stacked_sequence_outputs, final_state_tuple", "response": "This method computes the forward and backward LSTM for the given set of inputs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_weights(self, weight_file: str) -> None:\n        requires_grad = self.requires_grad\n\n        with h5py.File(cached_path(weight_file), 'r') as fin:\n            for i_layer, lstms in enumerate(\n                    zip(self.forward_layers, self.backward_layers)\n            ):\n                for j_direction, lstm in enumerate(lstms):\n                    # lstm is an instance of LSTMCellWithProjection\n                    cell_size = lstm.cell_size\n\n                    dataset = fin['RNN_%s' % j_direction]['RNN']['MultiRNNCell']['Cell%s' % i_layer\n                                                                                ]['LSTMCell']\n\n                    # tensorflow packs together both W and U matrices into one matrix,\n                    # but pytorch maintains individual matrices.  In addition, tensorflow\n                    # packs the gates as input, memory, forget, output but pytorch\n                    # uses input, forget, memory, output.  So we need to modify the weights.\n                    tf_weights = numpy.transpose(dataset['W_0'][...])\n                    torch_weights = tf_weights.copy()\n\n                    # split the W from U matrices\n                    input_size = lstm.input_size\n                    input_weights = torch_weights[:, :input_size]\n                    recurrent_weights = torch_weights[:, input_size:]\n                    tf_input_weights = tf_weights[:, :input_size]\n                    tf_recurrent_weights = tf_weights[:, input_size:]\n\n                    # handle the different gate order convention\n                    for torch_w, tf_w in [[input_weights, tf_input_weights],\n                                          [recurrent_weights, tf_recurrent_weights]]:\n                        torch_w[(1 * cell_size):(2 * cell_size), :] = tf_w[(2 * cell_size):(3 * cell_size), :]\n                        torch_w[(2 * cell_size):(3 * cell_size), :] = tf_w[(1 * cell_size):(2 * cell_size), :]\n\n                    lstm.input_linearity.weight.data.copy_(torch.FloatTensor(input_weights))\n                    lstm.state_linearity.weight.data.copy_(torch.FloatTensor(recurrent_weights))\n                    lstm.input_linearity.weight.requires_grad = requires_grad\n                    lstm.state_linearity.weight.requires_grad = requires_grad\n\n                    # the bias weights\n                    tf_bias = dataset['B'][...]\n                    # tensorflow adds 1.0 to forget gate bias instead of modifying the\n                    # parameters...\n                    tf_bias[(2 * cell_size):(3 * cell_size)] += 1\n                    torch_bias = tf_bias.copy()\n                    torch_bias[(1 * cell_size):(2 * cell_size)\n                              ] = tf_bias[(2 * cell_size):(3 * cell_size)]\n                    torch_bias[(2 * cell_size):(3 * cell_size)\n                              ] = tf_bias[(1 * cell_size):(2 * cell_size)]\n                    lstm.state_linearity.bias.data.copy_(torch.FloatTensor(torch_bias))\n                    lstm.state_linearity.bias.requires_grad = requires_grad\n\n                    # the projection weights\n                    proj_weights = numpy.transpose(dataset['W_P_0'][...])\n                    lstm.state_projection.weight.data.copy_(torch.FloatTensor(proj_weights))\n                    lstm.state_projection.weight.requires_grad = requires_grad", "response": "Load the pre - trained weights from the file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef substitute_any_type(type_: Type, basic_types: Set[BasicType]) -> List[Type]:\n    if type_ == ANY_TYPE:\n        return list(basic_types)\n    if isinstance(type_, BasicType):\n        return [type_]\n    # If we've made it this far, we have a ComplexType, and we can just call\n    # `type_.substitute_any_type()`.\n    return type_.substitute_any_type(basic_types)", "response": "Takes a type and a set of basic types and returns a list of all possible combinations of type_."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_complex_type_production(complex_type: ComplexType,\n                                 multi_match_mapping: Dict[Type, List[Type]]) -> List[Tuple[Type, str]]:\n    \"\"\"\n    Takes a complex type (without any placeholders), gets its return values, and returns productions\n    (perhaps each with multiple arguments) that produce the return values.  This method also takes\n    care of ``MultiMatchNamedBasicTypes``. If one of the arguments or the return types is a multi\n    match type, it gets all the substitutions of those types from ``multi_match_mapping`` and forms\n    a list with all possible combinations of substitutions. If the complex type passed to this method\n    has no ``MultiMatchNamedBasicTypes``, the returned list will contain a single tuple.  For\n    example, if the complex is type ``<a,<<b,c>,d>>``, and ``a`` is a multi match type that matches\n    ``e`` and ``f``, this gives the following list of tuples: ``[('d', 'd -> [<a,<<b,c>,d>, e,\n    <b,c>]), ('d', 'd -> [<a,<<b,c>,d>, f, <b,c>])]`` Note that we assume there will be no\n    productions from the multi match type, and the list above does not contain ``('d', 'd ->\n    [<a,<<b,c>,d>, a, <b,c>>]')``.\n    \"\"\"\n    return_type = complex_type.return_type()\n    if isinstance(return_type, MultiMatchNamedBasicType):\n        return_types_matched = list(multi_match_mapping[return_type] if return_type in\n                                    multi_match_mapping else return_type.types_to_match)\n    else:\n        return_types_matched = [return_type]\n    arguments = complex_type.argument_types()\n    argument_types_matched = []\n    for argument_type in arguments:\n        if isinstance(argument_type, MultiMatchNamedBasicType):\n            matched_types = list(multi_match_mapping[argument_type] if argument_type in\n                                 multi_match_mapping else argument_type.types_to_match)\n            argument_types_matched.append(matched_types)\n        else:\n            argument_types_matched.append([argument_type])\n    complex_type_productions: List[Tuple[Type, str]] = []\n    for matched_return_type in return_types_matched:\n        for matched_arguments in itertools.product(*argument_types_matched):\n            complex_type_productions.append((matched_return_type,\n                                             _make_production_string(return_type,\n                                                                     [complex_type] + list(matched_arguments))))\n    return complex_type_productions", "response": "This method takes a ComplexType and returns a list of productions that produce the return values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_valid_actions(name_mapping: Dict[str, str],\n                      type_signatures: Dict[str, Type],\n                      basic_types: Set[Type],\n                      multi_match_mapping: Dict[Type, List[Type]] = None,\n                      valid_starting_types: Set[Type] = None,\n                      num_nested_lambdas: int = 0) -> Dict[str, List[str]]:\n    \"\"\"\n    Generates all the valid actions starting from each non-terminal. For terminals of a specific\n    type, we simply add a production from the type to the terminal. For all terminal `functions`,\n    we additionally add a rule that allows their return type to be generated from an application of\n    the function.  For example, the function ``<e,<r,<d,r>>>``, which takes three arguments and\n    returns an ``r`` would generate a the production rule ``r -> [<e,<r,<d,r>>>, e, r, d]``.\n\n    For functions that do not contain ANY_TYPE or placeholder types, this is straight-forward.\n    When there are ANY_TYPES or placeholders, we substitute the ANY_TYPE with all possible basic\n    types, and then produce a similar rule.  For example, the identity function, with type\n    ``<#1,#1>`` and basic types ``e`` and ``r``,  would produce the rules ``e -> [<#1,#1>, e]`` and\n    ``r -> [<#1,#1>, r]``.\n\n    We additionally add a valid action from the start symbol to all ``valid_starting_types``.\n\n    Parameters\n    ----------\n    name_mapping : ``Dict[str, str]``\n        The mapping of names that appear in your logical form languages to their aliases for NLTK.\n        If you are getting all valid actions for a type declaration, this can be the\n        ``COMMON_NAME_MAPPING``.\n    type_signatures : ``Dict[str, Type]``\n        The mapping from name aliases to their types. If you are getting all valid actions for a\n        type declaration, this can be the ``COMMON_TYPE_SIGNATURE``.\n    basic_types : ``Set[Type]``\n        Set of all basic types in the type declaration.\n    multi_match_mapping : ``Dict[Type, List[Type]]`` (optional)\n        A mapping from `MultiMatchNamedBasicTypes` to the types they can match. This may be\n        different from the type's ``types_to_match`` field based on the context. While building action\n        sequences that lead to complex types with ``MultiMatchNamedBasicTypes``, if a type does not\n        occur in this mapping, the default set of ``types_to_match`` for that type will be used.\n    valid_starting_types : ``Set[Type]``, optional\n        These are the valid starting types for your grammar; e.g., what types are we allowed to\n        parse expressions into?  We will add a \"START -> TYPE\" rule for each of these types.  If\n        this is ``None``, we default to using ``basic_types``.\n    num_nested_lambdas : ``int`` (optional)\n        Does the language used permit lambda expressions?  And if so, how many nested lambdas do we\n        need to worry about?  We'll add rules like \"<r,d> -> ['lambda x', d]\" for all complex\n        types, where the variable is determined by the number of nestings.  We currently only\n        permit up to three levels of nesting, just for ease of implementation.\n    \"\"\"\n    valid_actions: Dict[str, Set[str]] = defaultdict(set)\n\n    valid_starting_types = valid_starting_types or basic_types\n    for type_ in valid_starting_types:\n        valid_actions[str(START_TYPE)].add(_make_production_string(START_TYPE, type_))\n\n    complex_types = set()\n    for name, alias in name_mapping.items():\n        # Lambda functions and variables associated with them get produced in specific contexts. So\n        # we do not add them to ``valid_actions`` here, and let ``GrammarState`` deal with it.\n        # ``var`` is a special function that some languages (like LambdaDCS) use within lambda\n        # functions to indicate the use of a variable (eg.: ``(lambda x (fb:row.row.year (var x)))``)\n        # We do not have to produce this function outside the scope of lambda. Even within lambdas,\n        # it is a lot easier to not do it, and let the action sequence to logical form transformation\n        # logic add it to the output logical forms instead.\n        if name in [\"lambda\", \"var\", \"x\", \"y\", \"z\"]:\n            continue\n        name_type = type_signatures[alias]\n        # Type to terminal productions.\n        for substituted_type in substitute_any_type(name_type, basic_types):\n            valid_actions[str(substituted_type)].add(_make_production_string(substituted_type, name))\n        # Keeping track of complex types.\n        if isinstance(name_type, ComplexType) and name_type != ANY_TYPE:\n            complex_types.add(name_type)\n\n    for complex_type in complex_types:\n        for substituted_type in substitute_any_type(complex_type, basic_types):\n            for head, production in _get_complex_type_production(substituted_type,\n                                                                 multi_match_mapping or {}):\n                valid_actions[str(head)].add(production)\n\n    # We can produce complex types with a lambda expression, though we'll leave out\n    # placeholder types for now.\n    for i in range(num_nested_lambdas):\n        lambda_var = chr(ord('x') + i)\n        # We'll only allow lambdas to be functions that take and return basic types as their\n        # arguments, for now.  Also, we're doing this for all possible complex types where\n        # the first and second types are basic types. So we may be overgenerating a bit.\n        for first_type in basic_types:\n            for second_type in basic_types:\n                key = ComplexType(first_type, second_type)\n                production_string = _make_production_string(key, ['lambda ' + lambda_var, second_type])\n                valid_actions[str(key)].add(production_string)\n\n    valid_action_strings = {key: sorted(value) for key, value in valid_actions.items()}\n    return valid_action_strings", "response": "Generates all the valid actions for a given NLTK file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef return_type(self) -> Type:\n        return_type = self.second\n        while isinstance(return_type, ComplexType):\n            return_type = return_type.second\n        return return_type", "response": "Returns the final return type for this function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef argument_types(self) -> List[Type]:\n        arguments = [self.first]\n        remaining_type = self.second\n        while isinstance(remaining_type, ComplexType):\n            arguments.append(remaining_type.first)\n            remaining_type = remaining_type.second\n        return arguments", "response": "Returns the types of all arguments to this function."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes a set of BasicTypes and replaces any instances of ANY_TYPE inside thisCOOKIE class with each of those basic types.", "response": "def substitute_any_type(self, basic_types: Set[BasicType]) -> List[Type]:\n        \"\"\"\n        Takes a set of ``BasicTypes`` and replaces any instances of ``ANY_TYPE`` inside this\n        complex type with each of those basic types.\n        \"\"\"\n        substitutions = []\n        for first_type in substitute_any_type(self.first, basic_types):\n            for second_type in substitute_any_type(self.second, basic_types):\n                substitutions.append(self.__class__(first_type, second_type))\n        return substitutions"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nresolves the union of two types.", "response": "def resolve(self, other) -> Optional[Type]:\n        \"\"\"See ``PlaceholderType.resolve``\"\"\"\n        if not isinstance(other, NltkComplexType):\n            return None\n        other_first = other.first.resolve(other.second)\n        if not other_first:\n            return None\n        other_second = other.second.resolve(other_first)\n        if not other_second:\n            return None\n        return UnaryOpType(other_first, self._allowed_substitutions, self._signature)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresolving the NLTK ComplexType to the binary operation type.", "response": "def resolve(self, other: Type) -> Optional[Type]:\n        \"\"\"See ``PlaceholderType.resolve``\"\"\"\n        if not isinstance(other, NltkComplexType):\n            return None\n        if not isinstance(other.second, NltkComplexType):\n            return None\n        other_first = other.first.resolve(other.second.first)\n        if other_first is None:\n            return None\n        other_first = other_first.resolve(other.second.second)\n        if not other_first:\n            return None\n        other_second = other.second.resolve(ComplexType(other_first, other_first))\n        if not other_second:\n            return None\n        return BinaryOpType(other_first, self._allowed_substitutions, self._signature)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_type(self, other_type: Type = ANY_TYPE, signature=None) -> None:\n        super(DynamicTypeApplicationExpression, self)._set_type(other_type, signature)\n        # TODO(pradeep): Assuming the mapping of \"var\" function is \"V\". Do something better.\n        if isinstance(self.argument, ApplicationExpression) and str(self.argument.function) == \"V\":\n            # pylint: disable=protected-access\n            self.argument.argument._set_type(self.function.type.first)\n        if str(self.argument) == \"X\" and str(self.function) != \"V\":\n            # pylint: disable=protected-access\n            self.argument._set_type(self.function.type.first)", "response": "Override this method to set the type of the application expression."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend mean std of all parameters and gradients to Tensorboard as well as logging the average gradient norm.", "response": "def log_parameter_and_gradient_statistics(self, # pylint: disable=invalid-name\n                                              model: Model,\n                                              batch_grad_norm: float) -> None:\n        \"\"\"\n        Send the mean and std of all parameters and gradients to tensorboard, as well\n        as logging the average gradient norm.\n        \"\"\"\n        if self._should_log_parameter_statistics:\n            # Log parameter values to Tensorboard\n            for name, param in model.named_parameters():\n                self.add_train_scalar(\"parameter_mean/\" + name, param.data.mean())\n                self.add_train_scalar(\"parameter_std/\" + name, param.data.std())\n                if param.grad is not None:\n                    if param.grad.is_sparse:\n                        # pylint: disable=protected-access\n                        grad_data = param.grad.data._values()\n                    else:\n                        grad_data = param.grad.data\n\n                    # skip empty gradients\n                    if torch.prod(torch.tensor(grad_data.shape)).item() > 0: # pylint: disable=not-callable\n                        self.add_train_scalar(\"gradient_mean/\" + name, grad_data.mean())\n                        self.add_train_scalar(\"gradient_std/\" + name, grad_data.std())\n                    else:\n                        # no gradient for a parameter with sparse gradients\n                        logger.info(\"No gradient for %s, skipping tensorboard logging.\", name)\n            # norm of gradients\n            if batch_grad_norm is not None:\n                self.add_train_scalar(\"gradient_norm\", batch_grad_norm)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends learning rates to tensorboard", "response": "def log_learning_rates(self,\n                           model: Model,\n                           optimizer: torch.optim.Optimizer):\n        \"\"\"\n        Send current parameter specific learning rates to tensorboard\n        \"\"\"\n        if self._should_log_learning_rate:\n            # optimizer stores lr info keyed by parameter tensor\n            # we want to log with parameter name\n            names = {param: name for name, param in model.named_parameters()}\n            for group in optimizer.param_groups:\n                if 'lr' not in group:\n                    continue\n                rate = group['lr']\n                for param in group['params']:\n                    # check whether params has requires grad or not\n                    effective_rate = rate * float(param.requires_grad)\n                    self.add_train_scalar(\"learning_rate/\" + names[param], effective_rate)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef log_histograms(self, model: Model, histogram_parameters: Set[str]) -> None:\n        for name, param in model.named_parameters():\n            if name in histogram_parameters:\n                self.add_train_histogram(\"parameter_histogram/\" + name, param)", "response": "Send histograms of parameters to tensorboard."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef log_metrics(self,\n                    train_metrics: dict,\n                    val_metrics: dict = None,\n                    epoch: int = None,\n                    log_to_console: bool = False) -> None:\n        \"\"\"\n        Sends all of the train metrics (and validation metrics, if provided) to tensorboard.\n        \"\"\"\n        metric_names = set(train_metrics.keys())\n        if val_metrics is not None:\n            metric_names.update(val_metrics.keys())\n        val_metrics = val_metrics or {}\n\n        # For logging to the console\n        if log_to_console:\n            dual_message_template = \"%s |  %8.3f  |  %8.3f\"\n            no_val_message_template = \"%s |  %8.3f  |  %8s\"\n            no_train_message_template = \"%s |  %8s  |  %8.3f\"\n            header_template = \"%s |  %-10s\"\n            name_length = max([len(x) for x in metric_names])\n            logger.info(header_template, \"Training\".rjust(name_length + 13), \"Validation\")\n\n        for name in metric_names:\n            # Log to tensorboard\n            train_metric = train_metrics.get(name)\n            if train_metric is not None:\n                self.add_train_scalar(name, train_metric, timestep=epoch)\n            val_metric = val_metrics.get(name)\n            if val_metric is not None:\n                self.add_validation_scalar(name, val_metric, timestep=epoch)\n\n            # And maybe log to console\n            if log_to_console and val_metric is not None and train_metric is not None:\n                logger.info(dual_message_template, name.ljust(name_length), train_metric, val_metric)\n            elif log_to_console and val_metric is not None:\n                logger.info(no_train_message_template, name.ljust(name_length), \"N/A\", val_metric)\n            elif log_to_console and train_metric is not None:\n                logger.info(no_val_message_template, name.ljust(name_length), train_metric, \"N/A\")", "response": "Log the train and validation metrics to the tensorboard."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_explanation(logical_form: str,\n                    world_extractions: JsonDict,\n                    answer_index: int,\n                    world: QuarelWorld) -> List[JsonDict]:\n    \"\"\"\n    Create explanation (as a list of header/content entries) for an answer\n    \"\"\"\n    output = []\n    nl_world = {}\n    if world_extractions['world1'] != \"N/A\" and world_extractions['world1'] != [\"N/A\"]:\n        nl_world['world1'] = nl_world_string(world_extractions['world1'])\n        nl_world['world2'] = nl_world_string(world_extractions['world2'])\n        output.append({\n                \"header\": \"Identified two worlds\",\n                \"content\": [f'''world1 = {nl_world['world1']}''',\n                            f'''world2 = {nl_world['world2']}''']\n        })\n    else:\n        nl_world['world1'] = 'world1'\n        nl_world['world2'] = 'world2'\n    parse = semparse_util.lisp_to_nested_expression(logical_form)\n    if parse[0] != \"infer\":\n        return None\n    setup = parse[1]\n    output.append({\n            \"header\": \"The question is stating\",\n            \"content\": nl_arg(setup, nl_world)\n    })\n    answers = parse[2:]\n    output.append({\n            \"header\": \"The answer options are stating\",\n            \"content\": [\"A: \" + \" and \".join(nl_arg(answers[0], nl_world)),\n                        \"B: \" + \" and \".join(nl_arg(answers[1], nl_world))]\n    })\n    setup_core = setup\n    if setup[0] == 'and':\n        setup_core = setup[1]\n    s_attr = setup_core[0]\n    s_dir = world.qr_size[setup_core[1]]\n    s_world = nl_world[setup_core[2]]\n    a_attr = answers[answer_index][0]\n    qr_dir = world._get_qr_coeff(strip_entity_type(s_attr), strip_entity_type(a_attr))  # pylint: disable=protected-access\n    a_dir = s_dir * qr_dir\n    a_world = nl_world[answers[answer_index][2]]\n\n    content = [f'When {nl_attr(s_attr)} is {nl_dir(s_dir)} ' +\n               f'then {nl_attr(a_attr)} is {nl_dir(a_dir)} (for {s_world})']\n    if a_world != s_world:\n        content.append(f'''Therefore {nl_attr(a_attr)} is {nl_dir(-a_dir)} for {a_world}''')\n    content.append(f\"Therefore {chr(65+answer_index)} is the correct answer\")\n\n    output.append({\n            \"header\": \"Theory used\",\n            \"content\": content\n    })\n\n    return output", "response": "Returns the explanation of an answer in a single resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\naligns extracted worlds with given world literals.", "response": "def align_entities(extracted: List[str],\n                   literals: JsonDict,\n                   stemmer: NltkPorterStemmer) -> List[str]:\n    \"\"\"\n    Use stemming to attempt alignment between extracted world and given world literals.\n    If more words align to one world vs the other, it's considered aligned.\n    \"\"\"\n    literal_keys = list(literals.keys())\n    literal_values = list(literals.values())\n    overlaps = [get_stem_overlaps(extract, literal_values, stemmer) for extract in extracted]\n    worlds = []\n    for overlap in overlaps:\n        if overlap[0] > overlap[1]:\n            worlds.append(literal_keys[0])\n        elif overlap[0] < overlap[1]:\n            worlds.append(literal_keys[1])\n        else:\n            worlds.append(None)\n    return worlds"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef multi_perspective_match(vector1: torch.Tensor,\n                            vector2: torch.Tensor,\n                            weight: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Calculate multi-perspective cosine matching between time-steps of vectors\n    of the same length.\n\n    Parameters\n    ----------\n    vector1 : ``torch.Tensor``\n        A tensor of shape ``(batch, seq_len, hidden_size)``\n    vector2 : ``torch.Tensor``\n        A tensor of shape ``(batch, seq_len or 1, hidden_size)``\n    weight : ``torch.Tensor``\n        A tensor of shape ``(num_perspectives, hidden_size)``\n\n    Returns\n    -------\n    A tuple of two tensors consisting multi-perspective matching results.\n    The first one is of the shape (batch, seq_len, 1), the second one is of shape\n    (batch, seq_len, num_perspectives)\n    \"\"\"\n    assert vector1.size(0) == vector2.size(0)\n    assert weight.size(1) == vector1.size(2) == vector1.size(2)\n\n    # (batch, seq_len, 1)\n    similarity_single = F.cosine_similarity(vector1, vector2, 2).unsqueeze(2)\n\n    # (1, 1, num_perspectives, hidden_size)\n    weight = weight.unsqueeze(0).unsqueeze(0)\n\n    # (batch, seq_len, num_perspectives, hidden_size)\n    vector1 = weight * vector1.unsqueeze(2)\n    vector2 = weight * vector2.unsqueeze(2)\n\n    similarity_multi = F.cosine_similarity(vector1, vector2, dim=3)\n\n    return similarity_single, similarity_multi", "response": "Calculate multi - perspective cosine matching between time - steps of vectors vector1 and vector2."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating multi - perspective cosine matching between two vectors.", "response": "def multi_perspective_match_pairwise(vector1: torch.Tensor,\n                                     vector2: torch.Tensor,\n                                     weight: torch.Tensor,\n                                     eps: float = 1e-8) -> torch.Tensor:\n    \"\"\"\n    Calculate multi-perspective cosine matching between each time step of\n    one vector and each time step of another vector.\n\n    Parameters\n    ----------\n    vector1 : ``torch.Tensor``\n        A tensor of shape ``(batch, seq_len1, hidden_size)``\n    vector2 : ``torch.Tensor``\n        A tensor of shape ``(batch, seq_len2, hidden_size)``\n    weight : ``torch.Tensor``\n        A tensor of shape ``(num_perspectives, hidden_size)``\n    eps : ``float`` optional, (default = 1e-8)\n        A small value to avoid zero division problem\n\n    Returns\n    -------\n    A tensor of shape (batch, seq_len1, seq_len2, num_perspectives) consisting\n    multi-perspective matching results\n    \"\"\"\n    num_perspectives = weight.size(0)\n\n    # (1, num_perspectives, 1, hidden_size)\n    weight = weight.unsqueeze(0).unsqueeze(2)\n\n    # (batch, num_perspectives, seq_len*, hidden_size)\n    vector1 = weight * vector1.unsqueeze(1).expand(-1, num_perspectives, -1, -1)\n    vector2 = weight * vector2.unsqueeze(1).expand(-1, num_perspectives, -1, -1)\n\n    # (batch, num_perspectives, seq_len*, 1)\n    vector1_norm = vector1.norm(p=2, dim=3, keepdim=True)\n    vector2_norm = vector2.norm(p=2, dim=3, keepdim=True)\n\n    # (batch, num_perspectives, seq_len1, seq_len2)\n    mul_result = torch.matmul(vector1, vector2.transpose(2, 3))\n    norm_value = vector1_norm * vector2_norm.transpose(2, 3)\n\n    # (batch, seq_len1, seq_len2, num_perspectives)\n    return (mul_result / norm_value.clamp(min=eps)).permute(0, 2, 3, 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef forward(self,\n                context_1: torch.Tensor,\n                mask_1: torch.Tensor,\n                context_2: torch.Tensor,\n                mask_2: torch.Tensor) -> Tuple[List[torch.Tensor], List[torch.Tensor]]:\n        # pylint: disable=arguments-differ\n        \"\"\"\n        Given the forward (or backward) representations of sentence1 and sentence2, apply four bilateral\n        matching functions between them in one direction.\n\n        Parameters\n        ----------\n        context_1 : ``torch.Tensor``\n            Tensor of shape (batch_size, seq_len1, hidden_dim) representing the encoding of the first sentence.\n        mask_1 : ``torch.Tensor``\n            Binary Tensor of shape (batch_size, seq_len1), indicating which\n            positions in the first sentence are padding (0) and which are not (1).\n        context_2 : ``torch.Tensor``\n            Tensor of shape (batch_size, seq_len2, hidden_dim) representing the encoding of the second sentence.\n        mask_2 : ``torch.Tensor``\n            Binary Tensor of shape (batch_size, seq_len2), indicating which\n            positions in the second sentence are padding (0) and which are not (1).\n\n        Returns\n        -------\n        A tuple of matching vectors for the two sentences. Each of which is a list of\n        matching vectors of shape (batch, seq_len, num_perspectives or 1)\n        \"\"\"\n        assert (not mask_2.requires_grad) and (not mask_1.requires_grad)\n        assert context_1.size(-1) == context_2.size(-1) == self.hidden_dim\n\n        # (batch,)\n        len_1 = get_lengths_from_binary_sequence_mask(mask_1)\n        len_2 = get_lengths_from_binary_sequence_mask(mask_2)\n\n        # (batch, seq_len*)\n        mask_1, mask_2 = mask_1.float(), mask_2.float()\n\n        # explicitly set masked weights to zero\n        # (batch_size, seq_len*, hidden_dim)\n        context_1 = context_1 * mask_1.unsqueeze(-1)\n        context_2 = context_2 * mask_2.unsqueeze(-1)\n\n        # array to keep the matching vectors for the two sentences\n        matching_vector_1: List[torch.Tensor] = []\n        matching_vector_2: List[torch.Tensor] = []\n\n        # Step 0. unweighted cosine\n        # First calculate the cosine similarities between each forward\n        # (or backward) contextual embedding and every forward (or backward)\n        # contextual embedding of the other sentence.\n\n        # (batch, seq_len1, seq_len2)\n        cosine_sim = F.cosine_similarity(context_1.unsqueeze(-2), context_2.unsqueeze(-3), dim=3)\n\n        # (batch, seq_len*, 1)\n        cosine_max_1 = masked_max(cosine_sim, mask_2.unsqueeze(-2), dim=2, keepdim=True)\n        cosine_mean_1 = masked_mean(cosine_sim, mask_2.unsqueeze(-2), dim=2, keepdim=True)\n        cosine_max_2 = masked_max(cosine_sim.permute(0, 2, 1), mask_1.unsqueeze(-2), dim=2, keepdim=True)\n        cosine_mean_2 = masked_mean(cosine_sim.permute(0, 2, 1), mask_1.unsqueeze(-2), dim=2, keepdim=True)\n\n        matching_vector_1.extend([cosine_max_1, cosine_mean_1])\n        matching_vector_2.extend([cosine_max_2, cosine_mean_2])\n\n        # Step 1. Full-Matching\n        # Each time step of forward (or backward) contextual embedding of one sentence\n        # is compared with the last time step of the forward (or backward)\n        # contextual embedding of the other sentence\n        if self.with_full_match:\n\n            # (batch, 1, hidden_dim)\n            if self.is_forward:\n                # (batch, 1, hidden_dim)\n                last_position_1 = (len_1 - 1).clamp(min=0)\n                last_position_1 = last_position_1.view(-1, 1, 1).expand(-1, 1, self.hidden_dim)\n                last_position_2 = (len_2 - 1).clamp(min=0)\n                last_position_2 = last_position_2.view(-1, 1, 1).expand(-1, 1, self.hidden_dim)\n\n                context_1_last = context_1.gather(1, last_position_1)\n                context_2_last = context_2.gather(1, last_position_2)\n            else:\n                context_1_last = context_1[:, 0:1, :]\n                context_2_last = context_2[:, 0:1, :]\n\n            # (batch, seq_len*, num_perspectives)\n            matching_vector_1_full = multi_perspective_match(context_1,\n                                                             context_2_last,\n                                                             self.full_match_weights)\n            matching_vector_2_full = multi_perspective_match(context_2,\n                                                             context_1_last,\n                                                             self.full_match_weights_reversed)\n\n            matching_vector_1.extend(matching_vector_1_full)\n            matching_vector_2.extend(matching_vector_2_full)\n\n        # Step 2. Maxpooling-Matching\n        # Each time step of forward (or backward) contextual embedding of one sentence\n        # is compared with every time step of the forward (or backward)\n        # contextual embedding of the other sentence, and only the max value of each\n        # dimension is retained.\n        if self.with_maxpool_match:\n            # (batch, seq_len1, seq_len2, num_perspectives)\n            matching_vector_max = multi_perspective_match_pairwise(context_1,\n                                                                   context_2,\n                                                                   self.maxpool_match_weights)\n\n            # (batch, seq_len*, num_perspectives)\n            matching_vector_1_max = masked_max(matching_vector_max,\n                                               mask_2.unsqueeze(-2).unsqueeze(-1),\n                                               dim=2)\n            matching_vector_1_mean = masked_mean(matching_vector_max,\n                                                 mask_2.unsqueeze(-2).unsqueeze(-1),\n                                                 dim=2)\n            matching_vector_2_max = masked_max(matching_vector_max.permute(0, 2, 1, 3),\n                                               mask_1.unsqueeze(-2).unsqueeze(-1),\n                                               dim=2)\n            matching_vector_2_mean = masked_mean(matching_vector_max.permute(0, 2, 1, 3),\n                                                 mask_1.unsqueeze(-2).unsqueeze(-1),\n                                                 dim=2)\n\n            matching_vector_1.extend([matching_vector_1_max, matching_vector_1_mean])\n            matching_vector_2.extend([matching_vector_2_max, matching_vector_2_mean])\n\n\n        # Step 3. Attentive-Matching\n        # Each forward (or backward) similarity is taken as the weight\n        # of the forward (or backward) contextual embedding, and calculate an\n        # attentive vector for the sentence by weighted summing all its\n        # contextual embeddings.\n        # Finally match each forward (or backward) contextual embedding\n        # with its corresponding attentive vector.\n\n        # (batch, seq_len1, seq_len2, hidden_dim)\n        att_2 = context_2.unsqueeze(-3) * cosine_sim.unsqueeze(-1)\n\n        # (batch, seq_len1, seq_len2, hidden_dim)\n        att_1 = context_1.unsqueeze(-2) * cosine_sim.unsqueeze(-1)\n\n        if self.with_attentive_match:\n            # (batch, seq_len*, hidden_dim)\n            att_mean_2 = masked_softmax(att_2.sum(dim=2), mask_1.unsqueeze(-1))\n            att_mean_1 = masked_softmax(att_1.sum(dim=1), mask_2.unsqueeze(-1))\n\n            # (batch, seq_len*, num_perspectives)\n            matching_vector_1_att_mean = multi_perspective_match(context_1,\n                                                                 att_mean_2,\n                                                                 self.attentive_match_weights)\n            matching_vector_2_att_mean = multi_perspective_match(context_2,\n                                                                 att_mean_1,\n                                                                 self.attentive_match_weights_reversed)\n            matching_vector_1.extend(matching_vector_1_att_mean)\n            matching_vector_2.extend(matching_vector_2_att_mean)\n\n        # Step 4. Max-Attentive-Matching\n        # Pick the contextual embeddings with the highest cosine similarity as the attentive\n        # vector, and match each forward (or backward) contextual embedding with its\n        # corresponding attentive vector.\n        if self.with_max_attentive_match:\n            # (batch, seq_len*, hidden_dim)\n            att_max_2 = masked_max(att_2, mask_2.unsqueeze(-2).unsqueeze(-1), dim=2)\n            att_max_1 = masked_max(att_1.permute(0, 2, 1, 3), mask_1.unsqueeze(-2).unsqueeze(-1), dim=2)\n\n            # (batch, seq_len*, num_perspectives)\n            matching_vector_1_att_max = multi_perspective_match(context_1,\n                                                                att_max_2,\n                                                                self.max_attentive_match_weights)\n            matching_vector_2_att_max = multi_perspective_match(context_2,\n                                                                att_max_1,\n                                                                self.max_attentive_match_weights_reversed)\n\n            matching_vector_1.extend(matching_vector_1_att_max)\n            matching_vector_2.extend(matching_vector_2_att_max)\n\n        return matching_vector_1, matching_vector_2", "response": "Given the forward representations of sentence1 and sentence2 apply four bilateral - level matching functions between them in one direction."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_example_line(lisp_string: str) -> Dict:\n    id_piece, rest = lisp_string.split(') (utterance \"')\n    example_id = id_piece.split('(id ')[1]\n    question, rest = rest.split('\") (context (graph tables.TableKnowledgeGraph ')\n    table_filename, rest = rest.split(')) (targetValue (list')\n    target_value_strings = rest.strip().split(\"(description\")\n    target_values = []\n    for string in target_value_strings:\n        string = string.replace(\")\", \"\").replace('\"', '').strip()\n        if string != \"\":\n            target_values.append(string)\n    return {'id': example_id,\n            'question': question,\n            'table_filename': table_filename,\n            'target_values': target_values}", "response": "Parse a single line of lisp into a dictionary of examples."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef execute(self, lf_raw: str) -> int:\n        # Remove \"a:\" prefixes from attributes (hack)\n        logical_form = re.sub(r\"\\(a:\", r\"(\", lf_raw)\n        parse = semparse_util.lisp_to_nested_expression(logical_form)\n        if len(parse) < 2:\n            return -1\n        if parse[0] == 'infer':\n            args = [self._exec_and(arg) for arg in parse[1:]]\n            if None in args:\n                return -1\n            return self._exec_infer(*args)\n        return -1", "response": "Execute the friction logical form and return the index of the answer or - 1 if no answer can be concluded."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive an utterance and a character offset map and a set of indices of words return a dictionary that maps the times to the corresponding times.", "response": "def get_times_from_utterance(utterance: str,\n                             char_offset_to_token_index: Dict[int, int],\n                             indices_of_approximate_words: Set[int]) -> Dict[str, List[int]]:\n    \"\"\"\n    Given an utterance, we get the numbers that correspond to times and convert them to\n    values that may appear in the query. For example: convert ``7pm`` to ``1900``.\n    \"\"\"\n\n    pm_linking_dict = _time_regex_match(r'\\d+pm',\n                                        utterance,\n                                        char_offset_to_token_index,\n                                        pm_map_match_to_query_value,\n                                        indices_of_approximate_words)\n\n    am_linking_dict = _time_regex_match(r'\\d+am',\n                                        utterance,\n                                        char_offset_to_token_index,\n                                        am_map_match_to_query_value,\n                                        indices_of_approximate_words)\n\n    oclock_linking_dict = _time_regex_match(r\"\\d+ o'clock\",\n                                            utterance,\n                                            char_offset_to_token_index,\n                                            lambda match: digit_to_query_time(match.rstrip(\" o'clock\")),\n                                            indices_of_approximate_words)\n\n    hours_linking_dict = _time_regex_match(r\"\\d+ hours\",\n                                           utterance,\n                                           char_offset_to_token_index,\n                                           lambda match: [int(match.rstrip(\" hours\"))],\n                                           indices_of_approximate_words)\n\n\n    times_linking_dict: Dict[str, List[int]] = defaultdict(list)\n    linking_dicts = [pm_linking_dict, am_linking_dict, oclock_linking_dict, hours_linking_dict]\n\n    for linking_dict in linking_dicts:\n        for key, value in linking_dict.items():\n            times_linking_dict[key].extend(value)\n\n    return times_linking_dict"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of dates from the utterance.", "response": "def get_date_from_utterance(tokenized_utterance: List[Token],\n                            year: int = 1993) -> List[datetime]:\n    \"\"\"\n    When the year is not explicitly mentioned in the utterance, the query assumes that\n    it is 1993 so we do the same here. If there is no mention of the month or day then\n    we do not return any dates from the utterance.\n    \"\"\"\n\n    dates = []\n\n    utterance = ' '.join([token.text for token in tokenized_utterance])\n    year_result = re.findall(r'199[0-4]', utterance)\n    if year_result:\n        year = int(year_result[0])\n    trigrams = ngrams([token.text for token in tokenized_utterance], 3)\n    for month, tens, digit in trigrams:\n        # This will match something like ``september twenty first``.\n        day = ' '.join([tens, digit])\n        if month in MONTH_NUMBERS and day in DAY_NUMBERS:\n            try:\n                dates.append(datetime(year, MONTH_NUMBERS[month], DAY_NUMBERS[day]))\n            except ValueError:\n                print('invalid month day')\n\n    bigrams = ngrams([token.text for token in tokenized_utterance], 2)\n    for month, day in bigrams:\n        if month in MONTH_NUMBERS and day in DAY_NUMBERS:\n            # This will match something like ``september first``.\n            try:\n                dates.append(datetime(year, MONTH_NUMBERS[month], DAY_NUMBERS[day]))\n            except ValueError:\n                print('invalid month day')\n\n    fivegrams = ngrams([token.text for token in tokenized_utterance], 5)\n    for tens, digit, _, year_match, month in fivegrams:\n        # This will match something like ``twenty first of 1993 july``.\n        day = ' '.join([tens, digit])\n        if month in MONTH_NUMBERS and day in DAY_NUMBERS and year_match.isdigit():\n            try:\n                dates.append(datetime(int(year_match), MONTH_NUMBERS[month], DAY_NUMBERS[day]))\n            except ValueError:\n                print('invalid month day')\n        if month in MONTH_NUMBERS and digit in DAY_NUMBERS and year_match.isdigit():\n            try:\n                dates.append(datetime(int(year_match), MONTH_NUMBERS[month], DAY_NUMBERS[digit]))\n            except ValueError:\n                print('invalid month day')\n    return dates"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_numbers_from_utterance(utterance: str, tokenized_utterance: List[Token]) -> Dict[str, List[int]]:\n    # When we use a regex to find numbers or strings, we need a mapping from\n    # the character to which token triggered it.\n    char_offset_to_token_index = {token.idx : token_index\n                                  for token_index, token in enumerate(tokenized_utterance)}\n\n    # We want to look up later for each time whether it appears after a word\n    # such as \"about\" or \"approximately\".\n    indices_of_approximate_words = {index for index, token in enumerate(tokenized_utterance)\n                                    if token.text in APPROX_WORDS}\n\n    indices_of_words_preceding_time = {index for index, token in enumerate(tokenized_utterance)\n                                       if token.text in WORDS_PRECEDING_TIME}\n\n    indices_of_am_pm = {index for index, token in enumerate(tokenized_utterance)\n                        if token.text in {'am', 'pm'}}\n\n    number_linking_dict: Dict[str, List[int]] = defaultdict(list)\n\n    for token_index, token in enumerate(tokenized_utterance):\n        if token.text.isdigit():\n            if token_index - 1 in indices_of_words_preceding_time and token_index + 1 not in indices_of_am_pm:\n                for time in digit_to_query_time(token.text):\n                    number_linking_dict[str(time)].append(token_index)\n    times_linking_dict = get_times_from_utterance(utterance,\n                                                  char_offset_to_token_index,\n                                                  indices_of_approximate_words)\n    for key, value in times_linking_dict.items():\n        number_linking_dict[key].extend(value)\n\n    for index, token in enumerate(tokenized_utterance):\n        for number in NUMBER_TRIGGER_DICT.get(token.text, []):\n            if index - 1 in indices_of_approximate_words:\n                for approx_time in get_approximate_times([int(number)]):\n                    number_linking_dict[str(approx_time)].append(index)\n            else:\n                number_linking_dict[number].append(index)\n    return number_linking_dict", "response": "Given an utterance this function finds all the numbers that are in the action space and returns a dictionary that maps the string representation of the number and the list of token indices that triggers that number."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a digit in the utterance return a list of the times that it corresponds to.", "response": "def digit_to_query_time(digit: str) -> List[int]:\n    \"\"\"\n    Given a digit in the utterance, return a list of the times that it corresponds to.\n    \"\"\"\n    if len(digit) > 2:\n        return [int(digit), int(digit) + TWELVE_TO_TWENTY_FOUR]\n    elif int(digit) % 12 == 0:\n        return [0, 1200, 2400]\n    return [int(digit) * HOUR_TO_TWENTY_FOUR,\n            (int(digit) * HOUR_TO_TWENTY_FOUR + TWELVE_TO_TWENTY_FOUR) % HOURS_IN_DAY]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive a list of times that follow a word such as about 7pm then we return a list of times that could appear in the query as a result .", "response": "def get_approximate_times(times: List[int]) -> List[int]:\n    \"\"\"\n    Given a list of times that follow a word such as ``about``,\n    we return a list of times that could appear in the query as a result\n    of this. For example if ``about 7pm`` appears in the utterance, then\n    we also want to add ``1830`` and ``1930``.\n    \"\"\"\n    approximate_times = []\n    for time in times:\n        hour = int(time/HOUR_TO_TWENTY_FOUR) % 24\n        minute = time % HOUR_TO_TWENTY_FOUR\n        approximate_time = datetime.now()\n        approximate_time = approximate_time.replace(hour=hour, minute=minute)\n\n        start_time_range = approximate_time - timedelta(minutes=30)\n        end_time_range = approximate_time + timedelta(minutes=30)\n        approximate_times.extend([start_time_range.hour * HOUR_TO_TWENTY_FOUR + start_time_range.minute,\n                                  end_time_range.hour * HOUR_TO_TWENTY_FOUR + end_time_range.minute])\n\n    return approximate_times"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _time_regex_match(regex: str,\n                      utterance: str,\n                      char_offset_to_token_index: Dict[int, int],\n                      map_match_to_query_value: Callable[[str], List[int]],\n                      indices_of_approximate_words: Set[int]) -> Dict[str, List[int]]:\n    r\"\"\"\n    Given a regex for matching times in the utterance, we want to convert the matches\n    to the values that appear in the query and token indices they correspond to.\n\n    ``char_offset_to_token_index`` is a dictionary that maps from the character offset to\n    the token index, we use this to look up what token a regex match corresponds to.\n    ``indices_of_approximate_words`` are the token indices of the words such as ``about`` or\n    ``approximately``. We use this to check if a regex match is preceded by one of these words.\n    If it is, we also want to add the times that define this approximate time range.\n\n    ``map_match_to_query_value`` is a function that converts the regex matches to the\n    values that appear in the query. For example, we may pass in a regex such as ``\\d+pm``\n    that matches times such as ``7pm``. ``map_match_to_query_value`` would be a function that\n    takes ``7pm`` as input and returns ``1900``.\n    \"\"\"\n    linking_scores_dict: Dict[str, List[int]] = defaultdict(list)\n    number_regex = re.compile(regex)\n    for match in number_regex.finditer(utterance):\n        query_values = map_match_to_query_value(match.group())\n        # If the time appears after a word like ``about`` then we also add\n        # the times that mark the start and end of the allowed range.\n        approximate_times = []\n        if char_offset_to_token_index.get(match.start(), 0) - 1 in indices_of_approximate_words:\n            approximate_times.extend(get_approximate_times(query_values))\n        query_values.extend(approximate_times)\n        if match.start() in char_offset_to_token_index:\n            for query_value in query_values:\n                linking_scores_dict[str(query_value)].extend([char_offset_to_token_index[match.start()],\n                                                              char_offset_to_token_index[match.start()] + 1])\n    return linking_scores_dict", "response": "r Given a regex for matching times in the utterance we want to convert it to the values that appear in the query and then add the times that are allowed to the utterance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nevaluate the predicted query and the query label of the sql query.", "response": "def _evaluate_sql_query_subprocess(self, predicted_query: str, sql_query_labels: List[str]) -> int:\n        \"\"\"\n        We evaluate here whether the predicted query and the query label evaluate to the\n        exact same table. This method is only called by the subprocess, so we just exit with\n        1 if it is correct and 0 otherwise.\n        \"\"\"\n\n        postprocessed_predicted_query = self.postprocess_query_sqlite(predicted_query)\n\n        try:\n            self._cursor.execute(postprocessed_predicted_query)\n            predicted_rows = self._cursor.fetchall()\n        except sqlite3.Error as error:\n            logger.warning(f'Error executing predicted: {error}')\n            exit(0)\n\n        # If predicted table matches any of the reference tables then it is counted as correct.\n        target_rows = None\n        for sql_query_label in sql_query_labels:\n            postprocessed_sql_query_label = self.postprocess_query_sqlite(sql_query_label)\n            try:\n                self._cursor.execute(postprocessed_sql_query_label)\n                target_rows = self._cursor.fetchall()\n            except sqlite3.Error as error:\n                logger.warning(f'Error executing predicted: {error}')\n            if predicted_rows == target_rows:\n                exit(1)\n        exit(0)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nformatting a dictionary of production rules into a string format expected by Parsimonious Grammar class.", "response": "def format_grammar_string(grammar_dictionary: Dict[str, List[str]]) -> str:\n    \"\"\"\n    Formats a dictionary of production rules into the string format expected\n    by the Parsimonious Grammar class.\n    \"\"\"\n    grammar_string = '\\n'.join([f\"{nonterminal} = {' / '.join(right_hand_side)}\"\n                                for nonterminal, right_hand_side in grammar_dictionary.items()])\n    return grammar_string.replace(\"\\\\\", \"\\\\\\\\\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef initialize_valid_actions(grammar: Grammar,\n                             keywords_to_uppercase: List[str] = None) -> Dict[str, List[str]]:\n    \"\"\"\n    We initialize the valid actions with the global actions. These include the\n    valid actions that result from the grammar and also those that result from\n    the tables provided. The keys represent the nonterminals in the grammar\n    and the values are lists of the valid actions of that nonterminal.\n    \"\"\"\n    valid_actions: Dict[str, Set[str]] = defaultdict(set)\n\n    for key in grammar:\n        rhs = grammar[key]\n\n        # Sequence represents a series of expressions that match pieces of the text in order.\n        # Eg. A -> B C\n        if isinstance(rhs, Sequence):\n            valid_actions[key].add(format_action(key, \" \".join(rhs._unicode_members()), # pylint: disable=protected-access\n                                                 keywords_to_uppercase=keywords_to_uppercase))\n\n        # OneOf represents a series of expressions, one of which matches the text.\n        # Eg. A -> B / C\n        elif isinstance(rhs, OneOf):\n            for option in rhs._unicode_members(): # pylint: disable=protected-access\n                valid_actions[key].add(format_action(key, option,\n                                                     keywords_to_uppercase=keywords_to_uppercase))\n\n        # A string literal, eg. \"A\"\n        elif isinstance(rhs, Literal):\n            if rhs.literal != \"\":\n                valid_actions[key].add(format_action(key, repr(rhs.literal),\n                                                     keywords_to_uppercase=keywords_to_uppercase))\n            else:\n                valid_actions[key] = set()\n\n    valid_action_strings = {key: sorted(value) for key, value in valid_actions.items()}\n    return valid_action_strings", "response": "Initialize the valid actions for the grammar."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef format_action(nonterminal: str,\n                  right_hand_side: str,\n                  is_string: bool = False,\n                  is_number: bool = False,\n                  keywords_to_uppercase: List[str] = None) -> str:\n    \"\"\"\n    This function formats an action as it appears in models. It\n    splits productions based on the special `ws` and `wsp` rules,\n    which are used in grammars to denote whitespace, and then\n    rejoins these tokens a formatted, comma separated list.\n    Importantly, note that it `does not` split on spaces in\n    the grammar string, because these might not correspond\n    to spaces in the language the grammar recognises.\n\n    Parameters\n    ----------\n    nonterminal : ``str``, required.\n        The nonterminal in the action.\n    right_hand_side : ``str``, required.\n        The right hand side of the action\n        (i.e the thing which is produced).\n    is_string : ``bool``, optional (default = False).\n        Whether the production produces a string.\n        If it does, it is formatted as ``nonterminal -> ['string']``\n    is_number : ``bool``, optional, (default = False).\n        Whether the production produces a string.\n        If it does, it is formatted as ``nonterminal -> ['number']``\n    keywords_to_uppercase: ``List[str]``, optional, (default = None)\n        Keywords in the grammar to uppercase. In the case of sql,\n        this might be SELECT, MAX etc.\n    \"\"\"\n    keywords_to_uppercase = keywords_to_uppercase or []\n    if right_hand_side.upper() in keywords_to_uppercase:\n        right_hand_side = right_hand_side.upper()\n\n    if is_string:\n        return f'{nonterminal} -> [\"\\'{right_hand_side}\\'\"]'\n\n    elif is_number:\n        return f'{nonterminal} -> [\"{right_hand_side}\"]'\n\n    else:\n        right_hand_side = right_hand_side.lstrip(\"(\").rstrip(\")\")\n        child_strings = [token for token in WHITESPACE_REGEX.split(right_hand_side) if token]\n        child_strings = [tok.upper() if tok.upper() in keywords_to_uppercase else tok for tok in child_strings]\n        return f\"{nonterminal} -> [{', '.join(child_strings)}]\"", "response": "This function formats an action in the grammar."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_action(self, node: Node) -> None:\n        if node.expr.name and node.expr.name not in ['ws', 'wsp']:\n            nonterminal = f'{node.expr.name} -> '\n\n            if isinstance(node.expr, Literal):\n                right_hand_side = f'[\"{node.text}\"]'\n\n            else:\n                child_strings = []\n                for child in node.__iter__():\n                    if child.expr.name in ['ws', 'wsp']:\n                        continue\n                    if child.expr.name != '':\n                        child_strings.append(child.expr.name)\n                    else:\n                        child_right_side_string = child.expr._as_rhs().lstrip(\"(\").rstrip(\")\") # pylint: disable=protected-access\n                        child_right_side_list = [tok for tok in\n                                                 WHITESPACE_REGEX.split(child_right_side_string) if tok]\n                        child_right_side_list = [tok.upper() if tok.upper() in\n                                                 self.keywords_to_uppercase else tok\n                                                 for tok in child_right_side_list]\n                        child_strings.extend(child_right_side_list)\n                right_hand_side = \"[\" + \", \".join(child_strings) + \"]\"\n            rule = nonterminal + right_hand_side\n            self.action_sequence = [rule] + self.action_sequence", "response": "Adds the node to the action_sequence."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvisits a node and return the node s unique ID.", "response": "def visit(self, node):\n        \"\"\"\n        See the ``NodeVisitor`` visit method. This just changes the order in which\n        we visit nonterminals from right to left to left to right.\n        \"\"\"\n        method = getattr(self, 'visit_' + node.expr_name, self.generic_visit)\n\n        # Call that method, and show where in the tree it failed if it blows\n        # up.\n        try:\n            # Changing this to reverse here!\n            return method(node, [self.visit(child) for child in reversed(list(node))])\n        except (VisitationError, UndefinedLabel):\n            # Don't catch and re-wrap already-wrapped exceptions.\n            raise\n        except self.unwrapped_exceptions:\n            raise\n        except Exception: # pylint: disable=broad-except\n            # Catch any exception, and tack on a parse tree so it's easier to\n            # see where it went wrong.\n            exc_class, exc, traceback = exc_info()\n            reraise(VisitationError, VisitationError(exc, exc_class, node), traceback)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nforwarding computation of the BERT model.", "response": "def forward(self,\n                input_ids: torch.LongTensor,\n                offsets: torch.LongTensor = None,\n                token_type_ids: torch.LongTensor = None) -> torch.Tensor:\n        \"\"\"\n        Parameters\n        ----------\n        input_ids : ``torch.LongTensor``\n            The (batch_size, ..., max_sequence_length) tensor of wordpiece ids.\n        offsets : ``torch.LongTensor``, optional\n            The BERT embeddings are one per wordpiece. However it's possible/likely\n            you might want one per original token. In that case, ``offsets``\n            represents the indices of the desired wordpiece for each original token.\n            Depending on how your token indexer is configured, this could be the\n            position of the last wordpiece for each token, or it could be the position\n            of the first wordpiece for each token.\n\n            For example, if you had the sentence \"Definitely not\", and if the corresponding\n            wordpieces were [\"Def\", \"##in\", \"##ite\", \"##ly\", \"not\"], then the input_ids\n            would be 5 wordpiece ids, and the \"last wordpiece\" offsets would be [3, 4].\n            If offsets are provided, the returned tensor will contain only the wordpiece\n            embeddings at those positions, and (in particular) will contain one embedding\n            per token. If offsets are not provided, the entire tensor of wordpiece embeddings\n            will be returned.\n        token_type_ids : ``torch.LongTensor``, optional\n            If an input consists of two sentences (as in the BERT paper),\n            tokens from the first sentence should have type 0 and tokens from\n            the second sentence should have type 1.  If you don't provide this\n            (the default BertIndexer doesn't) then it's assumed to be all 0s.\n        \"\"\"\n        # pylint: disable=arguments-differ\n        if token_type_ids is None:\n            token_type_ids = torch.zeros_like(input_ids)\n\n        input_mask = (input_ids != 0).long()\n\n        # input_ids may have extra dimensions, so we reshape down to 2-d\n        # before calling the BERT model and then reshape back at the end.\n        all_encoder_layers, _ = self.bert_model(input_ids=util.combine_initial_dims(input_ids),\n                                                token_type_ids=util.combine_initial_dims(token_type_ids),\n                                                attention_mask=util.combine_initial_dims(input_mask))\n        if self._scalar_mix is not None:\n            mix = self._scalar_mix(all_encoder_layers, input_mask)\n        else:\n            mix = all_encoder_layers[-1]\n\n        # At this point, mix is (batch_size * d1 * ... * dn, sequence_length, embedding_dim)\n\n        if offsets is None:\n            # Resize to (batch_size, d1, ..., dn, sequence_length, embedding_dim)\n            return util.uncombine_initial_dims(mix, input_ids.size())\n        else:\n            # offsets is (batch_size, d1, ..., dn, orig_sequence_length)\n            offsets2d = util.combine_initial_dims(offsets)\n            # now offsets is (batch_size * d1 * ... * dn, orig_sequence_length)\n            range_vector = util.get_range_vector(offsets2d.size(0),\n                                                 device=util.get_device_of(mix)).unsqueeze(1)\n            # selected embeddings is also (batch_size * d1 * ... * dn, orig_sequence_length)\n            selected_embeddings = mix[range_vector, offsets2d]\n\n            return util.uncombine_initial_dims(selected_embeddings, offsets.size())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_grammar_to_be_variable_free(grammar_dictionary: Dict[str, List[str]]):\n\n    # Tables in variable free grammars cannot be aliased, so we\n    # remove this functionality from the grammar.\n    grammar_dictionary[\"select_result\"] = ['\"*\"', '(table_name ws \".*\")', 'expr']\n\n    # Similarly, collapse the definition of a source table\n    # to not contain aliases and modify references to subqueries.\n    grammar_dictionary[\"single_source\"] = ['table_name', '(\"(\" ws query ws \")\")']\n    del grammar_dictionary[\"source_subq\"]\n    del grammar_dictionary[\"source_table\"]\n\n    grammar_dictionary[\"expr\"] = ['in_expr',\n                                  '(value wsp \"LIKE\" wsp string)',\n                                  '(value ws \"BETWEEN\" wsp value ws \"AND\" wsp value)',\n                                  '(value ws binaryop wsp expr)',\n                                  '(unaryop ws expr)',\n                                  '(col_ref ws \"IS\" ws \"NOT\" ws \"NULL\")',\n                                  '(col_ref ws \"IS\" ws \"NULL\")',\n                                  # This used to be source_subq - now\n                                  # we don't need aliases, we can colapse it to queries.\n                                  '(\"(\" ws query ws \")\")',\n                                  'value']\n\n    # Finally, remove the ability to reference an arbitrary name,\n    # because now we don't have aliased tables, we don't need\n    # to recognise new variables.\n    del grammar_dictionary[\"name\"]", "response": "Update the grammar dictionary to be variable free."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_grammar_with_untyped_entities(grammar_dictionary: Dict[str, List[str]]) -> None:\n    grammar_dictionary[\"string_set_vals\"] = ['(value ws \",\" ws string_set_vals)', 'value']\n    grammar_dictionary[\"value\"].remove('string')\n    grammar_dictionary[\"value\"].remove('number')\n    grammar_dictionary[\"limit\"] = ['(\"LIMIT\" ws \"1\")', '(\"LIMIT\" ws value)']\n    grammar_dictionary[\"expr\"][1] = '(value wsp \"LIKE\" wsp value)'\n    del grammar_dictionary[\"string\"]\n    del grammar_dictionary[\"number\"]", "response": "Update the grammar with untyped entities."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload the model from the given parameters.", "response": "def _load(cls,\n              config: Params,\n              serialization_dir: str,\n              weights_file: str = None,\n              cuda_device: int = -1) -> 'Model':\n        \"\"\"\n        Ensembles don't have vocabularies or weights of their own, so they override _load.\n        \"\"\"\n        model_params = config.get('model')\n\n        # The experiment config tells us how to _train_ a model, including where to get pre-trained\n        # embeddings from.  We're now _loading_ the model, so those embeddings will already be\n        # stored in our weights.  We don't need any pretrained weight file anymore, and we don't\n        # want the code to look for it, so we remove it from the parameters here.\n        remove_pretrained_embedding_params(model_params)\n        model = Model.from_params(vocab=None, params=model_params)\n\n        # Force model to cpu or gpu, as appropriate, to make sure that the embeddings are\n        # in sync with the weights\n        if cuda_device >= 0:\n            model.cuda(cuda_device)\n        else:\n            model.cpu()\n\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef text_standardize(text):\n    text = text.replace('\u2014', '-')\n    text = text.replace('\u2013', '-')\n    text = text.replace('\u2015', '-')\n    text = text.replace('\u2026', '...')\n    text = text.replace('\u00b4', \"'\")\n    text = re.sub(r'''(-+|~+|!+|\"+|;+|\\?+|\\++|,+|\\)+|\\(+|\\\\+|\\/+|\\*+|\\[+|\\]+|}+|{+|\\|+|_+)''', r' \\1 ', text)\n    text = re.sub(r'\\s*\\n\\s*', ' \\n ', text)\n    text = re.sub(r'[^\\S\\n]+', ' ', text)\n    return text.strip()", "response": "Apply text standardization following original implementation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main(prog: str = None,\n         subcommand_overrides: Dict[str, Subcommand] = {}) -> None:\n    \"\"\"\n    The :mod:`~allennlp.run` command only knows about the registered classes in the ``allennlp``\n    codebase. In particular, once you start creating your own ``Model`` s and so forth, it won't\n    work for them, unless you use the ``--include-package`` flag.\n    \"\"\"\n    # pylint: disable=dangerous-default-value\n    parser = ArgumentParserWithDefaults(description=\"Run AllenNLP\", usage='%(prog)s', prog=prog)\n    parser.add_argument('--version', action='version', version='%(prog)s ' + __version__)\n\n    subparsers = parser.add_subparsers(title='Commands', metavar='')\n\n    subcommands = {\n            # Default commands\n            \"configure\": Configure(),\n            \"train\": Train(),\n            \"evaluate\": Evaluate(),\n            \"predict\": Predict(),\n            \"make-vocab\": MakeVocab(),\n            \"elmo\": Elmo(),\n            \"fine-tune\": FineTune(),\n            \"dry-run\": DryRun(),\n            \"test-install\": TestInstall(),\n            \"find-lr\": FindLearningRate(),\n            \"print-results\": PrintResults(),\n            # Superseded by overrides\n            **subcommand_overrides\n    }\n\n    for name, subcommand in subcommands.items():\n        subparser = subcommand.add_subparser(name, subparsers)\n        # configure doesn't need include-package because it imports\n        # whatever classes it needs.\n        if name != \"configure\":\n            subparser.add_argument('--include-package',\n                                   type=str,\n                                   action='append',\n                                   default=[],\n                                   help='additional packages to include')\n\n    args = parser.parse_args()\n\n    # If a subparser is triggered, it adds its work as `args.func`.\n    # So if no such attribute has been added, no subparser was triggered,\n    # so give the user some help.\n    if 'func' in dir(args):\n        # Import any additional modules needed (to register custom classes).\n        for package_name in getattr(args, 'include_package', ()):\n            import_submodules(package_name)\n        args.func(args)\n    else:\n        parser.print_help()", "response": "The main function of the AllenNLP run command."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_padding_lengths(self) -> Dict[str, int]:\n        # Our basic outline: we will iterate over `TokenIndexers`, and aggregate lengths over tokens\n        # for each indexer separately.  Then we will combine the results for each indexer into a single\n        # dictionary, resolving any (unlikely) key conflicts by taking a max.\n        lengths = []\n        if self._indexed_tokens is None:\n            raise ConfigurationError(\"You must call .index(vocabulary) on a \"\n                                     \"field before determining padding lengths.\")\n\n        # Each indexer can return a different sequence length, and for indexers that return\n        # multiple arrays each can have a different length.  We'll keep track of them here.\n        for indexer_name, indexer in self._token_indexers.items():\n            indexer_lengths = {}\n\n            for indexed_tokens_key in self._indexer_name_to_indexed_token[indexer_name]:\n                # This is a list of dicts, one for each token in the field.\n                token_lengths = [indexer.get_padding_lengths(token)\n                                 for token in self._indexed_tokens[indexed_tokens_key]]\n            if not token_lengths:\n                # This is a padding edge case and occurs when we want to pad a ListField of\n                # TextFields. In order to pad the list field, we need to be able to have an\n                # _empty_ TextField, but if this is the case, token_lengths will be an empty\n                # list, so we add the default empty padding dictionary to the list instead.\n                token_lengths = [{}]\n            # Iterate over the keys and find the maximum token length.\n            # It's fine to iterate over the keys of the first token since all tokens have the same keys.\n            for key in token_lengths[0]:\n                indexer_lengths[key] = max(x[key] if key in x else 0 for x in token_lengths)\n            lengths.append(indexer_lengths)\n\n        padding_lengths = {}\n        num_tokens = set()\n        for indexer_name, token_list in self._indexed_tokens.items():\n            padding_lengths[f\"{indexer_name}_length\"] = len(token_list)\n            num_tokens.add(len(token_list))\n\n        # We don't actually use this for padding anywhere, but we used to.  We add this key back in\n        # so that older configs still work if they sorted by this key in a BucketIterator.  Taking\n        # the max of all of these should be fine for that purpose.\n        padding_lengths['num_tokens'] = max(num_tokens)\n\n        # Get all keys which have been used for padding for each indexer and take the max if there are duplicates.\n        padding_keys = {key for d in lengths for key in d.keys()}\n        for padding_key in padding_keys:\n            padding_lengths[padding_key] = max(x[padding_key] if padding_key in x else 0 for x in lengths)\n        return padding_lengths", "response": "This method returns the padding lengths for all the TokenIndexers in the TextField."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main(vocab_path: str,\n         elmo_config_path: str,\n         elmo_weights_path: str,\n         output_dir: str,\n         batch_size: int,\n         device: int,\n         use_custom_oov_token: bool = False):\n    \"\"\"\n    Creates ELMo word representations from a vocabulary file. These\n    word representations are _independent_ - they are the result of running\n    the CNN and Highway layers of the ELMo model, but not the Bidirectional LSTM.\n    ELMo requires 2 additional tokens: <S> and </S>. The first token\n    in this file is assumed to be an unknown token.\n\n    This script produces two artifacts: A new vocabulary file\n    with the <S> and </S> tokens inserted and a glove formatted embedding\n    file containing word : vector pairs, one per line, with all values\n    separated by a space.\n    \"\"\"\n\n    # Load the vocabulary words and convert to char ids\n    with open(vocab_path, 'r') as vocab_file:\n        tokens = vocab_file.read().strip().split('\\n')\n\n    # Insert the sentence boundary tokens which elmo uses at positions 1 and 2.\n    if tokens[0] != DEFAULT_OOV_TOKEN and not use_custom_oov_token:\n        raise ConfigurationError(\"ELMo embeddings require the use of a OOV token.\")\n\n    tokens = [tokens[0]] + [\"<S>\", \"</S>\"] + tokens[1:]\n\n    indexer = ELMoTokenCharactersIndexer()\n    indices = indexer.tokens_to_indices([Token(token) for token in tokens], Vocabulary(), \"indices\")[\"indices\"]\n    sentences = []\n    for k in range((len(indices) // 50) + 1):\n        sentences.append(indexer.pad_token_sequence(indices[(k * 50):((k + 1) * 50)],\n                                                    desired_num_tokens=50,\n                                                    padding_lengths={}))\n\n    last_batch_remainder = 50 - (len(indices) % 50)\n    if device != -1:\n        elmo_token_embedder = _ElmoCharacterEncoder(elmo_config_path,\n                                                    elmo_weights_path).cuda(device)\n    else:\n        elmo_token_embedder = _ElmoCharacterEncoder(elmo_config_path,\n                                                    elmo_weights_path)\n\n    all_embeddings = []\n    for i in range((len(sentences) // batch_size) + 1):\n        array = numpy.array(sentences[i * batch_size: (i + 1) * batch_size])\n        if device != -1:\n            batch = torch.from_numpy(array).cuda(device)\n        else:\n            batch = torch.from_numpy(array)\n\n        token_embedding = elmo_token_embedder(batch)['token_embedding'].data\n\n        # Reshape back to a list of words of shape (batch_size * 50, encoding_dim)\n        # We also need to remove the <S>, </S> tokens appended by the encoder.\n        per_word_embeddings = token_embedding[:, 1:-1, :].contiguous().view(-1, token_embedding.size(-1))\n\n        all_embeddings.append(per_word_embeddings)\n\n    # Remove the embeddings associated with padding in the last batch.\n    all_embeddings[-1] = all_embeddings[-1][:-last_batch_remainder, :]\n\n    embedding_weight = torch.cat(all_embeddings, 0).cpu().numpy()\n\n    # Write out the embedding in a glove format.\n    os.makedirs(output_dir, exist_ok=True)\n    with gzip.open(os.path.join(output_dir, \"elmo_embeddings.txt.gz\"), 'wb') as embeddings_file:\n        for i, word in enumerate(tokens):\n            string_array = \" \".join([str(x) for x in list(embedding_weight[i, :])])\n            embeddings_file.write(f\"{word} {string_array}\\n\".encode('utf-8'))\n\n    # Write out the new vocab with the <S> and </S> tokens.\n    _, vocab_file_name = os.path.split(vocab_path)\n    with open(os.path.join(output_dir, vocab_file_name), \"w\") as new_vocab_file:\n        for word in tokens:\n            new_vocab_file.write(f\"{word}\\n\")", "response": "This script creates the word representations from a vocabulary file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sort_by_padding(instances: List[Instance],\n                    sorting_keys: List[Tuple[str, str]],  # pylint: disable=invalid-sequence-index\n                    vocab: Vocabulary,\n                    padding_noise: float = 0.0) -> List[Instance]:\n    \"\"\"\n    Sorts the instances by their padding lengths, using the keys in\n    ``sorting_keys`` (in the order in which they are provided).  ``sorting_keys`` is a list of\n    ``(field_name, padding_key)`` tuples.\n    \"\"\"\n    instances_with_lengths = []\n    for instance in instances:\n        # Make sure instance is indexed before calling .get_padding\n        instance.index_fields(vocab)\n        padding_lengths = cast(Dict[str, Dict[str, float]], instance.get_padding_lengths())\n        if padding_noise > 0.0:\n            noisy_lengths = {}\n            for field_name, field_lengths in padding_lengths.items():\n                noisy_lengths[field_name] = add_noise_to_dict_values(field_lengths, padding_noise)\n            padding_lengths = noisy_lengths\n        instance_with_lengths = ([padding_lengths[field_name][padding_key]\n                                  for (field_name, padding_key) in sorting_keys],\n                                 instance)\n        instances_with_lengths.append(instance_with_lengths)\n    instances_with_lengths.sort(key=lambda x: x[0])\n    return [instance_with_lengths[-1] for instance_with_lengths in instances_with_lengths]", "response": "Sorts the instances by their padding lengths using the keys in sorting_keys."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef infer(self, setup: QuaRelType, answer_0: QuaRelType, answer_1: QuaRelType) -> int:\n        if self._check_quarels_compatible(setup, answer_0):\n            if self._check_quarels_compatible(setup, answer_1):\n                # Found two answers\n                return -2\n            else:\n                return 0\n        elif self._check_quarels_compatible(setup, answer_1):\n            return 1\n        else:\n            return -1", "response": "Infer the question from the answer choices."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a Flask app that serves up the given Predictor and returns it.", "response": "def make_app(predictor: Predictor,\n             field_names: List[str] = None,\n             static_dir: str = None,\n             sanitizer: Callable[[JsonDict], JsonDict] = None,\n             title: str = \"AllenNLP Demo\") -> Flask:\n    \"\"\"\n    Creates a Flask app that serves up the provided ``Predictor``\n    along with a front-end for interacting with it.\n\n    If you want to use the built-in bare-bones HTML, you must provide the\n    field names for the inputs (which will be used both as labels\n    and as the keys in the JSON that gets sent to the predictor).\n\n    If you would rather create your own HTML, call it index.html\n    and provide its directory as ``static_dir``. In that case you\n    don't need to supply the field names -- that information should\n    be implicit in your demo site. (Probably the easiest thing to do\n    is just start with the bare-bones HTML and modify it.)\n\n    In addition, if you want somehow transform the JSON prediction\n    (e.g. by removing probabilities or logits)\n    you can do that by passing in a ``sanitizer`` function.\n    \"\"\"\n    if static_dir is not None:\n        static_dir = os.path.abspath(static_dir)\n        if not os.path.exists(static_dir):\n            logger.error(\"app directory %s does not exist, aborting\", static_dir)\n            sys.exit(-1)\n    elif static_dir is None and field_names is None:\n        print(\"Neither build_dir nor field_names passed. Demo won't render on this port.\\n\"\n              \"You must use nodejs + react app to interact with the server.\")\n\n    app = Flask(__name__)  # pylint: disable=invalid-name\n\n    @app.errorhandler(ServerError)\n    def handle_invalid_usage(error: ServerError) -> Response:  # pylint: disable=unused-variable\n        response = jsonify(error.to_dict())\n        response.status_code = error.status_code\n        return response\n\n    @app.route('/')\n    def index() -> Response: # pylint: disable=unused-variable\n        if static_dir is not None:\n            return send_file(os.path.join(static_dir, 'index.html'))\n        else:\n            html = _html(title, field_names)\n            return Response(response=html, status=200)\n\n    @app.route('/predict', methods=['POST', 'OPTIONS'])\n    def predict() -> Response:  # pylint: disable=unused-variable\n        \"\"\"make a prediction using the specified model and return the results\"\"\"\n        if request.method == \"OPTIONS\":\n            return Response(response=\"\", status=200)\n\n        data = request.get_json()\n\n        prediction = predictor.predict_json(data)\n        if sanitizer is not None:\n            prediction = sanitizer(prediction)\n\n        log_blob = {\"inputs\": data, \"outputs\": prediction}\n        logger.info(\"prediction: %s\", json.dumps(log_blob))\n\n        return jsonify(prediction)\n\n    @app.route('/predict_batch', methods=['POST', 'OPTIONS'])\n    def predict_batch() -> Response:  # pylint: disable=unused-variable\n        \"\"\"make a prediction using the specified model and return the results\"\"\"\n        if request.method == \"OPTIONS\":\n            return Response(response=\"\", status=200)\n\n        data = request.get_json()\n\n        prediction = predictor.predict_batch_json(data)\n        if sanitizer is not None:\n            prediction = [sanitizer(p) for p in prediction]\n\n        return jsonify(prediction)\n\n    @app.route('/<path:path>')\n    def static_proxy(path: str) -> Response: # pylint: disable=unused-variable\n        if static_dir is not None:\n            return send_from_directory(static_dir, path)\n        else:\n            raise ServerError(\"static_dir not specified\", 404)\n\n    return app"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _html(title: str, field_names: List[str]) -> str:\n    inputs = ''.join(_SINGLE_INPUT_TEMPLATE.substitute(field_name=field_name)\n                     for field_name in field_names)\n\n    quoted_field_names = [f\"'{field_name}'\" for field_name in field_names]\n    quoted_field_list = f\"[{','.join(quoted_field_names)}]\"\n\n    return _PAGE_TEMPLATE.substitute(title=title,\n                                     css=_CSS,\n                                     inputs=inputs,\n                                     qfl=quoted_field_list)", "response": "Returns a bare bones HTML for serving up a single input form with the specified fields that can render predictions from the configured model."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_valid_actions(self) -> Dict[str, Tuple[torch.Tensor, torch.Tensor, List[int]]]:\n        actions = self._valid_actions[self._nonterminal_stack[-1]]\n        context_actions = []\n        for type_, variable in self._lambda_stacks:\n            if self._nonterminal_stack[-1] == type_:\n                production_string = f\"{type_} -> {variable}\"\n                context_actions.append(self._context_actions[production_string])\n        if context_actions:\n            input_tensor, output_tensor, action_ids = actions['global']\n            new_inputs = [input_tensor] + [x[0] for x in context_actions]\n            input_tensor = torch.cat(new_inputs, dim=0)\n            new_outputs = [output_tensor] + [x[1] for x in context_actions]\n            output_tensor = torch.cat(new_outputs, dim=0)\n            new_action_ids = action_ids + [x[2] for x in context_actions]\n            # We can't just reassign to actions['global'], because that would modify the state of\n            # self._valid_actions.  Instead, we need to construct a new actions dictionary.\n            new_actions = {**actions}\n            new_actions['global'] = (input_tensor, output_tensor, new_action_ids)\n            actions = new_actions\n        return actions", "response": "Returns the valid actions in the current grammar state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake an action in the current grammar state returning a new grammar state with whatever update is necessary.", "response": "def take_action(self, production_rule: str) -> 'LambdaGrammarStatelet':\n        \"\"\"\n        Takes an action in the current grammar state, returning a new grammar state with whatever\n        updates are necessary.  The production rule is assumed to be formatted as \"LHS -> RHS\".\n\n        This will update the non-terminal stack and the context-dependent actions.  Updating the\n        non-terminal stack involves popping the non-terminal that was expanded off of the stack,\n        then pushing on any non-terminals in the production rule back on the stack.  We push the\n        non-terminals on in `reverse` order, so that the first non-terminal in the production rule\n        gets popped off the stack first.\n\n        For example, if our current ``nonterminal_stack`` is ``[\"r\", \"<e,r>\", \"d\"]``, and\n        ``action`` is ``d -> [<e,d>, e]``, the resulting stack will be ``[\"r\", \"<e,r>\", \"e\",\n        \"<e,d>\"]``.\n        \"\"\"\n        left_side, right_side = production_rule.split(' -> ')\n        assert self._nonterminal_stack[-1] == left_side, (f\"Tried to expand {self._nonterminal_stack[-1]}\"\n                                                          f\"but got rule {left_side} -> {right_side}\")\n        assert all(self._lambda_stacks[key][-1] == left_side for key in self._lambda_stacks)\n\n        new_stack = self._nonterminal_stack[:-1]\n        new_lambda_stacks = {key: self._lambda_stacks[key][:-1] for key in self._lambda_stacks}\n\n        productions = self._get_productions_from_string(right_side)\n        # Looking for lambda productions, but not for cells or columns with the word \"lambda\" in\n        # them.\n        if 'lambda' in productions[0] and 'fb:' not in productions[0]:\n            production = productions[0]\n            if production[0] == \"'\" and production[-1] == \"'\":\n                # The production rule with a lambda is typically \"<t,d> -> ['lambda x', d]\".  We\n                # need to strip the quotes.\n                production = production[1:-1]\n            lambda_variable = production.split(' ')[1]\n            # The left side must be formatted as \"<t,d>\", where \"t\" is the type of the lambda\n            # variable, and \"d\" is the return type of the lambda function.  We need to pull out the\n            # \"t\" here.  TODO(mattg): this is pretty limiting, but I'm not sure how general we\n            # should make this.\n            if len(left_side) != 5:\n                raise NotImplementedError(\"Can't handle this type yet:\", left_side)\n            lambda_type = left_side[1]\n            new_lambda_stacks[(lambda_type, lambda_variable)] = []\n\n        for production in reversed(productions):\n            if self._is_nonterminal(production):\n                new_stack.append(production)\n                for lambda_stack in new_lambda_stacks.values():\n                    lambda_stack.append(production)\n\n        # If any of the lambda stacks have now become empty, we remove them from our dictionary.\n        new_lambda_stacks = {key: new_lambda_stacks[key]\n                             for key in new_lambda_stacks if new_lambda_stacks[key]}\n\n        return LambdaGrammarStatelet(nonterminal_stack=new_stack,\n                                     lambda_stacks=new_lambda_stacks,\n                                     valid_actions=self._valid_actions,\n                                     context_actions=self._context_actions,\n                                     is_nonterminal=self._is_nonterminal)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nnoting Counter to typical intuition, this function decodes the _maximum_ spanning tree. Decode the optimal MST tree with the Chu-Liu-Edmonds algorithm for maximum spanning arborescences on graphs. Parameters ---------- energy : ``numpy.ndarray``, required. A tensor with shape (num_labels, timesteps, timesteps) containing the energy of each edge. If has_labels is ``False``, the tensor should have shape (timesteps, timesteps) instead. length : ``int``, required. The length of this sequence, as the energy may have come from a padded batch. has_labels : ``bool``, optional, (default = True) Whether the graph has labels or not.", "response": "def decode_mst(energy: numpy.ndarray,\n               length: int,\n               has_labels: bool = True) -> Tuple[numpy.ndarray, numpy.ndarray]:\n    \"\"\"\n    Note: Counter to typical intuition, this function decodes the _maximum_\n    spanning tree.\n\n    Decode the optimal MST tree with the Chu-Liu-Edmonds algorithm for\n    maximum spanning arborescences on graphs.\n\n    Parameters\n    ----------\n    energy : ``numpy.ndarray``, required.\n        A tensor with shape (num_labels, timesteps, timesteps)\n        containing the energy of each edge. If has_labels is ``False``,\n        the tensor should have shape (timesteps, timesteps) instead.\n    length : ``int``, required.\n        The length of this sequence, as the energy may have come\n        from a padded batch.\n    has_labels : ``bool``, optional, (default = True)\n        Whether the graph has labels or not.\n    \"\"\"\n    if has_labels and energy.ndim != 3:\n        raise ConfigurationError(\"The dimension of the energy array is not equal to 3.\")\n    elif not has_labels and energy.ndim != 2:\n        raise ConfigurationError(\"The dimension of the energy array is not equal to 2.\")\n    input_shape = energy.shape\n    max_length = input_shape[-1]\n\n    # Our energy matrix might have been batched -\n    # here we clip it to contain only non padded tokens.\n    if has_labels:\n        energy = energy[:, :length, :length]\n        # get best label for each edge.\n        label_id_matrix = energy.argmax(axis=0)\n        energy = energy.max(axis=0)\n    else:\n        energy = energy[:length, :length]\n        label_id_matrix = None\n    # get original score matrix\n    original_score_matrix = energy\n    # initialize score matrix to original score matrix\n    score_matrix = numpy.array(original_score_matrix, copy=True)\n\n    old_input = numpy.zeros([length, length], dtype=numpy.int32)\n    old_output = numpy.zeros([length, length], dtype=numpy.int32)\n    current_nodes = [True for _ in range(length)]\n    representatives: List[Set[int]] = []\n\n    for node1 in range(length):\n        original_score_matrix[node1, node1] = 0.0\n        score_matrix[node1, node1] = 0.0\n        representatives.append({node1})\n\n        for node2 in range(node1 + 1, length):\n            old_input[node1, node2] = node1\n            old_output[node1, node2] = node2\n\n            old_input[node2, node1] = node2\n            old_output[node2, node1] = node1\n\n    final_edges: Dict[int, int] = {}\n\n    # The main algorithm operates inplace.\n    chu_liu_edmonds(length, score_matrix, current_nodes,\n                    final_edges, old_input, old_output, representatives)\n\n    heads = numpy.zeros([max_length], numpy.int32)\n    if has_labels:\n        head_type = numpy.ones([max_length], numpy.int32)\n    else:\n        head_type = None\n\n    for child, parent in final_edges.items():\n        heads[child] = parent\n        if has_labels:\n            head_type[child] = label_id_matrix[parent, child]\n\n    return heads, head_type"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies the chu-liu-edmonds algorithm recursively to a graph with edge weights defined by score_matrix. Note that this function operates in place, so variables will be modified. Parameters ---------- length : ``int``, required. The number of nodes. score_matrix : ``numpy.ndarray``, required. The score matrix representing the scores for pairs of nodes. current_nodes : ``List[bool]``, required. The nodes which are representatives in the graph. A representative at it's most basic represents a node, but as the algorithm progresses, individual nodes will represent collapsed cycles in the graph. final_edges: ``Dict[int, int]``, required. An empty dictionary which will be populated with the nodes which are connected in the maximum spanning tree. old_input: ``numpy.ndarray``, required. old_output: ``numpy.ndarray``, required. representatives : ``List[Set[int]]``, required. A list containing the nodes that a particular node is representing at this iteration in the graph. Returns ------- Nothing - all variables are modified in place.", "response": "def chu_liu_edmonds(length: int,\n                    score_matrix: numpy.ndarray,\n                    current_nodes: List[bool],\n                    final_edges: Dict[int, int],\n                    old_input: numpy.ndarray,\n                    old_output: numpy.ndarray,\n                    representatives: List[Set[int]]):\n    \"\"\"\n    Applies the chu-liu-edmonds algorithm recursively\n    to a graph with edge weights defined by score_matrix.\n\n    Note that this function operates in place, so variables\n    will be modified.\n\n    Parameters\n    ----------\n    length : ``int``, required.\n        The number of nodes.\n    score_matrix : ``numpy.ndarray``, required.\n        The score matrix representing the scores for pairs\n        of nodes.\n    current_nodes : ``List[bool]``, required.\n        The nodes which are representatives in the graph.\n        A representative at it's most basic represents a node,\n        but as the algorithm progresses, individual nodes will\n        represent collapsed cycles in the graph.\n    final_edges: ``Dict[int, int]``, required.\n        An empty dictionary which will be populated with the\n        nodes which are connected in the maximum spanning tree.\n    old_input: ``numpy.ndarray``, required.\n    old_output: ``numpy.ndarray``, required.\n    representatives : ``List[Set[int]]``, required.\n        A list containing the nodes that a particular node\n        is representing at this iteration in the graph.\n\n    Returns\n    -------\n    Nothing - all variables are modified in place.\n\n    \"\"\"\n    # Set the initial graph to be the greedy best one.\n    parents = [-1]\n    for node1 in range(1, length):\n        parents.append(0)\n        if current_nodes[node1]:\n            max_score = score_matrix[0, node1]\n            for node2 in range(1, length):\n                if node2 == node1 or not current_nodes[node2]:\n                    continue\n\n                new_score = score_matrix[node2, node1]\n                if new_score > max_score:\n                    max_score = new_score\n                    parents[node1] = node2\n\n    # Check if this solution has a cycle.\n    has_cycle, cycle = _find_cycle(parents, length, current_nodes)\n    # If there are no cycles, find all edges and return.\n    if not has_cycle:\n        final_edges[0] = -1\n        for node in range(1, length):\n            if not current_nodes[node]:\n                continue\n\n            parent = old_input[parents[node], node]\n            child = old_output[parents[node], node]\n            final_edges[child] = parent\n        return\n\n    # Otherwise, we have a cycle so we need to remove an edge.\n    # From here until the recursive call is the contraction stage of the algorithm.\n    cycle_weight = 0.0\n    # Find the weight of the cycle.\n    index = 0\n    for node in cycle:\n        index += 1\n        cycle_weight += score_matrix[parents[node], node]\n\n    # For each node in the graph, find the maximum weight incoming\n    # and outgoing edge into the cycle.\n    cycle_representative = cycle[0]\n    for node in range(length):\n        if not current_nodes[node] or node in cycle:\n            continue\n\n        in_edge_weight = float(\"-inf\")\n        in_edge = -1\n        out_edge_weight = float(\"-inf\")\n        out_edge = -1\n\n        for node_in_cycle in cycle:\n            if score_matrix[node_in_cycle, node] > in_edge_weight:\n                in_edge_weight = score_matrix[node_in_cycle, node]\n                in_edge = node_in_cycle\n\n            # Add the new edge score to the cycle weight\n            # and subtract the edge we're considering removing.\n            score = (cycle_weight +\n                     score_matrix[node, node_in_cycle] -\n                     score_matrix[parents[node_in_cycle], node_in_cycle])\n\n            if score > out_edge_weight:\n                out_edge_weight = score\n                out_edge = node_in_cycle\n\n        score_matrix[cycle_representative, node] = in_edge_weight\n        old_input[cycle_representative, node] = old_input[in_edge, node]\n        old_output[cycle_representative, node] = old_output[in_edge, node]\n\n        score_matrix[node, cycle_representative] = out_edge_weight\n        old_output[node, cycle_representative] = old_output[node, out_edge]\n        old_input[node, cycle_representative] = old_input[node, out_edge]\n\n    # For the next recursive iteration, we want to consider the cycle as a\n    # single node. Here we collapse the cycle into the first node in the\n    # cycle (first node is arbitrary), set all the other nodes not be\n    # considered in the next iteration. We also keep track of which\n    # representatives we are considering this iteration because we need\n    # them below to check if we're done.\n    considered_representatives: List[Set[int]] = []\n    for i, node_in_cycle in enumerate(cycle):\n        considered_representatives.append(set())\n        if i > 0:\n            # We need to consider at least one\n            # node in the cycle, arbitrarily choose\n            # the first.\n            current_nodes[node_in_cycle] = False\n\n        for node in representatives[node_in_cycle]:\n            considered_representatives[i].add(node)\n            if i > 0:\n                representatives[cycle_representative].add(node)\n\n    chu_liu_edmonds(length, score_matrix, current_nodes, final_edges, old_input, old_output, representatives)\n\n    # Expansion stage.\n    # check each node in cycle, if one of its representatives\n    # is a key in the final_edges, it is the one we need.\n    found = False\n    key_node = -1\n    for i, node in enumerate(cycle):\n        for cycle_rep in considered_representatives[i]:\n            if cycle_rep in final_edges:\n                key_node = node\n                found = True\n                break\n        if found:\n            break\n\n    previous = parents[key_node]\n    while previous != key_node:\n        child = old_output[parents[previous], previous]\n        parent = old_input[parents[previous], previous]\n        final_edges[child] = parent\n        previous = parents[previous]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef assign_average_value(self) -> None:\n        for name, parameter in self._parameters:\n            self._backups[name].copy_(parameter.data)\n            parameter.data.copy_(self._shadows[name])", "response": "Assign the average value of all the parameters to the current values."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef restore(self) -> None:\n        for name, parameter in self._parameters:\n            parameter.data.copy_(self._backups[name])", "response": "Restore the backed - up ( non - average parameter values."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef forward(self, tensor_1: torch.Tensor, tensor_2: torch.Tensor) -> torch.Tensor:\n        # pylint: disable=arguments-differ\n        \"\"\"\n        Takes two tensors of the same shape, such as ``(batch_size, length_1, length_2,\n        embedding_dim)``.  Computes a (possibly parameterized) similarity on the final dimension\n        and returns a tensor with one less dimension, such as ``(batch_size, length_1, length_2)``.\n        \"\"\"\n        raise NotImplementedError", "response": "Computes a similarity between two tensors."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _prune_beam(states: List[State],\n                    beam_size: int,\n                    sort_states: bool = False) -> List[State]:\n        \"\"\"\n        This method can be used to prune the set of unfinished states on a beam or finished states\n        at the end of search. In the former case, the states need not be sorted because the all come\n        from the same decoding step, which does the sorting. However, if the states are finished and\n        this method is called at the end of the search, they need to be sorted because they come\n        from different decoding steps.\n        \"\"\"\n        states_by_batch_index: Dict[int, List[State]] = defaultdict(list)\n        for state in states:\n            assert len(state.batch_indices) == 1\n            batch_index = state.batch_indices[0]\n            states_by_batch_index[batch_index].append(state)\n        pruned_states = []\n        for _, instance_states in states_by_batch_index.items():\n            if sort_states:\n                scores = torch.cat([state.score[0].view(-1) for state in instance_states])\n                _, sorted_indices = scores.sort(-1, descending=True)\n                sorted_states = [instance_states[i] for i in sorted_indices.detach().cpu().numpy()]\n                instance_states = sorted_states\n            for state in instance_states[:beam_size]:\n                pruned_states.append(state)\n        return pruned_states", "response": "This method is used to prune the beam of states."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_best_final_states(self, finished_states: List[StateType]) -> Dict[int, List[StateType]]:\n        batch_states: Dict[int, List[StateType]] = defaultdict(list)\n        for state in finished_states:\n            batch_states[state.batch_indices[0]].append(state)\n        best_states: Dict[int, List[StateType]] = {}\n        for batch_index, states in batch_states.items():\n            # The time this sort takes is pretty negligible, no particular need to optimize this\n            # yet.  Maybe with a larger beam size...\n            finished_to_sort = [(-state.score[0].item(), state) for state in states]\n            finished_to_sort.sort(key=lambda x: x[0])\n            best_states[batch_index] = [state[1] for state in finished_to_sort[:self._beam_size]]\n        return best_states", "response": "Returns the best finished states for each batch instance based on model scores. We return the best finished states for each batch instance based on self. _max_num_decoded_sequences number of sequences per instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _read_pretrained_embeddings_file(file_uri: str,\n                                     embedding_dim: int,\n                                     vocab: Vocabulary,\n                                     namespace: str = \"tokens\") -> torch.FloatTensor:\n    \"\"\"\n    Returns and embedding matrix for the given vocabulary using the pretrained embeddings\n    contained in the given file. Embeddings for tokens not found in the pretrained embedding file\n    are randomly initialized using a normal distribution with mean and standard deviation equal to\n    those of the pretrained embeddings.\n\n    We support two file formats:\n\n        * text format - utf-8 encoded text file with space separated fields: [word] [dim 1] [dim 2] ...\n          The text file can eventually be compressed, and even resides in an archive with multiple files.\n          If the file resides in an archive with other files, then ``embeddings_filename`` must\n          be a URI \"(archive_uri)#file_path_inside_the_archive\"\n\n        * hdf5 format - hdf5 file containing an embedding matrix in the form of a torch.Tensor.\n\n    If the filename ends with '.hdf5' or '.h5' then we load from hdf5, otherwise we assume\n    text format.\n\n    Parameters\n    ----------\n    file_uri : str, required.\n        It can be:\n\n        * a file system path or a URL of an eventually compressed text file or a zip/tar archive\n          containing a single file.\n\n        * URI of the type ``(archive_path_or_url)#file_path_inside_archive`` if the text file\n          is contained in a multi-file archive.\n\n    vocab : Vocabulary, required.\n        A Vocabulary object.\n    namespace : str, (optional, default=tokens)\n        The namespace of the vocabulary to find pretrained embeddings for.\n    trainable : bool, (optional, default=True)\n        Whether or not the embedding parameters should be optimized.\n\n    Returns\n    -------\n    A weight matrix with embeddings initialized from the read file.  The matrix has shape\n    ``(vocab.get_vocab_size(namespace), embedding_dim)``, where the indices of words appearing in\n    the pretrained embedding file are initialized to the pretrained embedding value.\n    \"\"\"\n    file_ext = get_file_extension(file_uri)\n    if file_ext in ['.h5', '.hdf5']:\n        return _read_embeddings_from_hdf5(file_uri,\n                                          embedding_dim,\n                                          vocab, namespace)\n\n    return _read_embeddings_from_text_file(file_uri,\n                                           embedding_dim,\n                                           vocab, namespace)", "response": "Reads a pre - trained embedding file and returns a weight matrix with embeddings initialized to the given embedding_dim."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading pre - trained word vectors from a text file.", "response": "def _read_embeddings_from_text_file(file_uri: str,\n                                    embedding_dim: int,\n                                    vocab: Vocabulary,\n                                    namespace: str = \"tokens\") -> torch.FloatTensor:\n    \"\"\"\n    Read pre-trained word vectors from an eventually compressed text file, possibly contained\n    inside an archive with multiple files. The text file is assumed to be utf-8 encoded with\n    space-separated fields: [word] [dim 1] [dim 2] ...\n\n    Lines that contain more numerical tokens than ``embedding_dim`` raise a warning and are skipped.\n\n    The remainder of the docstring is identical to ``_read_pretrained_embeddings_file``.\n    \"\"\"\n    tokens_to_keep = set(vocab.get_index_to_token_vocabulary(namespace).values())\n    vocab_size = vocab.get_vocab_size(namespace)\n    embeddings = {}\n\n    # First we read the embeddings from the file, only keeping vectors for the words we need.\n    logger.info(\"Reading pretrained embeddings from file\")\n\n    with EmbeddingsTextFile(file_uri) as embeddings_file:\n        for line in Tqdm.tqdm(embeddings_file):\n            token = line.split(' ', 1)[0]\n            if token in tokens_to_keep:\n                fields = line.rstrip().split(' ')\n                if len(fields) - 1 != embedding_dim:\n                    # Sometimes there are funny unicode parsing problems that lead to different\n                    # fields lengths (e.g., a word with a unicode space character that splits\n                    # into more than one column).  We skip those lines.  Note that if you have\n                    # some kind of long header, this could result in all of your lines getting\n                    # skipped.  It's hard to check for that here; you just have to look in the\n                    # embedding_misses_file and at the model summary to make sure things look\n                    # like they are supposed to.\n                    logger.warning(\"Found line with wrong number of dimensions (expected: %d; actual: %d): %s\",\n                                   embedding_dim, len(fields) - 1, line)\n                    continue\n\n                vector = numpy.asarray(fields[1:], dtype='float32')\n                embeddings[token] = vector\n\n    if not embeddings:\n        raise ConfigurationError(\"No embeddings of correct dimension found; you probably \"\n                                 \"misspecified your embedding_dim parameter, or didn't \"\n                                 \"pre-populate your Vocabulary\")\n\n    all_embeddings = numpy.asarray(list(embeddings.values()))\n    embeddings_mean = float(numpy.mean(all_embeddings))\n    embeddings_std = float(numpy.std(all_embeddings))\n    # Now we initialize the weight matrix for an embedding layer, starting with random vectors,\n    # then filling in the word vectors we just read.\n    logger.info(\"Initializing pre-trained embedding layer\")\n    embedding_matrix = torch.FloatTensor(vocab_size, embedding_dim).normal_(embeddings_mean,\n                                                                            embeddings_std)\n    num_tokens_found = 0\n    index_to_token = vocab.get_index_to_token_vocabulary(namespace)\n    for i in range(vocab_size):\n        token = index_to_token[i]\n\n        # If we don't have a pre-trained vector for this word, we'll just leave this row alone,\n        # so the word has a random initialization.\n        if token in embeddings:\n            embedding_matrix[i] = torch.FloatTensor(embeddings[token])\n            num_tokens_found += 1\n        else:\n            logger.debug(\"Token %s was not found in the embedding file. Initialising randomly.\", token)\n\n    logger.info(\"Pretrained embeddings were found for %d out of %d tokens\",\n                num_tokens_found, vocab_size)\n\n    return embedding_matrix"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _read_embeddings_from_hdf5(embeddings_filename: str,\n                               embedding_dim: int,\n                               vocab: Vocabulary,\n                               namespace: str = \"tokens\") -> torch.FloatTensor:\n    \"\"\"\n    Reads from a hdf5 formatted file. The embedding matrix is assumed to\n    be keyed by 'embedding' and of size ``(num_tokens, embedding_dim)``.\n    \"\"\"\n    with h5py.File(embeddings_filename, 'r') as fin:\n        embeddings = fin['embedding'][...]\n\n    if list(embeddings.shape) != [vocab.get_vocab_size(namespace), embedding_dim]:\n        raise ConfigurationError(\n                \"Read shape {0} embeddings from the file, but expected {1}\".format(\n                        list(embeddings.shape), [vocab.get_vocab_size(namespace), embedding_dim]))\n\n    return torch.FloatTensor(embeddings)", "response": "Reads embedding matrix from a hdf5 formatted file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_num_tokens_from_first_line(line: str) -> Optional[int]:\n        fields = line.split(' ')\n        if 1 <= len(fields) <= 2:\n            try:\n                int_fields = [int(x) for x in fields]\n            except ValueError:\n                return None\n            else:\n                num_tokens = max(int_fields)\n                logger.info('Recognized a header line in the embedding file with number of tokens: %d',\n                            num_tokens)\n                return num_tokens\n        return None", "response": "This function takes in input a string and returns the number of tokens from the first line of the embedding file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the predicted embedding addition for the current action in the checklist.", "response": "def _get_predicted_embedding_addition(self,\n                                          checklist_state: ChecklistStatelet,\n                                          action_ids: List[int],\n                                          action_embeddings: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Gets the embeddings of desired terminal actions yet to be produced by the decoder, and\n        returns their sum for the decoder to add it to the predicted embedding to bias the\n        prediction towards missing actions.\n        \"\"\"\n        # Our basic approach here will be to figure out which actions we want to bias, by doing\n        # some fancy indexing work, then multiply the action embeddings by a mask for those\n        # actions, and return the sum of the result.\n\n        # Shape: (num_terminal_actions, 1).  This is 1 if we still want to predict something on the\n        # checklist, and 0 otherwise.\n        checklist_balance = checklist_state.get_balance().clamp(min=0)\n\n        # (num_terminal_actions, 1)\n        actions_in_agenda = checklist_state.terminal_actions\n        # (1, num_current_actions)\n        action_id_tensor = checklist_balance.new(action_ids).long().unsqueeze(0)\n        # Shape: (num_terminal_actions, num_current_actions).  Will have a value of 1 if the\n        # terminal action i is our current action j, and a value of 0 otherwise.  Because both sets\n        # of actions are free of duplicates, there will be at most one non-zero value per current\n        # action, and per terminal action.\n        current_agenda_actions = (actions_in_agenda == action_id_tensor).float()\n\n        # Shape: (num_current_actions,).  With the inner multiplication, we remove any current\n        # agenda actions that are not in our checklist balance, then we sum over the terminal\n        # action dimension, which will have a sum of at most one.  So this will be a 0/1 tensor,\n        # where a 1 means to encourage the current action in that position.\n        actions_to_encourage = torch.sum(current_agenda_actions * checklist_balance, dim=0)\n\n        # Shape: (action_embedding_dim,).  This is the sum of the action embeddings that we want\n        # the model to prefer.\n        embedding_addition = torch.sum(action_embeddings * actions_to_encourage.unsqueeze(1),\n                                       dim=0,\n                                       keepdim=False)\n\n        if self._add_action_bias:\n            # If we're adding an action bias, the last dimension of the action embedding is a bias\n            # weight.  We don't want this addition to affect the bias (TODO(mattg): or do we?), so\n            # we zero out that dimension here.\n            embedding_addition[-1] = 0\n\n        return embedding_addition"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates TensorDicts from the input_queue and the output_queue.", "response": "def _create_tensor_dicts(input_queue: Queue,\n                         output_queue: Queue,\n                         iterator: DataIterator,\n                         shuffle: bool,\n                         index: int) -> None:\n    \"\"\"\n    Pulls at most ``max_instances_in_memory`` from the input_queue,\n    groups them into batches of size ``batch_size``, converts them\n    to ``TensorDict`` s, and puts them on the ``output_queue``.\n    \"\"\"\n    def instances() -> Iterator[Instance]:\n        instance = input_queue.get()\n        while instance is not None:\n            yield instance\n            instance = input_queue.get()\n\n    for tensor_dict in iterator(instances(), num_epochs=1, shuffle=shuffle):\n        output_queue.put(tensor_dict)\n\n    output_queue.put(index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads Instances from the iterable and puts them in the input_queue.", "response": "def _queuer(instances: Iterable[Instance],\n            input_queue: Queue,\n            num_workers: int,\n            num_epochs: Optional[int]) -> None:\n    \"\"\"\n    Reads Instances from the iterable and puts them in the input_queue.\n    \"\"\"\n    epoch = 0\n\n    while num_epochs is None or epoch < num_epochs:\n        epoch += 1\n        for instance in instances:\n            input_queue.put(instance)\n\n    # Now put a None for each worker, since each needs to receive one\n    # to know that it's done.\n    for _ in range(num_workers):\n        input_queue.put(None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of valid actions for each element of the group.", "response": "def get_valid_actions(self) -> List[Dict[str, Tuple[torch.Tensor, torch.Tensor, List[int]]]]:\n        \"\"\"\n        Returns a list of valid actions for each element of the group.\n        \"\"\"\n        return [state.get_valid_actions() for state in self.grammar_state]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the allowed transitions for the given labels and a constraint type.", "response": "def allowed_transitions(constraint_type: str, labels: Dict[int, str]) -> List[Tuple[int, int]]:\n    \"\"\"\n    Given labels and a constraint type, returns the allowed transitions. It will\n    additionally include transitions for the start and end states, which are used\n    by the conditional random field.\n\n    Parameters\n    ----------\n    constraint_type : ``str``, required\n        Indicates which constraint to apply. Current choices are\n        \"BIO\", \"IOB1\", \"BIOUL\", and \"BMES\".\n    labels : ``Dict[int, str]``, required\n        A mapping {label_id -> label}. Most commonly this would be the value from\n        Vocabulary.get_index_to_token_vocabulary()\n\n    Returns\n    -------\n    ``List[Tuple[int, int]]``\n        The allowed transitions (from_label_id, to_label_id).\n    \"\"\"\n    num_labels = len(labels)\n    start_tag = num_labels\n    end_tag = num_labels + 1\n    labels_with_boundaries = list(labels.items()) + [(start_tag, \"START\"), (end_tag, \"END\")]\n\n    allowed = []\n    for from_label_index, from_label in labels_with_boundaries:\n        if from_label in (\"START\", \"END\"):\n            from_tag = from_label\n            from_entity = \"\"\n        else:\n            from_tag = from_label[0]\n            from_entity = from_label[1:]\n        for to_label_index, to_label in labels_with_boundaries:\n            if to_label in (\"START\", \"END\"):\n                to_tag = to_label\n                to_entity = \"\"\n            else:\n                to_tag = to_label[0]\n                to_entity = to_label[1:]\n            if is_transition_allowed(constraint_type, from_tag, from_entity,\n                                     to_tag, to_entity):\n                allowed.append((from_label_index, to_label_index))\n    return allowed"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if the transition is allowed under the given constraint type and strings from_tag and to_entity.", "response": "def is_transition_allowed(constraint_type: str,\n                          from_tag: str,\n                          from_entity: str,\n                          to_tag: str,\n                          to_entity: str):\n    \"\"\"\n    Given a constraint type and strings ``from_tag`` and ``to_tag`` that\n    represent the origin and destination of the transition, return whether\n    the transition is allowed under the given constraint type.\n\n    Parameters\n    ----------\n    constraint_type : ``str``, required\n        Indicates which constraint to apply. Current choices are\n        \"BIO\", \"IOB1\", \"BIOUL\", and \"BMES\".\n    from_tag : ``str``, required\n        The tag that the transition originates from. For example, if the\n        label is ``I-PER``, the ``from_tag`` is ``I``.\n    from_entity: ``str``, required\n        The entity corresponding to the ``from_tag``. For example, if the\n        label is ``I-PER``, the ``from_entity`` is ``PER``.\n    to_tag : ``str``, required\n        The tag that the transition leads to. For example, if the\n        label is ``I-PER``, the ``to_tag`` is ``I``.\n    to_entity: ``str``, required\n        The entity corresponding to the ``to_tag``. For example, if the\n        label is ``I-PER``, the ``to_entity`` is ``PER``.\n\n    Returns\n    -------\n    ``bool``\n        Whether the transition is allowed under the given ``constraint_type``.\n    \"\"\"\n    # pylint: disable=too-many-return-statements\n    if to_tag == \"START\" or from_tag == \"END\":\n        # Cannot transition into START or from END\n        return False\n\n    if constraint_type == \"BIOUL\":\n        if from_tag == \"START\":\n            return to_tag in ('O', 'B', 'U')\n        if to_tag == \"END\":\n            return from_tag in ('O', 'L', 'U')\n        return any([\n                # O can transition to O, B-* or U-*\n                # L-x can transition to O, B-*, or U-*\n                # U-x can transition to O, B-*, or U-*\n                from_tag in ('O', 'L', 'U') and to_tag in ('O', 'B', 'U'),\n                # B-x can only transition to I-x or L-x\n                # I-x can only transition to I-x or L-x\n                from_tag in ('B', 'I') and to_tag in ('I', 'L') and from_entity == to_entity\n        ])\n    elif constraint_type == \"BIO\":\n        if from_tag == \"START\":\n            return to_tag in ('O', 'B')\n        if to_tag == \"END\":\n            return from_tag in ('O', 'B', 'I')\n        return any([\n                # Can always transition to O or B-x\n                to_tag in ('O', 'B'),\n                # Can only transition to I-x from B-x or I-x\n                to_tag == 'I' and from_tag in ('B', 'I') and from_entity == to_entity\n        ])\n    elif constraint_type == \"IOB1\":\n        if from_tag == \"START\":\n            return to_tag in ('O', 'I')\n        if to_tag == \"END\":\n            return from_tag in ('O', 'B', 'I')\n        return any([\n                # Can always transition to O or I-x\n                to_tag in ('O', 'I'),\n                # Can only transition to B-x from B-x or I-x, where\n                # x is the same tag.\n                to_tag == 'B' and from_tag in ('B', 'I') and from_entity == to_entity\n        ])\n    elif constraint_type == \"BMES\":\n        if from_tag == \"START\":\n            return to_tag in ('B', 'S')\n        if to_tag == \"END\":\n            return from_tag in ('E', 'S')\n        return any([\n                # Can only transition to B or S from E or S.\n                to_tag in ('B', 'S') and from_tag in ('E', 'S'),\n                # Can only transition to M-x from B-x, where\n                # x is the same tag.\n                to_tag == 'M' and from_tag in ('B', 'M') and from_entity == to_entity,\n                # Can only transition to E-x from B-x or M-x, where\n                # x is the same tag.\n                to_tag == 'E' and from_tag in ('B', 'M') and from_entity == to_entity,\n        ])\n    else:\n        raise ConfigurationError(f\"Unknown constraint type: {constraint_type}\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _input_likelihood(self, logits: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n        batch_size, sequence_length, num_tags = logits.size()\n\n        # Transpose batch size and sequence dimensions\n        mask = mask.float().transpose(0, 1).contiguous()\n        logits = logits.transpose(0, 1).contiguous()\n\n        # Initial alpha is the (batch_size, num_tags) tensor of likelihoods combining the\n        # transitions to the initial states and the logits for the first timestep.\n        if self.include_start_end_transitions:\n            alpha = self.start_transitions.view(1, num_tags) + logits[0]\n        else:\n            alpha = logits[0]\n\n        # For each i we compute logits for the transitions from timestep i-1 to timestep i.\n        # We do so in a (batch_size, num_tags, num_tags) tensor where the axes are\n        # (instance, current_tag, next_tag)\n        for i in range(1, sequence_length):\n            # The emit scores are for time i (\"next_tag\") so we broadcast along the current_tag axis.\n            emit_scores = logits[i].view(batch_size, 1, num_tags)\n            # Transition scores are (current_tag, next_tag) so we broadcast along the instance axis.\n            transition_scores = self.transitions.view(1, num_tags, num_tags)\n            # Alpha is for the current_tag, so we broadcast along the next_tag axis.\n            broadcast_alpha = alpha.view(batch_size, num_tags, 1)\n\n            # Add all the scores together and logexp over the current_tag axis\n            inner = broadcast_alpha + emit_scores + transition_scores\n\n            # In valid positions (mask == 1) we want to take the logsumexp over the current_tag dimension\n            # of ``inner``. Otherwise (mask == 0) we want to retain the previous alpha.\n            alpha = (util.logsumexp(inner, 1) * mask[i].view(batch_size, 1) +\n                     alpha * (1 - mask[i]).view(batch_size, 1))\n\n        # Every sequence needs to end with a transition to the stop_tag.\n        if self.include_start_end_transitions:\n            stops = alpha + self.end_transitions.view(1, num_tags)\n        else:\n            stops = alpha\n\n        # Finally we log_sum_exp along the num_tags dim, result is (batch_size,)\n        return util.logsumexp(stops)", "response": "Compute the log - likelihood of the input."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the joint likelihood term for the log - likelihood.", "response": "def _joint_likelihood(self,\n                          logits: torch.Tensor,\n                          tags: torch.Tensor,\n                          mask: torch.LongTensor) -> torch.Tensor:\n        \"\"\"\n        Computes the numerator term for the log-likelihood, which is just score(inputs, tags)\n        \"\"\"\n        batch_size, sequence_length, _ = logits.data.shape\n\n        # Transpose batch size and sequence dimensions:\n        logits = logits.transpose(0, 1).contiguous()\n        mask = mask.float().transpose(0, 1).contiguous()\n        tags = tags.transpose(0, 1).contiguous()\n\n        # Start with the transition scores from start_tag to the first tag in each input\n        if self.include_start_end_transitions:\n            score = self.start_transitions.index_select(0, tags[0])\n        else:\n            score = 0.0\n\n        # Add up the scores for the observed transitions and all the inputs but the last\n        for i in range(sequence_length - 1):\n            # Each is shape (batch_size,)\n            current_tag, next_tag = tags[i], tags[i+1]\n\n            # The scores for transitioning from current_tag to next_tag\n            transition_score = self.transitions[current_tag.view(-1), next_tag.view(-1)]\n\n            # The score for using current_tag\n            emit_score = logits[i].gather(1, current_tag.view(batch_size, 1)).squeeze(1)\n\n            # Include transition score if next element is unmasked,\n            # input_score if this element is unmasked.\n            score = score + transition_score * mask[i + 1] + emit_score * mask[i]\n\n        # Transition from last state to \"stop\" state. To start with, we need to find the last tag\n        # for each instance.\n        last_tag_index = mask.sum(0).long() - 1\n        last_tags = tags.gather(0, last_tag_index.view(1, batch_size)).squeeze(0)\n\n        # Compute score of transitioning to `stop_tag` from each \"last tag\".\n        if self.include_start_end_transitions:\n            last_transition_score = self.end_transitions.index_select(0, last_tags)\n        else:\n            last_transition_score = 0.0\n\n        # Add the last input if it's not masked.\n        last_inputs = logits[-1]                                         # (batch_size, num_tags)\n        last_input_score = last_inputs.gather(1, last_tags.view(-1, 1))  # (batch_size, 1)\n        last_input_score = last_input_score.squeeze()                    # (batch_size,)\n\n        score = score + last_transition_score + last_input_score * mask[-1]\n\n        return score"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef forward(self,\n                inputs: torch.Tensor,\n                tags: torch.Tensor,\n                mask: torch.ByteTensor = None) -> torch.Tensor:\n        \"\"\"\n        Computes the log likelihood.\n        \"\"\"\n        # pylint: disable=arguments-differ\n        if mask is None:\n            mask = torch.ones(*tags.size(), dtype=torch.long)\n\n        log_denominator = self._input_likelihood(inputs, mask)\n        log_numerator = self._joint_likelihood(inputs, tags, mask)\n\n        return torch.sum(log_numerator - log_denominator)", "response": "Computes the log likelihood of the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nusing viterbi algorithm to find most likely tags for the given inputs.", "response": "def viterbi_tags(self,\n                     logits: torch.Tensor,\n                     mask: torch.Tensor) -> List[Tuple[List[int], float]]:\n        \"\"\"\n        Uses viterbi algorithm to find most likely tags for the given inputs.\n        If constraints are applied, disallows all other transitions.\n        \"\"\"\n        _, max_seq_length, num_tags = logits.size()\n\n        # Get the tensors out of the variables\n        logits, mask = logits.data, mask.data\n\n        # Augment transitions matrix with start and end transitions\n        start_tag = num_tags\n        end_tag = num_tags + 1\n        transitions = torch.Tensor(num_tags + 2, num_tags + 2).fill_(-10000.)\n\n        # Apply transition constraints\n        constrained_transitions = (\n                self.transitions * self._constraint_mask[:num_tags, :num_tags] +\n                -10000.0 * (1 - self._constraint_mask[:num_tags, :num_tags])\n        )\n        transitions[:num_tags, :num_tags] = constrained_transitions.data\n\n        if self.include_start_end_transitions:\n            transitions[start_tag, :num_tags] = (\n                    self.start_transitions.detach() * self._constraint_mask[start_tag, :num_tags].data +\n                    -10000.0 * (1 - self._constraint_mask[start_tag, :num_tags].detach())\n            )\n            transitions[:num_tags, end_tag] = (\n                    self.end_transitions.detach() * self._constraint_mask[:num_tags, end_tag].data +\n                    -10000.0 * (1 - self._constraint_mask[:num_tags, end_tag].detach())\n            )\n        else:\n            transitions[start_tag, :num_tags] = (-10000.0 *\n                                                 (1 - self._constraint_mask[start_tag, :num_tags].detach()))\n            transitions[:num_tags, end_tag] = -10000.0 * (1 - self._constraint_mask[:num_tags, end_tag].detach())\n\n        best_paths = []\n        # Pad the max sequence length by 2 to account for start_tag + end_tag.\n        tag_sequence = torch.Tensor(max_seq_length + 2, num_tags + 2)\n\n        for prediction, prediction_mask in zip(logits, mask):\n            sequence_length = torch.sum(prediction_mask)\n\n            # Start with everything totally unlikely\n            tag_sequence.fill_(-10000.)\n            # At timestep 0 we must have the START_TAG\n            tag_sequence[0, start_tag] = 0.\n            # At steps 1, ..., sequence_length we just use the incoming prediction\n            tag_sequence[1:(sequence_length + 1), :num_tags] = prediction[:sequence_length]\n            # And at the last timestep we must have the END_TAG\n            tag_sequence[sequence_length + 1, end_tag] = 0.\n\n            # We pass the tags and the transitions to ``viterbi_decode``.\n            viterbi_path, viterbi_score = util.viterbi_decode(tag_sequence[:(sequence_length + 2)], transitions)\n            # Get rid of START and END sentinels and append.\n            viterbi_path = viterbi_path[1:-1]\n            best_paths.append((viterbi_path, viterbi_score.item()))\n\n        return best_paths"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a starting state and a step function, apply beam search to find the most likely target sequences. Notes ----- If your step function returns ``-inf`` for some log probabilities (like if you're using a masked log-softmax) then some of the \"best\" sequences returned may also have ``-inf`` log probability. Specifically this happens when the beam size is smaller than the number of actions with finite log probability (non-zero probability) returned by the step function. Therefore if you're using a mask you may want to check the results from ``search`` and potentially discard sequences with non-finite log probability. Parameters ---------- start_predictions : ``torch.Tensor`` A tensor containing the initial predictions with shape ``(batch_size,)``. Usually the initial predictions are just the index of the \"start\" token in the target vocabulary. start_state : ``StateType`` The initial state passed to the ``step`` function. Each value of the state dict should be a tensor of shape ``(batch_size, *)``, where ``*`` means any other number of dimensions. step : ``StepFunctionType`` A function that is responsible for computing the next most likely tokens, given the current state and the predictions from the last time step. The function should accept two arguments. The first being a tensor of shape ``(group_size,)``, representing the index of the predicted tokens from the last time step, and the second being the current state. The ``group_size`` will be ``batch_size * beam_size``, except in the initial step, for which it will just be ``batch_size``. The function is expected to return a tuple, where the first element is a tensor of shape ``(group_size, target_vocab_size)`` containing the log probabilities of the tokens for the next step, and the second element is the updated state. The tensor in the state should have shape ``(group_size, *)``, where ``*`` means any other number of dimensions. Returns ------- Tuple[torch.Tensor, torch.Tensor] Tuple of ``(predictions, log_probabilities)``, where ``predictions`` has shape ``(batch_size, beam_size, max_steps)`` and ``log_probabilities`` has shape ``(batch_size, beam_size)``.", "response": "def search(self,\n               start_predictions: torch.Tensor,\n               start_state: StateType,\n               step: StepFunctionType) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Given a starting state and a step function, apply beam search to find the\n        most likely target sequences.\n\n        Notes\n        -----\n        If your step function returns ``-inf`` for some log probabilities\n        (like if you're using a masked log-softmax) then some of the \"best\"\n        sequences returned may also have ``-inf`` log probability. Specifically\n        this happens when the beam size is smaller than the number of actions\n        with finite log probability (non-zero probability) returned by the step function.\n        Therefore if you're using a mask you may want to check the results from ``search``\n        and potentially discard sequences with non-finite log probability.\n\n        Parameters\n        ----------\n        start_predictions : ``torch.Tensor``\n            A tensor containing the initial predictions with shape ``(batch_size,)``.\n            Usually the initial predictions are just the index of the \"start\" token\n            in the target vocabulary.\n        start_state : ``StateType``\n            The initial state passed to the ``step`` function. Each value of the state dict\n            should be a tensor of shape ``(batch_size, *)``, where ``*`` means any other\n            number of dimensions.\n        step : ``StepFunctionType``\n            A function that is responsible for computing the next most likely tokens,\n            given the current state and the predictions from the last time step.\n            The function should accept two arguments. The first being a tensor\n            of shape ``(group_size,)``, representing the index of the predicted\n            tokens from the last time step, and the second being the current state.\n            The ``group_size`` will be ``batch_size * beam_size``, except in the initial\n            step, for which it will just be ``batch_size``.\n            The function is expected to return a tuple, where the first element\n            is a tensor of shape ``(group_size, target_vocab_size)`` containing\n            the log probabilities of the tokens for the next step, and the second\n            element is the updated state. The tensor in the state should have shape\n            ``(group_size, *)``, where ``*`` means any other number of dimensions.\n\n        Returns\n        -------\n        Tuple[torch.Tensor, torch.Tensor]\n            Tuple of ``(predictions, log_probabilities)``, where ``predictions``\n            has shape ``(batch_size, beam_size, max_steps)`` and ``log_probabilities``\n            has shape ``(batch_size, beam_size)``.\n        \"\"\"\n        batch_size = start_predictions.size()[0]\n\n        # List of (batch_size, beam_size) tensors. One for each time step. Does not\n        # include the start symbols, which are implicit.\n        predictions: List[torch.Tensor] = []\n\n        # List of (batch_size, beam_size) tensors. One for each time step. None for\n        # the first.  Stores the index n for the parent prediction, i.e.\n        # predictions[t-1][i][n], that it came from.\n        backpointers: List[torch.Tensor] = []\n\n        # Calculate the first timestep. This is done outside the main loop\n        # because we are going from a single decoder input (the output from the\n        # encoder) to the top `beam_size` decoder outputs. On the other hand,\n        # within the main loop we are going from the `beam_size` elements of the\n        # beam to `beam_size`^2 candidates from which we will select the top\n        # `beam_size` elements for the next iteration.\n        # shape: (batch_size, num_classes)\n        start_class_log_probabilities, state = step(start_predictions, start_state)\n\n        num_classes = start_class_log_probabilities.size()[1]\n\n        # Make sure `per_node_beam_size` is not larger than `num_classes`.\n        if self.per_node_beam_size > num_classes:\n            raise ConfigurationError(f\"Target vocab size ({num_classes:d}) too small \"\n                                     f\"relative to per_node_beam_size ({self.per_node_beam_size:d}).\\n\"\n                                     f\"Please decrease beam_size or per_node_beam_size.\")\n\n        # shape: (batch_size, beam_size), (batch_size, beam_size)\n        start_top_log_probabilities, start_predicted_classes = \\\n                start_class_log_probabilities.topk(self.beam_size)\n        if self.beam_size == 1 and (start_predicted_classes == self._end_index).all():\n            warnings.warn(\"Empty sequences predicted. You may want to increase the beam size or ensure \"\n                          \"your step function is working properly.\",\n                          RuntimeWarning)\n            return start_predicted_classes.unsqueeze(-1), start_top_log_probabilities\n\n        # The log probabilities for the last time step.\n        # shape: (batch_size, beam_size)\n        last_log_probabilities = start_top_log_probabilities\n\n        # shape: [(batch_size, beam_size)]\n        predictions.append(start_predicted_classes)\n\n        # Log probability tensor that mandates that the end token is selected.\n        # shape: (batch_size * beam_size, num_classes)\n        log_probs_after_end = start_class_log_probabilities.new_full(\n                (batch_size * self.beam_size, num_classes),\n                float(\"-inf\")\n        )\n        log_probs_after_end[:, self._end_index] = 0.\n\n        # Set the same state for each element in the beam.\n        for key, state_tensor in state.items():\n            _, *last_dims = state_tensor.size()\n            # shape: (batch_size * beam_size, *)\n            state[key] = state_tensor.\\\n                    unsqueeze(1).\\\n                    expand(batch_size, self.beam_size, *last_dims).\\\n                    reshape(batch_size * self.beam_size, *last_dims)\n\n        for timestep in range(self.max_steps - 1):\n            # shape: (batch_size * beam_size,)\n            last_predictions = predictions[-1].reshape(batch_size * self.beam_size)\n\n            # If every predicted token from the last step is `self._end_index`,\n            # then we can stop early.\n            if (last_predictions == self._end_index).all():\n                break\n\n            # Take a step. This get the predicted log probs of the next classes\n            # and updates the state.\n            # shape: (batch_size * beam_size, num_classes)\n            class_log_probabilities, state = step(last_predictions, state)\n\n            # shape: (batch_size * beam_size, num_classes)\n            last_predictions_expanded = last_predictions.unsqueeze(-1).expand(\n                    batch_size * self.beam_size,\n                    num_classes\n            )\n\n            # Here we are finding any beams where we predicted the end token in\n            # the previous timestep and replacing the distribution with a\n            # one-hot distribution, forcing the beam to predict the end token\n            # this timestep as well.\n            # shape: (batch_size * beam_size, num_classes)\n            cleaned_log_probabilities = torch.where(\n                    last_predictions_expanded == self._end_index,\n                    log_probs_after_end,\n                    class_log_probabilities\n            )\n\n            # shape (both): (batch_size * beam_size, per_node_beam_size)\n            top_log_probabilities, predicted_classes = \\\n                cleaned_log_probabilities.topk(self.per_node_beam_size)\n\n            # Here we expand the last log probabilities to (batch_size * beam_size, per_node_beam_size)\n            # so that we can add them to the current log probs for this timestep.\n            # This lets us maintain the log probability of each element on the beam.\n            # shape: (batch_size * beam_size, per_node_beam_size)\n            expanded_last_log_probabilities = last_log_probabilities.\\\n                    unsqueeze(2).\\\n                    expand(batch_size, self.beam_size, self.per_node_beam_size).\\\n                    reshape(batch_size * self.beam_size, self.per_node_beam_size)\n\n            # shape: (batch_size * beam_size, per_node_beam_size)\n            summed_top_log_probabilities = top_log_probabilities + expanded_last_log_probabilities\n\n            # shape: (batch_size, beam_size * per_node_beam_size)\n            reshaped_summed = summed_top_log_probabilities.\\\n                    reshape(batch_size, self.beam_size * self.per_node_beam_size)\n\n            # shape: (batch_size, beam_size * per_node_beam_size)\n            reshaped_predicted_classes = predicted_classes.\\\n                    reshape(batch_size, self.beam_size * self.per_node_beam_size)\n\n            # Keep only the top `beam_size` beam indices.\n            # shape: (batch_size, beam_size), (batch_size, beam_size)\n            restricted_beam_log_probs, restricted_beam_indices = reshaped_summed.topk(self.beam_size)\n\n            # Use the beam indices to extract the corresponding classes.\n            # shape: (batch_size, beam_size)\n            restricted_predicted_classes = reshaped_predicted_classes.gather(1, restricted_beam_indices)\n\n            predictions.append(restricted_predicted_classes)\n\n            # shape: (batch_size, beam_size)\n            last_log_probabilities = restricted_beam_log_probs\n\n            # The beam indices come from a `beam_size * per_node_beam_size` dimension where the\n            # indices with a common ancestor are grouped together. Hence\n            # dividing by per_node_beam_size gives the ancestor. (Note that this is integer\n            # division as the tensor is a LongTensor.)\n            # shape: (batch_size, beam_size)\n            backpointer = restricted_beam_indices / self.per_node_beam_size\n\n            backpointers.append(backpointer)\n\n            # Keep only the pieces of the state tensors corresponding to the\n            # ancestors created this iteration.\n            for key, state_tensor in state.items():\n                _, *last_dims = state_tensor.size()\n                # shape: (batch_size, beam_size, *)\n                expanded_backpointer = backpointer.\\\n                        view(batch_size, self.beam_size, *([1] * len(last_dims))).\\\n                        expand(batch_size, self.beam_size, *last_dims)\n\n                # shape: (batch_size * beam_size, *)\n                state[key] = state_tensor.\\\n                        reshape(batch_size, self.beam_size, *last_dims).\\\n                        gather(1, expanded_backpointer).\\\n                        reshape(batch_size * self.beam_size, *last_dims)\n\n        if not torch.isfinite(last_log_probabilities).all():\n            warnings.warn(\"Infinite log probabilities encountered. Some final sequences may not make sense. \"\n                          \"This can happen when the beam size is larger than the number of valid (non-zero \"\n                          \"probability) transitions that the step function produces.\",\n                          RuntimeWarning)\n\n        # Reconstruct the sequences.\n        # shape: [(batch_size, beam_size, 1)]\n        reconstructed_predictions = [predictions[-1].unsqueeze(2)]\n\n        # shape: (batch_size, beam_size)\n        cur_backpointers = backpointers[-1]\n\n        for timestep in range(len(predictions) - 2, 0, -1):\n            # shape: (batch_size, beam_size, 1)\n            cur_preds = predictions[timestep].gather(1, cur_backpointers).unsqueeze(2)\n\n            reconstructed_predictions.append(cur_preds)\n\n            # shape: (batch_size, beam_size)\n            cur_backpointers = backpointers[timestep - 1].gather(1, cur_backpointers)\n\n        # shape: (batch_size, beam_size, 1)\n        final_preds = predictions[0].gather(1, cur_backpointers).unsqueeze(2)\n\n        reconstructed_predictions.append(final_preds)\n\n        # shape: (batch_size, beam_size, max_steps)\n        all_predictions = torch.cat(list(reversed(reconstructed_predictions)), 2)\n\n        return all_predictions, last_log_probabilities"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef takes_arg(obj, arg: str) -> bool:\n    if inspect.isclass(obj):\n        signature = inspect.signature(obj.__init__)\n    elif inspect.ismethod(obj) or inspect.isfunction(obj):\n        signature = inspect.signature(obj)\n    else:\n        raise ConfigurationError(f\"object {obj} is not callable\")\n    return arg in signature.parameters", "response": "Checks whether the provided object takes a certain arg."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef takes_kwargs(obj) -> bool:\n    if inspect.isclass(obj):\n        signature = inspect.signature(obj.__init__)\n    elif inspect.ismethod(obj) or inspect.isfunction(obj):\n        signature = inspect.signature(obj)\n    else:\n        raise ConfigurationError(f\"object {obj} is not callable\")\n    return bool(any([p.kind == inspect.Parameter.VAR_KEYWORD  # type: ignore\n                     for p in signature.parameters.values()]))", "response": "Checks whether a provided object takes any positional arguments."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_optional(annotation: type):\n    origin = getattr(annotation, '__origin__', None)\n    args = getattr(annotation, '__args__', ())\n    if origin == Union and len(args) == 2 and args[1] == type(None):\n        return args[0]\n    else:\n        return annotation", "response": "Removes optional annotations from the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_kwargs(cls: Type[T], params: Params, **extras) -> Dict[str, Any]:\n    # Get the signature of the constructor.\n    signature = inspect.signature(cls.__init__)\n    kwargs: Dict[str, Any] = {}\n\n    # Iterate over all the constructor parameters and their annotations.\n    for name, param in signature.parameters.items():\n        # Skip \"self\". You're not *required* to call the first parameter \"self\",\n        # so in theory this logic is fragile, but if you don't call the self parameter\n        # \"self\" you kind of deserve what happens.\n        if name == \"self\":\n            continue\n\n        # If the annotation is a compound type like typing.Dict[str, int],\n        # it will have an __origin__ field indicating `typing.Dict`\n        # and an __args__ field indicating `(str, int)`. We capture both.\n        annotation = remove_optional(param.annotation)\n        kwargs[name] = construct_arg(cls, name, annotation, param.default, params, **extras)\n\n    params.assert_empty(cls.__name__)\n    return kwargs", "response": "Given some class a Params object and possibly other keyword arguments create a dict of keyword args suitable for passing to the class s constructor."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a dictionary of extra arguments returns a dictionary of extra arguments that actually are a part of the signature of the cls. from_params method.", "response": "def create_extras(cls: Type[T],\n                  extras: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Given a dictionary of extra arguments, returns a dictionary of\n    kwargs that actually are a part of the signature of the cls.from_params\n    (or cls) method.\n    \"\"\"\n    subextras: Dict[str, Any] = {}\n    if hasattr(cls, \"from_params\"):\n        from_params_method = cls.from_params  # type: ignore\n    else:\n        # In some rare cases, we get a registered subclass that does _not_ have a\n        # from_params method (this happens with Activations, for instance, where we\n        # register pytorch modules directly).  This is a bit of a hack to make those work,\n        # instead of adding a `from_params` method for them somehow. Then the extras\n        # in the class constructor are what we are looking for, to pass on.\n        from_params_method = cls\n    if takes_kwargs(from_params_method):\n        # If annotation.params accepts **kwargs, we need to pass them all along.\n        # For example, `BasicTextFieldEmbedder.from_params` requires a Vocabulary\n        # object, but `TextFieldEmbedder.from_params` does not.\n        subextras = extras\n    else:\n        # Otherwise, only supply the ones that are actual args; any additional ones\n        # will cause a TypeError.\n        subextras = {k: v for k, v in extras.items()\n                     if takes_arg(from_params_method, k)}\n    return subextras"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef construct_arg(cls: Type[T], # pylint: disable=inconsistent-return-statements,too-many-return-statements\n                  param_name: str,\n                  annotation: Type,\n                  default: Any,\n                  params: Params,\n                  **extras) -> Any:\n    \"\"\"\n    Does the work of actually constructing an individual argument for :func:`create_kwargs`.\n\n    Here we're in the inner loop of iterating over the parameters to a particular constructor,\n    trying to construct just one of them.  The information we get for that parameter is its name,\n    its type annotation, and its default value; we also get the full set of ``Params`` for\n    constructing the object (which we may mutate), and any ``extras`` that the constructor might\n    need.\n\n    We take the type annotation and default value here separately, instead of using an\n    ``inspect.Parameter`` object directly, so that we can handle ``Union`` types using recursion on\n    this method, trying the different annotation types in the union in turn.\n    \"\"\"\n    from allennlp.models.archival import load_archive  # import here to avoid circular imports\n\n    # We used `param_name` as the method argument to avoid conflicts with 'name' being a key in\n    # `extras`, which isn't _that_ unlikely.  Now that we are inside the method, we can switch back\n    # to using `name`.\n    name = param_name\n    origin = getattr(annotation, '__origin__', None)\n    args = getattr(annotation, '__args__', [])\n\n    # The parameter is optional if its default value is not the \"no default\" sentinel.\n    optional = default != _NO_DEFAULT\n\n    # Some constructors expect extra non-parameter items, e.g. vocab: Vocabulary.\n    # We check the provided `extras` for these and just use them if they exist.\n    if name in extras:\n        return extras[name]\n    # Next case is when argument should be loaded from pretrained archive.\n    elif name in params and isinstance(params.get(name), Params) and \"_pretrained\" in params.get(name):\n        load_module_params = params.pop(name).pop(\"_pretrained\")\n        archive_file = load_module_params.pop(\"archive_file\")\n        module_path = load_module_params.pop(\"module_path\")\n        freeze = load_module_params.pop(\"freeze\", True)\n        archive = load_archive(archive_file)\n        result = archive.extract_module(module_path, freeze) # pylint: disable=no-member\n        if not isinstance(result, annotation):\n            raise ConfigurationError(f\"The module from model at {archive_file} at path {module_path} \"\n                                     f\"was expected of type {annotation} but is of type {type(result)}\")\n        return result\n    # The next case is when the parameter type is itself constructible from_params.\n    elif hasattr(annotation, 'from_params'):\n        if name in params:\n            # Our params have an entry for this, so we use that.\n            subparams = params.pop(name)\n\n            subextras = create_extras(annotation, extras)\n\n            # In some cases we allow a string instead of a param dict, so\n            # we need to handle that case separately.\n            if isinstance(subparams, str):\n                return annotation.by_name(subparams)()\n            else:\n                return annotation.from_params(params=subparams, **subextras)\n        elif not optional:\n            # Not optional and not supplied, that's an error!\n            raise ConfigurationError(f\"expected key {name} for {cls.__name__}\")\n        else:\n            return default\n\n    # If the parameter type is a Python primitive, just pop it off\n    # using the correct casting pop_xyz operation.\n    elif annotation == str:\n        return params.pop(name, default) if optional else params.pop(name)\n    elif annotation == int:\n        return params.pop_int(name, default) if optional else params.pop_int(name)\n    elif annotation == bool:\n        return params.pop_bool(name, default) if optional else params.pop_bool(name)\n    elif annotation == float:\n        return params.pop_float(name, default) if optional else params.pop_float(name)\n\n    # This is special logic for handling types like Dict[str, TokenIndexer],\n    # List[TokenIndexer], Tuple[TokenIndexer, Tokenizer], and Set[TokenIndexer],\n    # which it creates by instantiating each value from_params and returning the resulting structure.\n    elif origin in (Dict, dict) and len(args) == 2 and hasattr(args[-1], 'from_params'):\n        value_cls = annotation.__args__[-1]\n\n        value_dict = {}\n\n        for key, value_params in params.pop(name, Params({})).items():\n            subextras = create_extras(value_cls, extras)\n            value_dict[key] = value_cls.from_params(params=value_params, **subextras)\n\n        return value_dict\n\n    elif origin in (List, list) and len(args) == 1 and hasattr(args[0], 'from_params'):\n        value_cls = annotation.__args__[0]\n\n        value_list = []\n\n        for value_params in params.pop(name, Params({})):\n            subextras = create_extras(value_cls, extras)\n            value_list.append(value_cls.from_params(params=value_params, **subextras))\n\n        return value_list\n\n    elif origin in (Tuple, tuple) and all(hasattr(arg, 'from_params') for arg in args):\n        value_list = []\n\n        for value_cls, value_params in zip(annotation.__args__, params.pop(name, Params({}))):\n            subextras = create_extras(value_cls, extras)\n            value_list.append(value_cls.from_params(params=value_params, **subextras))\n\n        return tuple(value_list)\n\n    elif origin in (Set, set) and len(args) == 1 and hasattr(args[0], 'from_params'):\n        value_cls = annotation.__args__[0]\n\n        value_set = set()\n\n        for value_params in params.pop(name, Params({})):\n            subextras = create_extras(value_cls, extras)\n            value_set.add(value_cls.from_params(params=value_params, **subextras))\n\n        return value_set\n\n    elif origin == Union:\n        # Storing this so we can recover it later if we need to.\n        param_value = params.get(name, Params({}))\n        if isinstance(param_value, Params):\n            param_value = param_value.duplicate()\n\n        # We'll try each of the given types in the union sequentially, returning the first one that\n        # succeeds.\n        for arg in args:\n            try:\n                return construct_arg(cls, name, arg, default, params, **extras)\n            except (ValueError, TypeError, ConfigurationError, AttributeError):\n                # Our attempt to construct the argument may have popped `params[name]`, so we\n                # restore it here.\n                params[name] = param_value\n                if isinstance(param_value, Params):\n                    param_value = param_value.duplicate()\n                continue\n\n        # If none of them succeeded, we crash.\n        raise ConfigurationError(f\"Failed to construct argument {name} with type {annotation}\")\n    else:\n        # Pass it on as is and hope for the best.   \u00af\\_(\u30c4)_/\u00af\n        if optional:\n            return params.pop(name, default)\n        else:\n            return params.pop(name)", "response": "Constructs an argument for a given parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef take_step(self,\n                  state: StateType,\n                  max_actions: int = None,\n                  allowed_actions: List[Set] = None) -> List[StateType]:\n        \"\"\"\n        The main method in the ``TransitionFunction`` API.  This function defines the computation\n        done at each step of decoding and returns a ranked list of next states.\n\n        The input state is `grouped`, to allow for efficient computation, but the output states\n        should all have a ``group_size`` of 1, to make things easier on the decoding algorithm.\n        They will get regrouped later as needed.\n\n        Because of the way we handle grouping in the decoder states, constructing a new state is\n        actually a relatively expensive operation.  If you know a priori that only some of the\n        states will be needed (either because you have a set of gold action sequences, or you have\n        a fixed beam size), passing that information into this function will keep us from\n        constructing more states than we need, which will greatly speed up your computation.\n\n        IMPORTANT: This method `must` returns states already sorted by their score, otherwise\n        ``BeamSearch`` and other methods will break.  For efficiency, we do not perform an\n        additional sort in those methods.\n\n        ALSO IMPORTANT: When ``allowed_actions`` is given and ``max_actions`` is not, we assume you\n        want to evaluate all possible states and do not need any sorting (e.g., this is true for\n        maximum marginal likelihood training that does not use a beam search).  In this case, we\n        may skip the sorting step for efficiency reasons.\n\n        Parameters\n        ----------\n        state : ``State``\n            The current state of the decoder, which we will take a step `from`.  We may be grouping\n            together computation for several states here.  Because we can have several states for\n            each instance in the original batch being evaluated at the same time, we use\n            ``group_size`` for this kind of batching, and ``batch_size`` for the `original` batch\n            in ``model.forward.``\n        max_actions : ``int``, optional\n            If you know that you will only need a certain number of states out of this (e.g., in a\n            beam search), you can pass in the max number of actions that you need, and we will only\n            construct that many states (for each `batch` instance - `not` for each `group`\n            instance!).  This can save a whole lot of computation if you have an action space\n            that's much larger than your beam size.\n        allowed_actions : ``List[Set]``, optional\n            If the ``DecoderTrainer`` has constraints on which actions need to be evaluated (e.g.,\n            maximum marginal likelihood only needs to evaluate action sequences in a given set),\n            you can pass those constraints here, to avoid constructing state objects unnecessarily.\n            If there are no constraints from the trainer, passing a value of ``None`` here will\n            allow all actions to be considered.\n\n            This is a list because it is `batched` - every instance in the batch has a set of\n            allowed actions.  Note that the size of this list is the ``group_size`` in the\n            ``State``, `not` the ``batch_size`` of ``model.forward``.  The training algorithm needs\n            to convert from the `batched` allowed action sequences that it has to a `grouped`\n            allowed action sequence list.\n\n        Returns\n        -------\n        next_states : ``List[State]``\n            A list of next states, ordered by score.\n        \"\"\"\n        raise NotImplementedError", "response": "This method is used to take a single step of decoding from a state."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _safe_sparse_mask(tensor: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n    # pylint: disable=protected-access\n    try:\n        return tensor.sparse_mask(mask)\n    except AttributeError:\n        # TODO(joelgrus): remove this and/or warn at some point\n        return tensor._sparse_mask(mask)", "response": "Wrapper for Tensor. sparse_mask."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_sentence(sentence_blob: str) -> Tuple[List[Dict[str, str]], List[Tuple[int, int]], List[str]]:\n    annotated_sentence = []\n    arc_indices = []\n    arc_tags = []\n    predicates = []\n\n    lines = [line.split(\"\\t\") for line in sentence_blob.split(\"\\n\")\n             if line and not line.strip().startswith(\"#\")]\n    for line_idx, line in enumerate(lines):\n        annotated_token = {k:v for k, v in zip(FIELDS, line)}\n        if annotated_token['pred'] == \"+\":\n            predicates.append(line_idx)\n        annotated_sentence.append(annotated_token)\n\n    for line_idx, line in enumerate(lines):\n        for predicate_idx, arg in enumerate(line[len(FIELDS):]):\n            if arg != \"_\":\n                arc_indices.append((line_idx, predicates[predicate_idx]))\n                arc_tags.append(arg)\n    return annotated_sentence, arc_indices, arc_tags", "response": "Parses a chunk of text in the SemEval SDP format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing cuda_device parameter into a list of cuda_device parameters.", "response": "def parse_cuda_device(cuda_device: Union[str, int, List[int]]) -> Union[int, List[int]]:\n    \"\"\"\n    Disambiguates single GPU and multiple GPU settings for cuda_device param.\n    \"\"\"\n    def from_list(strings):\n        if len(strings) > 1:\n            return [int(d) for d in strings]\n        elif len(strings) == 1:\n            return int(strings[0])\n        else:\n            return -1\n\n    if isinstance(cuda_device, str):\n        return from_list(re.split(r',\\s*', cuda_device))\n    elif isinstance(cuda_device, int):\n        return cuda_device\n    elif isinstance(cuda_device, list):\n        return from_list(cuda_device)\n    else:\n        # TODO(brendanr): Determine why mypy can't tell that this matches the Union.\n        return int(cuda_device)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fine_tune_model_from_args(args: argparse.Namespace):\n    fine_tune_model_from_file_paths(model_archive_path=args.model_archive,\n                                    config_file=args.config_file,\n                                    serialization_dir=args.serialization_dir,\n                                    overrides=args.overrides,\n                                    extend_vocab=args.extend_vocab,\n                                    file_friendly_logging=args.file_friendly_logging,\n                                    batch_weight_key=args.batch_weight_key,\n                                    embedding_sources_mapping=args.embedding_sources_mapping)", "response": "Fine tune a single model from an argparse. Namespace object to string paths."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a model archive from a file.", "response": "def fine_tune_model_from_file_paths(model_archive_path: str,\n                                    config_file: str,\n                                    serialization_dir: str,\n                                    overrides: str = \"\",\n                                    extend_vocab: bool = False,\n                                    file_friendly_logging: bool = False,\n                                    batch_weight_key: str = \"\",\n                                    embedding_sources_mapping: str = \"\") -> Model:\n    \"\"\"\n    A wrapper around :func:`fine_tune_model` which loads the model archive from a file.\n\n    Parameters\n    ----------\n    model_archive_path : ``str``\n        Path to a saved model archive that is the result of running the ``train`` command.\n    config_file : ``str``\n        A configuration file specifying how to continue training.  The format is identical to the\n        configuration file for the ``train`` command, but any contents in the ``model`` section is\n        ignored (as we are using the provided model archive instead).\n    serialization_dir : ``str``\n        The directory in which to save results and logs. We just pass this along to\n        :func:`fine_tune_model`.\n    overrides : ``str``\n        A JSON string that we will use to override values in the input parameter file.\n    extend_vocab: ``bool``, optional (default=False)\n        If ``True``, we use the new instances to extend your vocabulary.\n    file_friendly_logging : ``bool``, optional (default=False)\n        If ``True``, we make our output more friendly to saved model files.  We just pass this\n        along to :func:`fine_tune_model`.\n    batch_weight_key : ``str``, optional (default=\"\")\n        If non-empty, name of metric used to weight the loss on a per-batch basis.\n    embedding_sources_mapping: ``str``, optional (default=\"\")\n        JSON string to define dict mapping from embedding paths used during training to\n        the corresponding embedding filepaths available during fine-tuning.\n    \"\"\"\n    # We don't need to pass in `cuda_device` here, because the trainer will call `model.cuda()` if\n    # necessary.\n    archive = load_archive(model_archive_path)\n    params = Params.from_file(config_file, overrides)\n\n    embedding_sources: Dict[str, str] = json.loads(embedding_sources_mapping) if embedding_sources_mapping else {}\n    return fine_tune_model(model=archive.model,\n                           params=params,\n                           serialization_dir=serialization_dir,\n                           extend_vocab=extend_vocab,\n                           file_friendly_logging=file_friendly_logging,\n                           batch_weight_key=batch_weight_key,\n                           embedding_sources_mapping=embedding_sources)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fine_tune_model(model: Model,\n                    params: Params,\n                    serialization_dir: str,\n                    extend_vocab: bool = False,\n                    file_friendly_logging: bool = False,\n                    batch_weight_key: str = \"\",\n                    embedding_sources_mapping: Dict[str, str] = None) -> Model:\n    \"\"\"\n    Fine tunes the given model, using a set of parameters that is largely identical to those used\n    for :func:`~allennlp.commands.train.train_model`, except that the ``model`` section is ignored,\n    if it is present (as we are already given a ``Model`` here).\n\n    The main difference between the logic done here and the logic done in ``train_model`` is that\n    here we do not worry about vocabulary construction or creating the model object.  Everything\n    else is the same.\n\n    Parameters\n    ----------\n    model : ``Model``\n        A model to fine tune.\n    params : ``Params``\n        A parameter object specifying an AllenNLP Experiment\n    serialization_dir : ``str``\n        The directory in which to save results and logs.\n    extend_vocab: ``bool``, optional (default=False)\n        If ``True``, we use the new instances to extend your vocabulary.\n    file_friendly_logging : ``bool``, optional (default=False)\n        If ``True``, we add newlines to tqdm output, even on an interactive terminal, and we slow\n        down tqdm's output to only once every 10 seconds.\n    batch_weight_key : ``str``, optional (default=\"\")\n        If non-empty, name of metric used to weight the loss on a per-batch basis.\n    embedding_sources_mapping: ``Dict[str, str]``, optional (default=None)\n        mapping from model paths to the pretrained embedding filepaths\n        used during fine-tuning.\n    \"\"\"\n    prepare_environment(params)\n    if os.path.exists(serialization_dir) and os.listdir(serialization_dir):\n        raise ConfigurationError(f\"Serialization directory ({serialization_dir}) \"\n                                 f\"already exists and is not empty.\")\n\n    os.makedirs(serialization_dir, exist_ok=True)\n    prepare_global_logging(serialization_dir, file_friendly_logging)\n\n    serialization_params = deepcopy(params).as_dict(quiet=True)\n    with open(os.path.join(serialization_dir, CONFIG_NAME), \"w\") as param_file:\n        json.dump(serialization_params, param_file, indent=4)\n\n    if params.pop('model', None):\n        logger.warning(\"You passed parameters for the model in your configuration file, but we \"\n                       \"are ignoring them, using instead the model parameters in the archive.\")\n\n    vocabulary_params = params.pop('vocabulary', {})\n    if vocabulary_params.get('directory_path', None):\n        logger.warning(\"You passed `directory_path` in parameters for the vocabulary in \"\n                       \"your configuration file, but it will be ignored. \")\n\n    all_datasets = datasets_from_params(params)\n    vocab = model.vocab\n\n    if extend_vocab:\n        datasets_for_vocab_creation = set(params.pop(\"datasets_for_vocab_creation\", all_datasets))\n\n        for dataset in datasets_for_vocab_creation:\n            if dataset not in all_datasets:\n                raise ConfigurationError(f\"invalid 'dataset_for_vocab_creation' {dataset}\")\n\n        logger.info(\"Extending model vocabulary using %s data.\", \", \".join(datasets_for_vocab_creation))\n        vocab.extend_from_instances(vocabulary_params,\n                                    (instance for key, dataset in all_datasets.items()\n                                     for instance in dataset\n                                     if key in datasets_for_vocab_creation))\n\n        model.extend_embedder_vocab(embedding_sources_mapping)\n\n    vocab.save_to_files(os.path.join(serialization_dir, \"vocabulary\"))\n\n    iterator = DataIterator.from_params(params.pop(\"iterator\"))\n    iterator.index_with(model.vocab)\n    validation_iterator_params = params.pop(\"validation_iterator\", None)\n    if validation_iterator_params:\n        validation_iterator = DataIterator.from_params(validation_iterator_params)\n        validation_iterator.index_with(vocab)\n    else:\n        validation_iterator = None\n\n    train_data = all_datasets['train']\n    validation_data = all_datasets.get('validation')\n    test_data = all_datasets.get('test')\n\n    trainer_params = params.pop(\"trainer\")\n    no_grad_regexes = trainer_params.pop(\"no_grad\", ())\n    for name, parameter in model.named_parameters():\n        if any(re.search(regex, name) for regex in no_grad_regexes):\n            parameter.requires_grad_(False)\n\n    frozen_parameter_names, tunable_parameter_names = \\\n                   get_frozen_and_tunable_parameter_names(model)\n    logger.info(\"Following parameters are Frozen  (without gradient):\")\n    for name in frozen_parameter_names:\n        logger.info(name)\n    logger.info(\"Following parameters are Tunable (with gradient):\")\n    for name in tunable_parameter_names:\n        logger.info(name)\n\n    trainer_type = trainer_params.pop(\"type\", \"default\")\n    if trainer_type == \"default\":\n        trainer = Trainer.from_params(model=model,\n                                      serialization_dir=serialization_dir,\n                                      iterator=iterator,\n                                      train_data=train_data,\n                                      validation_data=validation_data,\n                                      params=trainer_params,\n                                      validation_iterator=validation_iterator)\n    else:\n        raise ConfigurationError(\"currently fine-tune only works with the default Trainer\")\n\n    evaluate_on_test = params.pop_bool(\"evaluate_on_test\", False)\n\n    params.assert_empty('base train command')\n    try:\n        metrics = trainer.train()\n    except KeyboardInterrupt:\n        # if we have completed an epoch, try to create a model archive.\n        if os.path.exists(os.path.join(serialization_dir, _DEFAULT_WEIGHTS)):\n            logging.info(\"Fine-tuning interrupted by the user. Attempting to create \"\n                         \"a model archive using the current best epoch weights.\")\n            archive_model(serialization_dir, files_to_archive=params.files_to_archive)\n        raise\n\n    # Evaluate\n    if test_data and evaluate_on_test:\n        logger.info(\"The model will be evaluated using the best epoch weights.\")\n        test_metrics = evaluate(model, test_data, validation_iterator or iterator,\n                                cuda_device=trainer._cuda_devices[0], # pylint: disable=protected-access,\n                                batch_weight_key=batch_weight_key)\n\n        for key, value in test_metrics.items():\n            metrics[\"test_\" + key] = value\n\n    elif test_data:\n        logger.info(\"To evaluate on the test set after training, pass the \"\n                    \"'evaluate_on_test' flag, or use the 'allennlp evaluate' command.\")\n\n\n    # Now tar up results\n    archive_model(serialization_dir, files_to_archive=params.files_to_archive)\n\n    metrics_json = json.dumps(metrics, indent=2)\n    with open(os.path.join(serialization_dir, \"metrics.json\"), \"w\") as metrics_file:\n        metrics_file.write(metrics_json)\n    logger.info(\"Metrics: %s\", metrics_json)\n\n    return model", "response": "Fine tunes the given model."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nforwarding computation of the top - k scoring items into the original embeddings and mask.", "response": "def forward(self, # pylint: disable=arguments-differ\n                embeddings: torch.FloatTensor,\n                mask: torch.LongTensor,\n                num_items_to_keep: Union[int, torch.LongTensor]) -> Tuple[torch.FloatTensor, torch.LongTensor,\n                                                                          torch.LongTensor, torch.FloatTensor]:\n        \"\"\"\n        Extracts the top-k scoring items with respect to the scorer. We additionally return\n        the indices of the top-k in their original order, not ordered by score, so that downstream\n        components can rely on the original ordering (e.g., for knowing what spans are valid\n        antecedents in a coreference resolution model). May use the same k for all sentences in\n        minibatch, or different k for each.\n\n        Parameters\n        ----------\n        embeddings : ``torch.FloatTensor``, required.\n            A tensor of shape (batch_size, num_items, embedding_size), containing an embedding for\n            each item in the list that we want to prune.\n        mask : ``torch.LongTensor``, required.\n            A tensor of shape (batch_size, num_items), denoting unpadded elements of\n            ``embeddings``.\n        num_items_to_keep : ``Union[int, torch.LongTensor]``, required.\n            If a tensor of shape (batch_size), specifies the number of items to keep for each\n            individual sentence in minibatch.\n            If an int, keep the same number of items for all sentences.\n\n        Returns\n        -------\n        top_embeddings : ``torch.FloatTensor``\n            The representations of the top-k scoring items.\n            Has shape (batch_size, max_num_items_to_keep, embedding_size).\n        top_mask : ``torch.LongTensor``\n            The corresponding mask for ``top_embeddings``.\n            Has shape (batch_size, max_num_items_to_keep).\n        top_indices : ``torch.IntTensor``\n            The indices of the top-k scoring items into the original ``embeddings``\n            tensor. This is returned because it can be useful to retain pointers to\n            the original items, if each item is being scored by multiple distinct\n            scorers, for instance. Has shape (batch_size, max_num_items_to_keep).\n        top_item_scores : ``torch.FloatTensor``\n            The values of the top-k scoring items.\n            Has shape (batch_size, max_num_items_to_keep, 1).\n        \"\"\"\n        # If an int was given for number of items to keep, construct tensor by repeating the value.\n        if isinstance(num_items_to_keep, int):\n            batch_size = mask.size(0)\n            # Put the tensor on same device as the mask.\n            num_items_to_keep = num_items_to_keep * torch.ones([batch_size], dtype=torch.long,\n                                                               device=mask.device)\n\n        max_items_to_keep = num_items_to_keep.max()\n\n        mask = mask.unsqueeze(-1)\n        num_items = embeddings.size(1)\n        # Shape: (batch_size, num_items, 1)\n        scores = self._scorer(embeddings)\n\n        if scores.size(-1) != 1 or scores.dim() != 3:\n            raise ValueError(f\"The scorer passed to Pruner must produce a tensor of shape\"\n                             f\"(batch_size, num_items, 1), but found shape {scores.size()}\")\n        # Make sure that we don't select any masked items by setting their scores to be very\n        # negative.  These are logits, typically, so -1e20 should be plenty negative.\n        scores = util.replace_masked_values(scores, mask, -1e20)\n\n        # Shape: (batch_size, max_num_items_to_keep, 1)\n        _, top_indices = scores.topk(max_items_to_keep, 1)\n\n        # Mask based on number of items to keep for each sentence.\n        # Shape: (batch_size, max_num_items_to_keep)\n        top_indices_mask = util.get_mask_from_sequence_lengths(num_items_to_keep, max_items_to_keep)\n        top_indices_mask = top_indices_mask.byte()\n\n        # Shape: (batch_size, max_num_items_to_keep)\n        top_indices = top_indices.squeeze(-1)\n\n        # Fill all masked indices with largest \"top\" index for that sentence, so that all masked\n        # indices will be sorted to the end.\n        # Shape: (batch_size, 1)\n        fill_value, _ = top_indices.max(dim=1)\n        fill_value = fill_value.unsqueeze(-1)\n        # Shape: (batch_size, max_num_items_to_keep)\n        top_indices = torch.where(top_indices_mask, top_indices, fill_value)\n\n        # Now we order the selected indices in increasing order with\n        # respect to their indices (and hence, with respect to the\n        # order they originally appeared in the ``embeddings`` tensor).\n        top_indices, _ = torch.sort(top_indices, 1)\n\n        # Shape: (batch_size * max_num_items_to_keep)\n        # torch.index_select only accepts 1D indices, but here\n        # we need to select items for each element in the batch.\n        flat_top_indices = util.flatten_and_batch_shift_indices(top_indices, num_items)\n\n        # Shape: (batch_size, max_num_items_to_keep, embedding_size)\n        top_embeddings = util.batched_index_select(embeddings, top_indices, flat_top_indices)\n\n        # Combine the masks on spans that are out-of-bounds, and the mask on spans that are outside\n        # the top k for each sentence.\n        # Shape: (batch_size, max_num_items_to_keep)\n        sequence_mask = util.batched_index_select(mask, top_indices, flat_top_indices)\n        sequence_mask = sequence_mask.squeeze(-1).byte()\n        top_mask = top_indices_mask & sequence_mask\n        top_mask = top_mask.long()\n\n        # Shape: (batch_size, max_num_items_to_keep, 1)\n        top_scores = util.batched_index_select(scores, top_indices, flat_top_indices)\n\n        return top_embeddings, top_mask, top_indices, top_scores"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_epoch_number(batch: Batch, epoch: int) -> Batch:\n    for instance in batch.instances:\n        instance.fields['epoch_num'] = MetadataField(epoch)\n    return batch", "response": "Adds the epoch number to the batch instances as a MetadataField."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _take_instances(self,\n                        instances: Iterable[Instance],\n                        max_instances: Optional[int] = None) -> Iterator[Instance]:\n        \"\"\"\n        Take the next `max_instances` instances from the given dataset.\n        If `max_instances` is `None`, then just take all instances from the dataset.\n        If `max_instances` is not `None`, each call resumes where the previous one\n        left off, and when you get to the end of the dataset you start again from the beginning.\n        \"\"\"\n        # If max_instances isn't specified, just iterate once over the whole dataset\n        if max_instances is None:\n            yield from iter(instances)\n        else:\n            # If we don't have a cursor for this dataset, create one. We use ``id()``\n            # for the key because ``instances`` could be a list, which can't be used as a key.\n            key = id(instances)\n            iterator = self._cursors.get(key, iter(instances))\n\n            while max_instances > 0:\n                try:\n                    # If there are instances left on this iterator,\n                    # yield one and decrement max_instances.\n                    yield next(iterator)\n                    max_instances -= 1\n                except StopIteration:\n                    # None left, so start over again at the beginning of the dataset.\n                    iterator = iter(instances)\n\n            # We may have a new iterator, so update the cursor.\n            self._cursors[key] = iterator", "response": "Take the next max_instances instances from the given dataset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nyield lists of instances from the given iterable of instance objects.", "response": "def _memory_sized_lists(self,\n                            instances: Iterable[Instance]) -> Iterable[List[Instance]]:\n        \"\"\"\n        Breaks the dataset into \"memory-sized\" lists of instances,\n        which it yields up one at a time until it gets through a full epoch.\n\n        For example, if the dataset is already an in-memory list, and each epoch\n        represents one pass through the dataset, it just yields back the dataset.\n        Whereas if the dataset is lazily read from disk and we've specified to\n        load 1000 instances at a time, then it yields lists of 1000 instances each.\n        \"\"\"\n        lazy = is_lazy(instances)\n\n        # Get an iterator over the next epoch worth of instances.\n        iterator = self._take_instances(instances, self._instances_per_epoch)\n\n        # We have four different cases to deal with:\n\n        # With lazy instances and no guidance about how many to load into memory,\n        # we just load ``batch_size`` instances at a time:\n        if lazy and self._max_instances_in_memory is None:\n            yield from lazy_groups_of(iterator, self._batch_size)\n        # If we specified max instances in memory, lazy or not, we just\n        # load ``max_instances_in_memory`` instances at a time:\n        elif self._max_instances_in_memory is not None:\n            yield from lazy_groups_of(iterator, self._max_instances_in_memory)\n        # If we have non-lazy instances, and we want all instances each epoch,\n        # then we just yield back the list of instances:\n        elif self._instances_per_epoch is None:\n            yield ensure_list(instances)\n        # In the final case we have non-lazy instances, we want a specific number\n        # of instances each epoch, and we didn't specify how to many instances to load\n        # into memory. So we convert the whole iterator to a list:\n        else:\n            yield list(iterator)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _ensure_batch_is_sufficiently_small(\n            self,\n            batch_instances: Iterable[Instance],\n            excess: Deque[Instance]) -> List[List[Instance]]:\n        \"\"\"\n        If self._maximum_samples_per_batch is specified, then split the batch\n        into smaller sub-batches if it exceeds the maximum size.\n\n        Parameters\n        ----------\n        batch_instances : ``Iterable[Instance]``\n            A candidate batch.\n        excess : ``Deque[Instance]``\n            Instances that were not sufficient to form an entire batch\n            previously. They will be used as part of the first sub-batch. This\n            will be populated with instances from the end of batch_instances\n            that do not consist of more than self._maximum_samples_per_batch\n            samples or self._batch_size instances. It is the caller's\n            responsibility to place these in a batch too, which may, of course,\n            be done in part with subsequent calls to this method.\n\n            WARNING: Mutated in place!\n        \"\"\"\n        if self._maximum_samples_per_batch is None:\n            assert not excess\n            return [list(batch_instances)]\n\n        key, limit = self._maximum_samples_per_batch\n\n        batches: List[List[Instance]] = []\n        batch: List[Instance] = []\n        padding_length = -1\n\n        excess.extend(batch_instances)\n        while excess:\n            instance = excess.popleft()\n\n            if self.vocab is not None:\n                # we index here to ensure that shape information is available,\n                # as in some cases (with self._maximum_samples_per_batch)\n                # we need access to shaping information before batches are constructed)\n                instance.index_fields(self.vocab)\n            field_lengths = instance.get_padding_lengths()\n            for _, lengths in field_lengths.items():\n                try:\n                    padding_length = max(padding_length,\n                                         lengths[key])\n                except KeyError:\n                    pass\n\n            proposed_batch_size = len(batch) + 1\n\n            # Adding the current instance would exceed the batch size or sample size.\n            if proposed_batch_size >= self._batch_size or padding_length * proposed_batch_size > limit:\n                # Output the already existing batch\n                batches.append(batch)\n\n                # Put the current instance back, reset state.\n                excess.appendleft(instance)\n                batch = []\n                padding_length = -1\n            else:\n                batch.append(instance)\n\n        # Keep the current batch as excess.\n        excess.extend(batch)\n\n        return batches", "response": "This method is used to ensure that a batch of instances is sufficiently small."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the number of batches that can be split into.", "response": "def get_num_batches(self, instances: Iterable[Instance]) -> int:\n        \"\"\"\n        Returns the number of batches that ``dataset`` will be split into; if you want to track\n        progress through the batch with the generator produced by ``__call__``, this could be\n        useful.\n        \"\"\"\n        if is_lazy(instances) and self._instances_per_epoch is None:\n            # Unable to compute num batches, so just return 1.\n            return 1\n        elif self._instances_per_epoch is not None:\n            return math.ceil(self._instances_per_epoch / self._batch_size)\n        else:\n            # Not lazy, so can compute the list length.\n            return math.ceil(len(ensure_list(instances)) / self._batch_size)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _create_batches(self, instances: Iterable[Instance], shuffle: bool) -> Iterable[Batch]:\n        raise NotImplementedError", "response": "Create batches for the given instances."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreplaces carriage returns with newlines.", "response": "def replace_cr_with_newline(message: str):\n    \"\"\"\n    TQDM and requests use carriage returns to get the training line to update for each batch\n    without adding more lines to the terminal output.  Displaying those in a file won't work\n    correctly, so we'll just make sure that each batch shows up on its one line.\n    :param message: the message to permute\n    :return: the message with carriage returns replaced with newlines\n    \"\"\"\n    if '\\r' in message:\n        message = message.replace('\\r', '')\n        if not message or message[-1] != '\\n':\n            message += '\\n'\n    return message"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _batch_json_to_instances(self, json_dicts: List[JsonDict]) -> List[Instance]:\n        instances = []\n        for json_dict in json_dicts:\n            instances.append(self._json_to_instance(json_dict))\n        return instances", "response": "Converts a list of JSON objects into a list of Instance s."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_path(cls, archive_path: str, predictor_name: str = None) -> 'Predictor':\n        return Predictor.from_archive(load_archive(archive_path), predictor_name)", "response": "Instantiate a Predictor instance from an archive path."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes Scaled Dot Product Attention", "response": "def attention(query: torch.Tensor,\n              key: torch.Tensor,\n              value: torch.Tensor,\n              mask: torch.Tensor = None,\n              dropout: Callable = None) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Compute 'Scaled Dot Product Attention'\"\"\"\n    d_k = query.size(-1)\n    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n    if mask is not None:\n        scores = scores.masked_fill(mask == 0, -1e9)\n    p_attn = F.softmax(scores, dim=-1)\n    if dropout is not None:\n        p_attn = dropout(p_attn)\n    return torch.matmul(p_attn, value), p_attn"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef subsequent_mask(size: int, device: str = 'cpu') -> torch.Tensor:\n    mask = torch.tril(torch.ones(size, size, device=device, dtype=torch.int32)).unsqueeze(0)\n    return mask", "response": "Mask out subsequent positions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef forward(self, x, mask):\n        all_layers = []\n        for layer in self.layers:\n            x = layer(x, mask)\n            if self.return_all_layers:\n                all_layers.append(x)\n\n        if self.return_all_layers:\n            all_layers[-1] = self.norm(all_layers[-1])\n            return all_layers\n        return self.norm(x)", "response": "Pass the input and mask through each layer in turn."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply residual connection to any sublayer with the same size.", "response": "def forward(self, x: torch.Tensor, sublayer: Callable[[torch.Tensor], torch.Tensor]) -> torch.Tensor:\n        \"\"\"Apply residual connection to any sublayer with the same size.\"\"\"\n        return x + self.dropout(sublayer(self.norm(x)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfollows Figure 1 ( left for connections.", "response": "def forward(self, x: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n        \"\"\"Follow Figure 1 (left) for connections.\"\"\"\n        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n        return self.sublayer[1](x, self.feed_forward)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nuniform unit scaling of the given tensor.", "response": "def uniform_unit_scaling(tensor: torch.Tensor, nonlinearity: str = \"linear\"):\n    \"\"\"\n    An initaliser which preserves output variance for approximately gaussian\n    distributed inputs. This boils down to initialising layers using a uniform\n    distribution in the range ``(-sqrt(3/dim[0]) * scale, sqrt(3 / dim[0]) * scale)``, where\n    ``dim[0]`` is equal to the input dimension of the parameter and the ``scale``\n    is a constant scaling factor which depends on the non-linearity used.\n\n    See `Random Walk Initialisation for Training Very Deep Feedforward Networks\n    <https://www.semanticscholar.org/paper/Random-Walk-Initialization-for-Training-Very-Deep-Sussillo-Abbott/be9728a0728b6acf7a485225b1e41592176eda0b>`_\n    for more information.\n\n    Parameters\n    ----------\n    tensor : ``torch.Tensor``, required.\n        The tensor to initialise.\n    nonlinearity : ``str``, optional (default = \"linear\")\n        The non-linearity which is performed after the projection that this\n        tensor is involved in. This must be the name of a function contained\n        in the ``torch.nn.functional`` package.\n\n    Returns\n    -------\n    The initialised tensor.\n    \"\"\"\n    size = 1.\n    # Estimate the input size. This won't work perfectly,\n    # but it covers almost all use cases where this initialiser\n    # would be expected to be useful, i.e in large linear and\n    # convolutional layers, as the last dimension will almost\n    # always be the output size.\n    for dimension in list(tensor.size())[:-1]:\n        size *= dimension\n\n    activation_scaling = torch.nn.init.calculate_gain(nonlinearity, tensor)\n    max_value = math.sqrt(3 / size) * activation_scaling\n\n    return tensor.data.uniform_(-max_value, max_value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef block_orthogonal(tensor: torch.Tensor,\n                     split_sizes: List[int],\n                     gain: float = 1.0) -> None:\n    \"\"\"\n    An initializer which allows initializing model parameters in \"blocks\". This is helpful\n    in the case of recurrent models which use multiple gates applied to linear projections,\n    which can be computed efficiently if they are concatenated together. However, they are\n    separate parameters which should be initialized independently.\n\n    Parameters\n    ----------\n    tensor : ``torch.Tensor``, required.\n        A tensor to initialize.\n    split_sizes : List[int], required.\n        A list of length ``tensor.ndim()`` specifying the size of the\n        blocks along that particular dimension. E.g. ``[10, 20]`` would\n        result in the tensor being split into chunks of size 10 along the\n        first dimension and 20 along the second.\n    gain : float, optional (default = 1.0)\n        The gain (scaling) applied to the orthogonal initialization.\n    \"\"\"\n    data = tensor.data\n    sizes = list(tensor.size())\n    if any([a % b != 0 for a, b in zip(sizes, split_sizes)]):\n        raise ConfigurationError(\"tensor dimensions must be divisible by their respective \"\n                                 \"split_sizes. Found size: {} and split_sizes: {}\".format(sizes, split_sizes))\n    indexes = [list(range(0, max_size, split))\n               for max_size, split in zip(sizes, split_sizes)]\n    # Iterate over all possible blocks within the tensor.\n    for block_start_indices in itertools.product(*indexes):\n        # A list of tuples containing the index to start at for this block\n        # and the appropriate step size (i.e split_size[i] for dimension i).\n        index_and_step_tuples = zip(block_start_indices, split_sizes)\n        # This is a tuple of slices corresponding to:\n        # tensor[index: index + step_size, ...]. This is\n        # required because we could have an arbitrary number\n        # of dimensions. The actual slices we need are the\n        # start_index: start_index + step for each dimension in the tensor.\n        block_slice = tuple([slice(start_index, start_index + step)\n                             for start_index, step in index_and_step_tuples])\n        data[block_slice] = torch.nn.init.orthogonal_(tensor[block_slice].contiguous(), gain=gain)", "response": "A function to create a block - orthogonal model from a tensor."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize the biases of the forget gate to 1 and all other gates to 0.", "response": "def lstm_hidden_bias(tensor: torch.Tensor) -> None:\n    \"\"\"\n    Initialize the biases of the forget gate to 1, and all other gates to 0,\n    following Jozefowicz et al., An Empirical Exploration of Recurrent Network Architectures\n    \"\"\"\n    # gates are (b_hi|b_hf|b_hg|b_ho) of shape (4*hidden_size)\n    tensor.data.zero_()\n    hidden_size = tensor.shape[0] // 4\n    tensor.data[hidden_size:(2 * hidden_size)] = 1.0"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_params(cls, params: List[Tuple[str, Params]] = None) -> \"InitializerApplicator\":\n        # pylint: disable=arguments-differ\n        params = params or []\n        is_prevent = lambda item: item == \"prevent\" or item == {\"type\": \"prevent\"}\n        prevent_regexes = [param[0] for param in params if is_prevent(param[1])]\n        params = [param for param in params if param[1] if not is_prevent(param[1])]\n        initializers = [(name, Initializer.from_params(init_params)) for name, init_params in params]\n        return InitializerApplicator(initializers, prevent_regexes)", "response": "Converts a list of parameters into an InitializerApplicator."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_from_file(cls, filename: str, question: List[Token]) -> 'TableQuestionKnowledgeGraph':\n        return cls.read_from_lines(open(filename).readlines(), question)", "response": "Reads the contents of a file into a TableQuestionKnowledgeGraph."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the object from the JSON format.", "response": "def read_from_json(cls, json_object: Dict[str, Any]) -> 'TableQuestionKnowledgeGraph':\n        \"\"\"\n        We read tables formatted as JSON objects (dicts) here. This is useful when you are reading\n        data from a demo. The expected format is::\n\n            {\"question\": [token1, token2, ...],\n             \"columns\": [column1, column2, ...],\n             \"cells\": [[row1_cell1, row1_cell2, ...],\n                       [row2_cell1, row2_cell2, ...],\n                       ... ]}\n        \"\"\"\n        entity_text: Dict[str, str] = {}\n        neighbors: DefaultDict[str, List[str]] = defaultdict(list)\n\n        # Getting number entities first.  Number entities don't have any neighbors, and their\n        # \"entity text\" is the text from the question that evoked the number.\n        question_tokens = json_object['question']\n        for number, number_text in cls._get_numbers_from_tokens(question_tokens):\n            entity_text[number] = number_text\n            neighbors[number] = []\n        for default_number in DEFAULT_NUMBERS:\n            if default_number not in neighbors:\n                neighbors[default_number] = []\n                entity_text[default_number] = default_number\n\n        # Following Sempre's convention for naming columns.  Sempre gives columns unique names when\n        # columns normalize to a collision, so we keep track of these.  We do not give cell text\n        # unique names, however, as `fb:cell.x` is actually a function that returns all cells that\n        # have text that normalizes to \"x\".\n        column_ids = []\n        columns: Dict[str, int] = {}\n        for column_string in json_object['columns']:\n            column_string = column_string.replace('\\\\n', '\\n')\n            normalized_string = f'fb:row.row.{cls._normalize_string(column_string)}'\n            if normalized_string in columns:\n                columns[normalized_string] += 1\n                normalized_string = f'{normalized_string}_{columns[normalized_string]}'\n            columns[normalized_string] = 1\n            column_ids.append(normalized_string)\n            entity_text[normalized_string] = column_string\n\n        # Stores cell text to cell name, making sure that unique text maps to a unique name.\n        cell_id_mapping: Dict[str, str] = {}\n        column_cells: List[List[str]] = [[] for _ in columns]\n        for row_index, row_cells in enumerate(json_object['cells']):\n            assert len(columns) == len(row_cells), (\"Invalid format. Row %d has %d cells, but header has %d\"\n                                                    \" columns\" % (row_index, len(row_cells), len(columns)))\n            # Following Sempre's convention for naming cells.\n            row_cell_ids = []\n            for column_index, cell_string in enumerate(row_cells):\n                cell_string = cell_string.replace('\\\\n', '\\n')\n                column_cells[column_index].append(cell_string)\n                if cell_string in cell_id_mapping:\n                    normalized_string = cell_id_mapping[cell_string]\n                else:\n                    base_normalized_string = f'fb:cell.{cls._normalize_string(cell_string)}'\n                    normalized_string = base_normalized_string\n                    attempt_number = 1\n                    while normalized_string in cell_id_mapping.values():\n                        attempt_number += 1\n                        normalized_string = f\"{base_normalized_string}_{attempt_number}\"\n                    cell_id_mapping[cell_string] = normalized_string\n                row_cell_ids.append(normalized_string)\n                entity_text[normalized_string] = cell_string\n            for column_id, cell_id in zip(column_ids, row_cell_ids):\n                neighbors[column_id].append(cell_id)\n                neighbors[cell_id].append(column_id)\n\n        for column in column_cells:\n            if cls._should_split_column_cells(column):\n                for cell_string in column:\n                    for part_entity, part_string in cls._get_cell_parts(cell_string):\n                        neighbors[part_entity] = []\n                        entity_text[part_entity] = part_string\n        return cls(set(neighbors.keys()), dict(neighbors), entity_text, question_tokens)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a list of tokens return a list of tuples where each tuple is the number and the text of the next token.", "response": "def _get_numbers_from_tokens(tokens: List[Token]) -> List[Tuple[str, str]]:\n        \"\"\"\n        Finds numbers in the input tokens and returns them as strings.  We do some simple heuristic\n        number recognition, finding ordinals and cardinals expressed as text (\"one\", \"first\",\n        etc.), as well as numerals (\"7th\", \"3rd\"), months (mapping \"july\" to 7), and units\n        (\"1ghz\").\n\n        We also handle year ranges expressed as decade or centuries (\"1800s\" or \"1950s\"), adding\n        the endpoints of the range as possible numbers to generate.\n\n        We return a list of tuples, where each tuple is the (number_string, token_text) for a\n        number found in the input tokens.\n        \"\"\"\n        numbers = []\n        for i, token in enumerate(tokens):\n            number: Union[int, float] = None\n            token_text = token.text\n            text = token.text.replace(',', '').lower()\n            if text in NUMBER_WORDS:\n                number = NUMBER_WORDS[text]\n\n            magnitude = 1\n            if i < len(tokens) - 1:\n                next_token = tokens[i + 1].text.lower()\n                if next_token in ORDER_OF_MAGNITUDE_WORDS:\n                    magnitude = ORDER_OF_MAGNITUDE_WORDS[next_token]\n                    token_text += ' ' + tokens[i + 1].text\n\n            is_range = False\n            if len(text) > 1 and text[-1] == 's' and text[-2] == '0':\n                is_range = True\n                text = text[:-1]\n\n            # We strip out any non-digit characters, to capture things like '7th', or '1ghz'.  The\n            # way we're doing this could lead to false positives for something like '1e2', but\n            # we'll take that risk.  It shouldn't be a big deal.\n            text = ''.join(text[i] for i, char in enumerate(text) if char in NUMBER_CHARACTERS)\n\n            try:\n                # We'll use a check for float(text) to find numbers, because text.isdigit() doesn't\n                # catch things like \"-3\" or \"0.07\".\n                number = float(text)\n            except ValueError:\n                pass\n\n            if number is not None:\n                number = number * magnitude\n                if '.' in text:\n                    number_string = '%.3f' % number\n                else:\n                    number_string = '%d' % number\n                numbers.append((number_string, token_text))\n                if is_range:\n                    # TODO(mattg): both numbers in the range will have the same text, and so the\n                    # linking score won't have any way to differentiate them...  We should figure\n                    # out a better way to handle this.\n                    num_zeros = 1\n                    while text[-(num_zeros + 1)] == '0':\n                        num_zeros += 1\n                    numbers.append((str(int(number + 10 ** num_zeros)), token_text))\n        return numbers"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_cell_parts(cls, cell_text: str) -> List[Tuple[str, str]]:\n        parts = []\n        for part_text in cls.cell_part_regex.split(cell_text):\n            part_text = part_text.strip()\n            part_entity = f'fb:part.{cls._normalize_string(part_text)}'\n            parts.append((part_entity, part_text))\n        return parts", "response": "Splits a cell into parts and returns the parts of the cell."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn true if there is any cell in this column that can be split.", "response": "def _should_split_column_cells(cls, column_cells: List[str]) -> bool:\n        \"\"\"\n        Returns true if there is any cell in this column that can be split.\n        \"\"\"\n        return any(cls._should_split_cell(cell_text) for cell_text in column_cells)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _should_split_cell(cls, cell_text: str) -> bool:\n        if ', ' in cell_text or '\\n' in cell_text or '/' in cell_text:\n            return True\n        return False", "response": "Checks whether the cell should be split."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_linked_agenda_items(self) -> List[str]:\n        agenda_items: List[str] = []\n        for entity in self._get_longest_span_matching_entities():\n            agenda_items.append(entity)\n            # If the entity is a cell, we need to add the column to the agenda as well,\n            # because the answer most likely involves getting the row with the cell.\n            if 'fb:cell' in entity:\n                agenda_items.append(self.neighbors[entity][0])\n        return agenda_items", "response": "Returns entities that can be linked to spans in the question that should be in the agenda."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main(inp_fn: str,\n         domain: str,\n         out_fn: str) -> None:\n    \"\"\"\n    inp_fn: str, required.\n       Path to file from which to read Open IE extractions in Open IE4's format.\n    domain: str, required.\n       Domain to be used when writing CoNLL format.\n    out_fn: str, required.\n       Path to file to which to write the CoNLL format Open IE extractions.\n    \"\"\"\n    with open(out_fn, 'w') as fout:\n        for sent_ls in read(inp_fn):\n            fout.write(\"{}\\n\\n\".format('\\n'.join(['\\t'.join(map(str,\n                                                                pad_line_to_ontonotes(line,\n                                                                                      domain)))\n                                                  for line\n                                                  in convert_sent_to_conll(sent_ls)])))", "response": "This function is used to convert the input file to CoNLL format."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef element_from_span(span: List[int],\n                      span_type: str) -> Element:\n    \"\"\"\n    Return an Element from span (list of spacy toks)\n    \"\"\"\n    return Element(span_type,\n                   [span[0].idx,\n                    span[-1].idx + len(span[-1])],\n                   ' '.join(map(str, span)))", "response": "Return an Element from a list of spacy toks"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nensures single word predicate by adding before - predicate and after - predicate arguments.", "response": "def split_predicate(ex: Extraction) -> Extraction:\n    \"\"\"\n    Ensure single word predicate\n    by adding \"before-predicate\" and \"after-predicate\"\n    arguments.\n    \"\"\"\n    rel_toks = ex.toks[char_to_word_index(ex.rel.span[0], ex.sent) \\\n                       : char_to_word_index(ex.rel.span[1], ex.sent) + 1]\n    if not rel_toks:\n        return ex\n\n    verb_inds = [tok_ind for (tok_ind, tok)\n                 in enumerate(rel_toks)\n                 if tok.tag_.startswith('VB')]\n\n    last_verb_ind = verb_inds[-1] if verb_inds \\\n                    else (len(rel_toks) - 1)\n\n    rel_parts = [element_from_span([rel_toks[last_verb_ind]],\n                                   'V')]\n\n    before_verb = rel_toks[ : last_verb_ind]\n    after_verb = rel_toks[last_verb_ind + 1 : ]\n\n    if before_verb:\n        rel_parts.append(element_from_span(before_verb, \"BV\"))\n\n    if after_verb:\n        rel_parts.append(element_from_span(after_verb, \"AV\"))\n\n    return Extraction(ex.sent, ex.toks, ex.arg1, rel_parts, ex.args2, ex.confidence)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extraction_to_conll(ex: Extraction) -> List[str]:\n    ex = split_predicate(ex)\n    toks = ex.sent.split(' ')\n    ret = ['*'] * len(toks)\n    args = [ex.arg1] + ex.args2\n    rels_and_args = [(\"ARG{}\".format(arg_ind), arg)\n                     for arg_ind, arg in enumerate(args)] + \\\n                         [(rel_part.elem_type, rel_part)\n                          for rel_part\n                          in ex.rel]\n\n    for rel, arg in rels_and_args:\n        # Add brackets\n        cur_start_ind = char_to_word_index(arg.span[0],\n                                           ex.sent)\n        cur_end_ind = char_to_word_index(arg.span[1],\n                                         ex.sent)\n        ret[cur_start_ind] = \"({}{}\".format(rel, ret[cur_start_ind])\n        ret[cur_end_ind] += ')'\n    return ret", "response": "Converts an extraction to a list of conll representation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninterpreting a list of text spans into a single integer tuple.", "response": "def interpret_span(text_spans: str) -> List[int]:\n    \"\"\"\n    Return an integer tuple from\n    textual representation of closed / open spans.\n    \"\"\"\n    m = regex.match(\"^(?:(?:([\\(\\[]\\d+, \\d+[\\)\\]])|({\\d+}))[,]?\\s*)+$\",\n                    text_spans)\n\n    spans = m.captures(1) + m.captures(2)\n\n    int_spans = []\n    for span in spans:\n        ints = list(map(int,\n                        span[1: -1].split(',')))\n        if span[0] == '(':\n            ints[0] += 1\n        if span[-1] == ']':\n            ints[1] += 1\n        if span.startswith('{'):\n            assert(len(ints) == 1)\n            ints.append(ints[0] + 1)\n\n        assert(len(ints) == 2)\n\n        int_spans.append(ints)\n\n    # Merge consecutive spans\n    ret = []\n    cur_span = int_spans[0]\n    for (start, end) in int_spans[1:]:\n        if start - 1 == cur_span[-1]:\n            cur_span = (cur_span[0],\n                        end)\n        else:\n            ret.append(cur_span)\n            cur_span = (start, end)\n\n    if (not ret) or (cur_span != ret[-1]):\n        ret.append(cur_span)\n\n    return ret[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef interpret_element(element_type: str, text: str, span: str) -> Element:\n    return Element(element_type,\n                   interpret_span(span),\n                   text)", "response": "Construct an Element instance from regexp\n    groups."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_element(raw_element: str) -> List[Element]:\n    elements = [regex.match(\"^(([a-zA-Z]+)\\(([^;]+),List\\(([^;]*)\\)\\))$\",\n                            elem.lstrip().rstrip())\n                for elem\n                in raw_element.split(';')]\n    return [interpret_element(*elem.groups()[1:])\n            for elem in elements\n            if elem]", "response": "Parses a raw element into text and indices."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a list of extractions for a single sentence - convert it to conll representation.", "response": "def convert_sent_to_conll(sent_ls: List[Extraction]):\n    \"\"\"\n    Given a list of extractions for a single sentence -\n    convert it to conll representation.\n    \"\"\"\n    # Sanity check - make sure all extractions are on the same sentence\n    assert(len(set([ex.sent for ex in sent_ls])) == 1)\n    toks = sent_ls[0].sent.split(' ')\n\n    return safe_zip(*[range(len(toks)),\n                      toks] + \\\n                    [extraction_to_conll(ex)\n                     for ex in sent_ls])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npadding a line to conform to ontonotes representation.", "response": "def pad_line_to_ontonotes(line, domain) -> List[str]:\n    \"\"\"\n    Pad line to conform to ontonotes representation.\n    \"\"\"\n    word_ind, word = line[ : 2]\n    pos = 'XX'\n    oie_tags = line[2 : ]\n    line_num = 0\n    parse = \"-\"\n    lemma = \"-\"\n    return [domain, line_num, word_ind, word, pos, parse, lemma, '-',\\\n            '-', '-', '*'] + list(oie_tags) + ['-', ]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert_sent_dict_to_conll(sent_dic, domain) -> str:\n    return '\\n\\n'.join(['\\n'.join(['\\t'.join(map(str, pad_line_to_ontonotes(line, domain)))\n                                   for line in convert_sent_to_conll(sent_ls)])\n                        for sent_ls\n                        in sent_dic.iteritems()])", "response": "Converts a dictionary from sentence -> extractions to CoNLL representation."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a base64 encoded base64 encoded data deaggregate if it was packed using the Kinesis Producer Library and return a list of all the records that were not aggregated.", "response": "def deaggregate_record(decoded_data):\n    '''Given a Kinesis record data that is decoded, deaggregate if it was packed using the\n    Kinesis Producer Library into individual records.  This method will be a no-op for any\n    records that are not aggregated (but will still return them).\n    \n    decoded_data - the base64 decoded data that comprises either the KPL aggregated data, or the Kinesis payload directly.    \n    return value - A list of deaggregated Kinesis record payloads (if the data is not aggregated, we just return a list with the payload alone) \n    '''\n    \n    is_aggregated = True\n    \n    #Verify the magic header\n    data_magic = None\n    if(len(decoded_data) >= len(aws_kinesis_agg.MAGIC)):\n        data_magic = decoded_data[:len(aws_kinesis_agg.MAGIC)]\n    else:\n        print(\"Not aggregated\") \n        is_aggregated = False\n    \n    decoded_data_no_magic = decoded_data[len(aws_kinesis_agg.MAGIC):]\n    \n    if aws_kinesis_agg.MAGIC != data_magic or len(decoded_data_no_magic) <= aws_kinesis_agg.DIGEST_SIZE:\n        is_aggregated = False\n        \n    if is_aggregated:            \n        \n        #verify the MD5 digest\n        message_digest = decoded_data_no_magic[-aws_kinesis_agg.DIGEST_SIZE:]\n        message_data = decoded_data_no_magic[:-aws_kinesis_agg.DIGEST_SIZE]\n        \n        md5_calc = md5.new()\n        md5_calc.update(message_data)\n        calculated_digest = md5_calc.digest()\n        \n        if message_digest != calculated_digest:            \n            return [decoded_data]            \n        else:                            \n            #Extract the protobuf message\n            try:    \n                ar = kpl_pb2.AggregatedRecord()\n                ar.ParseFromString(message_data)\n                \n                return [mr.data for mr in ar.records]\n            except BaseException as e:\n                raise e                   \n    else:\n        return [decoded_data]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a S3 Uri into a dict of the Bucket Key and VersionId.", "response": "def parse_s3_uri(uri):\n    \"\"\"Parses a S3 Uri into a dictionary of the Bucket, Key, and VersionId\n\n    :return: a BodyS3Location dict or None if not an S3 Uri\n    :rtype: dict\n    \"\"\"\n    if not isinstance(uri, string_types):\n        return None\n\n    url = urlparse(uri)\n    query = parse_qs(url.query)\n\n    if url.scheme == 's3' and url.netloc and url.path:\n        s3_pointer = {\n            'Bucket': url.netloc,\n            'Key': url.path.lstrip('/')\n        }\n        if 'versionId' in query and len(query['versionId']) == 1:\n            s3_pointer['Version'] = query['versionId'][0]\n        return s3_pointer\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_s3_uri(code_dict):\n\n    try:\n        uri = \"s3://{bucket}/{key}\".format(bucket=code_dict[\"S3Bucket\"], key=code_dict[\"S3Key\"])\n        version = code_dict.get(\"S3ObjectVersion\", None)\n    except (TypeError, AttributeError):\n        raise TypeError(\"Code location should be a dictionary\")\n\n    if version:\n        uri += \"?versionId=\" + version\n\n    return uri", "response": "Constructs a S3 URI string from a dictionary containing Lambda function Code S3 location of the form s3://bucket?key?versionId = version"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconstructs a Lambda Code or Content object from the SAM Location Uri or string.", "response": "def construct_s3_location_object(location_uri, logical_id, property_name):\n    \"\"\"Constructs a Lambda `Code` or `Content` property, from the SAM `CodeUri` or `ContentUri` property.\n    This follows the current scheme for Lambda Functions and LayerVersions.\n\n    :param dict or string location_uri: s3 location dict or string\n    :param string logical_id: logical_id of the resource calling this function\n    :param string property_name: name of the property which is used as an input to this function.\n    :returns: a Code dict, containing the S3 Bucket, Key, and Version of the Lambda layer code\n    :rtype: dict\n    \"\"\"\n    if isinstance(location_uri, dict):\n        if not location_uri.get(\"Bucket\") or not location_uri.get(\"Key\"):\n            # location_uri is a dictionary but does not contain Bucket or Key property\n            raise InvalidResourceException(logical_id,\n                                           \"'{}' requires Bucket and Key properties to be \"\n                                           \"specified\".format(property_name))\n\n        s3_pointer = location_uri\n\n    else:\n        # location_uri is NOT a dictionary. Parse it as a string\n        s3_pointer = parse_s3_uri(location_uri)\n\n        if s3_pointer is None:\n            raise InvalidResourceException(logical_id,\n                                           '\\'{}\\' is not a valid S3 Uri of the form '\n                                           '\"s3://bucket/key\" with optional versionId query '\n                                           'parameter.'.format(property_name))\n\n    code = {\n        'S3Bucket': s3_pointer['Bucket'],\n        'S3Key': s3_pointer['Key']\n    }\n    if 'Version' in s3_pointer:\n        code['S3ObjectVersion'] = s3_pointer['Version']\n    return code"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of policies from the resource properties.", "response": "def _get_policies(self, resource_properties):\n        \"\"\"\n        Returns a list of policies from the resource properties. This method knows how to interpret and handle\n        polymorphic nature of the policies property.\n\n        Policies can be one of the following:\n\n            * Managed policy name: string\n            * List of managed policy names: list of strings\n            * IAM Policy document: dict containing Statement key\n            * List of IAM Policy documents: list of IAM Policy Document\n            * Policy Template: dict with only one key where key is in list of supported policy template names\n            * List of Policy Templates: list of Policy Template\n\n\n        :param dict resource_properties: Dictionary of resource properties containing the policies property.\n            It is assumed that this is already a dictionary and contains policies key.\n        :return list of PolicyEntry: List of policies, where each item is an instance of named tuple `PolicyEntry`\n        \"\"\"\n\n        policies = None\n\n        if self._contains_policies(resource_properties):\n            policies = resource_properties[self.POLICIES_PROPERTY_NAME]\n\n        if not policies:\n            # Policies is None or empty\n            return []\n\n        if not isinstance(policies, list):\n            # Just a single entry. Make it into a list of convenience\n            policies = [policies]\n\n        result = []\n        for policy in policies:\n            policy_type = self._get_type(policy)\n            entry = PolicyEntry(data=policy, type=policy_type)\n            result.append(entry)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if the resource contains policies.", "response": "def _contains_policies(self, resource_properties):\n        \"\"\"\n        Is there policies data in this resource?\n\n        :param dict resource_properties: Properties of the resource\n        :return: True if we can process this resource. False, otherwise\n        \"\"\"\n        return resource_properties is not None \\\n            and isinstance(resource_properties, dict) \\\n            and self.POLICIES_PROPERTY_NAME in resource_properties"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the type of the given policy.", "response": "def _get_type(self, policy):\n        \"\"\"\n        Returns the type of the given policy\n\n        :param string or dict policy: Policy data\n        :return PolicyTypes: Type of the given policy. None, if type could not be inferred\n        \"\"\"\n\n        # Must handle intrinsic functions. Policy could be a primitive type or an intrinsic function\n\n        # Managed policies are either string or an intrinsic function that resolves to a string\n        if isinstance(policy, string_types) or is_instrinsic(policy):\n            return PolicyTypes.MANAGED_POLICY\n\n        # Policy statement is a dictionary with the key \"Statement\" in it\n        if isinstance(policy, dict) and \"Statement\" in policy:\n            return PolicyTypes.POLICY_STATEMENT\n\n        # This could be a policy template then.\n        if self._is_policy_template(policy):\n            return PolicyTypes.POLICY_TEMPLATE\n\n        # Nothing matches. Don't take opinions on how to handle it. Instead just set the appropriate type.\n        return PolicyTypes.UNKNOWN"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbeing the given policy data a policy template?", "response": "def _is_policy_template(self, policy):\n        \"\"\"\n        Is the given policy data a policy template? Policy templates is a dictionary with one key which is the name\n        of the template.\n\n        :param dict policy: Policy data\n        :return: True, if this is a policy template. False if it is not\n        \"\"\"\n\n        return self._policy_template_processor is not None and \\\n            isinstance(policy, dict) and \\\n            len(policy) == 1 and \\\n            self._policy_template_processor.has(list(policy.keys())[0]) is True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_thing_shadow(self, **kwargs):\n        thing_name = self._get_required_parameter('thingName', **kwargs)\n        payload = b''\n\n        return self._shadow_op('get', thing_name, payload)", "response": "r Returns the current shadow state of a thing."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef merge(self, resource_type, resource_properties):\n\n        if resource_type not in self.template_globals:\n            # Nothing to do. Return the template unmodified\n            return resource_properties\n\n        global_props = self.template_globals[resource_type]\n\n        return global_props.merge(resource_properties)", "response": "Adds global properties to the resource if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake a SAM template as input and parses the Globals section containing all properties and stores them in a dictionary that can be used to quickly identify properties for the current resource type.", "response": "def _parse(self, globals_dict):\n        \"\"\"\n        Takes a SAM template as input and parses the Globals section\n\n        :param globals_dict: Dictionary representation of the Globals section\n        :return: Processed globals dictionary which can be used to quickly identify properties to merge\n        :raises: InvalidResourceException if the input contains properties that we don't support\n        \"\"\"\n\n        globals = {}\n\n        if not isinstance(globals_dict, dict):\n            raise InvalidGlobalsSectionException(self._KEYWORD,\n                                                 \"It must be a non-empty dictionary\".format(self._KEYWORD))\n\n        for section_name, properties in globals_dict.items():\n            resource_type = self._make_resource_type(section_name)\n\n            if resource_type not in self.supported_properties:\n                raise InvalidGlobalsSectionException(self._KEYWORD,\n                                                     \"'{section}' is not supported. \"\n                                                     \"Must be one of the following values - {supported}\"\n                                                     .format(section=section_name,\n                                                             supported=self.supported_resource_section_names))\n\n            if not isinstance(properties, dict):\n                raise InvalidGlobalsSectionException(self._KEYWORD, \"Value of ${section} must be a dictionary\")\n\n            for key, value in properties.items():\n                supported = self.supported_properties[resource_type]\n                if key not in supported:\n                    raise InvalidGlobalsSectionException(self._KEYWORD,\n                                                         \"'{key}' is not a supported property of '{section}'. \"\n                                                         \"Must be one of the following values - {supported}\"\n                                                         .format(key=key, section=section_name, supported=supported))\n\n            # Store all Global properties in a map with key being the AWS::Serverless::* resource type\n            globals[resource_type] = GlobalProperties(properties)\n\n        return globals"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _do_merge(self, global_value, local_value):\n\n        token_global = self._token_of(global_value)\n        token_local = self._token_of(local_value)\n\n        # The following statements codify the rules explained in the doctring above\n        if token_global != token_local:\n            return self._prefer_local(global_value, local_value)\n\n        elif self.TOKEN.PRIMITIVE == token_global == token_local:\n            return self._prefer_local(global_value, local_value)\n\n        elif self.TOKEN.DICT == token_global == token_local:\n            return self._merge_dict(global_value, local_value)\n\n        elif self.TOKEN.LIST == token_global == token_local:\n            return self._merge_lists(global_value, local_value)\n\n        else:\n            raise TypeError(\n                \"Unsupported type of objects. GlobalType={}, LocalType={}\".format(token_global, token_local))", "response": "This method performs the actual merge operation for the given values."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _merge_dict(self, global_dict, local_dict):\n\n        # Local has higher priority than global. So iterate over local dict and merge into global if keys are overridden\n        global_dict = global_dict.copy()\n\n        for key in local_dict.keys():\n\n            if key in global_dict:\n                # Both local & global contains the same key. Let's do a merge.\n                global_dict[key] = self._do_merge(global_dict[key], local_dict[key])\n\n            else:\n                # Key is not in globals, just in local. Copy it over\n                global_dict[key] = local_dict[key]\n\n        return global_dict", "response": "Merges the two dictionaries together and returns a new dictionary with the values shallow copied\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _token_of(self, input):\n\n        if isinstance(input, dict):\n\n            # Intrinsic functions are always dicts\n            if is_intrinsics(input):\n                # Intrinsic functions are handled *exactly* like a primitive type because\n                # they resolve to a primitive type when creating a stack with CloudFormation\n                return self.TOKEN.PRIMITIVE\n            else:\n                return self.TOKEN.DICT\n\n        elif isinstance(input, list):\n            return self.TOKEN.LIST\n\n        else:\n            return self.TOKEN.PRIMITIVE", "response": "Returns the token type of the input."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates SAM template dictionary", "response": "def validate(template_dict, schema=None):\n        \"\"\"\n        Is this a valid SAM template dictionary\n\n        :param dict template_dict: Data to be validated\n        :param dict schema: Optional, dictionary containing JSON Schema representing SAM template\n        :return: Empty string if there are no validation errors in template\n        \"\"\"\n\n        if not schema:\n            schema = SamTemplateValidator._read_schema()\n\n        validation_errors = \"\"\n\n        try:\n            jsonschema.validate(template_dict, schema)\n        except ValidationError as ex:\n            # Stringifying the exception will give us useful error message\n            validation_errors = str(ex)\n            # Swallowing expected exception here as our caller is expecting validation errors and\n            # not the valiation exception itself\n            pass\n\n        return validation_errors"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_car_price(location, days, age, car_type):\n\n    car_types = ['economy', 'standard', 'midsize', 'full size', 'minivan', 'luxury']\n    base_location_cost = 0\n    for i in range(len(location)):\n        base_location_cost += ord(location.lower()[i]) - 97\n\n    age_multiplier = 1.10 if age < 25 else 1\n    # Select economy is car_type is not found\n    if car_type not in car_types:\n        car_type = car_types[0]\n\n    return days * ((100 + base_location_cost) + ((car_types.index(car_type) * 50) * age_multiplier))", "response": "Generates a number within a reasonable range that might be expected for a flight."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_hotel_price(location, nights, room_type):\n\n    room_types = ['queen', 'king', 'deluxe']\n    cost_of_living = 0\n    for i in range(len(location)):\n        cost_of_living += ord(location.lower()[i]) - 97\n\n    return nights * (100 + cost_of_living + (100 + room_types.index(room_type.lower())))", "response": "Generates a number that might be expected for a pair of location and roomType."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef book_hotel(intent_request):\n\n    location = try_ex(lambda: intent_request['currentIntent']['slots']['Location'])\n    checkin_date = try_ex(lambda: intent_request['currentIntent']['slots']['CheckInDate'])\n    nights = safe_int(try_ex(lambda: intent_request['currentIntent']['slots']['Nights']))\n\n    room_type = try_ex(lambda: intent_request['currentIntent']['slots']['RoomType'])\n    session_attributes = intent_request['sessionAttributes']\n\n    # Load confirmation history and track the current reservation.\n    reservation = json.dumps({\n        'ReservationType': 'Hotel',\n        'Location': location,\n        'RoomType': room_type,\n        'CheckInDate': checkin_date,\n        'Nights': nights\n    })\n\n    session_attributes['currentReservation'] = reservation\n\n    if intent_request['invocationSource'] == 'DialogCodeHook':\n        # Validate any slots which have been specified.  If any are invalid, re-elicit for their value\n        validation_result = validate_hotel(intent_request['currentIntent']['slots'])\n        if not validation_result['isValid']:\n            slots = intent_request['currentIntent']['slots']\n            slots[validation_result['violatedSlot']] = None\n\n            return elicit_slot(\n                session_attributes,\n                intent_request['currentIntent']['name'],\n                slots,\n                validation_result['violatedSlot'],\n                validation_result['message']\n            )\n\n        # Otherwise, let native DM rules determine how to elicit for slots and prompt for confirmation.  Pass price\n        # back in sessionAttributes once it can be calculated; otherwise clear any setting from sessionAttributes.\n        if location and checkin_date and nights and room_type:\n            # The price of the hotel has yet to be confirmed.\n            price = generate_hotel_price(location, nights, room_type)\n            session_attributes['currentReservationPrice'] = price\n        else:\n            try_ex(lambda: session_attributes.pop('currentReservationPrice'))\n\n        session_attributes['currentReservation'] = reservation\n        return delegate(session_attributes, intent_request['currentIntent']['slots'])\n\n    # Booking the hotel.  In a real application, this would likely involve a call to a backend service.\n    logger.debug('bookHotel under={}'.format(reservation))\n\n    try_ex(lambda: session_attributes.pop('currentReservationPrice'))\n    try_ex(lambda: session_attributes.pop('currentReservation'))\n    session_attributes['lastConfirmedReservation'] = reservation\n\n    return close(\n        session_attributes,\n        'Fulfilled',\n        {\n            'contentType': 'PlainText',\n            'content': 'Thanks, I have placed your reservation.   Please let me know if you would like to book a car '\n                       'rental, or another hotel.'\n        }\n    )", "response": "This function books a hotel."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbooking a car in the current context.", "response": "def book_car(intent_request):\n    \"\"\"\n    Performs dialog management and fulfillment for booking a car.\n\n    Beyond fulfillment, the implementation for this intent demonstrates the following:\n    1) Use of elicitSlot in slot validation and re-prompting\n    2) Use of sessionAttributes to pass information that can be used to guide conversation\n    \"\"\"\n    slots = intent_request['currentIntent']['slots']\n    pickup_city = slots['PickUpCity']\n    pickup_date = slots['PickUpDate']\n    return_date = slots['ReturnDate']\n    driver_age = slots['DriverAge']\n    car_type = slots['CarType']\n    confirmation_status = intent_request['currentIntent']['confirmationStatus']\n    session_attributes = intent_request['sessionAttributes']\n    last_confirmed_reservation = try_ex(lambda: session_attributes['lastConfirmedReservation'])\n    if last_confirmed_reservation:\n        last_confirmed_reservation = json.loads(last_confirmed_reservation)\n    confirmation_context = try_ex(lambda: session_attributes['confirmationContext'])\n\n    # Load confirmation history and track the current reservation.\n    reservation = json.dumps({\n        'ReservationType': 'Car',\n        'PickUpCity': pickup_city,\n        'PickUpDate': pickup_date,\n        'ReturnDate': return_date,\n        'CarType': car_type\n    })\n    session_attributes['currentReservation'] = reservation\n\n    if pickup_city and pickup_date and return_date and driver_age and car_type:\n        # Generate the price of the car in case it is necessary for future steps.\n        price = generate_car_price(pickup_city, get_day_difference(pickup_date, return_date), driver_age, car_type)\n        session_attributes['currentReservationPrice'] = price\n\n    if intent_request['invocationSource'] == 'DialogCodeHook':\n        # Validate any slots which have been specified.  If any are invalid, re-elicit for their value\n        validation_result = validate_book_car(intent_request['currentIntent']['slots'])\n        if not validation_result['isValid']:\n            slots[validation_result['violatedSlot']] = None\n            return elicit_slot(\n                session_attributes,\n                intent_request['currentIntent']['name'],\n                slots,\n                validation_result['violatedSlot'],\n                validation_result['message']\n            )\n\n        # Determine if the intent (and current slot settings) has been denied.  The messaging will be different\n        # if the user is denying a reservation he initiated or an auto-populated suggestion.\n        if confirmation_status == 'Denied':\n            # Clear out auto-population flag for subsequent turns.\n            try_ex(lambda: session_attributes.pop('confirmationContext'))\n            try_ex(lambda: session_attributes.pop('currentReservation'))\n            if confirmation_context == 'AutoPopulate':\n                return elicit_slot(\n                    session_attributes,\n                    intent_request['currentIntent']['name'],\n                    {\n                        'PickUpCity': None,\n                        'PickUpDate': None,\n                        'ReturnDate': None,\n                        'DriverAge': None,\n                        'CarType': None\n                    },\n                    'PickUpCity',\n                    {\n                        'contentType': 'PlainText',\n                        'content': 'Where would you like to make your car reservation?'\n                    }\n                )\n\n            return delegate(session_attributes, intent_request['currentIntent']['slots'])\n\n        if confirmation_status == 'None':\n            # If we are currently auto-populating but have not gotten confirmation, keep requesting for confirmation.\n            if (not pickup_city and not pickup_date and not return_date and not driver_age and not car_type)\\\n                    or confirmation_context == 'AutoPopulate':\n                if last_confirmed_reservation and try_ex(lambda: last_confirmed_reservation['ReservationType']) == 'Hotel':\n                    # If the user's previous reservation was a hotel - prompt for a rental with\n                    # auto-populated values to match this reservation.\n                    session_attributes['confirmationContext'] = 'AutoPopulate'\n                    return confirm_intent(\n                        session_attributes,\n                        intent_request['currentIntent']['name'],\n                        {\n                            'PickUpCity': last_confirmed_reservation['Location'],\n                            'PickUpDate': last_confirmed_reservation['CheckInDate'],\n                            'ReturnDate': add_days(\n                                last_confirmed_reservation['CheckInDate'], last_confirmed_reservation['Nights']\n                            ),\n                            'CarType': None,\n                            'DriverAge': None\n                        },\n                        {\n                            'contentType': 'PlainText',\n                            'content': 'Is this car rental for your {} night stay in {} on {}?'.format(\n                                last_confirmed_reservation['Nights'],\n                                last_confirmed_reservation['Location'],\n                                last_confirmed_reservation['CheckInDate']\n                            )\n                        }\n                    )\n\n            # Otherwise, let native DM rules determine how to elicit for slots and/or drive confirmation.\n            return delegate(session_attributes, intent_request['currentIntent']['slots'])\n\n        # If confirmation has occurred, continue filling any unfilled slot values or pass to fulfillment.\n        if confirmation_status == 'Confirmed':\n            # Remove confirmationContext from sessionAttributes so it does not confuse future requests\n            try_ex(lambda: session_attributes.pop('confirmationContext'))\n            if confirmation_context == 'AutoPopulate':\n                if not driver_age:\n                    return elicit_slot(\n                        session_attributes,\n                        intent_request['currentIntent']['name'],\n                        intent_request['currentIntent']['slots'],\n                        'DriverAge',\n                        {\n                            'contentType': 'PlainText',\n                            'content': 'How old is the driver of this car rental?'\n                        }\n                    )\n                elif not car_type:\n                    return elicit_slot(\n                        session_attributes,\n                        intent_request['currentIntent']['name'],\n                        intent_request['currentIntent']['slots'],\n                        'CarType',\n                        {\n                            'contentType': 'PlainText',\n                            'content': 'What type of car would you like? Popular models are '\n                                       'economy, midsize, and luxury.'\n                        }\n                    )\n\n            return delegate(session_attributes, intent_request['currentIntent']['slots'])\n\n    # Booking the car.  In a real application, this would likely involve a call to a backend service.\n    logger.debug('bookCar at={}'.format(reservation))\n    del session_attributes['currentReservationPrice']\n    del session_attributes['currentReservation']\n    session_attributes['lastConfirmedReservation'] = reservation\n    return close(\n        session_attributes,\n        'Fulfilled',\n        {\n            'contentType': 'PlainText',\n            'content': 'Thanks, I have placed your reservation.'\n        }\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dispatch(intent_request):\n\n    logger.debug('dispatch userId={}, intentName={}'.format(intent_request['userId'], intent_request['currentIntent']['name']))\n\n    intent_name = intent_request['currentIntent']['name']\n\n    # Dispatch to your bot's intent handlers\n    if intent_name == 'BookHotel':\n        return book_hotel(intent_request)\n    elif intent_name == 'BookCar':\n        return book_car(intent_request)\n\n    raise Exception('Intent with name ' + intent_name + ' not supported')", "response": "Dispatches the intent request to the appropriate handler."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_cloudformation(self, **kwargs):\n        function = kwargs.get('function')\n\n        if not function:\n            raise TypeError(\"Missing required keyword argument: function\")\n\n        resources = []\n\n        lambda_eventsourcemapping = LambdaEventSourceMapping(self.logical_id)\n        resources.append(lambda_eventsourcemapping)\n\n        try:\n            # Name will not be available for Alias resources\n            function_name_or_arn = function.get_runtime_attr(\"name\")\n        except NotImplementedError:\n            function_name_or_arn = function.get_runtime_attr(\"arn\")\n\n        if not self.Stream and not self.Queue:\n            raise InvalidEventException(\n                self.relative_id, \"No Queue (for SQS) or Stream (for Kinesis or DynamoDB) provided.\")\n\n        if self.Stream and not self.StartingPosition:\n            raise InvalidEventException(\n                self.relative_id, \"StartingPosition is required for Kinesis and DynamoDB.\")\n\n        lambda_eventsourcemapping.FunctionName = function_name_or_arn\n        lambda_eventsourcemapping.EventSourceArn = self.Stream or self.Queue\n        lambda_eventsourcemapping.StartingPosition = self.StartingPosition\n        lambda_eventsourcemapping.BatchSize = self.BatchSize\n        lambda_eventsourcemapping.Enabled = self.Enabled\n        if 'Condition' in function.resource_attributes:\n            lambda_eventsourcemapping.set_resource_attribute('Condition', function.resource_attributes['Condition'])\n\n        if 'role' in kwargs:\n            self._link_policy(kwargs['role'])\n\n        return resources", "response": "Returns the Lambda EventSourceMapping to which this pull event corresponds. Adds the appropriate managed\n        policy to the function s execution role."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlink the policy to the Lambda function whose execution role is auto - generated by SAM.", "response": "def _link_policy(self, role):\n        \"\"\"If this source triggers a Lambda function whose execution role is auto-generated by SAM, add the\n        appropriate managed policy to this Role.\n\n        :param model.iam.IAMROle role: the execution role generated for the function\n        \"\"\"\n        policy_arn = self.get_policy_arn()\n        if role is not None and policy_arn not in role.ManagedPolicyArns:\n            role.ManagedPolicyArns.append(policy_arn)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_default_parameter_values(self, sam_template):\n\n        parameter_definition = sam_template.get(\"Parameters\", None)\n        if not parameter_definition or not isinstance(parameter_definition, dict):\n            return self.parameter_values\n\n        for param_name, value in parameter_definition.items():\n            if param_name not in self.parameter_values and isinstance(value, dict) and \"Default\" in value:\n                self.parameter_values[param_name] = value[\"Default\"]", "response": "Method to read default values for the specified parameters and merge them with the user supplied values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd pseudo parameter values that have pseudo parameter in it", "response": "def add_pseudo_parameter_values(self):\n        \"\"\"\n        Add pseudo parameter values\n        :return: parameter values that have pseudo parameter in it\n        \"\"\"\n        if 'AWS::Region' not in self.parameter_values:\n            self.parameter_values['AWS::Region'] = boto3.session.Session().region_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add(self, logical_id, deployment_preference_dict):\n        if logical_id in self._resource_preferences:\n            raise ValueError(\"logical_id {logical_id} previously added to this deployment_preference_collection\".format(\n                logical_id=logical_id))\n\n        self._resource_preferences[logical_id] = DeploymentPreference.from_dict(logical_id, deployment_preference_dict)", "response": "Add this deployment preference to the collection"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef enabled_logical_ids(self):\n        return [logical_id for logical_id, preference in self._resource_preferences.items() if preference.enabled]", "response": "only the logical ids for the deployment preferences in this collection which are enabled\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a CodeDeployDeploymentGroup object for the given function_logical_id.", "response": "def deployment_group(self, function_logical_id):\n        \"\"\"\n        :param function_logical_id: logical_id of the function this deployment group belongs to\n        :return: CodeDeployDeploymentGroup resource\n        \"\"\"\n        deployment_preference = self.get(function_logical_id)\n\n        deployment_group = CodeDeployDeploymentGroup(self.deployment_group_logical_id(function_logical_id))\n\n        if deployment_preference.alarms is not None:\n            deployment_group.AlarmConfiguration = {'Enabled': True,\n                                                   'Alarms': [{'Name': alarm} for alarm in\n                                                              deployment_preference.alarms]}\n\n        deployment_group.ApplicationName = self.codedeploy_application.get_runtime_attr('name')\n        deployment_group.AutoRollbackConfiguration = {'Enabled': True,\n                                                      'Events': ['DEPLOYMENT_FAILURE',\n                                                                 'DEPLOYMENT_STOP_ON_ALARM',\n                                                                 'DEPLOYMENT_STOP_ON_REQUEST']}\n        deployment_group.DeploymentConfigName = fnSub(\"CodeDeployDefault.Lambda${ConfigName}\",\n                                                      {\"ConfigName\": deployment_preference.deployment_type})\n        deployment_group.DeploymentStyle = {'DeploymentType': 'BLUE_GREEN',\n                                            'DeploymentOption': 'WITH_TRAFFIC_CONTROL'}\n\n        deployment_group.ServiceRoleArn = self.codedeploy_iam_role.get_runtime_attr(\"arn\")\n        if deployment_preference.role:\n            deployment_group.ServiceRoleArn = deployment_preference.role\n\n        return deployment_group"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding a welcome response", "response": "def get_welcome_response():\n    \"\"\" If we wanted to initialize the session to have some attributes we could\n    add those here\n    \"\"\"\n\n    session_attributes = {}\n    card_title = \"Welcome\"\n    speech_output = \"Welcome to the Alexa Skills Kit sample. \" \\\n                    \"Please tell me your favorite color by saying, \" \\\n                    \"my favorite color is red\"\n    # If the user either does not reply to the welcome message or says something\n    # that is not understood, they will be prompted again with this text.\n    reprompt_text = \"Please tell me your favorite color by saying, \" \\\n                    \"my favorite color is red.\"\n    should_end_session = False\n    return build_response(session_attributes, build_speechlet_response(\n        card_title, speech_output, reprompt_text, should_end_session))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_color_in_session(intent, session):\n\n    card_title = intent['name']\n    session_attributes = {}\n    should_end_session = False\n\n    if 'Color' in intent['slots']:\n        favorite_color = intent['slots']['Color']['value']\n        session_attributes = create_favorite_color_attributes(favorite_color)\n        speech_output = \"I now know your favorite color is \" + \\\n                        favorite_color + \\\n                        \". You can ask me your favorite color by saying, \" \\\n                        \"what's my favorite color?\"\n        reprompt_text = \"You can ask me your favorite color by saying, \" \\\n                        \"what's my favorite color?\"\n    else:\n        speech_output = \"I'm not sure what your favorite color is. \" \\\n                        \"Please try again.\"\n        reprompt_text = \"I'm not sure what your favorite color is. \" \\\n                        \"You can tell me your favorite color by saying, \" \\\n                        \"my favorite color is red.\"\n    return build_response(session_attributes, build_speechlet_response(\n        card_title, speech_output, reprompt_text, should_end_session))", "response": "Sets the color in the session and prepares the speech to reply to the user."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_intent(intent_request, session):\n\n    print(\"on_intent requestId=\" + intent_request['requestId'] +\n          \", sessionId=\" + session['sessionId'])\n\n    intent = intent_request['intent']\n    intent_name = intent_request['intent']['name']\n\n    # Dispatch to your skill's intent handlers\n    if intent_name == \"MyColorIsIntent\":\n        return set_color_in_session(intent, session)\n    elif intent_name == \"WhatsMyColorIntent\":\n        return get_color_from_session(intent, session)\n    elif intent_name == \"AMAZON.HelpIntent\":\n        return get_welcome_response()\n    elif intent_name == \"AMAZON.CancelIntent\" or intent_name == \"AMAZON.StopIntent\":\n        return handle_session_end_request()\n    else:\n        raise ValueError(\"Invalid intent\")", "response": "Called when the user specifies an intent for this skill"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lambda_handler(event, context):\n    print(\"event.session.application.applicationId=\" +\n          event['session']['application']['applicationId'])\n\n    \"\"\"\n    Uncomment this if statement and populate with your skill's application ID to\n    prevent someone else from configuring a skill that sends requests to this\n    function.\n    \"\"\"\n    # if (event['session']['application']['applicationId'] !=\n    #         \"amzn1.echo-sdk-ams.app.[unique-value-here]\"):\n    #     raise ValueError(\"Invalid Application ID\")\n\n    if event['session']['new']:\n        on_session_started({'requestId': event['request']['requestId']},\n                           event['session'])\n\n    if event['request']['type'] == \"LaunchRequest\":\n        return on_launch(event['request'], event['session'])\n    elif event['request']['type'] == \"IntentRequest\":\n        return on_intent(event['request'], event['session'])\n    elif event['request']['type'] == \"SessionEndedRequest\":\n        return on_session_ended(event['request'], event['session'])", "response": "This function handles the incoming request based on the type of request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate stable LogicalId based on the prefix and data object.", "response": "def gen(self):\n        \"\"\"\n        Generate stable LogicalIds based on the prefix and given data. This method ensures that the logicalId is\n        deterministic and stable based on input prefix & data object. In other words:\n\n            logicalId changes *if and only if* either the `prefix` or `data_obj` changes\n\n        Internally we simply use a SHA1 of the data and append to the prefix to create the logicalId.\n\n        NOTE: LogicalIDs are how CloudFormation identifies a resource. If this ID changes, CFN will delete and\n              create a new resource. This can be catastrophic for most resources. So it is important to be *always*\n              backwards compatible here.\n\n\n        :return: LogicalId that can be used to construct resources\n        :rtype string\n        \"\"\"\n\n        data_hash = self.get_hash()\n        return \"{prefix}{hash}\".format(prefix=self._prefix, hash=data_hash)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_hash(self, length=HASH_LENGTH):\n\n        data_hash = \"\"\n        if not self.data_str:\n            return data_hash\n\n        encoded_data_str = self.data_str\n        if sys.version_info.major == 2:\n            # In Py2, only unicode needs to be encoded.\n            if isinstance(self.data_str, unicode):\n                encoded_data_str = self.data_str.encode('utf-8')\n        else:\n            # data_str should always be unicode on python 3\n            encoded_data_str = self.data_str.encode('utf-8')\n\n        data_hash = hashlib.sha1(encoded_data_str).hexdigest()\n\n        return data_hash[:length]", "response": "Generate and return a hash of data that can be used as suffix of logicalId\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a string representation of a dictionary with basic Python type.", "response": "def _stringify(self, data):\n        \"\"\"\n        Stable, platform & language-independent stringification of a data with basic Python type.\n\n        We use JSON to dump a string instead of `str()` method in order to be language independent.\n\n        :param data: Data to be stringified. If this is one of JSON native types like string, dict, array etc, it will\n                     be properly serialized. Otherwise this method will throw a TypeError for non-JSON serializable\n                     objects\n        :return: string representation of the dictionary\n        :rtype string\n        \"\"\"\n        if isinstance(data, string_types):\n            return data\n\n        # Get the most compact dictionary (separators) and sort the keys recursively to get a stable output\n        return json.dumps(data, separators=(',', ':'), sort_keys=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds the information that resource with given logical_id supports the given property and that a reference to the given value.", "response": "def add(self, logical_id, property, value):\n        \"\"\"\n        Add the information that resource with given `logical_id` supports the given `property`, and that a reference\n        to `logical_id.property` resolves to given `value.\n\n        Example:\n\n            \"MyApi.Deployment\" -> \"MyApiDeployment1234567890\"\n\n        :param logical_id: Logical ID of the resource  (Ex: MyLambdaFunction)\n        :param property: Property on the resource that can be referenced (Ex: Alias)\n        :param value: Value that this reference resolves to.\n        :return: nothing\n        \"\"\"\n\n        if not logical_id or not property:\n            raise ValueError(\"LogicalId and property must be a non-empty string\")\n\n        if not value or not isinstance(value, string_types):\n            raise ValueError(\"Property value must be a non-empty string\")\n\n        if logical_id not in self._refs:\n            self._refs[logical_id] = {}\n\n        if property in self._refs[logical_id]:\n            raise ValueError(\"Cannot add second reference value to {}.{} property\".format(logical_id, property))\n\n        self._refs[logical_id][property] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the value of the property of the resource with given logical_id.", "response": "def get(self, logical_id, property):\n        \"\"\"\n        Returns the value of the reference for given logical_id at given property. Ex: MyFunction.Alias\n\n        :param logical_id: Logical Id of the resource\n        :param property: Property of the resource you want to resolve. None if you want to get value of all properties\n        :return: Value of this property if present. None otherwise\n        \"\"\"\n\n        # By defaulting to empty dictionary, we can handle the case where logical_id is not in map without if statements\n        prop_values = self.get_all(logical_id)\n        if prop_values:\n            return prop_values.get(property, None)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encrypt(key, message):\n    '''encrypt leverages KMS encrypt and base64-encode encrypted blob\n\n        More info on KMS encrypt API:\n        https://docs.aws.amazon.com/kms/latest/APIReference/API_encrypt.html\n    '''\n    try:\n        ret = kms.encrypt(KeyId=key, Plaintext=message)\n        encrypted_data = base64.encodestring(ret.get('CiphertextBlob'))\n    except Exception as e:\n        # returns http 500 back to user and log error details in Cloudwatch Logs\n        raise Exception(\"Unable to encrypt data: \", e)\n\n    return encrypted_data.decode()", "response": "encrypt leverages KMS encrypt and base64 - encode encrypted blob\n\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_tag_list(resource_tag_dict):\n    tag_list = []\n    if resource_tag_dict is None:\n        return tag_list\n\n    for tag_key, tag_value in resource_tag_dict.items():\n\n        tag = {_KEY: tag_key, _VALUE: tag_value if tag_value else \"\"}\n        tag_list.append(tag)\n\n    return tag_list", "response": "Returns a list of SAM defined Tags from a customer defined dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the name of the partition given the region name.", "response": "def get_partition_name(cls, region=None):\n        \"\"\"\n        Gets the name of the partition given the region name. If region name is not provided, this method will\n        use Boto3 to get name of the region where this code is running.\n\n        This implementation is borrowed from AWS CLI\n        https://github.com/aws/aws-cli/blob/1.11.139/awscli/customizations/emr/createdefaultroles.py#L59\n\n        :param region: Optional name of the region\n        :return: Partition name\n        \"\"\"\n\n        if region is None:\n            # Use Boto3 to get the region where code is running. This uses Boto's regular region resolution\n            # mechanism, starting from AWS_DEFAULT_REGION environment variable.\n            region = boto3.session.Session().region_name\n\n        region_string = region.lower()\n        if region_string.startswith(\"cn-\"):\n            return \"aws-cn\"\n        elif region_string.startswith(\"us-gov\"):\n            return \"aws-us-gov\"\n        else:\n            return \"aws\""}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_before_transform_template(self, template_dict):\n        template = SamTemplate(template_dict)\n\n        for logicalId, api in template.iterate(SamResourceType.Api.value):\n            if api.properties.get('DefinitionBody') or api.properties.get('DefinitionUri'):\n                continue\n\n            api.properties['DefinitionBody'] = SwaggerEditor.gen_skeleton()\n            api.properties['__MANAGE_SWAGGER'] = True", "response": "Hook method that gets called before the SAM template is processed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if this Swagger has the given path and optional method", "response": "def has_path(self, path, method=None):\n        \"\"\"\n        Returns True if this Swagger has the given path and optional method\n\n        :param string path: Path name\n        :param string method: HTTP method\n        :return: True, if this path/method is present in the document\n        \"\"\"\n        method = self._normalize_method_name(method)\n\n        path_dict = self.get_path(path)\n        path_dict_exists = path_dict is not None\n        if method:\n            return path_dict_exists and method in path_dict\n        return path_dict_exists"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef method_has_integration(self, method):\n        for method_definition in self.get_method_contents(method):\n            if self.method_definition_has_integration(method_definition):\n                return True\n        return False", "response": "Returns true if the given method contains a valid method definition."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_method_contents(self, method):\n        if self._CONDITIONAL_IF in method:\n            return method[self._CONDITIONAL_IF][1:]\n        return [method]", "response": "Returns the swagger contents of the given method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if an API Gateway integration is already present at the given path and HTTP method.", "response": "def has_integration(self, path, method):\n        \"\"\"\n        Checks if an API Gateway integration is already present at the given path/method\n\n        :param string path: Path name\n        :param string method: HTTP method\n        :return: True, if an API Gateway integration is already present\n        \"\"\"\n        method = self._normalize_method_name(method)\n\n        path_dict = self.get_path(path)\n        return self.has_path(path, method) and \\\n            isinstance(path_dict[method], dict) and \\\n            self.method_has_integration(path_dict[method])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds the path and method combination to the Swagger if not already present.", "response": "def add_path(self, path, method=None):\n        \"\"\"\n        Adds the path/method combination to the Swagger, if not already present\n\n        :param string path: Path name\n        :param string method: HTTP method\n        :raises ValueError: If the value of `path` in Swagger is not a dictionary\n        \"\"\"\n        method = self._normalize_method_name(method)\n\n        path_dict = self.paths.setdefault(path, {})\n\n        if not isinstance(path_dict, dict):\n            # Either customers has provided us an invalid Swagger, or this class has messed it somehow\n            raise InvalidDocumentException(\n                [InvalidTemplateException(\"Value of '{}' path must be a dictionary according to Swagger spec.\"\n                                          .format(path))])\n\n        if self._CONDITIONAL_IF in path_dict:\n            path_dict = path_dict[self._CONDITIONAL_IF][1]\n\n        path_dict.setdefault(method, {})"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a Lambda integration to the given path + method.", "response": "def add_lambda_integration(self, path, method, integration_uri,\n                               method_auth_config=None, api_auth_config=None, condition=None):\n        \"\"\"\n        Adds aws_proxy APIGW integration to the given path+method.\n\n        :param string path: Path name\n        :param string method: HTTP Method\n        :param string integration_uri: URI for the integration.\n        \"\"\"\n\n        method = self._normalize_method_name(method)\n        if self.has_integration(path, method):\n            raise ValueError(\"Lambda integration already exists on Path={}, Method={}\".format(path, method))\n\n        self.add_path(path, method)\n\n        # Wrap the integration_uri in a Condition if one exists on that function\n        # This is necessary so CFN doesn't try to resolve the integration reference.\n        if condition:\n            integration_uri = make_conditional(condition, integration_uri)\n\n        path_dict = self.get_path(path)\n        path_dict[method][self._X_APIGW_INTEGRATION] = {\n                'type': 'aws_proxy',\n                'httpMethod': 'POST',\n                'uri': integration_uri\n        }\n\n        method_auth_config = method_auth_config or {}\n        api_auth_config = api_auth_config or {}\n        if method_auth_config.get('Authorizer') == 'AWS_IAM' \\\n           or api_auth_config.get('DefaultAuthorizer') == 'AWS_IAM' and not method_auth_config:\n            self.paths[path][method][self._X_APIGW_INTEGRATION]['credentials'] = self._generate_integration_credentials(\n                method_invoke_role=method_auth_config.get('InvokeRole'),\n                api_invoke_role=api_auth_config.get('InvokeRole')\n            )\n\n        # If 'responses' key is *not* present, add it with an empty dict as value\n        path_dict[method].setdefault('responses', {})\n\n        # If a condition is present, wrap all method contents up into the condition\n        if condition:\n            path_dict[method] = make_conditional(condition, path_dict[method])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_path_conditional(self, path, condition):\n        self.paths[path] = make_conditional(condition, self.paths[path])", "response": "Wrap entire API path definition in a CloudFormation conditional"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_cors(self, path, allowed_origins, allowed_headers=None, allowed_methods=None, max_age=None,\n                 allow_credentials=None):\n        \"\"\"\n        Add CORS configuration to this path. Specifically, we will add a OPTIONS response config to the Swagger that\n        will return headers required for CORS. Since SAM uses aws_proxy integration, we cannot inject the headers\n        into the actual response returned from Lambda function. This is something customers have to implement\n        themselves.\n\n        If OPTIONS method is already present for the Path, we will skip adding CORS configuration\n\n        Following this guide:\n        https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-cors.html#enable-cors-for-resource-using-swagger-importer-tool\n\n        :param string path: Path to add the CORS configuration to.\n        :param string/dict allowed_origins: Comma separate list of allowed origins.\n            Value can also be an intrinsic function dict.\n        :param string/dict allowed_headers: Comma separated list of allowed headers.\n            Value can also be an intrinsic function dict.\n        :param string/dict allowed_methods: Comma separated list of allowed methods.\n            Value can also be an intrinsic function dict.\n        :param integer/dict max_age: Maximum duration to cache the CORS Preflight request. Value is set on\n            Access-Control-Max-Age header. Value can also be an intrinsic function dict.\n        :param bool/None allow_credentials: Flags whether request is allowed to contain credentials.\n        :raises ValueError: When values for one of the allowed_* variables is empty\n        \"\"\"\n\n        # Skip if Options is already present\n        if self.has_path(path, self._OPTIONS_METHOD):\n            return\n\n        if not allowed_origins:\n            raise ValueError(\"Invalid input. Value for AllowedOrigins is required\")\n\n        if not allowed_methods:\n            # AllowMethods is not given. Let's try to generate the list from the given Swagger.\n            allowed_methods = self._make_cors_allowed_methods_for_path(path)\n\n            # APIGW expects the value to be a \"string expression\". Hence wrap in another quote. Ex: \"'GET,POST,DELETE'\"\n            allowed_methods = \"'{}'\".format(allowed_methods)\n\n        if allow_credentials is not True:\n            allow_credentials = False\n\n        # Add the Options method and the CORS response\n        self.add_path(path, self._OPTIONS_METHOD)\n        self.get_path(path)[self._OPTIONS_METHOD] = self._options_method_response_for_cors(allowed_origins,\n                                                                                           allowed_headers,\n                                                                                           allowed_methods,\n                                                                                           max_age,\n                                                                                           allow_credentials)", "response": "Add a CORS configuration to the Swagger file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a Swagger snippet containing configuration for OPTIONS HTTP Method to configure CORS.", "response": "def _options_method_response_for_cors(self, allowed_origins, allowed_headers=None, allowed_methods=None,\n                                          max_age=None, allow_credentials=None):\n        \"\"\"\n        Returns a Swagger snippet containing configuration for OPTIONS HTTP Method to configure CORS.\n\n        This snippet is taken from public documentation:\n        https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-cors.html#enable-cors-for-resource-using-swagger-importer-tool\n\n        :param string/dict allowed_origins: Comma separate list of allowed origins.\n            Value can also be an intrinsic function dict.\n        :param string/dict allowed_headers: Comma separated list of allowed headers.\n            Value can also be an intrinsic function dict.\n        :param string/dict allowed_methods: Comma separated list of allowed methods.\n            Value can also be an intrinsic function dict.\n        :param integer/dict max_age: Maximum duration to cache the CORS Preflight request. Value is set on\n            Access-Control-Max-Age header. Value can also be an intrinsic function dict.\n        :param bool allow_credentials: Flags whether request is allowed to contain credentials.\n\n        :return dict: Dictionary containing Options method configuration for CORS\n        \"\"\"\n\n        ALLOW_ORIGIN = \"Access-Control-Allow-Origin\"\n        ALLOW_HEADERS = \"Access-Control-Allow-Headers\"\n        ALLOW_METHODS = \"Access-Control-Allow-Methods\"\n        MAX_AGE = \"Access-Control-Max-Age\"\n        ALLOW_CREDENTIALS = \"Access-Control-Allow-Credentials\"\n        HEADER_RESPONSE = (lambda x: \"method.response.header.\" + x)\n\n        response_parameters = {\n            # AllowedOrigin is always required\n            HEADER_RESPONSE(ALLOW_ORIGIN): allowed_origins\n        }\n\n        response_headers = {\n            # Allow Origin is always required\n            ALLOW_ORIGIN: {\n                \"type\": \"string\"\n            }\n        }\n\n        # Optional values. Skip the header if value is empty\n        #\n        # The values must not be empty string or null. Also, value of '*' is a very recent addition (2017) and\n        # not supported in all the browsers. So it is important to skip the header if value is not given\n        #    https://fetch.spec.whatwg.org/#http-new-header-syntax\n        #\n        if allowed_headers:\n            response_parameters[HEADER_RESPONSE(ALLOW_HEADERS)] = allowed_headers\n            response_headers[ALLOW_HEADERS] = {\"type\": \"string\"}\n        if allowed_methods:\n            response_parameters[HEADER_RESPONSE(ALLOW_METHODS)] = allowed_methods\n            response_headers[ALLOW_METHODS] = {\"type\": \"string\"}\n        if max_age is not None:\n            # MaxAge can be set to 0, which is a valid value. So explicitly check against None\n            response_parameters[HEADER_RESPONSE(MAX_AGE)] = max_age\n            response_headers[MAX_AGE] = {\"type\": \"integer\"}\n        if allow_credentials is True:\n            # Allow-Credentials only has a valid value of true, it should be omitted otherwise.\n            # https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Access-Control-Allow-Credentials\n            response_parameters[HEADER_RESPONSE(ALLOW_CREDENTIALS)] = \"'true'\"\n            response_headers[ALLOW_CREDENTIALS] = {\"type\": \"string\"}\n\n        return {\n            \"summary\": \"CORS support\",\n            \"consumes\": [\"application/json\"],\n            \"produces\": [\"application/json\"],\n            self._X_APIGW_INTEGRATION: {\n                \"type\": \"mock\",\n                \"requestTemplates\": {\n                    \"application/json\": \"{\\n  \\\"statusCode\\\" : 200\\n}\\n\"\n                },\n                \"responses\": {\n                    \"default\": {\n                        \"statusCode\": \"200\",\n                        \"responseParameters\": response_parameters,\n                        \"responseTemplates\": {\n                            \"application/json\": \"{}\\n\"\n                        }\n                    }\n                }\n            },\n            \"responses\": {\n                \"200\": {\n                    \"description\": \"Default response for CORS method\",\n                    \"headers\": response_headers\n                }\n            }\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate the value for Access - Control - Allow - Methods header for given path.", "response": "def _make_cors_allowed_methods_for_path(self, path):\n        \"\"\"\n        Creates the value for Access-Control-Allow-Methods header for given path. All HTTP methods defined for this\n        path will be included in the result. If the path contains \"ANY\" method, then *all available* HTTP methods will\n        be returned as result.\n\n        :param string path: Path to generate AllowMethods value for\n        :return string: String containing the value of AllowMethods, if the path contains any methods.\n                        Empty string, otherwise\n        \"\"\"\n\n        # https://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html\n        all_http_methods = [\"OPTIONS\", \"GET\", \"HEAD\", \"POST\", \"PUT\", \"DELETE\", \"PATCH\"]\n\n        if not self.has_path(path):\n            return \"\"\n\n        # At this point, value of Swagger path should be a dictionary with method names being the keys\n        methods = list(self.get_path(path).keys())\n\n        if self._X_ANY_METHOD in methods:\n            # API Gateway's ANY method is not a real HTTP method but a wildcard representing all HTTP methods\n            allow_methods = all_http_methods\n        else:\n            allow_methods = methods\n            allow_methods.append(\"options\")  # Always add Options to the CORS methods response\n\n        # Clean up the result:\n        #\n        # - HTTP Methods **must** be upper case and they are case sensitive.\n        #   (https://tools.ietf.org/html/rfc7231#section-4.1)\n        # - Convert to set to remove any duplicates\n        # - Sort to keep this list stable because it could be constructed from dictionary keys which are *not* ordered.\n        #   Therefore we might get back a different list each time the code runs. To prevent any unnecessary\n        #   regression, we sort the list so the returned value is stable.\n        allow_methods = list({m.upper() for m in allow_methods})\n        allow_methods.sort()\n\n        # Allow-Methods is comma separated string\n        return ','.join(allow_methods)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds Authorizer definitions to the securityDefinitions part of Swagger.", "response": "def add_authorizers(self, authorizers):\n        \"\"\"\n        Add Authorizer definitions to the securityDefinitions part of Swagger.\n\n        :param list authorizers: List of Authorizer configurations which get translated to securityDefinitions.\n        \"\"\"\n        self.security_definitions = self.security_definitions or {}\n\n        for authorizer_name, authorizer in authorizers.items():\n            self.security_definitions[authorizer_name] = authorizer.generate_swagger()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the default authorizer for each method on this path.", "response": "def set_path_default_authorizer(self, path, default_authorizer, authorizers):\n        \"\"\"\n        Sets the DefaultAuthorizer for each method on this path. The DefaultAuthorizer won't be set if an Authorizer\n        was defined at the Function/Path/Method level\n\n        :param string path: Path name\n        :param string default_authorizer: Name of the authorizer to use as the default. Must be a key in the\n            authorizers param.\n        :param list authorizers: List of Authorizer configurations defined on the related Api.\n        \"\"\"\n        for method_name, method in self.get_path(path).items():\n            self.set_method_authorizer(path, method_name, default_authorizer, authorizers,\n                                       default_authorizer=default_authorizer, is_default=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding auth settings for this path and method.", "response": "def add_auth_to_method(self, path, method_name, auth, api):\n        \"\"\"\n        Adds auth settings for this path/method. Auth settings currently consist solely of Authorizers\n        but this method will eventually include setting other auth settings such as API Key,\n        Resource Policy, etc.\n\n        :param string path: Path name\n        :param string method_name: Method name\n        :param dict auth: Auth configuration such as Authorizers, ApiKey, ResourcePolicy (only Authorizers supported\n                          currently)\n        :param dict api: Reference to the related Api's properties as defined in the template.\n        \"\"\"\n        method_authorizer = auth and auth.get('Authorizer')\n        if method_authorizer:\n            api_auth = api.get('Auth')\n            api_authorizers = api_auth and api_auth.get('Authorizers')\n            default_authorizer = api_auth and api_auth.get('DefaultAuthorizer')\n\n            self.set_method_authorizer(path, method_name, method_authorizer, api_authorizers, default_authorizer)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd Gateway Response definitions to Swagger.", "response": "def add_gateway_responses(self, gateway_responses):\n        \"\"\"\n        Add Gateway Response definitions to Swagger.\n\n        :param dict gateway_responses: Dictionary of GatewayResponse configuration which gets translated.\n        \"\"\"\n        self.gateway_responses = self.gateway_responses or {}\n\n        for response_type, response in gateway_responses.items():\n            self.gateway_responses[response_type] = response.generate_swagger()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a copy of the Swagger document as a dictionary.", "response": "def swagger(self):\n        \"\"\"\n        Returns a **copy** of the Swagger document as a dictionary.\n\n        :return dict: Dictionary containing the Swagger document\n        \"\"\"\n\n        # Make sure any changes to the paths are reflected back in output\n        self._doc[\"paths\"] = self.paths\n\n        if self.security_definitions:\n            self._doc[\"securityDefinitions\"] = self.security_definitions\n        if self.gateway_responses:\n            self._doc[self._X_APIGW_GATEWAY_RESPONSES] = self.gateway_responses\n\n        return copy.deepcopy(self._doc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the input data is a Swagger document", "response": "def is_valid(data):\n        \"\"\"\n        Checks if the input data is a Swagger document\n\n        :param dict data: Data to be validated\n        :return: True, if data is a Swagger\n        \"\"\"\n        return bool(data) and \\\n            isinstance(data, dict) and \\\n            bool(data.get(\"swagger\")) and \\\n            isinstance(data.get('paths'), dict)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _normalize_method_name(method):\n        if not method or not isinstance(method, string_types):\n            return method\n\n        method = method.lower()\n        if method == 'any':\n            return SwaggerEditor._X_ANY_METHOD\n        else:\n            return method", "response": "Normalizes the HTTP Method name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_before_transform_template(self, template_dict):\n\n        try:\n            global_section = Globals(template_dict)\n        except InvalidGlobalsSectionException as ex:\n            raise InvalidDocumentException([ex])\n\n        # For each resource in template, try and merge with Globals if necessary\n        template = SamTemplate(template_dict)\n        for logicalId, resource in template.iterate():\n            resource.properties = global_section.merge(resource.type, resource.properties)\n            template.set(logicalId, resource)\n\n        # Remove the Globals section from template if necessary\n        Globals.del_section(template_dict)", "response": "This method is called by the template parsing and merging the SAM template with the Globals section."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a validator function that succeeds only for inputs of the provided type.", "response": "def is_type(valid_type):\n    \"\"\"Returns a validator function that succeeds only for inputs of the provided valid_type.\n\n    :param type valid_type: the type that should be considered valid for the validator\n    :returns: a function which returns True its input is an instance of valid_type, and raises TypeError otherwise\n    :rtype: callable\n    \"\"\"\n    def validate(value, should_raise=True):\n        if not isinstance(value, valid_type):\n            if should_raise:\n                raise TypeError(\"Expected value of type {expected}, actual value was of type {actual}.\".format(\n                    expected=valid_type, actual=type(value)))\n            return False\n        return True\n    return validate"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a validator function that succeeds only if the input is a list and each item in the list passes as input .", "response": "def list_of(validate_item):\n    \"\"\"Returns a validator function that succeeds only if the input is a list, and each item in the list passes as input\n    to the provided validator validate_item.\n\n    :param callable validate_item: the validator function for items in the list\n    :returns: a function which returns True its input is an list of valid items, and raises TypeError otherwise\n    :rtype: callable\n    \"\"\"\n    def validate(value, should_raise=True):\n        validate_type = is_type(list)\n        if not validate_type(value, should_raise=should_raise):\n            return False\n\n        for item in value:\n            try:\n                validate_item(item)\n            except TypeError as e:\n                if should_raise:\n                    samtranslator.model.exceptions.prepend(e, \"list contained an invalid item\")\n                    raise\n                return False\n        return True\n    return validate"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dict_of(validate_key, validate_item):\n    def validate(value, should_raise=True):\n        validate_type = is_type(dict)\n        if not validate_type(value, should_raise=should_raise):\n            return False\n\n        for key, item in value.items():\n            try:\n                validate_key(key)\n            except TypeError as e:\n                if should_raise:\n                    samtranslator.model.exceptions.prepend(e, \"dict contained an invalid key\")\n                    raise\n                return False\n\n            try:\n                validate_item(item)\n            except TypeError as e:\n                if should_raise:\n                    samtranslator.model.exceptions.prepend(e, \"dict contained an invalid value\")\n                    raise\n                return False\n        return True\n    return validate", "response": "Returns a validator function that succeeds only if the input is a dict and each key and value in the dict passes validate_key and validate_item respectively."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a validator function that succeeds only if the input passes at least one of the provided validators.", "response": "def one_of(*validators):\n    \"\"\"Returns a validator function that succeeds only if the input passes at least one of the provided validators.\n\n    :param callable validators: the validator functions\n    :returns: a function which returns True its input passes at least one of the validators, and raises TypeError\n              otherwise\n    :rtype: callable\n    \"\"\"\n    def validate(value, should_raise=True):\n        if any(validate(value, should_raise=False) for validate in validators):\n            return True\n\n        if should_raise:\n            raise TypeError(\"value did not match any allowable type\")\n        return False\n    return validate"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_statement(self, parameter_values):\n\n        missing = self.missing_parameter_values(parameter_values)\n        if len(missing) > 0:\n            # str() of elements of list to prevent any `u` prefix from being displayed in user-facing error message\n            raise InsufficientParameterValues(\"Following required parameters of template '{}' don't have values: {}\"\n                                              .format(self.name, [str(m) for m in missing]))\n\n        # Select only necessary parameter_values. this is to prevent malicious or accidental\n        # injection of values for parameters not intended in the template. This is important because \"Ref\" resolution\n        # will substitute any references for which a value is provided.\n        necessary_parameter_values = {name: value for name, value in parameter_values.items()\n                                      if name in self.parameters}\n\n        # Only \"Ref\" is supported\n        supported_intrinsics = {\n            RefAction.intrinsic_name: RefAction()\n        }\n\n        resolver = IntrinsicsResolver(necessary_parameter_values, supported_intrinsics)\n        definition_copy = copy.deepcopy(self.definition)\n\n        return resolver.resolve_parameter_refs(definition_copy)", "response": "Returns a dictionary containing the values for each parameter in the template that can be used by IAM."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef missing_parameter_values(self, parameter_values):\n\n        if not self._is_valid_parameter_values(parameter_values):\n            raise InvalidParameterValues(\"Parameter values are required to process a policy template\")\n\n        return list(set(self.parameters.keys()) - set(parameter_values.keys()))", "response": "Checks if the given input contains values for all parameters used by this template and returns a list of names that are missing."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_dict(template_name, template_values_dict):\n\n        parameters = template_values_dict.get(\"Parameters\", {})\n        definition = template_values_dict.get(\"Definition\", {})\n\n        return Template(template_name, parameters, definition)", "response": "Parses the input and returns an instance of this class containing the values provided in the dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register(self, plugin):\n\n        if not plugin or not isinstance(plugin, BasePlugin):\n            raise ValueError(\"Plugin must be implemented as a subclass of BasePlugin class\")\n\n        if self.is_registered(plugin.name):\n            raise ValueError(\"Plugin with name {} is already registered\".format(plugin.name))\n\n        self._plugins.append(plugin)", "response": "Register a new plugin."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the object with the given name if found None otherwise.", "response": "def _get(self, plugin_name):\n        \"\"\"\n        Retrieves the plugin with given name\n\n        :param plugin_name: Name of the plugin to retrieve\n        :return samtranslator.plugins.BasePlugin: Returns the plugin object if found. None, otherwise\n        \"\"\"\n\n        for p in self._plugins:\n            if p.name == plugin_name:\n                return p\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nact on the specific life cycle event.", "response": "def act(self, event, *args, **kwargs):\n        \"\"\"\n        Act on the specific life cycle event. The action here is to invoke the hook function on all registered plugins.\n        *args and **kwargs will be passed directly to the plugin's hook functions\n\n        :param samtranslator.plugins.LifeCycleEvents event: Event to act upon\n        :return: Nothing\n        :raises ValueError: If event is not a valid life cycle event\n        :raises NameError: If a plugin does not have the hook method defined\n        :raises Exception: Any exception that a plugin raises\n        \"\"\"\n\n        if not isinstance(event, LifeCycleEvents):\n            raise ValueError(\"'event' must be an instance of LifeCycleEvents class\")\n\n        method_name = \"on_\" + event.name\n\n        for plugin in self._plugins:\n\n            if not hasattr(plugin, method_name):\n                raise NameError(\"'{}' method is not found in the plugin with name '{}'\"\n                                .format(method_name, plugin.name))\n\n            try:\n                getattr(plugin, method_name)(*args, **kwargs)\n            except InvalidResourceException as ex:\n                # Don't need to log these because they don't result in crashes\n                raise ex\n            except Exception as ex:\n                logging.exception(\"Plugin '%s' raised an exception: %s\", plugin.name, ex)\n                raise ex"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new DeploymentPreference object from a dictionary.", "response": "def from_dict(cls, logical_id, deployment_preference_dict):\n        \"\"\"\n        :param logical_id: the logical_id of the resource that owns this deployment preference\n        :param deployment_preference_dict: the dict object taken from the SAM template\n        :return:\n        \"\"\"\n        enabled = deployment_preference_dict.get('Enabled', True)\n        if not enabled:\n            return DeploymentPreference(None, None, None, None, False, None)\n\n        if 'Type' not in deployment_preference_dict:\n            raise InvalidResourceException(logical_id, \"'DeploymentPreference' is missing required Property 'Type'\")\n\n        deployment_type = deployment_preference_dict['Type']\n        hooks = deployment_preference_dict.get('Hooks', dict())\n        if not isinstance(hooks, dict):\n            raise InvalidResourceException(logical_id,\n                                           \"'Hooks' property of 'DeploymentPreference' must be a dictionary\")\n\n        pre_traffic_hook = hooks.get('PreTraffic', None)\n        post_traffic_hook = hooks.get('PostTraffic', None)\n        alarms = deployment_preference_dict.get('Alarms', None)\n        role = deployment_preference_dict.get('Role', None)\n        return DeploymentPreference(deployment_type, pre_traffic_hook, post_traffic_hook, alarms, enabled, role)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decrypt(message):\n    '''decrypt leverages KMS decrypt and base64-encode decrypted blob\n\n        More info on KMS decrypt API:\n        https://docs.aws.amazon.com/kms/latest/APIReference/API_decrypt.html\n    '''\n    try:\n        ret = kms.decrypt(\n            CiphertextBlob=base64.decodestring(message))\n        decrypted_data = ret.get('Plaintext')\n    except Exception as e:\n        # returns http 500 back to user and log error details in Cloudwatch Logs\n        raise Exception(\"Unable to decrypt data: \", e)\n\n    return decrypted_data", "response": "decrypt leverages KMS decrypt and base64 - encode decrypted blob\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates the incoming token and produce the principal user identifier associated with the token. This can be accomplished in a number of ways: 1. Call out to the OAuth provider 2. Decode a JWT token inline 3. Lookup in a self-managed DB", "response": "def lambda_handler(event, context):\n    # incoming token value\n    token = event['authorizationToken']\n    print(\"Method ARN: \" + event['methodArn'])\n\n    '''\n    Validate the incoming token and produce the principal user identifier\n    associated with the token. This can be accomplished in a number of ways:\n\n    1. Call out to the OAuth provider\n    2. Decode a JWT token inline\n    3. Lookup in a self-managed DB\n    '''\n    principalId = 'user|a1b2c3d4'\n\n    '''\n    You can send a 401 Unauthorized response to the client by failing like so:\n\n      raise Exception('Unauthorized')\n\n    If the token is valid, a policy must be generated which will allow or deny\n    access to the client. If access is denied, the client will receive a 403\n    Access Denied response. If access is allowed, API Gateway will proceed with\n    the backend integration configured on the method that was called.\n\n    This function must generate a policy that is associated with the recognized\n    principal user identifier. Depending on your use case, you might store\n    policies in a DB, or generate them on the fly.\n\n    Keep in mind, the policy is cached for 5 minutes by default (TTL is\n    configurable in the authorizer) and will apply to subsequent calls to any\n    method/resource in the RestApi made with the same token.\n\n    The example policy below denies access to all resources in the RestApi.\n    '''\n    tmp = event['methodArn'].split(':')\n    apiGatewayArnTmp = tmp[5].split('/')\n    awsAccountId = tmp[4]\n\n    policy = AuthPolicy(principalId, awsAccountId)\n    policy.restApiId = apiGatewayArnTmp[0]\n    policy.region = tmp[3]\n    policy.stage = apiGatewayArnTmp[1]\n    policy.denyAllMethods()\n    #policy.allowMethod(HttpVerb.GET, '/pets/*')\n\n    # Finally, build the policy\n    authResponse = policy.build()\n\n    # new! -- add additional key-value pairs associated with the authenticated principal\n    # these are made available by APIGW like so: $context.authorizer.<key>\n    # additional context is cached\n    context = {\n        'key': 'value',  # $context.authorizer.key -> value\n        'number': 1,\n        'bool': True\n    }\n    # context['arr'] = ['foo'] <- this is invalid, APIGW will not accept it\n    # context['obj'] = {'foo':'bar'} <- also invalid\n\n    authResponse['context'] = context\n\n    return authResponse"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_before_transform_resource(self, logical_id, resource_type, resource_properties):\n\n        if not self._is_supported(resource_type):\n            return\n\n        function_policies = FunctionPolicies(resource_properties, self._policy_template_processor)\n\n        if len(function_policies) == 0:\n            # No policies to process\n            return\n\n        result = []\n        for policy_entry in function_policies.get():\n\n            if policy_entry.type is not PolicyTypes.POLICY_TEMPLATE:\n                # If we don't know the type, skip processing and pass to result as is.\n                result.append(policy_entry.data)\n                continue\n\n            # We are processing policy templates. We know they have a particular structure:\n            # {\"templateName\": { parameter_values_dict }}\n            template_data = policy_entry.data\n            template_name = list(template_data.keys())[0]\n            template_parameters = list(template_data.values())[0]\n\n            try:\n\n                # 'convert' will return a list of policy statements\n                result.append(self._policy_template_processor.convert(template_name, template_parameters))\n\n            except InsufficientParameterValues as ex:\n                # Exception's message will give lot of specific details\n                raise InvalidResourceException(logical_id, str(ex))\n            except InvalidParameterValues:\n                raise InvalidResourceException(logical_id,\n                                               \"Must specify valid parameter values for policy template '{}'\"\n                                               .format(template_name))\n\n        # Save the modified policies list to the input\n        resource_properties[FunctionPolicies.POLICIES_PROPERTY_NAME] = result", "response": "Hook method that gets called before each SAM resource gets processed\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transform(input_fragment, parameter_values, managed_policy_loader):\n\n    sam_parser = Parser()\n    translator = Translator(managed_policy_loader.load(), sam_parser)\n    return translator.translate(input_fragment, parameter_values=parameter_values)", "response": "Translates the SAM manifest provided in the and returns the translation to CloudFormation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_dict(self):\n        dict_with_nones = self._asdict()\n        codedeploy_lambda_alias_update_dict = dict((k, v) for k, v in dict_with_nones.items()\n                                                   if v != ref(None) and v is not None)\n        return {'CodeDeployLambdaAliasUpdate': codedeploy_lambda_alias_update_dict}", "response": "Returns a dict that can be used as part of a cloudformation template"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhooks method that gets called before the SAM template is processed. The template has pass the validation and is guaranteed to contain a non-empty \"Resources\" section. :param dict template_dict: Dictionary of the SAM template :return: Nothing", "response": "def on_before_transform_template(self, template_dict):\n        \"\"\"\n        Hook method that gets called before the SAM template is processed.\n        The template has pass the validation and is guaranteed to contain a non-empty \"Resources\" section.\n\n        :param dict template_dict: Dictionary of the SAM template\n        :return: Nothing\n        \"\"\"\n\n        template = SamTemplate(template_dict)\n\n        # Temporarily add Serverless::Api resource corresponding to Implicit API to the template.\n        # This will allow the processing code to work the same way for both Implicit & Explicit APIs\n        # If there are no implicit APIs, we will remove from the template later.\n\n        # If the customer has explicitly defined a resource with the id of \"ServerlessRestApi\",\n        # capture it.  If the template ends up not defining any implicit api's, instead of just\n        # removing the \"ServerlessRestApi\" resource, we just restore what the author defined.\n        self.existing_implicit_api_resource = copy.deepcopy(template.get(self.implicit_api_logical_id))\n\n        template.set(self.implicit_api_logical_id, ImplicitApiResource().to_dict())\n\n        errors = []\n        for logicalId, function in template.iterate(SamResourceType.Function.value):\n\n            api_events = self._get_api_events(function)\n            condition = function.condition\n            if len(api_events) == 0:\n                continue\n\n            try:\n                self._process_api_events(function, api_events, template, condition)\n\n            except InvalidEventException as ex:\n                errors.append(InvalidResourceException(logicalId, ex.message))\n\n        self._maybe_add_condition_to_implicit_api(template_dict)\n        self._maybe_add_conditions_to_implicit_api_paths(template)\n        self._maybe_remove_implicit_api(template)\n\n        if len(errors) > 0:\n            raise InvalidDocumentException(errors)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_api_events(self, function):\n\n        if not (function.valid() and\n                isinstance(function.properties, dict) and\n                isinstance(function.properties.get(\"Events\"), dict)\n                ):\n            # Function resource structure is invalid.\n            return {}\n\n        api_events = {}\n        for event_id, event in function.properties[\"Events\"].items():\n\n            if event and isinstance(event, dict) and event.get(\"Type\") == \"Api\":\n                api_events[event_id] = event\n\n        return api_events", "response": "Method to return a dictionary of API Events on the function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing API events and adds them to the Swagger JSON.", "response": "def _process_api_events(self, function, api_events, template, condition=None):\n        \"\"\"\n        Actually process given API events. Iteratively adds the APIs to Swagger JSON in the respective Serverless::Api\n        resource from the template\n\n        :param SamResource function: SAM Function containing the API events to be processed\n        :param dict api_events: API Events extracted from the function. These events will be processed\n        :param SamTemplate template: SAM Template where Serverless::Api resources can be found\n        :param str condition: optional; this is the condition that is on the function with the API event\n        \"\"\"\n\n        for logicalId, event in api_events.items():\n\n            event_properties = event.get(\"Properties\", {})\n            if not event_properties:\n                continue\n\n            self._add_implicit_api_id_if_necessary(event_properties)\n\n            api_id = self._get_api_id(event_properties)\n            try:\n                path = event_properties[\"Path\"]\n                method = event_properties[\"Method\"]\n            except KeyError as e:\n                raise InvalidEventException(logicalId, \"Event is missing key {}.\".format(e))\n\n            if (not isinstance(path, six.string_types)):\n                raise InvalidEventException(logicalId,\n                                            \"Api Event must have a String specified for 'Path'.\")\n            if (not isinstance(method, six.string_types)):\n                raise InvalidEventException(logicalId,\n                                            \"Api Event must have a String specified for 'Method'.\")\n\n            api_dict = self.api_conditions.setdefault(api_id, {})\n            method_conditions = api_dict.setdefault(path, {})\n            method_conditions[method] = condition\n\n            self._add_api_to_swagger(logicalId, event_properties, template)\n\n            api_events[logicalId] = event\n\n        # We could have made changes to the Events structure. Write it back to function\n        function.properties[\"Events\"].update(api_events)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _add_api_to_swagger(self, event_id, event_properties, template):\n\n        # Need to grab the AWS::Serverless::Api resource for this API event and update its Swagger definition\n        api_id = self._get_api_id(event_properties)\n\n        # RestApiId is not pointing to a valid  API resource\n        if isinstance(api_id, dict) or not template.get(api_id):\n            raise InvalidEventException(event_id,\n                                        \"RestApiId must be a valid reference to an 'AWS::Serverless::Api' resource \"\n                                        \"in same template\")\n\n        # Make sure Swagger is valid\n        resource = template.get(api_id)\n        if not (resource and\n                isinstance(resource.properties, dict) and\n                SwaggerEditor.is_valid(resource.properties.get(\"DefinitionBody\"))):\n            # This does not have an inline Swagger. Nothing can be done about it.\n            return\n\n        if not resource.properties.get(\"__MANAGE_SWAGGER\"):\n            # Do not add the api to Swagger, if the resource is not actively managed by SAM.\n            # ie. Implicit API resources are created & managed by SAM on behalf of customers.\n            # But for explicit API resources, customers write their own Swagger and manage it.\n            # If a path is present in Events section but *not* present in the Explicit API Swagger, then it is\n            # customer's responsibility to add to Swagger. We will not modify the Swagger here.\n            #\n            # In the future, we will might expose a flag that will allow SAM to manage explicit API Swagger as well.\n            # Until then, we will not modify explicit explicit APIs.\n            return\n\n        swagger = resource.properties.get(\"DefinitionBody\")\n\n        path = event_properties[\"Path\"]\n        method = event_properties[\"Method\"]\n        editor = SwaggerEditor(swagger)\n        editor.add_path(path, method)\n\n        resource.properties[\"DefinitionBody\"] = editor.swagger\n        template.set(api_id, resource)", "response": "Adds the API path and method from the given event to the Swagger JSON of Serverless API resources."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_api_id(self, event_properties):\n        api_id = event_properties.get(\"RestApiId\")\n        if isinstance(api_id, dict) and \"Ref\" in api_id:\n            api_id = api_id[\"Ref\"]\n        return api_id", "response": "Get API id from API event properties."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _maybe_add_condition_to_implicit_api(self, template_dict):\n        # Short-circuit if template doesn't have any functions with implicit API events\n        if not self.api_conditions.get(self.implicit_api_logical_id, {}):\n            return\n\n        # Add a condition to the API resource IFF all of its resource+methods are associated with serverless functions\n        # containing conditions.\n        implicit_api_conditions = self.api_conditions[self.implicit_api_logical_id]\n        all_resource_method_conditions = set([condition\n                                              for path, method_conditions in implicit_api_conditions.items()\n                                              for method, condition in method_conditions.items()])\n        at_least_one_resource_method = len(all_resource_method_conditions) > 0\n        all_resource_methods_contain_conditions = None not in all_resource_method_conditions\n        if at_least_one_resource_method and all_resource_methods_contain_conditions:\n            implicit_api_resource = template_dict.get('Resources').get(self.implicit_api_logical_id)\n            if len(all_resource_method_conditions) == 1:\n                condition = all_resource_method_conditions.pop()\n                implicit_api_resource['Condition'] = condition\n            else:\n                # If multiple functions with multiple different conditions reference the Implicit Api, we need to\n                # aggregate those conditions in order to conditionally create the Implicit Api. See RFC:\n                # https://github.com/awslabs/serverless-application-model/issues/758\n                implicit_api_resource['Condition'] = self.implicit_api_condition\n                self._add_combined_condition_to_template(\n                    template_dict, self.implicit_api_condition, all_resource_method_conditions)", "response": "Adds a condition to the implicit API resource if it is not already present in the template."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _add_combined_condition_to_template(self, template_dict, condition_name, conditions_to_combine):\n        # defensive precondition check\n        if not conditions_to_combine or len(conditions_to_combine) < 2:\n            raise ValueError('conditions_to_combine must have at least 2 conditions')\n\n        template_conditions = template_dict.setdefault('Conditions', {})\n        new_template_conditions = make_combined_condition(sorted(list(conditions_to_combine)), condition_name)\n        for name, definition in new_template_conditions.items():\n            template_conditions[name] = definition", "response": "Add a combined condition to the SAM template dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _maybe_add_conditions_to_implicit_api_paths(self, template):\n\n        for api_id, api in template.iterate(SamResourceType.Api.value):\n            if not api.properties.get('__MANAGE_SWAGGER'):\n                continue\n\n            swagger = api.properties.get(\"DefinitionBody\")\n            editor = SwaggerEditor(swagger)\n\n            for path in editor.iter_on_path():\n                all_method_conditions = set(\n                    [condition for method, condition in self.api_conditions[api_id][path].items()]\n                )\n                at_least_one_method = len(all_method_conditions) > 0\n                all_methods_contain_conditions = None not in all_method_conditions\n                if at_least_one_method and all_methods_contain_conditions:\n                    if len(all_method_conditions) == 1:\n                        editor.make_path_conditional(path, all_method_conditions.pop())\n                    else:\n                        path_condition_name = self._path_condition_name(api_id, path)\n                        self._add_combined_condition_to_template(\n                            template.template_dict, path_condition_name, all_method_conditions)\n                        editor.make_path_conditional(path, path_condition_name)\n\n            api.properties[\"DefinitionBody\"] = editor.swagger\n            template.set(api_id, api)", "response": "Add conditions to implicit API paths if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _path_condition_name(self, api_id, path):\n        # only valid characters for CloudFormation logical id are [A-Za-z0-9], but swagger paths can contain\n        # slashes and curly braces for templated params, e.g., /foo/{customerId}. So we'll replace\n        # non-alphanumeric characters.\n        path_logical_id = path.replace('/', 'SLASH').replace('{', 'OB').replace('}', 'CB')\n        return '{}{}PathCondition'.format(api_id, path_logical_id)", "response": "Generate valid logical id from the given API logical id and swagger resource path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _maybe_remove_implicit_api(self, template):\n\n        # Remove Implicit API resource if no paths got added\n        implicit_api_resource = template.get(self.implicit_api_logical_id)\n\n        if implicit_api_resource and len(implicit_api_resource.properties[\"DefinitionBody\"][\"paths\"]) == 0:\n            # If there's no implicit api and the author defined a \"ServerlessRestApi\"\n            # resource, restore it\n            if self.existing_implicit_api_resource:\n                template.set(self.implicit_api_logical_id, self.existing_implicit_api_resource)\n            else:\n                template.delete(self.implicit_api_logical_id)", "response": "Remove the Implicit API resource from the SAM template if there are no paths."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_auto_deployable(self, stage, swagger=None):\n        if not swagger:\n            return\n\n        # CloudFormation does NOT redeploy the API unless it has a new deployment resource\n        # that points to latest RestApi resource. Append a hash of Swagger Body location to\n        # redeploy only when the API data changes. First 10 characters of hash is good enough\n        # to prevent redeployment when API has not changed\n\n        # NOTE: `str(swagger)` is for backwards compatibility. Changing it to a JSON or something will break compat\n        generator = logical_id_generator.LogicalIdGenerator(self.logical_id, str(swagger))\n        self.logical_id = generator.gen()\n        hash = generator.get_hash(length=40)  # Get the full hash\n        self.Description = \"RestApi deployment id: {}\".format(hash)\n        stage.update_deployment_ref(self.logical_id)", "response": "Sets up the resource such that it will trigger a re - deployment when the Swagger changes"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread at most amt bytes from the stream.", "response": "def read(self, amt=None):\n        \"\"\"Read at most amt bytes from the stream.\n        If the amt argument is omitted, read all data.\n        \"\"\"\n        chunk = self._raw_stream.read(amt)\n        self._amount_read += len(chunk)\n        return chunk"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef post_work(self, function_arn, input_bytes, client_context, invocation_type=\"RequestResponse\"):\n        url = self._get_url(function_arn)\n        runtime_logger.info('Posting work for function [{}] to {}'.format(function_arn, url))\n\n        request = Request(url, input_bytes or b'')\n        request.add_header(HEADER_CLIENT_CONTEXT, client_context)\n        request.add_header(HEADER_AUTH_TOKEN, self.auth_token)\n        request.add_header(HEADER_INVOCATION_TYPE, invocation_type)\n\n        response = urlopen(request)\n\n        invocation_id = response.info().get(HEADER_INVOCATION_ID)\n        runtime_logger.info('Work posted with invocation id [{}]'.format(invocation_id))\n        return invocation_id", "response": "Send a work item to the Lambda function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve the next work item for the specified Lambda function.", "response": "def get_work(self, function_arn):\n        \"\"\"\n        Retrieve the next work item for specified :code:`function_arn`.\n\n        :param function_arn: Arn of the Lambda function intended to receive the work for processing.\n        :type function_arn: string\n\n        :returns: Next work item to be processed by the function.\n        :type returns: WorkItem\n        \"\"\"\n        url = self._get_work_url(function_arn)\n        runtime_logger.info('Getting work for function [{}] from {}'.format(function_arn, url))\n\n        request = Request(url)\n        request.add_header(HEADER_AUTH_TOKEN, self.auth_token)\n\n        response = urlopen(request)\n\n        invocation_id = response.info().get(HEADER_INVOCATION_ID)\n        client_context = response.info().get(HEADER_CLIENT_CONTEXT)\n\n        runtime_logger.info('Got work item with invocation id [{}]'.format(invocation_id))\n        return WorkItem(\n            invocation_id=invocation_id,\n            payload=response.read(),\n            client_context=client_context)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nposts the result of processing the work item by function_arn.", "response": "def post_work_result(self, function_arn, work_item):\n        \"\"\"\n        Post the result of processing work item by :code:`function_arn`.\n\n        :param function_arn: Arn of the Lambda function intended to receive the work for processing.\n        :type function_arn: string\n\n        :param work_item: The WorkItem holding the results of the work being posted.\n        :type work_item: WorkItem\n\n        :returns: None\n        \"\"\"\n        url = self._get_work_url(function_arn)\n\n        runtime_logger.info('Posting work result for invocation id [{}] to {}'.format(work_item.invocation_id, url))\n        request = Request(url, work_item.payload or b'')\n\n        request.add_header(HEADER_INVOCATION_ID, work_item.invocation_id)\n        request.add_header(HEADER_AUTH_TOKEN, self.auth_token)\n\n        urlopen(request)\n\n        runtime_logger.info('Posted work result for invocation id [{}]'.format(work_item.invocation_id))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef post_handler_err(self, function_arn, invocation_id, handler_err):\n        url = self._get_work_url(function_arn)\n\n        runtime_logger.info('Posting handler error for invocation id [{}] to {}'.format(invocation_id, url))\n\n        payload = json.dumps({\n            \"errorMessage\": handler_err,\n        }).encode('utf-8')\n\n        request = Request(url, payload)\n        request.add_header(HEADER_INVOCATION_ID, invocation_id)\n        request.add_header(HEADER_FUNCTION_ERR_TYPE, \"Handled\")\n        request.add_header(HEADER_AUTH_TOKEN, self.auth_token)\n\n        urlopen(request)\n\n        runtime_logger.info('Posted handler error for invocation id [{}]'.format(invocation_id))", "response": "Post the error message from executing the function handler for the given function_arn and invocation_id."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the result of the work processed by Lambda function with specified invocation_id.", "response": "def get_work_result(self, function_arn, invocation_id):\n        \"\"\"\n        Retrieve the result of the work processed by :code:`function_arn`\n        with specified :code:`invocation_id`.\n\n        :param function_arn: Arn of the Lambda function intended to receive the work for processing.\n        :type function_arn: string\n\n        :param invocation_id: Invocation ID of the work that is being requested\n        :type invocation_id: string\n\n        :returns: The get work result output contains result payload and function error type if the invoking is failed.\n        :type returns: GetWorkResultOutput\n        \"\"\"\n        url = self._get_url(function_arn)\n\n        runtime_logger.info('Getting work result for invocation id [{}] from {}'.format(invocation_id, url))\n\n        request = Request(url)\n        request.add_header(HEADER_INVOCATION_ID, invocation_id)\n        request.add_header(HEADER_AUTH_TOKEN, self.auth_token)\n\n        response = urlopen(request)\n\n        runtime_logger.info('Got result for invocation id [{}]'.format(invocation_id))\n\n        payload = response.read()\n        func_err = response.info().get(HEADER_FUNCTION_ERR_TYPE)\n\n        return GetWorkResultOutput(\n            payload=payload,\n            func_err=func_err)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhooks method that gets called before the SAM template is processed. The template has passed the validation and is guaranteed to contain a non-empty \"Resources\" section. This plugin needs to run as soon as possible to allow some time for templates to become available. This verifies that the user has access to all specified applications. :param dict template_dict: Dictionary of the SAM template :return: Nothing", "response": "def on_before_transform_template(self, template_dict):\n        \"\"\"\n        Hook method that gets called before the SAM template is processed.\n        The template has passed the validation and is guaranteed to contain a non-empty \"Resources\" section.\n\n        This plugin needs to run as soon as possible to allow some time for templates to become available.\n        This verifies that the user has access to all specified applications.\n\n        :param dict template_dict: Dictionary of the SAM template\n        :return: Nothing\n        \"\"\"\n        template = SamTemplate(template_dict)\n        intrinsic_resolvers = self._get_intrinsic_resolvers(template_dict.get('Mappings', {}))\n\n        service_call = None\n        if self._validate_only:\n            service_call = self._handle_get_application_request\n        else:\n            service_call = self._handle_create_cfn_template_request\n        for logical_id, app in template.iterate(SamResourceType.Application.value):\n            if not self._can_process_application(app):\n                # Handle these cases in the on_before_transform_resource event\n                continue\n\n            app_id = self._replace_value(app.properties[self.LOCATION_KEY],\n                                         self.APPLICATION_ID_KEY, intrinsic_resolvers)\n\n            semver = self._replace_value(app.properties[self.LOCATION_KEY],\n                                         self.SEMANTIC_VERSION_KEY, intrinsic_resolvers)\n\n            if isinstance(app_id, dict) or isinstance(semver, dict):\n                key = (json.dumps(app_id), json.dumps(semver))\n                self._applications[key] = False\n                continue\n\n            key = (app_id, semver)\n\n            if key not in self._applications:\n                try:\n                    # Lazy initialization of the client- create it when it is needed\n                    if not self._sar_client:\n                        self._sar_client = boto3.client('serverlessrepo')\n                    service_call(app_id, semver, key, logical_id)\n                except InvalidResourceException as e:\n                    # Catch all InvalidResourceExceptions, raise those in the before_resource_transform target.\n                    self._applications[key] = e"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _can_process_application(self, app):\n        return (self.LOCATION_KEY in app.properties and\n                isinstance(app.properties[self.LOCATION_KEY], dict) and\n                self.APPLICATION_ID_KEY in app.properties[self.LOCATION_KEY] and\n                self.SEMANTIC_VERSION_KEY in app.properties[self.LOCATION_KEY])", "response": "Determines whether or not the on_before_transform_template event can process this application."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_before_transform_resource(self, logical_id, resource_type, resource_properties):\n\n        if not self._resource_is_supported(resource_type):\n            return\n\n        # Sanitize properties\n        self._check_for_dictionary_key(logical_id, resource_properties, [self.LOCATION_KEY])\n\n        # If location isn't a dictionary, don't modify the resource.\n        if not isinstance(resource_properties[self.LOCATION_KEY], dict):\n            resource_properties[self.TEMPLATE_URL_KEY] = resource_properties[self.LOCATION_KEY]\n            return\n\n        # If it is a dictionary, check for other required parameters\n        self._check_for_dictionary_key(logical_id, resource_properties[self.LOCATION_KEY],\n                                       [self.APPLICATION_ID_KEY, self.SEMANTIC_VERSION_KEY])\n\n        app_id = resource_properties[self.LOCATION_KEY].get(self.APPLICATION_ID_KEY)\n\n        if not app_id:\n            raise InvalidResourceException(logical_id, \"Property 'ApplicationId' cannot be blank.\")\n\n        if isinstance(app_id, dict):\n            raise InvalidResourceException(logical_id, \"Property 'ApplicationId' cannot be resolved. Only FindInMap \"\n                                                       \"and Ref intrinsic functions are supported.\")\n\n        semver = resource_properties[self.LOCATION_KEY].get(self.SEMANTIC_VERSION_KEY)\n\n        if not semver:\n            raise InvalidResourceException(logical_id, \"Property 'SemanticVersion' cannot be blank.\")\n\n        if isinstance(semver, dict):\n            raise InvalidResourceException(logical_id, \"Property 'SemanticVersion' cannot be resolved. Only FindInMap \"\n                                                       \"and Ref intrinsic functions are supported.\")\n\n        key = (app_id, semver)\n\n        # Throw any resource exceptions saved from the before_transform_template event\n        if isinstance(self._applications[key], InvalidResourceException):\n            raise self._applications[key]\n\n        # validation does not resolve an actual template url\n        if not self._validate_only:\n            resource_properties[self.TEMPLATE_URL_KEY] = self._applications[key]", "response": "Hook method that gets called before each SAM resource gets processed\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_for_dictionary_key(self, logical_id, dictionary, keys):\n        for key in keys:\n            if key not in dictionary:\n                raise InvalidResourceException(logical_id, 'Resource is missing the required [{}] '\n                                                           'property.'.format(key))", "response": "Checks a dictionary to make sure that the key in the keys list is in the keys list. If it does not raise an InvalidResourceException"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhooks method that gets called after the template is processed Go through all the stored applications and make sure they're all ACTIVE. :param dict template: Dictionary of the SAM template :return: Nothing", "response": "def on_after_transform_template(self, template):\n        \"\"\"\n        Hook method that gets called after the template is processed\n\n        Go through all the stored applications and make sure they're all ACTIVE.\n\n        :param dict template: Dictionary of the SAM template\n        :return: Nothing\n        \"\"\"\n        if self._wait_for_template_active_status and not self._validate_only:\n            start_time = time()\n            while (time() - start_time) < self.TEMPLATE_WAIT_TIMEOUT_SECONDS:\n                temp = self._in_progress_templates\n                self._in_progress_templates = []\n\n                # Check each resource to make sure it's active\n                for application_id, template_id in temp:\n                    get_cfn_template = (lambda application_id, template_id:\n                                        self._sar_client.get_cloud_formation_template(\n                                            ApplicationId=self._sanitize_sar_str_param(application_id),\n                                            TemplateId=self._sanitize_sar_str_param(template_id)))\n                    response = self._sar_service_call(get_cfn_template, application_id, application_id, template_id)\n                    self._handle_get_cfn_template_response(response, application_id, template_id)\n\n                # Don't sleep if there are no more templates with PREPARING status\n                if len(self._in_progress_templates) == 0:\n                    break\n\n                # Sleep a little so we don't spam service calls\n                sleep(self.SLEEP_TIME_SECONDS)\n\n            # Not all templates reached active status\n            if len(self._in_progress_templates) != 0:\n                application_ids = [items[0] for items in self._in_progress_templates]\n                raise InvalidResourceException(application_ids, \"Timed out waiting for nested stack templates \"\n                                                                \"to reach ACTIVE status.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles the response from the GetCfnTemplate API call.", "response": "def _handle_get_cfn_template_response(self, response, application_id, template_id):\n        \"\"\"\n        Handles the response from the SAR service call\n\n        :param dict response: the response dictionary from the app repo\n        :param string application_id: the ApplicationId\n        :param string template_id: the unique TemplateId for this application\n        \"\"\"\n        status = response['Status']\n        if status != \"ACTIVE\":\n            # Other options are PREPARING and EXPIRED.\n            if status == 'EXPIRED':\n                message = (\"Template for {} with id {} returned status: {}. Cannot access an expired \"\n                           \"template.\".format(application_id, template_id, status))\n                raise InvalidResourceException(application_id, message)\n            self._in_progress_templates.append((application_id, template_id))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling service calls and exceptions management for service calls and exception management for service calls", "response": "def _sar_service_call(self, service_call_lambda, logical_id, *args):\n        \"\"\"\n        Handles service calls and exception management for service calls\n        to the Serverless Application Repository.\n\n        :param lambda service_call_lambda: lambda function that contains the service call\n        :param string logical_id: Logical ID of the resource being processed\n        :param list *args: arguments for the service call lambda\n        \"\"\"\n        try:\n            response = service_call_lambda(*args)\n            logging.info(response)\n            return response\n        except ClientError as e:\n            error_code = e.response['Error']['Code']\n            if error_code in ('AccessDeniedException', 'NotFoundException'):\n                raise InvalidResourceException(logical_id, e.response['Error']['Message'])\n\n            # 'ForbiddenException'- SAR rejects connection\n            logging.exception(e)\n            raise e"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _validate(self, sam_template, parameter_values):\n        if parameter_values is None:\n            raise ValueError(\"`parameter_values` argument is required\")\n\n        if (\"Resources\" not in sam_template or not isinstance(sam_template[\"Resources\"], dict) or not\n                sam_template[\"Resources\"]):\n            raise InvalidDocumentException(\n                [InvalidTemplateException(\"'Resources' section is required\")])\n\n        if (not all(isinstance(sam_resource, dict) for sam_resource in sam_template[\"Resources\"].values())):\n            raise InvalidDocumentException(\n                [InvalidTemplateException(\n                    \"All 'Resources' must be Objects. If you're using YAML, this may be an \"\n                    \"indentation issue.\"\n                )])\n\n        sam_template_instance = SamTemplate(sam_template)\n\n        for resource_logical_id, sam_resource in sam_template_instance.iterate():\n            # NOTE: Properties isn't required for SimpleTable, so we can't check\n            # `not isinstance(sam_resources.get(\"Properties\"), dict)` as this would be a breaking change.\n            # sam_resource.properties defaults to {} in SamTemplate init\n            if (not isinstance(sam_resource.properties, dict)):\n                raise InvalidDocumentException(\n                    [InvalidResourceException(resource_logical_id,\n                                              \"All 'Resources' must be Objects and have a 'Properties' Object. If \"\n                                              \"you're using YAML, this may be an indentation issue.\"\n                                              )])\n\n        SamTemplateValidator.validate(sam_template)", "response": "Validates the SAM template and parameter values and raises exceptions if there s an issue"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef iterate(self, resource_type=None):\n\n        for logicalId, resource_dict in self.resources.items():\n\n            resource = SamResource(resource_dict)\n            needs_filter = resource.valid()\n            if resource_type:\n                needs_filter = needs_filter and resource.type == resource_type\n\n            if needs_filter:\n                yield logicalId, resource", "response": "Iterate over all resources within the SAM template optionally filtering by type"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set(self, logicalId, resource):\n\n        resource_dict = resource\n        if isinstance(resource, SamResource):\n            resource_dict = resource.to_dict()\n\n        self.resources[logicalId] = resource_dict", "response": "Adds the resource to the dictionary with given logical Id."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the resource at the given logicalId.", "response": "def get(self, logicalId):\n        \"\"\"\n        Gets the resource at the given logicalId if present\n\n        :param string logicalId: Id of the resource\n        :return SamResource: Resource, if available at the Id. None, otherwise\n        \"\"\"\n        if logicalId not in self.resources:\n            return None\n\n        return SamResource(self.resources.get(logicalId))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate & returns a new SamPlugins object with the given list of plugins installed.", "response": "def prepare_plugins(plugins, parameters={}):\n    \"\"\"\n    Creates & returns a plugins object with the given list of plugins installed. In addition to the given plugins,\n    we will also install a few \"required\" plugins that are necessary to provide complete support for SAM template spec.\n\n    :param plugins: list of samtranslator.plugins.BasePlugin plugins: List of plugins to install\n    :param parameters: Dictionary of parameter values\n    :return samtranslator.plugins.SamPlugins: Instance of `SamPlugins`\n    \"\"\"\n\n    required_plugins = [\n        DefaultDefinitionBodyPlugin(),\n        make_implicit_api_plugin(),\n        GlobalsPlugin(),\n        make_policy_template_for_function_plugin(),\n    ]\n\n    plugins = [] if not plugins else plugins\n\n    # If a ServerlessAppPlugin does not yet exist, create one and add to the beginning of the required plugins list.\n    if not any(isinstance(plugin, ServerlessAppPlugin) for plugin in plugins):\n        required_plugins.insert(0, ServerlessAppPlugin(parameters=parameters))\n\n    # Execute customer's plugins first before running SAM plugins. It is very important to retain this order because\n    # other plugins will be dependent on this ordering.\n    return SamPlugins(plugins + required_plugins)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef translate(self, sam_template, parameter_values):\n        sam_parameter_values = SamParameterValues(parameter_values)\n        sam_parameter_values.add_default_parameter_values(sam_template)\n        sam_parameter_values.add_pseudo_parameter_values()\n        parameter_values = sam_parameter_values.parameter_values\n        # Create & Install plugins\n        sam_plugins = prepare_plugins(self.plugins, parameter_values)\n\n        self.sam_parser.parse(\n            sam_template=sam_template,\n            parameter_values=parameter_values,\n            sam_plugins=sam_plugins\n        )\n\n        template = copy.deepcopy(sam_template)\n        macro_resolver = ResourceTypeResolver(sam_resources)\n        intrinsics_resolver = IntrinsicsResolver(parameter_values)\n        deployment_preference_collection = DeploymentPreferenceCollection()\n        supported_resource_refs = SupportedResourceReferences()\n        document_errors = []\n        changed_logical_ids = {}\n\n        for logical_id, resource_dict in self._get_resources_to_iterate(sam_template, macro_resolver):\n            try:\n                macro = macro_resolver\\\n                    .resolve_resource_type(resource_dict)\\\n                    .from_dict(logical_id, resource_dict, sam_plugins=sam_plugins)\n\n                kwargs = macro.resources_to_link(sam_template['Resources'])\n                kwargs['managed_policy_map'] = self.managed_policy_map\n                kwargs['intrinsics_resolver'] = intrinsics_resolver\n                kwargs['deployment_preference_collection'] = deployment_preference_collection\n                translated = macro.to_cloudformation(**kwargs)\n\n                supported_resource_refs = macro.get_resource_references(translated, supported_resource_refs)\n\n                # Some resources mutate their logical ids. Track those to change all references to them:\n                if logical_id != macro.logical_id:\n                    changed_logical_ids[logical_id] = macro.logical_id\n\n                del template['Resources'][logical_id]\n                for resource in translated:\n                    if verify_unique_logical_id(resource, sam_template['Resources']):\n                        template['Resources'].update(resource.to_dict())\n                    else:\n                        document_errors.append(DuplicateLogicalIdException(\n                            logical_id, resource.logical_id, resource.resource_type))\n            except (InvalidResourceException, InvalidEventException) as e:\n                document_errors.append(e)\n\n        if deployment_preference_collection.any_enabled():\n            template['Resources'].update(deployment_preference_collection.codedeploy_application.to_dict())\n\n            if not deployment_preference_collection.can_skip_service_role():\n                template['Resources'].update(deployment_preference_collection.codedeploy_iam_role.to_dict())\n\n            for logical_id in deployment_preference_collection.enabled_logical_ids():\n                template['Resources'].update(deployment_preference_collection.deployment_group(logical_id).to_dict())\n\n        # Run the after-transform plugin target\n        try:\n            sam_plugins.act(LifeCycleEvents.after_transform_template, template)\n        except (InvalidDocumentException, InvalidResourceException) as e:\n            document_errors.append(e)\n\n        # Cleanup\n        if 'Transform' in template:\n            del template['Transform']\n\n        if len(document_errors) == 0:\n            template = intrinsics_resolver.resolve_sam_resource_id_refs(template, changed_logical_ids)\n            template = intrinsics_resolver.resolve_sam_resource_refs(template, supported_resource_refs)\n            return template\n        else:\n            raise InvalidDocumentException(document_errors)", "response": "Translate the SAM template into CloudFormation template."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of resources to iterate over based on the given SAM template and macro resolver.", "response": "def _get_resources_to_iterate(self, sam_template, macro_resolver):\n        \"\"\"\n        Returns a list of resources to iterate, order them based on the following order:\n\n            1. AWS::Serverless::Function - because API Events need to modify the corresponding Serverless::Api resource.\n            2. AWS::Serverless::Api\n            3. Anything else\n\n        This is necessary because a Function resource with API Events will modify the API resource's Swagger JSON.\n        Therefore API resource needs to be parsed only after all the Swagger modifications are complete.\n\n        :param dict sam_template: SAM template\n        :param macro_resolver: Resolver that knows if a resource can be processed or not\n        :return list: List containing tuple of (logicalId, resource_dict) in the order of processing\n        \"\"\"\n\n        functions = []\n        apis = []\n        others = []\n        resources = sam_template[\"Resources\"]\n\n        for logicalId, resource in resources.items():\n\n            data = (logicalId, resource)\n\n            # Skip over the resource if it is not a SAM defined Resource\n            if not macro_resolver.can_resolve(resource):\n                continue\n            elif resource[\"Type\"] == \"AWS::Serverless::Function\":\n                functions.append(data)\n            elif resource[\"Type\"] == \"AWS::Serverless::Api\":\n                apis.append(data)\n            else:\n                others.append(data)\n\n        return functions + apis + others"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_dict(cls, logical_id, resource_dict, relative_id=None, sam_plugins=None):\n\n        resource = cls(logical_id, relative_id=relative_id)\n\n        resource._validate_resource_dict(logical_id, resource_dict)\n\n        # Default to empty properties dictionary. If customers skip the Properties section, an empty dictionary\n        # accurately captures the intent.\n        properties = resource_dict.get(\"Properties\", {})\n\n        if sam_plugins:\n            sam_plugins.act(LifeCycleEvents.before_transform_resource, logical_id, cls.resource_type, properties)\n\n        for name, value in properties.items():\n            setattr(resource, name, value)\n\n        if 'DependsOn' in resource_dict:\n            resource.depends_on = resource_dict['DependsOn']\n\n        # Parse only well known properties. This is consistent with earlier behavior where we used to ignore resource\n        # all resource attributes ie. all attributes were unsupported before\n        for attr in resource._supported_resource_attributes:\n            if attr in resource_dict:\n                resource.set_resource_attribute(attr, resource_dict[attr])\n\n        resource.validate_properties()\n        return resource", "response": "Constructs a Resource object from a dictionary containing the logical id and the properties of the resource."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate that the provided logical id is an alphanumeric string.", "response": "def _validate_logical_id(cls, logical_id):\n        \"\"\"Validates that the provided logical id is an alphanumeric string.\n\n        :param str logical_id: the logical id to validate\n        :returns: True if the logical id is valid\n        :rtype: bool\n        :raises TypeError: if the logical id is invalid\n        \"\"\"\n        pattern = re.compile(r'^[A-Za-z0-9]+$')\n        if logical_id is not None and pattern.match(logical_id):\n            return True\n        raise InvalidResourceException(logical_id, \"Logical ids must be alphanumeric.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate that the provided resource dict contains the correct Type string and the required Properties dict.", "response": "def _validate_resource_dict(cls, logical_id, resource_dict):\n        \"\"\"Validates that the provided resource dict contains the correct Type string, and the required Properties dict.\n\n        :param dict resource_dict: the resource dict to validate\n        :returns: True if the resource dict has the expected format\n        :rtype: bool\n        :raises InvalidResourceException: if the resource dict has an invalid format\n        \"\"\"\n        if 'Type' not in resource_dict:\n            raise InvalidResourceException(logical_id, \"Resource dict missing key 'Type'.\")\n        if resource_dict['Type'] != cls.resource_type:\n            raise InvalidResourceException(logical_id, \"Resource has incorrect Type; expected '{expected}', \"\n                                                       \"got '{actual}'\".format(\n                                                            expected=cls.resource_type,\n                                                            actual=resource_dict['Type']))\n\n        if 'Properties' in resource_dict and not isinstance(resource_dict['Properties'], dict):\n            raise InvalidResourceException(logical_id, \"Properties of a resource must be an object.\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_dict(self):\n        self.validate_properties()\n\n        resource_dict = self._generate_resource_dict()\n\n        return {self.logical_id: resource_dict}", "response": "Returns a dict representation of this Resource object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _generate_resource_dict(self):\n        resource_dict = {}\n\n        resource_dict['Type'] = self.resource_type\n\n        if self.depends_on:\n            resource_dict['DependsOn'] = self.depends_on\n\n        resource_dict.update(self.resource_attributes)\n\n        properties_dict = {}\n        for name in self.property_types:\n            value = getattr(self, name)\n            if value is not None:\n                properties_dict[name] = value\n\n        resource_dict['Properties'] = properties_dict\n\n        return resource_dict", "response": "Generates the resource dict for this Resource object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_properties(self):\n        for name, property_type in self.property_types.items():\n            value = getattr(self, name)\n\n            # If the property value is an intrinsic function, any remaining validation has to be left to CloudFormation\n            if property_type.supports_intrinsics and self._is_intrinsic_function(value):\n                continue\n\n            # If the property value has not been set, verify that the property is not required.\n            if value is None:\n                if property_type.required:\n                    raise InvalidResourceException(\n                        self.logical_id,\n                        \"Missing required property '{property_name}'.\".format(property_name=name))\n            # Otherwise, validate the value of the property.\n            elif not property_type.validate(value, should_raise=False):\n                raise InvalidResourceException(\n                    self.logical_id,\n                    \"Type of property '{property_name}' is invalid.\".format(property_name=name))", "response": "Validates that all properties of this resource have been populated and that all properties have valid values."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_resource_attribute(self, attr, value):\n\n        if attr not in self._supported_resource_attributes:\n            raise KeyError(\"Unsupported resource attribute specified: %s\" % attr)\n\n        self.resource_attributes[attr] = value", "response": "Sets the value of the specified attribute on the resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_resource_attribute(self, attr):\n        if attr not in self.resource_attributes:\n            raise KeyError(\"%s is not in resource attributes\" % attr)\n\n        return self.resource_attributes[attr]", "response": "Gets the resource attribute if available."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a CloudFormation construct that provides value for this attribute.", "response": "def get_runtime_attr(self, attr_name):\n        \"\"\"\n        Returns a CloudFormation construct that provides value for this attribute. If the resource does not provide\n        this attribute, then this method raises an exception\n\n        :return: Dictionary that will resolve to value of the attribute when CloudFormation stack update is executed\n        \"\"\"\n\n        if attr_name in self.runtime_attrs:\n            return self.runtime_attrs[attr_name](self)\n        else:\n            raise NotImplementedError(attr_name + \" attribute is not implemented for resource \" + self.resource_type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_resource_references(self, generated_cfn_resources, supported_resource_refs):\n\n        if supported_resource_refs is None:\n            raise ValueError(\"`supported_resource_refs` object is required\")\n\n        # Create a map of {ResourceType: LogicalId} for quick access\n        resource_id_by_type = {resource.resource_type: resource.logical_id for resource in generated_cfn_resources}\n\n        for property, cfn_type in self.referable_properties.items():\n            if cfn_type in resource_id_by_type:\n                supported_resource_refs.add(self.logical_id, property, resource_id_by_type[cfn_type])\n\n        return supported_resource_refs", "response": "Constructs the list of supported resource references by going through the list of generated CFN resources and adding them to the list of supported resource references."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resolve_resource_type(self, resource_dict):\n        if not self.can_resolve(resource_dict):\n            raise TypeError(\"Resource dict has missing or invalid value for key Type. Event Type is: {}.\".format(\n                    resource_dict.get('Type')))\n        if resource_dict['Type'] not in self.resource_types:\n            raise TypeError(\"Invalid resource type {resource_type}\".format(resource_type=resource_dict['Type']))\n        return self.resource_types[resource_dict['Type']]", "response": "Resolves the resource type key in the given resource dict."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding a responseCard with a title subtitle and optional set of options which should be displayed as buttons.", "response": "def build_response_card(title, subtitle, options):\n    \"\"\"\n    Build a responseCard with a title, subtitle, and an optional set of options which should be displayed as buttons.\n    \"\"\"\n    buttons = None\n    if options is not None:\n        buttons = []\n        for i in range(min(5, len(options))):\n            buttons.append(options[i])\n\n    return {\n        'contentType': 'application/vnd.amazonaws.card.generic',\n        'version': 1,\n        'genericAttachments': [{\n            'title': title,\n            'subTitle': subtitle,\n            'buttons': buttons\n        }]\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a random integer between min and max", "response": "def get_random_int(minimum, maximum):\n    \"\"\"\n    Returns a random integer between min (included) and max (excluded)\n    \"\"\"\n    min_int = math.ceil(minimum)\n    max_int = math.floor(maximum)\n\n    return random.randint(min_int, max_int - 1)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_availabilities_for_duration(duration, availabilities):\n    duration_availabilities = []\n    start_time = '10:00'\n    while start_time != '17:00':\n        if start_time in availabilities:\n            if duration == 30:\n                duration_availabilities.append(start_time)\n            elif increment_time_by_thirty_mins(start_time) in availabilities:\n                duration_availabilities.append(start_time)\n\n        start_time = increment_time_by_thirty_mins(start_time)\n\n    return duration_availabilities", "response": "Helper function to return the windows of availability of the given duration."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a string eliciting for a possible time slot among at least two availabilities.", "response": "def build_available_time_string(availabilities):\n    \"\"\"\n    Build a string eliciting for a possible time slot among at least two availabilities.\n    \"\"\"\n    prefix = 'We have availabilities at '\n    if len(availabilities) > 3:\n        prefix = 'We have plenty of availability, including '\n\n    prefix += build_time_output_string(availabilities[0])\n    if len(availabilities) == 2:\n        return '{} and {}'.format(prefix, build_time_output_string(availabilities[1]))\n\n    return '{}, {} and {}'.format(prefix, build_time_output_string(availabilities[1]), build_time_output_string(availabilities[2]))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild a list of potential options for a given appointment type and date.", "response": "def build_options(slot, appointment_type, date, booking_map):\n    \"\"\"\n    Build a list of potential options for a given slot, to be used in responseCard generation.\n    \"\"\"\n    day_strings = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n    if slot == 'AppointmentType':\n        return [\n            {'text': 'cleaning (30 min)', 'value': 'cleaning'},\n            {'text': 'root canal (60 min)', 'value': 'root canal'},\n            {'text': 'whitening (30 min)', 'value': 'whitening'}\n        ]\n    elif slot == 'Date':\n        # Return the next five weekdays.\n        options = []\n        potential_date = datetime.datetime.today()\n        while len(options) < 5:\n            potential_date = potential_date + datetime.timedelta(days=1)\n            if potential_date.weekday() < 5:\n                options.append({'text': '{}-{} ({})'.format((potential_date.month), potential_date.day, day_strings[potential_date.weekday()]),\n                                'value': potential_date.strftime('%A, %B %d, %Y')})\n        return options\n    elif slot == 'Time':\n        # Return the availabilities on the given date.\n        if not appointment_type or not date:\n            return None\n\n        availabilities = try_ex(lambda: booking_map[date])\n        if not availabilities:\n            return None\n\n        availabilities = get_availabilities_for_duration(get_duration(appointment_type), availabilities)\n        if len(availabilities) == 0:\n            return None\n\n        options = []\n        for i in range(min(len(availabilities), 5)):\n            options.append({'text': build_time_output_string(availabilities[i]), 'value': build_time_output_string(availabilities[i])})\n\n        return options"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_appointment(intent_request):\n    appointment_type = intent_request['currentIntent']['slots']['AppointmentType']\n    date = intent_request['currentIntent']['slots']['Date']\n    time = intent_request['currentIntent']['slots']['Time']\n    source = intent_request['invocationSource']\n    output_session_attributes = intent_request['sessionAttributes']\n    booking_map = json.loads(try_ex(lambda: output_session_attributes['bookingMap']) or '{}')\n\n    if source == 'DialogCodeHook':\n        # Perform basic validation on the supplied input slots.\n        slots = intent_request['currentIntent']['slots']\n        validation_result = validate_book_appointment(appointment_type, date, time)\n        if not validation_result['isValid']:\n            slots[validation_result['violatedSlot']] = None\n            return elicit_slot(\n                output_session_attributes,\n                intent_request['currentIntent']['name'],\n                slots,\n                validation_result['violatedSlot'],\n                validation_result['message'],\n                build_response_card(\n                    'Specify {}'.format(validation_result['violatedSlot']),\n                    validation_result['message']['content'],\n                    build_options(validation_result['violatedSlot'], appointment_type, date, booking_map)\n                )\n            )\n\n        if not appointment_type:\n            return elicit_slot(\n                output_session_attributes,\n                intent_request['currentIntent']['name'],\n                intent_request['currentIntent']['slots'],\n                'AppointmentType',\n                {'contentType': 'PlainText', 'content': 'What type of appointment would you like to schedule?'},\n                build_response_card(\n                    'Specify Appointment Type', 'What type of appointment would you like to schedule?',\n                    build_options('AppointmentType', appointment_type, date, None)\n                )\n            )\n\n        if appointment_type and not date:\n            return elicit_slot(\n                output_session_attributes,\n                intent_request['currentIntent']['name'],\n                intent_request['currentIntent']['slots'],\n                'Date',\n                {'contentType': 'PlainText', 'content': 'When would you like to schedule your {}?'.format(appointment_type)},\n                build_response_card(\n                    'Specify Date',\n                    'When would you like to schedule your {}?'.format(appointment_type),\n                    build_options('Date', appointment_type, date, None)\n                )\n            )\n\n        if appointment_type and date:\n            # Fetch or generate the availabilities for the given date.\n            booking_availabilities = try_ex(lambda: booking_map[date])\n            if booking_availabilities is None:\n                booking_availabilities = get_availabilities(date)\n                booking_map[date] = booking_availabilities\n                output_session_attributes['bookingMap'] = json.dumps(booking_map)\n\n            appointment_type_availabilities = get_availabilities_for_duration(get_duration(appointment_type), booking_availabilities)\n            if len(appointment_type_availabilities) == 0:\n                # No availability on this day at all; ask for a new date and time.\n                slots['Date'] = None\n                slots['Time'] = None\n                return elicit_slot(\n                    output_session_attributes,\n                    intent_request['currentIntent']['name'],\n                    slots,\n                    'Date',\n                    {'contentType': 'PlainText', 'content': 'We do not have any availability on that date, is there another day which works for you?'},\n                    build_response_card(\n                        'Specify Date',\n                        'What day works best for you?',\n                        build_options('Date', appointment_type, date, booking_map)\n                    )\n                )\n\n            message_content = 'What time on {} works for you? '.format(date)\n            if time:\n                output_session_attributes['formattedTime'] = build_time_output_string(time)\n                # Validate that proposed time for the appointment can be booked by first fetching the availabilities for the given day.  To\n                # give consistent behavior in the sample, this is stored in sessionAttributes after the first lookup.\n                if is_available(time, get_duration(appointment_type), booking_availabilities):\n                    return delegate(output_session_attributes, slots)\n                message_content = 'The time you requested is not available. '\n\n            if len(appointment_type_availabilities) == 1:\n                # If there is only one availability on the given date, try to confirm it.\n                slots['Time'] = appointment_type_availabilities[0]\n                return confirm_intent(\n                    output_session_attributes,\n                    intent_request['currentIntent']['name'],\n                    slots,\n                    {\n                        'contentType': 'PlainText',\n                        'content': '{}{} is our only availability, does that work for you?'.format\n                                   (message_content, build_time_output_string(appointment_type_availabilities[0]))\n                    },\n                    build_response_card(\n                        'Confirm Appointment',\n                        'Is {} on {} okay?'.format(build_time_output_string(appointment_type_availabilities[0]), date),\n                        [{'text': 'yes', 'value': 'yes'}, {'text': 'no', 'value': 'no'}]\n                    )\n                )\n\n            available_time_string = build_available_time_string(appointment_type_availabilities)\n            return elicit_slot(\n                output_session_attributes,\n                intent_request['currentIntent']['name'],\n                slots,\n                'Time',\n                {'contentType': 'PlainText', 'content': '{}{}'.format(message_content, available_time_string)},\n                build_response_card(\n                    'Specify Time',\n                    'What time works best for you?',\n                    build_options('Time', appointment_type, date, booking_map)\n                )\n            )\n\n        return delegate(output_session_attributes, slots)\n\n    # Book the appointment.  In a real bot, this would likely involve a call to a backend service.\n    duration = get_duration(appointment_type)\n    booking_availabilities = booking_map[date]\n    if booking_availabilities:\n        # Remove the availability slot for the given date as it has now been booked.\n        booking_availabilities.remove(time)\n        if duration == 60:\n            second_half_hour_time = increment_time_by_thirty_mins(time)\n            booking_availabilities.remove(second_half_hour_time)\n\n        booking_map[date] = booking_availabilities\n        output_session_attributes['bookingMap'] = json.dumps(booking_map)\n    else:\n        # This is not treated as an error as this code sample supports functionality either as fulfillment or dialog code hook.\n        logger.debug('Availabilities for {} were null at fulfillment time.  '\n                     'This should have been initialized if this function was configured as the dialog code hook'.format(date))\n\n    return close(\n        output_session_attributes,\n        'Fulfilled',\n        {\n            'contentType': 'PlainText',\n            'content': 'Okay, I have booked your appointment.  We will see you at {} on {}'.format(build_time_output_string(time), date)\n        }\n    )", "response": "Makes an appointment for the specified slot."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dispatch(intent_request):\n\n    logger.debug('dispatch userId={}, intentName={}'.format(intent_request['userId'], intent_request['currentIntent']['name']))\n\n    intent_name = intent_request['currentIntent']['name']\n\n    # Dispatch to your bot's intent handlers\n    if intent_name == 'MakeAppointment':\n        return make_appointment(intent_request)\n    raise Exception('Intent with name ' + intent_name + ' not supported')", "response": "Dispatches the intent request to the appropriate handler."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lambda_handler(event, context):\n    '''Demonstrates a simple HTTP endpoint using API Gateway. You have full\n    access to the request and response payload, including headers and\n    status code.\n\n\tTableName provided by template.yaml.\n\n    To scan a DynamoDB table, make a GET request with optional query string parameter.\n\tTo put, update, or delete an item, make a POST, PUT, or DELETE request respectively,\n\tpassing in the payload to the DynamoDB API as a JSON body.\n    '''\n    print(\"Received event: \" + json.dumps(event, indent=2))\n\n    operations = {\n        'DELETE': lambda dynamo, x: dynamo.delete_item(TableName=table_name, **x),\n\t\t'GET': lambda dynamo, x: dynamo.scan(TableName=table_name, **x) if x else dynamo.scan(TableName=table_name),\n        'POST': lambda dynamo, x: dynamo.put_item(TableName=table_name, **x),\n        'PUT': lambda dynamo, x: dynamo.update_item(TableName=table_name, **x),\n    }\n\n    operation = event['httpMethod']\n    if operation in operations:\n        payload = event['queryStringParameters'] if operation == 'GET' else json.loads(event['body'])\n        return respond(None, operations[operation](dynamo, payload))\n    else:\n        return respond(ValueError('Unsupported method \"{}\"'.format(operation)))", "response": "This function handles the event and returns a response."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lambda_handler(event, context):\n    '''Demonstrates a simple HTTP endpoint using API Gateway. You have full\n    access to the request and response payload, including headers and\n    status code.\n\n    To scan a DynamoDB table, make a GET request with the TableName as a\n    query string parameter. To put, update, or delete an item, make a POST,\n    PUT, or DELETE request respectively, passing in the payload to the\n    DynamoDB API as a JSON body.\n    '''\n    #print(\"Received event: \" + json.dumps(event, indent=2))\n\n    operations = {\n        'DELETE': lambda dynamo, x: dynamo.delete_item(**x),\n        'GET': lambda dynamo, x: dynamo.scan(**x),\n        'POST': lambda dynamo, x: dynamo.put_item(**x),\n        'PUT': lambda dynamo, x: dynamo.update_item(**x),\n    }\n\n    operation = event['httpMethod']\n    if operation in operations:\n        payload = event['queryStringParameters'] if operation == 'GET' else json.loads(event['body'])\n        return respond(None, operations[operation](dynamo, payload))\n    else:\n        return respond(ValueError('Unsupported method \"{}\"'.format(operation)))", "response": "This function handles the event and returns a response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking a combined condition using Fn :: Or.", "response": "def make_combined_condition(conditions_list, condition_name):\n    \"\"\"\n    Makes a combined condition using Fn::Or. Since Fn::Or only accepts up to 10 conditions,\n    this method optionally creates multiple conditions. These conditions are named based on\n    the condition_name parameter that is passed into the method.\n\n    :param list conditions_list: list of conditions\n    :param string condition_name: base name desired for new condition\n    :return: dictionary of condition_name: condition_value\n    \"\"\"\n    if len(conditions_list) < 2:\n        # Can't make a condition if <2 conditions provided.\n        return None\n\n    # Total number of conditions allows in an Fn::Or statement. See docs:\n    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-conditions.html#intrinsic-function-reference-conditions-or\n    max_conditions = 10\n\n    conditions = {}\n    conditions_length = len(conditions_list)\n    # Get number of conditions needed, then minus one to use them as 0-based indices\n    zero_based_num_conditions = calculate_number_of_conditions(conditions_length, max_conditions) - 1\n\n    while len(conditions_list) > 1:\n        new_condition_name = condition_name\n        # If more than 1 new condition is needed, add a number to the end of the name\n        if zero_based_num_conditions > 0:\n            new_condition_name = '{}{}'.format(condition_name, zero_based_num_conditions)\n            zero_based_num_conditions -= 1\n        new_condition_content = make_or_condition(conditions_list[:max_conditions])\n        conditions_list = conditions_list[max_conditions:]\n        conditions_list.append(new_condition_name)\n        conditions[new_condition_name] = new_condition_content\n    return conditions"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the given input is an intrinsic function dictionary.", "response": "def is_instrinsic(input):\n    \"\"\"\n    Checks if the given input is an intrinsic function dictionary. Intrinsic function is a dictionary with single\n    key that is the name of the intrinsics.\n\n    :param input: Input value to check if it is an intrinsic\n    :return: True, if yes\n    \"\"\"\n\n    if input is not None \\\n            and isinstance(input, dict) \\\n            and len(input) == 1:\n\n        key = list(input.keys())[0]\n        return key == \"Ref\" or key == \"Condition\" or key.startswith(\"Fn::\")\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef can_handle(self, input_dict):\n\n        return input_dict is not None \\\n            and isinstance(input_dict, dict) \\\n            and len(input_dict) == 1 \\\n            and self.intrinsic_name in input_dict", "response": "Validates that the input dictionary contains only one key and is of the given intrinsic_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_resource_reference(cls, ref_value):\n        no_result = (None, None)\n\n        if not isinstance(ref_value, string_types):\n            return no_result\n\n        splits = ref_value.split(cls._resource_ref_separator, 1)\n\n        # Either there is no 'dot' (or) one of the values is empty string (Ex: when you split \"LogicalId.\")\n        if len(splits) != 2 or not all(splits):\n            return no_result\n\n        return splits[0], splits[1]", "response": "Splits a resource reference of structure LogicalId. Property and returns the LogicalId and Property separately."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resolve_parameter_refs(self, input_dict, parameters):\n        if not self.can_handle(input_dict):\n            return input_dict\n\n        param_name = input_dict[self.intrinsic_name]\n\n        if not isinstance(param_name, string_types):\n            return input_dict\n\n        if param_name in parameters:\n            return parameters[param_name]\n        else:\n            return input_dict", "response": "Resolves references that are present in the parameters and returns the value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resolve_resource_refs(self, input_dict, supported_resource_refs):\n\n        if not self.can_handle(input_dict):\n            return input_dict\n\n        ref_value = input_dict[self.intrinsic_name]\n        logical_id, property = self._parse_resource_reference(ref_value)\n\n        # ref_value could not be parsed\n        if not logical_id:\n            return input_dict\n\n        resolved_value = supported_resource_refs.get(logical_id, property)\n        if not resolved_value:\n            return input_dict\n\n        return {\n            self.intrinsic_name: resolved_value\n        }", "response": "Resolves references to some property of a resource."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nresolve the Ref function to the new logical id of a resource.", "response": "def resolve_resource_id_refs(self, input_dict, supported_resource_id_refs):\n        \"\"\"\n        Updates references to the old logical id of a resource to the new (generated) logical id.\n\n        Example:\n            {\"Ref\": \"MyLayer\"} => {\"Ref\": \"MyLayerABC123\"}\n\n        :param dict input_dict: Dictionary representing the Ref function to be resolved.\n        :param dict supported_resource_id_refs: Dictionary that maps old logical ids to new ones.\n        :return dict: Dictionary with resource references resolved.\n        \"\"\"\n\n        if not self.can_handle(input_dict):\n            return input_dict\n\n        ref_value = input_dict[self.intrinsic_name]\n        if not isinstance(ref_value, string_types) or self._resource_ref_separator in ref_value:\n            return input_dict\n\n        logical_id = ref_value\n\n        resolved_value = supported_resource_id_refs.get(logical_id)\n        if not resolved_value:\n            return input_dict\n\n        return {\n            self.intrinsic_name: resolved_value\n        }"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nresolve the parameter references found within the string of Fn :: Sub intrinsic function .", "response": "def resolve_parameter_refs(self, input_dict, parameters):\n        \"\"\"\n        Substitute references found within the string of `Fn::Sub` intrinsic function\n\n        :param input_dict: Dictionary representing the Fn::Sub function. Must contain only one key and it should be\n            `Fn::Sub`. Ex: {\"Fn::Sub\": ...}\n\n        :param parameters: Dictionary of parameter values for substitution\n        :return: Resolved\n        \"\"\"\n\n        def do_replacement(full_ref, prop_name):\n            \"\"\"\n            Replace parameter references with actual value. Return value of this method is directly replaces the\n            reference structure\n\n            :param full_ref: => ${logicalId.property}\n            :param prop_name: => logicalId.property\n            :return: Either the value it resolves to. If not the original reference\n            \"\"\"\n            return parameters.get(prop_name, full_ref)\n\n        return self._handle_sub_action(input_dict, do_replacement)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nresolves reference to some property of a resource.", "response": "def resolve_resource_refs(self, input_dict, supported_resource_refs):\n        \"\"\"\n        Resolves reference to some property of a resource. Inside string to be substituted, there could be either a\n        \"Ref\" or a \"GetAtt\" usage of this property. They have to be handled differently.\n\n        Ref usages are directly converted to a Ref on the resolved value. GetAtt usages are split under the assumption\n        that there can be only one property of resource referenced here. Everything else is an attribute reference.\n\n        Example:\n\n            Let's say `LogicalId.Property` will be resolved to `ResolvedValue`\n\n            Ref usage:\n                ${LogicalId.Property}  => ${ResolvedValue}\n\n            GetAtt usage:\n                ${LogicalId.Property.Arn} => ${ResolvedValue.Arn}\n                ${LogicalId.Property.Attr1.Attr2} => {ResolvedValue.Attr1.Attr2}\n\n\n        :param input_dict: Dictionary to be resolved\n        :param samtranslator.intrinsics.resource_refs.SupportedResourceReferences supported_resource_refs: Instance of\n            an `SupportedResourceReferences` object that contain value of the property.\n        :return: Resolved dictionary\n        \"\"\"\n\n        def do_replacement(full_ref, ref_value):\n            \"\"\"\n            Perform the appropriate replacement to handle ${LogicalId.Property} type references inside a Sub.\n            This method is called to get the replacement string for each reference within Sub's value\n\n            :param full_ref: Entire reference string such as \"${LogicalId.Property}\"\n            :param ref_value: Just the value of the reference such as \"LogicalId.Property\"\n            :return: Resolved reference of the structure \"${SomeOtherLogicalId}\". Result should always include the\n                ${} structure since we are not resolving to final value, but just converting one reference to another\n            \"\"\"\n\n            # Split the value by separator, expecting to separate out LogicalId.Property\n            splits = ref_value.split(self._resource_ref_separator)\n\n            # If we don't find at least two parts, there is nothing to resolve\n            if len(splits) < 2:\n                return full_ref\n\n            logical_id = splits[0]\n            property = splits[1]\n            resolved_value = supported_resource_refs.get(logical_id, property)\n            if not resolved_value:\n                # This ID/property combination is not in the supported references\n                return full_ref\n\n            # We found a LogicalId.Property combination that can be resolved. Construct the output by replacing\n            # the part of the reference string and not constructing a new ref. This allows us to support GetAtt-like\n            # syntax and retain other attributes. Ex: ${LogicalId.Property.Arn} => ${SomeOtherLogicalId.Arn}\n            replacement = self._resource_ref_separator.join([logical_id, property])\n            return full_ref.replace(replacement, resolved_value)\n\n        return self._handle_sub_action(input_dict, do_replacement)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresolves the resource id references in the given dictionary.", "response": "def resolve_resource_id_refs(self, input_dict, supported_resource_id_refs):\n        \"\"\"\n        Resolves reference to some property of a resource. Inside string to be substituted, there could be either a\n        \"Ref\" or a \"GetAtt\" usage of this property. They have to be handled differently.\n\n        Ref usages are directly converted to a Ref on the resolved value. GetAtt usages are split under the assumption\n        that there can be only one property of resource referenced here. Everything else is an attribute reference.\n\n        Example:\n\n            Let's say `LogicalId` will be resolved to `NewLogicalId`\n\n            Ref usage:\n                ${LogicalId}  => ${NewLogicalId}\n\n            GetAtt usage:\n                ${LogicalId.Arn} => ${NewLogicalId.Arn}\n                ${LogicalId.Attr1.Attr2} => {NewLogicalId.Attr1.Attr2}\n\n\n        :param input_dict: Dictionary to be resolved\n        :param dict supported_resource_id_refs: Dictionary that maps old logical ids to new ones.\n        :return: Resolved dictionary\n        \"\"\"\n\n        def do_replacement(full_ref, ref_value):\n            \"\"\"\n            Perform the appropriate replacement to handle ${LogicalId} type references inside a Sub.\n            This method is called to get the replacement string for each reference within Sub's value\n\n            :param full_ref: Entire reference string such as \"${LogicalId.Property}\"\n            :param ref_value: Just the value of the reference such as \"LogicalId.Property\"\n            :return: Resolved reference of the structure \"${SomeOtherLogicalId}\". Result should always include the\n                ${} structure since we are not resolving to final value, but just converting one reference to another\n            \"\"\"\n\n            # Split the value by separator, expecting to separate out LogicalId\n            splits = ref_value.split(self._resource_ref_separator)\n\n            # If we don't find at least one part, there is nothing to resolve\n            if len(splits) < 1:\n                return full_ref\n\n            logical_id = splits[0]\n            resolved_value = supported_resource_id_refs.get(logical_id)\n            if not resolved_value:\n                # This ID/property combination is not in the supported references\n                return full_ref\n\n            # We found a LogicalId.Property combination that can be resolved. Construct the output by replacing\n            # the part of the reference string and not constructing a new ref. This allows us to support GetAtt-like\n            # syntax and retain other attributes. Ex: ${LogicalId.Property.Arn} => ${SomeOtherLogicalId.Arn}\n            return full_ref.replace(logical_id, resolved_value)\n\n        return self._handle_sub_action(input_dict, do_replacement)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _handle_sub_action(self, input_dict, handler):\n        if not self.can_handle(input_dict):\n            return input_dict\n\n        key = self.intrinsic_name\n        sub_value = input_dict[key]\n\n        input_dict[key] = self._handle_sub_value(sub_value, handler)\n\n        return input_dict", "response": "Handles resolving replacements in the Sub action based on the handler that is passed as an input."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling the value of the Fn :: Sub key.", "response": "def _handle_sub_value(self, sub_value, handler_method):\n        \"\"\"\n        Generic method to handle value to Fn::Sub key. We are interested in parsing the ${} syntaxes inside\n        the string portion of the value.\n\n        :param sub_value: Value of the Sub function\n        :param handler_method: Method to be called on every occurrence of `${LogicalId}` structure within the string.\n            Implementation could resolve and replace this structure with whatever they seem fit\n        :return: Resolved value of the Sub dictionary\n        \"\"\"\n\n        # Just handle known references within the string to be substituted and return the whole dictionary\n        # because that's the best we can do here.\n        if isinstance(sub_value, string_types):\n            # Ex: {Fn::Sub: \"some string\"}\n            sub_value = self._sub_all_refs(sub_value, handler_method)\n\n        elif isinstance(sub_value, list) and len(sub_value) > 0 and isinstance(sub_value[0], string_types):\n            # Ex: {Fn::Sub: [\"some string\", {a:b}] }\n            sub_value[0] = self._sub_all_refs(sub_value[0], handler_method)\n\n        return sub_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsubstitutes references within a string that is using the syntax specified by handler_method.", "response": "def _sub_all_refs(self, text, handler_method):\n        \"\"\"\n        Substitute references within a string that is using ${key} syntax by calling the `handler_method` on every\n        occurrence of this structure. The value returned by this method directly replaces the reference structure.\n\n        Ex:\n            text = \"${key1}-hello-${key2}\n            def handler_method(full_ref, ref_value):\n                return \"foo\"\n\n            _sub_all_refs(text, handler_method) will output \"foo-hello-foo\"\n\n        :param string text: Input text\n        :param handler_method: Method to be called to handle each occurrence of ${blah} reference structure.\n            First parameter to this method is the full reference structure Ex: ${LogicalId.Property}.\n            Second parameter is just the value of the reference such as \"LogicalId.Property\"\n\n        :return string: Text with all reference structures replaced as necessary\n        \"\"\"\n\n        # RegExp to find pattern \"${logicalId.property}\" and return the word inside bracket\n        logical_id_regex = '[A-Za-z0-9\\.]+|AWS::[A-Z][A-Za-z]*'\n        ref_pattern = re.compile(r'\\$\\{(' + logical_id_regex + ')\\}')\n\n        # Find all the pattern, and call the handler to decide how to substitute them.\n        # Do the substitution and return the final text\n        return re.sub(ref_pattern,\n                      # Pass the handler entire string ${logicalId.property} as first parameter and \"logicalId.property\"\n                      # as second parameter. Return value will be substituted\n                      lambda match: handler_method(match.group(0), match.group(1)),\n                      text)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resolve_resource_refs(self, input_dict, supported_resource_refs):\n\n        if not self.can_handle(input_dict):\n            return input_dict\n\n        key = self.intrinsic_name\n        value = input_dict[key]\n\n        # Value must be an array with *at least* two elements. If not, this is invalid GetAtt syntax. We just pass along\n        # the input to CFN for it to do the \"official\" validation.\n        if not isinstance(value, list) or len(value) < 2:\n            return input_dict\n\n        if (not all(isinstance(entry, string_types) for entry in value)):\n            raise InvalidDocumentException(\n                [InvalidTemplateException('Invalid GetAtt value {}. GetAtt expects an array with 2 strings.'\n                                          .format(value))])\n\n        # Value of GetAtt is an array. It can contain any number of elements, with first being the LogicalId of\n        # resource and rest being the attributes. In a SAM template, a reference to a resource can be used in the\n        # first parameter. However tools like AWS CLI might break them down as well. So let's just concatenate\n        # all elements, and break them into separate parts in a more standard way.\n        #\n        # Example:\n        #   { Fn::GetAtt: [\"LogicalId.Property\", \"Arn\"] } is equivalent to { Fn::GetAtt: [\"LogicalId\", \"Property.Arn\"] }\n        #   Former is the correct notation. However tools like AWS CLI can construct the later style.\n        #   Let's normalize the value into \"LogicalId.Property.Arn\" to handle both scenarios\n\n        value_str = self._resource_ref_separator.join(value)\n        splits = value_str.split(self._resource_ref_separator)\n        logical_id = splits[0]\n        property = splits[1]\n        remaining = splits[2:]  # if any\n\n        resolved_value = supported_resource_refs.get(logical_id, property)\n        return self._get_resolved_dictionary(input_dict, key, resolved_value, remaining)", "response": "Resolves resource references within a GetAtt dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resolve_resource_id_refs(self, input_dict, supported_resource_id_refs):\n\n        if not self.can_handle(input_dict):\n            return input_dict\n\n        key = self.intrinsic_name\n        value = input_dict[key]\n\n        # Value must be an array with *at least* two elements. If not, this is invalid GetAtt syntax. We just pass along\n        # the input to CFN for it to do the \"official\" validation.\n        if not isinstance(value, list) or len(value) < 2:\n            return input_dict\n\n        value_str = self._resource_ref_separator.join(value)\n        splits = value_str.split(self._resource_ref_separator)\n        logical_id = splits[0]\n        remaining = splits[1:]  # if any\n\n        resolved_value = supported_resource_id_refs.get(logical_id)\n        return self._get_resolved_dictionary(input_dict, key, resolved_value, remaining)", "response": "Resolve resource references within a GetAtt dict."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresolving the function and returns the updated dictionary with the new value", "response": "def _get_resolved_dictionary(self, input_dict, key, resolved_value, remaining):\n        \"\"\"\n        Resolves the function and returns the updated dictionary\n\n        :param input_dict: Dictionary to be resolved\n        :param key: Name of this intrinsic.\n        :param resolved_value: Resolved or updated value for this action.\n        :param remaining: Remaining sections for the GetAtt action.\n        \"\"\"\n        if resolved_value:\n            # We resolved to a new resource logicalId. Use this as the first element and keep remaining elements intact\n            # This is the new value of Fn::GetAtt\n            input_dict[key] = [resolved_value] + remaining\n\n        return input_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nresolve FindInMap references that are present in the SAM template and returns the value.", "response": "def resolve_parameter_refs(self, input_dict, parameters):\n        \"\"\"\n        Recursively resolves \"Fn::FindInMap\"references that are present in the mappings and returns the value.\n        If it is not in mappings, this method simply returns the input unchanged.\n\n        :param input_dict: Dictionary representing the FindInMap function. Must contain only one key and it\n                           should be \"Fn::FindInMap\".\n\n        :param parameters: Dictionary of mappings from the SAM template\n        \"\"\"\n        if not self.can_handle(input_dict):\n            return input_dict\n\n        value = input_dict[self.intrinsic_name]\n\n        # FindInMap expects an array with 3 values\n        if not isinstance(value, list) or len(value) != 3:\n            raise InvalidDocumentException(\n                [InvalidTemplateException('Invalid FindInMap value {}. FindInMap expects an array with 3 values.'\n                                          .format(value))])\n\n        map_name = self.resolve_parameter_refs(value[0], parameters)\n        top_level_key = self.resolve_parameter_refs(value[1], parameters)\n        second_level_key = self.resolve_parameter_refs(value[2], parameters)\n\n        if not isinstance(map_name, string_types) or \\\n                not isinstance(top_level_key, string_types) or \\\n                not isinstance(second_level_key, string_types):\n            return input_dict\n\n        if map_name not in parameters or \\\n                top_level_key not in parameters[map_name] or \\\n                second_level_key not in parameters[map_name][top_level_key]:\n            return input_dict\n\n        return parameters[map_name][top_level_key][second_level_key]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprocess a RDS enhenced monitoring DATA_MESSAGE coming from CLOUDWATCH LOGS", "response": "def lambda_handler(event, context):\n    ''' Process a RDS enhenced monitoring DATA_MESSAGE,\n        coming from CLOUDWATCH LOGS\n    '''\n    # event is a dict containing a base64 string gzipped\n    event = json.loads(gzip.GzipFile(fileobj=StringIO(event['awslogs']['data'].decode('base64'))).read())\n\n    account = event['owner']\n    region = context.invoked_function_arn.split(':', 4)[3]\n\n    log_events = event['logEvents']\n\n    for log_event in log_events:\n        message = json.loads(log_event['message'])\n        ts = log_event['timestamp'] / 1000\n        _process_rds_enhanced_monitoring_message(ts, message, account, region)\n\n    stats.flush()\n    return {'Status': 'OK'}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _construct_rest_api(self):\n        rest_api = ApiGatewayRestApi(self.logical_id, depends_on=self.depends_on, attributes=self.resource_attributes)\n        rest_api.BinaryMediaTypes = self.binary_media\n        rest_api.MinimumCompressionSize = self.minimum_compression_size\n\n        if self.endpoint_configuration:\n            self._set_endpoint_configuration(rest_api, self.endpoint_configuration)\n\n        elif not RegionConfiguration.is_apigw_edge_configuration_supported():\n            # Since this region does not support EDGE configuration, we explicitly set the endpoint type\n            # to Regional which is the only supported config.\n            self._set_endpoint_configuration(rest_api, \"REGIONAL\")\n\n        if self.definition_uri and self.definition_body:\n            raise InvalidResourceException(self.logical_id,\n                                           \"Specify either 'DefinitionUri' or 'DefinitionBody' property and not both\")\n\n        self._add_cors()\n        self._add_auth()\n        self._add_gateway_responses()\n\n        if self.definition_uri:\n            rest_api.BodyS3Location = self._construct_body_s3_dict()\n        elif self.definition_body:\n            rest_api.Body = self.definition_body\n\n        if self.name:\n            rest_api.Name = self.name\n\n        return rest_api", "response": "Constructs and returns the ApiGateway RestApi object for this SAM Api."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconstruct the RestApi s BodyS3Location property_ from the SAM Api s DefinitionUri property.", "response": "def _construct_body_s3_dict(self):\n        \"\"\"Constructs the RestApi's `BodyS3Location property`_, from the SAM Api's DefinitionUri property.\n\n        :returns: a BodyS3Location dict, containing the S3 Bucket, Key, and Version of the Swagger definition\n        :rtype: dict\n        \"\"\"\n        if isinstance(self.definition_uri, dict):\n            if not self.definition_uri.get(\"Bucket\", None) or not self.definition_uri.get(\"Key\", None):\n                # DefinitionUri is a dictionary but does not contain Bucket or Key property\n                raise InvalidResourceException(self.logical_id,\n                                               \"'DefinitionUri' requires Bucket and Key properties to be specified\")\n            s3_pointer = self.definition_uri\n\n        else:\n\n            # DefinitionUri is a string\n            s3_pointer = parse_s3_uri(self.definition_uri)\n            if s3_pointer is None:\n                raise InvalidResourceException(self.logical_id,\n                                               '\\'DefinitionUri\\' is not a valid S3 Uri of the form '\n                                               '\"s3://bucket/key\" with optional versionId query parameter.')\n\n        body_s3 = {\n            'Bucket': s3_pointer['Bucket'],\n            'Key': s3_pointer['Key']\n        }\n        if 'Version' in s3_pointer:\n            body_s3['Version'] = s3_pointer['Version']\n        return body_s3"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _construct_deployment(self, rest_api):\n        deployment = ApiGatewayDeployment(self.logical_id + 'Deployment',\n                                          attributes=self.passthrough_resource_attributes)\n        deployment.RestApiId = rest_api.get_runtime_attr('rest_api_id')\n        deployment.StageName = 'Stage'\n\n        return deployment", "response": "Constructs and returns the ApiGateway Deployment."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconstructs and returns the ApiGateway Stage.", "response": "def _construct_stage(self, deployment, swagger):\n        \"\"\"Constructs and returns the ApiGateway Stage.\n\n        :param model.apigateway.ApiGatewayDeployment deployment: the Deployment for this Stage\n        :returns: the Stage to which this SAM Api corresponds\n        :rtype: model.apigateway.ApiGatewayStage\n        \"\"\"\n\n        # If StageName is some intrinsic function, then don't prefix the Stage's logical ID\n        # This will NOT create duplicates because we allow only ONE stage per API resource\n        stage_name_prefix = self.stage_name if isinstance(self.stage_name, string_types) else \"\"\n\n        stage = ApiGatewayStage(self.logical_id + stage_name_prefix + 'Stage',\n                                attributes=self.passthrough_resource_attributes)\n        stage.RestApiId = ref(self.logical_id)\n        stage.update_deployment_ref(deployment.logical_id)\n        stage.StageName = self.stage_name\n        stage.CacheClusterEnabled = self.cache_cluster_enabled\n        stage.CacheClusterSize = self.cache_cluster_size\n        stage.Variables = self.variables\n        stage.MethodSettings = self.method_settings\n        stage.AccessLogSetting = self.access_log_setting\n        stage.CanarySetting = self.canary_setting\n        stage.TracingEnabled = self.tracing_enabled\n\n        if swagger is not None:\n            deployment.make_auto_deployable(stage, swagger)\n\n        return stage"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_cloudformation(self):\n\n        rest_api = self._construct_rest_api()\n        deployment = self._construct_deployment(rest_api)\n\n        swagger = None\n        if rest_api.Body is not None:\n            swagger = rest_api.Body\n        elif rest_api.BodyS3Location is not None:\n            swagger = rest_api.BodyS3Location\n\n        stage = self._construct_stage(deployment, swagger)\n        permissions = self._construct_authorizer_lambda_permission()\n\n        return rest_api, deployment, stage, permissions", "response": "Generates a CloudFormation resource from a SAM API resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_cors(self):\n\n        INVALID_ERROR = \"Invalid value for 'Cors' property\"\n\n        if not self.cors:\n            return\n\n        if self.cors and not self.definition_body:\n            raise InvalidResourceException(self.logical_id,\n                                           \"Cors works only with inline Swagger specified in \"\n                                           \"'DefinitionBody' property\")\n\n        if isinstance(self.cors, string_types) or is_instrinsic(self.cors):\n            # Just set Origin property. Others will be defaults\n            properties = CorsProperties(AllowOrigin=self.cors)\n        elif isinstance(self.cors, dict):\n\n            # Make sure keys in the dict are recognized\n            if not all(key in CorsProperties._fields for key in self.cors.keys()):\n                raise InvalidResourceException(self.logical_id, INVALID_ERROR)\n\n            properties = CorsProperties(**self.cors)\n\n        else:\n            raise InvalidResourceException(self.logical_id, INVALID_ERROR)\n\n        if not SwaggerEditor.is_valid(self.definition_body):\n            raise InvalidResourceException(self.logical_id, \"Unable to add Cors configuration because \"\n                                                            \"'DefinitionBody' does not contain a valid Swagger\")\n\n        if properties.AllowCredentials is True and properties.AllowOrigin == _CORS_WILDCARD:\n            raise InvalidResourceException(self.logical_id, \"Unable to add Cors configuration because \"\n                                                            \"'AllowCredentials' can not be true when \"\n                                                            \"'AllowOrigin' is \\\"'*'\\\" or not set\")\n\n        editor = SwaggerEditor(self.definition_body)\n        for path in editor.iter_on_path():\n            editor.add_cors(path, properties.AllowOrigin, properties.AllowHeaders, properties.AllowMethods,\n                            max_age=properties.MaxAge, allow_credentials=properties.AllowCredentials)\n\n        # Assign the Swagger back to template\n        self.definition_body = editor.swagger", "response": "Add CORS configuration to the Swagger file if necessary"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd Auth configuration to the Swagger file if necessary", "response": "def _add_auth(self):\n        \"\"\"\n        Add Auth configuration to the Swagger file, if necessary\n        \"\"\"\n\n        if not self.auth:\n            return\n\n        if self.auth and not self.definition_body:\n            raise InvalidResourceException(self.logical_id,\n                                           \"Auth works only with inline Swagger specified in \"\n                                           \"'DefinitionBody' property\")\n\n        # Make sure keys in the dict are recognized\n        if not all(key in AuthProperties._fields for key in self.auth.keys()):\n            raise InvalidResourceException(\n                self.logical_id, \"Invalid value for 'Auth' property\")\n\n        if not SwaggerEditor.is_valid(self.definition_body):\n            raise InvalidResourceException(self.logical_id, \"Unable to add Auth configuration because \"\n                                                            \"'DefinitionBody' does not contain a valid Swagger\")\n        swagger_editor = SwaggerEditor(self.definition_body)\n        auth_properties = AuthProperties(**self.auth)\n        authorizers = self._get_authorizers(auth_properties.Authorizers, auth_properties.DefaultAuthorizer)\n\n        if authorizers:\n            swagger_editor.add_authorizers(authorizers)\n            self._set_default_authorizer(swagger_editor, authorizers, auth_properties.DefaultAuthorizer)\n\n        # Assign the Swagger back to template\n        self.definition_body = swagger_editor.swagger"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding Gateway Response configuration to the Swagger file if necessary", "response": "def _add_gateway_responses(self):\n        \"\"\"\n        Add Gateway Response configuration to the Swagger file, if necessary\n        \"\"\"\n\n        if not self.gateway_responses:\n            return\n\n        if self.gateway_responses and not self.definition_body:\n            raise InvalidResourceException(\n                self.logical_id, \"GatewayResponses works only with inline Swagger specified in \"\n                                 \"'DefinitionBody' property\")\n\n        # Make sure keys in the dict are recognized\n        for responses_key, responses_value in self.gateway_responses.items():\n            for response_key in responses_value.keys():\n                if response_key not in GatewayResponseProperties:\n                    raise InvalidResourceException(\n                        self.logical_id,\n                        \"Invalid property '{}' in 'GatewayResponses' property '{}'\".format(response_key, responses_key))\n\n        if not SwaggerEditor.is_valid(self.definition_body):\n            raise InvalidResourceException(\n                self.logical_id, \"Unable to add Auth configuration because \"\n                                 \"'DefinitionBody' does not contain a valid Swagger\")\n\n        swagger_editor = SwaggerEditor(self.definition_body)\n\n        gateway_responses = {}\n        for response_type, response in self.gateway_responses.items():\n            gateway_responses[response_type] = ApiGatewayResponse(\n                api_logical_id=self.logical_id,\n                response_parameters=response.get('ResponseParameters', {}),\n                response_templates=response.get('ResponseTemplates', {}),\n                status_code=response.get('StatusCode', None)\n            )\n\n        if gateway_responses:\n            swagger_editor.add_gateway_responses(gateway_responses)\n\n        # Assign the Swagger back to template\n        self.definition_body = swagger_editor.swagger"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconstructing and returns the Lambda Permission resource allowing the Authorizer to invoke the function.", "response": "def _get_permission(self, authorizer_name, authorizer_lambda_function_arn):\n        \"\"\"Constructs and returns the Lambda Permission resource allowing the Authorizer to invoke the function.\n\n        :returns: the permission resource\n        :rtype: model.lambda_.LambdaPermission\n        \"\"\"\n        rest_api = ApiGatewayRestApi(self.logical_id, depends_on=self.depends_on, attributes=self.resource_attributes)\n        api_id = rest_api.get_runtime_attr('rest_api_id')\n\n        partition = ArnGenerator.get_partition_name()\n        resource = '${__ApiId__}/authorizers/*'\n        source_arn = fnSub(ArnGenerator.generate_arn(partition=partition, service='execute-api', resource=resource),\n                           {\"__ApiId__\": api_id})\n\n        lambda_permission = LambdaPermission(self.logical_id + authorizer_name + 'AuthorizerPermission',\n                                             attributes=self.passthrough_resource_attributes)\n        lambda_permission.Action = 'lambda:invokeFunction'\n        lambda_permission.FunctionName = authorizer_lambda_function_arn\n        lambda_permission.Principal = 'apigateway.amazonaws.com'\n        lambda_permission.SourceArn = source_arn\n\n        return lambda_permission"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_endpoint_configuration(self, rest_api, value):\n\n        rest_api.EndpointConfiguration = {\"Types\": [value]}\n        rest_api.Parameters = {\"endpointConfigurationTypes\": value}", "response": "Sets the endpoint configuration property of AWS ::ApiGateway :: RestApi"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert this SAM Function into a CloudFormation resource list.", "response": "def to_cloudformation(self, **kwargs):\n        \"\"\"Returns the Lambda function, role, and event resources to which this SAM Function corresponds.\n\n        :param dict kwargs: already-converted resources that may need to be modified when converting this \\\n        macro to pure CloudFormation\n        :returns: a list of vanilla CloudFormation Resources, to which this Function expands\n        :rtype: list\n        \"\"\"\n        resources = []\n        intrinsics_resolver = kwargs[\"intrinsics_resolver\"]\n\n        if self.DeadLetterQueue:\n            self._validate_dlq()\n\n        lambda_function = self._construct_lambda_function()\n        resources.append(lambda_function)\n\n        lambda_alias = None\n        if self.AutoPublishAlias:\n            alias_name = self._get_resolved_alias_name(\"AutoPublishAlias\", self.AutoPublishAlias, intrinsics_resolver)\n            lambda_version = self._construct_version(lambda_function, intrinsics_resolver=intrinsics_resolver)\n            lambda_alias = self._construct_alias(alias_name, lambda_function, lambda_version)\n            resources.append(lambda_version)\n            resources.append(lambda_alias)\n\n        if self.DeploymentPreference:\n            self._validate_deployment_preference_and_add_update_policy(kwargs.get('deployment_preference_collection',\n                                                                                  None),\n                                                                       lambda_alias, intrinsics_resolver)\n\n        managed_policy_map = kwargs.get('managed_policy_map', {})\n        if not managed_policy_map:\n            raise Exception('Managed policy map is empty, but should not be.')\n\n        execution_role = None\n        if lambda_function.Role is None:\n            execution_role = self._construct_role(managed_policy_map)\n            lambda_function.Role = execution_role.get_runtime_attr('arn')\n            resources.append(execution_role)\n\n        try:\n            resources += self._generate_event_resources(lambda_function, execution_role, kwargs['event_resources'],\n                                                        lambda_alias=lambda_alias)\n        except InvalidEventException as e:\n            raise InvalidResourceException(self.logical_id, e.message)\n\n        return resources"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\naliasing names can be supplied as an intrinsic function. This method tries to extract alias name from a reference to a parameter. If it cannot completely resolve (ie. if a complex intrinsic function was used), then this method raises an exception. If alias name is just a plain string, it will return as is :param dict or string original_alias_value: Value of Alias property as provided by the customer :param samtranslator.intrinsics.resolver.IntrinsicsResolver intrinsics_resolver: Instance of the resolver that knows how to resolve parameter references :return string: Alias name :raises InvalidResourceException: If the value is a complex intrinsic function that cannot be resolved", "response": "def _get_resolved_alias_name(self, property_name, original_alias_value, intrinsics_resolver):\n        \"\"\"\n        Alias names can be supplied as an intrinsic function. This method tries to extract alias name from a reference\n        to a parameter. If it cannot completely resolve (ie. if a complex intrinsic function was used), then this\n        method raises an exception. If alias name is just a plain string, it will return as is\n\n        :param dict or string original_alias_value: Value of Alias property as provided by the customer\n        :param samtranslator.intrinsics.resolver.IntrinsicsResolver intrinsics_resolver: Instance of the resolver that\n            knows how to resolve parameter references\n        :return string: Alias name\n        :raises InvalidResourceException: If the value is a complex intrinsic function that cannot be resolved\n        \"\"\"\n\n        # Try to resolve.\n        resolved_alias_name = intrinsics_resolver.resolve_parameter_refs(original_alias_value)\n\n        if not isinstance(resolved_alias_name, string_types):\n            # This is still a dictionary which means we are not able to completely resolve intrinsics\n            raise InvalidResourceException(self.logical_id,\n                                           \"'{}' must be a string or a Ref to a template parameter\"\n                                           .format(property_name))\n\n        return resolved_alias_name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconstruct and returns the Lambda function.", "response": "def _construct_lambda_function(self):\n        \"\"\"Constructs and returns the Lambda function.\n\n        :returns: a list containing the Lambda function and execution role resources\n        :rtype: list\n        \"\"\"\n        lambda_function = LambdaFunction(self.logical_id, depends_on=self.depends_on,\n                                         attributes=self.resource_attributes)\n\n        if self.FunctionName:\n            lambda_function.FunctionName = self.FunctionName\n\n        lambda_function.Handler = self.Handler\n        lambda_function.Runtime = self.Runtime\n        lambda_function.Description = self.Description\n        lambda_function.MemorySize = self.MemorySize\n        lambda_function.Timeout = self.Timeout\n        lambda_function.VpcConfig = self.VpcConfig\n        lambda_function.Role = self.Role\n        lambda_function.Environment = self.Environment\n        lambda_function.Code = self._construct_code_dict()\n        lambda_function.KmsKeyArn = self.KmsKeyArn\n        lambda_function.ReservedConcurrentExecutions = self.ReservedConcurrentExecutions\n        lambda_function.Tags = self._construct_tag_list(self.Tags)\n        lambda_function.Layers = self.Layers\n\n        if self.Tracing:\n            lambda_function.TracingConfig = {\"Mode\": self.Tracing}\n\n        if self.DeadLetterQueue:\n            lambda_function.DeadLetterConfig = {\"TargetArn\": self.DeadLetterQueue['TargetArn']}\n\n        return lambda_function"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconstructs a Lambda execution role based on this SAM function s Policies property.", "response": "def _construct_role(self, managed_policy_map):\n        \"\"\"Constructs a Lambda execution role based on this SAM function's Policies property.\n\n        :returns: the generated IAM Role\n        :rtype: model.iam.IAMRole\n        \"\"\"\n        execution_role = IAMRole(self.logical_id + 'Role', attributes=self.get_passthrough_resource_attributes())\n        execution_role.AssumeRolePolicyDocument = IAMRolePolicies.lambda_assume_role_policy()\n\n        managed_policy_arns = [ArnGenerator.generate_aws_managed_policy_arn('service-role/AWSLambdaBasicExecutionRole')]\n        if self.Tracing:\n            managed_policy_arns.append(ArnGenerator.generate_aws_managed_policy_arn('AWSXrayWriteOnlyAccess'))\n\n        function_policies = FunctionPolicies({\"Policies\": self.Policies},\n                                             # No support for policy templates in the \"core\"\n                                             policy_template_processor=None)\n        policy_documents = []\n\n        if self.DeadLetterQueue:\n            policy_documents.append(IAMRolePolicies.dead_letter_queue_policy(\n                self.dead_letter_queue_policy_actions[self.DeadLetterQueue['Type']],\n                self.DeadLetterQueue['TargetArn']))\n\n        for index, policy_entry in enumerate(function_policies.get()):\n\n            if policy_entry.type is PolicyTypes.POLICY_STATEMENT:\n\n                policy_documents.append({\n                    'PolicyName': execution_role.logical_id + 'Policy' + str(index),\n                    'PolicyDocument': policy_entry.data\n                })\n            elif policy_entry.type is PolicyTypes.MANAGED_POLICY:\n\n                # There are three options:\n                #   Managed Policy Name (string): Try to convert to Managed Policy ARN\n                #   Managed Policy Arn (string): Insert it directly into the list\n                #   Intrinsic Function (dict): Insert it directly into the list\n                #\n                # When you insert into managed_policy_arns list, de-dupe to prevent same ARN from showing up twice\n                #\n\n                policy_arn = policy_entry.data\n                if isinstance(policy_entry.data, string_types) and policy_entry.data in managed_policy_map:\n                    policy_arn = managed_policy_map[policy_entry.data]\n\n                # De-Duplicate managed policy arns before inserting. Mainly useful\n                # when customer specifies a managed policy which is already inserted\n                # by SAM, such as AWSLambdaBasicExecutionRole\n                if policy_arn not in managed_policy_arns:\n                    managed_policy_arns.append(policy_arn)\n            else:\n                # Policy Templates are not supported here in the \"core\"\n                raise InvalidResourceException(\n                    self.logical_id,\n                    \"Policy at index {} in the 'Policies' property is not valid\".format(index))\n\n        execution_role.ManagedPolicyArns = list(managed_policy_arns)\n        execution_role.Policies = policy_documents or None\n        execution_role.PermissionsBoundary = self.PermissionsBoundary\n\n        return execution_role"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _validate_dlq(self):\n        # Validate required logical ids\n        valid_dlq_types = str(list(self.dead_letter_queue_policy_actions.keys()))\n        if not self.DeadLetterQueue.get('Type') or not self.DeadLetterQueue.get('TargetArn'):\n            raise InvalidResourceException(self.logical_id,\n                                           \"'DeadLetterQueue' requires Type and TargetArn properties to be specified\"\n                                           .format(valid_dlq_types))\n\n        # Validate required Types\n        if not self.DeadLetterQueue['Type'] in self.dead_letter_queue_policy_actions:\n            raise InvalidResourceException(self.logical_id,\n                                           \"'DeadLetterQueue' requires Type of {}\".format(valid_dlq_types))", "response": "Validates whether the DeadLetterQueue LogicalId is validation\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates and returns the event resources associated with this function s events.", "response": "def _generate_event_resources(self, lambda_function, execution_role, event_resources, lambda_alias=None):\n        \"\"\"Generates and returns the resources associated with this function's events.\n\n        :param model.lambda_.LambdaFunction lambda_function: generated Lambda function\n        :param iam.IAMRole execution_role: generated Lambda execution role\n        :param implicit_api: Global Implicit API resource where the implicit APIs get attached to, if necessary\n        :param implicit_api_stage: Global implicit API stage resource where implicit APIs get attached to, if necessary\n        :param event_resources: All the event sources associated with this Lambda function\n        :param model.lambda_.LambdaAlias lambda_alias: Optional Lambda Alias resource if we want to connect the\n            event sources to this alias\n\n        :returns: a list containing the function's event resources\n        :rtype: list\n        \"\"\"\n        resources = []\n        if self.Events:\n            for logical_id, event_dict in self.Events.items():\n                try:\n                    eventsource = self.event_resolver.resolve_resource_type(event_dict).from_dict(\n                        lambda_function.logical_id + logical_id, event_dict, logical_id)\n                except TypeError as e:\n                    raise InvalidEventException(logical_id, \"{}\".format(e))\n\n                kwargs = {\n                    # When Alias is provided, connect all event sources to the alias and *not* the function\n                    'function': lambda_alias or lambda_function,\n                    'role': execution_role,\n                }\n\n                for name, resource in event_resources[logical_id].items():\n                    kwargs[name] = resource\n                resources += eventsource.to_cloudformation(**kwargs)\n\n        return resources"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _construct_version(self, function, intrinsics_resolver):\n        code_dict = function.Code\n        if not code_dict:\n            raise ValueError(\"Lambda function code must be a valid non-empty dictionary\")\n\n        if not intrinsics_resolver:\n            raise ValueError(\"intrinsics_resolver is required for versions creation\")\n\n        # Resolve references to template parameters before creating hash. This will *not* resolve all intrinsics\n        # because we cannot resolve runtime values like Arn of a resource. For purposes of detecting changes, this\n        # is good enough. Here is why:\n        #\n        # When using intrinsic functions there are two cases when has must change:\n        #   - Value of the template parameter changes\n        #   - (or) LogicalId of a referenced resource changes ie. !GetAtt NewResource.Arn\n        #\n        # Later case will already change the hash because some value in the Code dictionary changes. We handle the\n        # first case by resolving references to template parameters. It is okay even if these references are\n        # present inside another intrinsic such as !Join. The resolver will replace the reference with the parameter's\n        # value and keep all other parts of !Join identical. This will still trigger a change in the hash.\n        code_dict = intrinsics_resolver.resolve_parameter_refs(code_dict)\n\n        # Construct the LogicalID of Lambda version by appending 10 characters of SHA of CodeUri. This is necessary\n        # to trigger creation of a new version every time code location changes. Since logicalId changes, CloudFormation\n        # will drop the old version and create a new one for us. We set a DeletionPolicy on the version resource to\n        # prevent CloudFormation from actually deleting the underlying version resource\n        #\n        # SHA Collisions: For purposes of triggering a new update, we are concerned about just the difference previous\n        #                 and next hashes. The chances that two subsequent hashes collide is fairly low.\n        prefix = \"{id}Version\".format(id=self.logical_id)\n        logical_id = logical_id_generator.LogicalIdGenerator(prefix, code_dict).gen()\n\n        attributes = self.get_passthrough_resource_attributes()\n        if attributes is None:\n            attributes = {}\n        attributes[\"DeletionPolicy\"] = \"Retain\"\n\n        lambda_version = LambdaVersion(logical_id=logical_id, attributes=attributes)\n        lambda_version.FunctionName = function.get_runtime_attr('name')\n        lambda_version.Description = self.VersionDescription\n\n        return lambda_version", "response": "Constructs a Lambda Version resource that will be auto - published when CodeUri of the Lambda function changes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconstruct a Lambda alias for the given function and pointing to the given version.", "response": "def _construct_alias(self, name, function, version):\n        \"\"\"Constructs a Lambda Alias for the given function and pointing to the given version\n\n        :param string name: Name of the alias\n        :param model.lambda_.LambdaFunction function: Lambda function object to associate the alias with\n        :param model.lambda_.LambdaVersion version: Lambda version object to associate the alias with\n        :return: Lambda alias object\n        :rtype model.lambda_.LambdaAlias\n        \"\"\"\n\n        if not name:\n            raise InvalidResourceException(self.logical_id, \"Alias name is required to create an alias\")\n\n        logical_id = \"{id}Alias{suffix}\".format(id=function.logical_id, suffix=name)\n        alias = LambdaAlias(logical_id=logical_id, attributes=self.get_passthrough_resource_attributes())\n        alias.Name = name\n        alias.FunctionName = function.get_runtime_attr('name')\n        alias.FunctionVersion = version.get_runtime_attr(\"version\")\n\n        return alias"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the API Gateway RestApi Deployment and Stage to which this SAM Api corresponds.", "response": "def to_cloudformation(self, **kwargs):\n        \"\"\"Returns the API Gateway RestApi, Deployment, and Stage to which this SAM Api corresponds.\n\n        :param dict kwargs: already-converted resources that may need to be modified when converting this \\\n        macro to pure CloudFormation\n        :returns: a list of vanilla CloudFormation Resources, to which this Function expands\n        :rtype: list\n        \"\"\"\n        resources = []\n\n        api_generator = ApiGenerator(self.logical_id,\n                                     self.CacheClusterEnabled,\n                                     self.CacheClusterSize,\n                                     self.Variables,\n                                     self.depends_on,\n                                     self.DefinitionBody,\n                                     self.DefinitionUri,\n                                     self.Name,\n                                     self.StageName,\n                                     endpoint_configuration=self.EndpointConfiguration,\n                                     method_settings=self.MethodSettings,\n                                     binary_media=self.BinaryMediaTypes,\n                                     minimum_compression_size=self.MinimumCompressionSize,\n                                     cors=self.Cors,\n                                     auth=self.Auth,\n                                     gateway_responses=self.GatewayResponses,\n                                     access_log_setting=self.AccessLogSetting,\n                                     canary_setting=self.CanarySetting,\n                                     tracing_enabled=self.TracingEnabled,\n                                     resource_attributes=self.resource_attributes,\n                                     passthrough_resource_attributes=self.get_passthrough_resource_attributes())\n\n        rest_api, deployment, stage, permissions = api_generator.to_cloudformation()\n\n        resources.extend([rest_api, deployment, stage])\n        resources.extend(permissions)\n\n        return resources"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconstruct a nested stack for this resource.", "response": "def _construct_nested_stack(self):\n        \"\"\"Constructs a AWS::CloudFormation::Stack resource\n        \"\"\"\n        nested_stack = NestedStack(self.logical_id, depends_on=self.depends_on,\n                                   attributes=self.get_passthrough_resource_attributes())\n        nested_stack.Parameters = self.Parameters\n        nested_stack.NotificationArns = self.NotificationArns\n        application_tags = self._get_application_tags()\n        nested_stack.Tags = self._construct_tag_list(self.Tags, application_tags)\n        nested_stack.TimeoutInMinutes = self.TimeoutInMinutes\n        nested_stack.TemplateURL = self.TemplateUrl if self.TemplateUrl else \"\"\n\n        return nested_stack"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding tags to the stack if this resource is using the serverless app repo", "response": "def _get_application_tags(self):\n        \"\"\"Adds tags to the stack if this resource is using the serverless app repo\n        \"\"\"\n        application_tags = {}\n        if isinstance(self.Location, dict):\n            if (self.APPLICATION_ID_KEY in self.Location.keys() and\n                    self.Location[self.APPLICATION_ID_KEY] is not None):\n                application_tags[self._SAR_APP_KEY] = self.Location[self.APPLICATION_ID_KEY]\n            if (self.SEMANTIC_VERSION_KEY in self.Location.keys() and\n                    self.Location[self.SEMANTIC_VERSION_KEY] is not None):\n                application_tags[self._SAR_SEMVER_KEY] = self.Location[self.SEMANTIC_VERSION_KEY]\n        return application_tags"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_cloudformation(self, **kwargs):\n        resources = []\n\n        # Append any CFN resources:\n        intrinsics_resolver = kwargs[\"intrinsics_resolver\"]\n        resources.append(self._construct_lambda_layer(intrinsics_resolver))\n\n        return resources", "response": "Returns the Lambda layer to which this Function corresponds."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _construct_lambda_layer(self, intrinsics_resolver):\n        # Resolve intrinsics if applicable:\n        self.LayerName = self._resolve_string_parameter(intrinsics_resolver, self.LayerName, 'LayerName')\n        self.LicenseInfo = self._resolve_string_parameter(intrinsics_resolver, self.LicenseInfo, 'LicenseInfo')\n        self.Description = self._resolve_string_parameter(intrinsics_resolver, self.Description, 'Description')\n        self.RetentionPolicy = self._resolve_string_parameter(intrinsics_resolver, self.RetentionPolicy,\n                                                              'RetentionPolicy')\n\n        retention_policy_value = self._get_retention_policy_value()\n\n        attributes = self.get_passthrough_resource_attributes()\n        if attributes is None:\n            attributes = {}\n        attributes['DeletionPolicy'] = retention_policy_value\n\n        old_logical_id = self.logical_id\n        new_logical_id = logical_id_generator.LogicalIdGenerator(old_logical_id, self.to_dict()).gen()\n        self.logical_id = new_logical_id\n\n        lambda_layer = LambdaLayerVersion(self.logical_id, depends_on=self.depends_on, attributes=attributes)\n\n        # Changing the LayerName property: when a layer is published, it is given an Arn\n        # example: arn:aws:lambda:us-west-2:123456789012:layer:MyLayer:1\n        # where MyLayer is the LayerName property if it exists; otherwise, it is the\n        # LogicalId of this resource. Since a LayerVersion is an immutable resource, when\n        # CloudFormation updates this resource, it will ALWAYS create a new version then\n        # delete the old version if the logical ids match. What this does is change the\n        # logical id of every layer (so a `DeletionPolicy: Retain` can work) and set the\n        # LayerName property of the layer so that the Arn will still always be the same\n        # with the exception of an incrementing version number.\n        if not self.LayerName:\n            self.LayerName = old_logical_id\n\n        lambda_layer.LayerName = self.LayerName\n        lambda_layer.Description = self.Description\n        lambda_layer.Content = construct_s3_location_object(self.ContentUri, self.logical_id, 'ContentUri')\n        lambda_layer.CompatibleRuntimes = self.CompatibleRuntimes\n        lambda_layer.LicenseInfo = self.LicenseInfo\n\n        return lambda_layer", "response": "Constructs and returns the Lambda function."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_retention_policy_value(self):\n\n        if self.RetentionPolicy is None or self.RetentionPolicy.lower() == self.RETAIN.lower():\n            return self.RETAIN\n        elif self.RetentionPolicy.lower() == self.DELETE.lower():\n            return self.DELETE\n        elif self.RetentionPolicy.lower() not in self.retention_policy_options:\n            raise InvalidResourceException(self.logical_id,\n                                           \"'{}' must be one of the following options: {}.\"\n                                           .format('RetentionPolicy', [self.RETAIN, self.DELETE]))", "response": "Returns the value for the DeletionPolicy attribute."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming dialog management and fulfillment for ordering flowers. Beyond fulfillment, the implementation of this intent demonstrates the use of the elicitSlot dialog action in slot validation and re-prompting.", "response": "def order_flowers(intent_request):\n    \"\"\"\n    Performs dialog management and fulfillment for ordering flowers.\n    Beyond fulfillment, the implementation of this intent demonstrates the use of the elicitSlot dialog action\n    in slot validation and re-prompting.\n    \"\"\"\n\n    flower_type = get_slots(intent_request)[\"FlowerType\"]\n    date = get_slots(intent_request)[\"PickupDate\"]\n    time = get_slots(intent_request)[\"PickupTime\"]\n    source = intent_request['invocationSource']\n\n    if source == 'DialogCodeHook':\n        # Perform basic validation on the supplied input slots.\n        # Use the elicitSlot dialog action to re-prompt for the first violation detected.\n        slots = get_slots(intent_request)\n\n        validation_result = validate_order_flowers(flower_type, date, time)\n        if not validation_result['isValid']:\n            slots[validation_result['violatedSlot']] = None\n            return elicit_slot(intent_request['sessionAttributes'],\n                               intent_request['currentIntent']['name'],\n                               slots,\n                               validation_result['violatedSlot'],\n                               validation_result['message'])\n\n        # Pass the price of the flowers back through session attributes to be used in various prompts defined\n        # on the bot model.\n        output_session_attributes = intent_request['sessionAttributes']\n        if flower_type is not None:\n            output_session_attributes['Price'] = len(flower_type) * 5  # Elegant pricing model\n\n        return delegate(output_session_attributes, get_slots(intent_request))\n\n    # Order the flowers, and rely on the goodbye message of the bot to define the message to the end user.\n    # In a real bot, this would likely involve a call to a backend service.\n    return close(intent_request['sessionAttributes'],\n                 'Fulfilled',\n                 {'contentType': 'PlainText',\n                  'content': 'Thanks, your order for {} has been placed and will be ready for pickup by {} on {}'.format(flower_type, time, date)})"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dispatch(intent_request):\n\n    logger.debug('dispatch userId={}, intentName={}'.format(intent_request['userId'], intent_request['currentIntent']['name']))\n\n    intent_name = intent_request['currentIntent']['name']\n\n    # Dispatch to your bot's intent handlers\n    if intent_name == 'OrderFlowers':\n        return order_flowers(intent_request)\n\n    raise Exception('Intent with name ' + intent_name + ' not supported')", "response": "Dispatches the intent request to the appropriate handlers."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconstructs the Lambda Permission resource allowing the source service to invoke the function this eventova triggers.", "response": "def _construct_permission(self, function, source_arn=None, source_account=None, suffix=\"\", event_source_token=None):\n        \"\"\"Constructs the Lambda Permission resource allowing the source service to invoke the function this event\n        source triggers.\n\n        :returns: the permission resource\n        :rtype: model.lambda_.LambdaPermission\n        \"\"\"\n        lambda_permission = LambdaPermission(self.logical_id + 'Permission' + suffix,\n                                             attributes=function.get_passthrough_resource_attributes())\n\n        try:\n            # Name will not be available for Alias resources\n            function_name_or_arn = function.get_runtime_attr(\"name\")\n        except NotImplementedError:\n            function_name_or_arn = function.get_runtime_attr(\"arn\")\n\n        lambda_permission.Action = 'lambda:invokeFunction'\n        lambda_permission.FunctionName = function_name_or_arn\n        lambda_permission.Principal = self.principal\n        lambda_permission.SourceArn = source_arn\n        lambda_permission.SourceAccount = source_account\n        lambda_permission.EventSourceToken = event_source_token\n\n        return lambda_permission"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the CloudWatch Events Rule and Lambda Permission to which this pull event source corresponds.", "response": "def to_cloudformation(self, **kwargs):\n        \"\"\"Returns the CloudWatch Events Rule and Lambda Permission to which this Schedule event source corresponds.\n\n        :param dict kwargs: no existing resources need to be modified\n        :returns: a list of vanilla CloudFormation Resources, to which this pull event expands\n        :rtype: list\n        \"\"\"\n        function = kwargs.get('function')\n\n        if not function:\n            raise TypeError(\"Missing required keyword argument: function\")\n\n        resources = []\n\n        events_rule = EventsRule(self.logical_id)\n        resources.append(events_rule)\n\n        events_rule.ScheduleExpression = self.Schedule\n        events_rule.Targets = [self._construct_target(function)]\n\n        source_arn = events_rule.get_runtime_attr(\"arn\")\n        if CONDITION in function.resource_attributes:\n            events_rule.set_resource_attribute(CONDITION, function.resource_attributes[CONDITION])\n        resources.append(self._construct_permission(function, source_arn=source_arn))\n\n        return resources"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _construct_target(self, function):\n        target = {\n                'Arn': function.get_runtime_attr(\"arn\"),\n                'Id': self.logical_id + 'LambdaTarget'\n        }\n        if self.Input is not None:\n            target['Input'] = self.Input\n\n        if self.InputPath is not None:\n            target['InputPath'] = self.InputPath\n        return target", "response": "Constructs the CloudWatch Events Rule target property for the CloudWatch Events Rule."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_cloudformation(self, **kwargs):\n        function = kwargs.get('function')\n\n        if not function:\n            raise TypeError(\"Missing required keyword argument: function\")\n\n        if 'bucket' not in kwargs or kwargs['bucket'] is None:\n            raise TypeError(\"Missing required keyword argument: bucket\")\n\n        if 'bucket_id' not in kwargs or kwargs['bucket_id'] is None:\n            raise TypeError(\"Missing required keyword argument: bucket_id\")\n\n        bucket = kwargs['bucket']\n        bucket_id = kwargs['bucket_id']\n\n        resources = []\n\n        source_account = ref('AWS::AccountId')\n        permission = self._construct_permission(function, source_account=source_account)\n        if CONDITION in permission.resource_attributes:\n            self._depend_on_lambda_permissions_using_tag(bucket, permission)\n        else:\n            self._depend_on_lambda_permissions(bucket, permission)\n        resources.append(permission)\n\n        # NOTE: `bucket` here is a dictionary representing the S3 Bucket resource in your SAM template. If there are\n        # multiple S3 Events attached to the same bucket, we will update the Bucket resource with notification\n        # configuration for each event. This is the reason why we continue to use existing bucket dict and append onto\n        # it.\n        #\n        # NOTE: There is some fragile logic here where we will append multiple resources to output\n        #   SAM template but de-dupe them when merging into output CFN template. This is scary because the order of\n        #   merging is literally \"last one wins\", which works fine because we linearly loop through the template once.\n        #   The de-dupe happens inside `samtranslator.translator.Translator.translate` method when merging results of\n        #   to_cloudformation() to output template.\n        self._inject_notification_configuration(function, bucket)\n        resources.append(S3Bucket.from_dict(bucket_id, bucket))\n\n        return resources", "response": "Returns the Lambda Permission resource allowing S3 to invoke the function this event source triggers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking the S3 bucket depends on Lambda Permissions resource because when S3 adds a Notification Configuration it will fail if Lambda does not have permission to invoke Lambda.", "response": "def _depend_on_lambda_permissions(self, bucket, permission):\n        \"\"\"\n        Make the S3 bucket depends on Lambda Permissions resource because when S3 adds a Notification Configuration,\n        it will check whether it has permissions to access Lambda. This will fail if the Lambda::Permissions is not\n        already applied for this bucket to invoke the Lambda.\n\n        :param dict bucket: Dictionary representing the bucket in SAM template. This is a raw dictionary and not a\n            \"resource\" object\n        :param model.lambda_.lambda_permission permission: Lambda Permission resource that needs to be created before\n            the bucket.\n        :return: Modified Bucket dictionary\n        \"\"\"\n\n        depends_on = bucket.get(\"DependsOn\", [])\n\n        # DependsOn can be either a list of strings or a scalar string\n        if isinstance(depends_on, string_types):\n            depends_on = [depends_on]\n\n        depends_on_set = set(depends_on)\n        depends_on_set.add(permission.logical_id)\n        bucket[\"DependsOn\"] = list(depends_on_set)\n\n        return bucket"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _depend_on_lambda_permissions_using_tag(self, bucket, permission):\n        properties = bucket.get('Properties', None)\n        if properties is None:\n            properties = {}\n            bucket['Properties'] = properties\n        tags = properties.get('Tags', None)\n        if tags is None:\n            tags = []\n            properties['Tags'] = tags\n        dep_tag = {\n            'sam:ConditionalDependsOn:' + permission.logical_id: {\n                'Fn::If': [\n                    permission.resource_attributes[CONDITION],\n                    ref(permission.logical_id),\n                    'no dependency'\n                ]\n            }\n        }\n        properties['Tags'] = tags + get_tag_list(dep_tag)\n        return bucket", "response": "This function is used to make conditional DependsOn depend on a resource and add it to the properties of the bucket."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the Lambda Permission resource allowing SNS to invoke the function this event source triggers.", "response": "def to_cloudformation(self, **kwargs):\n        \"\"\"Returns the Lambda Permission resource allowing SNS to invoke the function this event source triggers.\n\n        :param dict kwargs: no existing resources need to be modified\n        :returns: a list of vanilla CloudFormation Resources, to which this SNS event expands\n        :rtype: list\n        \"\"\"\n        function = kwargs.get('function')\n\n        if not function:\n            raise TypeError(\"Missing required keyword argument: function\")\n\n        return [self._construct_permission(function, source_arn=self.Topic),\n                self._inject_subscription(function, self.Topic, self.FilterPolicy)]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a list of resources return a dictionary of the resource names and the corresponding explicit API resource IDs.", "response": "def resources_to_link(self, resources):\n        \"\"\"\n        If this API Event Source refers to an explicit API resource, resolve the reference and grab\n        necessary data from the explicit API\n        \"\"\"\n\n        rest_api_id = self.RestApiId\n        if isinstance(rest_api_id, dict) and \"Ref\" in rest_api_id:\n            rest_api_id = rest_api_id[\"Ref\"]\n\n        # If RestApiId is a resource in the same template, then we try find the StageName by following the reference\n        # Otherwise we default to a wildcard. This stage name is solely used to construct the permission to\n        # allow this stage to invoke the Lambda function. If we are unable to resolve the stage name, we will\n        # simply permit all stages to invoke this Lambda function\n        # This hack is necessary because customers could use !ImportValue, !Ref or other intrinsic functions which\n        # can be sometimes impossible to resolve (ie. when it has cross-stack references)\n        permitted_stage = \"*\"\n        stage_suffix = \"AllStages\"\n        explicit_api = None\n        if isinstance(rest_api_id, string_types):\n\n            if rest_api_id in resources \\\n               and \"Properties\" in resources[rest_api_id] \\\n               and \"StageName\" in resources[rest_api_id][\"Properties\"]:\n\n                explicit_api = resources[rest_api_id][\"Properties\"]\n                permitted_stage = explicit_api[\"StageName\"]\n\n                # Stage could be a intrinsic, in which case leave the suffix to default value\n                if isinstance(permitted_stage, string_types):\n                    if not permitted_stage:\n                        raise InvalidResourceException(rest_api_id, 'StageName cannot be empty.')\n                    stage_suffix = permitted_stage\n                else:\n                    stage_suffix = \"Stage\"\n\n            else:\n                # RestApiId is a string, not an intrinsic, but we did not find a valid API resource for this ID\n                raise InvalidEventException(self.relative_id, \"RestApiId property of Api event must reference a valid \"\n                                                              \"resource in the same template.\")\n\n        return {\n            'explicit_api': explicit_api,\n            'explicit_api_stage': {\n                'permitted_stage': permitted_stage,\n                'suffix': stage_suffix\n            }\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_cloudformation(self, **kwargs):\n        resources = []\n\n        function = kwargs.get('function')\n\n        if not function:\n            raise TypeError(\"Missing required keyword argument: function\")\n\n        if self.Method is not None:\n            # Convert to lower case so that user can specify either GET or get\n            self.Method = self.Method.lower()\n\n        resources.extend(self._get_permissions(kwargs))\n\n        explicit_api = kwargs['explicit_api']\n        if explicit_api.get(\"__MANAGE_SWAGGER\"):\n            self._add_swagger_integration(explicit_api, function)\n\n        return resources", "response": "Converts the event source to a list of CloudFormation Resources."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding the path and method for this Api event source to the Swagger body for the provided RestApi.", "response": "def _add_swagger_integration(self, api, function):\n        \"\"\"Adds the path and method for this Api event source to the Swagger body for the provided RestApi.\n\n        :param model.apigateway.ApiGatewayRestApi rest_api: the RestApi to which the path and method should be added.\n        \"\"\"\n        swagger_body = api.get(\"DefinitionBody\")\n        if swagger_body is None:\n            return\n\n        function_arn = function.get_runtime_attr('arn')\n        partition = ArnGenerator.get_partition_name()\n        uri = fnSub('arn:' + partition + ':apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/' +\n                    make_shorthand(function_arn) + '/invocations')\n\n        editor = SwaggerEditor(swagger_body)\n\n        if editor.has_integration(self.Path, self.Method):\n            # Cannot add the Lambda Integration, if it is already present\n            raise InvalidEventException(\n                self.relative_id,\n                'API method \"{method}\" defined multiple times for path \"{path}\".'.format(\n                    method=self.Method, path=self.Path))\n\n        condition = None\n        if CONDITION in function.resource_attributes:\n            condition = function.resource_attributes[CONDITION]\n\n        editor.add_lambda_integration(self.Path, self.Method, uri, self.Auth, api.get('Auth'), condition=condition)\n\n        if self.Auth:\n            method_authorizer = self.Auth.get('Authorizer')\n\n            if method_authorizer:\n                api_auth = api.get('Auth')\n                api_authorizers = api_auth and api_auth.get('Authorizers')\n\n                if method_authorizer != 'AWS_IAM':\n                    if not api_authorizers:\n                        raise InvalidEventException(\n                            self.relative_id,\n                            'Unable to set Authorizer [{authorizer}] on API method [{method}] for path [{path}] '\n                            'because the related API does not define any Authorizers.'.format(\n                                authorizer=method_authorizer, method=self.Method, path=self.Path))\n\n                    if method_authorizer != 'NONE' and not api_authorizers.get(method_authorizer):\n                        raise InvalidEventException(\n                            self.relative_id,\n                            'Unable to set Authorizer [{authorizer}] on API method [{method}] for path [{path}] '\n                            'because it wasn\\'t defined in the API\\'s Authorizers.'.format(\n                                authorizer=method_authorizer, method=self.Method, path=self.Path))\n\n                    if method_authorizer == 'NONE' and not api_auth.get('DefaultAuthorizer'):\n                        raise InvalidEventException(\n                            self.relative_id,\n                            'Unable to set Authorizer on API method [{method}] for path [{path}] because \\'NONE\\' '\n                            'is only a valid value when a DefaultAuthorizer on the API is specified.'.format(\n                                method=self.Method, path=self.Path))\n\n                editor.add_auth_to_method(api=api, path=self.Path, method_name=self.Method, auth=self.Auth)\n\n        api[\"DefinitionBody\"] = editor.swagger"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nresolve references to parameters within the given dictionary recursively.", "response": "def resolve_parameter_refs(self, input):\n        \"\"\"\n        Resolves references to parameters within the given dictionary recursively. Other intrinsic functions such as\n        !GetAtt, !Sub or !Ref to non-parameters will be left untouched.\n\n        Result is a dictionary where parameter values are inlined. Don't pass this dictionary directly into\n        transform's output because it changes the template structure by inlining parameter values.\n\n        :param input: Any primitive type (dict, array, string etc) whose values might contain intrinsic functions\n        :return: A copy of a dictionary with parameter references replaced by actual value.\n        \"\"\"\n        return self._traverse(input, self.parameters, self._try_resolve_parameter_refs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _traverse_dict(self, input_dict, resolution_data, resolver_method):\n        for key, value in input_dict.items():\n            input_dict[key] = self._traverse(value, resolution_data, resolver_method)\n\n        return input_dict", "response": "Traverse a dictionary to resolve intrinsic functions on every value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _traverse_list(self, input_list, resolution_data, resolver_method):\n        for index, value in enumerate(input_list):\n            input_list[index] = self._traverse(value, resolution_data, resolver_method)\n\n        return input_list", "response": "Traverse a list to resolve intrinsic functions on every element of the list"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _try_resolve_parameter_refs(self, input, parameters):\n        if not self._is_intrinsic_dict(input):\n            return input\n\n        function_type = list(input.keys())[0]\n        return self.supported_intrinsics[function_type].resolve_parameter_refs(input, parameters)", "response": "Try to resolve parameter references on the input object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntries to resolve SAM resource references on the given template.", "response": "def _try_resolve_sam_resource_refs(self, input, supported_resource_refs):\n        \"\"\"\n        Try to resolve SAM resource references on the given template. If the given object looks like one of the\n        supported intrinsics, it calls the appropriate resolution on it. If not, this method returns the original input\n        unmodified.\n\n        :param dict input: Dictionary that may represent an intrinsic function\n        :param SupportedResourceReferences supported_resource_refs: Object containing information about available\n            resource references and the values they resolve to.\n        :return: Modified input dictionary with references resolved\n        \"\"\"\n        if not self._is_intrinsic_dict(input):\n            return input\n\n        function_type = list(input.keys())[0]\n        return self.supported_intrinsics[function_type].resolve_resource_refs(input, supported_resource_refs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _try_resolve_sam_resource_id_refs(self, input, supported_resource_id_refs):\n        if not self._is_intrinsic_dict(input):\n            return input\n\n        function_type = list(input.keys())[0]\n        return self.supported_intrinsics[function_type].resolve_resource_id_refs(input, supported_resource_id_refs)", "response": "Try to resolve SAM resource id references on the given template."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the input represent an intrinsic function in it.", "response": "def _is_intrinsic_dict(self, input):\n        \"\"\"\n        Can the input represent an intrinsic function in it?\n\n        :param input: Object to be checked\n        :return: True, if the input contains a supported intrinsic function.  False otherwise\n        \"\"\"\n        # All intrinsic functions are dictionaries with just one key\n        return isinstance(input, dict) \\\n            and len(input) == 1 \\\n            and list(input.keys())[0] in self.supported_intrinsics"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_cloudformation(self, **kwargs):\n        function = kwargs.get('function')\n\n        if not function:\n            raise TypeError(\"Missing required keyword argument: function\")\n\n        source_arn = self.get_source_arn()\n        permission = self._construct_permission(function, source_arn=source_arn)\n        subscription_filter = self.get_subscription_filter(function, permission)\n        resources = [permission, subscription_filter]\n\n        return resources", "response": "Returns the CloudWatch Logs Subscription Filter and Lambda Permission to which this CloudWatch Logs event source\n        corresponds."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert(self, template_name, parameter_values):\n\n        if not self.has(template_name):\n            raise TemplateNotFoundException(template_name)\n\n        template = self.get(template_name)\n        return template.to_statement(parameter_values)", "response": "Converts the given template to IAM - ready policy statement by substituting template parameters with the given values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the given dictionary is a valid policy template dictionary.", "response": "def _is_valid_templates_dict(policy_templates_dict, schema=None):\n        \"\"\"\n        Is this a valid policy template dictionary\n\n        :param dict policy_templates_dict: Data to be validated\n        :param dict schema: Optional, dictionary containing JSON Schema representing policy template\n        :return: True, if it is valid.\n        :raises ValueError: If the template dictionary doesn't match up with the schema\n        \"\"\"\n\n        if not schema:\n            schema = PolicyTemplatesProcessor._read_schema()\n\n        try:\n            jsonschema.validate(policy_templates_dict, schema)\n        except ValidationError as ex:\n            # Stringifying the exception will give us useful error message\n            raise ValueError(str(ex))\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render_chart_to_file(self, template_name: str, chart: Any, path: str):\n        tpl = self.env.get_template(template_name)\n        html = tpl.render(chart=self.generate_js_link(chart))\n        write_utf8_html_file(path, self._reg_replace(html))", "response": "Render a chart or page to local html files."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decode_base64(data: str) -> bytes:\n    missing_padding = len(data) % 4\n    if missing_padding != 0:\n        data += \"=\" * (4 - missing_padding)\n    return base64.decodebytes(data.encode(\"utf-8\"))", "response": "Decode base64 data as an ASCII byte string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the collapsed flag of the children of the data.", "response": "def _set_collapse_interval(data, interval):\r\n        \"\"\"\r\n        \u95f4\u9694\u6298\u53e0\u8282\u70b9\uff0c\u5f53\u8282\u70b9\u8fc7\u591a\u65f6\u53ef\u4ee5\u89e3\u51b3\u8282\u70b9\u663e\u793a\u8fc7\u6742\u95f4\u9694\u3002\r\n\r\n        :param data: \u8282\u70b9\u6570\u636e\r\n        :param interval: \u6307\u5b9a\u95f4\u9694\r\n        \"\"\"\r\n        if interval <= 0:\r\n            return data\r\n        if data and isinstance(data, list):\r\n            for d in data:\r\n                children = d.get(\"children\", None)\r\n                if children and interval > 0:\r\n                    for index, value in enumerate(children):\r\n                        if index % interval == 0:\r\n                            value.update(collapsed=\"false\")\r\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_pin(name_str):\n    if len(name_str) < 1:\n        raise ValueError(\"Expecting pin name to be at least 4 charcters.\")\n    if name_str[0] != 'P':\n        raise ValueError(\"Expecting pin name to start with P\")\n    pin_str = name_str[1:].split('/')[0]\n    if not pin_str.isdigit():\n        raise ValueError(\"Expecting numeric pin number.\")\n    return int(pin_str)", "response": "Parses a string and returns a pin - num."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ptr(self):\n        if self.fn_num is None:\n            return self.func\n        return '{:s}{:d}'.format(self.func, self.fn_num)", "response": "Returns the numbered function name for this AF."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print(self):\n        if self.supported:\n            print('  AF',  end='')\n        else:\n            print('  //', end='')\n        fn_num = self.fn_num\n        if fn_num is None:\n            fn_num = 0\n        print('({:2d}, {:8s}, {:2d}, {:10s}, {:8s}), // {:s}'.format(self.idx,\n              self.func, fn_num, self.pin_type, self.ptr(), self.af_str))", "response": "Prints the C representation of this AF."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts the loop. :param `leds`: Which LEDs to light up upon switch press. :type `leds`: sequence of LED objects", "response": "def run_loop(leds=all_leds):\n    \"\"\"\n    Start the loop.\n\n    :param `leds`: Which LEDs to light up upon switch press.\n    :type `leds`: sequence of LED objects\n    \"\"\"\n    print('Loop started.\\nPress Ctrl+C to break out of the loop.')\n    while 1:\n        try:\n            if switch():\n                [led.on() for led in leds]\n            else:\n                [led.off() for led in leds]\n        except OSError: # VCPInterrupt # Ctrl+C in interpreter mode.\n            break"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_c_file(obj_file, vpath):\n    c_file = None\n    relative_c_file = os.path.splitext(obj_file)[0] + \".c\"\n    relative_c_file = relative_c_file.lstrip('/\\\\')\n    for p in vpath:\n        possible_c_file = os.path.join(p, relative_c_file)\n        if os.path.exists(possible_c_file):\n            c_file = possible_c_file\n            break\n\n    return c_file", "response": "Search vpaths for the c file that matches the provided object file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding any MP_REGISTER_MODULE definitions in the provided c file.", "response": "def find_module_registrations(c_file):\n    \"\"\" Find any MP_REGISTER_MODULE definitions in the provided c file.\n\n    :param str c_file: path to c file to check\n    :return: List[(module_name, obj_module, enabled_define)]\n    \"\"\"\n    global pattern\n\n    if c_file is None:\n        # No c file to match the object file, skip\n        return set()\n\n    with io.open(c_file, encoding='utf-8') as c_file_obj:\n        return set(re.findall(pattern, c_file_obj.read()))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate header file for all external modules.", "response": "def generate_module_table_header(modules):\n    \"\"\" Generate header with module table entries for builtin modules.\n\n    :param List[(module_name, obj_module, enabled_define)] modules: module defs\n    :return: None\n    \"\"\"\n\n    # Print header file for all external modules.\n    mod_defs = []\n    print(\"// Automatically generated by makemoduledefs.py.\\n\")\n    for module_name, obj_module, enabled_define in modules:\n        mod_def = \"MODULE_DEF_{}\".format(module_name.upper())\n        mod_defs.append(mod_def)\n        print((\n            \"#if ({enabled_define})\\n\"\n            \"    extern const struct _mp_obj_module_t {obj_module};\\n\"\n            \"    #define {mod_def} {{ MP_ROM_QSTR({module_name}), MP_ROM_PTR(&{obj_module}) }},\\n\"\n            \"#else\\n\"\n            \"    #define {mod_def}\\n\"\n            \"#endif\\n\"\n            ).format(module_name=module_name, obj_module=obj_module,\n                     enabled_define=enabled_define, mod_def=mod_def)\n        )\n\n    print(\"\\n#define MICROPY_REGISTERED_MODULES \\\\\")\n\n    for mod_def in mod_defs:\n        print(\"    {mod_def} \\\\\".format(mod_def=mod_def))\n\n    print(\"// MICROPY_REGISTERED_MODULES\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef readfiles():\n    tests = list(filter(lambda x: x.endswith('.py'), os.listdir(TESTPATH)))\n    tests.sort()\n    files = []\n\n    for test in tests:\n        text = open(TESTPATH + test, 'r').read()\n\n        try:\n            class_, desc, cause, workaround, code = [x.rstrip() for x in \\\n                                                    list(filter(None, re.split(SPLIT, text)))]\n            output = Output(test, class_, desc, cause, workaround, code, '', '', '')\n            files.append(output)\n        except IndexError:\n            print('Incorrect format in file ' + TESTPATH + test)\n\n    return files", "response": "Reads test files and returns a list of Output objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts CPython module names into MicroPython equivalents", "response": "def uimports(code):\n    \"\"\" converts CPython module names into MicroPython equivalents \"\"\"\n    for uimport in UIMPORTLIST:\n        uimport = bytes(uimport, 'utf8')\n        code = code.replace(uimport, b'u' + uimport)\n    return code"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef indent(block, spaces):\n    new_block = ''\n    for line in block.split('\\n'):\n        new_block += spaces + line + '\\n'\n    return new_block", "response": "indents paragraphs of text for rst formatting"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a table given any set of columns", "response": "def gen_table(contents):\n    \"\"\" creates a table given any set of columns \"\"\"\n    xlengths = []\n    ylengths = []\n    for column in contents:\n        col_len = 0\n        for entry in column:\n            lines = entry.split('\\n')\n            for line in lines:\n                col_len = max(len(line) + 2, col_len)\n        xlengths.append(col_len)\n    for i in range(len(contents[0])):\n        ymax = 0\n        for j in range(len(contents)):\n            ymax = max(ymax, len(contents[j][i].split('\\n')))\n        ylengths.append(ymax)\n\n    table_divider = '+' + ''.join(['-' * i + '+' for i in xlengths]) + '\\n'\n    table = table_divider\n    for i in range(len(ylengths)):\n        row = [column[i] for column in contents]\n        row = [entry + '\\n' * (ylengths[i]-len(entry.split('\\n'))) for entry in row]\n        row = [entry.split('\\n') for entry in row]\n        for j in range(ylengths[i]):\n            k = 0\n            for entry in row:\n                width = xlengths[k]\n                table += ''.join(['| {:{}}'.format(entry[j], width - 1)])\n                k += 1\n            table += '|\\n'\n        table += table_divider\n    return table + '\\n'"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gen_rst(results):\n\n    # make sure the destination directory exists\n    try:\n        os.mkdir(DOCPATH)\n    except OSError as e:\n        if e.args[0] != errno.EEXIST and e.args[0] != errno.EISDIR:\n            raise\n\n    toctree = []\n    class_ = []\n    for output in results:\n        section = output.class_.split(',')\n        for i in range(len(section)):\n            section[i] = section[i].rstrip()\n            if section[i] in CLASSMAP:\n                section[i] = CLASSMAP[section[i]]\n            if i >= len(class_) or section[i] != class_[i]:\n                if i == 0:\n                    filename = section[i].replace(' ', '_').lower()\n                    rst = open(DOCPATH + filename + '.rst', 'w')\n                    rst.write(HEADER)\n                    rst.write(section[i] + '\\n')\n                    rst.write(RSTCHARS[0] * len(section[i]))\n                    rst.write(time.strftime(\"\\nGenerated %a %d %b %Y %X UTC\\n\\n\", time.gmtime()))\n                    toctree.append(filename)\n                else:\n                    rst.write(section[i] + '\\n')\n                    rst.write(RSTCHARS[min(i, len(RSTCHARS)-1)] * len(section[i]))\n                    rst.write('\\n\\n')\n        class_ = section\n        rst.write('.. _cpydiff_%s:\\n\\n' % output.name.rsplit('.', 1)[0])\n        rst.write(output.desc + '\\n')\n        rst.write('~' * len(output.desc) + '\\n\\n')\n        if output.cause != 'Unknown':\n            rst.write('**Cause:** ' + output.cause + '\\n\\n')\n        if output.workaround != 'Unknown':\n            rst.write('**Workaround:** ' + output.workaround + '\\n\\n')\n\n        rst.write('Sample code::\\n\\n' + indent(output.code, TAB) + '\\n')\n        output_cpy = indent(''.join(output.output_cpy[0:2]), TAB).rstrip()\n        output_cpy = ('::\\n\\n' if output_cpy != '' else '') + output_cpy\n        output_upy = indent(''.join(output.output_upy[0:2]), TAB).rstrip()\n        output_upy = ('::\\n\\n' if output_upy != '' else '') + output_upy\n        table = gen_table([['CPy output:', output_cpy], ['uPy output:', output_upy]])\n        rst.write(table)\n\n    template = open(INDEXTEMPLATE, 'r')\n    index = open(DOCPATH + INDEX, 'w')\n    index.write(HEADER)\n    index.write(template.read())\n    for section in INDEXPRIORITY:\n        if section in toctree:\n            index.write(indent(section + '.rst', TAB))\n            toctree.remove(section)\n    for section in toctree:\n        index.write(indent(section + '.rst', TAB))", "response": "Generates the rst file for the given list of results."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing the found DFU device so that we can program it.", "response": "def init():\n    \"\"\"Initializes the found DFU device so that we can program it.\"\"\"\n    global __dev, __cfg_descr\n    devices = get_dfu_devices(idVendor=__VID, idProduct=__PID)\n    if not devices:\n        raise ValueError('No DFU device found')\n    if len(devices) > 1:\n        raise ValueError(\"Multiple DFU devices found\")\n    __dev = devices[0]\n    __dev.set_configuration()\n\n    # Claim DFU interface\n    usb.util.claim_interface(__dev, __DFU_INTERFACE)\n\n    # Find the DFU configuration descriptor, either in the device or interfaces\n    __cfg_descr = None\n    for cfg in __dev.configurations():\n        __cfg_descr = find_dfu_cfg_descr(cfg.extra_descriptors)\n        if __cfg_descr:\n            break\n        for itf in cfg.interfaces():\n            __cfg_descr = find_dfu_cfg_descr(itf.extra_descriptors)\n            if __cfg_descr:\n                break\n\n    # Get device into idle state\n    for attempt in range(4):\n        status = get_status()\n        if status == __DFU_STATE_DFU_IDLE:\n            break\n        elif (status == __DFU_STATE_DFU_DOWNLOAD_IDLE\n            or status == __DFU_STATE_DFU_UPLOAD_IDLE):\n            abort_request()\n        else:\n            clr_status()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef page_erase(addr):\n    if __verbose:\n        print(\"Erasing page: 0x%x...\" % (addr))\n\n    # Send DNLOAD with first byte=0x41 and page address\n    buf = struct.pack(\"<BI\", 0x41, addr)\n    __dev.ctrl_transfer(0x21, __DFU_DNLOAD, 0, __DFU_INTERFACE, buf, __TIMEOUT)\n\n    # Execute last command\n    if get_status() != __DFU_STATE_DFU_DOWNLOAD_BUSY:\n        raise Exception(\"DFU: erase failed\")\n\n    # Check command state\n    if get_status() != __DFU_STATE_DFU_DOWNLOAD_IDLE:\n\n        raise Exception(\"DFU: erase failed\")", "response": "Erases a single page."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the address for the next operation.", "response": "def set_address(addr):\n    \"\"\"Sets the address for the next operation.\"\"\"\n    # Send DNLOAD with first byte=0x21 and page address\n    buf = struct.pack(\"<BI\", 0x21, addr)\n    __dev.ctrl_transfer(0x21, __DFU_DNLOAD, 0, __DFU_INTERFACE, buf, __TIMEOUT)\n\n    # Execute last command\n    if get_status() != __DFU_STATE_DFU_DOWNLOAD_BUSY:\n        raise Exception(\"DFU: set address failed\")\n\n    # Check command state\n    if get_status() != __DFU_STATE_DFU_DOWNLOAD_IDLE:\n        raise Exception(\"DFU: set address failed\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites a buffer into memory.", "response": "def write_memory(addr, buf, progress=None, progress_addr=0, progress_size=0):\n    \"\"\"Writes a buffer into memory. This routine assumes that memory has\n    already been erased.\n    \"\"\"\n\n    xfer_count = 0\n    xfer_bytes = 0\n    xfer_total = len(buf)\n    xfer_base = addr\n\n    while xfer_bytes < xfer_total:\n        if __verbose and xfer_count % 512 == 0:\n            print (\"Addr 0x%x %dKBs/%dKBs...\" % (xfer_base + xfer_bytes,\n                                                 xfer_bytes // 1024,\n                                                 xfer_total // 1024))\n        if progress and xfer_count % 2 == 0:\n            progress(progress_addr, xfer_base + xfer_bytes - progress_addr,\n                     progress_size)\n\n        # Set mem write address\n        set_address(xfer_base+xfer_bytes)\n\n        # Send DNLOAD with fw data\n        chunk = min(__cfg_descr.wTransferSize, xfer_total-xfer_bytes)\n        __dev.ctrl_transfer(0x21, __DFU_DNLOAD, 2, __DFU_INTERFACE,\n                            buf[xfer_bytes:xfer_bytes + chunk], __TIMEOUT)\n\n        # Execute last command\n        if get_status() != __DFU_STATE_DFU_DOWNLOAD_BUSY:\n            raise Exception(\"DFU: write memory failed\")\n\n        # Check command state\n        if get_status() != __DFU_STATE_DFU_DOWNLOAD_IDLE:\n            raise Exception(\"DFU: write memory failed\")\n\n        xfer_count += 1\n        xfer_bytes += chunk"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_page(buf, xfer_offset):\n\n    xfer_base = 0x08000000\n\n    # Set mem write address\n    set_address(xfer_base+xfer_offset)\n\n    # Send DNLOAD with fw data\n    __dev.ctrl_transfer(0x21, __DFU_DNLOAD, 2, __DFU_INTERFACE, buf, __TIMEOUT)\n\n    # Execute last command\n    if get_status() != __DFU_STATE_DFU_DOWNLOAD_BUSY:\n        raise Exception(\"DFU: write memory failed\")\n\n    # Check command state\n    if get_status() != __DFU_STATE_DFU_DOWNLOAD_IDLE:\n        raise Exception(\"DFU: write memory failed\")\n\n    if __verbose:\n        print (\"Write: 0x%x \" % (xfer_base + xfer_offset))", "response": "Writes a single page from the memory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef exit_dfu():\n\n    # set jump address\n    set_address(0x08000000)\n\n    # Send DNLOAD with 0 length to exit DFU\n    __dev.ctrl_transfer(0x21, __DFU_DNLOAD, 0, __DFU_INTERFACE,\n                        None, __TIMEOUT)\n\n    try:\n        # Execute last command\n        if get_status() != __DFU_STATE_DFU_MANIFEST:\n            print(\"Failed to reset device\")\n\n        # Release device\n        usb.util.dispose_resources(__dev)\n    except:\n        pass", "response": "Exit DFU mode and start running the program."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the struct defined by fmt from data stores the parsed fields into a named tuple using names. Returns the named tuple and the data with the struct stripped off.", "response": "def consume(fmt, data, names):\n    \"\"\"Parses the struct defined by `fmt` from `data`, stores the parsed fields\n    into a named tuple using `names`. Returns the named tuple, and the data\n    with the struct stripped off.\"\"\"\n    size = struct.calcsize(fmt)\n    return named(struct.unpack(fmt, data[:size]), names), data[size:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_dfu_file(filename):\n\n    print(\"File: {}\".format(filename))\n    with open(filename, 'rb') as fin:\n        data = fin.read()\n    crc = compute_crc(data[:-4])\n    elements = []\n\n    # Decode the DFU Prefix\n    #\n    # <5sBIB\n    #   <   little endian\n    #   5s  char[5]     signature   \"DfuSe\"\n    #   B   uint8_t     version     1\n    #   I   uint32_t    size        Size of the DFU file (not including suffix)\n    #   B   uint8_t     targets     Number of targets\n    dfu_prefix, data = consume('<5sBIB', data,\n                               'signature version size targets')\n    print (\"    %(signature)s v%(version)d, image size: %(size)d, \"\n           \"targets: %(targets)d\" % dfu_prefix)\n    for target_idx in range(dfu_prefix['targets']):\n        # Decode the Image Prefix\n        #\n        # <6sBI255s2I\n        #   <   little endian\n        #   6s      char[6]     signature   \"Target\"\n        #   B       uint8_t     altsetting\n        #   I       uint32_t    named       bool indicating if a name was used\n        #   255s    char[255]   name        name of the target\n        #   I       uint32_t    size        size of image (not incl prefix)\n        #   I       uint32_t    elements    Number of elements in the image\n        img_prefix, data = consume('<6sBI255s2I', data,\n                                   'signature altsetting named name '\n                                   'size elements')\n        img_prefix['num'] = target_idx\n        if img_prefix['named']:\n            img_prefix['name'] = cstring(img_prefix['name'])\n        else:\n            img_prefix['name'] = ''\n        print('    %(signature)s %(num)d, alt setting: %(altsetting)s, '\n              'name: \"%(name)s\", size: %(size)d, elements: %(elements)d'\n              % img_prefix)\n\n        target_size = img_prefix['size']\n        target_data, data = data[:target_size], data[target_size:]\n        for elem_idx in range(img_prefix['elements']):\n            # Decode target prefix\n            #   <   little endian\n            #   I   uint32_t    element address\n            #   I   uint32_t    element size\n            elem_prefix, target_data = consume('<2I', target_data, 'addr size')\n            elem_prefix['num'] = elem_idx\n            print('      %(num)d, address: 0x%(addr)08x, size: %(size)d'\n                  % elem_prefix)\n            elem_size = elem_prefix['size']\n            elem_data = target_data[:elem_size]\n            target_data = target_data[elem_size:]\n            elem_prefix['data'] = elem_data\n            elements.append(elem_prefix)\n\n        if len(target_data):\n            print(\"target %d PARSE ERROR\" % target_idx)\n\n    # Decode DFU Suffix\n    #   <   little endian\n    #   H   uint16_t    device  Firmware version\n    #   H   uint16_t    product\n    #   H   uint16_t    vendor\n    #   H   uint16_t    dfu     0x11a   (DFU file format version)\n    #   3s  char[3]     ufd     'UFD'\n    #   B   uint8_t     len     16\n    #   I   uint32_t    crc32\n    dfu_suffix = named(struct.unpack('<4H3sBI', data[:16]),\n                       'device product vendor dfu ufd len crc')\n    print ('    usb: %(vendor)04x:%(product)04x, device: 0x%(device)04x, '\n           'dfu: 0x%(dfu)04x, %(ufd)s, %(len)d, 0x%(crc)08x' % dfu_suffix)\n    if crc != dfu_suffix['crc']:\n        print(\"CRC ERROR: computed crc32 is 0x%08x\" % crc)\n        return\n    data = data[16:]\n    if data:\n        print(\"PARSE ERROR\")\n        return\n\n    return elements", "response": "Reads a DFU file and parses the individual elements into a list of dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_dfu_devices(*args, **kwargs):\n    # convert to list for compatibility with newer pyusb\n    return list(usb.core.find(*args, find_all=True,\n                              custom_match=FilterDFU(), **kwargs))", "response": "Returns a list of USB devices currently in DFU mode."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an array which identifies the memory layout of the specified device.", "response": "def get_memory_layout(device):\n    \"\"\"Returns an array which identifies the memory layout. Each entry\n    of the array will contain a dictionary with the following keys:\n        addr        - Address of this memory segment\n        last_addr   - Last address contained within the memory segment.\n        size        - size of the segment, in bytes\n        num_pages   - number of pages in the segment\n        page_size   - size of each page, in bytes\n    \"\"\"\n    cfg = device[0]\n    intf = cfg[(0, 0)]\n    mem_layout_str = get_string(device, intf.iInterface)\n    mem_layout = mem_layout_str.split('/')\n    result = []\n    for mem_layout_index in range(1, len(mem_layout), 2):\n        addr = int(mem_layout[mem_layout_index], 0)\n        segments = mem_layout[mem_layout_index + 1].split(',')\n        seg_re = re.compile(r'(\\d+)\\*(\\d+)(.)(.)')\n        for segment in segments:\n            seg_match = seg_re.match(segment)\n            num_pages = int(seg_match.groups()[0], 10)\n            page_size = int(seg_match.groups()[1], 10)\n            multiplier = seg_match.groups()[2]\n            if multiplier == 'K':\n                page_size *= 1024\n            if multiplier == 'M':\n                page_size *= 1024 * 1024\n            size = num_pages * page_size\n            last_addr = addr + size - 1\n            result.append(named((addr, last_addr, size, num_pages, page_size),\n                          \"addr last_addr size num_pages page_size\"))\n            addr += size\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting a lits of devices detected in DFU mode.", "response": "def list_dfu_devices(*args, **kwargs):\n    \"\"\"Prints a lits of devices detected in DFU mode.\"\"\"\n    devices = get_dfu_devices(*args, **kwargs)\n    if not devices:\n        print(\"No DFU capable devices found\")\n        return\n    for device in devices:\n        print(\"Bus {} Device {:03d}: ID {:04x}:{:04x}\"\n              .format(device.bus, device.address,\n                      device.idVendor, device.idProduct))\n        layout = get_memory_layout(device)\n        print(\"Memory Layout\")\n        for entry in layout:\n            print(\"    0x{:x} {:2d} pages of {:3d}K bytes\"\n                  .format(entry['addr'], entry['num_pages'],\n                          entry['page_size'] // 1024))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite the indicated elements into the target memory erasing as needed.", "response": "def write_elements(elements, mass_erase_used, progress=None):\n    \"\"\"Writes the indicated elements into the target memory,\n    erasing as needed.\n    \"\"\"\n\n    mem_layout = get_memory_layout(__dev)\n    for elem in elements:\n        addr = elem['addr']\n        size = elem['size']\n        data = elem['data']\n        elem_size = size\n        elem_addr = addr\n        if progress:\n            progress(elem_addr, 0, elem_size)\n        while size > 0:\n            write_size = size\n            if not mass_erase_used:\n                for segment in mem_layout:\n                    if addr >= segment['addr'] and \\\n                       addr <= segment['last_addr']:\n                        # We found the page containing the address we want to\n                        # write, erase it\n                        page_size = segment['page_size']\n                        page_addr = addr & ~(page_size - 1)\n                        if addr + write_size > page_addr + page_size:\n                            write_size = page_addr + page_size - addr\n                        page_erase(page_addr)\n                        break\n            write_memory(addr, data[:write_size], progress,\n                         elem_addr, elem_size)\n            data = data[write_size:]\n            addr += write_size\n            size -= write_size\n            if progress:\n                progress(elem_addr, addr - elem_addr, elem_size)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cli_progress(addr, offset, size):\n    width = 25\n    done = offset * width // size\n    print(\"\\r0x{:08x} {:7d} [{}{}] {:3d}% \"\n          .format(addr, size, '=' * done, ' ' * (width - done),\n                  offset * 100 // size), end=\"\")\n    try:\n        sys.stdout.flush()\n    except OSError:\n        pass # Ignore Windows CLI \"WinError 87\" on Python 3.6\n    if offset == size:\n        print(\"\")", "response": "Prints a progress report suitable for use on the command line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main():\n    global __verbose\n    # Parse CMD args\n    parser = argparse.ArgumentParser(description='DFU Python Util')\n    #parser.add_argument(\"path\", help=\"file path\")\n    parser.add_argument(\n        \"-l\", \"--list\",\n        help=\"list available DFU devices\",\n        action=\"store_true\",\n        default=False\n    )\n    parser.add_argument(\n        \"-m\", \"--mass-erase\",\n        help=\"mass erase device\",\n        action=\"store_true\",\n        default=False\n    )\n    parser.add_argument(\n        \"-u\", \"--upload\",\n        help=\"read file from DFU device\",\n        dest=\"path\",\n        default=False\n    )\n    parser.add_argument(\n        \"-v\", \"--verbose\",\n        help=\"increase output verbosity\",\n        action=\"store_true\",\n        default=False\n    )\n    args = parser.parse_args()\n\n    __verbose = args.verbose\n\n    if args.list:\n        list_dfu_devices(idVendor=__VID, idProduct=__PID)\n        return\n\n    init()\n\n    if args.mass_erase:\n        print (\"Mass erase...\")\n        mass_erase()\n\n    if args.path:\n        elements = read_dfu_file(args.path)\n        if not elements:\n            return\n        print(\"Writing memory...\")\n        write_elements(elements, args.mass_erase, progress=cli_progress)\n\n        print(\"Exiting DFU...\")\n        exit_dfu()\n        return\n\n    print(\"No command specified\")", "response": "Test program for verifying this files functionality."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_port_pin(name_str):\n    if len(name_str) < 3:\n        raise ValueError(\"Expecting pin name to be at least 3 charcters.\")\n    if name_str[0] != 'P':\n        raise ValueError(\"Expecting pin name to start with P\")\n    if name_str[1] < 'A' or name_str[1] > 'K':\n        raise ValueError(\"Expecting pin port to be between A and K\")\n    port = ord(name_str[1]) - ord('A')\n    pin_str = name_str[2:]\n    if not pin_str.isdigit():\n        raise ValueError(\"Expecting numeric pin number.\")\n    return (port, int(pin_str))", "response": "Parses a string and returns a tuple of port and pin."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print(self):\n        cond_var = None\n        if self.supported:\n            cond_var = conditional_var('{}{}'.format(self.func, self.fn_num))\n            print_conditional_if(cond_var)\n            print('  AF',  end='')\n        else:\n            print('  //', end='')\n        fn_num = self.fn_num\n        if fn_num is None:\n            fn_num = 0\n        print('({:2d}, {:8s}, {:2d}, {:10s}, {:8s}), // {:s}'.format(self.idx,\n              self.func, fn_num, self.pin_type, self.ptr(), self.af_str))\n        print_conditional_endif(cond_var)", "response": "Prints the C representation of this AF."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a string and returns a tuple containing the port and gpio bit.", "response": "def parse_port_pin(name_str):\n    \"\"\"Parses a string and returns a (port, gpio_bit) tuple.\"\"\"\n    if len(name_str) < 3:\n        raise ValueError(\"Expecting pin name to be at least 3 characters\")\n    if name_str[:2] != 'GP':\n        raise ValueError(\"Expecting pin name to start with GP\")\n    if not name_str[2:].isdigit():\n        raise ValueError(\"Expecting numeric GPIO number\")\n    port = int(int(name_str[2:]) / 8)\n    gpio_bit = 1 << int(int(name_str[2:]) % 8)\n    return (port, gpio_bit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run_node(cls,\n                 node,  # type: NodeProto\n                 inputs,  # type: Any\n                 device='CPU',  # type: Text\n                 outputs_info=None,  # type: Optional[Sequence[Tuple[numpy.dtype, Tuple[int, ...]]]]\n                 **kwargs  # type: Dict[Text, Any]\n                 ):  # type: (...) -> Optional[Tuple[Any, ...]]\n        '''Simple run one operator and return the results.\n        Args:\n            outputs_info: a list of tuples, which contains the element type and\n            shape of each output. First element of the tuple is the dtype, and\n            the second element is the shape. More use case can be found in\n            https://github.com/onnx/onnx/blob/master/onnx/backend/test/runner/__init__.py\n        '''\n        # TODO Remove Optional from return type\n        if 'opset_version' in kwargs:\n            special_context = c_checker.CheckerContext()\n            special_context.ir_version = IR_VERSION\n            special_context.opset_imports = {'': kwargs['opset_version']}  # type: ignore\n            onnx.checker.check_node(node, special_context)\n        else:\n            onnx.checker.check_node(node)\n        return None", "response": "Simple run one operator and return the results."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload the raw_data field of the given tensor into the object.", "response": "def load_external_data_for_tensor(tensor, base_dir):  # type: (TensorProto, Text) -> None\n    \"\"\"\n    Load data from an external file for tensor.\n\n    @params\n    tensor: a TensorProto object.\n    base_dir: directory that contains the external data.\n    \"\"\"\n    if tensor.HasField(\"raw_data\"):  # already loaded\n        return\n    info = ExternalDataInfo(tensor)\n    file_location = _sanitize_path(info.location)\n    external_data_file_path = os.path.join(base_dir, file_location)\n\n    with open(external_data_file_path, 'rb') as data_file:\n\n        if info.offset:\n            data_file.seek(info.offset)\n\n        if info.length:\n            tensor.raw_data = data_file.read(info.length)\n        else:\n            tensor.raw_data = data_file.read()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_external_data_for_model(model, base_dir):  # type: (ModelProto, Text) -> None\n    for tensor in _get_all_tensors(model):\n        if uses_external_data(tensor):\n            load_external_data_for_tensor(tensor, base_dir)", "response": "Loads external data for all tensors in the given model into the specified base_dir."}
